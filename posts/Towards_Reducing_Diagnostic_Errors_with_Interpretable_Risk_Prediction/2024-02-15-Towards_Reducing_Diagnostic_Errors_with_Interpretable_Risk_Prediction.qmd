
---
title: "Towards Reducing Diagnostic Errors with Interpretable Risk Prediction"
id: "2402.10109v1"
description: "Method uses LLMs to identify evidence in EHRs, reduce diagnostic errors, and mitigate delays."
author: Denis Jered McInerney, William Dickinson, Lucy Flynn, Andrea Young, Geoffrey Young, Jan-Willem van de Meent, Byron C. Wallace
date: "2024-02-15"
image: "../../img/2402.10109v1/image_1.png"
categories: ['production']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.10109v1/image_1.png)

### Summary:
- The article proposes a method to use LLMs to identify pieces of evidence in patient EHR data that indicate increased or decreased risk of specific diagnoses.
- The ultimate aim is to increase access to evidence and reduce diagnostic errors.
- The proposed approach uses a Neural Additive Model to make predictions backed by evidence with individualized risk estimates at time-points where clinicians are still uncertain.

### Major Findings:
1. Diagnostic errors result in around 795,000 serious harms annually.
2. The proposed approach combines the power and flexibility of zero-shot instruction-tuned LLMs with the transparency and modeling ability of Neural Additive Models to train a risk-prediction model that can also surface evidence to support predictions.
3. The proposed approach offers a particular form of interpretability that can expose faithful relationships between specific pieces of retrieved evidence and an output prediction.

### Analysis and Critique:
- The proposed approach shows promise in reducing diagnostic errors by providing interpretable risk predictions backed by evidence.
- However, there are concerns about the use of abstractive "evidence" produced by LLMs, which may lead to hallucinations and potentially mislead clinicians.
- The study is limited by the small number of annotations and the lack of significant baseline models for comparison.
- Future work should focus on addressing the potential risks of hallucinated evidence and improving the recall of the system while maintaining precision.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.10109v1](https://arxiv.org/abs/2402.10109v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.10109v1](https://browse.arxiv.org/html/2402.10109v1)       |
| Truncated       | False       |
| Word Count       | 14424       |