
---
title: "Chain-of-Thought Reasoning Without Prompting"
id: "2402.10200v1"
description: "Novel approach uses top-k decoding to elicit reasoning paths in LLMs without prompting."
author: Xuezhi Wang, Denny Zhou
date: "2024-02-15"
image: "../../img/2402.10200v1/image_1.png"
categories: ['education', 'prompt-engineering', 'production']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.10200v1/image_1.png)

### Summary:
- The authors propose a novel approach called CoT-decoding to elicit chain-of-thought (CoT) reasoning from large language models (LLMs) without the use of prompting. This approach significantly outperforms standard greedy decoding across various reasoning benchmarks, demonstrating the models' inherent reasoning capabilities.
- CoT-decoding is shown to be more sample-efficient and capable of recovering CoT reasoning paths during decoding without the need for specialized prompting. It enhances models' reasoning ability over the greedy decoding approach, particularly in mathematical reasoning tasks, natural language reasoning tasks, and symbolic reasoning tasks.
- The paper contrasts existing works that require prompting for reasoning paths with the approach presented, which removes the need for explicit prompting and explores alternative decoding paths.

### Major Findings:
1. CoT-decoding significantly outperforms standard greedy decoding across various reasoning benchmarks, demonstrating the models' inherent reasoning capabilities.
2. CoT-decoding enhances models' reasoning ability over the greedy decoding approach, particularly in mathematical reasoning tasks, natural language reasoning tasks, and symbolic reasoning tasks.
3. The approach presented in the paper removes the need for explicit prompting and explores alternative decoding paths, contributing to the improvement of language models' reasoning capabilities.

### Analysis and Critique:
- The study provides valuable insights into the effectiveness of CoT-decoding in improving the reasoning abilities of large language models without the need for specialized prompting. However, potential limitations or biases in the experimental settings and the need for further research on enhancing decoding algorithms specifically for reasoning tasks are areas that require attention.
- The examples provided demonstrate the effectiveness of CoT-decoding in eliciting chain-of-thought reasoning and generating more accurate responses compared to greedy decoding, highlighting the potential of CoT-decoding to improve reasoning and problem-solving capabilities in language models.
- The detailed discussion of experimental settings and additional processing steps adds transparency to the evaluation process and addresses potential limitations of the models, contributing to the reproducibility and reliability of the study's results.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.10200v1](https://arxiv.org/abs/2402.10200v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.10200v1](https://browse.arxiv.org/html/2402.10200v1)       |
| Truncated       | True       |
| Word Count       | 20101       |