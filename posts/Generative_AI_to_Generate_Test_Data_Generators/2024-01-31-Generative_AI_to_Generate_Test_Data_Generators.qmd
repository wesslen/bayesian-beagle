
---
title: "Generative AI to Generate Test Data Generators"
id: "2401.17626v1"
description: "AI can effectively generate realistic test data across different domains and languages."
author: Benoit Baudry, Khashayar Etemadi, Sen Fang, Yogya Gamage, Yi Liu, Yuxin Liu, Martin Monperrus, Javier Ron, Andr√© Silva, Deepika Tiwari
date: "2024-01-31"
image: "../../../bayesian-beagle.png"
categories: ['prompt-engineering', 'security', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](None)

### **Summary:**
The article discusses the use of Large Language Models (LLMs) to generate fake test data for software testing. It highlights the challenges of generating realistic test data and the potential of LLMs to address these challenges. The authors present a study where they prompt LLMs to generate test data and evaluate the results based on domain adequacy, executability, and compatibility with existing faking libraries.

### Major Findings:
1. **Domain Adequacy:**
   - LLMs are able to generate high-quality test data that is appropriate for the specified application domain.
   - The study shows strong domain adequacy for high-resource languages such as Chinese, French, Hindi, Portuguese, and Spanish.
   
2. **Executability:**
   - LLMs are capable of synthesizing executable code that generates fake data, including data constraints related to cultural contexts such as wine-pairing conventions in Portuguese cuisine.
   - The study demonstrates the successful execution of LLM-generated code for generating Farsi poetry in right-to-left script.

3. **Compatibility with Existing Faking Libraries:**
   - LLMs can generate new fakers that are directly interoperable with existing test suites, as demonstrated by the successful integration of an LLM-generated faker into a mature Java project's test suite.
   - The study shows that LLM-generated fakers can seamlessly replace conventional fakers in real-world test suites.

### Analysis and Critique:
The article provides valuable insights into the potential of LLMs for generating test data, addressing the challenges of domain adequacy, executability, and compatibility with existing faking libraries. However, the study primarily focuses on high-resource languages, and the limitations of LLMs for low-resource languages are acknowledged. Additionally, the article could benefit from discussing potential ethical considerations and biases associated with using LLMs for generating culturally relevant test data. Further research is needed to explore the generalizability of the findings to a wider range of application domains and cultural contexts.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-02       |
| Abstract | [https://arxiv.org/abs/2401.17626v1](https://arxiv.org/abs/2401.17626v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.17626v1](https://browse.arxiv.org/html/2401.17626v1)       |
| Truncated       | False       |
| Word Count       | 9452       |