
---
title: "LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation"
id: "2408.08208v1"
description: "LLM4DSR: A model-agnostic approach for denoising sequential recommendation using LLMs, outperforming existing methods."
author: Bohao Wang, Feng Liu, Jiawei Chen, Yudi Wu, Xingyu Lou, Jun Wang, Yan Feng, Chun Chen, Can Wang
date: "2024-08-15"
image: "https://browse.arxiv.org/html/2408.08208v1/extracted/5794041/fail_case.png"
categories: ['recommender']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.08208v1/extracted/5794041/fail_case.png)

### Summary:

The paper introduces LLM4DSR, a novel approach for denoising sequential recommendations using Large Language Models (LLMs). The method addresses the challenges of employing LLMs for denoising tasks, such as the incompetence of pre-trained LLMs for the task and the reliability of LLM outputs. LLM4DSR utilizes a self-supervised fine-tuning task to activate LLMs' capabilities to identify noisy items and suggest replacements. Additionally, an uncertainty estimation module ensures that only high-confidence responses are used for sequence corrections. The model-agnostic nature of LLM4DSR allows for the corrected sequences to be applied across various recommendation models. Extensive experiments validate the superiority of LLM4DSR over existing methods across three datasets and three recommendation backbones.

### Major Findings:

1. LLM4DSR is a tailored approach for denoising sequential recommendations using LLMs, addressing the challenges of employing LLMs for denoising tasks.
2. The method utilizes a self-supervised fine-tuning task to activate LLMs' capabilities to identify noisy items and suggest replacements.
3. An uncertainty estimation module ensures that only high-confidence responses are used for sequence corrections, improving the accuracy and flexibility of the denoising process.
4. LLM4DSR is model-agnostic, allowing for the corrected sequences to be applied across various recommendation models.
5. Extensive experiments validate the superiority of LLM4DSR over existing methods across three datasets and three recommendation backbones.

### Analysis and Critique:

While LLM4DSR demonstrates significant improvements in denoising sequential recommendations, there are potential limitations and areas for further research. The computational cost of using LLMs may be higher than traditional methods, which could be addressed by employing techniques such as knowledge distillation to transfer the denoising capabilities to smaller models. Additionally, the paper does not discuss the potential biases in the pre-trained LLM outputs, which could amplify biases present in the data. Future research should focus on addressing these issues and further validating the effectiveness of LLM4DSR in real-world applications.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-20       |
| Abstract | [https://arxiv.org/abs/2408.08208v1](https://arxiv.org/abs/2408.08208v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.08208v1](https://browse.arxiv.org/html/2408.08208v1)       |
| Truncated       | False       |
| Word Count       | 7657       |