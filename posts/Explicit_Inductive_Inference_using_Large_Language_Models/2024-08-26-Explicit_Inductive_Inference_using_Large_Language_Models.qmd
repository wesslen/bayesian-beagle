
---
title: "Explicit Inductive Inference using Large Language Models"
id: "2408.14467v1"
description: "LLMs exhibit undesirable attestation bias, which our proposed pipeline mitigates, improving inference performance."
author: Tianyang Liu, Tianyi Li, Liang Cheng, Mark Steedman
date: "2024-08-26"
image: "https://browse.arxiv.org/html/2408.14467v1/extracted/5814627/pictures/narrow.png"
categories: ['production']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.14467v1/extracted/5814627/pictures/narrow.png)

# Summary:

**Summary:**

- The paper proposes a pipeline called Explicit Inductive Inference (EIDI) to improve the performance of Large Language Models (LLMs) on inference tasks.
- The EIDI pipeline exploits the attestation bias of LLMs, which is the tendency to use the out-of-context truth label of a hypothesis instead of its conditional truthfulness entailed by the premise.
- The pipeline transforms a premise into a set of attested alternatives by replacing the arguments and aggregates the LLM's predictions on these derived inquiries to support answering the original question.
- The EIDI pipeline is tested on a directional predicate entailment benchmark and is shown to improve the overall performance of LLMs on inference and substantially alleviate the impact of their attestation bias.

**Major Findings:**

1. The EIDI pipeline improves LLMs' performance on predicate inference.
2. The EIDI pipeline substantially alleviates the negative effects of the LLMs' attestation bias.
3. The EIDI pipeline uses LLMs' own generation capability without requiring external knowledge.

**Analysis and Critique:**

- The paper does not discuss the potential limitations or shortcomings of the proposed pipeline.
- The paper does not provide a detailed analysis of the methodology used to evaluate the performance of the EIDI pipeline.
- The paper does not discuss the potential impact of the EIDI pipeline on other inference tasks or its generalizability to other domains.
- The paper does not discuss the potential ethical implications of using the EIDI pipeline to improve the performance of LLMs on inference tasks.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-27       |
| Abstract | [https://arxiv.org/abs/2408.14467v1](https://arxiv.org/abs/2408.14467v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.14467v1](https://browse.arxiv.org/html/2408.14467v1)       |
| Truncated       | False       |
| Word Count       | 4032       |