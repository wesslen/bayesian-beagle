
---
title: "LoRec: Large Language Model for Robust Sequential Recommendation against Poisoning Attacks"
id: "2401.17723v1"
description: "TL;DR: LLM4Dec detects unknown fraudsters in recommender systems, LoRec integrates LLMs to defend against poisoning attacks."
author: Kaike Zhang, Qi Cao, Yunfan Wu, Fei Sun, Huawei Shen, Xueqi Cheng
date: "2024-01-31"
image: "../../../bayesian-beagle.png"
categories: ['recommender', 'security', 'architectures', 'production']
format:
  html:
    code-overflow: wrap
---

![](None)

### Overall Summary:

The article introduces two frameworks, LLM4Dec and LoRec, designed to enhance the robustness of sequential recommender systems against fraudulent activities and poisoning attacks. LLM4Dec leverages Large Language Models (LLMs) to detect fraudulent activities by transforming user interaction data into prompts to query LLMs' knowledge. It utilizes a two-layer perceptron and an Entropy Regularization term to compute the probability that a user is fraudulent. On the other hand, LoRec integrates an LLM-enhanced Calibrator to estimate the likelihood of users being fraudsters and calibrate user weights during the training phase of the recommender system. Both frameworks demonstrate the potential to generalize across different types of attacks, including unknown ones, and enhance the robustness of recommender systems.

### Major Findings:
1. LLM4Dec and LoRec demonstrate the potential to generalize across different types of fraudulent activities and poisoning attacks, including unknown ones.
2. The frameworks effectively enhance the robustness of sequential recommender systems against poisoning attacks while preserving recommendation performance.
3. The LLM4Dec framework's loss function, including a regularization term, prevents extreme predictions, contributing to its overall effectiveness.

### Analysis and Critique:
The article represents a significant advancement in the detection of fraudulent activities and the mitigation of poisoning attacks in sequential recommender systems. However, potential limitations or areas for further research include the need for more extensive real-world testing and the exploration of the frameworks' adaptability to diverse recommendation settings and backbone models. Additionally, the impact of hyperparameters and the size of the LLM on the frameworks' performance could be further investigated. Overall, the frameworks show promise in enhancing the security and reliability of recommender systems, but further research is needed to fully understand their real-world applicability and potential limitations.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-02       |
| Abstract | [https://arxiv.org/abs/2401.17723v1](https://arxiv.org/abs/2401.17723v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.17723v1](https://browse.arxiv.org/html/2401.17723v1)       |
| Truncated       | True       |
| Word Count       | 17835       |