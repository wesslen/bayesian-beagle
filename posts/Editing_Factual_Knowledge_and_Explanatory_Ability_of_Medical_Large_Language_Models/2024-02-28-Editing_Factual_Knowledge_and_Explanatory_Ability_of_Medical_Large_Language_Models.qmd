
---
title: "Editing Factual Knowledge and Explanatory Ability of Medical Large Language Models"
id: "2402.18099v1"
description: "Model editing improves large language models for medical knowledge without affecting irrelevant information."
author: Derong Xu, Ziheng Zhang, Zhihong Zhu, Zhenxi Lin, Qidong Liu, Xian Wu, Tong Xu, Xiangyu Zhao, Yefeng Zheng, Enhong Chen
date: "2024-02-28"
image: "https://browse.arxiv.org/html/2402.18099v1/x1.png"
categories: ['architectures', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.18099v1/x1.png)

### **Summary:**
- Model editing aims to modify the behaviors of large language models (LLMs) by precisely manipulating specific knowledge while keeping other knowledge unaffected.
- The proposed MedLaSA strategy employs causal tracing to identify the precise location of knowledge in neurons and introduces scalable adapters into the dense layers of LLMs.
- Extensive experiments on medical LLMs demonstrate the editing efficiency of MedLaSA, without affecting irrelevant knowledge that is not edited.

### Major Findings:
1. Model editing methods struggle with the specialization and complexity of medical knowledge.
2. MedLaSA significantly outperforms existing cutting-edge methods in editing medical LLMs.
3. The removal of Scaling Rank (SR) leads to a decline in all metrics, indicating its crucial role in maintaining the overall performance.

### Analysis and Critique:
- The proposed MedLaSA method effectively addresses the challenges of specialization and complexity of medical knowledge in model editing.
- However, the method may have a negative impact on Generality and lacks consideration for batch editing and sequence editing.
- The datasets used for medical model editing do not consider more robust evaluations, such as portability, and the number of samples for medical model editing is relatively small.
- The performance of MedLaSA on encyclopedic data remains to be explored.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.18099v1](https://arxiv.org/abs/2402.18099v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.18099v1](https://browse.arxiv.org/html/2402.18099v1)       |
| Truncated       | False       |
| Word Count       | 6898       |