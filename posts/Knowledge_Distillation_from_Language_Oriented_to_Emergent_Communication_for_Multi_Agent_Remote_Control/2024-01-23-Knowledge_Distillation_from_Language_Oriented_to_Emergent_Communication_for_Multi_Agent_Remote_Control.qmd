
---
title: "Knowledge Distillation from Language-Oriented to Emergent Communication for Multi-Agent Remote Control"
id: "2401.12624v1"
description: "Comparison finds emergent communication (EC) incurs high training cost, while language-oriented semantic communication (LSC) yields high inference cost. Proposed language-guided EC (LEC) achieves faster travel time and speeds up training convergence."
author: ['Yongjun Kim', 'Sejin Seo', 'Jihong Park', 'Mehdi Bennis', 'Seong-Lyun Kim', 'Junil Choi']
date: "2024-01-23"
image: "https://browse.arxiv.org/html/2401.12624v1/extracted/5362782/Fig_LEC_Summary.png"
categories: ['hci', 'production', 'architectures']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.12624v1/extracted/5362782/Fig_LEC_Summary.png)

**Summary:**

The article compares emergent communication (EC) based on multi-agent deep reinforcement learning (MADRL) with language-oriented semantic communication (LSC) empowered by a pre-trained large language model (LLM). The comparison is made in the context of a multi-agent remote navigation task, using multimodal input data comprising location and channel maps. The study shows that EC incurs high training cost and struggles with multimodal data, while LSC yields high inference computing cost due to the large size of the LLM. To address these limitations, the authors propose a language-guided EC (LEC) framework by guiding EC training using LSC via knowledge distillation. The simulations demonstrate that LEC achieves faster travel time and improves MADRL training convergence compared to EC.

### Major Findings:
1. Emergent communication (EC) struggles with multimodal data and incurs high training cost, while language-oriented semantic communication (LSC) yields high inference computing cost due to the large size of the pre-trained large language model (LLM).
2. Language-guided EC (LEC) addresses the limitations of EC and LSC, achieving faster travel time and speeding up the MADRL training convergence by up to 61.8% compared to EC.
3. LEC demonstrates low computing costs during both training and inference, thanks to in-context learning of LSC and training convergence acceleration of knowledge distillation (KD) in EC.

### Analysis and Critique:

The article provides a comprehensive comparison between emergent communication (EC) and language-oriented semantic communication (LSC), along with the introduction of the innovative language-guided EC (LEC) framework. The study offers valuable insights into the strengths and weaknesses of each communication approach and illustrates the potential of combining EC with LSC using knowledge distillation.

One potential limitation of the study is its reliance on simulations to validate the proposed LEC framework. While the simulations demonstrate promising results, the real-world applicability of LEC may vary, especially in dynamic and complex environments. Additionally, the article focuses on a specific multi-agent remote navigation task, and the generalizability of LEC to other domains or tasks remains unclear. Further research should investigate the robustness and scalability of LEC across diverse real-world scenarios.

The article also highlights the high computing costs associated with LSC, which could limit its practical implementation in resource-constrained environments. Therefore, future studies should explore methods to optimize the computational efficiency of LSC without compromising its effectiveness.

Overall, the article presents an innovative approach to address the limitations of existing communication paradigms and offers valuable implications for the development of efficient multi-agent communication systems. However, further empirical studies and real-world validations are necessary to fully assess the practical utility and limitations of the proposed LEC framework.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-02       |
| Abstract | [http://arxiv.org/abs/2401.12624v1](http://arxiv.org/abs/2401.12624v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.12624v1](https://browse.arxiv.org/html/2401.12624v1)       |
| Truncated       | False       |
| Word Count       | 5666       |