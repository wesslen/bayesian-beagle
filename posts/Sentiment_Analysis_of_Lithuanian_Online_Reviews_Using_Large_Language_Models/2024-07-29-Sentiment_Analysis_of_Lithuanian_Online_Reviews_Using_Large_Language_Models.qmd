
---
title: "Sentiment Analysis of Lithuanian Online Reviews Using Large Language Models"
id: "2407.19914v1"
description: "This work explores transformer models for Lithuanian sentiment analysis, achieving high accuracy and outperforming GPT-4."
author: Brigita Vileikytė, Mantas Lukoševičius, Lukas Stankevičius
date: "2024-07-29"
image: "../../../bayesian-beagle.png"
categories: ['architectures', 'social-sciences']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### Summary:

- The paper focuses on sentiment analysis of Lithuanian five-star-based online reviews from multiple domains, using transformer models for the first time.
- The authors apply pre-trained multilingual Large Language Models (LLMs), specifically fine-tuning BERT and T5 models.
- The fine-tuned models perform well, especially when sentiments are less ambiguous, with 80.74% and 89.61% testing recognition accuracy for the most popular one- and five-star reviews, respectively.
- The fine-tuned models significantly outperform current commercial state-of-the-art general-purpose LLM GPT-4.

### Major Findings:

1. The fine-tuned BERT and T5 models perform well in sentiment analysis of Lithuanian online reviews, with high testing recognition accuracy for the most popular one- and five-star reviews.
2. The fine-tuned models significantly outperform current commercial state-of-the-art general-purpose LLM GPT-4.
3. The fine-tuned models are effective in handling the inherent difficulty of the task, especially when sentiments are less ambiguous.

### Analysis and Critique:

- The paper provides a valuable contribution to the field of sentiment analysis for less-studied and less-resourced languages such as Lithuanian.
- The use of transformer models and fine-tuning of BERT and T5 models is a novel approach to sentiment analysis of Lithuanian online reviews.
- The high testing recognition accuracy of the fine-tuned models demonstrates the effectiveness of the approach.
- However, the paper does not provide a detailed comparison of the performance of the fine-tuned models with other existing methods for sentiment analysis of Lithuanian online reviews.
- Additionally, the paper does not discuss the potential limitations of the approach, such as the need for large amounts of labeled data for fine-tuning the models.
- Further research is needed to evaluate the generalizability of the approach to other less-studied and less-resourced languages.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-30       |
| Abstract | [https://arxiv.org/abs/2407.19914v1](https://arxiv.org/abs/2407.19914v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.19914v1](https://browse.arxiv.org/html/2407.19914v1)       |
| Truncated       | False       |
| Word Count       | 8863       |