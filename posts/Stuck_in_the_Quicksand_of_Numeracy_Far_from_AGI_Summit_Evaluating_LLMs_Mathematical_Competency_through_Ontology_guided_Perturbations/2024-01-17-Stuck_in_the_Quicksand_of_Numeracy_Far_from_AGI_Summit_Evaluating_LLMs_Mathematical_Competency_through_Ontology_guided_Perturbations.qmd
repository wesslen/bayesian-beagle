
---
title: "Stuck in the Quicksand of Numeracy, Far from AGI Summit: Evaluating LLMs' Mathematical Competency through Ontology-guided Perturbations"
id: "2401.09395v1"
description: "Advancements in language models excel in reasoning, but struggle with math; created dataset exposes limitations. Models' robustness questioned."
author: ['Pengfei Hong', 'Deepanway Ghosal', 'Navonil Majumder', 'Somak Aditya', 'Rada Mihalcea', 'Soujanya Poria']
date: "2024-01-17"
image: "https://browse.arxiv.org/html/2401.09395v1/x2.png"
categories: ['production', 'architectures', 'education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.09395v1/x2.png)

### Summary of the Article:

The article evaluates the mathematical competency of Large Language Models (LLMs) by developing an ontology of perturbations for math questions, using the GPT-4 model to generate a dataset of 216 perturbed math problems, and conducting a comprehensive evaluation of LLMs on these perturbed questions. The results reveal a significant performance drop across all LLM models, suggesting their lack of robust mathematical skills and deep reasoning abilities. The researchers propose a novel extensive extensible ontology of perturbation operations and provide a way to semi-automatically create such perturbations. They benchmark five state-of-the-art LLMs' numeracy abilities on the dataset and observe how these models can be fragile, exposing their limitations in reasoning. The article emphasizes the importance of assessing the mathematical problem-solving and analytical capabilities of LLMs beyond conventional leaderboard performance metrics.

### Major Findings:
1. Controlled perturbations of math questions using the ontology resulted in a dataset of 216 perturbed math problems.
2. Comprehensive evaluation of LLMs on the perturbed questions showed a significant performance drop across all models, indicating their lack of robust mathematical skills and deep reasoning abilities.
3. The proposed ontology of perturbation operations and the dataset pave the way for a fresh perspective in assessing the mathematical problem-solving and analytical capabilities of LLMs.


### Analysis and Critique:
The article effectively addresses the limitations of current LLMs' mathematical reasoning abilities through a well-structured methodology. However, the reliance on GPT-4 for generating perturbed questions raises concerns about the quality and accuracy of the perturbations, which are acknowledged in the filtering and validation process. The human verification process ensures improved quality and relevance of the perturbed questions, but the potential impact of human bias in rephrasing or rewriting the questions should be considered. Additionally, the article lacks information about the specific limitations and weaknesses observed in different LLM models, which could provide more insights into their mathematical reasoning capabilities. Further research could focus on refining the perturbation process and exploring alternative methods for evaluating LLMs' mathematical competencies to enhance the validity of the findings.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-29       |
| Abstract | [http://arxiv.org/abs/2401.09395v1](http://arxiv.org/abs/2401.09395v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.09395v1](https://browse.arxiv.org/html/2401.09395v1)       |
| Truncated       | True       |
| Word Count       | 17363       |