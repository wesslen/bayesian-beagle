
---
title: "USDC: A Dataset of User Stance and Dogmatism in Long Conversations"
id: "2406.16833v1"
description: "LLMs automate annotation for user stance, dogmatism in Reddit conversations, creating USDC dataset for finetuning small language models."
author: Mounika Marreddy, Subba Reddy Oota, Venkata Charan Chinni, Manish Gupta, Lucie Flek
date: "2024-06-24"
image: "https://browse.arxiv.org/html/2406.16833v1/x2.png"
categories: ['production']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.16833v1/x2.png)

### Summary:

The paper presents a new dataset, USDC, which is a large-scale dataset of user stance and dogmatism in conversations. The dataset is created by using large language models (LLMs) as human-like annotators to generate author-level stance and dogmatism labels via zero, one, and few-shot settings. The full-length multi-user conversation aspect of USDC allows it to capture the contextual and opinion shifts of multiple users in a conversation. The dataset is used to finetune and instruction-tune small language models (SLMs) for user opinions at a large scale, which can bridge the gap between SLMs and commercial LLMs for understanding user traits. The results show that finetuning SLMs shows good F1-score on both stance and dogmatism tasks, but the F1-score remains below 60%. Instruction-tuning of SLMs only improves F1-score performance on stance, not the dogmatism task. The findings indicate that there is still significant room for improvement in understanding user opinions from a text segment.

### Major Findings:

1. The paper presents a new dataset, USDC, which is a large-scale dataset of user stance and dogmatism in conversations.
2. The dataset is created by using large language models (LLMs) as human-like annotators to generate author-level stance and dogmatism labels via zero, one, and few-shot settings.
3. The full-length multi-user conversation aspect of USDC allows it to capture the contextual and opinion shifts of multiple users in a conversation.
4. The dataset is used to finetune and instruction-tune small language models (SLMs) for user opinions at a large scale, which can bridge the gap between SLMs and commercial LLMs for understanding user traits.
5. The results show that finetuning SLMs shows good F1-score on both stance and dogmatism tasks, but the F1-score remains below 60%.
6. Instruction-tuning of SLMs only improves F1-score performance on stance, not the dogmatism task.

### Analysis and Critique:

The paper presents an interesting approach to creating a large-scale dataset of user stance and dogmatism in conversations using LLMs as human-like

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-07       |
| Abstract | [https://arxiv.org/abs/2406.16833v1](https://arxiv.org/abs/2406.16833v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.16833v1](https://browse.arxiv.org/html/2406.16833v1)       |
| Truncated       | False       |
| Word Count       | 9875       |