
---
title: "Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models"
id: "2402.03877v1"
description: "LLMs struggle with geometric reasoning, but a new framework enhances their abilities."
author: Spyridon Mouselinos, Henryk Michalewski, Mateusz Malinowski
date: "2024-02-06"
image: "../../img/2402.03877v1/image_1.png"
categories: ['prompt-engineering', 'education']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.03877v1/image_1.png)

### Summary:
- The article addresses the limitations of Large Language Models (LLMs) in solving constructive geometric problems and proposes a framework to overcome these challenges. It discusses biases and naming conventions observed in LLMs, presents a multi-agent setup for problem-solving, and explores the use of geometric tools and visual prompts to enhance reasoning capabilities.

### Major Findings:
1. LLMs struggle with spatial relationships, variable naming biases, and misrepresenting objects in geometric constructions.
2. The proposed framework includes adaptive prompting, multi-agent collaboration, visual relations prompts, and mitigating naming biases to enhance LLMs' geometric reasoning.
3. The multi-agent setup performs close to state-of-the-art methods, even in non-geometric setups, showing promise for improving LLMs' performance in mathematical problem-solving.

### Analysis and Critique:
- The article provides valuable insights into the challenges faced by LLMs in geometric reasoning and proposes innovative solutions to address these challenges.
- The experiments conducted shed light on the effectiveness of different approaches and configurations, contributing to a comprehensive understanding of the capabilities and limitations of LLMs in mathematical reasoning.
- The multi-agent setup and the promising results obtained have implications for the development of new generation LLMs and breakthroughs in domains requiring deep, specific, and accurate cognitive processing. The article also offers transparency and reproducibility in terms of the models, datasets, and experimental setup used, essential for potential replication or further research in the field of geometric reasoning in large language models.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-07       |
| Abstract | [https://arxiv.org/abs/2402.03877v1](https://arxiv.org/abs/2402.03877v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.03877v1](https://browse.arxiv.org/html/2402.03877v1)       |
| Truncated       | True       |
| Word Count       | 26470       |