
---
title: "Benchmarking Retrieval-Augmented Generation for Medicine"
id: "2402.13178v1"
description: "LLMs struggle with outdated knowledge, but RAG improves medical question answering accuracy."
author: Guangzhi Xiong, Qiao Jin, Zhiyong Lu, Aidong Zhang
date: "2024-02-20"
image: "https://browse.arxiv.org/html/2402.13178v1/x1.png"
categories: ['robustness', 'social-sciences', 'architectures', 'production']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.13178v1/x1.png)

### **Summary:**
- Retrieval-augmented generation (RAG) is a promising solution for addressing challenges with hallucinations and outdated knowledge in large language models (LLMs) for medical question answering (QA).
- The Medical Information Retrieval-Augmented Generation Evaluation (Mirage) benchmark was introduced to systematically evaluate RAG systems, including 7,663 questions from five medical QA datasets.
- MedRag, a toolkit for medical QA, was used to conduct large-scale experiments with over 1.8 trillion prompt tokens on 41 combinations of different corpora, retrievers, and backbone LLMs. The results showed that MedRag improved the accuracy of six different LLMs by up to 18% over chain-of-thought prompting, elevating the performance of GPT-3.5 and Mixtral to GPT-4-level.

### Major Findings:
1. MedRag improved the accuracy of six different LLMs by up to 18% over chain-of-thought prompting.
2. The combination of various medical corpora and retrievers achieved the best performance.
3. A log-linear scaling property and the "lost-in-the-middle" effects in medical RAG were discovered.

### Analysis and Critique:
- The study provides comprehensive evaluations and practical recommendations for medical RAG systems, but there are limitations in evaluating new RAG system designs, incorporating additional resources, and evaluating the retrieved snippets for examination datasets.
- Practical recommendations include corpus selection, retriever selection, and LLM selection based on the evaluation results. However, further research is needed to address the limitations and explore potential solutions.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-26       |
| Abstract | [https://arxiv.org/abs/2402.13178v1](https://arxiv.org/abs/2402.13178v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.13178v1](https://browse.arxiv.org/html/2402.13178v1)       |
| Truncated       | False       |
| Word Count       | 8966       |