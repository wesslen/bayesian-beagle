
---
title: "What Did I Do Wrong? Quantifying LLMs' Sensitivity and Consistency to Prompt Engineering"
id: "2406.12334v1"
description: "LLMs face debugging challenges; new metrics sensitivity and consistency introduced for classification tasks to improve LLM performance and robustness."
author: Federico Errica, Giuseppe Siracusano, Davide Sanvito, Roberto Bifulco
date: "2024-06-18"
image: "https://browse.arxiv.org/html/2406.12334v1/extracted/5674854/artificial-intelligence-ai-icon.png"
categories: ['programming']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.12334v1/extracted/5674854/artificial-intelligence-ai-icon.png)

### Summary:

- The paper introduces two metrics, sensitivity and consistency, to measure the performance of Large Language Models (LLMs) in classification tasks.
- Sensitivity measures changes in predictions across rephrasings of the prompt, while consistency measures how predictions vary across rephrasings for elements of the same class.
- The authors perform an empirical comparison of these metrics on text classification tasks and use them as a guideline for understanding failure modes of the LLM.
- The hope is that sensitivity and consistency will be powerful allies in automatic prompt engineering frameworks to obtain LLMs that balance robustness with performance.

### Major Findings:

1. Sensitivity and consistency are complementary to task performance and can help understand failure modes of LLMs.
2. Sensitivity measures changes in predictions across rephrasings of the prompt and does not require access to ground truth labels.
3. Consistency measures how predictions vary across rephrasings for elements of the same class.
4. The authors perform an empirical comparison of these metrics on text classification tasks and use them as a guideline for understanding failure modes of the LLM.
5. The authors hope that sensitivity and consistency will be powerful allies in automatic prompt engineering frameworks to obtain LLMs that balance robustness with performance.

### Analysis and Critique:

- The paper provides a novel approach to measuring the performance of LLMs in classification tasks.
- The use of sensitivity and consistency as metrics is a valuable contribution to the field of LLM research.
- However, the paper does not provide a comprehensive evaluation of these metrics on a wide range of tasks and datasets.
- The authors also do not discuss the limitations of these metrics or potential biases that may arise from their use.
- Further research is needed to evaluate the effectiveness of these metrics in real-world applications and to address any potential limitations or biases.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-23       |
| Abstract | [https://arxiv.org/abs/2406.12334v1](https://arxiv.org/abs/2406.12334v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.12334v1](https://browse.arxiv.org/html/2406.12334v1)       |
| Truncated       | False       |
| Word Count       | 6408       |