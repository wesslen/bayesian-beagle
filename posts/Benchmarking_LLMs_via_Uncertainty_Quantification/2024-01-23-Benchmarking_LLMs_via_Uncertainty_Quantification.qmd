
---
title: "Benchmarking LLMs via Uncertainty Quantification"
id: "2401.12794v1"
description: "New benchmarking approach introduces uncertainty quantification for Large Language Models, revealing its significance in evaluation."
author: Fanghua Ye, Mingming Yang, Jianhui Pang, Longyue Wang, Derek F. Wong, Emine Yilmaz, Shuming Shi, Zhaopeng Tu
date: "2024-01-23"
image: "https://browse.arxiv.org/html/2401.12794v1/x1.png"
categories: ['production', 'architectures']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.12794v1/x1.png)

### **Summary of the Article:**
The article discusses the importance of uncertainty quantification in the evaluation of Large Language Models (LLMs) and proposes a new benchmarking approach that integrates uncertainty quantification. The study includes the examination of eight LLMs across five Natural Language Processing (NLP) tasks and introduces a novel evaluation metric, UAcc, which takes into account both prediction accuracy and prediction uncertainty. The findings reveal that LLMs with higher accuracy may exhibit lower certainty, larger-scale LLMs may display greater uncertainty compared to smaller ones, and instruction-finetuning tends to increase the uncertainty of LLMs.

### Major Findings:
1. LLMs with higher accuracy may exhibit lower certainty.
2. Larger-scale LLMs may display greater uncertainty compared to their smaller counterparts.
3. Instruction-finetuning tends to increase the uncertainty of LLMs.

### Analysis and Critique:
The article successfully highlights the significance of incorporating uncertainty in the evaluation of LLMs, shedding light on the limitations of current evaluation platforms that neglect uncertainty. The proposed UAcc metric provides a more comprehensive assessment of LLMs by considering both prediction accuracy and uncertainty. However, the study does not provide a standardized methodology for benchmarking purpose, and the proposed approach may not be applicable to certain LLMs that are only accessible via their APIs. Additionally, it mainly focuses on language understanding abilities rather than generative potential, hence limiting its scope. Furthermore, the study does not delve into the evaluation of multi-modal foundation models, which represents an important area for future research.

Overall, while the article effectively demonstrates the importance of uncertainty quantification in LLM evaluation, it falls short in providing a standardized methodology for benchmarking purposes and addressing the generative capabilities of LLMs. Additionally, it overlooks the evaluation of multi-modal foundation models, which could impact the generalizability of the findings.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-24       |
| Abstract | [http://arxiv.org/abs/2401.12794v1](http://arxiv.org/abs/2401.12794v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.12794v1](https://browse.arxiv.org/html/2401.12794v1)       |
| Truncated       | False       |
| Word Count       | 12871       |