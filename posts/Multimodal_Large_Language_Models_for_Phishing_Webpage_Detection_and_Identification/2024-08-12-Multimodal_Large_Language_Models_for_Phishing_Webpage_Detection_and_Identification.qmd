
---
title: "Multimodal Large Language Models for Phishing Webpage Detection and Identification"
id: "2408.05941v1"
description: "LLMs effectively detect phishing webpages, offering high precision and interpretable results, outperforming existing brand-based systems."
author: Jehyun Lee, Peiyuan Lim, Bryan Hooi, Dinil Mon Divakaran
date: "2024-08-12"
image: "../../img/2408.05941v1/image_1.png"
categories: ['production', 'architectures', 'security']
format:
  html:
    code-overflow: wrap
---

![](../../img/2408.05941v1/image_1.png)

**Summary:**

This paper explores the use of multimodal large language models (LLMs) for detecting phishing webpages. The authors propose a two-phase system that employs LLMs in both phases: the first phase focuses on brand identification, while the second verifies the domain. The study evaluates three state-of-the-art multimodal LLMs, namely GPT-4, GeminiPro 1.0, and Claude3, on their capability to assist with phishing detection. The results demonstrate that LLMs show promise in detecting phishing pages at high precision, while also providing explanations. The system also performs significantly better than a state-of-the-art brand-based phishing detection system and demonstrates robustness against two known adversarial attacks.

**Major Findings:**

1. Multimodal LLMs, such as GPT-4, GeminiPro 1.0, and Claude3, can be used to detect phishing webpages with high precision and provide interpretable evidence for the decisions.
2. The proposed two-phase system, which uses LLMs for both brand identification and domain verification, outperforms a state-of-the-art brand-based phishing detection system.
3. The LLM-based system demonstrates robustness against two known adversarial attacks, making it a promising approach for phishing detection.

**Analysis and Critique:**

The paper presents an innovative approach to phishing detection using multimodal LLMs. The authors provide a comprehensive evaluation of the proposed system, demonstrating its effectiveness in detecting phishing webpages and its robustness against adversarial attacks. However, the study does not discuss the potential limitations or biases of the LLMs used in the system. Additionally, the paper does not address the potential challenges in maintaining and updating the LLMs as new phishing techniques emerge. Further research is needed to explore these aspects and ensure the long-term effectiveness of the proposed system.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-13       |
| Abstract | [https://arxiv.org/abs/2408.05941v1](https://arxiv.org/abs/2408.05941v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.05941v1](https://browse.arxiv.org/html/2408.05941v1)       |
| Truncated       | False       |
| Word Count       | 17527       |