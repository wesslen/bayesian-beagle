
---
title: "Decomposed Prompting: Unveiling Multilingual Linguistic Structure Knowledge in English-Centric Large Language Models"
id: "2402.18397v1"
description: "English-centric LLMs excel in multilingual tasks, decomposed prompting improves efficacy and efficiency in sequence labeling."
author: Ercong Nie, Shuzhou Yuan, Bolei Ma, Helmut Schmid, Michael Färber, Frauke Kreuter, Hinrich Schütze
date: "2024-02-28"
image: "https://browse.arxiv.org/html/2402.18397v1/x1.png"
categories: ['education', 'production', 'architectures', 'prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.18397v1/x1.png)

### **Summary:**
- The paper introduces the decomposed prompting approach to probe the linguistic structure understanding of English-centric Large Language Models (LLMs) in sequence labeling tasks.
- The method generates an individual prompt for each token of the input sentence, asking for its linguistic label.
- The study assesses the method on the Universal Dependencies part-of-speech tagging dataset for 38 languages, utilizing both English-centric and multilingual LLMs.
- Findings show that decomposed prompting surpasses the iterative prompting baseline in efficacy and efficiency under zero- and few-shot settings.
- The study offers insights into the multilingual transferability of English-centric LLMs, contributing to the understanding of their multilingual linguistic knowledge.

### Major Findings:
1. Decomposed prompting outperforms iterative prompting in efficacy and efficiency under zero- and few-shot settings.
2. English-centric LLMs perform better on average than multilingual models in multilingual investigations.
3. The inclusion of an instruction in prompts negatively impacts the performance of LLMs in both probability-based and generation-based evaluation methods.

### Analysis and Critique:
- The decomposed prompting strategy struggles if the same word occurs twice in a sentence with different POS tags.
- The efficiency of decomposed prompting suffers as the length of the input sequence and the complexity of the task increase.
- The study uses decomposed prompting methods for part-of-speech (POS) tagging as a means to evaluate the multilingual structural knowledge of English-centric Large Language Models (LLMs). However, the scope for extending this methodology to probe more intricate aspects of linguistic structure is substantial.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.18397v1](https://arxiv.org/abs/2402.18397v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.18397v1](https://browse.arxiv.org/html/2402.18397v1)       |
| Truncated       | False       |
| Word Count       | 6429       |