
---
title: "Navigating the Labyrinth: Evaluating and Enhancing LLMs' Ability to Reason About Search Problems"
id: "2406.12172v1"
description: "LLMs struggle with logic problems; in-context learning with A* algorithm and Multi-Stage-Multi-Try method improves performance."
author: Nasim Borazjanizadeh, Roei Herzig, Trevor Darrell, Rogerio Feris, Leonid Karlinsky
date: "2024-06-18"
image: "../../img/2406.12172v1/image_1.png"
categories: ['programming']
format:
  html:
    code-overflow: wrap
---

![](../../img/2406.12172v1/image_1.png)

**Summary:**

The paper introduces a new benchmark, SearchBench, to evaluate the reasoning abilities of Large Language Models (LLMs) on search problems. SearchBench consists of 11 unique search problems, each with automated pipelines for generating instances and analyzing solutions. The authors demonstrate that even advanced LLMs struggle with these problems, with GPT4 solving only 1.4% end-to-end in text. The paper proposes in-context learning with A* algorithm implementations and a Multi-Stage-Multi-Try (MSMT) method to enhance performance, raising GPT-4's performance above 57%.

**Key Terminology:**

* Large Language Models (LLMs)
* SearchBench
* A* algorithm
* Multi-Stage-Multi-Try (MSMT) method

**Major Findings:**

1. LLMs, including GPT4

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-23       |
| Abstract | [https://arxiv.org/abs/2406.12172v1](https://arxiv.org/abs/2406.12172v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.12172v1](https://browse.arxiv.org/html/2406.12172v1)       |
| Truncated       | True       |
| Word Count       | 72494       |