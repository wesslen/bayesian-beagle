
---
title: "On the Tip of the Tongue: Analyzing Conceptual Representation in Large Language Models with Reverse-Dictionary Probe"
id: "2402.14404v1"
description: "LLMs excel at reverse dictionary task, predicting general reasoning performance. In-context learning enhances conceptual inference."
author: Ningyu Xu, Qi Zhang, Menghan Zhang, Peng Qian, Xuanjing Huang
date: "2024-02-22"
image: "https://browse.arxiv.org/html/2402.14404v1/x1.png"
categories: ['prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.14404v1/x1.png)

### Summary:
- The article explores the conceptual inference capacity of large language models (LLMs) using the reverse dictionary task as a probe.
- LLMs demonstrate high accuracy in inferring object concepts from linguistic descriptions, and their representation space encodes information about object categories and fine-grained features.
- The conceptual inference ability as probed by the reverse-dictionary task predicts the model’s general reasoning performance across multiple benchmarks.

### Major Findings:
1. LLMs achieve high accuracy in the reverse dictionary task, indicating their capacity for conceptual inference.
2. The representation space of LLMs encodes information about object categories and fine-grained features.
3. The conceptual inference ability as probed by the reverse-dictionary task predicts the model’s general reasoning performance across multiple benchmarks.

### Analysis and Critique:
- The study provides valuable insights into the conceptual inference capacity of LLMs and its implications for general reasoning tasks.
- The article lacks an in-depth analysis of phrase-level meaning composition and does not provide a mechanistic explanation of how LLMs achieve the ability to perform the reverse dictionary task.
- The study's focus on definitional descriptions about concrete objects may limit the generalizability of the experimental results to a broader range of concepts and domains.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-26       |
| Abstract | [https://arxiv.org/abs/2402.14404v1](https://arxiv.org/abs/2402.14404v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.14404v1](https://browse.arxiv.org/html/2402.14404v1)       |
| Truncated       | False       |
| Word Count       | 9388       |