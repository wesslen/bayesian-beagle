
---
title: "Simulating Human Strategic Behavior: Comparing Single and Multi-agent LLMs"
id: "2402.08189v1"
description: "LLMs can simulate human strategic behavior in social settings, with multi-agent architecture more accurate."
author: Karthik Sreedhar, Lydia Chilton
date: "2024-02-13"
image: "https://browse.arxiv.org/html/2402.08189v1/extracted/5398680/figures/singleLLMsim.png"
categories: ['hci', 'social-sciences', 'architectures']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.08189v1/extracted/5398680/figures/singleLLMsim.png)

### Summary:
- The article investigates whether Large Language Models (LLMs) can simulate human strategic behavior, specifically in the context of the ultimatum game, which is a classic economics experiment used to understand human social strategic behavior.
- The study compares two LLM architectures: single- and multi-agent LLMs, and evaluates their abilities to simulate human-like actions in the ultimatum game, simulate two player personalities, and create robust strategies that are logically complete and consistent with personality.
- The evaluation shows that the multi-agent LLM architecture is much more accurate than single LLMs in simulating human strategy creation and actions for personality pairs, with the multi-agent architecture being consistent with human behavior 88% of the time, compared to 50% for single LLMs.

### Major Findings:
1. The multi-agent LLM architecture is much more accurate than single LLMs (88% vs. 50%) in simulating human strategy creation and actions for personality pairs.
2. Multi-agent LLMs outperformed single LLMs in modeling the actions of player personalities, achieving human-like gameplay for all four personality pairs at least 80% of the time.
3. Multi-agent architectures create robust strategies at a higher rate than SingleLLMs, with MultiAgent-4 creating complete and personality-consistent strategies for both players in 87.5% of simulations.

### Analysis and Critique:
- The study provides valuable insights into the potential of LLMs to simulate human strategic behavior, particularly in complex scenarios such as the ultimatum game.
- The comparison between single- and multi-agent LLM architectures highlights the advantages of the multi-agent approach in accurately modeling human-like actions and creating robust strategies.
- However, the study could benefit from further exploration of the limitations and challenges associated with LLM simulations, as well as the implications for real-world applications and decision-making processes. Additionally, the article could address potential ethical considerations and biases in LLM-based simulations.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.08189v1](https://arxiv.org/abs/2402.08189v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.08189v1](https://browse.arxiv.org/html/2402.08189v1)       |
| Truncated       | False       |
| Word Count       | 7434       |