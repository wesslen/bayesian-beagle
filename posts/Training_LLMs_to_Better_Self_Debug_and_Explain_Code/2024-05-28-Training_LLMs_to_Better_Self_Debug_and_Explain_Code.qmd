
---
title: "Training LLMs to Better Self-Debug and Explain Code"
id: "2405.18649v1"
description: "LLMs trained with our framework improve code generation, iterative refinement, and bug understanding."
author: Nan Jiang, Xiaopeng Li, Shiqi Wang, Qiang Zhou, Soneya Binta Hossain, Baishakhi Ray, Varun Kumar, Xiaofei Ma, Anoop Deoras
date: "2024-05-28"
image: "https://browse.arxiv.org/html/2405.18649v1/x1.png"
categories: ['robustness', 'programming']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2405.18649v1/x1.png)

### Summary:

This paper presents a novel training framework for improving the self-debugging capabilities of Large Language Models (LLMs) in the context of code generation. The proposed framework consists of an automated pipeline for collecting high-quality code explanation and refinement data, followed by supervised fine-tuning (SFT) and reinforcement learning (RL) with a novel reward design. The SFT significantly improves the pass@1 by up to 15.92% and pass@10 by 9.30% over four benchmarks, while RL training brings additional improvements of up to 3.54% on pass@1 and 2.55% on pass@10. The trained LLMs demonstrate iterative refinement ability and can generate more useful code explanations to help developers better understand bugs in source code.

### Major Findings:

1. The proposed training framework significantly improves the self-debugging capabilities of LLMs, with SFT improving the pass@1 by up to 15.92% and pass@10 by 9.30% over four benchmarks.
2. RL training with a novel reward design further enhances the performance of LLMs, bringing additional improvements of up to 3.54% on pass@1 and 2.55% on pass@10.
3. The trained LLMs demonstrate iterative refinement ability, allowing them to continuously refine code and achieve increasingly higher pass@k with more iterations.

### Analysis and Critique:

The paper presents a well-structured and coherent summary of the proposed training framework for improving the self-debugging capabilities of LLMs. The authors provide a clear and concise summary of their findings, highlighting the significant improvements achieved through SFT and RL training. However, there are a few potential limitations and areas for improvement:

1. The paper does not discuss the scalability of the proposed framework, particularly in terms of the computational resources required for data collection, SFT, and RL training.
2. The paper does not provide a detailed comparison with other existing methods for improving the self-debugging capabilities of LLMs, which could help to better understand the advantages and limitations of the proposed framework.
3. The paper does not discuss the potential impact of the proposed framework on the

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2405.18649v1](https://arxiv.org/abs/2405.18649v1)        |
| HTML     | [https://browse.arxiv.org/html/2405.18649v1](https://browse.arxiv.org/html/2405.18649v1)       |
| Truncated       | False       |
| Word Count       | 8619       |