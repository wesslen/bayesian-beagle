
---
title: "Theory of Mind abilities of Large Language Models in Human-Robot Interaction : An Illusion?"
id: "2401.05302v1"
description: "Large Language Models exhibit ToM abilities in Human Robot Interaction task but fail perturbation tests."
author: ['Mudit Verma', 'Siddhant Bhambri', 'Subbarao Kambhampati']
date: "2024-01-10"
image: "https://browse.arxiv.org/html/2401.05302v1/extracted/5340607/images/hri_main.png"
categories: ['robustness', 'production', 'prompt-engineering', 'social-sciences', 'hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.05302v1/extracted/5340607/images/hri_main.png)

# Theory of Mind abilities of Large Language Models in Human-Robot Interaction: An Illusion?

## Major Takeaways
1. This paper investigates the **Theory of Mind (ToM)** abilities of **Large Language Models (LLMs)** in the context of Human-Robot Interaction (HRI) using the Perceived Behavior Recognition task.
2. The study reveals the potential usability of LLMs as human proxies in HRI settings; however, it also highlights that LLMs lack the invariance to trivial or irrelevant perturbations required to possess ToM abilities.
3. While LLMs demonstrate strong performance on vanilla prompts, perturbation tests such as Inconsistent Belief and Uninformative Context break the illusion of their ToM abilities.

## Introduction
- ToM involves attributing mental states to oneself and others, and understanding that these mental states may differ from one's own.
- ToM is crucial for effective communication and collaboration in human-agent interaction.

## Related Work
- Large Language Models, such as GPT family and others, have gained popularity for their exceptional natural language processing abilities.
- ToM has been a challenging goal for AI agents, and previous works have explored the emergent ToM abilities of LLMs.
- Previous studies have investigated the variations among behavior types crucial for HRI, but this work focuses on LLM's failures in ToM abilities.

## Preliminaries
- Behavior synthesis in HRI requires the agent to possess ToM and reasoning abilities.
- The four behavior types considered in this study are explicability, legibility, predictability, and obfuscation.

## Methodology
- The study addresses three key research questions related to ToM reasoning in HRI scenarios.
- A user subject study is conducted to compare the performance of lay users and LLMs in ToM reasoning tasks.

## Evaluation Domains
- Five domains, including Fetch Robot, Passage Gridworld, Environment Design, Urban Search and Rescue, and Package Delivery, were used for the evaluation of ToM reasoning in HRI scenarios.

## Results
- Lay users performed well on ToM reasoning tasks in HRI scenarios, and their responses aligned with LLMs' performance.
- However, perturbation tests revealed that LLMs lack robustness in their ToM reasoning abilities, breaking the illusion of their ToM capabilities.

## Case Study
- A case study with the Fetch robot demonstrated that human users were consistent in answering ToM queries, even when perturbations were introduced.

## Conclusion & Future Work
- The study contributes to the understanding of LLMs' ToM abilities in HRI settings and calls for further investigation into the robustness of LLM responses.
- Future work could explore additional failure modes of LLMs in ToM tasks and study the impact of using LLMs in HRI settings.

## Critique
- While the study provides valuable insights into the limitations of LLMs in ToM reasoning, it would benefit from further exploration of potential solutions or alternative approaches to address the identified challenges.
- The study could also benefit from a more extensive discussion on the implications of the findings for the broader field of HRI and AI.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-02       |
| Abstract | [http://arxiv.org/abs/2401.05302v1](http://arxiv.org/abs/2401.05302v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.05302v1](https://browse.arxiv.org/html/2401.05302v1)       |
| Truncated       | False       |
| Word Count       | 10659       |