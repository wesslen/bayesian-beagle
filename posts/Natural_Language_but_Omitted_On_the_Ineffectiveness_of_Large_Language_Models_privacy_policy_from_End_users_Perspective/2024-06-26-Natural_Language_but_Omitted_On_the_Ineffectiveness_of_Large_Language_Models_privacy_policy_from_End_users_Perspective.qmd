
---
title: "Natural Language but Omitted? On the Ineffectiveness of Large Language Models' privacy policy from End-users' Perspective"
id: "2406.18100v1"
description: "[TEXT] This study explores the relationship between social media use and mental health in young adults. Results suggest a negative correlation between excessive social media use and mental well-being.

[TL;DR] Excessive social media use linked to poor mental health in young adults."
author: Shuning Zhang, Haobin Xing, Xin Yi, Hewu Li
date: "2024-06-26"
image: "https://browse.arxiv.org/html/2406.18100v1/extracted/5692298/Figure/chatgpt.png"
categories: ['hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.18100v1/extracted/5692298/Figure/chatgpt.png)

# Summary:

- The study explores users' perceptions and opinions on LLM products' privacy policies, comparing them to traditional AI products.
- The research reveals the ineffectiveness of users' reading and the presentation of LLMs' privacy policies and agreements, indicating a need for improvement.
- Four design implications are proposed to improve privacy policy presentations and content, focusing on visualization, content presentation, focal points, and user experience optimization.

# Major Findings:

1. LLMs' privacy policies and user agreements have over 50 important information, with data privacy being the most important difference.
2. Participants lack important information upon cursory reading, which is reflected in the shortening of their answers.
3. Participants grasp more information upon detailed reading, but still lack important information, and the privacy policy and user agreement cannot solve their privacy concerns.

# Analysis and Critique:

- The study focuses on a specific type of LLM-based products (text-based) and a limited demographic (Chinese youths), which may not be representative of all LLM-based products and users.
- The research does not consider the knowledge from legal and law perspectives, which could provide a more well-rounded analysis of privacy policies.
- The study does not address the potential limitations and biases of LLMs, such as their reliance on large-scale training data and the potential for privacy leaks.
- The research does not explore the potential impact of LLMs on other areas, such as voice or image-based products, which may have different privacy concerns.
- The study does not consider the potential for LLMs to be used for malicious purposes, such as generating misinformation or propaganda.
- The research does not address the potential for LLMs to be used to manipulate or deceive users, such as through the use of "deepfakes" or other forms of synthetic media.
- The study does not consider the potential for LLMs to be used to automate or replace human jobs, which could have significant social and economic implications.
- The research does not explore the potential for LLMs to be used to perpetuate or exacerbate existing social inequalities, such as those based on race, gender, or socioeconomic status.
- The study does not consider the potential for LLMs to

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-07       |
| Abstract | [https://arxiv.org/abs/2406.18100v1](https://arxiv.org/abs/2406.18100v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.18100v1](https://browse.arxiv.org/html/2406.18100v1)       |
| Truncated       | False       |
| Word Count       | 9590       |