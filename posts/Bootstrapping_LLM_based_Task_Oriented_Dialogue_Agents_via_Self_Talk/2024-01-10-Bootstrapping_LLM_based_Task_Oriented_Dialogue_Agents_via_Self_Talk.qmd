
---
title: "Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk"
id: "2401.05033v1"
description: "TL;DR: A new method uses large language models to collect data through self-talk dialogues for fine-tuning and improving conversation quality."
author: ['Dennis Ulmer', 'Elman Mansimov', 'Kaixiang Lin', 'Justin Sun', 'Xibin Gao', 'Yi Zhang']
date: "2024-01-10"
image: "../../https://browse.arxiv.org/html/2401.05033v1/extracted/5339646/img/schema.png"
categories: ['production', 'architectures', 'social-sciences']
format:
  html:
    code-overflow: wrap
---

![](../../https://browse.arxiv.org/html/2401.05033v1/extracted/5339646/img/schema.png)

rom the structured prompting (see Figure 15), might come from the last client response not being close enough to the sample answers defined in the workflow, thus leading the structured prompting from Section 3.1 to choose the "None of the above" option. As the agent model is being given the option to freely generate, the model might decide to simply copy the start of the conversation.

In general, our observations show that while the structured prompting and automated evaluation metrics are useful tools for guiding the dialogues and selecting useful training samples, they are not foolproof and the quality of the generated dialogues can vary depending on the specific circumstances of each conversation. As a result, caution is warranted when interpreting the results of the automated evaluations and when using the generated dialogues for finetuning.

Overall, these sample conversations illustrate the dynamics and challenges of using self-talk to bootstrap training data for task-oriented dialogue agents and highlight the complexity of generating high-quality, task-oriented dialogues with language models.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [http://arxiv.org/abs/2401.05033v1](http://arxiv.org/abs/2401.05033v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.05033v1](https://browse.arxiv.org/html/2401.05033v1)       |
| Truncated       | True       |
| Word Count       | 13790       |