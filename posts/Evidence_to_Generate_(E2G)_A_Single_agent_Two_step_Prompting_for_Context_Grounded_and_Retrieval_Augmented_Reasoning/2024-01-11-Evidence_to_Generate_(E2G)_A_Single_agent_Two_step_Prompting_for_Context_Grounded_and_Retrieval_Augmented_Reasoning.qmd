
---
title: "Evidence to Generate (E2G): A Single-agent Two-step Prompting for Context Grounded and Retrieval Augmented Reasoning"
id: "2401.05787v1"
description: "New E2G prompting framework improves reasoning in LLMs, outperforming current methods on various tasks."
author: ['Md Rizwan Parvez']
date: "2024-01-11"
image: "https://browse.arxiv.org/html/2401.05787v1/x1.png"
categories: ['production', 'programming', 'architectures', 'prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.05787v1/x1.png)

### Major Findings

- **Evidence to Generate (E2G)**, a single-agent two-step prompting framework, is introduced to overcome limitations of existing chain-of-thought (CoT) prompting methods. E2G leverages evidence from the context for robust and context-aware reasoning in large language models (LLMs).
- E2G achieves remarkable results across a wide range of knowledge-intensive reasoning and generation tasks, surpassing baseline approaches with state-of-the-art LLMs, such as surpassing CoT and other CoT variants by significant margins.
- E2G provides a novel approach to context-grounded and retrieval-augmented reasoning, addressing challenges such as grounding reasoning paths and reducing dependence on iterative prompting methods.

### Key Sections Summarized

#### Introduction
- Chain-of-Thought (CoT) prompting revolutionized reasoning in LLMs but suffers from limitations in context awareness and hallucinations due to ungrounded internal reasoning.
- Retrieval-augmented and context-based generation have improved LLM capabilities but face challenges in effective reasoning.
  
#### Evidence to Generate (E2G) Prompting
- E2G is a single-agent, two-step framework designed for context-aware reasoning, leveraging evidence from the context to guide the output generation process.
- The E-step instructs the model to generate rationales or evidence from the context, while the G-step processes the evidence to derive the final answer.

#### Experimental Setup
- E2G is evaluated on eight context-intensive language tasks, showing robust performance improvements over existing approaches across various tasks and language models (LLMs).

### Critique

The paper presents a novel approach to addressing limitations in reasoning tasks for large language models. However, potential limitations or ethical considerations related to the generalization of the findings, model fine-tuning, and inconsistent retrieval accuracy in retrieval-augmented generation tasks are not fully addressed. Furthermore, the paper's claim of robust performance gains requires further validation across different domains and languages. Additionally, the paper could benefit from transparency in the reporting of potential challenges and limitations encountered during the development and evaluation of the E2G framework.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-31       |
| Abstract | [http://arxiv.org/abs/2401.05787v1](http://arxiv.org/abs/2401.05787v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.05787v1](https://browse.arxiv.org/html/2401.05787v1)       |
| Truncated       | False       |
| Word Count       | 7969       |