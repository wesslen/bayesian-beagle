
---
title: "A Comparison of Large Language Model and Human Performance on Random Number Generation Tasks"
id: "2408.09656v1"
description: "LLMs like ChatGPT-3.5 generate random sequences more effectively than humans, with fewer repetitive and sequential patterns."
author: Rachel M. Harrison
date: "2024-08-19"
image: "https://browse.arxiv.org/html/2408.09656v1/extracted/5799024/figures/patterns_frequency.png"
categories: ['prompt-engineering', 'social-sciences', 'robustness', 'hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.09656v1/extracted/5799024/figures/patterns_frequency.png)

### Summary:

- The study compares the performance of ChatGPT-3.5, a large language model (LLM), with human performance on Random Number Generation Tasks (RNGTs).
- ChatGPT-3.5 more effectively avoids repetitive and sequential patterns compared to humans, with notably lower repeat frequencies and adjacent number frequencies.
- The research aims to deepen our understanding of how LLMs can more closely mimic human random generation behaviors and broaden their applications in cognitive and behavioral science research.

### Major Findings:

1. **ChatGPT-3.5 exhibits human-like cognitive biases**: The study tests whether ChatGPT-3.5, trained on human-generated text, exhibits human-like cognitive biases when generating random number sequences.
2. **ChatGPT-3.5 more effectively avoids repetitive and sequential patterns**: Initial findings indicate that ChatGPT-3.5 more effectively avoids repetitive and sequential patterns compared to humans, with notably lower repeat frequencies and adjacent number frequencies.
3. **Potential for broader applications in cognitive and behavioral science research**: Continued research into different models, parameters, and prompting methodologies will deepen our understanding of how LLMs can more closely mimic human random generation behaviors, while also broadening their applications in cognitive and behavioral science research.

### Analysis and Critique:

- The study's focus on comparing LLMs with human performance on RNGTs is a novel approach to understanding the capabilities and limitations of LLMs.
- The use of ChatGPT-3.5, a widely recognized and advanced model, provides a strong foundation for the study.
- The study's findings suggest that LLMs can mimic certain aspects of human cognitive biases, which could have significant implications for cognitive and behavioral science research.
- However, the study's reliance on a single model (ChatGPT-3.5) may limit the generalizability of its findings. Future research could benefit from comparing the performance of multiple LLMs.
- Additionally, the study does not explore the potential impact of different prompting strategies or model parameters on the performance of LLMs in RNGTs. This could be a fruitful area for future research.
- Finally, the study's focus on

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-20       |
| Abstract | [https://arxiv.org/abs/2408.09656v1](https://arxiv.org/abs/2408.09656v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.09656v1](https://browse.arxiv.org/html/2408.09656v1)       |
| Truncated       | False       |
| Word Count       | 4221       |