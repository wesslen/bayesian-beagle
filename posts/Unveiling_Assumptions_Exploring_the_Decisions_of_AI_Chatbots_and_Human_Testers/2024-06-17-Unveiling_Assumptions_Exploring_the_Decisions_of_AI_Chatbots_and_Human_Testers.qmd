
---
title: "Unveiling Assumptions: Exploring the Decisions of AI Chatbots and Human Testers"
id: "2406.11339v1"
description: "LLM-based chatbots can aid software testers in decision-making, with some aligning with human intuition in preferring diverse test scenarios."
author: Francisco Gomes de Oliveira Neto
date: "2024-06-17"
image: "https://browse.arxiv.org/html/2406.11339v1/extracted/5672150/figs/Fig-Results.png"
categories: ['programming']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.11339v1/extracted/5672150/figs/Fig-Results.png)

### Summary:

The integration of Large Language Models (LLMs) and chatbots in software testing presents new opportunities for decision-making processes. This paper explores the potential of LLM-based chatbots like Bard, Copilot, and ChatGPT in supporting software testers in test decisions, such as prioritizing test cases effectively. The study investigates whether LLM-based chatbots and human testers share similar "assumptions" or intuition in prohibitive testing scenarios where exhaustive execution of test cases is often impractical. Preliminary results from a survey of 127 testers indicate a preference for diverse test scenarios, with a significant majority (96%) favoring dissimilar test sets. Interestingly, two out of four chatbots mirrored this preference, aligning with human intuition, while the others opted for similar test scenarios, chosen by only 3.9% of testers.

### Major Findings:

1. **Preference for diverse test scenarios**: The majority of human testers (96%) and two LLM-based chatbots (Copilot and ChatGPT 4.0) preferred diverse test scenarios, aligning with literature on the effectiveness of varied test suites for bug detection.
2. **Similar intuition between chatbots and human testers**: Despite showing variability in responses, LLM-based chatbots' rationales highlighted the importance of scenario diversity, system familiarity, and efficient time management in testing, which mirrored human testers' reasoning.
3. **Potential for greater synergy**: The alignment between human testers and LLMs in their testing strategies and priorities suggests potential for greater synergy at higher autonomy levels, as proposed in Feldt et al.'s taxonomy.

### Analysis and Critique:

* The study provides valuable insights into the potential of LLM-based chatbots in supporting software testers in decision-making processes. However, the simplicity of the example used in the study may not fully capture the complexity of real-world testing scenarios.
* The limited reproducibility of the chat aspect of LLMs, due to output variability and time-based output drift, poses challenges for the reliability of the recommendations produced

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-23       |
| Abstract | [https://arxiv.org/abs/2406.11339v1](https://arxiv.org/abs/2406.11339v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.11339v1](https://browse.arxiv.org/html/2406.11339v1)       |
| Truncated       | False       |
| Word Count       | 5891       |