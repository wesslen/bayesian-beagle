
---
title: "Authorship Obfuscation in Multilingual Machine-Generated Text Detection"
id: "2401.07867v1"
description: "Latest Large Language Models (LLMs) can generate disinformation, evading detection in multiple languages."
author: Dominik Macko, Robert Moro, Adaku Uchendu, Ivan Srba, Jason Samuel Lucas, Michiharu Yamashita, Nafis Irtiza Tripto, Dongwon Lee, Jakub Simko, Maria Bielikova
date: "2024-01-15"
image: "../../../bayesian-beagle.png"
categories: ['security', 'social-sciences', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### Summary:
The article addresses the threat of detecting machine-generated text (MGT) in multilingual settings and the susceptibility of MGT detection to authorship obfuscation (AO) methods. It presents a comprehensive multilingual benchmark of AO methods, evaluates the robustness of multilingual MGT detection methods, and explores the impact of data augmentation on adversarial robustness. The study also discusses the computational resources used, post-obfuscation analysis, and the detection performance of various MGT detection methods across different languages and AO methods.

### Major Findings:
1. AO methods are usable in multilingual settings, with homoglyph-based attacks being most successful across languages.
2. Adversarial retraining by data augmentation using obfuscated texts can increase the overall performance of MGT detection methods, but the choice of AO methods for adversarial retraining plays a crucial role in the performance.
3. The detection performance of various MGT detection methods varies across different languages and AO methods, with fine-tuned and pre-trained methods showing different levels of effectiveness.

### Analysis and Critique:
The article provides valuable insights into the effectiveness and robustness of AO methods in multilingual settings, the impact of multilingual obfuscation on the adversarial robustness of MGT detection methods, and the detection performance of various MGT detection methods across different languages and AO methods. However, the study could benefit from further exploration of the implications of these findings for real-world applications and the development of strategies to counter adversarial attacks. Additionally, the article could address potential limitations in the experimental setup and methodological considerations for future research.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2401.07867v1](https://arxiv.org/abs/2401.07867v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.07867v1](https://browse.arxiv.org/html/2401.07867v1)       |
| Truncated       | True       |
| Word Count       | 34327       |