
---
title: "Towards Safer Large Language Models through Machine Unlearning"
id: "2402.10058v1"
description: "TL;DR: Selective Knowledge negation Unlearning (SKU) removes harmful knowledge while preserving model utility."
author: Zheyuan Liu, Guangyao Dou, Zhaoxuan Tan, Yijun Tian, Meng Jiang
date: "2024-02-15"
image: "../../img/2402.10058v1/image_1.png"
categories: ['production', 'prompt-engineering', 'architectures', 'robustness', 'security']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.10058v1/image_1.png)

### Summary:
The article introduces a novel unlearning framework, Selective Knowledge negation Unlearning (SKU), designed to remove harmful knowledge from Large Language Models (LLMs) while preserving utility on normal prompts. The framework consists of two stages: harmful knowledge acquisition and knowledge negation. The experiments demonstrate that SKU effectively balances unlearning harmfulness and preserving utility performance across various LLM architectures.

### Major Findings:
1. SKU effectively balances unlearning harmfulness and preserving utility performance in LLMs.
2. The harmful knowledge acquisition stage facilitates the learning of harmful content from different angles.
3. The knowledge negation stage effectively removes harmful knowledge while preserving model utility on normal prompts.

### Analysis and Critique:
- The article effectively addresses the trade-off between unlearning harmfulness and preserving utility performance in LLMs.
- The experiments demonstrate the effectiveness of SKU in reducing harmful outputs without sacrificing response quality on normal prompts.
- The article provides a comprehensive evaluation of the proposed framework and compares it with various baseline approaches.
- The study provides valuable insights into the challenges and potential solutions for unlearning harmful knowledge in LLMs.

Overall, the article presents a well-structured and coherent framework for unlearning harmful knowledge in LLMs, with valuable insights and practical implications for future research in this area. However, further research is needed to address potential limitations and extend the applicability of the proposed framework to other scenarios.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.10058v1](https://arxiv.org/abs/2402.10058v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.10058v1](https://browse.arxiv.org/html/2402.10058v1)       |
| Truncated       | False       |
| Word Count       | 14759       |