
---
title: "Lying Blindly: Bypassing ChatGPT's Safeguards to Generate Hard-to-Detect Disinformation Claims at Scale"
id: "2402.08467v1"
description: "ChatGPT can create realistic disinformation about the war in Ukraine that's hard to detect."
author: Freddy Heppell, Mehmet E. Bakir, Kalina Bontcheva
date: "2024-02-13"
image: "../../../bayesian-beagle.png"
categories: ['production', 'hci']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### **Summary:**
- The study explores ChatGPT's capability to generate unconditioned claims about the war in Ukraine and evaluates whether such claims can be differentiated by human readers and automated tools from human-written ones.
- ChatGPT can produce realistic, target-specific disinformation cheaply, fast, and at scale, and these claims cannot be reliably distinguished by humans or existing automated tools.
- The study demonstrates that ChatGPT can even generate realistic disinformation about events that postdate its knowledge cutoff.

### Major Findings:
1. ChatGPT can produce realistic, target-specific disinformation cheaply, fast, and at scale.
2. Claims generated by ChatGPT cannot be reliably distinguished by humans or existing automated tools.
3. ChatGPT can generate realistic disinformation about events that postdate its knowledge cutoff.

### Analysis and Critique:
- The study raises concerns about the potential misuse of ChatGPT for large-scale disinformation campaigns.
- It highlights the challenges in reliably detecting AI-generated content by both humans and automated tools.
- The study emphasizes the need for transparency in commercial AI detection products and the ethical considerations surrounding the release of synthetic disinformation claims.

The study provides valuable insights into the potential risks associated with the misuse of AI language models for generating disinformation and the challenges in detecting such content. However, it also raises concerns about the ethical implications and the need for transparency in the development and use of AI detection tools. Further research and measures to address these challenges are warranted.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-14       |
| Abstract | [https://arxiv.org/abs/2402.08467v1](https://arxiv.org/abs/2402.08467v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.08467v1](https://browse.arxiv.org/html/2402.08467v1)       |
| Truncated       | False       |
| Word Count       | 9801       |