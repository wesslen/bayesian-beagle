
---
title: "From Decision to Action in Surgical Autonomy: Multi-Modal Large Language Models for Robot-Assisted Blood Suction"
id: "2408.07806v1"
description: "LLMs enhance contextual understanding and decision-making in robotic-assisted surgeries, enabling autonomous blood suction."
author: Sadra Zargarzadeh, Maryam Mirzaei, Yafei Ou, Mahdi Tavakoli
date: "2024-08-14"
image: "https://browse.arxiv.org/html/2408.07806v1/x1.png"
categories: ['prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.07806v1/x1.png)

# Summary:

**Summary:**
The paper proposes a multi-modal Large Language Model (LLM) integration in robot-assisted surgery for autonomous blood suction. The reasoning and prioritization are delegated to the higher-level task-planning LLM, and the motion planning and execution are handled by the lower-level deep reinforcement learning model. The study aims to surmount the limitations of current autonomous systems by introducing a level of reasoning and adaptability previously unattainable in robot-assisted surgeries. The main contribution of this work is the proposal of an LLM-powered framework for autonomous robot-assisted blood suctioning, the comparison of the performance of LLM reasoning to random reasoning and no reasoning modules in blood removal time and tool movement, and the analysis of how augmenting the prompts with context and expert-defined guidelines changes the reasoning capabilities of the LLM in zero-shot prompting.

**Major Findings:**
1. The integration of multi-modal LLMs as a higher-level reasoning unit can account for surgical complexities, such as active bleeding and blood clots, to achieve a level of reasoning and explainability previously unattainable in robot-assisted surgeries.
2. The study compares the performance of LLM reasoning to random reasoning and no reasoning modules in blood removal time and tool movement, demonstrating the potential of multi-modal LLMs to significantly enhance contextual understanding and decision-making in robotic-assisted surgeries.
3. The analysis of how augmenting the prompts with context and expert-defined guidelines changes the reasoning capabilities of the LLM in zero-shot prompting reveals that incorporating contextual understanding in robotic surgery could bridge the gap between automated procedures and the intuitive decision-making of humans.

**Analysis and Critique:**
- The study's reliance on simulation-based environments may limit its applicability to real-world surgical settings.
- The assumption that blood pools are separate and independent may not hold in all surgical scenarios.
- The generation speed of OpenAI's GPT-4V, which led to the system not operating in real-time, is a limitation that needs to be addressed in future work.
- The paper does not discuss the potential risks and ethical considerations associated with the use of LLMs in

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-20       |
| Abstract | [https://arxiv.org/abs/2408.07806v1](https://arxiv.org/abs/2408.07806v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.07806v1](https://browse.arxiv.org/html/2408.07806v1)       |
| Truncated       | False       |
| Word Count       | 5814       |