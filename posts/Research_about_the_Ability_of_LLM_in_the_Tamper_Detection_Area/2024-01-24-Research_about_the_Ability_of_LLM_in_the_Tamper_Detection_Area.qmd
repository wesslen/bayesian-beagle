
---
title: "Research about the Ability of LLM in the Tamper-Detection Area"
id: "2401.13504v1"
description: "Large Language Models (LLMs) effective in basic tamper detection, struggle with highly sophisticated forgeries and AI-generated images."
author: ['Xinyu Yang', 'Jizhe Zhou']
date: "2024-01-24"
image: "https://browse.arxiv.org/html/2401.13504v1/x1.png"
categories: ['education', 'architectures', 'production', 'security', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.13504v1/x1.png)

### **Summary:**
The article discusses the emerging role of Large Language Models (LLMs) in the field of tamper detection, specifically in detecting AI-generated content and image manipulation. It evaluates the performance of five different LLMs â€“ GPT-4, LLaVA, Bard, ERNIE Bot 4.0, and Tongyi Qianwen, in identifying tampering instances. The experiments revealed that while most LLMs can identify basic tampering activities, they struggle with highly sophisticated forgeries and AI-generated images that closely resemble reality, indicating that LLMs still have limitations in tamper detection.

### **Major Findings:**
1. LLMs are capable of identifying composite pictures that are inconsistent with logic, but struggle to identify carefully forged images and very realistic AI-generated images.
2. The more powerful LLMs demonstrate higher success rates in identifying tampered images that are detectable by the human eye, while less sophisticated models struggle significantly with this task.
3. In the realm of deepfake detection, all LLMs were unable to effectively recognize these manipulations, indicating the ongoing challenges for LLMs in mastering tamper detection.

### **Analysis and Critique:**
The study provides valuable insights into the capabilities and limitations of LLMs in tamper detection, shedding light on their current inefficacy in detecting highly sophisticated forgeries and deepfake manipulations. However, the article could benefit from a discussion on potential solutions or future research directions to address these limitations. Additionally, the study's reliance on a limited number of LLMs and datasets may impact the generalizability of the findings. Further research involving a broader range of LLMs and diverse tampering instances would provide a more comprehensive understanding of LLMs' effectiveness in tamper detection.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [http://arxiv.org/abs/2401.13504v1](http://arxiv.org/abs/2401.13504v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.13504v1](https://browse.arxiv.org/html/2401.13504v1)       |
| Truncated       | False       |
| Word Count       | 3757       |