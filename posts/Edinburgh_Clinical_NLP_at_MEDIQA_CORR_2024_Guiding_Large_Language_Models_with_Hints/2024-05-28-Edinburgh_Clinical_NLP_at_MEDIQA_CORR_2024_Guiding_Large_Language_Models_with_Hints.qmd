
---
title: "Edinburgh Clinical NLP at MEDIQA-CORR 2024: Guiding Large Language Models with Hints"
id: "2405.18028v1"
description: "LLMs like GPT-3.5 and GPT-4 can correct medical errors better with fine-tuned model hints and multiple-choice options."
author: Aryo Pradipta Gema, Chaeeun Lee, Pasquale Minervini, Luke Daines, T. Ian Simpson, Beatrice Alex
date: "2024-05-28"
image: "https://browse.arxiv.org/html/2405.18028v1/x1.png"
categories: ['social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2405.18028v1/x1.png)

### Summary:

The study focuses on the MEDIQA-CORR 2024 shared task, which aims to evaluate the ability of Large Language Models (LLMs) to identify and correct medical errors in clinical notes. The authors evaluate the performance of GPT-3.5 and GPT-4 in this task using multiple prompting strategies, including In-context Learning (ICL) and Chain-of-Thought (CoT). They propose incorporating a smaller fine-tuned language model, BioLinkBERT, to aid LLMs in locating an error span in a clinical note. The findings reveal that LLMs show noticeable improvements in their generation capability when presented with more ICL examples and the CoT prompt also improves the error correction capability of the LLMs. The best-performing prompting strategy is the combination of 8-shot ICL with Brief CoT reasoning and hints, which ranked sixth in the shared task leaderboard.

### Major Findings:

1. LLMs show noticeable improvements in their generation capability when presented with more ICL examples.
2. The CoT prompt also improves the error correction capability of the LLMs.
3. The best-performing prompting strategy is the combination of 8-shot ICL with Brief CoT reasoning and hints, which ranked sixth in the shared task leaderboard.

### Analysis and Critique:

The study provides a comprehensive analysis of the impact of ICL on the performance of LLMs for medical error correction and an extensive exploration of CoT to inject various reasoning styles into the LLM and their impact on the performance. The authors also propose novel approaches to integrate the predictions of a smaller language model into the LLM generation. However, the study has some limitations. The scope of the study was exclusively confined to GPT-based models, and the reported findings may differ across different types of LLMs. The study also did not investigate the effect of integrating MCQ prompt with CoT reasoning, which may offer additional improvements in the LLMâ€™s error correction capabilities. Furthermore, the study underscores that LLMs may not be ready for deployment in real-world clinical environments without human oversight, highlighting the critical need for human supervision, especially given the potential risks associated with inaccuracies in medical documentation and the consequent impacts on

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2405.18028v1](https://arxiv.org/abs/2405.18028v1)        |
| HTML     | [https://browse.arxiv.org/html/2405.18028v1](https://browse.arxiv.org/html/2405.18028v1)       |
| Truncated       | False       |
| Word Count       | 6700       |