
---
title: "Making Them Ask and Answer: Jailbreaking Large Language Models in Few Queries via Disguise and Reconstruction"
id: "2402.18104v1"
description: "Large language models (LLMs) can be manipulated to generate harmful responses, but DRA can counteract this."
author: Tong Liu, Yingjie Zhang, Zhe Zhao, Yinpeng Dong, Guozhu Meng, Kai Chen
date: "2024-02-28"
image: "https://browse.arxiv.org/html/2402.18104v1/x1.png"
categories: ['prompt-engineering', 'security', 'architectures', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.18104v1/x1.png)

### Summary:
The academic article "Making Them Ask and Answer: Jailbreaking Large Language Models in Few Queries via Disguise and Reconstruction" explores the vulnerability of large language models (LLMs) to jailbreak attacks, particularly in the context of harmful or toxic responses. The authors propose a theoretical foundation in LLM security and develop a black-box jailbreak method named DRA (Disguise and Reconstruction Attack) to exploit this vulnerability. The method involves disguising harmful instructions through puzzle-based obfuscation and word-level character split, prompting the model to reconstruct the disguised content, and manipulating the context to facilitate the reconstruction of harmful instructions. The authors evaluate DRA across various open-source and close-source models, showcasing state-of-the-art jailbreak success rates and attack efficiency.

### Major Findings:
1. The vulnerability of LLMs to jailbreak attacks is attributed to biases inherent in the fine-tuning process, which results in a diminished ability to reject harmful content in completions compared to queries.
2. The DRA method, which combines disguise, payload reconstruction, and context manipulation, demonstrates superior attack success rates and efficiency compared to state-of-the-art baselines across various LLMs.
3. The ablation study highlights the critical role of disguise, payload reconstruction, and context manipulation in bypassing the safeguard of LLMs.

### Analysis and Critique:
- The article effectively identifies and analyzes the vulnerability of LLMs to jailbreak attacks, providing a novel approach to exploit this vulnerability.
- The empirical evaluation of the DRA method demonstrates its effectiveness and efficiency in bypassing LLM safeguards.
- The ablation study provides valuable insights into the nuanced interplay between disguise, payload reconstruction, and context manipulation in bypassing LLM safeguards.
- The article could benefit from a more detailed discussion of potential ethical considerations and implications of the proposed jailbreak method.

Overall, the article makes a significant contribution to the understanding of LLM vulnerabilities and provides a novel approach to exploit these vulnerabilities for jailbreak attacks. Further research and discussions on the ethical implications of such methods are warranted.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.18104v1](https://arxiv.org/abs/2402.18104v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.18104v1](https://browse.arxiv.org/html/2402.18104v1)       |
| Truncated       | False       |
| Word Count       | 10757       |