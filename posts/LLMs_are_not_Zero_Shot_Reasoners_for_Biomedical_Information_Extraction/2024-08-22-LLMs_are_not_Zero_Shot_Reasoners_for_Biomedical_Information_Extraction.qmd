
---
title: "LLMs are not Zero-Shot Reasoners for Biomedical Information Extraction"
id: "2408.12249v1"
description: "LLMs underperform in biomedical tasks; standard prompting outperforms complex techniques like CoT, self-consistency, and RAG. External knowledge integration needs improvement."
author: Aishik Nagar, Viktor Schlegel, Thanh-Tung Nguyen, Hao Li, Yuping Wu, Kuluhan Binici, Stefan Winkler
date: "2024-08-22"
image: "https://browse.arxiv.org/html/2408.12249v1/extracted/5807097/single_vs_multi_cls.png"
categories: ['prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.12249v1/extracted/5807097/single_vs_multi_cls.png)

### Summary:

This paper investigates the performance of Large Language Models (LLMs) in Medical Classification and Named Entity Recognition (NER) tasks, focusing on their ability to handle structured information extraction. The authors evaluate various open LLMs, including BioMistral and Llama-2 models, on a diverse set of biomedical datasets. They employ standard prompting, Chain-of-Thought (CoT), Self-Consistency, and Retrieval-Augmented Generation (RAG) techniques to assess the impact of different factors on performance.

### Major Findings:

1. Standard prompting consistently outperforms more complex techniques, such as CoT, Self-Consistency, and RAG, across both Medical Classification and NER tasks.
2. Parametric knowledge capacity, i.e., model size, is a primary and often sole driver of performance in zero-shot settings.
3. Advanced prompting methods developed for knowledge- or reasoning-intensive tasks are not easily portable to biomedical tasks where precise structured outputs are required.

### Analysis and Critique:

* The study highlights the need for more effective integration of external knowledge and reasoning mechanisms in LLMs to enhance their performance in real-world biomedical applications.
* The authors acknowledge the limitations of their study, including the use of large, commercial models like ChatGPT and GPT-4, which present significant challenges in real-world applications due to computational cost and privacy concerns.
* The paper does not address the issue of hallucinations generated by LLMs, which can compromise the truthfulness of the outputs.
* The study focuses on a limited number of LLMs and does not explore the performance of other models, such as T5 or BERT, in Medical Classification and NER tasks.
* The authors do not provide a detailed comparison of the performance of different prompting techniques, which could help identify the most effective strategies for improving LLM performance in biomedical tasks.
* The paper does not discuss the potential impact of different pre-training strategies, such as domain-specific pre-training or multi-task learning, on the performance of LLMs in Medical Classification and NER tasks.
* The study does not explore the potential of using ensemble methods, such as combining the outputs of multiple models, to improve the

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-27       |
| Abstract | [https://arxiv.org/abs/2408.12249v1](https://arxiv.org/abs/2408.12249v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.12249v1](https://browse.arxiv.org/html/2408.12249v1)       |
| Truncated       | False       |
| Word Count       | 7773       |