
---
title: "FormulaQA: A Question Answering Dataset for Formula-Based Numerical Reasoning"
id: "2402.12692v1"
description: "Proposing FormulaQA dataset for formula-based numerical reasoning, evaluating LLMs and exploring retrieval-augmented LLMs."
author: Xiao Li, Sichen Liu, Bolin Zhu, Yin Zhu, Yiwei liu, Gong Cheng
date: "2024-02-20"
image: "https://browse.arxiv.org/html/2402.12692v1/x1.png"
categories: ['education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.12692v1/x1.png)

### Summary:
The article introduces FormulaQA, a question-answering dataset for formula-based numerical reasoning, collected from junior high school physics examinations. The dataset includes questions requiring formula-based numerical reasoning, with each question annotated with an explanation text, a final answer, and relevant formulas. The article evaluates the dataset using large language models (LLMs) and fine-tuned small models, as well as retrieval-augmented LLMs. The findings underscore the challenging nature of FormulaQA and the potential for improvement in existing models for formula-based numerical reasoning.

### Major Findings:
1. **FormulaQA Dataset Construction**: The dataset consists of 5,420 questions collected from Chinese junior high school physics exams, annotated with reasoning steps and formulas.
2. **Evaluation of LLMs**: Large language models (LLMs) ranging from 7B to over 100B parameters were evaluated on FormulaQA, demonstrating the challenging nature of the dataset and the need for improvement in existing models.
3. **Fine-tuned Small Models**: Fine-tuned small models with sizes less than 2B parameters were evaluated, showing generalization ability in formula prediction and the potential for enhanced performance when using calculators.

### Analysis and Critique:
- **Limitations**: The English version of the dataset has not been accurately assessed for quality, and the dataset is limited to the domain of physics, potentially limiting its applicability to other domains.
- **Ethical Considerations**: The dataset was collected from publicly available sources and focuses on elementary physics, with no foreseen potential risks. Annotators were undergraduate students skilled in elementary physics.
- **Error Analysis**: Error cases were categorized into formula errors and calculation errors, highlighting the challenges posed by FormulaQA to existing models in terms of formula application and numerical calculation.

The article provides valuable insights into the construction and evaluation of FormulaQA, highlighting the need for further research and improvement in models for formula-based numerical reasoning.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-21       |
| Abstract | [https://arxiv.org/abs/2402.12692v1](https://arxiv.org/abs/2402.12692v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.12692v1](https://browse.arxiv.org/html/2402.12692v1)       |
| Truncated       | False       |
| Word Count       | 7183       |