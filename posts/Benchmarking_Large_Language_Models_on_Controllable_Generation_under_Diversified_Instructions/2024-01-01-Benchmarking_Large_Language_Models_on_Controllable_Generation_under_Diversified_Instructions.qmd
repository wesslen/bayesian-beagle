
---
title: "Benchmarking Large Language Models on Controllable Generation under Diversified Instructions"
id: "2401.00690v1"
description: "CoDI-Eval evaluates large language models' ability to follow instructions with specific constraints, revealing limitations and the need for improvement."
author: ['Yihan Chen', 'Benfeng Xu', 'Quan Wang', 'Yi Liu', 'Zhendong Mao']
date: "2024-01-01"
image: "https://browse.arxiv.org/html/2401.00690v1/x1.png"
categories: ['programming']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.00690v1/x1.png)

### Summary of "Benchmarking Large Language Models on Controllable Generation under Diversified Instructions"

#### Key Findings:
1. CoDI-Eval is a new benchmark designed to comprehensively evaluate the performance of Large Language Models (LLMs) in responding to diversified instructions. The benchmark covers a wide range of controllable text generation tasks, including sentiment, topic, length, keyword, and toxicity avoidance.
2. Mainstream LLMs, while capable of handling certain controllable text generation tasks, still have limitations in following instructions with specific constraints. There is a notable performance gap between open-source and commercial closed-source LLMs.
3. The benchmark provides extensive evaluations of representative LLMs on CoDI-Eval, revealing opportunities for enhancing their overall controllable text generation capabilities. The results suggest potential for progress in aligning LLMs with human expectations.

#### Critique:
- The paper does not delve into potential biases or limitations in the instructions construction process, which could impact the robustness and applicability of the benchmark. Further exploration of the possible sources of bias could enhance the validity of the benchmark.

Overall, the paper presents a robust new benchmark for evaluating LLMs' controllable generation capabilities, offering valuable insights into the limitations and potential for improvement in LLM performance. However, a more in-depth exploration of potential biases could enhance the credibility of the benchmark.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-26       |
| Abstract | [http://arxiv.org/abs/2401.00690v1](http://arxiv.org/abs/2401.00690v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.00690v1](https://browse.arxiv.org/html/2401.00690v1)       |
| Truncated       | False       |
| Word Count       | 12181       |