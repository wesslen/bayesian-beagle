
---
title: "Psychomatics -- A Multidisciplinary Framework for Understanding Artificial Minds"
id: "2407.16444v1"
description: "Psychomatics: A Framework Comparing LLMs and Human Cognition, Highlighting Differences and Potential for AI Development."
author: Giuseppe Riva, Fabrizia Mantovani, Brenda K. Wiederhold, Antonella Marchetti, Andrea Gaggioli
date: "2024-07-23"
image: "../../img/2407.16444v1/image_1.png"
categories: ['hci', 'education']
format:
  html:
    code-overflow: wrap
---

![](../../img/2407.16444v1/image_1.png)

# Summary:

The paper "Psychomatics - A Multidisciplinary Framework for Understanding Artificial Minds" presents a new approach to understanding the cognitive abilities of AI systems, particularly Large Language Models (LLMs). The authors argue that current methods, such as behavioral evaluations and comparisons with human behavior, do not provide a deeper insight into AI. They propose "Psychomatics," a multidisciplinary framework that combines cognitive science, linguistics, and computer science to explore how LLMs process information.

The framework focuses on how LLMs perceive, learn, remember, and use information, drawing parallels between LLMs and biological systems. The authors use a comparative methodology, starting from a theory-driven research question: "Is the process of language development and use different in humans and LLMs?"

The paper discusses the differences between humans and LLMs in language learning, language use, meaning, decision-making, truth assessment, and intentionality. It highlights that while LLMs can map complex linguistic patterns and follow Grice's Cooperative Principle, they lack the social and relational aspects of human communication and the ability to generate novel meanings.

# Major Findings:

1. LLMs can map complex linguistic patterns in their training data and navigate meaning through self-attention and cross-attention mechanisms. However, they struggle with implicit, contextual meanings like sarcasm and faux pas.
2. LLMs differ significantly from humans in their developmental trajectory. Unlike children who acquire language through continuous social, emotional, and linguistic interactions, LLMs are "trained" on predefined datasets.
3. LLMs lack the ability to generate novel meanings and fully understand the nuances of human language due to their asocial environment and lack of personal experiences.

# Analysis and Critique:

The paper provides a comprehensive and insightful analysis of the differences between LLMs and humans in language processing and understanding. However, it could benefit from a more in-depth discussion on the potential implications of these differences for the development and use of AI systems. Additionally, the paper could explore more practical applications of the Psychomatics framework in AI research and development.

The paper also raises important questions about the ethical implications of using LLMs, particularly in relation

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-30       |
| Abstract | [https://arxiv.org/abs/2407.16444v1](https://arxiv.org/abs/2407.16444v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.16444v1](https://browse.arxiv.org/html/2407.16444v1)       |
| Truncated       | False       |
| Word Count       | 11619       |