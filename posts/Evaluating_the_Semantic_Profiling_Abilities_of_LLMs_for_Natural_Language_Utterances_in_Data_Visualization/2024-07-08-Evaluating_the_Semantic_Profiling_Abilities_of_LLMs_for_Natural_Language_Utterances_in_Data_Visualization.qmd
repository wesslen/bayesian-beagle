
---
title: "Evaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization"
id: "2407.06129v1"
description: "LLMs can extract data context but struggle with visual tasks, despite being sensitive to uncertainties in utterances."
author: Hannah K. Bako, Arshnoor Buthani, Xinyi Liu, Kwesi A. Cobbina, Zhicheng Liu
date: "2024-07-08"
image: "https://browse.arxiv.org/html/2407.06129v1/extracted/5718099/figures/gpt-logo.png"
categories: ['hci', 'production', 'architectures', 'social-sciences', 'education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2407.06129v1/extracted/5718099/figures/gpt-logo.png)

### Summary:

This study evaluates the ability of four publicly available Large Language Models (LLMs) - GPT-4, Gemini-Pro, Llama3, and Mixtral - to comprehend natural language utterances and identify relevant data context and visual tasks for data visualization generation. The findings reveal that LLMs are sensitive to uncertainties in utterances and can extract relevant data context, but struggle with inferring visualization tasks. The study highlights future research directions on using LLMs for visualization generation.

### Major Findings:
1. LLMs are sensitive to uncertainties in utterances and can extract relevant data context.
2. LLMs struggle with inferring visualization tasks.
3. LLMs make inferences at a different level of abstraction than humans, causing them to be hyper-sensitive to uncertainties in utterances.

### Analysis and Critique:
- The study provides a comprehensive evaluation of LLMs' ability to extract relevant data context and identify visual tasks from natural language utterances.
- The use of a diverse corpus of 500 data-related utterances and the manual annotation of these utterances by three visualization researchers adds to the credibility of the findings.
- The study highlights the potential of LLMs for data visualization generation, but also identifies their limitations in inferring visualization tasks.
- The study could have benefited from a more detailed analysis of the reasons behind LLMs' struggle with inferring visualization tasks.
- The study does not provide a comparison of the performance of the four LLMs, which could have provided insights into the strengths and weaknesses of each model.
- The study does not discuss the implications of the findings for the design and development of NLIs for data visualization.
- The study does not discuss the potential ethical implications of using LLMs for data visualization generation, such as the risk of bias in the models.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-09       |
| Abstract | [https://arxiv.org/abs/2407.06129v1](https://arxiv.org/abs/2407.06129v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.06129v1](https://browse.arxiv.org/html/2407.06129v1)       |
| Truncated       | False       |
| Word Count       | 6332       |