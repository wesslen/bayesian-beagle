
---
title: "Microstructures and Accuracy of Graph Recall by Large Language Models"
id: "2402.11821v1"
description: "LLMs struggle with graph recall, exhibiting biased patterns and domain dependence."
author: Yanbang Wang, Hejie Cui, Jon Kleinberg
date: "2024-02-19"
image: "../../img/2402.11821v1/image_1.png"
categories: ['social-sciences', 'hci']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.11821v1/image_1.png)

### Summary:
- The article investigates the accuracy of graph recall by Large Language Models (LLMs) and highlights the challenges faced by LLMs in accurately recalling and encoding graphs described in text. 
- It discusses the methodology and results of a study on the accuracy of graph recall by LLMs, indicating that LLMs underperform in the graph recall test and tend to forget edges rather than hallucinate them. 
- The section also explores the correlation between the performance of LLMs in graph recall and link prediction tasks, emphasizing the significance of understanding LLM's graph reasoning abilities. 
- Additionally, it highlights the development of datasets and frameworks to integrate graphs with LLMs and the lack of studies addressing the basic question of whether LLMs can accurately remember the graph they are supposed to reason upon.

### Major Findings:
1. LLMs underperform in graph recall and exhibit biased microstructures, which could have implications for their performance in more complex graph reasoning tasks.
2. LLMs struggle with accurately recalling graph structures, and the study raises questions about the impact of memory clearance and sex priming on LLMs' graph recall performance.
3. LLM's behavior in different graph reasoning tasks can be subtly revealed by examining their microstructural patterns, which is crucial for leveraging LLMs to advance the field of Graph Machine Learning.

### Analysis and Critique:
- The findings of the article have implications for improving LLMs' ability to reason on graphs and understanding the mechanisms of their information decoding and recall.
- The lack of existing literature addressing the accuracy of graph recall by LLMs is highlighted, indicating a gap in research that needs to be addressed.
- The lack of coherence in one of the sections makes it difficult to discern any significance or implications of its content in the broader context of the paper.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-20       |
| Abstract | [https://arxiv.org/abs/2402.11821v1](https://arxiv.org/abs/2402.11821v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.11821v1](https://browse.arxiv.org/html/2402.11821v1)       |
| Truncated       | True       |
| Word Count       | 20039       |