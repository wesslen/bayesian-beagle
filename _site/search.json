[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Bayesian beagle",
    "section": "",
    "text": "Welcome to the Bayesian beagle blog! This project is a unique intersection of machine learning and scientific communication, providing a platform where readers can quickly get insights from the latest research papers hosted on ArXiv. Utilizing state-of-the-art Large Language Models (LLMs), our system generates concise, comprehensible summaries of complex research articles, covering a wide array of disciplines.\nAll content is LLM generated. Assume skepticism and verify in the original paper as LLM models are imperfect and can struggle under certain circumstances.\nOur blog is built using Quarto and then published with Netlify.\n\n\n\n\ngraph LR\n    A[\"Download weekly Arxiv articles\"] --&gt; B[\"Predict and Filter LLM topic\"]\n    B --&gt; C[\"Summarize short docs\"]\n    B --&gt; D[\"Summarize by Map-Reduce long docs\"]\n    C --&gt; E[\"Update website with summaries weekly\"]\n    D --&gt; E"
  },
  {
    "objectID": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#major-findings",
    "href": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#major-findings",
    "title": "World Models with Hints of Large Language Models for Goal Achieving",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nDLLM integrates hinting subgoals from LLMs into the model rollouts to encourage goal discovery and reaching in challenging tasks.\nDLLM assigns higher intrinsic rewards to samples that align with the hints outlined by the language model during model rollouts.\nDLLM outperforms recent methods in various challenging, sparse-reward environments such as HomeGrid, Crafter, and Minecraft."
  },
  {
    "objectID": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#analysis-and-critique",
    "href": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#analysis-and-critique",
    "title": "World Models with Hints of Large Language Models for Goal Achieving",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents an innovative approach to addressing the challenges of long-horizon tasks and sparse rewards in RL. The use of LLMs to provide hinting subgoals is a promising direction for improving exploration and goal-reaching in complex environments. However, the paper does not discuss potential limitations or biases in the LLMs used, which could impact the performance of DLLM. Additionally, the paper does not provide a detailed comparison with other methods that use intrinsic rewards or LLMs for goal-setting. Further research is needed to evaluate the robustness and generalizability of DLLM in different environments and tasks."
  },
  {
    "objectID": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#appendix",
    "href": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#appendix",
    "title": "World Models with Hints of Large Language Models for Goal Achieving",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07381v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07381v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10623"
  },
  {
    "objectID": "posts/DiVERT_Distractor_Generation_with_Variational_Errors_Represented_as_Text_for_Math_Multiple_choice_Questions/2024-06-27-DiVERT_Distractor_Generation_with_Variational_Errors_Represented_as_Text_for_Math_Multiple_choice_Questions.html#appendix",
    "href": "posts/DiVERT_Distractor_Generation_with_Variational_Errors_Represented_as_Text_for_Math_Multiple_choice_Questions/2024-06-27-DiVERT_Distractor_Generation_with_Variational_Errors_Represented_as_Text_for_Math_Multiple_choice_Questions.html#appendix",
    "title": "DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19356v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19356v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9499"
  },
  {
    "objectID": "posts/Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering/2024-06-06-Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering.html",
    "href": "posts/Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering/2024-06-06-Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering.html",
    "title": "Tool-Planner: Dynamic Solution Tree Planning for Large Language Model with Tool Clustering",
    "section": "",
    "text": "Summary: The paper introduces Tool-Planner, a task-processing framework that groups tools based on their API functions into toolkits. This approach allows large language models (LLMs) to implement planning across various toolkits and reselect or adjust tools when a tool error occurs. The authors propose Tool-Planner to address the challenges of redundant error correction and designing a correct plan among multiple tools in tool learning. The experiments conducted demonstrate that Tool-Planner has a high pass and win rate across different datasets and optimizes the planning scheme for tool learning in models such as GPT-4 and Claude 3.\nMajor Findings: 1. Tool-Planner achieves state-of-the-art performance on five out of six datasets and shows competitive performance on the remaining dataset. 2. The method improves the pass rate by +8.8% and the win rate by +9.1% compared to the"
  },
  {
    "objectID": "posts/Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering/2024-06-06-Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering.html#appendix",
    "href": "posts/Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering/2024-06-06-Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering.html#appendix",
    "title": "Tool-Planner: Dynamic Solution Tree Planning for Large Language Model with Tool Clustering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03807v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03807v1\n\n\nTruncated\nTrue\n\n\nWord Count\n29774"
  },
  {
    "objectID": "posts/Enhancing_Repository_Level_Code_Generation_with_Integrated_Contextual_Information/2024-06-05-Enhancing_Repository_Level_Code_Generation_with_Integrated_Contextual_Information.html#appendix",
    "href": "posts/Enhancing_Repository_Level_Code_Generation_with_Integrated_Contextual_Information/2024-06-05-Enhancing_Repository_Level_Code_Generation_with_Integrated_Contextual_Information.html#appendix",
    "title": "Enhancing Repository-Level Code Generation with Integrated Contextual Information",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03283v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03283v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9447"
  },
  {
    "objectID": "posts/Crosslingual_Capabilities_and_Knowledge_Barriers_in_Multilingual_Large_Language_Models/2024-06-23-Crosslingual_Capabilities_and_Knowledge_Barriers_in_Multilingual_Large_Language_Models.html#appendix",
    "href": "posts/Crosslingual_Capabilities_and_Knowledge_Barriers_in_Multilingual_Large_Language_Models/2024-06-23-Crosslingual_Capabilities_and_Knowledge_Barriers_in_Multilingual_Large_Language_Models.html#appendix",
    "title": "Crosslingual Capabilities and Knowledge Barriers in Multilingual Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16135v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16135v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11266"
  },
  {
    "objectID": "posts/iMotion_LLM_Motion_Prediction_Instruction_Tuning/2024-06-10-iMotion_LLM_Motion_Prediction_Instruction_Tuning.html#appendix",
    "href": "posts/iMotion_LLM_Motion_Prediction_Instruction_Tuning/2024-06-10-iMotion_LLM_Motion_Prediction_Instruction_Tuning.html#appendix",
    "title": "iMotion-LLM: Motion Prediction Instruction Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06211v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06211v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5777"
  },
  {
    "objectID": "posts/Knowledge_Graph_Enhanced_Large_Language_Models_via_Path_Selection/2024-06-19-Knowledge_Graph_Enhanced_Large_Language_Models_via_Path_Selection.html#appendix",
    "href": "posts/Knowledge_Graph_Enhanced_Large_Language_Models_via_Path_Selection/2024-06-19-Knowledge_Graph_Enhanced_Large_Language_Models_via_Path_Selection.html#appendix",
    "title": "Knowledge Graph-Enhanced Large Language Models via Path Selection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13862v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13862v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6798"
  },
  {
    "objectID": "posts/Cambrian_1_A_Fully_Open_Vision_Centric_Exploration_of_Multimodal_LLMs/2024-06-24-Cambrian_1_A_Fully_Open_Vision_Centric_Exploration_of_Multimodal_LLMs.html",
    "href": "posts/Cambrian_1_A_Fully_Open_Vision_Centric_Exploration_of_Multimodal_LLMs/2024-06-24-Cambrian_1_A_Fully_Open_Vision_Centric_Exploration_of_Multimodal_LLMs.html",
    "title": "Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs",
    "section": "",
    "text": "Summary:\nThe paper introduces Cambrian-1, a family of multimodal large language models (MLLMs) that adopt a vision-centric approach. The authors argue that the design choices for vision components in MLLMs are often insufficiently explored and disconnected from visual representation learning research, hindering accurate sensory grounding in real-world scenarios. The study uses LLMs and visual instruction tuning as an interface to evaluate various visual representations, offering new insights into different models and architectures. The authors critically examine existing MLLM benchmarks and introduce a new vision-centric benchmark, CV-Bench. They also propose the Spatial Vision Aggregator (SVA), a dynamic and spatially-aware connector that integrates high-resolution vision features with LLMs while reducing the number of tokens.\nMajor Findings:"
  },
  {
    "objectID": "posts/Cambrian_1_A_Fully_Open_Vision_Centric_Exploration_of_Multimodal_LLMs/2024-06-24-Cambrian_1_A_Fully_Open_Vision_Centric_Exploration_of_Multimodal_LLMs.html#appendix",
    "href": "posts/Cambrian_1_A_Fully_Open_Vision_Centric_Exploration_of_Multimodal_LLMs/2024-06-24-Cambrian_1_A_Fully_Open_Vision_Centric_Exploration_of_Multimodal_LLMs.html#appendix",
    "title": "Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16860v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16860v1\n\n\nTruncated\nTrue\n\n\nWord Count\n44586"
  },
  {
    "objectID": "posts/BIPED_Pedagogically_Informed_Tutoring_System_for_ESL_Education/2024-06-05-BIPED_Pedagogically_Informed_Tutoring_System_for_ESL_Education.html#appendix",
    "href": "posts/BIPED_Pedagogically_Informed_Tutoring_System_for_ESL_Education/2024-06-05-BIPED_Pedagogically_Informed_Tutoring_System_for_ESL_Education.html#appendix",
    "title": "BIPED: Pedagogically Informed Tutoring System for ESL Education",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03486v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03486v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7759"
  },
  {
    "objectID": "posts/Enhancing_Computer_Programming_Education_with_LLMs_A_Study_on_Effective_Prompt_Engineering_for_Python_Code_Generation/2024-07-07-Enhancing_Computer_Programming_Education_with_LLMs_A_Study_on_Effective_Prompt_Engineering_for_Python_Code_Generation.html#appendix",
    "href": "posts/Enhancing_Computer_Programming_Education_with_LLMs_A_Study_on_Effective_Prompt_Engineering_for_Python_Code_Generation/2024-07-07-Enhancing_Computer_Programming_Education_with_LLMs_A_Study_on_Effective_Prompt_Engineering_for_Python_Code_Generation.html#appendix",
    "title": "Enhancing Computer Programming Education with LLMs: A Study on Effective Prompt Engineering for Python Code Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05437v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05437v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9547"
  },
  {
    "objectID": "posts/An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection/2024-06-10-An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection.html",
    "href": "posts/An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection/2024-06-10-An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection.html",
    "title": "An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection",
    "section": "",
    "text": "Summary:\nThe paper introduces CodeBreaker, a pioneering LLM-assisted backdoor attack framework on code completion models. Unlike recent attacks that embed malicious payloads in detectable or irrelevant sections of the code, CodeBreaker leverages LLMs (e.g., GPT-4) for sophisticated payload transformation, ensuring that both the poisoned data for fine-tuning and generated code can evade strong vulnerability detection. CodeBreaker stands out with its comprehensive coverage of vulnerabilities, making it the first to provide such an extensive set for evaluation.\nMajor Findings:\nAnalysis and Critique:\nWhile CodeBreaker presents a significant advancement in backdoor attacks on code completion models, there are potential limitations and areas for improvement. The reliance on LLMs for payload transformation and obfuscation may introduce new vulnerabilities in the LLMs themselves, as they are used to facilitate adversarial attacks. Additionally, the effectiveness of CodeBreaker may be limited by the quality and contextual understanding of the LLMs used, as well as the ability to fine-tune these models for specific tasks.\nFurther research is needed to explore the potential for more robust defenses"
  },
  {
    "objectID": "posts/An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection/2024-06-10-An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection.html#appendix",
    "href": "posts/An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection/2024-06-10-An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection.html#appendix",
    "title": "An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06822v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06822v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11894"
  },
  {
    "objectID": "posts/Buffer_of_Thoughts_Thought_Augmented_Reasoning_with_Large_Language_Models/2024-06-06-Buffer_of_Thoughts_Thought_Augmented_Reasoning_with_Large_Language_Models.html#appendix",
    "href": "posts/Buffer_of_Thoughts_Thought_Augmented_Reasoning_with_Large_Language_Models/2024-06-06-Buffer_of_Thoughts_Thought_Augmented_Reasoning_with_Large_Language_Models.html#appendix",
    "title": "Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04271v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04271v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6204"
  },
  {
    "objectID": "posts/Suri_Multi_constraint_Instruction_Following_for_Long_form_Text_Generation/2024-06-27-Suri_Multi_constraint_Instruction_Following_for_Long_form_Text_Generation.html#appendix",
    "href": "posts/Suri_Multi_constraint_Instruction_Following_for_Long_form_Text_Generation/2024-06-27-Suri_Multi_constraint_Instruction_Following_for_Long_form_Text_Generation.html#appendix",
    "title": "Suri: Multi-constraint Instruction Following for Long-form Text Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19371v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19371v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8097"
  },
  {
    "objectID": "posts/Q_Improving_Multi_step_Reasoning_for_LLMs_with_Deliberative_Planning/2024-06-20-Q_Improving_Multi_step_Reasoning_for_LLMs_with_Deliberative_Planning.html#appendix",
    "href": "posts/Q_Improving_Multi_step_Reasoning_for_LLMs_with_Deliberative_Planning/2024-06-20-Q_Improving_Multi_step_Reasoning_for_LLMs_with_Deliberative_Planning.html#appendix",
    "title": "Q*: Improving Multi-step Reasoning for LLMs with Deliberative Planning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14283v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14283v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5312"
  },
  {
    "objectID": "posts/A_Context_Driven_Approach_for_Co_Auditing_Smart_Contracts_with_The_Support_of_GPT_4_code_interpreter/2024-06-26-A_Context_Driven_Approach_for_Co_Auditing_Smart_Contracts_with_The_Support_of_GPT_4_code_interpreter.html#appendix",
    "href": "posts/A_Context_Driven_Approach_for_Co_Auditing_Smart_Contracts_with_The_Support_of_GPT_4_code_interpreter/2024-06-26-A_Context_Driven_Approach_for_Co_Auditing_Smart_Contracts_with_The_Support_of_GPT_4_code_interpreter.html#appendix",
    "title": "A Context-Driven Approach for Co-Auditing Smart Contracts with The Support of GPT-4 code interpreter",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18075v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18075v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9396"
  },
  {
    "objectID": "posts/Empirical_Study_of_Symmetrical_Reasoning_in_Conversational_Chatbots/2024-07-08-Empirical_Study_of_Symmetrical_Reasoning_in_Conversational_Chatbots.html#appendix",
    "href": "posts/Empirical_Study_of_Symmetrical_Reasoning_in_Conversational_Chatbots/2024-07-08-Empirical_Study_of_Symmetrical_Reasoning_in_Conversational_Chatbots.html#appendix",
    "title": "Empirical Study of Symmetrical Reasoning in Conversational Chatbots",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05734v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05734v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4950"
  },
  {
    "objectID": "posts/The_FineWeb_Datasets_Decanting_the_Web_for_the_Finest_Text_Data_at_Scale/2024-06-25-The_FineWeb_Datasets_Decanting_the_Web_for_the_Finest_Text_Data_at_Scale.html#appendix",
    "href": "posts/The_FineWeb_Datasets_Decanting_the_Web_for_the_Finest_Text_Data_at_Scale/2024-06-25-The_FineWeb_Datasets_Decanting_the_Web_for_the_Finest_Text_Data_at_Scale.html#appendix",
    "title": "The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17557v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17557v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10755"
  },
  {
    "objectID": "posts/A_Probabilistic_Framework_for_LLM_Hallucination_Detection_via_Belief_Tree_Propagation/2024-06-11-A_Probabilistic_Framework_for_LLM_Hallucination_Detection_via_Belief_Tree_Propagation.html#appendix",
    "href": "posts/A_Probabilistic_Framework_for_LLM_Hallucination_Detection_via_Belief_Tree_Propagation/2024-06-11-A_Probabilistic_Framework_for_LLM_Hallucination_Detection_via_Belief_Tree_Propagation.html#appendix",
    "title": "A Probabilistic Framework for LLM Hallucination Detection via Belief Tree Propagation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06950v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06950v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10310"
  },
  {
    "objectID": "posts/Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs/2024-06-18-Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs.html",
    "href": "posts/Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs/2024-06-18-Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs.html",
    "title": "Can We Trust Large Language Models Generated Code? A Framework for In-Context Learning, Security Patterns, and Code Evaluations Across Diverse LLMs",
    "section": "",
    "text": "Summary:\nThis research aims to tackle the security and quality concerns of code generated by Large Language Models (LLMs) like ChatGPT and GitHub Copilot. These models are increasingly utilized for software development but are primarily trained on publicly available code repositories and internet-based textual data, which may contain insecure code. This presents a significant risk of perpetuating vulnerabilities in the generated code. The research introduces a framework for secure behavioral learning of LLMs through In-Context Learning (ICL) patterns during the code generation process, followed by rigorous security evaluations. Four diverse LLMs are selected for experimentation, and their coding capabilities are evaluated across three programming languages. The research indicates that ICL-driven one-shot and few-shot learning patterns can enhance code security, reducing vulnerabilities in various programming scenarios. However, developers and researchers should be aware that LLMs have a limited understanding of security principles, which may lead to security breaches when the generated code is deployed in production systems. The research highlights that LLMs are a potential source of new vulnerabilities to the software supply chain and emphasizes the importance of considering this when using LLMs for code generation.\nMajor Findings:\nAnalysis and Critique:\nThe research provides"
  },
  {
    "objectID": "posts/Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs/2024-06-18-Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs.html#appendix",
    "href": "posts/Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs/2024-06-18-Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs.html#appendix",
    "title": "Can We Trust Large Language Models Generated Code? A Framework for In-Context Learning, Security Patterns, and Code Evaluations Across Diverse LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12513v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12513v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18028"
  },
  {
    "objectID": "posts/Exploring_Human_LLM_Conversations_Mental_Models_and_the_Originator_of_Toxicity/2024-07-08-Exploring_Human_LLM_Conversations_Mental_Models_and_the_Originator_of_Toxicity.html#appendix",
    "href": "posts/Exploring_Human_LLM_Conversations_Mental_Models_and_the_Originator_of_Toxicity/2024-07-08-Exploring_Human_LLM_Conversations_Mental_Models_and_the_Originator_of_Toxicity.html#appendix",
    "title": "Exploring Human-LLM Conversations: Mental Models and the Originator of Toxicity",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05977v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05977v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8762"
  },
  {
    "objectID": "posts/Mind_the_Privacy_Unit!_User_Level_Differential_Privacy_for_Language_Model_Fine_Tuning/2024-06-20-Mind_the_Privacy_Unit!_User_Level_Differential_Privacy_for_Language_Model_Fine_Tuning.html#appendix",
    "href": "posts/Mind_the_Privacy_Unit!_User_Level_Differential_Privacy_for_Language_Model_Fine_Tuning/2024-06-20-Mind_the_Privacy_Unit!_User_Level_Differential_Privacy_for_Language_Model_Fine_Tuning.html#appendix",
    "title": "Mind the Privacy Unit! User-Level Differential Privacy for Language Model Fine-Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14322v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14322v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7165"
  },
  {
    "objectID": "posts/Generalization_Enhanced_Code_Vulnerability_Detection_via_Multi_Task_Instruction_Fine_Tuning/2024-06-06-Generalization_Enhanced_Code_Vulnerability_Detection_via_Multi_Task_Instruction_Fine_Tuning.html#appendix",
    "href": "posts/Generalization_Enhanced_Code_Vulnerability_Detection_via_Multi_Task_Instruction_Fine_Tuning/2024-06-06-Generalization_Enhanced_Code_Vulnerability_Detection_via_Multi_Task_Instruction_Fine_Tuning.html#appendix",
    "title": "Generalization-Enhanced Code Vulnerability Detection via Multi-Task Instruction Fine-Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03718v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03718v1\n\n\nTruncated\nFalse\n\n\nWord Count\n22567"
  },
  {
    "objectID": "posts/Defending_Against_Social_Engineering_Attacks_in_the_Age_of_LLMs/2024-06-18-Defending_Against_Social_Engineering_Attacks_in_the_Age_of_LLMs.html#appendix",
    "href": "posts/Defending_Against_Social_Engineering_Attacks_in_the_Age_of_LLMs/2024-06-18-Defending_Against_Social_Engineering_Attacks_in_the_Age_of_LLMs.html#appendix",
    "title": "Defending Against Social Engineering Attacks in the Age of LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12263v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12263v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7850"
  },
  {
    "objectID": "posts/CleanGen_Mitigating_Backdoor_Attacks_for_Generation_Tasks_in_Large_Language_Models/2024-06-18-CleanGen_Mitigating_Backdoor_Attacks_for_Generation_Tasks_in_Large_Language_Models.html#appendix",
    "href": "posts/CleanGen_Mitigating_Backdoor_Attacks_for_Generation_Tasks_in_Large_Language_Models/2024-06-18-CleanGen_Mitigating_Backdoor_Attacks_for_Generation_Tasks_in_Large_Language_Models.html#appendix",
    "title": "CleanGen: Mitigating Backdoor Attacks for Generation Tasks in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12257v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12257v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7540"
  },
  {
    "objectID": "posts/Experiments_with_truth_using_Machine_Learning_Spectral_analysis_and_explainable_classification_of_synthetic_false_and_genuine_information/2024-07-07-Experiments_with_truth_using_Machine_Learning_Spectral_analysis_and_explainable_classification_of_synthetic_false_and_genuine_information.html#appendix",
    "href": "posts/Experiments_with_truth_using_Machine_Learning_Spectral_analysis_and_explainable_classification_of_synthetic_false_and_genuine_information/2024-07-07-Experiments_with_truth_using_Machine_Learning_Spectral_analysis_and_explainable_classification_of_synthetic_false_and_genuine_information.html#appendix",
    "title": "Experiments with truth using Machine Learning: Spectral analysis and explainable classification of synthetic, false, and genuine information",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05464v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05464v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9665"
  },
  {
    "objectID": "posts/LLM_Internal_States_Reveal_Hallucination_Risk_Faced_With_a_Query/2024-07-03-LLM_Internal_States_Reveal_Hallucination_Risk_Faced_With_a_Query.html#appendix",
    "href": "posts/LLM_Internal_States_Reveal_Hallucination_Risk_Faced_With_a_Query/2024-07-03-LLM_Internal_States_Reveal_Hallucination_Risk_Faced_With_a_Query.html#appendix",
    "title": "LLM Internal States Reveal Hallucination Risk Faced With a Query",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03282v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03282v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11970"
  },
  {
    "objectID": "posts/RES_Q_Evaluating_Code_Editing_Large_Language_Model_Systems_at_the_Repository_Scale/2024-06-24-RES_Q_Evaluating_Code_Editing_Large_Language_Model_Systems_at_the_Repository_Scale.html#appendix",
    "href": "posts/RES_Q_Evaluating_Code_Editing_Large_Language_Model_Systems_at_the_Repository_Scale/2024-06-24-RES_Q_Evaluating_Code_Editing_Large_Language_Model_Systems_at_the_Repository_Scale.html#appendix",
    "title": "RES-Q: Evaluating Code-Editing Large Language Model Systems at the Repository Scale",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16801v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16801v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3509"
  },
  {
    "objectID": "posts/Can_Large_Language_Models_Always_Solve_Easy_Problems_if_They_Can_Solve_Harder_Ones/2024-06-18-Can_Large_Language_Models_Always_Solve_Easy_Problems_if_They_Can_Solve_Harder_Ones.html#appendix",
    "href": "posts/Can_Large_Language_Models_Always_Solve_Easy_Problems_if_They_Can_Solve_Harder_Ones/2024-06-18-Can_Large_Language_Models_Always_Solve_Easy_Problems_if_They_Can_Solve_Harder_Ones.html#appendix",
    "title": "Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12809v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12809v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9280"
  },
  {
    "objectID": "posts/RAGSys_Item_Cold_Start_Recommender_as_RAG_System/2024-05-27-RAGSys_Item_Cold_Start_Recommender_as_RAG_System.html#appendix",
    "href": "posts/RAGSys_Item_Cold_Start_Recommender_as_RAG_System/2024-05-27-RAGSys_Item_Cold_Start_Recommender_as_RAG_System.html#appendix",
    "title": "RAGSys: Item-Cold-Start Recommender as RAG System",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.17587v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.17587v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9098"
  },
  {
    "objectID": "posts/New_intelligent_empowerment_for_digital_transformation/2024-06-26-New_intelligent_empowerment_for_digital_transformation.html",
    "href": "posts/New_intelligent_empowerment_for_digital_transformation/2024-06-26-New_intelligent_empowerment_for_digital_transformation.html",
    "title": "New intelligent empowerment for digital transformation",
    "section": "",
    "text": "Summary:\nThis study proposes a novel evaluation method for measuring the digital transformation (DT) process of enterprises based on large language models (LLMs). The authors analyzed annual reports of 4407 companies listed on the New York Stock Exchange and Nasdaq from 2005 to 2022, constructing a comprehensive set of DT indicators. The findings reveal that DT significantly improves a company’s financial performance, but different digital technologies have varying effects on financial performance. Specifically, blockchain technology has a relatively limited positive impact on financial performance. Additionally, DT can promote the growth of financial performance by enhancing operational efficiency and reducing costs.\nMajor Findings:\nAnalysis and Critique:\nThe study provides a novel DT evaluation tool for the academic community and expands the application scope of generative artificial intelligence technology in economic research. However, several limitations and potential biases should be considered:"
  },
  {
    "objectID": "posts/New_intelligent_empowerment_for_digital_transformation/2024-06-26-New_intelligent_empowerment_for_digital_transformation.html#appendix",
    "href": "posts/New_intelligent_empowerment_for_digital_transformation/2024-06-26-New_intelligent_empowerment_for_digital_transformation.html#appendix",
    "title": "New intelligent empowerment for digital transformation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18440v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18440v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17294"
  },
  {
    "objectID": "posts/InverseCoder_Unleashing_the_Power_of_Instruction_Tuned_Code_LLMs_with_Inverse_Instruct/2024-07-08-InverseCoder_Unleashing_the_Power_of_Instruction_Tuned_Code_LLMs_with_Inverse_Instruct.html#appendix",
    "href": "posts/InverseCoder_Unleashing_the_Power_of_Instruction_Tuned_Code_LLMs_with_Inverse_Instruct/2024-07-08-InverseCoder_Unleashing_the_Power_of_Instruction_Tuned_Code_LLMs_with_Inverse_Instruct.html#appendix",
    "title": "InverseCoder: Unleashing the Power of Instruction-Tuned Code LLMs with Inverse-Instruct",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05700v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05700v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6732"
  },
  {
    "objectID": "posts/RS_Agent_Automating_Remote_Sensing_Tasks_through_Intelligent_Agents/2024-06-11-RS_Agent_Automating_Remote_Sensing_Tasks_through_Intelligent_Agents.html#appendix",
    "href": "posts/RS_Agent_Automating_Remote_Sensing_Tasks_through_Intelligent_Agents/2024-06-11-RS_Agent_Automating_Remote_Sensing_Tasks_through_Intelligent_Agents.html#appendix",
    "title": "RS-Agent: Automating Remote Sensing Tasks through Intelligent Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07089v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07089v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5913"
  },
  {
    "objectID": "posts/MoPS_Modular_Story_Premise_Synthesis_for_Open_Ended_Automatic_Story_Generation/2024-06-09-MoPS_Modular_Story_Premise_Synthesis_for_Open_Ended_Automatic_Story_Generation.html#appendix",
    "href": "posts/MoPS_Modular_Story_Premise_Synthesis_for_Open_Ended_Automatic_Story_Generation/2024-06-09-MoPS_Modular_Story_Premise_Synthesis_for_Open_Ended_Automatic_Story_Generation.html#appendix",
    "title": "MoPS: Modular Story Premise Synthesis for Open-Ended Automatic Story Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05690v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05690v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9468"
  },
  {
    "objectID": "posts/Role_Play_Zero_Shot_Prompting_with_Large_Language_Models_for_Open_Domain_Human_Machine_Conversation/2024-06-26-Role_Play_Zero_Shot_Prompting_with_Large_Language_Models_for_Open_Domain_Human_Machine_Conversation.html#appendix",
    "href": "posts/Role_Play_Zero_Shot_Prompting_with_Large_Language_Models_for_Open_Domain_Human_Machine_Conversation/2024-06-26-Role_Play_Zero_Shot_Prompting_with_Large_Language_Models_for_Open_Domain_Human_Machine_Conversation.html#appendix",
    "title": "Role-Play Zero-Shot Prompting with Large Language Models for Open-Domain Human-Machine Conversation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18460v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18460v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7179"
  },
  {
    "objectID": "posts/LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs/2024-06-26-LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs.html#major-findings",
    "href": "posts/LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs/2024-06-26-LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs.html#major-findings",
    "title": "LongIns: A Challenging Long-context Instruction-based Exam for LLMs",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe top-performing GPT-4 with 128k context length performs poorly on the evaluation context window of 16k in LongIns.\nSignificant efforts are still needed for the multi-hop reasoning ability of many existing LLMs under short context windows (&lt;4k).\nMost models fail to achieve high scores when the critical information length is only 8k, and even GPT-4 and GPT-4o score poorly at 16k length."
  },
  {
    "objectID": "posts/LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs/2024-06-26-LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs.html#analysis-and-critique",
    "href": "posts/LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs/2024-06-26-LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs.html#analysis-and-critique",
    "title": "LongIns: A Challenging Long-context Instruction-based Exam for LLMs",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper provides a valuable contribution to the field by introducing a benchmark that focuses on the actual comprehensible window length of LLMs, which is often overlooked in existing benchmarks.\nThe authors evaluate a diverse set of LLMs, providing a comprehensive analysis of their long-context understanding capabilities.\nHowever, the paper does not discuss the potential limitations of the proposed benchmark, such as the generalizability of the findings to other types of tasks or the potential biases in the dataset.\nAdditionally, the paper does not provide a detailed analysis of the methodology used to generate the dataset, which could impact the validity of the results.\nFinally, the paper does not discuss the potential implications of the findings for the development of LLMs or the design of future benchmarks."
  },
  {
    "objectID": "posts/LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs/2024-06-26-LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs.html#appendix",
    "href": "posts/LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs/2024-06-26-LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs.html#appendix",
    "title": "LongIns: A Challenging Long-context Instruction-based Exam for LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17588v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17588v2\n\n\nTruncated\nFalse\n\n\nWord Count\n5491"
  },
  {
    "objectID": "posts/Investigating_Low_Cost_LLM_Annotation_for~Spoken_Dialogue_Understanding_Datasets/2024-06-19-Investigating_Low_Cost_LLM_Annotation_for~Spoken_Dialogue_Understanding_Datasets.html#appendix",
    "href": "posts/Investigating_Low_Cost_LLM_Annotation_for~Spoken_Dialogue_Understanding_Datasets/2024-06-19-Investigating_Low_Cost_LLM_Annotation_for~Spoken_Dialogue_Understanding_Datasets.html#appendix",
    "title": "Investigating Low-Cost LLM Annotation for~Spoken Dialogue Understanding Datasets",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13269v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13269v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6424"
  },
  {
    "objectID": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#major-findings",
    "href": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#major-findings",
    "title": "Digital Business Model Analysis Using a Large Language Model",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe study demonstrates the potential of using LLMs for analyzing and designing new business models, which is still an evolving field with scarce research.\nThe proposed method can support idea generation in digital business model design by learning patterns from the commonalities of DX cases and using this knowledge as a reference when considering DX initiatives.\nThe analysis examples show that LLM can effectively extract similar DX cases, not only within the same industry but also from different industries, and consider their commonalities to support the ideation of digital business models."
  },
  {
    "objectID": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#analysis-and-critique",
    "href": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#analysis-and-critique",
    "title": "Digital Business Model Analysis Using a Large Language Model",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe study’s findings are preliminary, and further research is needed to refine the analytical methods using advanced NLP technologies and broaden the examination of digital business models across a wider spectrum of industries.\nThe proposed method potentially offers companies easy access to insights into the use of digital technologies and business model innovations that have previously been less accessible.\nThe authors plan to develop a recommendation system, possibly implemented via chatbots, that could suggest similar cases to act as a catalyst for companies aiming to accelerate their DX efforts.\nThe study makes certain academic contributions by demonstrating the potential of this approach, but more research is needed to fully understand its implications and limitations."
  },
  {
    "objectID": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#appendix",
    "href": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#appendix",
    "title": "Digital Business Model Analysis Using a Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05741v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05741v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3431"
  },
  {
    "objectID": "posts/FVEL_Interactive_Formal_Verification_Environment_with_Large_Language_Models_via_Theorem_Proving/2024-06-20-FVEL_Interactive_Formal_Verification_Environment_with_Large_Language_Models_via_Theorem_Proving.html#appendix",
    "href": "posts/FVEL_Interactive_Formal_Verification_Environment_with_Large_Language_Models_via_Theorem_Proving/2024-06-20-FVEL_Interactive_Formal_Verification_Environment_with_Large_Language_Models_via_Theorem_Proving.html#appendix",
    "title": "FVEL: Interactive Formal Verification Environment with Large Language Models via Theorem Proving",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14408v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14408v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11049"
  },
  {
    "objectID": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#major-findings",
    "href": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#major-findings",
    "title": "Characterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People",
    "section": "Major Findings",
    "text": "Major Findings\n\nThe proposed method enables the characterization of conversational tones and their taxonomies in any target human population as well as LLMs, without relying on predefined taxonomies or constrained sets of stimuli.\nThe study addresses the challenges of biased apriori taxonomy and biased stimulus set in existing research on conversational tones.\nThe paper presents an additional experiment where humans and GPT-4 annotated all sentences with all tones, resulting in an interpretable geometric representation of relations between conversational tones in humans and GPT-4."
  },
  {
    "objectID": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#analysis-and-critique",
    "href": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#analysis-and-critique",
    "title": "Characterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\nThe paper presents a novel and promising approach to characterize conversational tones and their taxonomies in humans and LLMs. The proposed method addresses the limitations"
  },
  {
    "objectID": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#appendix",
    "href": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#appendix",
    "title": "Characterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04278v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04278v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14313"
  },
  {
    "objectID": "posts/Are_Large_Language_Models_Consistent_over_Value_laden_Questions/2024-07-03-Are_Large_Language_Models_Consistent_over_Value_laden_Questions.html#appendix",
    "href": "posts/Are_Large_Language_Models_Consistent_over_Value_laden_Questions/2024-07-03-Are_Large_Language_Models_Consistent_over_Value_laden_Questions.html#appendix",
    "title": "Are Large Language Models Consistent over Value-laden Questions?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02996v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02996v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11041"
  },
  {
    "objectID": "posts/Towards_Open_World_Grasping_with_Large_Vision_Language_Models/2024-06-26-Towards_Open_World_Grasping_with_Large_Vision_Language_Models.html#major-findings",
    "href": "posts/Towards_Open_World_Grasping_with_Large_Vision_Language_Models/2024-06-26-Towards_Open_World_Grasping_with_Large_Vision_Language_Models.html#major-findings",
    "title": "Towards Open-World Grasping with Large Vision-Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nClarity of Visual Markers: The authors find that the most common failure mode of visual marker prompting with GPT-4v is that it sometimes struggles to discriminate which ID corresponds to what segment, especially in cluttered scenes. Techniques such as overlaying numeric IDs with minimal overlap, coloring both the internal of each segment’s mask and its ID with the same unique color, and increasing the resolution of the marked image and the size layout of the markers can assist in making the markers more clear to the VLM.\nReference Image and Chain-of-Thoughts: The authors propose techniques to ameliorate the issue of GPT-4v sometimes referring to regions with wrong IDs, especially in highly cluttered scenes. They suggest passing both the original (reference) and the marked image and constructing a text prompt that explains that the latter corresponds to annotated segments of the first. They also find that VLMs share similar properties with LLMs and prompting them to reason about their final answer before producing it can robustify the response quality.\nSelf-consistency and In-context Examples: The authors observe that the outputs of GPT-4v are not always reproducible, even with exactly the same prompt. They propose using the self-consistency method developed for LLMs to reduce the effect of this phenomenon and robustify VLM outputs. They also find that in-context examples can improve the robustness of the grasp planning and contact reasoning stages."
  },
  {
    "objectID": "posts/Towards_Open_World_Grasping_with_Large_Vision_Language_Models/2024-06-26-Towards_Open_World_Grasping_with_Large_Vision_Language_Models.html#analysis-and-critique",
    "href": "posts/Towards_Open_World_Grasping_with_Large_Vision_Language_Models/2024-06-26-Towards_Open_World_Grasping_with_Large_Vision_Language_Models.html#analysis-and-critique",
    "title": "Towards Open-World Grasping with Large Vision-Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe article provides a comprehensive exploration of various techniques to improve the performance of VLMs in open-world grasping tasks. However, the study is limited to the GPT-4v model, and the results may not generalize to other VLMs. The authors also acknowledge that the actual model specifics of GPT-4v are unknown, which makes it difficult to fully understand the reasons behind its performance. Furthermore, the study does not provide"
  },
  {
    "objectID": "posts/Towards_Open_World_Grasping_with_Large_Vision_Language_Models/2024-06-26-Towards_Open_World_Grasping_with_Large_Vision_Language_Models.html#appendix",
    "href": "posts/Towards_Open_World_Grasping_with_Large_Vision_Language_Models/2024-06-26-Towards_Open_World_Grasping_with_Large_Vision_Language_Models.html#appendix",
    "title": "Towards Open-World Grasping with Large Vision-Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18722v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18722v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3751"
  },
  {
    "objectID": "posts/NeBuLa_A_discourse_aware_Minecraft_Builder/2024-06-26-NeBuLa_A_discourse_aware_Minecraft_Builder.html#appendix",
    "href": "posts/NeBuLa_A_discourse_aware_Minecraft_Builder/2024-06-26-NeBuLa_A_discourse_aware_Minecraft_Builder.html#appendix",
    "title": "NeBuLa: A discourse aware Minecraft Builder",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18164v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18164v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6185"
  },
  {
    "objectID": "posts/Towards_Large_Language_Model_Aided_Program_Refinement/2024-06-26-Towards_Large_Language_Model_Aided_Program_Refinement.html#appendix",
    "href": "posts/Towards_Large_Language_Model_Aided_Program_Refinement/2024-06-26-Towards_Large_Language_Model_Aided_Program_Refinement.html#appendix",
    "title": "Towards Large Language Model Aided Program Refinement",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18616v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18616v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5456"
  },
  {
    "objectID": "posts/Session_Context_Embedding_for_Intent_Understanding_in_Product_Search/2024-06-03-Session_Context_Embedding_for_Intent_Understanding_in_Product_Search.html#appendix",
    "href": "posts/Session_Context_Embedding_for_Intent_Understanding_in_Product_Search/2024-06-03-Session_Context_Embedding_for_Intent_Understanding_in_Product_Search.html#appendix",
    "title": "Session Context Embedding for Intent Understanding in Product Search",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01702v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01702v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3385"
  },
  {
    "objectID": "posts/Investigating_the_Influence_of_Prompt_Specific_Shortcuts_in_AI_Generated_Text_Detection/2024-06-24-Investigating_the_Influence_of_Prompt_Specific_Shortcuts_in_AI_Generated_Text_Detection.html#appendix",
    "href": "posts/Investigating_the_Influence_of_Prompt_Specific_Shortcuts_in_AI_Generated_Text_Detection/2024-06-24-Investigating_the_Influence_of_Prompt_Specific_Shortcuts_in_AI_Generated_Text_Detection.html#appendix",
    "title": "Investigating the Influence of Prompt-Specific Shortcuts in AI Generated Text Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16275v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16275v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8427"
  },
  {
    "objectID": "posts/Joint_Demonstration_and_Preference_Learning_Improves_Policy_Alignment_with_Human_Feedback/2024-06-11-Joint_Demonstration_and_Preference_Learning_Improves_Policy_Alignment_with_Human_Feedback.html#appendix",
    "href": "posts/Joint_Demonstration_and_Preference_Learning_Improves_Policy_Alignment_with_Human_Feedback/2024-06-11-Joint_Demonstration_and_Preference_Learning_Improves_Policy_Alignment_with_Human_Feedback.html#appendix",
    "title": "Joint Demonstration and Preference Learning Improves Policy Alignment with Human Feedback",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06874v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06874v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10718"
  },
  {
    "objectID": "posts/Nicer_Than_Humans_How_do_Large_Language_Models_Behave_in_the_Prisoners_Dilemma/2024-06-19-Nicer_Than_Humans_How_do_Large_Language_Models_Behave_in_the_Prisoners_Dilemma.html#appendix",
    "href": "posts/Nicer_Than_Humans_How_do_Large_Language_Models_Behave_in_the_Prisoners_Dilemma/2024-06-19-Nicer_Than_Humans_How_do_Large_Language_Models_Behave_in_the_Prisoners_Dilemma.html#appendix",
    "title": "Nicer Than Humans: How do Large Language Models Behave in the Prisoner’s Dilemma?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13605v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13605v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7427"
  },
  {
    "objectID": "posts/Noisy_Neighbors_Efficient_membership_inference_attacks_against_LLMs/2024-06-24-Noisy_Neighbors_Efficient_membership_inference_attacks_against_LLMs.html#appendix",
    "href": "posts/Noisy_Neighbors_Efficient_membership_inference_attacks_against_LLMs/2024-06-24-Noisy_Neighbors_Efficient_membership_inference_attacks_against_LLMs.html#appendix",
    "title": "Noisy Neighbors: Efficient membership inference attacks against LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16565v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16565v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3223"
  },
  {
    "objectID": "posts/Model_Merging_and_Safety_Alignment_One_Bad_Model_Spoils_the_Bunch/2024-06-20-Model_Merging_and_Safety_Alignment_One_Bad_Model_Spoils_the_Bunch.html#appendix",
    "href": "posts/Model_Merging_and_Safety_Alignment_One_Bad_Model_Spoils_the_Bunch/2024-06-20-Model_Merging_and_Safety_Alignment_One_Bad_Model_Spoils_the_Bunch.html#appendix",
    "title": "Model Merging and Safety Alignment: One Bad Model Spoils the Bunch",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14563v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14563v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8326"
  },
  {
    "objectID": "posts/LLMs_instead_of_Human_Judges_A_Large_Scale_Empirical_Study_across_20_NLP_Evaluation_Tasks/2024-06-26-LLMs_instead_of_Human_Judges_A_Large_Scale_Empirical_Study_across_20_NLP_Evaluation_Tasks.html#appendix",
    "href": "posts/LLMs_instead_of_Human_Judges_A_Large_Scale_Empirical_Study_across_20_NLP_Evaluation_Tasks/2024-06-26-LLMs_instead_of_Human_Judges_A_Large_Scale_Empirical_Study_across_20_NLP_Evaluation_Tasks.html#appendix",
    "title": "LLMs instead of Human Judges? A Large Scale Empirical Study across 20 NLP Evaluation Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18403v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18403v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5321"
  },
  {
    "objectID": "posts/SPL_A_Socratic_Playground_for_Learning_Powered_by_Large_Language_Mode/2024-06-20-SPL_A_Socratic_Playground_for_Learning_Powered_by_Large_Language_Mode.html#appendix",
    "href": "posts/SPL_A_Socratic_Playground_for_Learning_Powered_by_Large_Language_Mode/2024-06-20-SPL_A_Socratic_Playground_for_Learning_Powered_by_Large_Language_Mode.html#appendix",
    "title": "SPL: A Socratic Playground for Learning Powered by Large Language Mode",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13919v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13919v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7284"
  },
  {
    "objectID": "posts/AMBROSIA_A_Benchmark_for_Parsing_Ambiguous_Questions_into_Database_Queries/2024-06-27-AMBROSIA_A_Benchmark_for_Parsing_Ambiguous_Questions_into_Database_Queries.html",
    "href": "posts/AMBROSIA_A_Benchmark_for_Parsing_Ambiguous_Questions_into_Database_Queries/2024-06-27-AMBROSIA_A_Benchmark_for_Parsing_Ambiguous_Questions_into_Database_Queries.html",
    "title": "AMBROSIA: A Benchmark for Parsing Ambiguous Questions into Database Queries",
    "section": "",
    "text": "Summary:\nThe paper introduces a new benchmark, “, for text-to-SQL parsers capable of recognizing and interpreting ambiguous requests. The dataset contains questions showcasing three different types of ambiguity (scope ambiguity, attachment ambiguity, and vagueness), their interpretations, and corresponding SQL queries. The dataset includes 846 multi-table databases, ambiguous questions, unambiguous interpretations, and complex SQL queries (4,242 in total). The authors aim to mimic real-world semantic parsing scenarios with realistic and diverse databases, creating them automatically in three steps: specifying a domain of interest, generating key concepts and relations, and generating SQL statements to construct tables with the desired structure. The paper also presents the results of benchmarking multiple advanced large language models on “, revealing that even the most advanced models struggle to identify and interpret ambiguity in questions.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel benchmark for text-to-SQL parsers capable of recognizing and interpreting ambiguous requests. The dataset is diverse and covers a wide range of SQL queries, making it a valuable resource for researchers in the field. However, the paper does not provide a detailed analysis of the performance of the benchmarked models, making it difficult to assess the effectiveness of the proposed approach. Additionally, the paper does not discuss potential limitations or biases in the dataset, which could impact the generaliz"
  },
  {
    "objectID": "posts/AMBROSIA_A_Benchmark_for_Parsing_Ambiguous_Questions_into_Database_Queries/2024-06-27-AMBROSIA_A_Benchmark_for_Parsing_Ambiguous_Questions_into_Database_Queries.html#appendix",
    "href": "posts/AMBROSIA_A_Benchmark_for_Parsing_Ambiguous_Questions_into_Database_Queries/2024-06-27-AMBROSIA_A_Benchmark_for_Parsing_Ambiguous_Questions_into_Database_Queries.html#appendix",
    "title": "AMBROSIA: A Benchmark for Parsing Ambiguous Questions into Database Queries",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19073v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19073v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20704"
  },
  {
    "objectID": "posts/Large_Language_Models_as_Evaluators_for_Scientific_Synthesis/2024-07-03-Large_Language_Models_as_Evaluators_for_Scientific_Synthesis.html#appendix",
    "href": "posts/Large_Language_Models_as_Evaluators_for_Scientific_Synthesis/2024-07-03-Large_Language_Models_as_Evaluators_for_Scientific_Synthesis.html#appendix",
    "title": "Large Language Models as Evaluators for Scientific Synthesis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02977v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02977v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6836"
  },
  {
    "objectID": "posts/Validating_LLM_Generated_Programs_with_Metamorphic_Prompt_Testing/2024-06-11-Validating_LLM_Generated_Programs_with_Metamorphic_Prompt_Testing.html#appendix",
    "href": "posts/Validating_LLM_Generated_Programs_with_Metamorphic_Prompt_Testing/2024-06-11-Validating_LLM_Generated_Programs_with_Metamorphic_Prompt_Testing.html#appendix",
    "title": "Validating LLM-Generated Programs with Metamorphic Prompt Testing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06864v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06864v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6738"
  },
  {
    "objectID": "posts/On_the_Robustness_of_Language_Models_for_Tabular_Question_Answering/2024-06-18-On_the_Robustness_of_Language_Models_for_Tabular_Question_Answering.html#appendix",
    "href": "posts/On_the_Robustness_of_Language_Models_for_Tabular_Question_Answering/2024-06-18-On_the_Robustness_of_Language_Models_for_Tabular_Question_Answering.html#appendix",
    "title": "On the Robustness of Language Models for Tabular Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12719v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12719v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3509"
  },
  {
    "objectID": "posts/Empowering_1000_tokenssecond_on_device_LLM_prefilling_with_mllm_NPU/2024-07-08-Empowering_1000_tokenssecond_on_device_LLM_prefilling_with_mllm_NPU.html#appendix",
    "href": "posts/Empowering_1000_tokenssecond_on_device_LLM_prefilling_with_mllm_NPU/2024-07-08-Empowering_1000_tokenssecond_on_device_LLM_prefilling_with_mllm_NPU.html#appendix",
    "title": "Empowering 1000 tokens/second on-device LLM prefilling with mllm-NPU",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05858v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05858v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11855"
  },
  {
    "objectID": "posts/A_Survey_of_Backdoor_Attacks_and_Defenses_on_Large_Language_Models_Implications_for_Security_Measures/2024-06-10-A_Survey_of_Backdoor_Attacks_and_Defenses_on_Large_Language_Models_Implications_for_Security_Measures.html#appendix",
    "href": "posts/A_Survey_of_Backdoor_Attacks_and_Defenses_on_Large_Language_Models_Implications_for_Security_Measures/2024-06-10-A_Survey_of_Backdoor_Attacks_and_Defenses_on_Large_Language_Models_Implications_for_Security_Measures.html#appendix",
    "title": "A Survey of Backdoor Attacks and Defenses on Large Language Models: Implications for Security Measures",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06852v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06852v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9560"
  },
  {
    "objectID": "posts/Themis_Towards_Flexible_and_Interpretable_NLG_Evaluation/2024-06-26-Themis_Towards_Flexible_and_Interpretable_NLG_Evaluation.html#appendix",
    "href": "posts/Themis_Towards_Flexible_and_Interpretable_NLG_Evaluation/2024-06-26-Themis_Towards_Flexible_and_Interpretable_NLG_Evaluation.html#appendix",
    "title": "Themis: Towards Flexible and Interpretable NLG Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18365v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18365v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6245"
  },
  {
    "objectID": "posts/Towards_Truthful_Multilingual_Large_Language_Models_Benchmarking_and_Alignment_Strategies/2024-06-20-Towards_Truthful_Multilingual_Large_Language_Models_Benchmarking_and_Alignment_Strategies.html#appendix",
    "href": "posts/Towards_Truthful_Multilingual_Large_Language_Models_Benchmarking_and_Alignment_Strategies/2024-06-20-Towards_Truthful_Multilingual_Large_Language_Models_Benchmarking_and_Alignment_Strategies.html#appendix",
    "title": "Towards Truthful Multilingual Large Language Models: Benchmarking and Alignment Strategies",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14434v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14434v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6080"
  },
  {
    "objectID": "posts/Hierarchical_Context_Pruning_Optimizing_Real_World_Code_Completion_with_Repository_Level_Pretrained_Code_LLMs/2024-06-27-Hierarchical_Context_Pruning_Optimizing_Real_World_Code_Completion_with_Repository_Level_Pretrained_Code_LLMs.html#appendix",
    "href": "posts/Hierarchical_Context_Pruning_Optimizing_Real_World_Code_Completion_with_Repository_Level_Pretrained_Code_LLMs/2024-06-27-Hierarchical_Context_Pruning_Optimizing_Real_World_Code_Completion_with_Repository_Level_Pretrained_Code_LLMs.html#appendix",
    "title": "Hierarchical Context Pruning: Optimizing Real-World Code Completion with Repository-Level Pretrained Code LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18294v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18294v2\n\n\nTruncated\nFalse\n\n\nWord Count\n6374"
  },
  {
    "objectID": "posts/Enhancing_Data_Privacy_in_Large_Language_Models_through_Private_Association_Editing/2024-06-26-Enhancing_Data_Privacy_in_Large_Language_Models_through_Private_Association_Editing.html",
    "href": "posts/Enhancing_Data_Privacy_in_Large_Language_Models_through_Private_Association_Editing/2024-06-26-Enhancing_Data_Privacy_in_Large_Language_Models_through_Private_Association_Editing.html",
    "title": "Enhancing Data Privacy in Large Language Models through Private Association Editing",
    "section": "",
    "text": "Summary:\nThe paper introduces Private Association Editing (PAE), a novel defense approach for private data leakage in Large Language Models (LLMs). PAE is designed to effectively remove Personally Identifiable Information (PII) without retraining the model. The approach consists of a four-step procedure: detecting memorized PII, applying PAE cards to mitigate memorization of private data, verifying resilience to targeted data extraction (TDE) attacks, and ensuring consistency in the post-edit LLMs. The versatility and efficiency of PAE, which allows for batch modifications, significantly enhance data privacy in LLMs. Experimental results demonstrate the effectiveness of PAE in mitigating private data leakage.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/Enhancing_Data_Privacy_in_Large_Language_Models_through_Private_Association_Editing/2024-06-26-Enhancing_Data_Privacy_in_Large_Language_Models_through_Private_Association_Editing.html#appendix",
    "href": "posts/Enhancing_Data_Privacy_in_Large_Language_Models_through_Private_Association_Editing/2024-06-26-Enhancing_Data_Privacy_in_Large_Language_Models_through_Private_Association_Editing.html#appendix",
    "title": "Enhancing Data Privacy in Large Language Models through Private Association Editing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18221v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18221v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7076"
  },
  {
    "objectID": "posts/LLMCloudHunter_Harnessing_LLMs_for_Automated_Extraction_of_Detection_Rules_from_Cloud_Based_CTI/2024-07-06-LLMCloudHunter_Harnessing_LLMs_for_Automated_Extraction_of_Detection_Rules_from_Cloud_Based_CTI.html#appendix",
    "href": "posts/LLMCloudHunter_Harnessing_LLMs_for_Automated_Extraction_of_Detection_Rules_from_Cloud_Based_CTI/2024-07-06-LLMCloudHunter_Harnessing_LLMs_for_Automated_Extraction_of_Detection_Rules_from_Cloud_Based_CTI.html#appendix",
    "title": "LLMCloudHunter: Harnessing LLMs for Automated Extraction of Detection Rules from Cloud-Based CTI",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05194v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05194v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11552"
  },
  {
    "objectID": "posts/Generating_Educational_Materials_with_Different_Levels_of_Readability_using_LLMs/2024-06-18-Generating_Educational_Materials_with_Different_Levels_of_Readability_using_LLMs.html#appendix",
    "href": "posts/Generating_Educational_Materials_with_Different_Levels_of_Readability_using_LLMs/2024-06-18-Generating_Educational_Materials_with_Different_Levels_of_Readability_using_LLMs.html#appendix",
    "title": "Generating Educational Materials with Different Levels of Readability using LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12787v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12787v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5307"
  },
  {
    "objectID": "posts/A_Collaborative_Data_Analytics_System_with_Recommender_for_Diverse_Users/2024-06-17-A_Collaborative_Data_Analytics_System_with_Recommender_for_Diverse_Users.html#appendix",
    "href": "posts/A_Collaborative_Data_Analytics_System_with_Recommender_for_Diverse_Users/2024-06-17-A_Collaborative_Data_Analytics_System_with_Recommender_for_Diverse_Users.html#appendix",
    "title": "A Collaborative Data Analytics System with Recommender for Diverse Users",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11232v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11232v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13618"
  },
  {
    "objectID": "posts/African_or_European_Swallow_Benchmarking_Large_Vision_Language_Models_for_Fine_Grained_Object_Classification/2024-06-20-African_or_European_Swallow_Benchmarking_Large_Vision_Language_Models_for_Fine_Grained_Object_Classification.html#appendix",
    "href": "posts/African_or_European_Swallow_Benchmarking_Large_Vision_Language_Models_for_Fine_Grained_Object_Classification/2024-06-20-African_or_European_Swallow_Benchmarking_Large_Vision_Language_Models_for_Fine_Grained_Object_Classification.html#appendix",
    "title": "African or European Swallow? Benchmarking Large Vision-Language Models for Fine-Grained Object Classification",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14496v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14496v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8786"
  },
  {
    "objectID": "posts/Evaluating_the_Retrieval_Component_in_LLM_Based_Question_Answering_Systems/2024-06-10-Evaluating_the_Retrieval_Component_in_LLM_Based_Question_Answering_Systems.html#appendix",
    "href": "posts/Evaluating_the_Retrieval_Component_in_LLM_Based_Question_Answering_Systems/2024-06-10-Evaluating_the_Retrieval_Component_in_LLM_Based_Question_Answering_Systems.html#appendix",
    "title": "Evaluating the Retrieval Component in LLM-Based Question Answering Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06458v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06458v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4825"
  },
  {
    "objectID": "posts/MAGIC_Generating_Self_Correction_Guideline_for_In_Context_Text_to_SQL/2024-06-18-MAGIC_Generating_Self_Correction_Guideline_for_In_Context_Text_to_SQL.html#appendix",
    "href": "posts/MAGIC_Generating_Self_Correction_Guideline_for_In_Context_Text_to_SQL/2024-06-18-MAGIC_Generating_Self_Correction_Guideline_for_In_Context_Text_to_SQL.html#appendix",
    "title": "MAGIC: Generating Self-Correction Guideline for In-Context Text-to-SQL",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12692v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12692v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7370"
  },
  {
    "objectID": "posts/SeCoKD_Aligning_Large_Language_Models_for_In_Context_Learning_with_Fewer_Shots/2024-06-20-SeCoKD_Aligning_Large_Language_Models_for_In_Context_Learning_with_Fewer_Shots.html#appendix",
    "href": "posts/SeCoKD_Aligning_Large_Language_Models_for_In_Context_Learning_with_Fewer_Shots/2024-06-20-SeCoKD_Aligning_Large_Language_Models_for_In_Context_Learning_with_Fewer_Shots.html#appendix",
    "title": "SeCoKD: Aligning Large Language Models for In-Context Learning with Fewer Shots",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14208v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14208v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6370"
  },
  {
    "objectID": "posts/Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents/2024-06-09-Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents.html",
    "href": "posts/Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents/2024-06-09-Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents.html",
    "title": "Machine Against the RAG: Jamming Retrieval-Augmented Generation with Blocker Documents",
    "section": "",
    "text": "Summary:\nThe paper introduces a new class of denial-of-service vulnerabilities in retrieval-augmented generation (RAG) systems, where a single “blocker” document in the RAG database can cause the system to refuse to answer certain queries. The authors demonstrate this attack against several popular large language models (LLMs) and show that resistance to jamming is a novel LLM-safety property not captured by existing safety and trustworthiness metrics.\nThe authors investigate several methods for generating blocker documents, including a new method based on black-box optimization that does not require knowledge of the embedding or LLM used by the target RAG system. They also discuss the limitations of this method, such as producing blocker documents that have no semantics and can be easily filtered out from RAG databases.\nThe paper concludes with a discussion of future research directions, such as minimizing the number of queries to the target RAG system, generating blocker documents with access to a RAG system whose database is not exactly the same as the target system, and generating passive blocker documents that are difficult to detect or even semantically plausible.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an interesting and novel attack on RAG systems, highlighting a previously unrecognized vulnerability. The authors’ investigation of different methods for generating blocker documents is thorough and well-presented. However, the paper could benefit from a more in-depth discussion of the potential real-world implications of this attack and possible countermeasures. Additionally, the limitations of the black-box optimization method for generating blocker documents should be further explored and addressed."
  },
  {
    "objectID": "posts/Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents/2024-06-09-Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents.html#appendix",
    "href": "posts/Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents/2024-06-09-Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents.html#appendix",
    "title": "Machine Against the RAG: Jamming Retrieval-Augmented Generation with Blocker Documents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05870v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05870v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12156"
  },
  {
    "objectID": "posts/Tools_Fail_Detecting_Silent_Errors_in_Faulty_Tools/2024-06-27-Tools_Fail_Detecting_Silent_Errors_in_Faulty_Tools.html#appendix",
    "href": "posts/Tools_Fail_Detecting_Silent_Errors_in_Faulty_Tools/2024-06-27-Tools_Fail_Detecting_Silent_Errors_in_Faulty_Tools.html#appendix",
    "title": "Tools Fail: Detecting Silent Errors in Faulty Tools",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19228v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19228v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8580"
  },
  {
    "objectID": "posts/Few_shot_Personalization_of_LLMs_with_Mis_aligned_Responses/2024-06-26-Few_shot_Personalization_of_LLMs_with_Mis_aligned_Responses.html#appendix",
    "href": "posts/Few_shot_Personalization_of_LLMs_with_Mis_aligned_Responses/2024-06-26-Few_shot_Personalization_of_LLMs_with_Mis_aligned_Responses.html#appendix",
    "title": "Few-shot Personalization of LLMs with Mis-aligned Responses",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18678v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18678v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11156"
  },
  {
    "objectID": "posts/GenFollower_Enhancing_Car_Following_Prediction_with_Large_Language_Models/2024-07-08-GenFollower_Enhancing_Car_Following_Prediction_with_Large_Language_Models.html#appendix",
    "href": "posts/GenFollower_Enhancing_Car_Following_Prediction_with_Large_Language_Models/2024-07-08-GenFollower_Enhancing_Car_Following_Prediction_with_Large_Language_Models.html#appendix",
    "title": "GenFollower: Enhancing Car-Following Prediction with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05611v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05611v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7041"
  },
  {
    "objectID": "posts/Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated/2024-06-26-Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated.html#major-findings",
    "href": "posts/Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated/2024-06-26-Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated.html#major-findings",
    "title": "Detecting Machine-Generated Texts: Not Just AI vs Humans and Explainability is Complicated",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe study introduces a novel ternary classification system for analyzing texts, adding an “undecided” category to the classification framework. This category recognizes that some texts may simultaneously share characteristics of both machine-generated and human-generated texts.\nThe authors developed a ternary classification dataset and designed experiments to test the validity of this approach. The methodology includes rigorous statistical and model-based analyses and incorporates detailed human evaluations to provide a nuanced understanding of the new ternary text classification task and the complexity of producing human-understandable explanations.\nThe study compares the explanatory power of human assessments with that of automated detectors, highlighting the current explanatory limitations faced by MGT detectors. The results show that the “undecided” category is much needed from the viewpoint of explainability."
  },
  {
    "objectID": "posts/Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated/2024-06-26-Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated.html#analysis-and-critique",
    "href": "posts/Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated/2024-06-26-Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated.html#analysis-and-critique",
    "title": "Detecting Machine-Generated Texts: Not Just AI vs Humans and Explainability is Complicated",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a well-structured and coherent summary of the academic article, effectively communicating the essential information. The major findings are clearly highlighted, and the analysis provides a critical evaluation of the article’s strengths and weaknesses. However, the critique could be more detailed, addressing specific methodological issues, conflicting evidence, or areas that require further research or clarification. Additionally, the summary could benefit from a more concise and focused presentation of the article’s main arguments and contributions.\nIn summary, the paper provides a valuable overview of the challenges and limitations of current methods for detecting machine-generated texts."
  },
  {
    "objectID": "posts/Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated/2024-06-26-Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated.html#appendix",
    "href": "posts/Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated/2024-06-26-Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated.html#appendix",
    "title": "Detecting Machine-Generated Texts: Not Just AI vs Humans and Explainability is Complicated",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18259v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18259v1\n\n\nTruncated\nFalse\n\n\nWord Count\n19402"
  },
  {
    "objectID": "posts/A_Teacher_Is_Worth_A_Million_Instructions/2024-06-27-A_Teacher_Is_Worth_A_Million_Instructions.html#appendix",
    "href": "posts/A_Teacher_Is_Worth_A_Million_Instructions/2024-06-27-A_Teacher_Is_Worth_A_Million_Instructions.html#appendix",
    "title": "A Teacher Is Worth A Million Instructions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19112v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19112v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5345"
  },
  {
    "objectID": "posts/The_Model_Arena_for_Cross_lingual_Sentiment_Analysis_A_Comparative_Study_in_the_Era_of_Large_Language_Models/2024-06-27-The_Model_Arena_for_Cross_lingual_Sentiment_Analysis_A_Comparative_Study_in_the_Era_of_Large_Language_Models.html#appendix",
    "href": "posts/The_Model_Arena_for_Cross_lingual_Sentiment_Analysis_A_Comparative_Study_in_the_Era_of_Large_Language_Models/2024-06-27-The_Model_Arena_for_Cross_lingual_Sentiment_Analysis_A_Comparative_Study_in_the_Era_of_Large_Language_Models.html#appendix",
    "title": "The Model Arena for Cross-lingual Sentiment Analysis: A Comparative Study in the Era of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19358v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19358v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5764"
  },
  {
    "objectID": "posts/CoSQA+_Enhancing_Code_Search_Dataset_with_Matching_Code/2024-06-17-CoSQA+_Enhancing_Code_Search_Dataset_with_Matching_Code.html#appendix",
    "href": "posts/CoSQA+_Enhancing_Code_Search_Dataset_with_Matching_Code/2024-06-17-CoSQA+_Enhancing_Code_Search_Dataset_with_Matching_Code.html#appendix",
    "title": "CoSQA+: Enhancing Code Search Dataset with Matching Code",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11589v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11589v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6587"
  },
  {
    "objectID": "posts/61A_Bot_AI_homework_assistance_in_CS1_is_fast_and_cheap____but_is_it_helpful/2024-06-09-61A_Bot_AI_homework_assistance_in_CS1_is_fast_and_cheap____but_is_it_helpful.html#appendix",
    "href": "posts/61A_Bot_AI_homework_assistance_in_CS1_is_fast_and_cheap____but_is_it_helpful/2024-06-09-61A_Bot_AI_homework_assistance_in_CS1_is_fast_and_cheap____but_is_it_helpful.html#appendix",
    "title": "61A-Bot: AI homework assistance in CS1 is fast and cheap – but is it helpful?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05600v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05600v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7095"
  },
  {
    "objectID": "posts/Navigating_User_Experience_of_ChatGPT_based_Conversational_Recommender_Systems_The_Effects_of_Prompt_Guidance_and_Recommendation_Domain/2024-05-22-Navigating_User_Experience_of_ChatGPT_based_Conversational_Recommender_Systems_The_Effects_of_Prompt_Guidance_and_Recommendation_Domain.html#appendix",
    "href": "posts/Navigating_User_Experience_of_ChatGPT_based_Conversational_Recommender_Systems_The_Effects_of_Prompt_Guidance_and_Recommendation_Domain/2024-05-22-Navigating_User_Experience_of_ChatGPT_based_Conversational_Recommender_Systems_The_Effects_of_Prompt_Guidance_and_Recommendation_Domain.html#appendix",
    "title": "Navigating User Experience of ChatGPT-based Conversational Recommender Systems: The Effects of Prompt Guidance and Recommendation Domain",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.13560v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.13560v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8278"
  },
  {
    "objectID": "posts/Using_LLMs_to_Aid_Annotation_and_Collection_of_Clinically_Enriched_Data_in_Bipolar_Disorder_and_Schizophrenia/2024-06-18-Using_LLMs_to_Aid_Annotation_and_Collection_of_Clinically_Enriched_Data_in_Bipolar_Disorder_and_Schizophrenia.html#appendix",
    "href": "posts/Using_LLMs_to_Aid_Annotation_and_Collection_of_Clinically_Enriched_Data_in_Bipolar_Disorder_and_Schizophrenia/2024-06-18-Using_LLMs_to_Aid_Annotation_and_Collection_of_Clinically_Enriched_Data_in_Bipolar_Disorder_and_Schizophrenia.html#appendix",
    "title": "Using LLMs to Aid Annotation and Collection of Clinically-Enriched Data in Bipolar Disorder and Schizophrenia",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12687v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12687v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5994"
  },
  {
    "objectID": "posts/PlagBench_Exploring_the_Duality_of_Large_Language_Models_in_Plagiarism_Generation_and_Detection/2024-06-24-PlagBench_Exploring_the_Duality_of_Large_Language_Models_in_Plagiarism_Generation_and_Detection.html#appendix",
    "href": "posts/PlagBench_Exploring_the_Duality_of_Large_Language_Models_in_Plagiarism_Generation_and_Detection/2024-06-24-PlagBench_Exploring_the_Duality_of_Large_Language_Models_in_Plagiarism_Generation_and_Detection.html#appendix",
    "title": "PlagBench: Exploring the Duality of Large Language Models in Plagiarism Generation and Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16288v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16288v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8349"
  },
  {
    "objectID": "posts/Agentless_Demystifying_LLM_based_Software_Engineering_Agents/2024-07-01-Agentless_Demystifying_LLM_based_Software_Engineering_Agents.html#appendix",
    "href": "posts/Agentless_Demystifying_LLM_based_Software_Engineering_Agents/2024-07-01-Agentless_Demystifying_LLM_based_Software_Engineering_Agents.html#appendix",
    "title": "Agentless: Demystifying LLM-based Software Engineering Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01489v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01489v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8295"
  },
  {
    "objectID": "posts/Understanding_Different_Design_Choices_in_Training_Large_Time_Series_Models/2024-06-20-Understanding_Different_Design_Choices_in_Training_Large_Time_Series_Models.html#appendix",
    "href": "posts/Understanding_Different_Design_Choices_in_Training_Large_Time_Series_Models/2024-06-20-Understanding_Different_Design_Choices_in_Training_Large_Time_Series_Models.html#appendix",
    "title": "Understanding Different Design Choices in Training Large Time Series Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14045v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14045v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7858"
  },
  {
    "objectID": "posts/Knowledge_Tagging_System_on_Math_Questions_via_LLMs_with_Flexible_Demonstration_Retriever/2024-06-19-Knowledge_Tagging_System_on_Math_Questions_via_LLMs_with_Flexible_Demonstration_Retriever.html#appendix",
    "href": "posts/Knowledge_Tagging_System_on_Math_Questions_via_LLMs_with_Flexible_Demonstration_Retriever/2024-06-19-Knowledge_Tagging_System_on_Math_Questions_via_LLMs_with_Flexible_Demonstration_Retriever.html#appendix",
    "title": "Knowledge Tagging System on Math Questions via LLMs with Flexible Demonstration Retriever",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13885v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13885v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6455"
  },
  {
    "objectID": "posts/Chain_of_Agents_Large_Language_Models_Collaborating_on_Long_Context_Tasks/2024-06-04-Chain_of_Agents_Large_Language_Models_Collaborating_on_Long_Context_Tasks.html#appendix",
    "href": "posts/Chain_of_Agents_Large_Language_Models_Collaborating_on_Long_Context_Tasks/2024-06-04-Chain_of_Agents_Large_Language_Models_Collaborating_on_Long_Context_Tasks.html#appendix",
    "title": "Chain of Agents: Large Language Models Collaborating on Long-Context Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02818v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02818v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6877"
  },
  {
    "objectID": "posts/SOS!_Soft_Prompt_Attack_Against_Open_Source_Large_Language_Models/2024-07-03-SOS!_Soft_Prompt_Attack_Against_Open_Source_Large_Language_Models.html",
    "href": "posts/SOS!_Soft_Prompt_Attack_Against_Open_Source_Large_Language_Models/2024-07-03-SOS!_Soft_Prompt_Attack_Against_Open_Source_Large_Language_Models.html",
    "title": "SOS! Soft Prompt Attack Against Open-Source Large Language Models",
    "section": "",
    "text": "Summary: The paper presents a novel attack called SOS (Soft prompt attack against Open-Source LLMs) that targets open-source large language models (LLMs). SOS is designed to be computationally efficient and does not require clean data or modification of the model weights, ensuring the model’s utility remains intact. The attack addresses security issues in various scenarios, including backdoor attacks, jailbreak attacks, and prompt stealing attacks. The authors demonstrate the effectiveness of SOS across all evaluated targets and present a novel technique called the copyright token, which enables users to mark their copyrighted content and prevent models from using it.\nKey Terms:\nMajor Findings:"
  },
  {
    "objectID": "posts/SOS!_Soft_Prompt_Attack_Against_Open_Source_Large_Language_Models/2024-07-03-SOS!_Soft_Prompt_Attack_Against_Open_Source_Large_Language_Models.html#appendix",
    "href": "posts/SOS!_Soft_Prompt_Attack_Against_Open_Source_Large_Language_Models/2024-07-03-SOS!_Soft_Prompt_Attack_Against_Open_Source_Large_Language_Models.html#appendix",
    "title": "SOS! Soft Prompt Attack Against Open-Source Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03160v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03160v1\n\n\nTruncated\nTrue\n\n\nWord Count\n28326"
  },
  {
    "objectID": "posts/Machine_Unlearning_Fails_to_Remove_Data_Poisoning_Attacks/2024-06-25-Machine_Unlearning_Fails_to_Remove_Data_Poisoning_Attacks.html#appendix",
    "href": "posts/Machine_Unlearning_Fails_to_Remove_Data_Poisoning_Attacks/2024-06-25-Machine_Unlearning_Fails_to_Remove_Data_Poisoning_Attacks.html#appendix",
    "title": "Machine Unlearning Fails to Remove Data Poisoning Attacks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17216v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17216v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15361"
  },
  {
    "objectID": "posts/What_Affects_the_Stability_of_Tool_Learning_An_Empirical_Study_on_the_Robustness_of_Tool_Learning_Frameworks/2024-07-03-What_Affects_the_Stability_of_Tool_Learning_An_Empirical_Study_on_the_Robustness_of_Tool_Learning_Frameworks.html#appendix",
    "href": "posts/What_Affects_the_Stability_of_Tool_Learning_An_Empirical_Study_on_the_Robustness_of_Tool_Learning_Frameworks/2024-07-03-What_Affects_the_Stability_of_Tool_Learning_An_Empirical_Study_on_the_Robustness_of_Tool_Learning_Frameworks.html#appendix",
    "title": "What Affects the Stability of Tool Learning? An Empirical Study on the Robustness of Tool Learning Frameworks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03007v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03007v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2525"
  },
  {
    "objectID": "posts/Enhancing_LLM_Based_Human_Robot_Interaction_with_Nuances_for_Diversity_Awareness/2024-06-25-Enhancing_LLM_Based_Human_Robot_Interaction_with_Nuances_for_Diversity_Awareness.html#appendix",
    "href": "posts/Enhancing_LLM_Based_Human_Robot_Interaction_with_Nuances_for_Diversity_Awareness/2024-06-25-Enhancing_LLM_Based_Human_Robot_Interaction_with_Nuances_for_Diversity_Awareness.html#appendix",
    "title": "Enhancing LLM-Based Human-Robot Interaction with Nuances for Diversity Awareness",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17531v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17531v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7209"
  },
  {
    "objectID": "posts/Annotation_alignment_Comparing_LLM_and_human_annotations_of_conversational_safety/2024-06-10-Annotation_alignment_Comparing_LLM_and_human_annotations_of_conversational_safety.html#appendix",
    "href": "posts/Annotation_alignment_Comparing_LLM_and_human_annotations_of_conversational_safety/2024-06-10-Annotation_alignment_Comparing_LLM_and_human_annotations_of_conversational_safety.html#appendix",
    "title": "Annotation alignment: Comparing LLM and human annotations of conversational safety",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06369v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06369v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7965"
  },
  {
    "objectID": "posts/Sub_SA_Strengthen_In_context_Learning_via_Submodular_Selective_Annotation/2024-07-08-Sub_SA_Strengthen_In_context_Learning_via_Submodular_Selective_Annotation.html#appendix",
    "href": "posts/Sub_SA_Strengthen_In_context_Learning_via_Submodular_Selective_Annotation/2024-07-08-Sub_SA_Strengthen_In_context_Learning_via_Submodular_Selective_Annotation.html#appendix",
    "title": "Sub-SA: Strengthen In-context Learning via Submodular Selective Annotation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05693v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05693v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6160"
  },
  {
    "objectID": "posts/Symbolic_Learning_Enables_Self_Evolving_Agents/2024-06-26-Symbolic_Learning_Enables_Self_Evolving_Agents.html#appendix",
    "href": "posts/Symbolic_Learning_Enables_Self_Evolving_Agents/2024-06-26-Symbolic_Learning_Enables_Self_Evolving_Agents.html#appendix",
    "title": "Symbolic Learning Enables Self-Evolving Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18532v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18532v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6153"
  },
  {
    "objectID": "posts/A_Comprehensive_Evaluation_of_Parameter_Efficient_Fine_Tuning_on_Automated_Program_Repair/2024-06-09-A_Comprehensive_Evaluation_of_Parameter_Efficient_Fine_Tuning_on_Automated_Program_Repair.html#appendix",
    "href": "posts/A_Comprehensive_Evaluation_of_Parameter_Efficient_Fine_Tuning_on_Automated_Program_Repair/2024-06-09-A_Comprehensive_Evaluation_of_Parameter_Efficient_Fine_Tuning_on_Automated_Program_Repair.html#appendix",
    "title": "A Comprehensive Evaluation of Parameter-Efficient Fine-Tuning on Automated Program Repair",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05639v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05639v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12423"
  },
  {
    "objectID": "posts/FFN_a_Fine_grained_Chinese_English_Financial_Domain_Parallel_Corpus/2024-06-27-FFN_a_Fine_grained_Chinese_English_Financial_Domain_Parallel_Corpus.html#appendix",
    "href": "posts/FFN_a_Fine_grained_Chinese_English_Financial_Domain_Parallel_Corpus/2024-06-27-FFN_a_Fine_grained_Chinese_English_Financial_Domain_Parallel_Corpus.html#appendix",
    "title": "FFN: a Fine-grained Chinese-English Financial Domain Parallel Corpus",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18856v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18856v1\n\n\nTruncated\nFalse\n\n\nWord Count\n848"
  },
  {
    "objectID": "posts/Improving_Weak_to_Strong_Generalization_with_Reliability_Aware_Alignment/2024-06-27-Improving_Weak_to_Strong_Generalization_with_Reliability_Aware_Alignment.html",
    "href": "posts/Improving_Weak_to_Strong_Generalization_with_Reliability_Aware_Alignment/2024-06-27-Improving_Weak_to_Strong_Generalization_with_Reliability_Aware_Alignment.html",
    "title": "Improving Weak-to-Strong Generalization with Reliability-Aware Alignment",
    "section": "",
    "text": "Summary: The paper addresses the challenge of aligning strong language models with weak supervision signals, focusing on the “super-alignment” problem of aligning super-human language models with human knowledge. The authors propose an unsupervised method to enhance weak-to-strong generalization through reliability-aware alignment. This involves generating prompt variations, assessing the reliability of responses using entropy-based uncertainty and probability-based reliability metrics, and applying reliability-aware techniques such as uncertainty filtering and reliability re-weighting during the alignment process. Experimental results on four datasets demonstrated that the proposed methods effectively identified high-quality weak labels and significantly improved alignment robustness compared to baseline approaches.\nMajor Findings: 1. The proposed unsupervised method for enhancing weak-to-strong generalization through reliability-aware alignment effectively identifies high-quality weak labels and significantly improves alignment robustness compared to baseline approaches. 2. The method involves generating prompt variations, assessing the reliability of responses using entropy-based uncertainty and probability-based reliability metrics, and applying reliability-aware techniques such as uncertainty filtering and reliability re-weighting during the alignment process. 3. Experimental results on four datasets demonstrated the effectiveness of the proposed methods in improving weak-to-strong generalization.\nAnalysis and Critique: 1. The proposed method introduces significant computational overhead due to querying the weak supervisor multiple times and performing additional computations for uncertainty filtering and reliability re-weighting. This could limit the scalability of the approach, especially when dealing with large-scale datasets or complex models. 2. The overall performance of the method heavily relies on the quality of the weak supervisor. If the weak supervisor consistently provides highly unreliable or incorrect labels, the effectiveness of the reliability-aware methods may diminish. 3. The inherent subjectivity and variability in human-generated labels could introduce challenges not fully addressed by the current reliability estimation techniques. Further research is needed to tailor the methods specifically for human-annotated data, considering factors like annotator bias and expertise."
  },
  {
    "objectID": "posts/Improving_Weak_to_Strong_Generalization_with_Reliability_Aware_Alignment/2024-06-27-Improving_Weak_to_Strong_Generalization_with_Reliability_Aware_Alignment.html#appendix",
    "href": "posts/Improving_Weak_to_Strong_Generalization_with_Reliability_Aware_Alignment/2024-06-27-Improving_Weak_to_Strong_Generalization_with_Reliability_Aware_Alignment.html#appendix",
    "title": "Improving Weak-to-Strong Generalization with Reliability-Aware Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19032v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19032v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6944"
  },
  {
    "objectID": "posts/Seeing_Through_AIs_Lens_Enhancing_Human_Skepticism_Towards_LLM_Generated_Fake_News/2024-06-20-Seeing_Through_AIs_Lens_Enhancing_Human_Skepticism_Towards_LLM_Generated_Fake_News.html#appendix",
    "href": "posts/Seeing_Through_AIs_Lens_Enhancing_Human_Skepticism_Towards_LLM_Generated_Fake_News/2024-06-20-Seeing_Through_AIs_Lens_Enhancing_Human_Skepticism_Towards_LLM_Generated_Fake_News.html#appendix",
    "title": "Seeing Through AI’s Lens: Enhancing Human Skepticism Towards LLM-Generated Fake News",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14012v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14012v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7336"
  },
  {
    "objectID": "posts/A_Critical_Study_of_What_Code_LLMs_(Do_Not)_Learn/2024-06-17-A_Critical_Study_of_What_Code_LLMs_(Do_Not)_Learn.html#appendix",
    "href": "posts/A_Critical_Study_of_What_Code_LLMs_(Do_Not)_Learn/2024-06-17-A_Critical_Study_of_What_Code_LLMs_(Do_Not)_Learn.html#appendix",
    "title": "A Critical Study of What Code-LLMs (Do Not) Learn",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11930v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11930v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10566"
  },
  {
    "objectID": "posts/Raccoon_Prompt_Extraction_Benchmark_of_LLM_Integrated_Applications/2024-06-10-Raccoon_Prompt_Extraction_Benchmark_of_LLM_Integrated_Applications.html#appendix",
    "href": "posts/Raccoon_Prompt_Extraction_Benchmark_of_LLM_Integrated_Applications/2024-06-10-Raccoon_Prompt_Extraction_Benchmark_of_LLM_Integrated_Applications.html#appendix",
    "title": "Raccoon: Prompt Extraction Benchmark of LLM-Integrated Applications",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06737v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06737v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6069"
  },
  {
    "objectID": "posts/Translating_Across_Cultures_LLMs_for_Intralingual_Cultural_Adaptation/2024-06-20-Translating_Across_Cultures_LLMs_for_Intralingual_Cultural_Adaptation.html#appendix",
    "href": "posts/Translating_Across_Cultures_LLMs_for_Intralingual_Cultural_Adaptation/2024-06-20-Translating_Across_Cultures_LLMs_for_Intralingual_Cultural_Adaptation.html#appendix",
    "title": "Translating Across Cultures: LLMs for Intralingual Cultural Adaptation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14504v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14504v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7296"
  },
  {
    "objectID": "posts/LoRA_Guard_Parameter_Efficient_Guardrail_Adaptation_for_Content_Moderation_of_Large_Language_Models/2024-07-03-LoRA_Guard_Parameter_Efficient_Guardrail_Adaptation_for_Content_Moderation_of_Large_Language_Models.html#appendix",
    "href": "posts/LoRA_Guard_Parameter_Efficient_Guardrail_Adaptation_for_Content_Moderation_of_Large_Language_Models/2024-07-03-LoRA_Guard_Parameter_Efficient_Guardrail_Adaptation_for_Content_Moderation_of_Large_Language_Models.html#appendix",
    "title": "LoRA-Guard: Parameter-Efficient Guardrail Adaptation for Content Moderation of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02987v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02987v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10286"
  },
  {
    "objectID": "posts/Large_Language_Models_Assume_People_are_More_Rational_than_We_Really_are/2024-06-24-Large_Language_Models_Assume_People_are_More_Rational_than_We_Really_are.html#appendix",
    "href": "posts/Large_Language_Models_Assume_People_are_More_Rational_than_We_Really_are/2024-06-24-Large_Language_Models_Assume_People_are_More_Rational_than_We_Really_are.html#appendix",
    "title": "Large Language Models Assume People are More Rational than We Really are",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17055v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17055v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9964"
  },
  {
    "objectID": "posts/M2CVD_Multi_Model_Collaboration_for_Code_Vulnerability_Detection/2024-06-10-M2CVD_Multi_Model_Collaboration_for_Code_Vulnerability_Detection.html#appendix",
    "href": "posts/M2CVD_Multi_Model_Collaboration_for_Code_Vulnerability_Detection/2024-06-10-M2CVD_Multi_Model_Collaboration_for_Code_Vulnerability_Detection.html#appendix",
    "title": "M2CVD: Multi-Model Collaboration for Code Vulnerability Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05940v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05940v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9185"
  },
  {
    "objectID": "posts/VersiCode_Towards_Version_controllable_Code_Generation/2024-06-11-VersiCode_Towards_Version_controllable_Code_Generation.html#appendix",
    "href": "posts/VersiCode_Towards_Version_controllable_Code_Generation/2024-06-11-VersiCode_Towards_Version_controllable_Code_Generation.html#appendix",
    "title": "VersiCode: Towards Version-controllable Code Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07411v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07411v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6957"
  },
  {
    "objectID": "posts/Safety_Alignment_Should_Be_Made_More_Than_Just_a_Few_Tokens_Deep/2024-06-10-Safety_Alignment_Should_Be_Made_More_Than_Just_a_Few_Tokens_Deep.html#appendix",
    "href": "posts/Safety_Alignment_Should_Be_Made_More_Than_Just_a_Few_Tokens_Deep/2024-06-10-Safety_Alignment_Should_Be_Made_More_Than_Just_a_Few_Tokens_Deep.html#appendix",
    "title": "Safety Alignment Should Be Made More Than Just a Few Tokens Deep",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05946v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05946v1\n\n\nTruncated\nFalse\n\n\nWord Count\n16740"
  },
  {
    "objectID": "posts/On_Speeding_Up_Language_Model_Evaluation/2024-07-08-On_Speeding_Up_Language_Model_Evaluation.html#major-findings",
    "href": "posts/On_Speeding_Up_Language_Model_Evaluation/2024-07-08-On_Speeding_Up_Language_Model_Evaluation.html#major-findings",
    "title": "On Speeding Up Language Model Evaluation",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe proposed algorithms, UCB-E and UCB-E-LRF, can identify the top-performing method using only 5-15% of the typically needed resources, resulting in an 85-95% reduction in cost.\nThe UCB-E algorithm enjoys a theoretical guarantee that the chance of selecting the best arm converges to 100% by an exponential decay of the number of evaluations.\nThe UCB-E-LRF algorithm leverages the intrinsic low-rankness of the scoring matrices, which can be well-approximated by a low-rank matrix, to predict the remaining unobserved method-example pairs and prioritize evaluations of the pairs with large uncertainties in this prediction."
  },
  {
    "objectID": "posts/On_Speeding_Up_Language_Model_Evaluation/2024-07-08-On_Speeding_Up_Language_Model_Evaluation.html#analysis-and-critique",
    "href": "posts/On_Speeding_Up_Language_Model_Evaluation/2024-07-08-On_Speeding_Up_Language_Model_Evaluation.html#analysis-and-critique",
    "title": "On Speeding Up Language Model Evaluation",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a novel approach to reducing the cost of evaluating methods on test examples in the context of LLMs. The proposed algorithms, UCB-E and UCB-E-LRF, offer significant improvements over traditional methods, reducing the required resources by up to 95%. However, the paper does not discuss the potential limitations or biases of the proposed approach, such as the impact of the choice of low-rank factorization or the potential for overfitting to the training data. Additionally, the paper does not provide a comparison with other state-of-the-art methods for reducing the cost of evaluating LLMs. Further research is needed to evaluate the proposed approach in a broader context and to address potential limitations and biases."
  },
  {
    "objectID": "posts/On_Speeding_Up_Language_Model_Evaluation/2024-07-08-On_Speeding_Up_Language_Model_Evaluation.html#appendix",
    "href": "posts/On_Speeding_Up_Language_Model_Evaluation/2024-07-08-On_Speeding_Up_Language_Model_Evaluation.html#appendix",
    "title": "On Speeding Up Language Model Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06172v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06172v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9151"
  },
  {
    "objectID": "posts/The_Remarkable_Robustness_of_LLMs_Stages_of_Inference/2024-06-27-The_Remarkable_Robustness_of_LLMs_Stages_of_Inference.html#appendix",
    "href": "posts/The_Remarkable_Robustness_of_LLMs_Stages_of_Inference/2024-06-27-The_Remarkable_Robustness_of_LLMs_Stages_of_Inference.html#appendix",
    "title": "The Remarkable Robustness of LLMs: Stages of Inference?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19384v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19384v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8310"
  },
  {
    "objectID": "posts/Should_We_Fine_Tune_or_RAG_Evaluating_Different_Techniques_to_Adapt_LLMs_for_Dialogue/2024-06-10-Should_We_Fine_Tune_or_RAG_Evaluating_Different_Techniques_to_Adapt_LLMs_for_Dialogue.html#appendix",
    "href": "posts/Should_We_Fine_Tune_or_RAG_Evaluating_Different_Techniques_to_Adapt_LLMs_for_Dialogue/2024-06-10-Should_We_Fine_Tune_or_RAG_Evaluating_Different_Techniques_to_Adapt_LLMs_for_Dialogue.html#appendix",
    "title": "Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06399v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06399v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3367"
  },
  {
    "objectID": "posts/CoSafe_Evaluating_Large_Language_Model_Safety_in_Multi_Turn_Dialogue_Coreference/2024-06-25-CoSafe_Evaluating_Large_Language_Model_Safety_in_Multi_Turn_Dialogue_Coreference.html#appendix",
    "href": "posts/CoSafe_Evaluating_Large_Language_Model_Safety_in_Multi_Turn_Dialogue_Coreference/2024-06-25-CoSafe_Evaluating_Large_Language_Model_Safety_in_Multi_Turn_Dialogue_Coreference.html#appendix",
    "title": "CoSafe: Evaluating Large Language Model Safety in Multi-Turn Dialogue Coreference",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17626v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17626v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14149"
  },
  {
    "objectID": "posts/Towards_Human_AI_Collaboration_in_Healthcare_Guided_Deferral_Systems_with_Large_Language_Models/2024-06-11-Towards_Human_AI_Collaboration_in_Healthcare_Guided_Deferral_Systems_with_Large_Language_Models.html#appendix",
    "href": "posts/Towards_Human_AI_Collaboration_in_Healthcare_Guided_Deferral_Systems_with_Large_Language_Models/2024-06-11-Towards_Human_AI_Collaboration_in_Healthcare_Guided_Deferral_Systems_with_Large_Language_Models.html#appendix",
    "title": "Towards Human-AI Collaboration in Healthcare: Guided Deferral Systems with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07212v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07212v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4804"
  },
  {
    "objectID": "posts/CrowdMoGen_Zero_Shot_Text_Driven_Collective_Motion_Generation/2024-07-08-CrowdMoGen_Zero_Shot_Text_Driven_Collective_Motion_Generation.html#appendix",
    "href": "posts/CrowdMoGen_Zero_Shot_Text_Driven_Collective_Motion_Generation/2024-07-08-CrowdMoGen_Zero_Shot_Text_Driven_Collective_Motion_Generation.html#appendix",
    "title": "CrowdMoGen: Zero-Shot Text-Driven Collective Motion Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06188v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06188v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6649"
  },
  {
    "objectID": "posts/Fine_Tuning_with_Divergent_Chains_of_Thought_Boosts_Reasoning_Through_Self_Correction_in_Language_Models/2024-07-03-Fine_Tuning_with_Divergent_Chains_of_Thought_Boosts_Reasoning_Through_Self_Correction_in_Language_Models.html#appendix",
    "href": "posts/Fine_Tuning_with_Divergent_Chains_of_Thought_Boosts_Reasoning_Through_Self_Correction_in_Language_Models/2024-07-03-Fine_Tuning_with_Divergent_Chains_of_Thought_Boosts_Reasoning_Through_Self_Correction_in_Language_Models.html#appendix",
    "title": "Fine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03181v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03181v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8440"
  },
  {
    "objectID": "posts/ObfuscaTune_Obfuscated_Offsite_Fine_tuning_and_Inference_of_Proprietary_LLMs_on_Private_Datasets/2024-07-03-ObfuscaTune_Obfuscated_Offsite_Fine_tuning_and_Inference_of_Proprietary_LLMs_on_Private_Datasets.html#appendix",
    "href": "posts/ObfuscaTune_Obfuscated_Offsite_Fine_tuning_and_Inference_of_Proprietary_LLMs_on_Private_Datasets/2024-07-03-ObfuscaTune_Obfuscated_Offsite_Fine_tuning_and_Inference_of_Proprietary_LLMs_on_Private_Datasets.html#appendix",
    "title": "ObfuscaTune: Obfuscated Offsite Fine-tuning and Inference of Proprietary LLMs on Private Datasets",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02960v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02960v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4546"
  },
  {
    "objectID": "posts/The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts/2024-06-20-The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts.html",
    "href": "posts/The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts/2024-06-20-The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts.html",
    "title": "The Fire Thief Is Also the Keeper: Balancing Usability and Privacy in Prompts",
    "section": "",
    "text": "Summary:\nThe paper introduces Prompt Privacy Sanitizer (ProSan), an end-to-end framework for prompt privacy protection that balances usability and privacy. ProSan generates anonymized prompts by removing contextual privacy while maintaining task usability and human readability. It can be seamlessly integrated into the online LLM service pipeline. ProSan dynamically adjusts its protection targets and strength based on the importance of words and the privacy leakage risk of prompts. It is also capable of adapting to diverse computational resource conditions, ensuring privacy protection even for mobile devices with limited computing power.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a promising approach to addressing the issue of privacy leaks in prompts. However, it does not provide a comprehensive evaluation of the framework’s performance across a wide range of tasks and datasets. Additionally, the paper does not discuss potential limitations or biases in the framework, such as the reliance on self-information for measuring privacy risk, which may not fully capture the complexity of privacy in natural language. Further research is needed to evaluate the framework’s robustness and generalizability, as well as to explore alternative methods for measuring privacy risk."
  },
  {
    "objectID": "posts/The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts/2024-06-20-The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts.html#appendix",
    "href": "posts/The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts/2024-06-20-The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts.html#appendix",
    "title": "The Fire Thief Is Also the Keeper: Balancing Usability and Privacy in Prompts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14318v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14318v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11663"
  },
  {
    "objectID": "posts/Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents/2024-06-10-Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents.html",
    "href": "posts/Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents/2024-06-10-Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents.html",
    "title": "Transforming Wearable Data into Health Insights using Large Language Model Agents",
    "section": "",
    "text": "Summary: The paper presents a study on the Personal Health Insights Agent (PHIA), an AI model designed to answer personal health queries using wearable data. PHIA outperforms the Code Generation baseline by 14% (84% vs. 74%) in exact matching accuracy for objective personal health queries. In open-ended reasoning quality, PHIA demonstrates a significant advantage over the Code Generation baseline in all ratings except for personalization. Expert evaluation shows that PHIA has a significant advantage over the Code Generation baseline in overall code quality, avoiding hallucinations, and personalization. PHIA is also quantitatively less likely to generate code that raises an error.\nMajor Findings: 1. PHIA outperforms the Code Generation baseline by 14% in exact matching accuracy for objective personal health queries. 2. PHIA demonstrates a significant advantage over the Code Generation baseline in open-ended reasoning quality."
  },
  {
    "objectID": "posts/Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents/2024-06-10-Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents.html#appendix",
    "href": "posts/Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents/2024-06-10-Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents.html#appendix",
    "title": "Transforming Wearable Data into Health Insights using Large Language Model Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06464v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06464v1\n\n\nTruncated\nTrue\n\n\nWord Count\n28809"
  },
  {
    "objectID": "posts/Let_the_Code_LLM_Edit_Itself_When_You_Edit_the_Code/2024-07-03-Let_the_Code_LLM_Edit_Itself_When_You_Edit_the_Code.html#appendix",
    "href": "posts/Let_the_Code_LLM_Edit_Itself_When_You_Edit_the_Code/2024-07-03-Let_the_Code_LLM_Edit_Itself_When_You_Edit_the_Code.html#appendix",
    "title": "Let the Code LLM Edit Itself When You Edit the Code",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03157v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03157v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6193"
  },
  {
    "objectID": "posts/Enhancing_Tool_Retrieval_with_Iterative_Feedback_from_Large_Language_Models/2024-06-25-Enhancing_Tool_Retrieval_with_Iterative_Feedback_from_Large_Language_Models.html#appendix",
    "href": "posts/Enhancing_Tool_Retrieval_with_Iterative_Feedback_from_Large_Language_Models/2024-06-25-Enhancing_Tool_Retrieval_with_Iterative_Feedback_from_Large_Language_Models.html#appendix",
    "title": "Enhancing Tool Retrieval with Iterative Feedback from Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17465v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17465v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5575"
  },
  {
    "objectID": "posts/Item_Language_Model_for_Conversational_Recommendation/2024-06-05-Item_Language_Model_for_Conversational_Recommendation.html#appendix",
    "href": "posts/Item_Language_Model_for_Conversational_Recommendation/2024-06-05-Item_Language_Model_for_Conversational_Recommendation.html#appendix",
    "title": "Item-Language Model for Conversational Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02844v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02844v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6105"
  },
  {
    "objectID": "posts/Self_assessment_Exhibition_and_Recognition_a_Review_of_Personality_in_Large_Language_Models/2024-06-25-Self_assessment_Exhibition_and_Recognition_a_Review_of_Personality_in_Large_Language_Models.html#appendix",
    "href": "posts/Self_assessment_Exhibition_and_Recognition_a_Review_of_Personality_in_Large_Language_Models/2024-06-25-Self_assessment_Exhibition_and_Recognition_a_Review_of_Personality_in_Large_Language_Models.html#appendix",
    "title": "Self-assessment, Exhibition, and Recognition: a Review of Personality in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17624v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17624v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9841"
  },
  {
    "objectID": "posts/WildGuard_Open_One_Stop_Moderation_Tools_for_Safety_Risks_Jailbreaks_and_Refusals_of_LLMs/2024-06-26-WildGuard_Open_One_Stop_Moderation_Tools_for_Safety_Risks_Jailbreaks_and_Refusals_of_LLMs.html#appendix",
    "href": "posts/WildGuard_Open_One_Stop_Moderation_Tools_for_Safety_Risks_Jailbreaks_and_Refusals_of_LLMs/2024-06-26-WildGuard_Open_One_Stop_Moderation_Tools_for_Safety_Risks_Jailbreaks_and_Refusals_of_LLMs.html#appendix",
    "title": "WildGuard: Open One-Stop Moderation Tools for Safety Risks, Jailbreaks, and Refusals of LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18495v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18495v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13217"
  },
  {
    "objectID": "posts/Merging_Improves_Self_Critique_Against_Jailbreak_Attacks/2024-06-11-Merging_Improves_Self_Critique_Against_Jailbreak_Attacks.html#appendix",
    "href": "posts/Merging_Improves_Self_Critique_Against_Jailbreak_Attacks/2024-06-11-Merging_Improves_Self_Critique_Against_Jailbreak_Attacks.html#appendix",
    "title": "Merging Improves Self-Critique Against Jailbreak Attacks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07188v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07188v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3164"
  },
  {
    "objectID": "posts/HuatuoGPT_Vision_Towards_Injecting_Medical_Visual_Knowledge_into_Multimodal_LLMs_at_Scale/2024-06-27-HuatuoGPT_Vision_Towards_Injecting_Medical_Visual_Knowledge_into_Multimodal_LLMs_at_Scale.html#appendix",
    "href": "posts/HuatuoGPT_Vision_Towards_Injecting_Medical_Visual_Knowledge_into_Multimodal_LLMs_at_Scale/2024-06-27-HuatuoGPT_Vision_Towards_Injecting_Medical_Visual_Knowledge_into_Multimodal_LLMs_at_Scale.html#appendix",
    "title": "HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19280v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19280v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6836"
  },
  {
    "objectID": "posts/Progressive_Query_Expansion_for_Retrieval_Over_Cost_constrained_Data_Sources/2024-06-11-Progressive_Query_Expansion_for_Retrieval_Over_Cost_constrained_Data_Sources.html#appendix",
    "href": "posts/Progressive_Query_Expansion_for_Retrieval_Over_Cost_constrained_Data_Sources/2024-06-11-Progressive_Query_Expansion_for_Retrieval_Over_Cost_constrained_Data_Sources.html#appendix",
    "title": "Progressive Query Expansion for Retrieval Over Cost-constrained Data Sources",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07136v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07136v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4716"
  },
  {
    "objectID": "posts/USDC_A_Dataset_of_User_Stance_and_Dogmatism_in_Long_Conversations/2024-06-24-USDC_A_Dataset_of_User_Stance_and_Dogmatism_in_Long_Conversations.html#appendix",
    "href": "posts/USDC_A_Dataset_of_User_Stance_and_Dogmatism_in_Long_Conversations/2024-06-24-USDC_A_Dataset_of_User_Stance_and_Dogmatism_in_Long_Conversations.html#appendix",
    "title": "USDC: A Dataset of User Stance and Dogmatism in Long Conversations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16833v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16833v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9875"
  },
  {
    "objectID": "posts/Chain_of_Probe_Examing_the_Necessity_and_Accuracy_of_CoT_Step_by_Step/2024-06-23-Chain_of_Probe_Examing_the_Necessity_and_Accuracy_of_CoT_Step_by_Step.html",
    "href": "posts/Chain_of_Probe_Examing_the_Necessity_and_Accuracy_of_CoT_Step_by_Step/2024-06-23-Chain_of_Probe_Examing_the_Necessity_and_Accuracy_of_CoT_Step_by_Step.html",
    "title": "Chain-of-Probe: Examing the Necessity and Accuracy of CoT Step-by-Step",
    "section": "",
    "text": "Summary:\nThe paper proposes a method called Chain-of-Probe (CoP) to examine the necessity and accuracy of Chain-of-Thought (CoT) in large language models (LLMs). The authors address the issue of early answering, where LLMs already have an answer before generating the CoT, and investigate the underlying causes of this phenomenon. The study reveals that early answering is linked to question difficulty, with models tending to predict answers in advance for simpler questions, making CoT unnecessary for simple tasks. The authors propose the CoP Score to evaluate and select CoTs, aiming for more positive improvements.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a novel method, CoP, to detect changes in model thoughts and addresses the issue of early answering in LLMs. However, the study has some limitations. First, CoP currently only applies to multiple-choice questions or questions where the answer is a single token, making it challenging to define the model’s confidence in the final prediction when the target word exceeds one token. Second, regarding the necessity of CoT, it is difficult to determine in advance whether a task is simple, making it impossible to pre-judge whether CoT is needed for a particular question. Lastly, concerning the accuracy of CoT, the CoP Tree has high precision but relatively low recall, leading to an increase in the number of samples needed.\nThe paper also raises ethical concerns regarding the use of GPT-4 as an evaluator. While the authors prioritize transparency, accountability, and mitigation of potential biases, the limitations of AI should be acknowledged, and it should supplement rather than replace human judgment.\nOverall, the paper provides valuable insights into the necessity and accuracy of CoT in LLMs and proposes a novel method to address the issue of early answering. However, further research is needed to overcome the limitations and ethical concerns raised in the study."
  },
  {
    "objectID": "posts/Chain_of_Probe_Examing_the_Necessity_and_Accuracy_of_CoT_Step_by_Step/2024-06-23-Chain_of_Probe_Examing_the_Necessity_and_Accuracy_of_CoT_Step_by_Step.html#appendix",
    "href": "posts/Chain_of_Probe_Examing_the_Necessity_and_Accuracy_of_CoT_Step_by_Step/2024-06-23-Chain_of_Probe_Examing_the_Necessity_and_Accuracy_of_CoT_Step_by_Step.html#appendix",
    "title": "Chain-of-Probe: Examing the Necessity and Accuracy of CoT Step-by-Step",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16144v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16144v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6521"
  },
  {
    "objectID": "posts/MPCODER_Multi_user_Personalized_Code_Generator_with_Explicit_and_Implicit_Style_Representation_Learning/2024-06-25-MPCODER_Multi_user_Personalized_Code_Generator_with_Explicit_and_Implicit_Style_Representation_Learning.html#appendix",
    "href": "posts/MPCODER_Multi_user_Personalized_Code_Generator_with_Explicit_and_Implicit_Style_Representation_Learning/2024-06-25-MPCODER_Multi_user_Personalized_Code_Generator_with_Explicit_and_Implicit_Style_Representation_Learning.html#appendix",
    "title": "MPCODER: Multi-user Personalized Code Generator with Explicit and Implicit Style Representation Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17255v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17255v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8886"
  },
  {
    "objectID": "posts/MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models/2024-06-20-MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models.html#major-findings",
    "href": "posts/MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models/2024-06-20-MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models.html#major-findings",
    "title": "MR-BEN: A Comprehensive Meta-Reasoning Benchmark for Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nMr-Ben is a comprehensive benchmark that employs a meta-reasoning paradigm, where LLMs are challenged to reason about different forms of reasoning. This paradigm involves LLMs acting as teachers, evaluating the reasoning process by assessing correctness, analyzing potential errors, and providing corrections.\nThe analyses of various LLMs on Mr-Ben reveal distinct limitations and previously unidentified weaknesses in their reasoning abilities. While many LLMs can generate the correct answer to a question, they struggle to pinpoint errors in the reasoning process and correct them. This suggests that existing LLMs have yet to master reasoning, particularly the smaller models.\nTechniques such as the use of high-quality synthetic data can significantly improve reasoning abilities, offering a potential pathway to enhance performance regardless of model size. However, different LLMs excel in different reasoning paradigms, challenging the assumption that domain-specific enhancements necessarily lead to broad cognitive improvements."
  },
  {
    "objectID": "posts/MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models/2024-06-20-MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models/2024-06-20-MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models.html#analysis-and-critique",
    "title": "MR-BEN: A Comprehensive Meta-Reasoning Benchmark for Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nWhile Mr-Ben provides a comprehensive evaluation of LLMs’ reasoning abilities, it has some limitations. The benchmark’s applicability may be restricted when it comes to subjects that are inherently holistic or creative in nature, such as humanities or sociology. Additionally, Mr-Ben is currently confined to questions in English, which could potentially limit the scope of reasoning challenges that can be explored. Furthermore, the analysis and correction of errors in the reasoning steps are currently based on solutions generated by three LLMs, which may not represent the diverse reasoning and error patterns of different LLMs and individuals.\nMoreover, the benchmark may present potential negative societal impacts, such as the risk of LLMs being misused or used maliciously. For instance, LLMs with advanced reasoning capabilities could be used to manipulate information or deceive people. The use"
  },
  {
    "objectID": "posts/MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models/2024-06-20-MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models.html#appendix",
    "href": "posts/MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models/2024-06-20-MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models.html#appendix",
    "title": "MR-BEN: A Comprehensive Meta-Reasoning Benchmark for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13975v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13975v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8416"
  },
  {
    "objectID": "posts/Self_Evaluation_as_a_Defense_Against_Adversarial_Attacks_on_LLMs/2024-07-03-Self_Evaluation_as_a_Defense_Against_Adversarial_Attacks_on_LLMs.html#appendix",
    "href": "posts/Self_Evaluation_as_a_Defense_Against_Adversarial_Attacks_on_LLMs/2024-07-03-Self_Evaluation_as_a_Defense_Against_Adversarial_Attacks_on_LLMs.html#appendix",
    "title": "Self-Evaluation as a Defense Against Adversarial Attacks on LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03234v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03234v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18444"
  },
  {
    "objectID": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#summary-1",
    "href": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#summary-1",
    "title": "LangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling",
    "section": "Summary:",
    "text": "Summary:\nThe paper introduces a novel framework, LangTopo, which aligns graph structure modeling with natural language understanding at the token level. LangTopo quantifies the graph structure modeling capabilities of GNNs and LLMs by constructing a codebook for the graph modality and performs consistency maximization. This process aligns the text description of LLM with the topological modeling of GNN, allowing LLM to learn the ability of GNN to capture graph structures, enabling LLM to handle graph-structured data independently. The effectiveness of the proposed method is demonstrated on multiple datasets."
  },
  {
    "objectID": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#major-findings",
    "href": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#major-findings",
    "title": "LangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe paper proposes LangTopo, a new framework for learning graph structures using LLMs, which enables LLMs to learn GNNs’ ability to model graph structures through supervised learning.\nLangTopo achieves alignment between the natural language descriptive text in LLMs and the processing and operation of GNN models by constructing a codebook for the graph data modality.\nUnlike existing paradigms that usually introduce external modules to recognize graph structures, LangTopo endows the LLM itself with the ability to model graph structures, obviating the need for external data or model integration during inference."
  },
  {
    "objectID": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#analysis-and-critique",
    "href": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#analysis-and-critique",
    "title": "LangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper presents a promising approach to addressing the challenges of combining the structural modeling capacity of GNNs with the text processing capability of LLMs.\nThe use of an external GNN to extract spatial structure embeddings and training a projection layer or adapter to inject these embeddings into the LLM has been a common approach, but LLMs still lack the ability to handle graph data independently and continue to rely on external models during inference.\nThe paper’s focus on modeling, rather than embedding, is a significant contribution to the field, as it addresses the fundamental issue of LLMs lacking the capability to model graph structures.\nThe paper’s evaluation on multiple datasets demonstrates the effectiveness of the proposed method, but further research is needed to explore the generalizability and scalability of LangTopo.\nThe paper’s limitation is the unexplored scenario of jointly training with multiple datasets for graph modality"
  },
  {
    "objectID": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#appendix",
    "href": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#appendix",
    "title": "LangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13250v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13250v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10341"
  },
  {
    "objectID": "posts/APEER_Automatic_Prompt_Engineering_Enhances_Large_Language_Model_Reranking/2024-06-20-APEER_Automatic_Prompt_Engineering_Enhances_Large_Language_Model_Reranking.html#appendix",
    "href": "posts/APEER_Automatic_Prompt_Engineering_Enhances_Large_Language_Model_Reranking/2024-06-20-APEER_Automatic_Prompt_Engineering_Enhances_Large_Language_Model_Reranking.html#appendix",
    "title": "APEER: Automatic Prompt Engineering Enhances Large Language Model Reranking",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14449v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14449v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7262"
  },
  {
    "objectID": "posts/Breaking_Bias_Building_Bridges_Evaluation_and_Mitigation_of_Social_Biases_in_LLMs_via_Contact_Hypothesis/2024-07-02-Breaking_Bias_Building_Bridges_Evaluation_and_Mitigation_of_Social_Biases_in_LLMs_via_Contact_Hypothesis.html#appendix",
    "href": "posts/Breaking_Bias_Building_Bridges_Evaluation_and_Mitigation_of_Social_Biases_in_LLMs_via_Contact_Hypothesis/2024-07-02-Breaking_Bias_Building_Bridges_Evaluation_and_Mitigation_of_Social_Biases_in_LLMs_via_Contact_Hypothesis.html#appendix",
    "title": "Breaking Bias, Building Bridges: Evaluation and Mitigation of Social Biases in LLMs via Contact Hypothesis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02030v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02030v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7434"
  },
  {
    "objectID": "posts/Augmenting_Query_and_Passage_for_Retrieval_Augmented_Generation_using_LLMs_for_Open_Domain_Question_Answering/2024-06-20-Augmenting_Query_and_Passage_for_Retrieval_Augmented_Generation_using_LLMs_for_Open_Domain_Question_Answering.html#appendix",
    "href": "posts/Augmenting_Query_and_Passage_for_Retrieval_Augmented_Generation_using_LLMs_for_Open_Domain_Question_Answering/2024-06-20-Augmenting_Query_and_Passage_for_Retrieval_Augmented_Generation_using_LLMs_for_Open_Domain_Question_Answering.html#appendix",
    "title": "Augmenting Query and Passage for Retrieval-Augmented Generation using LLMs for Open-Domain Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14277v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14277v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6421"
  },
  {
    "objectID": "posts/Improving_LLMs_for_Recommendation_with_Out_Of_Vocabulary_Tokens/2024-06-12-Improving_LLMs_for_Recommendation_with_Out_Of_Vocabulary_Tokens.html#appendix",
    "href": "posts/Improving_LLMs_for_Recommendation_with_Out_Of_Vocabulary_Tokens/2024-06-12-Improving_LLMs_for_Recommendation_with_Out_Of_Vocabulary_Tokens.html#appendix",
    "title": "Improving LLMs for Recommendation with Out-Of-Vocabulary Tokens",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.08477v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.08477v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9535"
  },
  {
    "objectID": "posts/Blending_LLMs_into_Cascaded_Speech_Translation_KITs_Offline_Speech_Translation_System_for_IWSLT_2024/2024-06-24-Blending_LLMs_into_Cascaded_Speech_Translation_KITs_Offline_Speech_Translation_System_for_IWSLT_2024.html#appendix",
    "href": "posts/Blending_LLMs_into_Cascaded_Speech_Translation_KITs_Offline_Speech_Translation_System_for_IWSLT_2024/2024-06-24-Blending_LLMs_into_Cascaded_Speech_Translation_KITs_Offline_Speech_Translation_System_for_IWSLT_2024.html#appendix",
    "title": "Blending LLMs into Cascaded Speech Translation: KIT’s Offline Speech Translation System for IWSLT 2024",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16777v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16777v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4916"
  },
  {
    "objectID": "posts/LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction/2024-06-20-LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction.html",
    "href": "posts/LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction/2024-06-20-LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction.html",
    "title": "LLM4CP: Adapting Large Language Models for Channel Prediction",
    "section": "",
    "text": "Summary:\nThe paper proposes a novel channel prediction method called LLM4CP, which is based on fine-tuning pre-trained GPT-2 for MISO-OFDM channel prediction tasks. The method predicts future downlink CSI sequences based on historical uplink CSI sequences and can be applied to both TDD and FDD systems. To account for channel characteristics, the authors have tailored preprocessor, embedding, and output modules to bridge the gap between CSI data and LLM. Preliminary simulations validate the superiority of LLM4CP over existing model-based and deep learning-based channel prediction methods in full-sample, few-shot, and generalization tests with acceptable training and inference costs.\nMajor Findings:\nAnalysis and Critique:\nOverall, the paper presents an interesting and promising approach to channel prediction based on fine-tuning pre-trained GPT-2. However, more detailed analysis and comparison with other state-of-the-art methods are needed to better understand its advantages and"
  },
  {
    "objectID": "posts/LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction/2024-06-20-LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction.html#appendix",
    "href": "posts/LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction/2024-06-20-LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction.html#appendix",
    "title": "LLM4CP: Adapting Large Language Models for Channel Prediction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14440v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14440v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8453"
  },
  {
    "objectID": "posts/SecureNet_A_Comparative_Study_of_DeBERTa_and_Large_Language_Models_for_Phishing_Detection/2024-06-10-SecureNet_A_Comparative_Study_of_DeBERTa_and_Large_Language_Models_for_Phishing_Detection.html#appendix",
    "href": "posts/SecureNet_A_Comparative_Study_of_DeBERTa_and_Large_Language_Models_for_Phishing_Detection/2024-06-10-SecureNet_A_Comparative_Study_of_DeBERTa_and_Large_Language_Models_for_Phishing_Detection.html#appendix",
    "title": "SecureNet: A Comparative Study of DeBERTa and Large Language Models for Phishing Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06663v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06663v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8220"
  },
  {
    "objectID": "posts/STBench_Assessing_the_Ability_of_Large_Language_Models_in_Spatio_Temporal_Analysis/2024-06-27-STBench_Assessing_the_Ability_of_Large_Language_Models_in_Spatio_Temporal_Analysis.html#appendix",
    "href": "posts/STBench_Assessing_the_Ability_of_Large_Language_Models_in_Spatio_Temporal_Analysis/2024-06-27-STBench_Assessing_the_Ability_of_Large_Language_Models_in_Spatio_Temporal_Analysis.html#appendix",
    "title": "STBench: Assessing the Ability of Large Language Models in Spatio-Temporal Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19065v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19065v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11715"
  },
  {
    "objectID": "posts/Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations/2024-07-03-Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations.html",
    "href": "posts/Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations/2024-07-03-Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations.html",
    "title": "Social Bias Evaluation for Large Language Models Requires Prompt Variations",
    "section": "",
    "text": "Summary:\nThis paper investigates the sensitivity of 12 large language models (LLMs) to prompt variations in evaluating task performance and social bias, focusing on a question-answering dataset, BBQ. The study categorizes three prompt variation factors: 1) task instruction and prompt for task recognition, 2) few-shot examples for task performance improvement, and 3) debias-prompt for bias mitigation. The experimental results reveal that LLMs are highly sensitive to prompts in bias evaluation, with the ranking of LLMs and debiasing effectiveness fluctuating when comparing models for task performance and bias scores. The study also shows that LLMs have tradeoffs among task performance and social bias caused by the prompts, and the ambiguity of instances contributes to the sensitivity in advanced LLMs.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive analysis of the sensitivity of LLMs to prompt variations in evaluating task performance and social bias. However, the study is limited to a single question-answering dataset, BBQ, and does not explore other types of datasets or tasks. Additionally, the paper does not discuss the potential impact of prompt variations on the fairness and ethical considerations of LLMs. Further research is needed to investigate the generalizability of the findings to other datasets and tasks and to explore the ethical implications of prompt variations in LLMs."
  },
  {
    "objectID": "posts/Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations/2024-07-03-Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations.html#appendix",
    "href": "posts/Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations/2024-07-03-Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations.html#appendix",
    "title": "Social Bias Evaluation for Large Language Models Requires Prompt Variations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03129v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03129v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17789"
  },
  {
    "objectID": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#major-findings",
    "href": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#major-findings",
    "title": "DomainRAG: A Chinese Benchmark for Evaluating Domain-specific Retrieval-Augmented Generation",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nExisting closed-book LLMs struggle with domain-specific questions, emphasizing the importance of RAG models for solving expert problems.\nThere is room for RAG models to improve their abilities in comprehending conversational history, analyzing structural information, denoising, processing multi-document interactions, and faithfulness in expert knowledge.\nThe use of domain-specific corpora and questions is essential to assess the ability of LLMs to effectively use external knowledge from specific fields to solve expert problems."
  },
  {
    "objectID": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#analysis-and-critique",
    "href": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#analysis-and-critique",
    "title": "DomainRAG: A Chinese Benchmark for Evaluating Domain-specific Retrieval-Augmented Generation",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper provides a comprehensive evaluation of RAG models in a domain-specific context, which is crucial for addressing the limitations of LLMs in expert and domain-specific applications.\nThe study identifies six essential abilities for RAG models, which can serve as a foundation for future research and development in this area.\nThe experimental results highlight the need for RAG models to improve their performance in complex scenarios involving various kinds of information sources.\nThe paper could benefit from a more detailed analysis of the limitations and potential biases of the evaluated LLMs and RAG models.\nFuture studies should explore more sophisticated frameworks for enhancing the performance of RAG systems and evaluate their performance in various application scenarios."
  },
  {
    "objectID": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#appendix",
    "href": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#appendix",
    "title": "DomainRAG: A Chinese Benchmark for Evaluating Domain-specific Retrieval-Augmented Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05654v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05654v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6448"
  },
  {
    "objectID": "posts/EAGLE_2_Faster_Inference_of_Language_Models_with_Dynamic_Draft_Trees/2024-06-24-EAGLE_2_Faster_Inference_of_Language_Models_with_Dynamic_Draft_Trees.html#appendix",
    "href": "posts/EAGLE_2_Faster_Inference_of_Language_Models_with_Dynamic_Draft_Trees/2024-06-24-EAGLE_2_Faster_Inference_of_Language_Models_with_Dynamic_Draft_Trees.html#appendix",
    "title": "EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16858v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16858v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6645"
  },
  {
    "objectID": "posts/Talk_With_Human_like_Agents_Empathetic_Dialogue_Through_Perceptible_Acoustic_Reception_and_Reaction/2024-06-18-Talk_With_Human_like_Agents_Empathetic_Dialogue_Through_Perceptible_Acoustic_Reception_and_Reaction.html#appendix",
    "href": "posts/Talk_With_Human_like_Agents_Empathetic_Dialogue_Through_Perceptible_Acoustic_Reception_and_Reaction/2024-06-18-Talk_With_Human_like_Agents_Empathetic_Dialogue_Through_Perceptible_Acoustic_Reception_and_Reaction.html#appendix",
    "title": "Talk With Human-like Agents: Empathetic Dialogue Through Perceptible Acoustic Reception and Reaction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12707v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12707v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6339"
  },
  {
    "objectID": "posts/SEC_QA_A_Systematic_Evaluation_Corpus_for_Financial_QA/2024-06-20-SEC_QA_A_Systematic_Evaluation_Corpus_for_Financial_QA.html#appendix",
    "href": "posts/SEC_QA_A_Systematic_Evaluation_Corpus_for_Financial_QA/2024-06-20-SEC_QA_A_Systematic_Evaluation_Corpus_for_Financial_QA.html#appendix",
    "title": "SEC-QA: A Systematic Evaluation Corpus for Financial QA",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14394v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14394v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6714"
  },
  {
    "objectID": "posts/Is_In_Context_Learning_a_Type_of_Gradient_Based_Learning_Evidence_from_the_Inverse_Frequency_Effect_in_Structural_Priming/2024-06-26-Is_In_Context_Learning_a_Type_of_Gradient_Based_Learning_Evidence_from_the_Inverse_Frequency_Effect_in_Structural_Priming.html#appendix",
    "href": "posts/Is_In_Context_Learning_a_Type_of_Gradient_Based_Learning_Evidence_from_the_Inverse_Frequency_Effect_in_Structural_Priming/2024-06-26-Is_In_Context_Learning_a_Type_of_Gradient_Based_Learning_Evidence_from_the_Inverse_Frequency_Effect_in_Structural_Priming.html#appendix",
    "title": "Is In-Context Learning a Type of Gradient-Based Learning? Evidence from the Inverse Frequency Effect in Structural Priming",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18501v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18501v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8453"
  },
  {
    "objectID": "posts/Do_LLMs_Recognize_me_When_I_is_not_me_Assessment_of_LLMs_Understanding_of_Turkish_Indexical_Pronouns_in_Indexical_Shift_Contexts/2024-06-08-Do_LLMs_Recognize_me_When_I_is_not_me_Assessment_of_LLMs_Understanding_of_Turkish_Indexical_Pronouns_in_Indexical_Shift_Contexts.html#appendix",
    "href": "posts/Do_LLMs_Recognize_me_When_I_is_not_me_Assessment_of_LLMs_Understanding_of_Turkish_Indexical_Pronouns_in_Indexical_Shift_Contexts/2024-06-08-Do_LLMs_Recognize_me_When_I_is_not_me_Assessment_of_LLMs_Understanding_of_Turkish_Indexical_Pronouns_in_Indexical_Shift_Contexts.html#appendix",
    "title": "Do LLMs Recognize me, When I is not me: Assessment of LLMs Understanding of Turkish Indexical Pronouns in Indexical Shift Contexts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05569v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05569v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5917"
  },
  {
    "objectID": "posts/Silent_Signals_Loud_Impact_LLMs_for_Word_Sense_Disambiguation_of_Coded_Dog_Whistles/2024-06-10-Silent_Signals_Loud_Impact_LLMs_for_Word_Sense_Disambiguation_of_Coded_Dog_Whistles.html#appendix",
    "href": "posts/Silent_Signals_Loud_Impact_LLMs_for_Word_Sense_Disambiguation_of_Coded_Dog_Whistles/2024-06-10-Silent_Signals_Loud_Impact_LLMs_for_Word_Sense_Disambiguation_of_Coded_Dog_Whistles.html#appendix",
    "title": "Silent Signals, Loud Impact: LLMs for Word-Sense Disambiguation of Coded Dog Whistles",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06840v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06840v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8725"
  },
  {
    "objectID": "posts/Adversarial_Search_Engine_Optimization_for_Large_Language_Models/2024-06-26-Adversarial_Search_Engine_Optimization_for_Large_Language_Models.html#appendix",
    "href": "posts/Adversarial_Search_Engine_Optimization_for_Large_Language_Models/2024-06-26-Adversarial_Search_Engine_Optimization_for_Large_Language_Models.html#appendix",
    "title": "Adversarial Search Engine Optimization for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18382v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18382v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13149"
  },
  {
    "objectID": "posts/Harnessing_the_Power_of_LLMs_Automating_Unit_Test_Generation_for_High_Performance_Computing/2024-07-06-Harnessing_the_Power_of_LLMs_Automating_Unit_Test_Generation_for_High_Performance_Computing.html#appendix",
    "href": "posts/Harnessing_the_Power_of_LLMs_Automating_Unit_Test_Generation_for_High_Performance_Computing/2024-07-06-Harnessing_the_Power_of_LLMs_Automating_Unit_Test_Generation_for_High_Performance_Computing.html#appendix",
    "title": "Harnessing the Power of LLMs: Automating Unit Test Generation for High-Performance Computing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05202v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05202v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10114"
  },
  {
    "objectID": "posts/Teaching_LLMs_to_Abstain_across_Languages_via_Multilingual_Feedback/2024-06-22-Teaching_LLMs_to_Abstain_across_Languages_via_Multilingual_Feedback.html",
    "href": "posts/Teaching_LLMs_to_Abstain_across_Languages_via_Multilingual_Feedback/2024-06-22-Teaching_LLMs_to_Abstain_across_Languages_via_Multilingual_Feedback.html",
    "title": "Teaching LLMs to Abstain across Languages via Multilingual Feedback",
    "section": "",
    "text": "Summary:\nThe paper presents a study on teaching multilingual large language models (LLMs) to abstain from answering when they encounter knowledge gaps, with a focus on mitigating hallucinations in multilingual settings. The authors propose a strategy that involves generating and learning from multilingual feedback in related languages, which helps identify knowledge gaps across diverse languages, cultures, and communities. The proposed approach is evaluated on three datasets featuring open-book, closed-book, and commonsense QA, and is shown to outperform various strong baselines, achieving up to 9.2% improvement for low-resource languages. The study also reveals that multilingual feedback is an effective and more equitable abstain strategy, with cultural factors playing a significant role in language selection and LLM abstention behavior.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel approach to teaching LLMs to abstain from answering in the face of knowledge gaps, with a focus on multilingual settings. The proposed strategy of generating and learning from multilingual feedback in related languages is shown to be effective in identifying knowledge gaps and improving LLM abstention behavior. However, the study is limited in its evaluation of the proposed approach on only three datasets, and it is unclear how well the approach would generalize to other datasets and tasks. Additionally, the study does not address potential issues related to the quality and reliability of the generated feedback, which could impact the effectiveness of the proposed approach. Further research is needed to address these limitations and evaluate the proposed approach in a more comprehensive manner."
  },
  {
    "objectID": "posts/Teaching_LLMs_to_Abstain_across_Languages_via_Multilingual_Feedback/2024-06-22-Teaching_LLMs_to_Abstain_across_Languages_via_Multilingual_Feedback.html#appendix",
    "href": "posts/Teaching_LLMs_to_Abstain_across_Languages_via_Multilingual_Feedback/2024-06-22-Teaching_LLMs_to_Abstain_across_Languages_via_Multilingual_Feedback.html#appendix",
    "title": "Teaching LLMs to Abstain across Languages via Multilingual Feedback",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.15948v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.15948v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8591"
  },
  {
    "objectID": "posts/FactFinders_at_CheckThat!_2024_Refining_Check_worthy_Statement_Detection_with_LLMs_through_Data_Pruning/2024-06-26-FactFinders_at_CheckThat!_2024_Refining_Check_worthy_Statement_Detection_with_LLMs_through_Data_Pruning.html#appendix",
    "href": "posts/FactFinders_at_CheckThat!_2024_Refining_Check_worthy_Statement_Detection_with_LLMs_through_Data_Pruning/2024-06-26-FactFinders_at_CheckThat!_2024_Refining_Check_worthy_Statement_Detection_with_LLMs_through_Data_Pruning.html#appendix",
    "title": "FactFinders at CheckThat! 2024: Refining Check-worthy Statement Detection with LLMs through Data Pruning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18297v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18297v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7119"
  },
  {
    "objectID": "posts/Semantic_Structure_Mapping_in_LLM_and_Human_Analogical_Reasoning/2024-06-19-Semantic_Structure_Mapping_in_LLM_and_Human_Analogical_Reasoning.html#appendix",
    "href": "posts/Semantic_Structure_Mapping_in_LLM_and_Human_Analogical_Reasoning/2024-06-19-Semantic_Structure_Mapping_in_LLM_and_Human_Analogical_Reasoning.html#appendix",
    "title": "Semantic Structure-Mapping in LLM and Human Analogical Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13803v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13803v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12911"
  },
  {
    "objectID": "posts/Multi_Stage_Balanced_Distillation_Addressing_Long_Tail_Challenges_in_Sequence_Level_Knowledge_Distillation/2024-06-19-Multi_Stage_Balanced_Distillation_Addressing_Long_Tail_Challenges_in_Sequence_Level_Knowledge_Distillation.html#appendix",
    "href": "posts/Multi_Stage_Balanced_Distillation_Addressing_Long_Tail_Challenges_in_Sequence_Level_Knowledge_Distillation/2024-06-19-Multi_Stage_Balanced_Distillation_Addressing_Long_Tail_Challenges_in_Sequence_Level_Knowledge_Distillation.html#appendix",
    "title": "Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13114v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13114v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7892"
  },
  {
    "objectID": "posts/Towards_Fast_Multilingual_LLM_Inference_Speculative_Decoding_and_Specialized_Drafters/2024-06-24-Towards_Fast_Multilingual_LLM_Inference_Speculative_Decoding_and_Specialized_Drafters.html#appendix",
    "href": "posts/Towards_Fast_Multilingual_LLM_Inference_Speculative_Decoding_and_Specialized_Drafters/2024-06-24-Towards_Fast_Multilingual_LLM_Inference_Speculative_Decoding_and_Specialized_Drafters.html#appendix",
    "title": "Towards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16758v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16758v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6782"
  },
  {
    "objectID": "posts/Enhancing_Language_Model_Rationality_with_Bi_Directional_Deliberation_Reasoning/2024-07-08-Enhancing_Language_Model_Rationality_with_Bi_Directional_Deliberation_Reasoning.html#appendix",
    "href": "posts/Enhancing_Language_Model_Rationality_with_Bi_Directional_Deliberation_Reasoning/2024-07-08-Enhancing_Language_Model_Rationality_with_Bi_Directional_Deliberation_Reasoning.html#appendix",
    "title": "Enhancing Language Model Rationality with Bi-Directional Deliberation Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06112v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06112v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5655"
  },
  {
    "objectID": "posts/Mitigating_Hallucination_in_Fictional_Character_Role_Play/2024-06-25-Mitigating_Hallucination_in_Fictional_Character_Role_Play.html#appendix",
    "href": "posts/Mitigating_Hallucination_in_Fictional_Character_Role_Play/2024-06-25-Mitigating_Hallucination_in_Fictional_Character_Role_Play.html#appendix",
    "title": "Mitigating Hallucination in Fictional Character Role-Play",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17260v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17260v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5369"
  },
  {
    "objectID": "posts/Can_Large_Language_Models_Understand_DL_Lite_Ontologies_An_Empirical_Study/2024-06-25-Can_Large_Language_Models_Understand_DL_Lite_Ontologies_An_Empirical_Study.html#appendix",
    "href": "posts/Can_Large_Language_Models_Understand_DL_Lite_Ontologies_An_Empirical_Study/2024-06-25-Can_Large_Language_Models_Understand_DL_Lite_Ontologies_An_Empirical_Study.html#appendix",
    "title": "Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17532v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17532v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10388"
  },
  {
    "objectID": "posts/Open_Generative_Large_Language_Models_for_Galician/2024-06-19-Open_Generative_Large_Language_Models_for_Galician.html#appendix",
    "href": "posts/Open_Generative_Large_Language_Models_for_Galician/2024-06-19-Open_Generative_Large_Language_Models_for_Galician.html#appendix",
    "title": "Open Generative Large Language Models for Galician",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13893v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13893v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6815"
  },
  {
    "objectID": "posts/Large_Language_Models_for_Constrained_Based_Causal_Discovery/2024-06-11-Large_Language_Models_for_Constrained_Based_Causal_Discovery.html#appendix",
    "href": "posts/Large_Language_Models_for_Constrained_Based_Causal_Discovery/2024-06-11-Large_Language_Models_for_Constrained_Based_Causal_Discovery.html#appendix",
    "title": "Large Language Models for Constrained-Based Causal Discovery",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07378v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07378v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7632"
  },
  {
    "objectID": "posts/Lifelong_Robot_Library_Learning_Bootstrapping_Composable_and_Generalizable_Skills_for_Embodied_Control_with_Language_Models/2024-06-26-Lifelong_Robot_Library_Learning_Bootstrapping_Composable_and_Generalizable_Skills_for_Embodied_Control_with_Language_Models.html#appendix",
    "href": "posts/Lifelong_Robot_Library_Learning_Bootstrapping_Composable_and_Generalizable_Skills_for_Embodied_Control_with_Language_Models/2024-06-26-Lifelong_Robot_Library_Learning_Bootstrapping_Composable_and_Generalizable_Skills_for_Embodied_Control_with_Language_Models.html#appendix",
    "title": "Lifelong Robot Library Learning: Bootstrapping Composable and Generalizable Skills for Embodied Control with Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18746v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18746v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6688"
  },
  {
    "objectID": "posts/TheoremLlama_Transforming_General_Purpose_LLMs_into_Lean4_Experts/2024-07-03-TheoremLlama_Transforming_General_Purpose_LLMs_into_Lean4_Experts.html#appendix",
    "href": "posts/TheoremLlama_Transforming_General_Purpose_LLMs_into_Lean4_Experts/2024-07-03-TheoremLlama_Transforming_General_Purpose_LLMs_into_Lean4_Experts.html#appendix",
    "title": "TheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03203v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03203v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8361"
  },
  {
    "objectID": "posts/ELCoRec_Enhance_Language_Understanding_with_Co_Propagation_of_Numerical_and_Categorical_Features_for_Recommendation/2024-06-27-ELCoRec_Enhance_Language_Understanding_with_Co_Propagation_of_Numerical_and_Categorical_Features_for_Recommendation.html#appendix",
    "href": "posts/ELCoRec_Enhance_Language_Understanding_with_Co_Propagation_of_Numerical_and_Categorical_Features_for_Recommendation/2024-06-27-ELCoRec_Enhance_Language_Understanding_with_Co_Propagation_of_Numerical_and_Categorical_Features_for_Recommendation.html#appendix",
    "title": "ELCoRec: Enhance Language Understanding with Co-Propagation of Numerical and Categorical Features for Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18825v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18825v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9136"
  },
  {
    "objectID": "posts/Ask_LLMs_Directly_What_shapes_your_bias_Measuring_Social_Bias_in_Large_Language_Models/2024-06-06-Ask_LLMs_Directly_What_shapes_your_bias_Measuring_Social_Bias_in_Large_Language_Models.html#appendix",
    "href": "posts/Ask_LLMs_Directly_What_shapes_your_bias_Measuring_Social_Bias_in_Large_Language_Models/2024-06-06-Ask_LLMs_Directly_What_shapes_your_bias_Measuring_Social_Bias_in_Large_Language_Models.html#appendix",
    "title": "Ask LLMs Directly, What shapes your bias?: Measuring Social Bias in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04064v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04064v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5188"
  },
  {
    "objectID": "posts/A_Survey_on_LLM_Based_Agentic_Workflows_and_LLM_Profiled_Components/2024-06-09-A_Survey_on_LLM_Based_Agentic_Workflows_and_LLM_Profiled_Components.html#appendix",
    "href": "posts/A_Survey_on_LLM_Based_Agentic_Workflows_and_LLM_Profiled_Components/2024-06-09-A_Survey_on_LLM_Based_Agentic_Workflows_and_LLM_Profiled_Components.html#appendix",
    "title": "A Survey on LLM-Based Agentic Workflows and LLM-Profiled Components",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05804v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05804v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5941"
  },
  {
    "objectID": "posts/GraCoRe_Benchmarking_Graph_Comprehension_and_Complex_Reasoning_in_Large_Language_Models/2024-07-03-GraCoRe_Benchmarking_Graph_Comprehension_and_Complex_Reasoning_in_Large_Language_Models.html#appendix",
    "href": "posts/GraCoRe_Benchmarking_Graph_Comprehension_and_Complex_Reasoning_in_Large_Language_Models/2024-07-03-GraCoRe_Benchmarking_Graph_Comprehension_and_Complex_Reasoning_in_Large_Language_Models.html#appendix",
    "title": "GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02936v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02936v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5687"
  },
  {
    "objectID": "posts/LLMEmbed_Rethinking_Lightweight_LLMs_Genuine_Function_in_Text_Classification/2024-06-06-LLMEmbed_Rethinking_Lightweight_LLMs_Genuine_Function_in_Text_Classification.html#appendix",
    "href": "posts/LLMEmbed_Rethinking_Lightweight_LLMs_Genuine_Function_in_Text_Classification/2024-06-06-LLMEmbed_Rethinking_Lightweight_LLMs_Genuine_Function_in_Text_Classification.html#appendix",
    "title": "LLMEmbed: Rethinking Lightweight LLM’s Genuine Function in Text Classification",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03725v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03725v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5774"
  },
  {
    "objectID": "posts/Self_and_Cross_Model_Distillation_for_LLMs_Effective_Methods_for_Refusal_Pattern_Alignment/2024-06-17-Self_and_Cross_Model_Distillation_for_LLMs_Effective_Methods_for_Refusal_Pattern_Alignment.html#appendix",
    "href": "posts/Self_and_Cross_Model_Distillation_for_LLMs_Effective_Methods_for_Refusal_Pattern_Alignment/2024-06-17-Self_and_Cross_Model_Distillation_for_LLMs_Effective_Methods_for_Refusal_Pattern_Alignment.html#appendix",
    "title": "Self and Cross-Model Distillation for LLMs: Effective Methods for Refusal Pattern Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11285v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11285v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6660"
  },
  {
    "objectID": "posts/Can_I_understand_what_I_create_Self_Knowledge_Evaluation_of_Large_Language_Models/2024-06-10-Can_I_understand_what_I_create_Self_Knowledge_Evaluation_of_Large_Language_Models.html#appendix",
    "href": "posts/Can_I_understand_what_I_create_Self_Knowledge_Evaluation_of_Large_Language_Models/2024-06-10-Can_I_understand_what_I_create_Self_Knowledge_Evaluation_of_Large_Language_Models.html#appendix",
    "title": "Can I understand what I create? Self-Knowledge Evaluation of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06140v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06140v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7449"
  },
  {
    "objectID": "posts/Methodology_of_Adapting_Large_English_Language_Models_for_Specific_Cultural_Contexts/2024-06-27-Methodology_of_Adapting_Large_English_Language_Models_for_Specific_Cultural_Contexts.html#appendix",
    "href": "posts/Methodology_of_Adapting_Large_English_Language_Models_for_Specific_Cultural_Contexts/2024-06-27-Methodology_of_Adapting_Large_English_Language_Models_for_Specific_Cultural_Contexts.html#appendix",
    "title": "Methodology of Adapting Large English Language Models for Specific Cultural Contexts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18192v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18192v2\n\n\nTruncated\nFalse\n\n\nWord Count\n4216"
  },
  {
    "objectID": "posts/Preference_Tuning_For_Toxicity_Mitigation_Generalizes_Across_Languages/2024-06-23-Preference_Tuning_For_Toxicity_Mitigation_Generalizes_Across_Languages.html#appendix",
    "href": "posts/Preference_Tuning_For_Toxicity_Mitigation_Generalizes_Across_Languages/2024-06-23-Preference_Tuning_For_Toxicity_Mitigation_Generalizes_Across_Languages.html#appendix",
    "title": "Preference Tuning For Toxicity Mitigation Generalizes Across Languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16235v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16235v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8475"
  },
  {
    "objectID": "posts/How_Efficient_is_LLM_Generated_Code_A_Rigorous__High_Standard_Benchmark/2024-06-10-How_Efficient_is_LLM_Generated_Code_A_Rigorous__High_Standard_Benchmark.html#appendix",
    "href": "posts/How_Efficient_is_LLM_Generated_Code_A_Rigorous__High_Standard_Benchmark/2024-06-10-How_Efficient_is_LLM_Generated_Code_A_Rigorous__High_Standard_Benchmark.html#appendix",
    "title": "How Efficient is LLM-Generated Code? A Rigorous & High-Standard Benchmark",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06647v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06647v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8226"
  },
  {
    "objectID": "posts/How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States/2024-06-09-How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States.html",
    "href": "posts/How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States/2024-06-09-How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States.html",
    "title": "How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States",
    "section": "",
    "text": "Summary:\nThis paper explores how alignment and jailbreak work in large language models (LLMs) by using weak classifiers to explain LLM safety through intermediate hidden states. The authors confirm that LLMs learn ethical concepts during pre-training rather than alignment and can identify malicious and normal inputs in the early layers. Alignment associates the early concepts with emotion guesses in the middle layers and then refines them to specific reject tokens for safe generations. Jailbreak disturbs the transformation of early unethical classification into negative emotions. The paper conducts experiments on models from 7B to 70B across various model families to prove their conclusion.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a novel perspective on LLM safety by explaining how alignment and jailbreak work through intermediate hidden states. The use of weak classifiers to explain LLM safety is an innovative approach that could be applied to other aspects of LLM behavior. However, the paper does not discuss the limitations of using weak classifiers or the potential biases that may be introduced. Additionally, the paper does not address the potential risks of jailbreak, such as the generation of harmful content, and how these risks can be mitigated. Overall, the paper provides valuable insights into LLM safety and offers a new perspective on how alignment and jailbreak work."
  },
  {
    "objectID": "posts/How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States/2024-06-09-How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States.html#appendix",
    "href": "posts/How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States/2024-06-09-How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States.html#appendix",
    "title": "How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05644v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05644v1\n\n\nTruncated\nFalse\n\n\nWord Count\n19114"
  },
  {
    "objectID": "posts/Dye4AI_Assuring_Data_Boundary_on_Generative_AI_Services/2024-06-20-Dye4AI_Assuring_Data_Boundary_on_Generative_AI_Services.html#appendix",
    "href": "posts/Dye4AI_Assuring_Data_Boundary_on_Generative_AI_Services/2024-06-20-Dye4AI_Assuring_Data_Boundary_on_Generative_AI_Services.html#appendix",
    "title": "Dye4AI: Assuring Data Boundary on Generative AI Services",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14114v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14114v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15379"
  },
  {
    "objectID": "posts/Jogging_the_Memory_of_Unlearned_Model_Through_Targeted_Relearning_Attack/2024-06-19-Jogging_the_Memory_of_Unlearned_Model_Through_Targeted_Relearning_Attack.html#appendix",
    "href": "posts/Jogging_the_Memory_of_Unlearned_Model_Through_Targeted_Relearning_Attack/2024-06-19-Jogging_the_Memory_of_Unlearned_Model_Through_Targeted_Relearning_Attack.html#appendix",
    "title": "Jogging the Memory of Unlearned Model Through Targeted Relearning Attack",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13356v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13356v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5602"
  },
  {
    "objectID": "posts/PISTOL_Dataset_Compilation_Pipeline_for_Structural_Unlearning_of_LLMs/2024-06-24-PISTOL_Dataset_Compilation_Pipeline_for_Structural_Unlearning_of_LLMs.html#appendix",
    "href": "posts/PISTOL_Dataset_Compilation_Pipeline_for_Structural_Unlearning_of_LLMs/2024-06-24-PISTOL_Dataset_Compilation_Pipeline_for_Structural_Unlearning_of_LLMs.html#appendix",
    "title": "PISTOL: Dataset Compilation Pipeline for Structural Unlearning of LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16810v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16810v1\n\n\nTruncated\nFalse\n\n\nWord Count\n25194"
  },
  {
    "objectID": "posts/Prompt_Consistency_Image_Generation_(PCIG)_A_Unified_Framework_Integrating_LLMs_Knowledge_Graphs_and_Controllable_Diffusion_Models/2024-06-24-Prompt_Consistency_Image_Generation_(PCIG)_A_Unified_Framework_Integrating_LLMs_Knowledge_Graphs_and_Controllable_Diffusion_Models.html",
    "href": "posts/Prompt_Consistency_Image_Generation_(PCIG)_A_Unified_Framework_Integrating_LLMs_Knowledge_Graphs_and_Controllable_Diffusion_Models/2024-06-24-Prompt_Consistency_Image_Generation_(PCIG)_A_Unified_Framework_Integrating_LLMs_Knowledge_Graphs_and_Controllable_Diffusion_Models.html",
    "title": "Prompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models",
    "section": "",
    "text": "Summary:\nThe paper introduces a novel diffusion-based framework called Prompt-Consistency Image Generation (PCIG) to address the inconsistency between visual output and textual input in Text-to-Image (T2I) generative models. The framework leverages a state-of-the-art large language module to extract objects and construct a knowledge graph to predict the locations of these objects in potentially generated images. It then integrates a controllable image generation model with a visual text generation module to generate an image that is consistent with the original prompt, guided by the predicted object locations.\nMajor Findings:\nAnalysis and Critique:\nWhile PCIG shows promising results in generating images that align with the original prompt, there are some potential limitations and areas for improvement. For instance, the use of GPT4-turbo as the LLM for prompt analysis may introduce additional costs. Additionally, the framework may struggle with generating images with complex relationships and interactions between objects or with small text. Future work could explore the use of more powerful basic diffusion models to address these challenges."
  },
  {
    "objectID": "posts/Prompt_Consistency_Image_Generation_(PCIG)_A_Unified_Framework_Integrating_LLMs_Knowledge_Graphs_and_Controllable_Diffusion_Models/2024-06-24-Prompt_Consistency_Image_Generation_(PCIG)_A_Unified_Framework_Integrating_LLMs_Knowledge_Graphs_and_Controllable_Diffusion_Models.html#appendix",
    "href": "posts/Prompt_Consistency_Image_Generation_(PCIG)_A_Unified_Framework_Integrating_LLMs_Knowledge_Graphs_and_Controllable_Diffusion_Models/2024-06-24-Prompt_Consistency_Image_Generation_(PCIG)_A_Unified_Framework_Integrating_LLMs_Knowledge_Graphs_and_Controllable_Diffusion_Models.html#appendix",
    "title": "Prompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16333v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16333v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5668"
  },
  {
    "objectID": "posts/InternLM_XComposer_2.5_A_Versatile_Large_Vision_Language_Model_Supporting_Long_Contextual_Input_and_Output/2024-07-03-InternLM_XComposer_2.5_A_Versatile_Large_Vision_Language_Model_Supporting_Long_Contextual_Input_and_Output.html#appendix",
    "href": "posts/InternLM_XComposer_2.5_A_Versatile_Large_Vision_Language_Model_Supporting_Long_Contextual_Input_and_Output/2024-07-03-InternLM_XComposer_2.5_A_Versatile_Large_Vision_Language_Model_Supporting_Long_Contextual_Input_and_Output.html#appendix",
    "title": "InternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03320v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03320v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6365"
  },
  {
    "objectID": "posts/HyCIR_Boosting_Zero_Shot_Composed_Image_Retrieval_with_Synthetic_Labels/2024-07-08-HyCIR_Boosting_Zero_Shot_Composed_Image_Retrieval_with_Synthetic_Labels.html#appendix",
    "href": "posts/HyCIR_Boosting_Zero_Shot_Composed_Image_Retrieval_with_Synthetic_Labels/2024-07-08-HyCIR_Boosting_Zero_Shot_Composed_Image_Retrieval_with_Synthetic_Labels.html#appendix",
    "title": "HyCIR: Boosting Zero-Shot Composed Image Retrieval with Synthetic Labels",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05795v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05795v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10950"
  },
  {
    "objectID": "posts/SynDARin_Synthesising_Datasets_for_Automated_Reasoning_in_Low_Resource_Languages/2024-06-20-SynDARin_Synthesising_Datasets_for_Automated_Reasoning_in_Low_Resource_Languages.html#appendix",
    "href": "posts/SynDARin_Synthesising_Datasets_for_Automated_Reasoning_in_Low_Resource_Languages/2024-06-20-SynDARin_Synthesising_Datasets_for_Automated_Reasoning_in_Low_Resource_Languages.html#appendix",
    "title": "SynDARin: Synthesising Datasets for Automated Reasoning in Low-Resource Languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14425v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14425v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3686"
  },
  {
    "objectID": "posts/TCSR_SQL_Towards_Table_Content_aware_Text_to_SQL_with_Self_retrieval/2024-07-01-TCSR_SQL_Towards_Table_Content_aware_Text_to_SQL_with_Self_retrieval.html#appendix",
    "href": "posts/TCSR_SQL_Towards_Table_Content_aware_Text_to_SQL_with_Self_retrieval/2024-07-01-TCSR_SQL_Towards_Table_Content_aware_Text_to_SQL_with_Self_retrieval.html#appendix",
    "title": "TCSR-SQL: Towards Table Content-aware Text-to-SQL with Self-retrieval",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01183v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01183v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10323"
  },
  {
    "objectID": "posts/Finding_Safety_Neurons_in_Large_Language_Models/2024-06-20-Finding_Safety_Neurons_in_Large_Language_Models.html#appendix",
    "href": "posts/Finding_Safety_Neurons_in_Large_Language_Models/2024-06-20-Finding_Safety_Neurons_in_Large_Language_Models.html#appendix",
    "title": "Finding Safety Neurons in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14144v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14144v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10356"
  },
  {
    "objectID": "posts/CoEvol_Constructing_Better_Responses_for_Instruction_Finetuning_through_Multi_Agent_Cooperation/2024-06-11-CoEvol_Constructing_Better_Responses_for_Instruction_Finetuning_through_Multi_Agent_Cooperation.html#appendix",
    "href": "posts/CoEvol_Constructing_Better_Responses_for_Instruction_Finetuning_through_Multi_Agent_Cooperation/2024-06-11-CoEvol_Constructing_Better_Responses_for_Instruction_Finetuning_through_Multi_Agent_Cooperation.html#appendix",
    "title": "CoEvol: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07054v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07054v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6780"
  },
  {
    "objectID": "posts/MIRAI_Evaluating_LLM_Agents_for_Event_Forecasting/2024-07-01-MIRAI_Evaluating_LLM_Agents_for_Event_Forecasting.html#appendix",
    "href": "posts/MIRAI_Evaluating_LLM_Agents_for_Event_Forecasting/2024-07-01-MIRAI_Evaluating_LLM_Agents_for_Event_Forecasting.html#appendix",
    "title": "MIRAI: Evaluating LLM Agents for Event Forecasting",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01231v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01231v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4187"
  },
  {
    "objectID": "posts/Towards_Next_Era_of_Multi_objective_Optimization_Large_Language_Models_as_Architects_of_Evolutionary_Operators/2024-06-13-Towards_Next_Era_of_Multi_objective_Optimization_Large_Language_Models_as_Architects_of_Evolutionary_Operators.html#appendix",
    "href": "posts/Towards_Next_Era_of_Multi_objective_Optimization_Large_Language_Models_as_Architects_of_Evolutionary_Operators/2024-06-13-Towards_Next_Era_of_Multi_objective_Optimization_Large_Language_Models_as_Architects_of_Evolutionary_Operators.html#appendix",
    "title": "Towards Next Era of Multi-objective Optimization: Large Language Models as Architects of Evolutionary Operators",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.08987v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.08987v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8531"
  },
  {
    "objectID": "posts/Generation_and_De_Identification_of_Indian_Clinical_Discharge_Summaries_using_LLMs/2024-07-08-Generation_and_De_Identification_of_Indian_Clinical_Discharge_Summaries_using_LLMs.html#appendix",
    "href": "posts/Generation_and_De_Identification_of_Indian_Clinical_Discharge_Summaries_using_LLMs/2024-07-08-Generation_and_De_Identification_of_Indian_Clinical_Discharge_Summaries_using_LLMs.html#appendix",
    "title": "Generation and De-Identification of Indian Clinical Discharge Summaries using LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05887v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05887v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9455"
  },
  {
    "objectID": "posts/A_Survey_on_Human_Preference_Learning_for_Large_Language_Models/2024-06-18-A_Survey_on_Human_Preference_Learning_for_Large_Language_Models.html#appendix",
    "href": "posts/A_Survey_on_Human_Preference_Learning_for_Large_Language_Models/2024-06-18-A_Survey_on_Human_Preference_Learning_for_Large_Language_Models.html#appendix",
    "title": "A Survey on Human Preference Learning for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11191v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11191v2\n\n\nTruncated\nFalse\n\n\nWord Count\n12234"
  },
  {
    "objectID": "posts/Data_Augmentation_of_Multi_turn_Psychological_Dialogue_via_Knowledge_driven_Progressive_Thought_Prompting/2024-06-24-Data_Augmentation_of_Multi_turn_Psychological_Dialogue_via_Knowledge_driven_Progressive_Thought_Prompting.html#appendix",
    "href": "posts/Data_Augmentation_of_Multi_turn_Psychological_Dialogue_via_Knowledge_driven_Progressive_Thought_Prompting/2024-06-24-Data_Augmentation_of_Multi_turn_Psychological_Dialogue_via_Knowledge_driven_Progressive_Thought_Prompting.html#appendix",
    "title": "Data Augmentation of Multi-turn Psychological Dialogue via Knowledge-driven Progressive Thought Prompting",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16567v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16567v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4719"
  },
  {
    "objectID": "posts/Large_Language_Models_in_Student_Assessment_Comparing_ChatGPT_and_Human_Graders/2024-06-24-Large_Language_Models_in_Student_Assessment_Comparing_ChatGPT_and_Human_Graders.html#appendix",
    "href": "posts/Large_Language_Models_in_Student_Assessment_Comparing_ChatGPT_and_Human_Graders/2024-06-24-Large_Language_Models_in_Student_Assessment_Comparing_ChatGPT_and_Human_Graders.html#appendix",
    "title": "Large Language Models in Student Assessment: Comparing ChatGPT and Human Graders",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16510v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16510v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9017"
  },
  {
    "objectID": "posts/Multilingual_Trolley_Problems_for_Language_Models/2024-07-02-Multilingual_Trolley_Problems_for_Language_Models.html#appendix",
    "href": "posts/Multilingual_Trolley_Problems_for_Language_Models/2024-07-02-Multilingual_Trolley_Problems_for_Language_Models.html#appendix",
    "title": "Multilingual Trolley Problems for Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02273v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02273v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12265"
  },
  {
    "objectID": "posts/Where_Do_Large_Language_Models_Fail_When_Generating_Code/2024-06-13-Where_Do_Large_Language_Models_Fail_When_Generating_Code.html#appendix",
    "href": "posts/Where_Do_Large_Language_Models_Fail_When_Generating_Code/2024-06-13-Where_Do_Large_Language_Models_Fail_When_Generating_Code.html#appendix",
    "title": "Where Do Large Language Models Fail When Generating Code?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.08731v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.08731v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9595"
  },
  {
    "objectID": "posts/ScreenTK_Seamless_Detection_of_Time_Killing_Moments_Using_Continuous_Mobile_Screen_Text_Monitoring/2024-07-03-ScreenTK_Seamless_Detection_of_Time_Killing_Moments_Using_Continuous_Mobile_Screen_Text_Monitoring.html#appendix",
    "href": "posts/ScreenTK_Seamless_Detection_of_Time_Killing_Moments_Using_Continuous_Mobile_Screen_Text_Monitoring/2024-07-03-ScreenTK_Seamless_Detection_of_Time_Killing_Moments_Using_Continuous_Mobile_Screen_Text_Monitoring.html#appendix",
    "title": "ScreenTK: Seamless Detection of Time-Killing Moments Using Continuous Mobile Screen Text Monitoring",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03063v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03063v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3256"
  },
  {
    "objectID": "posts/Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory/2024-06-20-Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory.html",
    "href": "posts/Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory/2024-06-20-Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory.html",
    "title": "Artificial Leviathan: Exploring Social Evolution of LLM Agents Through the Lens of Hobbesian Social Contract Theory",
    "section": "",
    "text": "Summary:\nThe paper presents a novel multi-agent simulation framework that generates believable artificial societies capable of replicating complex human group behaviors and social interactions. The agents’ behaviors are conditioned by their innate psychological drives, intrinsic motivations, and the constraints of their simulated environment. Empirical evidence from systematic experiments establishes correlations between agent attributes and available resources, and the evolutionary trajectories of simulated societies. The analysis discusses the collective behaviors of the generative agents, highlighting the opportunities and potential risks associated with leveraging LLMs for societal simulations.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an innovative approach to simulating complex human group behaviors and social interactions using LLMs. The empirical evidence from systematic experiments supports the correlations between agent attributes and available resources, and the evolutionary trajectories of simulated societies. However, the paper does not address the limitations of LLMs in accurately modeling human behavior, such as the inability to capture the nuances of human emotions and decision-making processes. Additionally, the paper does not discuss the potential biases introduced by the LLMs used in the simulation, which could impact the accuracy of the results. Overall, the paper provides a valuable contribution to the field of computational social science, but further research is needed to address the limitations and biases of LLMs in simulating human behavior."
  },
  {
    "objectID": "posts/Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory/2024-06-20-Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory.html#appendix",
    "href": "posts/Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory/2024-06-20-Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory.html#appendix",
    "title": "Artificial Leviathan: Exploring Social Evolution of LLM Agents Through the Lens of Hobbesian Social Contract Theory",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14373v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14373v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12979"
  },
  {
    "objectID": "posts/Natural_Language_but_Omitted_On_the_Ineffectiveness_of_Large_Language_Models_privacy_policy_from_End_users_Perspective/2024-06-26-Natural_Language_but_Omitted_On_the_Ineffectiveness_of_Large_Language_Models_privacy_policy_from_End_users_Perspective.html#appendix",
    "href": "posts/Natural_Language_but_Omitted_On_the_Ineffectiveness_of_Large_Language_Models_privacy_policy_from_End_users_Perspective/2024-06-26-Natural_Language_but_Omitted_On_the_Ineffectiveness_of_Large_Language_Models_privacy_policy_from_End_users_Perspective.html#appendix",
    "title": "Natural Language but Omitted? On the Ineffectiveness of Large Language Models’ privacy policy from End-users’ Perspective",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18100v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18100v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9590"
  },
  {
    "objectID": "posts/Pelican_Correcting_Hallucination_in_Vision_LLMs_via_Claim_Decomposition_and_Program_of_Thought_Verification/2024-07-02-Pelican_Correcting_Hallucination_in_Vision_LLMs_via_Claim_Decomposition_and_Program_of_Thought_Verification.html#appendix",
    "href": "posts/Pelican_Correcting_Hallucination_in_Vision_LLMs_via_Claim_Decomposition_and_Program_of_Thought_Verification/2024-07-02-Pelican_Correcting_Hallucination_in_Vision_LLMs_via_Claim_Decomposition_and_Program_of_Thought_Verification.html#appendix",
    "title": "Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02352v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02352v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8633"
  },
  {
    "objectID": "posts/Simulating_Classroom_Education_with_LLM_Empowered_Agents/2024-06-27-Simulating_Classroom_Education_with_LLM_Empowered_Agents.html#appendix",
    "href": "posts/Simulating_Classroom_Education_with_LLM_Empowered_Agents/2024-06-27-Simulating_Classroom_Education_with_LLM_Empowered_Agents.html#appendix",
    "title": "Simulating Classroom Education with LLM-Empowered Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19226v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19226v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6252"
  },
  {
    "objectID": "posts/Distilling_System_2_into_System_1/2024-07-08-Distilling_System_2_into_System_1.html#appendix",
    "href": "posts/Distilling_System_2_into_System_1/2024-07-08-Distilling_System_2_into_System_1.html#appendix",
    "title": "Distilling System 2 into System 1",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06023v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06023v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8154"
  },
  {
    "objectID": "posts/Improving_Multilingual_Instruction_Finetuning_via_Linguistically_Natural_and_Diverse_Datasets/2024-07-01-Improving_Multilingual_Instruction_Finetuning_via_Linguistically_Natural_and_Diverse_Datasets.html#appendix",
    "href": "posts/Improving_Multilingual_Instruction_Finetuning_via_Linguistically_Natural_and_Diverse_Datasets/2024-07-01-Improving_Multilingual_Instruction_Finetuning_via_Linguistically_Natural_and_Diverse_Datasets.html#appendix",
    "title": "Improving Multilingual Instruction Finetuning via Linguistically Natural and Diverse Datasets",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01853v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01853v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6194"
  },
  {
    "objectID": "posts/RePrompt_Planning_by_Automatic_Prompt_Engineering_for_Large_Language_Models_Agents/2024-06-17-RePrompt_Planning_by_Automatic_Prompt_Engineering_for_Large_Language_Models_Agents.html#appendix",
    "href": "posts/RePrompt_Planning_by_Automatic_Prompt_Engineering_for_Large_Language_Models_Agents/2024-06-17-RePrompt_Planning_by_Automatic_Prompt_Engineering_for_Large_Language_Models_Agents.html#appendix",
    "title": "RePrompt: Planning by Automatic Prompt Engineering for Large Language Models Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11132v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11132v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9868"
  },
  {
    "objectID": "posts/LIT_Large_Language_Model_Driven_Intention_Tracking_for_Proactive_Human_Robot_Collaboration____A_Robot_Sous_Chef_Application/2024-06-19-LIT_Large_Language_Model_Driven_Intention_Tracking_for_Proactive_Human_Robot_Collaboration____A_Robot_Sous_Chef_Application.html#appendix",
    "href": "posts/LIT_Large_Language_Model_Driven_Intention_Tracking_for_Proactive_Human_Robot_Collaboration____A_Robot_Sous_Chef_Application/2024-06-19-LIT_Large_Language_Model_Driven_Intention_Tracking_for_Proactive_Human_Robot_Collaboration____A_Robot_Sous_Chef_Application.html#appendix",
    "title": "LIT: Large Language Model Driven Intention Tracking for Proactive Human-Robot Collaboration – A Robot Sous-Chef Application",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13787v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13787v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3696"
  },
  {
    "objectID": "posts/Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models/2024-06-17-Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models.html",
    "href": "posts/Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models/2024-06-17-Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models.html",
    "title": "Long Code Arena: a Set of Benchmarks for Long-Context Code Models",
    "section": "",
    "text": "Summary:\nThe paper introduces Long Code Arena, a suite of six benchmarks for code processing tasks that require project-wide context. These tasks include library-based code generation, CI builds repair, project-level code completion, commit message generation, bug localization, and module summarization. The paper highlights the limitations of existing ML4SE benchmarks, such as short context length and limited resemblance to practical use cases. Long Code Arena aims to address these issues by providing manually verified datasets, evaluation suites, and open-source baseline solutions based on popular LLMs. The benchmark page, leaderboard, and links to datasets are available on HuggingFace Spaces.\nMajor Findings:"
  },
  {
    "objectID": "posts/Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models/2024-06-17-Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models.html#appendix",
    "href": "posts/Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models/2024-06-17-Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models.html#appendix",
    "title": "Long Code Arena: a Set of Benchmarks for Long-Context Code Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11612v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11612v1\n\n\nTruncated\nTrue\n\n\nWord Count\n31007"
  },
  {
    "objectID": "posts/Sparser_is_Faster_and_Less_is_More_Efficient_Sparse_Attention_for_Long_Range_Transformers/2024-06-24-Sparser_is_Faster_and_Less_is_More_Efficient_Sparse_Attention_for_Long_Range_Transformers.html",
    "href": "posts/Sparser_is_Faster_and_Less_is_More_Efficient_Sparse_Attention_for_Long_Range_Transformers/2024-06-24-Sparser_is_Faster_and_Less_is_More_Efficient_Sparse_Attention_for_Long_Range_Transformers.html",
    "title": "Sparser is Faster and Less is More: Efficient Sparse Attention for Long-Range Transformers",
    "section": "",
    "text": "Summary:\nThe paper introduces SparseK Attention, a novel sparse attention mechanism designed to overcome computational and memory obstacles in long-range Transformer computing. This approach integrates a scoring network and a differentiable top-k mask operator, SparseK, to select a constant number of KV pairs for each query, enabling gradient-based optimization. SparseK Attention offers linear time complexity and constant memory footprint during generation. Experimental results reveal that SparseK Attention outperforms previous sparse attention methods and provides significant speed improvements during both training and inference, particularly in language modeling and downstream tasks. The method can be seamlessly integrated into pre-trained Large Language Models (LLMs) with minimal fine-tuning, offering a practical solution for effectively managing long-range dependencies in diverse applications.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a promising approach to addressing the computational and memory challenges in long-range Transformer computing. The proposed SparseK Attention mechanism offers a practical solution for managing long-range dependencies in diverse applications. However, the paper does not discuss potential limitations or biases that may arise from the use of this method. Additionally, the method’s performance on different types of data and tasks, as well as its generalizability, are not thoroughly evaluated. Further research is needed to explore these aspects and ensure the robustness and applicability of the SparseK Attention mechanism."
  },
  {
    "objectID": "posts/Sparser_is_Faster_and_Less_is_More_Efficient_Sparse_Attention_for_Long_Range_Transformers/2024-06-24-Sparser_is_Faster_and_Less_is_More_Efficient_Sparse_Attention_for_Long_Range_Transformers.html#appendix",
    "href": "posts/Sparser_is_Faster_and_Less_is_More_Efficient_Sparse_Attention_for_Long_Range_Transformers/2024-06-24-Sparser_is_Faster_and_Less_is_More_Efficient_Sparse_Attention_for_Long_Range_Transformers.html#appendix",
    "title": "Sparser is Faster and Less is More: Efficient Sparse Attention for Long-Range Transformers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16747v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16747v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9535"
  },
  {
    "objectID": "posts/Multi_Agent_Software_Development_through_Cross_Team_Collaboration/2024-06-13-Multi_Agent_Software_Development_through_Cross_Team_Collaboration.html#appendix",
    "href": "posts/Multi_Agent_Software_Development_through_Cross_Team_Collaboration/2024-06-13-Multi_Agent_Software_Development_through_Cross_Team_Collaboration.html#appendix",
    "title": "Multi-Agent Software Development through Cross-Team Collaboration",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.08979v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.08979v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8963"
  },
  {
    "objectID": "posts/Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study/2024-07-02-Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study.html",
    "href": "posts/Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study/2024-07-02-Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study.html",
    "title": "Understanding Alignment in Multimodal LLMs: A Comprehensive Study",
    "section": "",
    "text": "Summary: This academic article focuses on the challenges of hallucination in Multimodal Large Language Models (MLLMs) and the importance of alignment in MLLMs to produce responses more closely aligned with image information. The authors introduce a novel technique called Bias-Driven Hallucination Sampling (BDHS) to address the shortcomings of previous methods. BDHS limits access in the latent space via attention masking, which more directly achieves the underlying motivation of triggering the inherent bias of the underlying language model. The study also introduces a new derivative called MMHALBench-V, which incorporates GPT-4o to provide input images as additional context for evaluating model capabilities. The results of ablation experiments for BDHS show that all BDHS ablations significantly improve performance on LLaVABench-in-the-Wild compared to the DPO baseline and POVID-style"
  },
  {
    "objectID": "posts/Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study/2024-07-02-Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study.html#appendix",
    "href": "posts/Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study/2024-07-02-Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study.html#appendix",
    "title": "Understanding Alignment in Multimodal LLMs: A Comprehensive Study",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02477v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02477v1\n\n\nTruncated\nTrue\n\n\nWord Count\n29846"
  },
  {
    "objectID": "posts/Limited_Out_of_Context_Knowledge_Reasoning_in_Large_Language_Models/2024-06-11-Limited_Out_of_Context_Knowledge_Reasoning_in_Large_Language_Models.html#appendix",
    "href": "posts/Limited_Out_of_Context_Knowledge_Reasoning_in_Large_Language_Models/2024-06-11-Limited_Out_of_Context_Knowledge_Reasoning_in_Large_Language_Models.html#appendix",
    "title": "Limited Out-of-Context Knowledge Reasoning in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07393v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07393v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5931"
  },
  {
    "objectID": "posts/Towards_Detecting_LLMs_Hallucination_via_Markov_Chain_based_Multi_agent_Debate_Framework/2024-06-05-Towards_Detecting_LLMs_Hallucination_via_Markov_Chain_based_Multi_agent_Debate_Framework.html#appendix",
    "href": "posts/Towards_Detecting_LLMs_Hallucination_via_Markov_Chain_based_Multi_agent_Debate_Framework/2024-06-05-Towards_Detecting_LLMs_Hallucination_via_Markov_Chain_based_Multi_agent_Debate_Framework.html#appendix",
    "title": "Towards Detecting LLMs Hallucination via Markov Chain-based Multi-agent Debate Framework",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03075v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03075v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5918"
  },
  {
    "objectID": "posts/LLaMAX_Scaling_Linguistic_Horizons_of_LLM_by_Enhancing_Translation_Capabilities_Beyond_100_Languages/2024-07-08-LLaMAX_Scaling_Linguistic_Horizons_of_LLM_by_Enhancing_Translation_Capabilities_Beyond_100_Languages.html#appendix",
    "href": "posts/LLaMAX_Scaling_Linguistic_Horizons_of_LLM_by_Enhancing_Translation_Capabilities_Beyond_100_Languages/2024-07-08-LLaMAX_Scaling_Linguistic_Horizons_of_LLM_by_Enhancing_Translation_Capabilities_Beyond_100_Languages.html#appendix",
    "title": "LLaMAX: Scaling Linguistic Horizons of LLM by Enhancing Translation Capabilities Beyond 100 Languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05975v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05975v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10244"
  },
  {
    "objectID": "posts/Large_Language_Models_Memorize_Sensor_Datasets!_Implications_on_Human_Activity_Recognition_Research/2024-06-09-Large_Language_Models_Memorize_Sensor_Datasets!_Implications_on_Human_Activity_Recognition_Research.html#appendix",
    "href": "posts/Large_Language_Models_Memorize_Sensor_Datasets!_Implications_on_Human_Activity_Recognition_Research/2024-06-09-Large_Language_Models_Memorize_Sensor_Datasets!_Implications_on_Human_Activity_Recognition_Research.html#appendix",
    "title": "Large Language Models Memorize Sensor Datasets! Implications on Human Activity Recognition Research",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05900v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05900v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6787"
  },
  {
    "objectID": "posts/The_current_status_of_large_language_models_in_summarizing_radiology_report_impressions/2024-06-04-The_current_status_of_large_language_models_in_summarizing_radiology_report_impressions.html#appendix",
    "href": "posts/The_current_status_of_large_language_models_in_summarizing_radiology_report_impressions/2024-06-04-The_current_status_of_large_language_models_in_summarizing_radiology_report_impressions.html#appendix",
    "title": "The current status of large language models in summarizing radiology report impressions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02134v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02134v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7591"
  },
  {
    "objectID": "posts/Advancing_Tool_Augmented_Large_Language_Models_Integrating_Insights_from_Errors_in_Inference_Trees/2024-06-11-Advancing_Tool_Augmented_Large_Language_Models_Integrating_Insights_from_Errors_in_Inference_Trees.html#appendix",
    "href": "posts/Advancing_Tool_Augmented_Large_Language_Models_Integrating_Insights_from_Errors_in_Inference_Trees/2024-06-11-Advancing_Tool_Augmented_Large_Language_Models_Integrating_Insights_from_Errors_in_Inference_Trees.html#appendix",
    "title": "Advancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07115v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07115v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6467"
  },
  {
    "objectID": "posts/OPTune_Efficient_Online_Preference_Tuning/2024-06-11-OPTune_Efficient_Online_Preference_Tuning.html#appendix",
    "href": "posts/OPTune_Efficient_Online_Preference_Tuning/2024-06-11-OPTune_Efficient_Online_Preference_Tuning.html#appendix",
    "title": "OPTune: Efficient Online Preference Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07657v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07657v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7692"
  },
  {
    "objectID": "posts/AssertionBench_A_Benchmark_to_Evaluate_Large_Language_Models_for_Assertion_Generation/2024-06-26-AssertionBench_A_Benchmark_to_Evaluate_Large_Language_Models_for_Assertion_Generation.html#appendix",
    "href": "posts/AssertionBench_A_Benchmark_to_Evaluate_Large_Language_Models_for_Assertion_Generation/2024-06-26-AssertionBench_A_Benchmark_to_Evaluate_Large_Language_Models_for_Assertion_Generation.html#appendix",
    "title": "AssertionBench: A Benchmark to Evaluate Large-Language Models for Assertion Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18627v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18627v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6426"
  },
  {
    "objectID": "posts/Faux_Polyglot_A_Study_on_Information_Disparity_in_Multilingual_Large_Language_Models/2024-07-07-Faux_Polyglot_A_Study_on_Information_Disparity_in_Multilingual_Large_Language_Models.html#appendix",
    "href": "posts/Faux_Polyglot_A_Study_on_Information_Disparity_in_Multilingual_Large_Language_Models/2024-07-07-Faux_Polyglot_A_Study_on_Information_Disparity_in_Multilingual_Large_Language_Models.html#appendix",
    "title": "Faux Polyglot: A Study on Information Disparity in Multilingual Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05502v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05502v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8494"
  },
  {
    "objectID": "posts/LLM_enhanced_Reranking_in_Recommender_Systems/2024-06-18-LLM_enhanced_Reranking_in_Recommender_Systems.html#appendix",
    "href": "posts/LLM_enhanced_Reranking_in_Recommender_Systems/2024-06-18-LLM_enhanced_Reranking_in_Recommender_Systems.html#appendix",
    "title": "LLM-enhanced Reranking in Recommender Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12433v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12433v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8439"
  },
  {
    "objectID": "posts/Serial_Position_Effects_of_Large_Language_Models/2024-06-23-Serial_Position_Effects_of_Large_Language_Models.html#appendix",
    "href": "posts/Serial_Position_Effects_of_Large_Language_Models/2024-06-23-Serial_Position_Effects_of_Large_Language_Models.html#appendix",
    "title": "Serial Position Effects of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.15981v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.15981v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10164"
  },
  {
    "objectID": "posts/VAIYAKARANA__A_Benchmark_for_Automatic_Grammar_Correction_in_Bangla/2024-06-20-VAIYAKARANA__A_Benchmark_for_Automatic_Grammar_Correction_in_Bangla.html",
    "href": "posts/VAIYAKARANA__A_Benchmark_for_Automatic_Grammar_Correction_in_Bangla/2024-06-20-VAIYAKARANA__A_Benchmark_for_Automatic_Grammar_Correction_in_Bangla.html",
    "title": "VAIYAKARANA : A Benchmark for Automatic Grammar Correction in Bangla",
    "section": "",
    "text": "Summary:\nThe paper titled “VAIYAKARANA: A Benchmark for Automatic Grammar Correction in Bangla” by Pramit Bhattacharyya and Arnab Bhattacharya proposes a pragmatic approach to generate grammatically incorrect sentences in Bangla. The authors categorize the different kinds of errors in Bangla into 5 broad classes and 12 finer classes. They then use these categories to generate erroneous sentences systematically from a correct sentence. This approach can generate a large number of wrong sentences, which can be used to train neural networks. The authors also provide a dataset, Vaiyākaraṇa, consisting of 92,830 grammatically incorrect sentences and 18,426 correct sentences. They also collected 619 human-generated sentences from essays written by Bangla native speakers. The authors evaluate their corpus against neural models and LLMs and benchmark it against human evaluators, who are native speakers of Bangla. The analysis shows that native speakers are far more accurate than state-of-the-art models to detect whether a sentence is grammatically correct. However, even native speakers find it difficult to categorize the type of error. This shows the efficacy of the Vaiyākaraṇa corpus. The methodology of generating erroneous sentences can be applied for most other Indian languages as well.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel approach to generate grammatically incorrect sentences in"
  },
  {
    "objectID": "posts/VAIYAKARANA__A_Benchmark_for_Automatic_Grammar_Correction_in_Bangla/2024-06-20-VAIYAKARANA__A_Benchmark_for_Automatic_Grammar_Correction_in_Bangla.html#appendix",
    "href": "posts/VAIYAKARANA__A_Benchmark_for_Automatic_Grammar_Correction_in_Bangla/2024-06-20-VAIYAKARANA__A_Benchmark_for_Automatic_Grammar_Correction_in_Bangla.html#appendix",
    "title": "VAIYAKARANA : A Benchmark for Automatic Grammar Correction in Bangla",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14284v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14284v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20042"
  },
  {
    "objectID": "posts/Whats_Wrong_with_Your_Code_Generated_by_Large_Language_Models_An_Extensive_Study/2024-07-08-Whats_Wrong_with_Your_Code_Generated_by_Large_Language_Models_An_Extensive_Study.html#appendix",
    "href": "posts/Whats_Wrong_with_Your_Code_Generated_by_Large_Language_Models_An_Extensive_Study/2024-07-08-Whats_Wrong_with_Your_Code_Generated_by_Large_Language_Models_An_Extensive_Study.html#appendix",
    "title": "What’s Wrong with Your Code Generated by Large Language Models? An Extensive Study",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06153v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06153v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14163"
  },
  {
    "objectID": "posts/CodeNav_Beyond_tool_use_to_using_real_world_codebases_with_LLM_agents/2024-06-18-CodeNav_Beyond_tool_use_to_using_real_world_codebases_with_LLM_agents.html#appendix",
    "href": "posts/CodeNav_Beyond_tool_use_to_using_real_world_codebases_with_LLM_agents/2024-06-18-CodeNav_Beyond_tool_use_to_using_real_world_codebases_with_LLM_agents.html#appendix",
    "title": "CodeNav: Beyond tool-use to using real-world codebases with LLM agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12276v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12276v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10119"
  },
  {
    "objectID": "posts/Exploring_the_Capabilities_of_LLMs_for_Code_Change_Related_Tasks/2024-07-03-Exploring_the_Capabilities_of_LLMs_for_Code_Change_Related_Tasks.html#appendix",
    "href": "posts/Exploring_the_Capabilities_of_LLMs_for_Code_Change_Related_Tasks/2024-07-03-Exploring_the_Capabilities_of_LLMs_for_Code_Change_Related_Tasks.html#appendix",
    "title": "Exploring the Capabilities of LLMs for Code Change Related Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02824v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02824v1\n\n\nTruncated\nFalse\n\n\nWord Count\n16271"
  },
  {
    "objectID": "posts/Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems/2024-06-18-Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems.html",
    "href": "posts/Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems/2024-06-18-Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems.html",
    "title": "Navigating the Labyrinth: Evaluating and Enhancing LLMs’ Ability to Reason About Search Problems",
    "section": "",
    "text": "Summary:\nThe paper introduces a new benchmark, SearchBench, to evaluate the reasoning abilities of Large Language Models (LLMs) on search problems. SearchBench consists of 11 unique search problems, each with automated pipelines for generating instances and analyzing solutions. The authors demonstrate that even advanced LLMs struggle with these problems, with GPT4 solving only 1.4% end-to-end in text. The paper proposes in-context learning with A* algorithm implementations and a Multi-Stage-Multi-Try (MSMT) method to enhance performance, raising GPT-4’s performance above 57%.\nKey Terminology:\nMajor Findings:"
  },
  {
    "objectID": "posts/Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems/2024-06-18-Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems.html#appendix",
    "href": "posts/Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems/2024-06-18-Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems.html#appendix",
    "title": "Navigating the Labyrinth: Evaluating and Enhancing LLMs’ Ability to Reason About Search Problems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12172v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12172v1\n\n\nTruncated\nTrue\n\n\nWord Count\n72494"
  },
  {
    "objectID": "posts/Talking_to_Machines_do_you_read_me/2024-07-02-Talking_to_Machines_do_you_read_me.html",
    "href": "posts/Talking_to_Machines_do_you_read_me/2024-07-02-Talking_to_Machines_do_you_read_me.html",
    "title": "Talking to Machines: do you read me?",
    "section": "",
    "text": "Summary:\nThis academic paper provides an overview of the research on dialogue systems, focusing on the contributions of Lina María Rojas Barahona. The author discusses her work on task-oriented dialogues and conversational question answering, as well as her role as an industrial supervisor for four PhD theses. The paper also briefly reviews the state of the art in conversational agents and highlights open research problems. The author emphasizes the progress made in dialogue systems since the introduction of Eliza, the automated psychoanalyst, in 1966. She notes that while early systems were limited by poor understanding and lack of expressivity, recent advances in deep learning and data-driven techniques have led to promising results in creating artificial agents capable of conversing with humans.\nThe paper explores various aspects of dialogue systems, including the use of Partially Observable Markov Decision Processes (POMDPs) in spoken dialogue systems, Machine Learning (ML)"
  },
  {
    "objectID": "posts/Talking_to_Machines_do_you_read_me/2024-07-02-Talking_to_Machines_do_you_read_me.html#appendix",
    "href": "posts/Talking_to_Machines_do_you_read_me/2024-07-02-Talking_to_Machines_do_you_read_me.html#appendix",
    "title": "Talking to Machines: do you read me?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02354v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02354v1\n\n\nTruncated\nTrue\n\n\nWord Count\n44116"
  },
  {
    "objectID": "posts/Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models/2024-07-08-Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models.html#major-findings",
    "href": "posts/Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models/2024-07-08-Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models.html#major-findings",
    "title": "Merge, Ensemble, and Cooperate! A Survey on Collaborative Strategies in the Era of Large Language Models",
    "section": "Major Findings",
    "text": "Major Findings\n\nMerging: This approach integrates the parameters of multiple LLMs into a single, unified model, requiring that the parameters are compatible within a linear space. Merging methods are tailored to be more suitable for LLMs, effectively leveraging the collaborative advantages of diverse LLMs.\nEnsemble: Ensemble methods focus on combining the outputs generated by various LLMs to produce coherent results, with less emphasis on the parameters of the individual models. These methods are derived from traditional fusion techniques commonly explored in machine learning.\nCooperation: Cooperation extends beyond merging and ensemble, focusing on cooperative methods that harness the diverse strengths of LLMs to achieve specific objectives. These techniques expand the methodologies for model collaboration, holding significant research importance for LLMs."
  },
  {
    "objectID": "posts/Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models/2024-07-08-Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models/2024-07-08-Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models.html#analysis-and-critique",
    "title": "Merge, Ensemble, and Cooperate! A Survey on Collaborative Strategies in the Era of Large Language Models",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\nThe paper provides a well-structured and coherent summary of the emerging research area of collaboration strategies for LLMs. The authors’ categorization of these strategies into Merging, Ensemble, and Cooperation offers a clear understanding of their respective frameworks and applications.\nHowever, the paper does not discuss the potential limitations, unanswered questions, or biases that may be apparent while reviewing the text. Additionally, the paper does not address any methodological issues, conflicting evidence, or areas that require further research or clarification.\nIn conclusion, the paper serves as a valuable resource for understanding the strategies and methodologies for collaborative efforts among LLMs. However, it would benefit from a more critical analysis of the discussed topics, addressing potential limitations and areas for further research."
  },
  {
    "objectID": "posts/Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models/2024-07-08-Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models.html#appendix",
    "href": "posts/Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models/2024-07-08-Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models.html#appendix",
    "title": "Merge, Ensemble, and Cooperate! A Survey on Collaborative Strategies in the Era of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06089v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06089v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14228"
  },
  {
    "objectID": "posts/Large_language_models_for_generating_rules_yay_or_nay/2024-06-10-Large_language_models_for_generating_rules_yay_or_nay.html#appendix",
    "href": "posts/Large_language_models_for_generating_rules_yay_or_nay/2024-06-10-Large_language_models_for_generating_rules_yay_or_nay.html#appendix",
    "title": "Large language models for generating rules, yay or nay?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06835v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06835v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4575"
  },
  {
    "objectID": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#major-findings",
    "href": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#major-findings",
    "title": "McEval: Massively Multilingual Code Evaluation",
    "section": "Major Findings",
    "text": "Major Findings\n\nMcEval is the first massively multilingual code evaluation benchmark, covering 40 programming languages with 16K test samples.\nThe benchmark includes challenging code completion, understanding, and generation evaluation tasks with finely curated multilingual instruction corpora McEval-Instruct.\nThe authors introduce an effective multilingual coder mCoder trained on McEval-Instruct to support multilingual programming language generation."
  },
  {
    "objectID": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#analysis-and-critique",
    "href": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#analysis-and-critique",
    "title": "McEval: Massively Multilingual Code Evaluation",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\n\nThe paper does not provide a detailed comparison of McEval with existing benchmarks, making it difficult to assess its advantages and limitations.\nThe paper does not discuss the potential biases in the data used for training mCoder, which could impact its performance on certain tasks or languages.\nThe paper does not provide a detailed analysis of the performance of mCoder on different tasks and languages, making it difficult to assess its strengths and weaknesses.\nThe paper does not discuss the potential applications of McEval and mCoder in real-world software development scenarios.\nThe paper does not discuss the potential ethical implications of using mCoder for code generation, such as the risk of generating code that violates software licenses or copyright laws."
  },
  {
    "objectID": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#appendix",
    "href": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#appendix",
    "title": "McEval: Massively Multilingual Code Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07436v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07436v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7788"
  },
  {
    "objectID": "posts/PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models/2024-06-27-PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models.html#major-findings",
    "href": "posts/PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models/2024-06-27-PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models.html#major-findings",
    "title": "PhysioLLM: Supporting Personalized Health Insights with Wearables and Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nImproved Understanding of Health Data: PhysioLLM outperforms both the Fitbit App alone and a generic LLM chatbot in facilitating a deeper, personalized understanding of health data.\nPersonalized Insights: The system provides effective personalized insights using an LLM architecture, which improves one’s understanding of their own health.\nActionable Steps Toward Personal Health Goals: The interface is perceived as more personalized than chatting with a generic LLM-based chatbot, and it results in users having more motivation to change and their goals being found to be more actionable."
  },
  {
    "objectID": "posts/PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models/2024-06-27-PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models/2024-06-27-PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models.html#analysis-and-critique",
    "title": "PhysioLLM: Supporting Personalized Health Insights with Wearables and Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nLimited Expert Health Knowledge: The system uses an off-the-shelf, general-purpose LLM, which has limited expert health knowledge. Integrations of fine-tuned specialized LLMs with the system will further improve the quality of the insights.\nHandling Randomness and Unknowns: The system has limitations in handling the randomness and unknowns in the data and contexts. However, its adaptability ensures beneficial and personalized suggestions.\nPotential for Positive Behavior Change: Anecdotal evidence suggests that the system has the potential to nudge people towards positive behavior change, which merits further study.\nPrivacy and Ethical Considerations: The system has embedded counter-action prompts to prevent abusive uses, but further tests on the robustness of the safety prompt are needed. The system should acknowledge its limitations and ensure that no raw data is sent to the LLM, and all data and survey results are de-identified.\n**Broader User"
  },
  {
    "objectID": "posts/PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models/2024-06-27-PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models.html#appendix",
    "href": "posts/PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models/2024-06-27-PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models.html#appendix",
    "title": "PhysioLLM: Supporting Personalized Health Insights with Wearables and Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19283v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19283v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7356"
  },
  {
    "objectID": "posts/Enhancing_Hallucination_Detection_through_Perturbation_Based_Synthetic_Data_Generation_in_System_Responses/2024-07-07-Enhancing_Hallucination_Detection_through_Perturbation_Based_Synthetic_Data_Generation_in_System_Responses.html#appendix",
    "href": "posts/Enhancing_Hallucination_Detection_through_Perturbation_Based_Synthetic_Data_Generation_in_System_Responses/2024-07-07-Enhancing_Hallucination_Detection_through_Perturbation_Based_Synthetic_Data_Generation_in_System_Responses.html#appendix",
    "title": "Enhancing Hallucination Detection through Perturbation-Based Synthetic Data Generation in System Responses",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05474v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05474v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5380"
  },
  {
    "objectID": "posts/SLMRec_Empowering_Small_Language_Models_for_Sequential_Recommendation/2024-05-28-SLMRec_Empowering_Small_Language_Models_for_Sequential_Recommendation.html#appendix",
    "href": "posts/SLMRec_Empowering_Small_Language_Models_for_Sequential_Recommendation/2024-05-28-SLMRec_Empowering_Small_Language_Models_for_Sequential_Recommendation.html#appendix",
    "title": "SLMRec: Empowering Small Language Models for Sequential Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.17890v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.17890v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6690"
  },
  {
    "objectID": "posts/Sonnet_or_Not_Bot_Poetry_Evaluation_for_Large_Models_and_Datasets/2024-06-27-Sonnet_or_Not_Bot_Poetry_Evaluation_for_Large_Models_and_Datasets.html#appendix",
    "href": "posts/Sonnet_or_Not_Bot_Poetry_Evaluation_for_Large_Models_and_Datasets/2024-06-27-Sonnet_or_Not_Bot_Poetry_Evaluation_for_Large_Models_and_Datasets.html#appendix",
    "title": "Sonnet or Not, Bot? Poetry Evaluation for Large Models and Datasets",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18906v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18906v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3809"
  },
  {
    "objectID": "posts/Contrastive_Policy_Gradient_Aligning_LLMs_on_sequence_level_scores_in_a_supervised_friendly_fashion/2024-06-27-Contrastive_Policy_Gradient_Aligning_LLMs_on_sequence_level_scores_in_a_supervised_friendly_fashion.html#appendix",
    "href": "posts/Contrastive_Policy_Gradient_Aligning_LLMs_on_sequence_level_scores_in_a_supervised_friendly_fashion/2024-06-27-Contrastive_Policy_Gradient_Aligning_LLMs_on_sequence_level_scores_in_a_supervised_friendly_fashion.html#appendix",
    "title": "Contrastive Policy Gradient: Aligning LLMs on sequence-level scores in a supervised-friendly fashion",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19185v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19185v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8271"
  },
  {
    "objectID": "posts/LLMs_for_User_Interest_Exploration_A_Hybrid_Approach/2024-05-25-LLMs_for_User_Interest_Exploration_A_Hybrid_Approach.html#appendix",
    "href": "posts/LLMs_for_User_Interest_Exploration_A_Hybrid_Approach/2024-05-25-LLMs_for_User_Interest_Exploration_A_Hybrid_Approach.html#appendix",
    "title": "LLMs for User Interest Exploration: A Hybrid Approach",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.16363v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.16363v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5005"
  },
  {
    "objectID": "posts/Advancing_Annotation_of_Stance_in_Social_Media_Posts_A_Comparative_Analysis_of_Large_Language_Models_and_Crowd_Sourcing/2024-06-11-Advancing_Annotation_of_Stance_in_Social_Media_Posts_A_Comparative_Analysis_of_Large_Language_Models_and_Crowd_Sourcing.html#appendix",
    "href": "posts/Advancing_Annotation_of_Stance_in_Social_Media_Posts_A_Comparative_Analysis_of_Large_Language_Models_and_Crowd_Sourcing/2024-06-11-Advancing_Annotation_of_Stance_in_Social_Media_Posts_A_Comparative_Analysis_of_Large_Language_Models_and_Crowd_Sourcing.html#appendix",
    "title": "Advancing Annotation of Stance in Social Media Posts: A Comparative Analysis of Large Language Models and Crowd Sourcing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07483v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07483v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7463"
  },
  {
    "objectID": "posts/Exploring_Mathematical_Extrapolation_of_Large_Language_Models_with_Synthetic_Data/2024-06-04-Exploring_Mathematical_Extrapolation_of_Large_Language_Models_with_Synthetic_Data.html#appendix",
    "href": "posts/Exploring_Mathematical_Extrapolation_of_Large_Language_Models_with_Synthetic_Data/2024-06-04-Exploring_Mathematical_Extrapolation_of_Large_Language_Models_with_Synthetic_Data.html#appendix",
    "title": "Exploring Mathematical Extrapolation of Large Language Models with Synthetic Data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02100v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02100v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3993"
  },
  {
    "objectID": "posts/Selective_Prompting_Tuning_for_Personalized_Conversations_with_LLMs/2024-06-26-Selective_Prompting_Tuning_for_Personalized_Conversations_with_LLMs.html#appendix",
    "href": "posts/Selective_Prompting_Tuning_for_Personalized_Conversations_with_LLMs/2024-06-26-Selective_Prompting_Tuning_for_Personalized_Conversations_with_LLMs.html#appendix",
    "title": "Selective Prompting Tuning for Personalized Conversations with LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18187v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18187v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8201"
  },
  {
    "objectID": "posts/In_Context_Learning_and_Fine_Tuning_GPT_for_Argument_Mining/2024-06-10-In_Context_Learning_and_Fine_Tuning_GPT_for_Argument_Mining.html#appendix",
    "href": "posts/In_Context_Learning_and_Fine_Tuning_GPT_for_Argument_Mining/2024-06-10-In_Context_Learning_and_Fine_Tuning_GPT_for_Argument_Mining.html#appendix",
    "title": "In-Context Learning and Fine-Tuning GPT for Argument Mining",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06699v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06699v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2590"
  },
  {
    "objectID": "posts/MG_Verilog_Multi_grained_Dataset_Towards_Enhanced_LLM_assisted_Verilog_Generation/2024-07-03-MG_Verilog_Multi_grained_Dataset_Towards_Enhanced_LLM_assisted_Verilog_Generation.html#appendix",
    "href": "posts/MG_Verilog_Multi_grained_Dataset_Towards_Enhanced_LLM_assisted_Verilog_Generation/2024-07-03-MG_Verilog_Multi_grained_Dataset_Towards_Enhanced_LLM_assisted_Verilog_Generation.html#appendix",
    "title": "MG-Verilog: Multi-grained Dataset Towards Enhanced LLM-assisted Verilog Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01910v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01910v2\n\n\nTruncated\nFalse\n\n\nWord Count\n3899"
  },
  {
    "objectID": "posts/CREF_An_LLM_based_Conversational_Software_Repair_Framework_for_Programming_Tutors/2024-06-20-CREF_An_LLM_based_Conversational_Software_Repair_Framework_for_Programming_Tutors.html#appendix",
    "href": "posts/CREF_An_LLM_based_Conversational_Software_Repair_Framework_for_Programming_Tutors/2024-06-20-CREF_An_LLM_based_Conversational_Software_Repair_Framework_for_Programming_Tutors.html#appendix",
    "title": "CREF: An LLM-based Conversational Software Repair Framework for Programming Tutors",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13972v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13972v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12780"
  },
  {
    "objectID": "posts/LLM_Based_Open_Domain_Integrated_Task_and_Knowledge_Assistants_with_Programmable_Policies/2024-07-08-LLM_Based_Open_Domain_Integrated_Task_and_Knowledge_Assistants_with_Programmable_Policies.html",
    "href": "posts/LLM_Based_Open_Domain_Integrated_Task_and_Knowledge_Assistants_with_Programmable_Policies/2024-07-08-LLM_Based_Open_Domain_Integrated_Task_and_Knowledge_Assistants_with_Programmable_Policies.html",
    "title": "LLM-Based Open-Domain Integrated Task and Knowledge Assistants with Programmable Policies",
    "section": "",
    "text": "Summary:\nThe paper presents KITA, a programmable framework for creating task-oriented conversational agents that can handle complex user interactions. Unlike traditional dialogue trees, KITA provides reliable grounded responses and controllable agent policies through its expressive specification, KITA Worksheet. The authors conducted a real-user study involving 62 participants, demonstrating that KITA outperforms the GPT-4 with function calling baseline by 26.1, 22.5, and 52.4 points on execution accuracy, dialogue act accuracy, and goal completion rate, respectively.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel approach to creating task-oriented conversational agents that can handle complex user interactions. The use of KITA Worksheet as an expressive specification for agent policies is a significant contribution, as it allows for more control and flexibility in designing conversational agents. The real-user study demonstrates the effectiveness of KITA in handling complex user interactions and outperforming existing methods.\nHowever, the paper does not provide a detailed comparison with other programmable frameworks for creating task-oriented conversational agents. Additionally, the authors do not discuss the limitations of KITA or potential biases that may arise from using the framework. The paper also does not provide a clear explanation of how KITA handles ambiguity in user inputs or how it adapts to changes in user behavior over time.\nOverall, the paper presents a promising approach to creating task-oriented conversational agents that can handle complex user interactions. However, further research is needed to compare KITA with other programmable frameworks and to address potential limitations and biases in the framework."
  },
  {
    "objectID": "posts/LLM_Based_Open_Domain_Integrated_Task_and_Knowledge_Assistants_with_Programmable_Policies/2024-07-08-LLM_Based_Open_Domain_Integrated_Task_and_Knowledge_Assistants_with_Programmable_Policies.html#appendix",
    "href": "posts/LLM_Based_Open_Domain_Integrated_Task_and_Knowledge_Assistants_with_Programmable_Policies/2024-07-08-LLM_Based_Open_Domain_Integrated_Task_and_Knowledge_Assistants_with_Programmable_Policies.html#appendix",
    "title": "LLM-Based Open-Domain Integrated Task and Knowledge Assistants with Programmable Policies",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05674v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05674v1\n\n\nTruncated\nFalse\n\n\nWord Count\n23690"
  },
  {
    "objectID": "posts/Fundamental_Problems_With_Model_Editing_How_Should_Rational_Belief_Revision_Work_in_LLMs/2024-06-27-Fundamental_Problems_With_Model_Editing_How_Should_Rational_Belief_Revision_Work_in_LLMs.html",
    "href": "posts/Fundamental_Problems_With_Model_Editing_How_Should_Rational_Belief_Revision_Work_in_LLMs/2024-06-27-Fundamental_Problems_With_Model_Editing_How_Should_Rational_Belief_Revision_Work_in_LLMs.html",
    "title": "Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?",
    "section": "",
    "text": "Summary:\nThe paper critiques the predominant formulation of the model editing problem and proposes a semi-synthetic setting for evaluating model editing. The authors present 12 open challenges, summarized in three categories: (1) challenges with defining the model editing problem, (2) challenges with developing benchmarks, and (3) challenges with assuming LLMs have editable beliefs. The paper also introduces a semi-synthetic setting for evaluating model editing that precisely formalizes the problem, albeit with a simplified problem and models trained from scratch. The evaluation compares an LLM against a Bayesian model, reflecting that Bayesian epistemology is the gold standard in belief revision. The authors use facts from Wikidata to generate a corpus of noisy sentences, which they then train an autoregressive Transformer on. By fitting a Bayesian model to the same data, they obtain exact Bayesian posteriors that serve as the targets for evaluating language models. The experiments show that edits to language models generalize poorly with respect to other relevant beliefs, yielding inconsistent model beliefs.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive critique of the model editing problem and proposes a semi-synthetic setting for evaluating model editing. However, the proposed setting simplifies the problem and uses models trained from scratch, which may not fully capture the complexities of real-world LLMs. Additionally, the paper does not address potential solutions to the 12 open challenges it presents, leaving room for further research in this area. The experiments conducted in the paper"
  },
  {
    "objectID": "posts/Fundamental_Problems_With_Model_Editing_How_Should_Rational_Belief_Revision_Work_in_LLMs/2024-06-27-Fundamental_Problems_With_Model_Editing_How_Should_Rational_Belief_Revision_Work_in_LLMs.html#appendix",
    "href": "posts/Fundamental_Problems_With_Model_Editing_How_Should_Rational_Belief_Revision_Work_in_LLMs/2024-06-27-Fundamental_Problems_With_Model_Editing_How_Should_Rational_Belief_Revision_Work_in_LLMs.html#appendix",
    "title": "Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19354v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19354v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14906"
  },
  {
    "objectID": "posts/Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course/2024-06-10-Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course.html",
    "href": "posts/Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course/2024-06-10-Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course.html",
    "title": "Insights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course",
    "section": "",
    "text": "Summary:\nThis study explores the social dynamics surrounding the use of large language models (LLMs) in an undergraduate programming course. The research is guided by the social shaping of technology theory and focuses on two research questions: (1) How do social perceptions influence the usage of LLMs in an undergraduate intermediate-level programming course? (2) How does LLM usage relate to programming self-efficacy and midterm scores among undergraduate students in an intermediate-level programming course?\nThe study employs a mixed-methods approach, including an anonymous student survey, student interviews, and a regression analysis of midterm performance data with students’ self-reported use of LLMs on homework. The findings suggest that students’ engagement with LLMs is significantly associated with their perceptions of their future careers and their peers’ usage. Additionally, the use of LLMs has mixed impacts on students’ self-efficacy and perceived learning outcomes, with a notable negative correlation between LLM usage and self-efficacy regardless of major and a negative correlation between LLM usage and performance on the first midterm.\nMajor Findings:\nAnalysis and Critique:\nThe study provides valuable insights into the social dynamics surrounding the use of LLMs in undergraduate programming education. However, the research has some limitations, including the context of the study, potential selection bias, reliance on self-reported data, and the correlational nature of the regression analyses. Additionally, the study’s focus on peer-reviewed literature may have led to the omission of relevant contributions from non-peer-reviewed sources. Despite these limitations, the research offers a nuanced understanding of the complex dynamic between technology and social factors, challenging the notion of technological determinism. As LLMs and other AI technologies continue to evolve, it is crucial to consider the social dynamics that shape their appropriation."
  },
  {
    "objectID": "posts/Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course/2024-06-10-Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course.html#appendix",
    "href": "posts/Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course/2024-06-10-Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course.html#appendix",
    "title": "Insights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06451v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06451v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14658"
  },
  {
    "objectID": "posts/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions/2024-07-07-Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions.html#summary-1",
    "href": "posts/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions/2024-07-07-Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions.html#summary-1",
    "title": "Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions",
    "section": "Summary:",
    "text": "Summary:\nThe study examines the performance of autoregressive LLMs and fine-tuned foundation language models in predicting gender categories (i.e., female, male, and neutral) given first names. It also investigates the impact of adding birth year on gender prediction accuracy. The research focuses on the limitations and biases of LLMs in predicting gender-neutral names and names with evolving gender associations over time."
  },
  {
    "objectID": "posts/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions/2024-07-07-Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions.html#major-findings",
    "href": "posts/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions/2024-07-07-Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions.html#major-findings",
    "title": "Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nFine-tuned foundational language models predicted gender-neutral first names more accurately than LLMs under 0-shot prompting across all three datasets. BERT results in the highest average accuracy for the US and Canada dataset, while RoBERTa outperformed BERT on the France dataset.\nMost LLMs showed higher accuracy in gender prediction when provided with 5 labeled name-gender pairs through in-context learning compared to the 0-shot setting across all datasets.\nIncorporating birth years as an additional input feature improved the prediction accuracy of foundational language models compared to the first-name-only setting. However, most LLMs showed a decline in accuracy when birth years were added, particularly in predicting gender-neutral names.\nThe accuracy of gender prediction using the US SSA dynamic gender label dataset has increased in recent years for most LLMs, including Llama3, Mixtral-8x7B, Claude 3 Haiku, and GPT-3.5.\nLLMs have worst performance on gender-neutral names, and the accuracy of gender prediction is higher for English-based first names in the US and Canada SSA datasets than in the France SSA."
  },
  {
    "objectID": "posts/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions/2024-07-07-Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions.html#analysis-and-critique",
    "href": "posts/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions/2024-07-07-Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions.html#analysis-and-critique",
    "title": "Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe study highlights the limitations and biases of LLMs in predicting gender-neutral names and names with evolving gender associations over time. The research underscores the need for more inclusive gender categories and the importance of considering temporal information in gender prediction tasks. However, the study is limited to specific countries, and the dataset preparation involved a subjective threshold to determine gender-neutral names. The prompt templates employed for interacting with LLMs were not optimized, which may lead to variations in results with different prompt formulations. The study also does not consider a broad spectrum of countries and cultures"
  },
  {
    "objectID": "posts/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions/2024-07-07-Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions.html#appendix",
    "href": "posts/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions/2024-07-07-Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions.html#appendix",
    "title": "Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05271v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05271v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6704"
  },
  {
    "objectID": "posts/Improving_Entity_Recognition_Using_Ensembles_of_Deep_Learning_and_Fine_tuned_Large_Language_Models_A_Case_Study_on_Adverse_Event_Extraction_from_Multiple_Sources/2024-06-26-Improving_Entity_Recognition_Using_Ensembles_of_Deep_Learning_and_Fine_tuned_Large_Language_Models_A_Case_Study_on_Adverse_Event_Extraction_from_Multiple_Sources.html",
    "href": "posts/Improving_Entity_Recognition_Using_Ensembles_of_Deep_Learning_and_Fine_tuned_Large_Language_Models_A_Case_Study_on_Adverse_Event_Extraction_from_Multiple_Sources/2024-06-26-Improving_Entity_Recognition_Using_Ensembles_of_Deep_Learning_and_Fine_tuned_Large_Language_Models_A_Case_Study_on_Adverse_Event_Extraction_from_Multiple_Sources.html",
    "title": "Improving Entity Recognition Using Ensembles of Deep Learning and Fine-tuned Large Language Models: A Case Study on Adverse Event Extraction from Multiple Sources",
    "section": "",
    "text": "Summary:\nThis study evaluates the effectiveness of large language models (LLMs) and traditional deep learning models in adverse event (AE) extraction following COVID-19 vaccines. The authors utilized reports and posts from the Vaccine Adverse Event Reporting System (VAERS), Twitter, and Reddit as their corpora. Their goal was to extract three types of entities: vaccine, shot, and adverse event (ae). They explored and fine-tuned multiple LLMs, including GPT-2, GPT-3.5, GPT-4, Llama-2 7b, and Llama-2 13b, as well as traditional deep learning models like Recurrent Neural Network (RNN) and Bidirectional Encoder Representations from Transformers for Biomedical Text Mining (BioBERT). To enhance performance, they created ensembles of the three models with the best performance. The ensemble model achieved the highest performance in “vaccine,” “shot,” and “ae,” with strict F1-scores of 0.878, 0.930, and 0.925, respectively, along with a micro-average score of 0.903. These results underscore the significance of fine-tuning models for specific tasks and demonstrate the effectiveness of ensemble methods in enhancing performance.\nMajor Findings:\nAnalysis and Critique:\nThe study demonstrates the effectiveness and robustness of ensembling fine-tuned traditional deep learning models and LLMs for extracting AE-related information following COVID-19 vaccination. However, the authors acknowledge that the corpora"
  },
  {
    "objectID": "posts/Improving_Entity_Recognition_Using_Ensembles_of_Deep_Learning_and_Fine_tuned_Large_Language_Models_A_Case_Study_on_Adverse_Event_Extraction_from_Multiple_Sources/2024-06-26-Improving_Entity_Recognition_Using_Ensembles_of_Deep_Learning_and_Fine_tuned_Large_Language_Models_A_Case_Study_on_Adverse_Event_Extraction_from_Multiple_Sources.html#appendix",
    "href": "posts/Improving_Entity_Recognition_Using_Ensembles_of_Deep_Learning_and_Fine_tuned_Large_Language_Models_A_Case_Study_on_Adverse_Event_Extraction_from_Multiple_Sources/2024-06-26-Improving_Entity_Recognition_Using_Ensembles_of_Deep_Learning_and_Fine_tuned_Large_Language_Models_A_Case_Study_on_Adverse_Event_Extraction_from_Multiple_Sources.html#appendix",
    "title": "Improving Entity Recognition Using Ensembles of Deep Learning and Fine-tuned Large Language Models: A Case Study on Adverse Event Extraction from Multiple Sources",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18049v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18049v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13358"
  },
  {
    "objectID": "posts/Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models/2024-06-08-Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models.html",
    "href": "posts/Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models/2024-06-08-Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models.html",
    "title": "Creativity Has Left the Chat: The Price of Debiasing Language Models",
    "section": "",
    "text": "Summary:\nThe paper “Creativity Has Left the Chat: The Price of Debiasing Language Models” explores the impact of the Reinforcement Learning from Human Feedback (RLHF) process on the creativity and output diversity of Large Language Models (LLMs). The authors use the Llama-2 series of models to conduct three experiments, focusing on the Llama-2-7B-text (base model) and Llama-2-7B-chat (aligned model). The experiments reveal that while RLHF effectively reduces biases and toxicity in LLMs, it may inadvertently lead to a reduction in the models’ creative potential. The aligned models exhibit lower entropy in token predictions, form distinct clusters in the embedding space, and gravitate towards “attractor states,” indicating limited output diversity. These findings have significant implications for marketers who rely on LLMs for creative tasks, as the trade-off between consistency and creativity in aligned models should be carefully considered.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides valuable insights into the unintended consequences of the RLHF process on the creativity and output diversity of LLMs. However, the study is limited by the computational costs and resource demands, which prevented the authors from delving into various parameters or configurations of the RLHF process. Future research should explore different parameters and configurations to understand their impact on the creativity and output diversity of aligned LLMs. Additionally, further investigation is needed to analyze other unintended consequences of model alignment and RLHF to enhance our understanding of the trade-offs involved in practical applications of these models."
  },
  {
    "objectID": "posts/Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models/2024-06-08-Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models.html#appendix",
    "href": "posts/Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models/2024-06-08-Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models.html#appendix",
    "title": "Creativity Has Left the Chat: The Price of Debiasing Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05587v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05587v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20391"
  },
  {
    "objectID": "posts/GenderAlign_An_Alignment_Dataset_for_Mitigating_Gender_Bias_in_Large_Language_Models/2024-06-20-GenderAlign_An_Alignment_Dataset_for_Mitigating_Gender_Bias_in_Large_Language_Models.html#appendix",
    "href": "posts/GenderAlign_An_Alignment_Dataset_for_Mitigating_Gender_Bias_in_Large_Language_Models/2024-06-20-GenderAlign_An_Alignment_Dataset_for_Mitigating_Gender_Bias_in_Large_Language_Models.html#appendix",
    "title": "GenderAlign: An Alignment Dataset for Mitigating Gender Bias in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13925v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13925v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6741"
  },
  {
    "objectID": "posts/MrRank_Improving_Question_Answering_Retrieval_System_through_Multi_Result_Ranking_Model/2024-06-09-MrRank_Improving_Question_Answering_Retrieval_System_through_Multi_Result_Ranking_Model.html#appendix",
    "href": "posts/MrRank_Improving_Question_Answering_Retrieval_System_through_Multi_Result_Ranking_Model/2024-06-09-MrRank_Improving_Question_Answering_Retrieval_System_through_Multi_Result_Ranking_Model.html#appendix",
    "title": "MrRank: Improving Question Answering Retrieval System through Multi-Result Ranking Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05733v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05733v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5268"
  },
  {
    "objectID": "posts/From_Decoding_to_Meta_Generation_Inference_time_Algorithms_for_Large_Language_Models/2024-06-24-From_Decoding_to_Meta_Generation_Inference_time_Algorithms_for_Large_Language_Models.html",
    "href": "posts/From_Decoding_to_Meta_Generation_Inference_time_Algorithms_for_Large_Language_Models/2024-06-24-From_Decoding_to_Meta_Generation_Inference_time_Algorithms_for_Large_Language_Models.html",
    "title": "From Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models",
    "section": "",
    "text": "Summary:\nThe paper explores the use of large language models (LLMs) in natural language processing, focusing on three main themes: token-level generation algorithms, meta-generation algorithms, and efficient generation. Token-level generation algorithms, such as decoding algorithms, have a rich history in natural language processing and operate by sampling one token at a time or constructing a token-level search space. Recently, there has been growing interest in meta-generation algorithms, which operate on partial or full sequences and treat the LLM as a black box that is called as part of a larger generation program. These algorithms can increase the compute resources devoted to generation by making multiple model calls, augmenting the model with search algorithms, or incorporating external data sources. The paper also discusses the limitations of the Maximum A Posteriori (MAP) decoding objective in neural machine translation (NMT) and the use of reranking and transforming N-"
  },
  {
    "objectID": "posts/From_Decoding_to_Meta_Generation_Inference_time_Algorithms_for_Large_Language_Models/2024-06-24-From_Decoding_to_Meta_Generation_Inference_time_Algorithms_for_Large_Language_Models.html#appendix",
    "href": "posts/From_Decoding_to_Meta_Generation_Inference_time_Algorithms_for_Large_Language_Models/2024-06-24-From_Decoding_to_Meta_Generation_Inference_time_Algorithms_for_Large_Language_Models.html#appendix",
    "title": "From Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16838v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16838v1\n\n\nTruncated\nTrue\n\n\nWord Count\n45988"
  },
  {
    "objectID": "posts/DELRec_Distilling_Sequential_Pattern_to_Enhance_LLM_based_Recommendation/2024-06-17-DELRec_Distilling_Sequential_Pattern_to_Enhance_LLM_based_Recommendation.html#appendix",
    "href": "posts/DELRec_Distilling_Sequential_Pattern_to_Enhance_LLM_based_Recommendation/2024-06-17-DELRec_Distilling_Sequential_Pattern_to_Enhance_LLM_based_Recommendation.html#appendix",
    "title": "DELRec: Distilling Sequential Pattern to Enhance LLM-based Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11156v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11156v2\n\n\nTruncated\nFalse\n\n\nWord Count\n8935"
  },
  {
    "objectID": "posts/Large_Language_Models_as_Recommender_Systems_A_Study_of_Popularity_Bias/2024-06-03-Large_Language_Models_as_Recommender_Systems_A_Study_of_Popularity_Bias.html#appendix",
    "href": "posts/Large_Language_Models_as_Recommender_Systems_A_Study_of_Popularity_Bias/2024-06-03-Large_Language_Models_as_Recommender_Systems_A_Study_of_Popularity_Bias.html#appendix",
    "title": "Large Language Models as Recommender Systems: A Study of Popularity Bias",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01285v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01285v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9391"
  },
  {
    "objectID": "posts/Knowledge_Graph_Tuning_Real_time_Large_Language_Model_Personalization_based_on_Human_Feedback/2024-05-30-Knowledge_Graph_Tuning_Real_time_Large_Language_Model_Personalization_based_on_Human_Feedback.html#appendix",
    "href": "posts/Knowledge_Graph_Tuning_Real_time_Large_Language_Model_Personalization_based_on_Human_Feedback/2024-05-30-Knowledge_Graph_Tuning_Real_time_Large_Language_Model_Personalization_based_on_Human_Feedback.html#appendix",
    "title": "Knowledge Graph Tuning: Real-time Large Language Model Personalization based on Human Feedback",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.19686v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.19686v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6292"
  },
  {
    "objectID": "posts/medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs/2024-06-20-medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs.html",
    "href": "posts/medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs/2024-06-20-medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs.html",
    "title": "medIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced Clinical Diagnosis on EMRs",
    "section": "",
    "text": "Summary:\nThe paper introduces medIKAL, a framework that integrates Large Language Models (LLMs) with knowledge graphs (KGs) to enhance clinical diagnosis on Electronic Medical Records (EMRs). The framework assigns weighted importance to entities in medical records based on their type, enabling precise localization of candidate diseases within KGs. It employs a residual network-like approach, allowing initial diagnosis by the LLM to be merged into KG search results. The diagnostic process is further refined through a path-based reranking algorithm and a fill-in-the-blank style prompt template. The effectiveness of medIKAL is validated through extensive experiments on a newly introduced open-sourced Chinese EMR dataset.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs/2024-06-20-medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs.html#appendix",
    "href": "posts/medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs/2024-06-20-medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs.html#appendix",
    "title": "medIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced Clinical Diagnosis on EMRs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14326v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14326v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7194"
  },
  {
    "objectID": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#major-findings",
    "href": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#major-findings",
    "title": "SemCoder: Training Code Language Models with Comprehensive Semantics",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe paper introduces a novel strategy to train Code LLMs with comprehensive semantics, including high-level functional descriptions, local execution effects of individual statements, and overall input/output behavior.\nThe authors propose training Code LLMs to write code and represent and reason about execution behaviors using natural language, mimicking human verbal debugging.\nThe paper presents SEMCODER, a Code LLM with only 6.7B parameters, which shows competitive performance with GPT-3.5-turbo on code generation and execution reasoning tasks.\nSEMCODER achieves 81.1% on HumanEval (GPT-3.5-turbo: 76.8%) and 54.5% on CRUXEval-I (GPT-3.5-turbo: 50.3%).\nThe paper also studies the effectiveness of SEMCODER’s monologue-style execution reasoning compared to concrete scratchpad reasoning, showing that their approach integrates semantics from multiple dimensions more smoothly."
  },
  {
    "objectID": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#analysis-and-critique",
    "href": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#analysis-and-critique",
    "title": "SemCoder: Training Code Language Models with Comprehensive Semantics",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a novel approach to training Code LLMs with comprehensive semantics, which has the potential to improve the performance of Code LLMs on code generation and execution reasoning tasks. The authors’ proposal to train Code LLMs to write code and represent and reason about execution behaviors using natural language is an interesting and promising direction.\nHowever, the paper does not provide a detailed comparison of SEMCODER with other state-of-the-art Code LLMs, which makes it difficult to evaluate the effectiveness of their approach. Additionally, the"
  },
  {
    "objectID": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#appendix",
    "href": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#appendix",
    "title": "SemCoder: Training Code Language Models with Comprehensive Semantics",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01006v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01006v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18724"
  },
  {
    "objectID": "posts/Jailbreaking_LLMs_with_Arabic_Transliteration_and_Arabizi/2024-06-26-Jailbreaking_LLMs_with_Arabic_Transliteration_and_Arabizi.html#appendix",
    "href": "posts/Jailbreaking_LLMs_with_Arabic_Transliteration_and_Arabizi/2024-06-26-Jailbreaking_LLMs_with_Arabic_Transliteration_and_Arabizi.html#appendix",
    "title": "Jailbreaking LLMs with Arabic Transliteration and Arabizi",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18725v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18725v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8377"
  },
  {
    "objectID": "posts/FSM_A_Finite_State_Machine_Based_Zero_Shot_Prompting_Paradigm_for_Multi_Hop_Question_Answering/2024-07-03-FSM_A_Finite_State_Machine_Based_Zero_Shot_Prompting_Paradigm_for_Multi_Hop_Question_Answering.html#appendix",
    "href": "posts/FSM_A_Finite_State_Machine_Based_Zero_Shot_Prompting_Paradigm_for_Multi_Hop_Question_Answering/2024-07-03-FSM_A_Finite_State_Machine_Based_Zero_Shot_Prompting_Paradigm_for_Multi_Hop_Question_Answering.html#appendix",
    "title": "FSM: A Finite State Machine Based Zero-Shot Prompting Paradigm for Multi-Hop Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02964v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02964v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4635"
  },
  {
    "objectID": "posts/Modular_Pluralism_Pluralistic_Alignment_via_Multi_LLM_Collaboration/2024-06-22-Modular_Pluralism_Pluralistic_Alignment_via_Multi_LLM_Collaboration.html#appendix",
    "href": "posts/Modular_Pluralism_Pluralistic_Alignment_via_Multi_LLM_Collaboration/2024-06-22-Modular_Pluralism_Pluralistic_Alignment_via_Multi_LLM_Collaboration.html#appendix",
    "title": "Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.15951v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.15951v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8836"
  },
  {
    "objectID": "posts/An_Empirical_Study_of_Unit_Test_Generation_with_Large_Language_Models/2024-06-26-An_Empirical_Study_of_Unit_Test_Generation_with_Large_Language_Models.html#appendix",
    "href": "posts/An_Empirical_Study_of_Unit_Test_Generation_with_Large_Language_Models/2024-06-26-An_Empirical_Study_of_Unit_Test_Generation_with_Large_Language_Models.html#appendix",
    "title": "An Empirical Study of Unit Test Generation with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18181v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18181v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13168"
  },
  {
    "objectID": "posts/UniCoder_Scaling_Code_Large_Language_Model_via_Universal_Code/2024-06-24-UniCoder_Scaling_Code_Large_Language_Model_via_Universal_Code.html#appendix",
    "href": "posts/UniCoder_Scaling_Code_Large_Language_Model_via_Universal_Code/2024-06-24-UniCoder_Scaling_Code_Large_Language_Model_via_Universal_Code.html#appendix",
    "title": "UniCoder: Scaling Code Large Language Model via Universal Code",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16441v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16441v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3736"
  },
  {
    "objectID": "posts/HalluDial_A_Large_Scale_Benchmark_for_Automatic_Dialogue_Level_Hallucination_Evaluation/2024-06-11-HalluDial_A_Large_Scale_Benchmark_for_Automatic_Dialogue_Level_Hallucination_Evaluation.html#appendix",
    "href": "posts/HalluDial_A_Large_Scale_Benchmark_for_Automatic_Dialogue_Level_Hallucination_Evaluation/2024-06-11-HalluDial_A_Large_Scale_Benchmark_for_Automatic_Dialogue_Level_Hallucination_Evaluation.html#appendix",
    "title": "HalluDial: A Large-Scale Benchmark for Automatic Dialogue-Level Hallucination Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07070v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07070v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10462"
  },
  {
    "objectID": "posts/Single_Codec_Single_Codebook_Speech_Codec_towards_High_Performance_Speech_Generation/2024-06-11-Single_Codec_Single_Codebook_Speech_Codec_towards_High_Performance_Speech_Generation.html#appendix",
    "href": "posts/Single_Codec_Single_Codebook_Speech_Codec_towards_High_Performance_Speech_Generation/2024-06-11-Single_Codec_Single_Codebook_Speech_Codec_towards_High_Performance_Speech_Generation.html#appendix",
    "title": "Single-Codec: Single-Codebook Speech Codec towards High-Performance Speech Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07422v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07422v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4062"
  },
  {
    "objectID": "posts/Large_Language_Model_as_an_Assignment_Evaluator_Insights_Feedback_and_Challenges_in_a_1000+_Student_Course/2024-07-07-Large_Language_Model_as_an_Assignment_Evaluator_Insights_Feedback_and_Challenges_in_a_1000+_Student_Course.html#appendix",
    "href": "posts/Large_Language_Model_as_an_Assignment_Evaluator_Insights_Feedback_and_Challenges_in_a_1000+_Student_Course/2024-07-07-Large_Language_Model_as_an_Assignment_Evaluator_Insights_Feedback_and_Challenges_in_a_1000+_Student_Course.html#appendix",
    "title": "Large Language Model as an Assignment Evaluator: Insights, Feedback, and Challenges in a 1000+ Student Course",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05216v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05216v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5931"
  },
  {
    "objectID": "posts/DCA_Bench_A_Benchmark_for_Dataset_Curation_Agents/2024-06-11-DCA_Bench_A_Benchmark_for_Dataset_Curation_Agents.html#appendix",
    "href": "posts/DCA_Bench_A_Benchmark_for_Dataset_Curation_Agents/2024-06-11-DCA_Bench_A_Benchmark_for_Dataset_Curation_Agents.html#appendix",
    "title": "DCA-Bench: A Benchmark for Dataset Curation Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07275v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07275v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8553"
  },
  {
    "objectID": "posts/Open_LLM_Leaderboard_From_Multi_choice_to_Open_style_Questions_for_LLMs_Evaluation_Benchmark_and_Arena/2024-06-11-Open_LLM_Leaderboard_From_Multi_choice_to_Open_style_Questions_for_LLMs_Evaluation_Benchmark_and_Arena.html#appendix",
    "href": "posts/Open_LLM_Leaderboard_From_Multi_choice_to_Open_style_Questions_for_LLMs_Evaluation_Benchmark_and_Arena/2024-06-11-Open_LLM_Leaderboard_From_Multi_choice_to_Open_style_Questions_for_LLMs_Evaluation_Benchmark_and_Arena.html#appendix",
    "title": "Open-LLM-Leaderboard: From Multi-choice to Open-style Questions for LLMs Evaluation, Benchmark, and Arena",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07545v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07545v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5687"
  },
  {
    "objectID": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#summary-1",
    "href": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#summary-1",
    "title": "Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining",
    "section": "Summary:",
    "text": "Summary:\n\nThe paper introduces a novel framework that combines context-aware retrieval-augmented generation with a prompt-based TTS system.\nThe proposed framework incorporates an innovative Context-Aware Contrastive Language-Audio Pre-training (CA-CLAP) model to extract context-aware, style-related textual features (STFs) under audio supervision.\nThe CA-CLAP model employs an audio encoder for extracting style embeddings from speech and a text encoder for deriving STFs from both the text and its context.\nThe framework also implements cross-attention mechanisms between textual and contextual features to enhance context integration.\nThe paper makes the following contributions: 1) proposing a RAG-enhanced prompt-based TTS framework to enhance audio prompt specialized selection, 2) designing a CA-CLAP model to extract textual and acoustic representations for retrieval, and 3) conducting extensive subjective and objective experiments to demonstrate the proposed methods’ superiority over baselines and the introduced CA-CLAP’s better results than text-only embedding methods."
  },
  {
    "objectID": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#major-findings",
    "href": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#major-findings",
    "title": "Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe proposed RAG-enhanced prompt-based TTS framework improves audio prompt specialized selection.\nThe CA-CLAP model effectively extracts context-aware, style-related textual features (STFs) under audio supervision.\nThe proposed methods outperform baselines, and the introduced CA-CLAP achieves better results than text-only embedding methods."
  },
  {
    "objectID": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#analysis-and-critique",
    "href": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#analysis-and-critique",
    "title": "Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper effectively addresses the challenge of selecting appropriate speech prompts by adapting the RAG concept to the speech domain.\nThe proposed framework incorporates an innovative CA-CLAP model to extract context-aware, style-related textual features (STFs) under audio supervision, which enhances the overall quality and relevance of the retrieved content.\nThe paper provides extensive subjective and objective experiments to demonstrate the proposed methods’ superiority over baselines and the introduced CA-CLAP’s better results than"
  },
  {
    "objectID": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#appendix",
    "href": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#appendix",
    "title": "Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03714v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03714v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3915"
  },
  {
    "objectID": "posts/TextGrad_Automatic_Differentiation_via_Text/2024-06-11-TextGrad_Automatic_Differentiation_via_Text.html#appendix",
    "href": "posts/TextGrad_Automatic_Differentiation_via_Text/2024-06-11-TextGrad_Automatic_Differentiation_via_Text.html#appendix",
    "title": "TextGrad: Automatic Differentiation via Text",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07496v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07496v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14644"
  },
  {
    "objectID": "posts/Every_Language_Counts_Learn_and_Unlearn_in_Multilingual_LLMs/2024-06-19-Every_Language_Counts_Learn_and_Unlearn_in_Multilingual_LLMs.html#appendix",
    "href": "posts/Every_Language_Counts_Learn_and_Unlearn_in_Multilingual_LLMs/2024-06-19-Every_Language_Counts_Learn_and_Unlearn_in_Multilingual_LLMs.html#appendix",
    "title": "Every Language Counts: Learn and Unlearn in Multilingual LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13748v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13748v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5047"
  },
  {
    "objectID": "posts/Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients/2024-06-23-Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients.html#major-findings",
    "href": "posts/Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients/2024-06-23-Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients.html#major-findings",
    "title": "Effectiveness of ChatGPT in explaining complex medical reports to patients",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nInaccurate Information: ChatGPT’s explanations contained errors, including incorrect interpretation of abbreviations, URLs, and test results.\nInappropriate Language: The language used by ChatGPT was sometimes too complex, grammatically incorrect, or used American English, which is inappropriate in the UK.\nLimited Personalization: The responses were not always tailored to the patient, and the content was often too vague or technical.\nAI Distrust: Patients and doctors expressed reluctance to trust ChatGPT responses unless they were checked, preferably by clinicians. Some patients did not want to use them at all.\nIntegration Challenges: Integrating ChatGPT into existing clinical workflows, including getting approval from the NHS, poses significant challenges."
  },
  {
    "objectID": "posts/Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients/2024-06-23-Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients.html#analysis-and-critique",
    "href": "posts/Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients/2024-06-23-Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients.html#analysis-and-critique",
    "title": "Effectiveness of ChatGPT in explaining complex medical reports to patients",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe study highlights the potential of ChatGPT in assisting with complex medical reports but also underscores the need for improvements. The issues identified, such as inaccurate information, inappropriate language, limited personalization, and AI distrust, need to be addressed before LLMs can be effectively used to explain complex personal medical information to patients. The study also points out the challenges of integrating LLMs into clinical workflow and the need for more research on what patients and doctors need from such tools.\nThe study’s limitations include the small sample size for annotations and the lack of comprehensive data on focus group participants, which may have introduced bias. The use of only the webpage version of ChatGPT4 also limits the applicability of the findings to other LLMs.\nEthical considerations were addressed, with two ethical approvals obtained and all experiments conducted with the informed consent of the participants."
  },
  {
    "objectID": "posts/Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients/2024-06-23-Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients.html#appendix",
    "href": "posts/Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients/2024-06-23-Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients.html#appendix",
    "title": "Effectiveness of ChatGPT in explaining complex medical reports to patients",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.15963v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.15963v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7576"
  },
  {
    "objectID": "posts/3D_Properties_Identifying_Challenges_in_DPO_and_Charting_a_Path_Forward/2024-06-11-3D_Properties_Identifying_Challenges_in_DPO_and_Charting_a_Path_Forward.html#appendix",
    "href": "posts/3D_Properties_Identifying_Challenges_in_DPO_and_Charting_a_Path_Forward/2024-06-11-3D_Properties_Identifying_Challenges_in_DPO_and_Charting_a_Path_Forward.html#appendix",
    "title": "3D-Properties: Identifying Challenges in DPO and Charting a Path Forward",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07327v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07327v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8028"
  },
  {
    "objectID": "posts/Does_Object_Grounding_Really_Reduce_Hallucination_of_Large_Vision_Language_Models/2024-06-20-Does_Object_Grounding_Really_Reduce_Hallucination_of_Large_Vision_Language_Models.html#appendix",
    "href": "posts/Does_Object_Grounding_Really_Reduce_Hallucination_of_Large_Vision_Language_Models/2024-06-20-Does_Object_Grounding_Really_Reduce_Hallucination_of_Large_Vision_Language_Models.html#appendix",
    "title": "Does Object Grounding Really Reduce Hallucination of Large Vision-Language Models?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14492v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14492v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7908"
  },
  {
    "objectID": "posts/SimsChat_A_Customisable_Persona_Driven_Role_Playing_Agent/2024-06-25-SimsChat_A_Customisable_Persona_Driven_Role_Playing_Agent.html#appendix",
    "href": "posts/SimsChat_A_Customisable_Persona_Driven_Role_Playing_Agent/2024-06-25-SimsChat_A_Customisable_Persona_Driven_Role_Playing_Agent.html#appendix",
    "title": "SimsChat: A Customisable Persona-Driven Role-Playing Agent",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17962v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17962v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6407"
  },
  {
    "objectID": "posts/Agent_Driven_Automatic_Software_Improvement/2024-06-24-Agent_Driven_Automatic_Software_Improvement.html#appendix",
    "href": "posts/Agent_Driven_Automatic_Software_Improvement/2024-06-24-Agent_Driven_Automatic_Software_Improvement.html#appendix",
    "title": "Agent-Driven Automatic Software Improvement",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16739v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16739v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5961"
  },
  {
    "objectID": "posts/Learning_to_Ask_Informative_Questions_Enhancing_LLMs_with_Preference_Optimization_and_Expected_Information_Gain/2024-06-25-Learning_to_Ask_Informative_Questions_Enhancing_LLMs_with_Preference_Optimization_and_Expected_Information_Gain.html#appendix",
    "href": "posts/Learning_to_Ask_Informative_Questions_Enhancing_LLMs_with_Preference_Optimization_and_Expected_Information_Gain/2024-06-25-Learning_to_Ask_Informative_Questions_Enhancing_LLMs_with_Preference_Optimization_and_Expected_Information_Gain.html#appendix",
    "title": "Learning to Ask Informative Questions: Enhancing LLMs with Preference Optimization and Expected Information Gain",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17453v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17453v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5253"
  },
  {
    "objectID": "posts/Trace_is_the_New_AutoDiff____Unlocking_Efficient_Optimization_of_Computational_Workflows/2024-06-23-Trace_is_the_New_AutoDiff____Unlocking_Efficient_Optimization_of_Computational_Workflows.html",
    "href": "posts/Trace_is_the_New_AutoDiff____Unlocking_Efficient_Optimization_of_Computational_Workflows/2024-06-23-Trace_is_the_New_AutoDiff____Unlocking_Efficient_Optimization_of_Computational_Workflows.html",
    "title": "Trace is the New AutoDiff – Unlocking Efficient Optimization of Computational Workflows",
    "section": "",
    "text": "Summary:\nThe paper introduces a new optimization framework called Trace, which is designed to optimize computational workflows in AI systems. The framework is inspired by back-propagation and treats the computational workflow as a graph, similar to neural networks. The optimization process involves rich feedback, heterogeneous parameters, and intricate objectives. The paper also introduces a new mathematical setup called Optimization with Trace Oracle (OPTO) to capture and abstract these properties, enabling the design of optimizers that work across multiple domains. The authors propose a general-purpose LLM-based optimizer called OptoPrime, which can effectively solve OPTO problems. Empirical studies show that OptoPrime is capable of first-order numerical optimization, prompt optimization, hyper-parameter tuning, robot controller design, code debugging, and more. The authors believe that Trace, OptoPrime, and the OPTO framework will enable the next generation of interactive agents that automatically adapt using various kinds of feedback.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an interesting and novel approach to optimizing computational workflows in AI systems. The Trace framework and the OPTO mathematical setup provide a new perspective on how to optimize complex workflows, and the proposed OptoPrime optimizer demonstrates promising results in various optimization tasks. However, the paper does not provide a detailed comparison with existing optimization techniques, which could help to better understand the advantages and limitations of the proposed approach. Additionally, the paper does not discuss the scalability and"
  },
  {
    "objectID": "posts/Trace_is_the_New_AutoDiff____Unlocking_Efficient_Optimization_of_Computational_Workflows/2024-06-23-Trace_is_the_New_AutoDiff____Unlocking_Efficient_Optimization_of_Computational_Workflows.html#appendix",
    "href": "posts/Trace_is_the_New_AutoDiff____Unlocking_Efficient_Optimization_of_Computational_Workflows/2024-06-23-Trace_is_the_New_AutoDiff____Unlocking_Efficient_Optimization_of_Computational_Workflows.html#appendix",
    "title": "Trace is the New AutoDiff – Unlocking Efficient Optimization of Computational Workflows",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16218v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16218v1\n\n\nTruncated\nFalse\n\n\nWord Count\n16085"
  },
  {
    "objectID": "posts/QuickLLaMA_Query_aware_Inference_Acceleration_for_Large_Language_Models/2024-06-11-QuickLLaMA_Query_aware_Inference_Acceleration_for_Large_Language_Models.html#appendix",
    "href": "posts/QuickLLaMA_Query_aware_Inference_Acceleration_for_Large_Language_Models/2024-06-11-QuickLLaMA_Query_aware_Inference_Acceleration_for_Large_Language_Models.html#appendix",
    "title": "QuickLLaMA: Query-aware Inference Acceleration for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07528v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07528v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7459"
  },
  {
    "objectID": "posts/THaLLE_Text_Hyperlocally_Augmented_Large_Language_Extension____Technical_Report/2024-06-11-THaLLE_Text_Hyperlocally_Augmented_Large_Language_Extension____Technical_Report.html#appendix",
    "href": "posts/THaLLE_Text_Hyperlocally_Augmented_Large_Language_Extension____Technical_Report/2024-06-11-THaLLE_Text_Hyperlocally_Augmented_Large_Language_Extension____Technical_Report.html#appendix",
    "title": "THaLLE: Text Hyperlocally Augmented Large Language Extension – Technical Report",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07505v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07505v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5344"
  },
  {
    "objectID": "posts/On_the_Transformations_across_Reward_Model_Parameter_Update_and_In_Context_Prompt/2024-06-24-On_the_Transformations_across_Reward_Model_Parameter_Update_and_In_Context_Prompt.html",
    "href": "posts/On_the_Transformations_across_Reward_Model_Parameter_Update_and_In_Context_Prompt/2024-06-24-On_the_Transformations_across_Reward_Model_Parameter_Update_and_In_Context_Prompt.html",
    "title": "On the Transformations across Reward Model, Parameter Update, and In-Context Prompt",
    "section": "",
    "text": "Summary:\nThis paper presents a holistic view of the interchangeability among three popular and distinct adaptation tools for pre-trained large language models (LLMs): parameter updating, reward modeling, and in-context prompting. The authors establish a triangular framework with six transformation directions, each facilitating various applications. The primary contribution of this work is to offer a unified perspective that connects numerous existing studies and outlines potential future research directions.\nMajor Findings:\nAnalysis and Critique:\nThe paper offers a comprehensive and unified view of the interchangeability among parameter updating, reward modeling, and in-context prompting in adapting pre-trained LLMs. This framework serves as a useful guide for researchers and practitioners in the field of LLMs, empowering them to make more informed decisions in their research and applications. However, the paper does not address the limitations and unanswered questions that may arise from the proposed framework. Additionally, the authors do not discuss any methodological issues, conflicting evidence, or areas that require further research or clarification.\nIn conclusion, the paper provides a valuable contribution to the field of LLMs by offering a unified perspective on the interchangeability of adaptation tools. However, further research is needed to address the limitations and unanswered questions that may arise from the proposed framework."
  },
  {
    "objectID": "posts/On_the_Transformations_across_Reward_Model_Parameter_Update_and_In_Context_Prompt/2024-06-24-On_the_Transformations_across_Reward_Model_Parameter_Update_and_In_Context_Prompt.html#appendix",
    "href": "posts/On_the_Transformations_across_Reward_Model_Parameter_Update_and_In_Context_Prompt/2024-06-24-On_the_Transformations_across_Reward_Model_Parameter_Update_and_In_Context_Prompt.html#appendix",
    "title": "On the Transformations across Reward Model, Parameter Update, and In-Context Prompt",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16377v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16377v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14264"
  },
  {
    "objectID": "posts/Hopping_Too_Late_Exploring_the_Limitations_of_Large_Language_Models_on_Multi_Hop_Queries/2024-06-18-Hopping_Too_Late_Exploring_the_Limitations_of_Large_Language_Models_on_Multi_Hop_Queries.html#appendix",
    "href": "posts/Hopping_Too_Late_Exploring_the_Limitations_of_Large_Language_Models_on_Multi_Hop_Queries/2024-06-18-Hopping_Too_Late_Exploring_the_Limitations_of_Large_Language_Models_on_Multi_Hop_Queries.html#appendix",
    "title": "Hopping Too Late: Exploring the Limitations of Large Language Models on Multi-Hop Queries",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12775v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12775v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8033"
  },
  {
    "objectID": "posts/XRec_Large_Language_Models_for_Explainable_Recommendation/2024-06-04-XRec_Large_Language_Models_for_Explainable_Recommendation.html#appendix",
    "href": "posts/XRec_Large_Language_Models_for_Explainable_Recommendation/2024-06-04-XRec_Large_Language_Models_for_Explainable_Recommendation.html#appendix",
    "title": "XRec: Large Language Models for Explainable Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02377v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02377v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6297"
  },
  {
    "objectID": "posts/Dual_Space_Knowledge_Distillation_for_Large_Language_Models/2024-06-25-Dual_Space_Knowledge_Distillation_for_Large_Language_Models.html#appendix",
    "href": "posts/Dual_Space_Knowledge_Distillation_for_Large_Language_Models/2024-06-25-Dual_Space_Knowledge_Distillation_for_Large_Language_Models.html#appendix",
    "title": "Dual-Space Knowledge Distillation for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17328v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17328v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8166"
  },
  {
    "objectID": "posts/Generative_AI_for_Enhancing_Active_Learning_in_Education_A_Comparative_Study_of_GPT_3.5_and_GPT_4_in_Crafting_Customized_Test_Questions/2024-06-20-Generative_AI_for_Enhancing_Active_Learning_in_Education_A_Comparative_Study_of_GPT_3.5_and_GPT_4_in_Crafting_Customized_Test_Questions.html#appendix",
    "href": "posts/Generative_AI_for_Enhancing_Active_Learning_in_Education_A_Comparative_Study_of_GPT_3.5_and_GPT_4_in_Crafting_Customized_Test_Questions/2024-06-20-Generative_AI_for_Enhancing_Active_Learning_in_Education_A_Comparative_Study_of_GPT_3.5_and_GPT_4_in_Crafting_Customized_Test_Questions.html#appendix",
    "title": "Generative AI for Enhancing Active Learning in Education: A Comparative Study of GPT-3.5 and GPT-4 in Crafting Customized Test Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13903v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13903v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6168"
  },
  {
    "objectID": "posts/Step_Back_Profiling_Distilling_User_History_for_Personalized_Scientific_Writing/2024-06-20-Step_Back_Profiling_Distilling_User_History_for_Personalized_Scientific_Writing.html#appendix",
    "href": "posts/Step_Back_Profiling_Distilling_User_History_for_Personalized_Scientific_Writing/2024-06-20-Step_Back_Profiling_Distilling_User_History_for_Personalized_Scientific_Writing.html#appendix",
    "title": "Step-Back Profiling: Distilling User History for Personalized Scientific Writing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14275v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14275v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5200"
  },
  {
    "objectID": "posts/VideoLLaMA_2_Advancing_Spatial_Temporal_Modeling_and_Audio_Understanding_in_Video_LLMs/2024-06-11-VideoLLaMA_2_Advancing_Spatial_Temporal_Modeling_and_Audio_Understanding_in_Video_LLMs.html#appendix",
    "href": "posts/VideoLLaMA_2_Advancing_Spatial_Temporal_Modeling_and_Audio_Understanding_in_Video_LLMs/2024-06-11-VideoLLaMA_2_Advancing_Spatial_Temporal_Modeling_and_Audio_Understanding_in_Video_LLMs.html#appendix",
    "title": "VideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understanding in Video-LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07476v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07476v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5170"
  },
  {
    "objectID": "posts/VELO_A_Vector_Database_Assisted_Cloud_Edge_Collaborative_LLM_QoS_Optimization_Framework/2024-06-19-VELO_A_Vector_Database_Assisted_Cloud_Edge_Collaborative_LLM_QoS_Optimization_Framework.html#appendix",
    "href": "posts/VELO_A_Vector_Database_Assisted_Cloud_Edge_Collaborative_LLM_QoS_Optimization_Framework/2024-06-19-VELO_A_Vector_Database_Assisted_Cloud_Edge_Collaborative_LLM_QoS_Optimization_Framework.html#appendix",
    "title": "VELO: A Vector Database-Assisted Cloud-Edge Collaborative LLM QoS Optimization Framework",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13399v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13399v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7725"
  },
  {
    "objectID": "posts/LLM4MSR_An_LLM_Enhanced_Paradigm_for_Multi_Scenario_Recommendation/2024-06-18-LLM4MSR_An_LLM_Enhanced_Paradigm_for_Multi_Scenario_Recommendation.html#appendix",
    "href": "posts/LLM4MSR_An_LLM_Enhanced_Paradigm_for_Multi_Scenario_Recommendation/2024-06-18-LLM4MSR_An_LLM_Enhanced_Paradigm_for_Multi_Scenario_Recommendation.html#appendix",
    "title": "LLM4MSR: An LLM-Enhanced Paradigm for Multi-Scenario Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12529v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12529v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9061"
  },
  {
    "objectID": "posts/Iterative_or_Innovative_A_Problem_Oriented_Perspective_for_Code_Optimization/2024-06-17-Iterative_or_Innovative_A_Problem_Oriented_Perspective_for_Code_Optimization.html#appendix",
    "href": "posts/Iterative_or_Innovative_A_Problem_Oriented_Perspective_for_Code_Optimization/2024-06-17-Iterative_or_Innovative_A_Problem_Oriented_Perspective_for_Code_Optimization.html#appendix",
    "title": "Iterative or Innovative? A Problem-Oriented Perspective for Code Optimization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11935v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11935v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10246"
  },
  {
    "objectID": "posts/Banishing_LLM_Hallucinations_Requires_Rethinking_Generalization/2024-06-25-Banishing_LLM_Hallucinations_Requires_Rethinking_Generalization.html#appendix",
    "href": "posts/Banishing_LLM_Hallucinations_Requires_Rethinking_Generalization/2024-06-25-Banishing_LLM_Hallucinations_Requires_Rethinking_Generalization.html#appendix",
    "title": "Banishing LLM Hallucinations Requires Rethinking Generalization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17642v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17642v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5811"
  },
  {
    "objectID": "posts/Averaging_log_likelihoods_in_direct_alignment/2024-06-27-Averaging_log_likelihoods_in_direct_alignment.html#appendix",
    "href": "posts/Averaging_log_likelihoods_in_direct_alignment/2024-06-27-Averaging_log_likelihoods_in_direct_alignment.html#appendix",
    "title": "Averaging log-likelihoods in direct alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19188v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19188v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5452"
  },
  {
    "objectID": "posts/Subtractive_Training_for_Music_Stem_Insertion_using_Latent_Diffusion_Models/2024-06-27-Subtractive_Training_for_Music_Stem_Insertion_using_Latent_Diffusion_Models.html#appendix",
    "href": "posts/Subtractive_Training_for_Music_Stem_Insertion_using_Latent_Diffusion_Models/2024-06-27-Subtractive_Training_for_Music_Stem_Insertion_using_Latent_Diffusion_Models.html#appendix",
    "title": "Subtractive Training for Music Stem Insertion using Latent Diffusion Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19328v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19328v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1133"
  },
  {
    "objectID": "posts/Supporters_and_Skeptics_LLM_based_Analysis_of_Engagement_with_Mental_Health_(Mis)Information_Content_on_Video_sharing_Platforms/2024-07-02-Supporters_and_Skeptics_LLM_based_Analysis_of_Engagement_with_Mental_Health_(Mis)Information_Content_on_Video_sharing_Platforms.html#appendix",
    "href": "posts/Supporters_and_Skeptics_LLM_based_Analysis_of_Engagement_with_Mental_Health_(Mis)Information_Content_on_Video_sharing_Platforms/2024-07-02-Supporters_and_Skeptics_LLM_based_Analysis_of_Engagement_with_Mental_Health_(Mis)Information_Content_on_Video_sharing_Platforms.html#appendix",
    "title": "Supporters and Skeptics: LLM-based Analysis of Engagement with Mental Health (Mis)Information Content on Video-sharing Platforms",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02662v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02662v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12539"
  },
  {
    "objectID": "posts/Towards_Optimizing_and_Evaluating_a_Retrieval_Augmented_QA_Chatbot_using_LLMs_with_Human_in_the_Loop/2024-07-08-Towards_Optimizing_and_Evaluating_a_Retrieval_Augmented_QA_Chatbot_using_LLMs_with_Human_in_the_Loop.html#appendix",
    "href": "posts/Towards_Optimizing_and_Evaluating_a_Retrieval_Augmented_QA_Chatbot_using_LLMs_with_Human_in_the_Loop/2024-07-08-Towards_Optimizing_and_Evaluating_a_Retrieval_Augmented_QA_Chatbot_using_LLMs_with_Human_in_the_Loop.html#appendix",
    "title": "Towards Optimizing and Evaluating a Retrieval Augmented QA Chatbot using LLMs with Human in the Loop",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05925v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05925v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6545"
  },
  {
    "objectID": "posts/Accessing_GPT_4_level_Mathematical_Olympiad_Solutions_via_Monte_Carlo_Tree_Self_refine_with_LLaMa_3_8B/2024-06-11-Accessing_GPT_4_level_Mathematical_Olympiad_Solutions_via_Monte_Carlo_Tree_Self_refine_with_LLaMa_3_8B.html#appendix",
    "href": "posts/Accessing_GPT_4_level_Mathematical_Olympiad_Solutions_via_Monte_Carlo_Tree_Self_refine_with_LLaMa_3_8B/2024-06-11-Accessing_GPT_4_level_Mathematical_Olympiad_Solutions_via_Monte_Carlo_Tree_Self_refine_with_LLaMa_3_8B.html#appendix",
    "title": "Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07394v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07394v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5818"
  },
  {
    "objectID": "posts/Large_Language_Models_are_Interpretable_Learners/2024-06-25-Large_Language_Models_are_Interpretable_Learners.html#major-findings",
    "href": "posts/Large_Language_Models_are_Interpretable_Learners/2024-06-25-Large_Language_Models_are_Interpretable_Learners.html#major-findings",
    "title": "Large Language Models are Interpretable Learners",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nLSPs effectively bridge the gap between expressiveness and interpretability in machine learning models by leveraging pretrained LLMs and symbolic programs.\nThe proposed divide-and-conquer approach to incrementally build the program from scratch, guided by LLMs, demonstrates superior performance compared to traditional methods.\nThe knowledge learned by LSPs is easily transferable to humans, other LLMs, and generalizes well to out-of-distribution samples."
  },
  {
    "objectID": "posts/Large_Language_Models_are_Interpretable_Learners/2024-06-25-Large_Language_Models_are_Interpretable_Learners.html#analysis-and-critique",
    "href": "posts/Large_Language_Models_are_Interpretable_Learners/2024-06-25-Large_Language_Models_are_Interpretable_Learners.html#analysis-and-critique",
    "title": "Large Language Models are Interpretable Learners",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents an innovative approach to addressing the trade-off between expressiveness and interpretability in machine learning models. The use of pretrained LLMs and symbolic programs in LSPs offers a promising solution to this long-standing challenge.\nHowever, the paper does not discuss potential limitations or unanswered questions that may arise from the proposed method. For instance, the reliance on pretrained LLMs may introduce biases or limitations in the learned programs, as these models are trained on specific datasets and may not generalize well to all scenarios. Additionally, the paper does not address the computational cost of training LSPs, which may be a significant concern for large-scale applications.\nFur"
  },
  {
    "objectID": "posts/Large_Language_Models_are_Interpretable_Learners/2024-06-25-Large_Language_Models_are_Interpretable_Learners.html#appendix",
    "href": "posts/Large_Language_Models_are_Interpretable_Learners/2024-06-25-Large_Language_Models_are_Interpretable_Learners.html#appendix",
    "title": "Large Language Models are Interpretable Learners",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17224v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17224v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8763"
  },
  {
    "objectID": "posts/Do_they_mean_us_Interpreting_Referring_Expressions_in_Intergroup_Bias/2024-06-25-Do_they_mean_us_Interpreting_Referring_Expressions_in_Intergroup_Bias.html",
    "href": "posts/Do_they_mean_us_Interpreting_Referring_Expressions_in_Intergroup_Bias/2024-06-25-Do_they_mean_us_Interpreting_Referring_Expressions_in_Intergroup_Bias.html",
    "title": "Do they mean ‘us’? Interpreting Referring Expressions in Intergroup Bias",
    "section": "",
    "text": "Summary:\nThis paper presents a study on intergroup bias in language, focusing on the variations in language used by in-group and out-group members in online sports forums. The authors curate a unique dataset of over 6 million game-time comments from opposing perspectives in NFL team subreddits, each comment grounded in non-linguistic descriptions of the events that precipitated these comments. The study reveals that modeling the bias through tagging of implicit and explicit referring expressions requires a rich, contextual understanding of language and the world. The authors use LLMs for automated tagging and discover that some LLMs perform best when prompted with linguistic descriptions of the win probability at the time of the comment. Large-scale tagging of comments using LLMs uncovers linear variations in the form of referent across win probabilities that distinguish in-group and out-group utterances.\nMajor Findings:"
  },
  {
    "objectID": "posts/Do_they_mean_us_Interpreting_Referring_Expressions_in_Intergroup_Bias/2024-06-25-Do_they_mean_us_Interpreting_Referring_Expressions_in_Intergroup_Bias.html#appendix",
    "href": "posts/Do_they_mean_us_Interpreting_Referring_Expressions_in_Intergroup_Bias/2024-06-25-Do_they_mean_us_Interpreting_Referring_Expressions_in_Intergroup_Bias.html#appendix",
    "title": "Do they mean ‘us’? Interpreting Referring Expressions in Intergroup Bias",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17947v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17947v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14790"
  },
  {
    "objectID": "posts/Safe_Unlearning_A_Surprisingly_Effective_and_Generalizable_Solution_to_Defend_Against_Jailbreak_Attacks/2024-07-03-Safe_Unlearning_A_Surprisingly_Effective_and_Generalizable_Solution_to_Defend_Against_Jailbreak_Attacks.html",
    "href": "posts/Safe_Unlearning_A_Surprisingly_Effective_and_Generalizable_Solution_to_Defend_Against_Jailbreak_Attacks/2024-07-03-Safe_Unlearning_A_Surprisingly_Effective_and_Generalizable_Solution_to_Defend_Against_Jailbreak_Attacks.html",
    "title": "Safe Unlearning: A Surprisingly Effective and Generalizable Solution to Defend Against Jailbreak Attacks",
    "section": "",
    "text": "Summary:\nThe paper “Safe Unlearning: A Surprisingly Effective and Generalizable Solution to Defend Against Jailbreak Attacks” presents a novel approach to address the vulnerability of large language models (LLMs) to jailbreak attacks. The authors propose unlearning harmful knowledge in the LLM as a more effective way to defend against such attacks than mainstream supervised fine-tuning (SFT) approaches. The proposed method, called Safe Unlearning, involves training the LLM with a small set of raw harmful questions without incorporating any jailbreak prompts. The results show that Safe Unlearning significantly outperforms Llama2-7B-Chat, which is fine-tuned on a large number of safety alignment samples, in terms of Attack Success Rate (ASR) on out-of-distribution (OOD) harmful questions wrapped with various complex jailbreak prompts. The authors attribute the strong generalization ability of Safe Unlearning to the intrinsic relatedness among harmful responses across harmful questions.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an interesting and novel approach to addressing the vulnerability of LLMs to jailbreak attacks. The proposed method, Safe Unlearning, shows promising results in terms of reducing the ASR on OOD harmful questions wrapped with various complex jailbreak prompts. However, the paper does not provide a detailed comparison of Safe Unlearning with other unlearning-based approaches, which could have strengthened the argument for the proposed method. Additionally, the paper does not discuss the potential limitations or shortcomings of Safe Unlearning, such as the impact of unlearning on the overall performance of the LLM or the potential for overfitting to the small set of raw harmful questions used in training. Overall, the paper provides a valuable"
  },
  {
    "objectID": "posts/Safe_Unlearning_A_Surprisingly_Effective_and_Generalizable_Solution_to_Defend_Against_Jailbreak_Attacks/2024-07-03-Safe_Unlearning_A_Surprisingly_Effective_and_Generalizable_Solution_to_Defend_Against_Jailbreak_Attacks.html#appendix",
    "href": "posts/Safe_Unlearning_A_Surprisingly_Effective_and_Generalizable_Solution_to_Defend_Against_Jailbreak_Attacks/2024-07-03-Safe_Unlearning_A_Surprisingly_Effective_and_Generalizable_Solution_to_Defend_Against_Jailbreak_Attacks.html#appendix",
    "title": "Safe Unlearning: A Surprisingly Effective and Generalizable Solution to Defend Against Jailbreak Attacks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02855v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02855v1\n\n\nTruncated\nFalse\n\n\nWord Count\n16311"
  },
  {
    "objectID": "posts/Assessing_Code_Generation_with_Intermediate_Languages/2024-07-07-Assessing_Code_Generation_with_Intermediate_Languages.html#appendix",
    "href": "posts/Assessing_Code_Generation_with_Intermediate_Languages/2024-07-07-Assessing_Code_Generation_with_Intermediate_Languages.html#appendix",
    "title": "Assessing Code Generation with Intermediate Languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05411v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05411v1\n\n\nTruncated\nFalse\n\n\nWord Count\n370"
  },
  {
    "objectID": "posts/Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias/2024-07-08-Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias.html",
    "href": "posts/Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias/2024-07-08-Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias.html",
    "title": "Do Multilingual Large Language Models Mitigate Stereotype Bias?",
    "section": "",
    "text": "Summary: This paper investigates the impact of multilingual training on bias mitigation in large language models (LLMs). The authors train six LLMs of identical size (2.6B parameters) and architecture, including five monolingual models (English, German, French, Italian, and Spanish) and one multilingual model. The models are evaluated on standard bias benchmarks, which are automatically translated and verified for both translation quality and bias preservation. The results show that multilingual training effectively mitigates bias, and multilingual models achieve not only lower bias but also superior prediction accuracy compared to monolingual models with the same amount of training data, model architecture, and size.\nMajor Findings: 1. Multilingual training effectively mitigates bias in LLMs. 2. Multilingual models achieve lower bias than monolingual models with the same amount of training data, model architecture, and size. 3. Multilingual models outperform monolingual models in prediction accuracy.\nAnalysis and Critique: The paper presents a well-structured and coherent summary of the research, providing a clear overview of the methodology and findings. The use of a controlled setting and the evaluation of both bias and prediction accuracy are strengths of the study. However, the paper does not discuss potential limitations or shortcomings of the research, such as the generalizability of the findings to other languages or the impact of different translation methods on the results. Additionally, the paper does not address the potential for biases to be introduced during the translation process, which could affect the validity of the results. Further research is needed to explore these issues and to validate the findings in other contexts."
  },
  {
    "objectID": "posts/Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias/2024-07-08-Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias.html#appendix",
    "href": "posts/Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias/2024-07-08-Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias.html#appendix",
    "title": "Do Multilingual Large Language Models Mitigate Stereotype Bias?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05740v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05740v1\n\n\nTruncated\nFalse\n\n\nWord Count\n21234"
  },
  {
    "objectID": "posts/Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing/2024-06-20-Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing.html",
    "href": "posts/Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing/2024-06-20-Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing.html",
    "title": "Raising the Bar: Investigating the Values of Large Language Models via Generative Evolving Testing",
    "section": "",
    "text": "Summary:\nThe paper proposes a novel framework called GETA (Generative Evolving Testing of vAlues) to address the evaluation chronoeffect problem in assessing the value alignment of Large Language Models (LLMs). GETA incorporates an iteratively-updated item generator that infers each LLM’s moral boundaries and generates difficulty-tailored testing items, accurately reflecting the true alignment extent. This process theoretically learns a joint distribution of item and model response, with item difficulty and value conformity as latent variables. The generator co-evolves with the LLM, addressing the chronoeffect. The paper evaluates various popular LLMs and demonstrates that GETA can create difficulty-matching testing items and more accurately assess LLMs’ values, better consistent with their performance on unseen OOD and i.i.d. items.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a promising approach to address the evaluation chronoeffect problem in assessing the value alignment of LLMs. However, there are some potential limitations and areas for further research:\nOverall, the paper presents an innovative approach to address a significant challenge in evaluating LLMs, and further research is needed to fully understand its"
  },
  {
    "objectID": "posts/Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing/2024-06-20-Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing.html#appendix",
    "href": "posts/Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing/2024-06-20-Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing.html#appendix",
    "title": "Raising the Bar: Investigating the Values of Large Language Models via Generative Evolving Testing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14230v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14230v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11743"
  },
  {
    "objectID": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#major-findings",
    "href": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#major-findings",
    "title": "Teaching Language Models to Self-Improve by Learning from Language Feedback",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nSRT significantly outperforms strong baselines across diverse tasks and model sizes, with an average performance enhancement of 3.7 to 4.0 points.\nWhen applied to a 70B parameter model, SRT increases the win rate from 9.6% to 25.8% on the AlpacaEval 2.0 benchmark, surpassing well-established systems such as GPT-4-0314, Claude 2, and Gemini.\nThe success of SRT primarily stems from its language feedback feature, which identifies weak areas and offers valuable suggestions for improvement."
  },
  {
    "objectID": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#analysis-and-critique",
    "href": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#analysis-and-critique",
    "title": "Teaching Language Models to Self-Improve by Learning from Language Feedback",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper presents a novel and promising approach to aligning language models using self-refinement and language feedback.\nThe empirical evaluations demonstrate the effectiveness of SRT in improving model performance across various tasks and model sizes.\nThe paper highlights the crucial role of language feedback in the success of SRT, suggesting potential for further exploration in this direction.\nHowever, the paper does not discuss potential limitations or challenges associated with the SRT method, such as the computational cost of generating feedback and refinements or the potential for overfitting to the feedback.\nAdditionally, the paper does not address the potential for biases in the feedback and refinements generated by the more advanced model, which could impact the alignment of the base model.\nFuture work could explore these limitations and potential solutions to improve the SRT method."
  },
  {
    "objectID": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#appendix",
    "href": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#appendix",
    "title": "Teaching Language Models to Self-Improve by Learning from Language Feedback",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07168v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07168v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6361"
  },
  {
    "objectID": "posts/Assessing_the_Code_Clone_Detection_Capability_of_Large_Language_Models/2024-07-02-Assessing_the_Code_Clone_Detection_Capability_of_Large_Language_Models.html#appendix",
    "href": "posts/Assessing_the_Code_Clone_Detection_Capability_of_Large_Language_Models/2024-07-02-Assessing_the_Code_Clone_Detection_Capability_of_Large_Language_Models.html#appendix",
    "title": "Assessing the Code Clone Detection Capability of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02402v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02402v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4970"
  },
  {
    "objectID": "posts/Adversarial_Contrastive_Decoding_Boosting_Safety_Alignment_of_Large_Language_Models_via_Opposite_Prompt_Optimization/2024-06-24-Adversarial_Contrastive_Decoding_Boosting_Safety_Alignment_of_Large_Language_Models_via_Opposite_Prompt_Optimization.html#appendix",
    "href": "posts/Adversarial_Contrastive_Decoding_Boosting_Safety_Alignment_of_Large_Language_Models_via_Opposite_Prompt_Optimization/2024-06-24-Adversarial_Contrastive_Decoding_Boosting_Safety_Alignment_of_Large_Language_Models_via_Opposite_Prompt_Optimization.html#appendix",
    "title": "Adversarial Contrastive Decoding: Boosting Safety Alignment of Large Language Models via Opposite Prompt Optimization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16743v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16743v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6567"
  },
  {
    "objectID": "posts/Jailbreak_Paradox_The_Achilles_Heel_of_LLMs/2024-06-18-Jailbreak_Paradox_The_Achilles_Heel_of_LLMs.html#appendix",
    "href": "posts/Jailbreak_Paradox_The_Achilles_Heel_of_LLMs/2024-06-18-Jailbreak_Paradox_The_Achilles_Heel_of_LLMs.html#appendix",
    "title": "Jailbreak Paradox: The Achilles’ Heel of LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12702v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12702v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4006"
  },
  {
    "objectID": "posts/Improving_Expert_Radiology_Report_Summarization_by_Prompting_Large_Language_Models_with_a_Layperson_Summary/2024-06-20-Improving_Expert_Radiology_Report_Summarization_by_Prompting_Large_Language_Models_with_a_Layperson_Summary.html#appendix",
    "href": "posts/Improving_Expert_Radiology_Report_Summarization_by_Prompting_Large_Language_Models_with_a_Layperson_Summary/2024-06-20-Improving_Expert_Radiology_Report_Summarization_by_Prompting_Large_Language_Models_with_a_Layperson_Summary.html#appendix",
    "title": "Improving Expert Radiology Report Summarization by Prompting Large Language Models with a Layperson Summary",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14500v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14500v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8909"
  },
  {
    "objectID": "posts/Task_Oriented_In_Domain_Data_Augmentation/2024-06-24-Task_Oriented_In_Domain_Data_Augmentation.html#appendix",
    "href": "posts/Task_Oriented_In_Domain_Data_Augmentation/2024-06-24-Task_Oriented_In_Domain_Data_Augmentation.html#appendix",
    "title": "Task Oriented In-Domain Data Augmentation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16694v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16694v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6953"
  },
  {
    "objectID": "posts/Synthetic_Multimodal_Question_Generation/2024-07-02-Synthetic_Multimodal_Question_Generation.html#summary",
    "href": "posts/Synthetic_Multimodal_Question_Generation/2024-07-02-Synthetic_Multimodal_Question_Generation.html#summary",
    "title": "Synthetic Multimodal Question Generation",
    "section": "Summary:",
    "text": "Summary:\nThe paper introduces a method for Synthetic Multimodal Question Generation (SMMQG), a framework that leverages the interplay between a retriever, a large language model (LLM), and a large multimodal model (LMM) to generate question-answer pairs directly from multimodal documents. SMMQG enables fine-grained control over the styles and modalities of questions, and is capable of producing both unimodal and cross-modal questions. The authors use SMMQG to generate an MMRAG dataset of 1024 questions over Wikipedia documents and evaluate state-of-the-art models using it, revealing insights into model performance that are attainable only through style- and modality-specific evaluation data. A human study is conducted to measure the quality of the synthetic data, which is found to be on par with the quality of the crowdsourced benchmark MMQA."
  },
  {
    "objectID": "posts/Synthetic_Multimodal_Question_Generation/2024-07-02-Synthetic_Multimodal_Question_Generation.html#major-findings",
    "href": "posts/Synthetic_Multimodal_Question_Generation/2024-07-02-Synthetic_Multimodal_Question_Generation.html#major-findings",
    "title": "Synthetic Multimodal Question Generation",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nSMMQG is a powerful approach to question-answering over multimodal documents, enabling fine-grained control over the styles and modalities of questions.\nThe quality of the synthetic data generated by SMMQG is on par with the quality of the crowdsourced benchmark MMQA, as demonstrated by a human study.\nEvaluation results using the SMMQG dataset strongly concur with those obtained using MMQA, demonstrating that the synthetic dataset can be used in place of MMQA for model selection."
  },
  {
    "objectID": "posts/Synthetic_Multimodal_Question_Generation/2024-07-02-Synthetic_Multimodal_Question_Generation.html#analysis-and-critique",
    "href": "posts/Synthetic_Multimodal_Question_Generation/2024-07-02-Synthetic_Multimodal_Question_Generation.html#analysis-and-critique",
    "title": "Synthetic Multimodal Question Generation",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a novel and promising approach to generating synthetic multimodal question-answer pairs, addressing a key challenge in evaluating MMRAG systems. The use of a large language model and a large multimodal model in conjunction with a retriever allows for the generation of diverse and high-quality questions and answers. The evaluation of state-of-the-art models using the SMMQG dataset provides valuable insights into model performance, and the human study confirms the quality of the synthetic data.\nHowever, the paper does not discuss potential limitations or biases in the SMMQG framework, nor does it address the issue of generalizability to"
  },
  {
    "objectID": "posts/Synthetic_Multimodal_Question_Generation/2024-07-02-Synthetic_Multimodal_Question_Generation.html#appendix",
    "href": "posts/Synthetic_Multimodal_Question_Generation/2024-07-02-Synthetic_Multimodal_Question_Generation.html#appendix",
    "title": "Synthetic Multimodal Question Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02233v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02233v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13736"
  },
  {
    "objectID": "posts/Whats_in_an_embedding_Would_a_rose_by_any_embedding_smell_as_sweet/2024-06-11-Whats_in_an_embedding_Would_a_rose_by_any_embedding_smell_as_sweet.html#appendix",
    "href": "posts/Whats_in_an_embedding_Would_a_rose_by_any_embedding_smell_as_sweet/2024-06-11-Whats_in_an_embedding_Would_a_rose_by_any_embedding_smell_as_sweet.html#appendix",
    "title": "What’s in an embedding? Would a rose by any embedding smell as sweet?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06870v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06870v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5609"
  },
  {
    "objectID": "posts/Aligning_Teacher_with_Student_Preferences_for_Tailored_Training_Data_Generation/2024-06-27-Aligning_Teacher_with_Student_Preferences_for_Tailored_Training_Data_Generation.html#appendix",
    "href": "posts/Aligning_Teacher_with_Student_Preferences_for_Tailored_Training_Data_Generation/2024-06-27-Aligning_Teacher_with_Student_Preferences_for_Tailored_Training_Data_Generation.html#appendix",
    "title": "Aligning Teacher with Student Preferences for Tailored Training Data Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19227v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19227v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8697"
  },
  {
    "objectID": "posts/Optimizing_Psychological_Counseling_with_Instruction_Tuned_Large_Language_Models/2024-06-19-Optimizing_Psychological_Counseling_with_Instruction_Tuned_Large_Language_Models.html#appendix",
    "href": "posts/Optimizing_Psychological_Counseling_with_Instruction_Tuned_Large_Language_Models/2024-06-19-Optimizing_Psychological_Counseling_with_Instruction_Tuned_Large_Language_Models.html#appendix",
    "title": "Optimizing Psychological Counseling with Instruction-Tuned Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13617v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13617v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4397"
  },
  {
    "objectID": "posts/GraphCoder_Enhancing_Repository_Level_Code_Completion_via_Code_Context_Graph_based_Retrieval_and_Language_Model/2024-06-11-GraphCoder_Enhancing_Repository_Level_Code_Completion_via_Code_Context_Graph_based_Retrieval_and_Language_Model.html#appendix",
    "href": "posts/GraphCoder_Enhancing_Repository_Level_Code_Completion_via_Code_Context_Graph_based_Retrieval_and_Language_Model/2024-06-11-GraphCoder_Enhancing_Repository_Level_Code_Completion_via_Code_Context_Graph_based_Retrieval_and_Language_Model.html#appendix",
    "title": "GraphCoder: Enhancing Repository-Level Code Completion via Code Context Graph-based Retrieval and Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07003v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07003v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9656"
  },
  {
    "objectID": "posts/CFinBench_A_Comprehensive_Chinese_Financial_Benchmark_for_Large_Language_Models/2024-07-02-CFinBench_A_Comprehensive_Chinese_Financial_Benchmark_for_Large_Language_Models.html#appendix",
    "href": "posts/CFinBench_A_Comprehensive_Chinese_Financial_Benchmark_for_Large_Language_Models/2024-07-02-CFinBench_A_Comprehensive_Chinese_Financial_Benchmark_for_Large_Language_Models.html#appendix",
    "title": "CFinBench: A Comprehensive Chinese Financial Benchmark for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02301v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02301v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7394"
  },
  {
    "objectID": "posts/From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty/2024-07-08-From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty.html",
    "href": "posts/From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty/2024-07-08-From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty.html",
    "title": "From Loops to Oops: Fallback Behaviors of Language Models Under Uncertainty",
    "section": "",
    "text": "Summary:\nThe paper “From Loops to Oops: Fallback Behaviors of Language Models Under Uncertainty” investigates the undesirable behaviors of large language models (LLMs), such as hallucinations and sequence repetitions, and proposes to view these behaviors as fallbacks that models exhibit under uncertainty. The authors categorize fallback behaviors into sequence repetitions, degenerate text, and hallucinations, and extensively analyze them in models from the same family that differ by the amount of pretraining tokens, parameter count, or the inclusion of instruction-following training. The experiments reveal a clear and consistent ordering of fallback behaviors, with more advanced LLMs exhibiting more complex fallback behaviors. The same ordering is observed throughout a single generation, even for the best-performing models, as uncertainty increases. The paper also demonstrates that common decoding techniques, such as random sampling, might alleviate some unwanted behaviors like sequence repetitions but increase harder-to-detect hallucinations.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive analysis of the fallback behaviors of LLMs under uncertainty, offering valuable insights into the relationship between model complexity, training, and the emergence of different fallback behaviors. The authors’ categorization of fallback behaviors and their extensive experiments contribute to a better understanding of the limitations and challenges of LLMs. However, the paper does not discuss potential solutions to mitigate the identified issues or explore the implications of these findings for the development and deployment of LLMs in real-world applications. Additionally, the paper does not address the potential impact of different decoding strategies on the performance and reliability of LLMs. Further research is needed to investigate these aspects and develop more robust and reliable LLMs."
  },
  {
    "objectID": "posts/From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty/2024-07-08-From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty.html#appendix",
    "href": "posts/From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty/2024-07-08-From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty.html#appendix",
    "title": "From Loops to Oops: Fallback Behaviors of Language Models Under Uncertainty",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06071v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06071v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17045"
  },
  {
    "objectID": "posts/Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination/2024-06-10-Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination.html",
    "href": "posts/Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination/2024-06-10-Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination.html",
    "title": "Enhancing Food Safety in Supply Chains: The Potential Role of Large Language Models in Preventing Campylobacter Contamination",
    "section": "",
    "text": "Summary:\nThis study explores the potential of large language models (LLMs), specifically generative pre-trained transformers (GPTs), to mitigate Campylobacter contamination across four typical stages of the food supply chain: primary production, food processing, distribution and retail, and preparation and consumption. The study also considers critical barriers to implementing GPTs at each step of the supply chain and proposes initial measures to overcome these obstacles.\nMajor Findings:\nAnalysis and Critique:\nThe study presents an intriguing potential for LLMs to enhance food safety, but the ‘LLM – food safety’ interface remains largely underexplored. The proposed applications of LLMs in this domain are promising, but they require further investigation and practical applications. The study also acknowledges that the adoption of LLMs in the food industry and agri-food supply chains may face several inhibiting factors, such as technological adoption, cultural barriers, data quality and availability, and technical challenges in integrating LLMs with existing food processing and slaughterhouse systems.\nTo alleviate these barriers and enable the deployment of LLMs for bacterial contamination reduction across food supply chains, a"
  },
  {
    "objectID": "posts/Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination/2024-06-10-Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination.html#appendix",
    "href": "posts/Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination/2024-06-10-Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination.html#appendix",
    "title": "Enhancing Food Safety in Supply Chains: The Potential Role of Large Language Models in Preventing Campylobacter Contamination",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06049v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06049v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18111"
  },
  {
    "objectID": "posts/PaCE_Parsimonious_Concept_Engineering_for_Large_Language_Models/2024-06-06-PaCE_Parsimonious_Concept_Engineering_for_Large_Language_Models.html#appendix",
    "href": "posts/PaCE_Parsimonious_Concept_Engineering_for_Large_Language_Models/2024-06-06-PaCE_Parsimonious_Concept_Engineering_for_Large_Language_Models.html#appendix",
    "title": "PaCE: Parsimonious Concept Engineering for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04331v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04331v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9538"
  },
  {
    "objectID": "posts/Improving_Robustness_of_LLM_based_Speech_Synthesis_by_Learning_Monotonic_Alignment/2024-06-25-Improving_Robustness_of_LLM_based_Speech_Synthesis_by_Learning_Monotonic_Alignment.html#appendix",
    "href": "posts/Improving_Robustness_of_LLM_based_Speech_Synthesis_by_Learning_Monotonic_Alignment/2024-06-25-Improving_Robustness_of_LLM_based_Speech_Synthesis_by_Learning_Monotonic_Alignment.html#appendix",
    "title": "Improving Robustness of LLM-based Speech Synthesis by Learning Monotonic Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17957v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17957v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4644"
  },
  {
    "objectID": "posts/T2VSafetyBench_Evaluating_the_Safety_of_Text_to_Video_Generative_Models/2024-07-08-T2VSafetyBench_Evaluating_the_Safety_of_Text_to_Video_Generative_Models.html#appendix",
    "href": "posts/T2VSafetyBench_Evaluating_the_Safety_of_Text_to_Video_Generative_Models/2024-07-08-T2VSafetyBench_Evaluating_the_Safety_of_Text_to_Video_Generative_Models.html#appendix",
    "title": "T2VSafetyBench: Evaluating the Safety of Text-to-Video Generative Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05965v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05965v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8108"
  },
  {
    "objectID": "posts/Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue/2024-06-04-Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue.html",
    "href": "posts/Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue/2024-06-04-Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue.html",
    "title": "Position Debiasing Fine-Tuning for Causal Perception in Long-Term Dialogue",
    "section": "",
    "text": "Summary:\nThe paper proposes a novel method, Causal Perception long-term Dialogue framework (CPD), to alleviate the position bias in large language models (LLMs) for long-term dialogue tasks. The CPD framework employs perturbation-based causal variable discovery to extract causally relevant utterances from dialogue history and enhances the model’s causal perception during fine-tuning. The framework includes a local-position awareness method for inter-sentence position correlation elimination and a causal-perception fine-tuning strategy to improve the model’s ability to discover causal invariant factors. Experimental results on two datasets demonstrate that the proposed method effectively alleviates position bias and achieves significant progress compared to existing baselines.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a well-structured and coherent summary of the proposed CPD framework for addressing position bias in LLMs for long-term dialogue tasks. The use of perturbation-based causal variable discovery and the local-position awareness method are innovative approaches to extract causally relevant utterances from dialogue history. The causal-perception fine-tuning strategy also provides a promising direction for improving the model’s ability to discover causal invariant factors.\nHowever, the paper could benefit from a more detailed analysis of the limitations and potential biases of the proposed method. For instance, the paper does not discuss the potential impact of the perturbation-based approach on the model’s performance or the generalizability of the method to other types of dialogue tasks. Additionally, the paper could provide more insights into the potential challenges and trade-offs in implementing the proposed method in real-world applications.\nOverall, the paper presents a promising approach to addressing position bias in LLMs for long-term dialogue tasks. The proposed CPD framework and the experimental results provide valuable insights into the potential of perturbation-based causal variable discovery and causal-perception fine-t"
  },
  {
    "objectID": "posts/Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue/2024-06-04-Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue.html#appendix",
    "href": "posts/Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue/2024-06-04-Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue.html#appendix",
    "title": "Position Debiasing Fine-Tuning for Causal Perception in Long-Term Dialogue",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02002v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02002v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7030"
  },
  {
    "objectID": "posts/REPOEXEC_Evaluate_Code_Generation_with_a_Repository_Level_Executable_Benchmark/2024-06-17-REPOEXEC_Evaluate_Code_Generation_with_a_Repository_Level_Executable_Benchmark.html#appendix",
    "href": "posts/REPOEXEC_Evaluate_Code_Generation_with_a_Repository_Level_Executable_Benchmark/2024-06-17-REPOEXEC_Evaluate_Code_Generation_with_a_Repository_Level_Executable_Benchmark.html#appendix",
    "title": "REPOEXEC: Evaluate Code Generation with a Repository-Level Executable Benchmark",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11927v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11927v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7146"
  },
  {
    "objectID": "posts/Benchmarks_and_Metrics_for_Evaluations_of_Code_Generation_A_Critical_Review/2024-06-18-Benchmarks_and_Metrics_for_Evaluations_of_Code_Generation_A_Critical_Review.html#appendix",
    "href": "posts/Benchmarks_and_Metrics_for_Evaluations_of_Code_Generation_A_Critical_Review/2024-06-18-Benchmarks_and_Metrics_for_Evaluations_of_Code_Generation_A_Critical_Review.html#appendix",
    "title": "Benchmarks and Metrics for Evaluations of Code Generation: A Critical Review",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12655v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12655v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5871"
  },
  {
    "objectID": "posts/SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research/2024-07-03-SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research.html#major-findings",
    "href": "posts/SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research/2024-07-03-SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research.html#major-findings",
    "title": "SemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nModels achieve above-chance classification performance, with prompt engineering significantly improving their outcome. Some models achieve close-to-clinical performance and reasoning.\nGPT-4 emerges as the top-performing model across all evaluation metrics, while Mixtral8x7B, while competitive with GPT-4 in performance, exhibits tendencies to hallucinate in source citations and provides incomplete and partially incorrect reasoning.\nGPT-3.5 and Qwen-72B exhibit higher confidence levels in their outputs, albeit with reduced correctness."
  },
  {
    "objectID": "posts/SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research/2024-07-03-SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research.html#analysis-and-critique",
    "href": "posts/SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research/2024-07-03-SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research.html#analysis-and-critique",
    "title": "SemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe study provides the first extensive benchmark comparing current SOTA LLMs in the medical domain of epilepsy and highlights their ability to leverage unstructured texts from patients’ medical history to aid diagnostic processes in health care.\nHowever, the analyses also reveal significant pitfalls with several models being overly confident while showing poor performance, as well as exhibiting citation errors and hallucinations.\nThe lack of systematic evaluation of LLMs’ understanding of specific clinical domains is a limitation, requiring large-scale annotated text-datasets, systematic investigation of prompt designs, and exploration of in-context learning strategies.\nThe study does not address the potential biases in the annotated clinical database, which could impact the performance of the LLMs.\nThe study does not provide a comparison with other machine learning or deep learning models, which could offer a more comprehensive understanding of the performance of LLMs in this domain.\nThe study does not discuss the potential ethical implications of using LLMs for epilepsy diagnosis, such as the risk of over"
  },
  {
    "objectID": "posts/SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research/2024-07-03-SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research.html#appendix",
    "href": "posts/SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research/2024-07-03-SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research.html#appendix",
    "title": "SemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03004v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03004v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6699"
  },
  {
    "objectID": "posts/LayoutCopilot_An_LLM_powered_Multi_agent_Collaborative_Framework_for_Interactive_Analog_Layout_Design/2024-06-27-LayoutCopilot_An_LLM_powered_Multi_agent_Collaborative_Framework_for_Interactive_Analog_Layout_Design.html#appendix",
    "href": "posts/LayoutCopilot_An_LLM_powered_Multi_agent_Collaborative_Framework_for_Interactive_Analog_Layout_Design/2024-06-27-LayoutCopilot_An_LLM_powered_Multi_agent_Collaborative_Framework_for_Interactive_Analog_Layout_Design.html#appendix",
    "title": "LayoutCopilot: An LLM-powered Multi-agent Collaborative Framework for Interactive Analog Layout Design",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18873v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18873v1\n\n\nTruncated\nFalse\n\n\nWord Count\n91"
  },
  {
    "objectID": "posts/Towards_a_Client_Centered_Assessment_of_LLM_Therapists_by_Client_Simulation/2024-06-18-Towards_a_Client_Centered_Assessment_of_LLM_Therapists_by_Client_Simulation.html#appendix",
    "href": "posts/Towards_a_Client_Centered_Assessment_of_LLM_Therapists_by_Client_Simulation/2024-06-18-Towards_a_Client_Centered_Assessment_of_LLM_Therapists_by_Client_Simulation.html#appendix",
    "title": "Towards a Client-Centered Assessment of LLM Therapists by Client Simulation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12266v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12266v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10101"
  },
  {
    "objectID": "posts/Adaptable_Logical_Control_for_Large_Language_Models/2024-06-19-Adaptable_Logical_Control_for_Large_Language_Models.html#appendix",
    "href": "posts/Adaptable_Logical_Control_for_Large_Language_Models/2024-06-19-Adaptable_Logical_Control_for_Large_Language_Models.html#appendix",
    "title": "Adaptable Logical Control for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13892v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13892v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7583"
  },
  {
    "objectID": "posts/Explicit_and_Implicit_Large_Language_Model_Personas_Generate_Opinions_but_Fail_to_Replicate_Deeper_Perceptions_and_Biases/2024-06-20-Explicit_and_Implicit_Large_Language_Model_Personas_Generate_Opinions_but_Fail_to_Replicate_Deeper_Perceptions_and_Biases.html#appendix",
    "href": "posts/Explicit_and_Implicit_Large_Language_Model_Personas_Generate_Opinions_but_Fail_to_Replicate_Deeper_Perceptions_and_Biases/2024-06-20-Explicit_and_Implicit_Large_Language_Model_Personas_Generate_Opinions_but_Fail_to_Replicate_Deeper_Perceptions_and_Biases.html#appendix",
    "title": "Explicit and Implicit Large Language Model Personas Generate Opinions but Fail to Replicate Deeper Perceptions and Biases",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14462v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14462v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6689"
  },
  {
    "objectID": "posts/GraphReader_Building_Graph_based_Agent_to_Enhance_Long_Context_Abilities_of_Large_Language_Models/2024-06-20-GraphReader_Building_Graph_based_Agent_to_Enhance_Long_Context_Abilities_of_Large_Language_Models.html#appendix",
    "href": "posts/GraphReader_Building_Graph_based_Agent_to_Enhance_Long_Context_Abilities_of_Large_Language_Models/2024-06-20-GraphReader_Building_Graph_based_Agent_to_Enhance_Long_Context_Abilities_of_Large_Language_Models.html#appendix",
    "title": "GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14550v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14550v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7927"
  },
  {
    "objectID": "posts/Privacy_in_LLM_based_Recommendation_Recent_Advances_and_Future_Directions/2024-06-03-Privacy_in_LLM_based_Recommendation_Recent_Advances_and_Future_Directions.html#appendix",
    "href": "posts/Privacy_in_LLM_based_Recommendation_Recent_Advances_and_Future_Directions/2024-06-03-Privacy_in_LLM_based_Recommendation_Recent_Advances_and_Future_Directions.html#appendix",
    "title": "Privacy in LLM-based Recommendation: Recent Advances and Future Directions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01363v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01363v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3447"
  },
  {
    "objectID": "posts/Large_Language_Models_Make_Sample_Efficient_Recommender_Systems/2024-06-04-Large_Language_Models_Make_Sample_Efficient_Recommender_Systems.html#appendix",
    "href": "posts/Large_Language_Models_Make_Sample_Efficient_Recommender_Systems/2024-06-04-Large_Language_Models_Make_Sample_Efficient_Recommender_Systems.html#appendix",
    "title": "Large Language Models Make Sample-Efficient Recommender Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02368v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02368v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3649"
  },
  {
    "objectID": "posts/Large_Language_Models_for_Automatic_Milestone_Detection_in_Group_Discussions/2024-06-16-Large_Language_Models_for_Automatic_Milestone_Detection_in_Group_Discussions.html#appendix",
    "href": "posts/Large_Language_Models_for_Automatic_Milestone_Detection_in_Group_Discussions/2024-06-16-Large_Language_Models_for_Automatic_Milestone_Detection_in_Group_Discussions.html#appendix",
    "title": "Large Language Models for Automatic Milestone Detection in Group Discussions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.10842v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.10842v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4838"
  },
  {
    "objectID": "posts/Disentangling_Knowledge_based_and_Visual_Reasoning_by_Question_Decomposition_in_KB_VQA/2024-06-27-Disentangling_Knowledge_based_and_Visual_Reasoning_by_Question_Decomposition_in_KB_VQA.html#appendix",
    "href": "posts/Disentangling_Knowledge_based_and_Visual_Reasoning_by_Question_Decomposition_in_KB_VQA/2024-06-27-Disentangling_Knowledge_based_and_Visual_Reasoning_by_Question_Decomposition_in_KB_VQA.html#appendix",
    "title": "Disentangling Knowledge-based and Visual Reasoning by Question Decomposition in KB-VQA",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18839v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18839v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4974"
  },
  {
    "objectID": "posts/Are_LLMs_Naturally_Good_at_Synthetic_Tabular_Data_Generation/2024-06-20-Are_LLMs_Naturally_Good_at_Synthetic_Tabular_Data_Generation.html#appendix",
    "href": "posts/Are_LLMs_Naturally_Good_at_Synthetic_Tabular_Data_Generation/2024-06-20-Are_LLMs_Naturally_Good_at_Synthetic_Tabular_Data_Generation.html#appendix",
    "title": "Are LLMs Naturally Good at Synthetic Tabular Data Generation?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14541v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14541v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10309"
  },
  {
    "objectID": "posts/Hierarchical_Micro_Segmentations_for_Zero_Trust_Services_via_Large_Language_Model_(LLM)_enhanced_Graph_Diffusion/2024-06-20-Hierarchical_Micro_Segmentations_for_Zero_Trust_Services_via_Large_Language_Model_(LLM)_enhanced_Graph_Diffusion.html#appendix",
    "href": "posts/Hierarchical_Micro_Segmentations_for_Zero_Trust_Services_via_Large_Language_Model_(LLM)_enhanced_Graph_Diffusion/2024-06-20-Hierarchical_Micro_Segmentations_for_Zero_Trust_Services_via_Large_Language_Model_(LLM)_enhanced_Graph_Diffusion.html#appendix",
    "title": "Hierarchical Micro-Segmentations for Zero-Trust Services via Large Language Model (LLM)-enhanced Graph Diffusion",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13964v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13964v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11153"
  },
  {
    "objectID": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#major-findings",
    "href": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#major-findings",
    "title": "Solution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe team proposes a new instruction-tuned vision-language model with two novel ideas: grounding visual cues in the text modality and utilizing an object detection algorithm to capture complex diagrammatic visual patterns.\nThe team achieves a 27.11 WOSA score on the challenge split and qualitatively validates the effectiveness of their proposed approach.\nThe team utilizes the Segmentation Anything Model (SAM) algorithm to capture the complex visual features and uses this information as input for the LLM."
  },
  {
    "objectID": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#analysis-and-critique",
    "href": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#analysis-and-critique",
    "title": "Solution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper does not provide a detailed analysis of the performance of the proposed method compared to other state-of-the-art methods.\nThe paper does not discuss the limitations of the proposed method or any potential biases that were apparent while reviewing the text.\nThe paper does not discuss any methodological issues, conflicting evidence, or areas that require further research or clarification.\nThe paper does not provide a detailed analysis of the performance of the proposed method on different types of puzzles.\nThe paper does not discuss the generalizability of the proposed method to other types of multimodal reasoning tasks."
  },
  {
    "objectID": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#appendix",
    "href": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#appendix",
    "title": "Solution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05963v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05963v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3407"
  },
  {
    "objectID": "posts/DocCGen_Document_based_Controlled_Code_Generation/2024-06-17-DocCGen_Document_based_Controlled_Code_Generation.html#appendix",
    "href": "posts/DocCGen_Document_based_Controlled_Code_Generation/2024-06-17-DocCGen_Document_based_Controlled_Code_Generation.html#appendix",
    "title": "DocCGen: Document-based Controlled Code Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11925v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11925v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9497"
  },
  {
    "objectID": "posts/Graph_Augmented_LLMs_for_Personalized_Health_Insights_A_Case_Study_in_Sleep_Analysis/2024-06-24-Graph_Augmented_LLMs_for_Personalized_Health_Insights_A_Case_Study_in_Sleep_Analysis.html#appendix",
    "href": "posts/Graph_Augmented_LLMs_for_Personalized_Health_Insights_A_Case_Study_in_Sleep_Analysis/2024-06-24-Graph_Augmented_LLMs_for_Personalized_Health_Insights_A_Case_Study_in_Sleep_Analysis.html#appendix",
    "title": "Graph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16252v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16252v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3224"
  },
  {
    "objectID": "posts/PDSS_A_Privacy_Preserving_Framework_for_Step_by_Step_Distillation_of_Large_Language_Models/2024-06-18-PDSS_A_Privacy_Preserving_Framework_for_Step_by_Step_Distillation_of_Large_Language_Models.html#appendix",
    "href": "posts/PDSS_A_Privacy_Preserving_Framework_for_Step_by_Step_Distillation_of_Large_Language_Models/2024-06-18-PDSS_A_Privacy_Preserving_Framework_for_Step_by_Step_Distillation_of_Large_Language_Models.html#appendix",
    "title": "PDSS: A Privacy-Preserving Framework for Step-by-Step Distillation of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12403v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12403v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6497"
  },
  {
    "objectID": "posts/Large_Language_Models_are_Skeptics_False_Negative_Problem_of_Input_conflicting_Hallucination/2024-06-20-Large_Language_Models_are_Skeptics_False_Negative_Problem_of_Input_conflicting_Hallucination.html#appendix",
    "href": "posts/Large_Language_Models_are_Skeptics_False_Negative_Problem_of_Input_conflicting_Hallucination/2024-06-20-Large_Language_Models_are_Skeptics_False_Negative_Problem_of_Input_conflicting_Hallucination.html#appendix",
    "title": "Large Language Models are Skeptics: False Negative Problem of Input-conflicting Hallucination",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13929v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13929v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4576"
  },
  {
    "objectID": "posts/KGym_A_Platform_and_Dataset_to_Benchmark_Large_Language_Models_on_Linux_Kernel_Crash_Resolution/2024-07-02-KGym_A_Platform_and_Dataset_to_Benchmark_Large_Language_Models_on_Linux_Kernel_Crash_Resolution.html#appendix",
    "href": "posts/KGym_A_Platform_and_Dataset_to_Benchmark_Large_Language_Models_on_Linux_Kernel_Crash_Resolution/2024-07-02-KGym_A_Platform_and_Dataset_to_Benchmark_Large_Language_Models_on_Linux_Kernel_Crash_Resolution.html#appendix",
    "title": "KGym: A Platform and Dataset to Benchmark Large Language Models on Linux Kernel Crash Resolution",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02680v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02680v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3950"
  },
  {
    "objectID": "posts/Inducing_Group_Fairness_in_LLM_Based_Decisions/2024-06-24-Inducing_Group_Fairness_in_LLM_Based_Decisions.html#appendix",
    "href": "posts/Inducing_Group_Fairness_in_LLM_Based_Decisions/2024-06-24-Inducing_Group_Fairness_in_LLM_Based_Decisions.html#appendix",
    "title": "Inducing Group Fairness in LLM-Based Decisions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16738v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16738v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5964"
  },
  {
    "objectID": "posts/JailbreakHunter_A_Visual_Analytics_Approach_for_Jailbreak_Prompts_Discovery_from_Large_Scale_Human_LLM_Conversational_Datasets/2024-07-03-JailbreakHunter_A_Visual_Analytics_Approach_for_Jailbreak_Prompts_Discovery_from_Large_Scale_Human_LLM_Conversational_Datasets.html#appendix",
    "href": "posts/JailbreakHunter_A_Visual_Analytics_Approach_for_Jailbreak_Prompts_Discovery_from_Large_Scale_Human_LLM_Conversational_Datasets/2024-07-03-JailbreakHunter_A_Visual_Analytics_Approach_for_Jailbreak_Prompts_Discovery_from_Large_Scale_Human_LLM_Conversational_Datasets.html#appendix",
    "title": "JailbreakHunter: A Visual Analytics Approach for Jailbreak Prompts Discovery from Large-Scale Human-LLM Conversational Datasets",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03045v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03045v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13931"
  },
  {
    "objectID": "posts/Is_ChatGPT_a_Better_Explainer_than_My_Professor_Evaluating_the_Explanation_Capabilities_of_LLMs_in_Conversation_Compared_to_a_Human_Baseline/2024-06-26-Is_ChatGPT_a_Better_Explainer_than_My_Professor_Evaluating_the_Explanation_Capabilities_of_LLMs_in_Conversation_Compared_to_a_Human_Baseline.html#appendix",
    "href": "posts/Is_ChatGPT_a_Better_Explainer_than_My_Professor_Evaluating_the_Explanation_Capabilities_of_LLMs_in_Conversation_Compared_to_a_Human_Baseline/2024-06-26-Is_ChatGPT_a_Better_Explainer_than_My_Professor_Evaluating_the_Explanation_Capabilities_of_LLMs_in_Conversation_Compared_to_a_Human_Baseline.html#appendix",
    "title": "Is ChatGPT a Better Explainer than My Professor?: Evaluating the Explanation Capabilities of LLMs in Conversation Compared to a Human Baseline",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18512v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18512v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4167"
  },
  {
    "objectID": "posts/Self_play_with_Execution_Feedback_Improving_Instruction_following_Capabilities_of_Large_Language_Models/2024-06-19-Self_play_with_Execution_Feedback_Improving_Instruction_following_Capabilities_of_Large_Language_Models.html#appendix",
    "href": "posts/Self_play_with_Execution_Feedback_Improving_Instruction_following_Capabilities_of_Large_Language_Models/2024-06-19-Self_play_with_Execution_Feedback_Improving_Instruction_following_Capabilities_of_Large_Language_Models.html#appendix",
    "title": "Self-play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13542v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13542v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4670"
  },
  {
    "objectID": "posts/Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities/2024-06-11-Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities.html",
    "href": "posts/Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities/2024-06-11-Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities.html",
    "title": "Toxic Memes: A Survey of Computational Perspectives on the Detection and Explanation of Meme Toxicities",
    "section": "",
    "text": "Summary:\nThis paper provides a comprehensive survey of 158 papers on computational perspectives on toxic memes, covering key developments up to early 2024. The study identifies a wide variety of terminology used to refer to toxic memes, highlighting the need for a clearer taxonomy and harmonized definitions. The authors introduce a novel taxonomy and offer insights into various dimensions of meme toxicity, including intent, target, and conveyance tactics. The paper also catalogs datasets containing toxic memes, analyzes prevalent challenges, and identifies emerging trends in computational approaches to toxic meme detection and interpretation. The survey aims to promote interdisciplinary collaboration and innovation to foster media literacy and a safer online ecosystem.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive survey of the literature on computational perspectives on toxic memes, offering valuable insights into the current state of the field. The introduction of a novel taxonomy and harmonized definitions is a significant contribution, as it addresses the need for a clearer taxonomy and harmonized definitions. The paper also identifies emerging trends in computational approaches to toxic meme detection and interpretation, which can guide future research in the field.\nHowever, the paper does not provide a critical analysis of the limitations and biases of the existing literature. Additionally, the paper does not discuss the potential ethical implications of using computational approaches to detect and interpret toxic memes. Future research should address these limitations and consider the ethical implications of using computational approaches to detect and interpret toxic"
  },
  {
    "objectID": "posts/Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities/2024-06-11-Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities.html#appendix",
    "href": "posts/Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities/2024-06-11-Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities.html#appendix",
    "title": "Toxic Memes: A Survey of Computational Perspectives on the Detection and Explanation of Meme Toxicities",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07353v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07353v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20322"
  },
  {
    "objectID": "posts/Single_Character_Perturbations_Break_LLM_Alignment/2024-07-03-Single_Character_Perturbations_Break_LLM_Alignment.html",
    "href": "posts/Single_Character_Perturbations_Break_LLM_Alignment/2024-07-03-Single_Character_Perturbations_Break_LLM_Alignment.html",
    "title": "Single Character Perturbations Break LLM Alignment",
    "section": "",
    "text": "Summary:\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/Single_Character_Perturbations_Break_LLM_Alignment/2024-07-03-Single_Character_Perturbations_Break_LLM_Alignment.html#appendix",
    "href": "posts/Single_Character_Perturbations_Break_LLM_Alignment/2024-07-03-Single_Character_Perturbations_Break_LLM_Alignment.html#appendix",
    "title": "Single Character Perturbations Break LLM Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03232v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03232v1\n\n\nTruncated\nFalse\n\n\nWord Count\n21366"
  },
  {
    "objectID": "posts/A_Comparative_Study_of_DSL_Code_Generation_Fine_Tuning_vs._Optimized_Retrieval_Augmentation/2024-07-03-A_Comparative_Study_of_DSL_Code_Generation_Fine_Tuning_vs._Optimized_Retrieval_Augmentation.html#appendix",
    "href": "posts/A_Comparative_Study_of_DSL_Code_Generation_Fine_Tuning_vs._Optimized_Retrieval_Augmentation/2024-07-03-A_Comparative_Study_of_DSL_Code_Generation_Fine_Tuning_vs._Optimized_Retrieval_Augmentation.html#appendix",
    "title": "A Comparative Study of DSL Code Generation: Fine-Tuning vs. Optimized Retrieval Augmentation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02742v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02742v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6386"
  },
  {
    "objectID": "posts/Benchmark_Data_Contamination_of_Large_Language_Models_A_Survey/2024-06-06-Benchmark_Data_Contamination_of_Large_Language_Models_A_Survey.html#appendix",
    "href": "posts/Benchmark_Data_Contamination_of_Large_Language_Models_A_Survey/2024-06-06-Benchmark_Data_Contamination_of_Large_Language_Models_A_Survey.html#appendix",
    "title": "Benchmark Data Contamination of Large Language Models: A Survey",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04244v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04244v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13688"
  },
  {
    "objectID": "posts/AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models/2024-06-24-AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models.html#summary",
    "href": "posts/AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models/2024-06-24-AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models.html#summary",
    "title": "AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models",
    "section": "Summary:",
    "text": "Summary:\n\nThe paper introduces a unified framework, AutoDetect, to automatically expose weaknesses in LLMs across various tasks.\nThe framework is inspired by the educational assessment process and consists of three LLM-powered agents: Examiner, Questioner, and Assessor.\nAutoDetect demonstrates significant success in uncovering flaws, with an identification success rate exceeding 30% in prominent models such as ChatGPT and Claude.\nThe identified weaknesses can guide specific model improvements, proving more effective than untargeted data augmentation methods like Self-Instruct.\nThe approach has led to substantial enhancements in popular LLMs, including the Llama series and Mistral-7b, boosting their performance by over 10% across several benchmarks."
  },
  {
    "objectID": "posts/AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models/2024-06-24-AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models.html#major-findings",
    "href": "posts/AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models/2024-06-24-AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models.html#major-findings",
    "title": "AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nAutoDetect is a pioneering unified framework that aims to systematically and automatically expose potential weaknesses within LLMs across a variety of tasks.\nThe framework demonstrates exceptional adaptability and effectiveness, with a success rate of over 50% in uncovering deficiencies across multiple models and tasks.\nAutoDetect facilitates significant model improvements. Leveraging the data derived from the weakness detection process, we can effectively enhance model performance, yielding over 10% improvements on several tasks."
  },
  {
    "objectID": "posts/AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models/2024-06-24-AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models/2024-06-24-AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models.html#analysis-and-critique",
    "title": "AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper provides a comprehensive and well-structured approach to identifying weaknesses in LLMs.\nThe use of three specialized roles implemented by LLM-based agents allows for a thorough and tailored testing framework.\nThe iterative search process enables the adjustment of question difficulty for the target model, effectively identifying weaknesses.\nHowever, the paper does not discuss the potential limitations or biases of the framework, which could be a topic for future research.\nAdditionally, the paper does not provide a detailed comparison with other existing methods for weakness detection in LLMs.\nThe paper also does not discuss the potential scalability issues or computational costs associated with the framework.\nFinally, the paper does not provide a detailed analysis of the impact of the identified weaknesses on the overall performance of"
  },
  {
    "objectID": "posts/AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models/2024-06-24-AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models.html#appendix",
    "href": "posts/AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models/2024-06-24-AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models.html#appendix",
    "title": "AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16714v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16714v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5957"
  },
  {
    "objectID": "posts/Beyond_Demographics_Aligning_Role_playing_LLM_based_Agents_Using_Human_Belief_Networks/2024-06-25-Beyond_Demographics_Aligning_Role_playing_LLM_based_Agents_Using_Human_Belief_Networks.html#appendix",
    "href": "posts/Beyond_Demographics_Aligning_Role_playing_LLM_based_Agents_Using_Human_Belief_Networks/2024-06-25-Beyond_Demographics_Aligning_Role_playing_LLM_based_Agents_Using_Human_Belief_Networks.html#appendix",
    "title": "Beyond Demographics: Aligning Role-playing LLM-based Agents Using Human Belief Networks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17232v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17232v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7041"
  },
  {
    "objectID": "posts/Using_Grammar_Masking_to_Ensure_Syntactic_Validity_in_LLM_based_Modeling_Tasks/2024-07-08-Using_Grammar_Masking_to_Ensure_Syntactic_Validity_in_LLM_based_Modeling_Tasks.html#appendix",
    "href": "posts/Using_Grammar_Masking_to_Ensure_Syntactic_Validity_in_LLM_based_Modeling_Tasks/2024-07-08-Using_Grammar_Masking_to_Ensure_Syntactic_Validity_in_LLM_based_Modeling_Tasks.html#appendix",
    "title": "Using Grammar Masking to Ensure Syntactic Validity in LLM-based Modeling Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06146v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06146v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6526"
  },
  {
    "objectID": "posts/Cactus_Towards_Psychological_Counseling_Conversations_using_Cognitive_Behavioral_Theory/2024-07-03-Cactus_Towards_Psychological_Counseling_Conversations_using_Cognitive_Behavioral_Theory.html#appendix",
    "href": "posts/Cactus_Towards_Psychological_Counseling_Conversations_using_Cognitive_Behavioral_Theory/2024-07-03-Cactus_Towards_Psychological_Counseling_Conversations_using_Cognitive_Behavioral_Theory.html#appendix",
    "title": "Cactus: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03103v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03103v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10331"
  },
  {
    "objectID": "posts/S2D_Sorted_Speculative_Decoding_For_More_Efficient_Deployment_of_Nested_Large_Language_Models/2024-07-02-S2D_Sorted_Speculative_Decoding_For_More_Efficient_Deployment_of_Nested_Large_Language_Models.html#appendix",
    "href": "posts/S2D_Sorted_Speculative_Decoding_For_More_Efficient_Deployment_of_Nested_Large_Language_Models/2024-07-02-S2D_Sorted_Speculative_Decoding_For_More_Efficient_Deployment_of_Nested_Large_Language_Models.html#appendix",
    "title": "S2D: Sorted Speculative Decoding For More Efficient Deployment of Nested Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01955v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01955v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6189"
  },
  {
    "objectID": "posts/Fine_tuned_network_relies_on_generic_representation_to_solve_unseen_cognitive_task/2024-06-27-Fine_tuned_network_relies_on_generic_representation_to_solve_unseen_cognitive_task.html#appendix",
    "href": "posts/Fine_tuned_network_relies_on_generic_representation_to_solve_unseen_cognitive_task/2024-06-27-Fine_tuned_network_relies_on_generic_representation_to_solve_unseen_cognitive_task.html#appendix",
    "title": "Fine-tuned network relies on generic representation to solve unseen cognitive task",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18926v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18926v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4648"
  },
  {
    "objectID": "posts/CogMG_Collaborative_Augmentation_Between_Large_Language_Model_and_Knowledge_Graph/2024-06-25-CogMG_Collaborative_Augmentation_Between_Large_Language_Model_and_Knowledge_Graph.html#appendix",
    "href": "posts/CogMG_Collaborative_Augmentation_Between_Large_Language_Model_and_Knowledge_Graph/2024-06-25-CogMG_Collaborative_Augmentation_Between_Large_Language_Model_and_Knowledge_Graph.html#appendix",
    "title": "CogMG: Collaborative Augmentation Between Large Language Model and Knowledge Graph",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17231v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17231v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4470"
  },
  {
    "objectID": "posts/Fairness_and_Bias_in_Multimodal_AI_A_Survey/2024-06-27-Fairness_and_Bias_in_Multimodal_AI_A_Survey.html#appendix",
    "href": "posts/Fairness_and_Bias_in_Multimodal_AI_A_Survey/2024-06-27-Fairness_and_Bias_in_Multimodal_AI_A_Survey.html#appendix",
    "title": "Fairness and Bias in Multimodal AI: A Survey",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19097v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19097v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5909"
  },
  {
    "objectID": "posts/MedExQA_Medical_Question_Answering_Benchmark_with_Multiple_Explanations/2024-06-10-MedExQA_Medical_Question_Answering_Benchmark_with_Multiple_Explanations.html#appendix",
    "href": "posts/MedExQA_Medical_Question_Answering_Benchmark_with_Multiple_Explanations/2024-06-10-MedExQA_Medical_Question_Answering_Benchmark_with_Multiple_Explanations.html#appendix",
    "title": "MedExQA: Medical Question Answering Benchmark with Multiple Explanations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06331v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06331v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7134"
  },
  {
    "objectID": "posts/Zero_Shot_End_To_End_Spoken_Question_Answering_In_Medical_Domain/2024-06-09-Zero_Shot_End_To_End_Spoken_Question_Answering_In_Medical_Domain.html#appendix",
    "href": "posts/Zero_Shot_End_To_End_Spoken_Question_Answering_In_Medical_Domain/2024-06-09-Zero_Shot_End_To_End_Spoken_Question_Answering_In_Medical_Domain.html#appendix",
    "title": "Zero-Shot End-To-End Spoken Question Answering In Medical Domain",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05876v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05876v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4005"
  },
  {
    "objectID": "posts/Leveraging_Large_Language_Models_for_Efficient_Failure_Analysis_in_Game_Development/2024-06-11-Leveraging_Large_Language_Models_for_Efficient_Failure_Analysis_in_Game_Development.html#appendix",
    "href": "posts/Leveraging_Large_Language_Models_for_Efficient_Failure_Analysis_in_Game_Development/2024-06-11-Leveraging_Large_Language_Models_for_Efficient_Failure_Analysis_in_Game_Development.html#appendix",
    "title": "Leveraging Large Language Models for Efficient Failure Analysis in Game Development",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07084v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07084v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6064"
  },
  {
    "objectID": "posts/ShadowLLM_Predictor_based_Contextual_Sparsity_for_Large_Language_Models/2024-06-24-ShadowLLM_Predictor_based_Contextual_Sparsity_for_Large_Language_Models.html#appendix",
    "href": "posts/ShadowLLM_Predictor_based_Contextual_Sparsity_for_Large_Language_Models/2024-06-24-ShadowLLM_Predictor_based_Contextual_Sparsity_for_Large_Language_Models.html#appendix",
    "title": "ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16635v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16635v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6242"
  },
  {
    "objectID": "posts/M2Lingual_Enhancing_Multilingual_Multi_Turn_Instruction_Alignment_in_Large_Language_Models/2024-06-24-M2Lingual_Enhancing_Multilingual_Multi_Turn_Instruction_Alignment_in_Large_Language_Models.html#appendix",
    "href": "posts/M2Lingual_Enhancing_Multilingual_Multi_Turn_Instruction_Alignment_in_Large_Language_Models/2024-06-24-M2Lingual_Enhancing_Multilingual_Multi_Turn_Instruction_Alignment_in_Large_Language_Models.html#appendix",
    "title": "M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16783v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16783v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8562"
  },
  {
    "objectID": "posts/Helpful_assistant_or_fruitful_facilitator_Investigating_how_personas_affect_language_model_behavior/2024-07-02-Helpful_assistant_or_fruitful_facilitator_Investigating_how_personas_affect_language_model_behavior.html#appendix",
    "href": "posts/Helpful_assistant_or_fruitful_facilitator_Investigating_how_personas_affect_language_model_behavior/2024-07-02-Helpful_assistant_or_fruitful_facilitator_Investigating_how_personas_affect_language_model_behavior.html#appendix",
    "title": "Helpful assistant or fruitful facilitator? Investigating how personas affect language model behavior",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02099v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02099v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8203"
  },
  {
    "objectID": "posts/HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs/2024-06-10-HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs.html",
    "href": "posts/HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs/2024-06-10-HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs.html",
    "title": "HOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs",
    "section": "",
    "text": "Summary:\nThe paper introduces a new method called HOLMES for multi-hop question answering (MHQA) using large language models (LLMs). The method involves transforming unstructured text into a hyper-relational knowledge graph (KG) using a query-derived schema, which is then used as input to the LLM. The proposed method significantly improves upon the state-of-the-art (SoTA) multi-hop QA method, achieving 18.7% and 20% improvements in exact match (EM) scores on the Hotpot dataset and 26% and 14.3% on the MuSiQue dataset for GPT-3.5 and GPT-4, respectively. Additionally, the method uses up to 67% fewer tokens to represent query-relevant information than the current SoTA method and up to 60% fewer tokens compared to the original supporting documents.\nMajor Findings:\nAnalysis and Critique:\nThe proposed method, HOLMES, presents a significant improvement over the SoTA multi-hop QA method. The use of a hyper-relational KG as input to the LLM allows for a more efficient and effective representation of query-relevant information. The method’s ability to use fewer tokens to represent this information is particularly noteworthy, as it can lead to reduced computational costs and improved performance.\nHowever, there are some potential limitations and areas for further research. For example, the method’s reliance on a query-"
  },
  {
    "objectID": "posts/HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs/2024-06-10-HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs.html#appendix",
    "href": "posts/HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs/2024-06-10-HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs.html#appendix",
    "title": "HOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06027v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06027v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20470"
  },
  {
    "objectID": "posts/DARA_Decomposition_Alignment_Reasoning_Autonomous_Language_Agent_for_Question_Answering_over_Knowledge_Graphs/2024-06-11-DARA_Decomposition_Alignment_Reasoning_Autonomous_Language_Agent_for_Question_Answering_over_Knowledge_Graphs.html#appendix",
    "href": "posts/DARA_Decomposition_Alignment_Reasoning_Autonomous_Language_Agent_for_Question_Answering_over_Knowledge_Graphs/2024-06-11-DARA_Decomposition_Alignment_Reasoning_Autonomous_Language_Agent_for_Question_Answering_over_Knowledge_Graphs.html#appendix",
    "title": "DARA: Decomposition-Alignment-Reasoning Autonomous Language Agent for Question Answering over Knowledge Graphs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07080v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07080v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8918"
  },
  {
    "objectID": "posts/Chain_of_Scrutiny_Detecting_Backdoor_Attacks_for_Large_Language_Models/2024-06-10-Chain_of_Scrutiny_Detecting_Backdoor_Attacks_for_Large_Language_Models.html#appendix",
    "href": "posts/Chain_of_Scrutiny_Detecting_Backdoor_Attacks_for_Large_Language_Models/2024-06-10-Chain_of_Scrutiny_Detecting_Backdoor_Attacks_for_Large_Language_Models.html#appendix",
    "title": "Chain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05948v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05948v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6961"
  },
  {
    "objectID": "posts/Retrieved_In_Context_Principles_from_Previous_Mistakes/2024-07-08-Retrieved_In_Context_Principles_from_Previous_Mistakes.html#appendix",
    "href": "posts/Retrieved_In_Context_Principles_from_Previous_Mistakes/2024-07-08-Retrieved_In_Context_Principles_from_Previous_Mistakes.html#appendix",
    "title": "Retrieved In-Context Principles from Previous Mistakes",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05682v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05682v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5199"
  },
  {
    "objectID": "posts/Exploring_the_Role_of_Transliteration_in_In_Context_Learning_for_Low_resource_Languages_Written_in_Non_Latin_Scripts/2024-07-02-Exploring_the_Role_of_Transliteration_in_In_Context_Learning_for_Low_resource_Languages_Written_in_Non_Latin_Scripts.html#appendix",
    "href": "posts/Exploring_the_Role_of_Transliteration_in_In_Context_Learning_for_Low_resource_Languages_Written_in_Non_Latin_Scripts/2024-07-02-Exploring_the_Role_of_Transliteration_in_In_Context_Learning_for_Low_resource_Languages_Written_in_Non_Latin_Scripts.html#appendix",
    "title": "Exploring the Role of Transliteration in In-Context Learning for Low-resource Languages Written in Non-Latin Scripts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02320v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02320v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3417"
  },
  {
    "objectID": "posts/A_Tool_for_Test_Case_Scenarios_Generation_Using_Large_Language_Models/2024-06-11-A_Tool_for_Test_Case_Scenarios_Generation_Using_Large_Language_Models.html#appendix",
    "href": "posts/A_Tool_for_Test_Case_Scenarios_Generation_Using_Large_Language_Models/2024-06-11-A_Tool_for_Test_Case_Scenarios_Generation_Using_Large_Language_Models.html#appendix",
    "title": "A Tool for Test Case Scenarios Generation Using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07021v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07021v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3062"
  },
  {
    "objectID": "posts/Instruct_Not_Assist_LLM_based_Multi_Turn_Planning_and_Hierarchical_Questioning_for_Socratic_Code_Debugging/2024-06-17-Instruct_Not_Assist_LLM_based_Multi_Turn_Planning_and_Hierarchical_Questioning_for_Socratic_Code_Debugging.html#appendix",
    "href": "posts/Instruct_Not_Assist_LLM_based_Multi_Turn_Planning_and_Hierarchical_Questioning_for_Socratic_Code_Debugging/2024-06-17-Instruct_Not_Assist_LLM_based_Multi_Turn_Planning_and_Hierarchical_Questioning_for_Socratic_Code_Debugging.html#appendix",
    "title": "Instruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11709v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11709v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9274"
  },
  {
    "objectID": "posts/Evaluation_of_Instruction_Following_Ability_for_Large_Language_Models_on_Story_Ending_Generation/2024-06-24-Evaluation_of_Instruction_Following_Ability_for_Large_Language_Models_on_Story_Ending_Generation.html#appendix",
    "href": "posts/Evaluation_of_Instruction_Following_Ability_for_Large_Language_Models_on_Story_Ending_Generation/2024-06-24-Evaluation_of_Instruction_Following_Ability_for_Large_Language_Models_on_Story_Ending_Generation.html#appendix",
    "title": "Evaluation of Instruction-Following Ability for Large Language Models on Story-Ending Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16356v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16356v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4154"
  },
  {
    "objectID": "posts/Generative_Debunking_of_Climate_Misinformation/2024-07-08-Generative_Debunking_of_Climate_Misinformation.html#appendix",
    "href": "posts/Generative_Debunking_of_Climate_Misinformation/2024-07-08-Generative_Debunking_of_Climate_Misinformation.html#appendix",
    "title": "Generative Debunking of Climate Misinformation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05599v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05599v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6823"
  },
  {
    "objectID": "posts/MMBench_Video_A_Long_Form_Multi_Shot_Benchmark_for_Holistic_Video_Understanding/2024-06-20-MMBench_Video_A_Long_Form_Multi_Shot_Benchmark_for_Holistic_Video_Understanding.html#appendix",
    "href": "posts/MMBench_Video_A_Long_Form_Multi_Shot_Benchmark_for_Holistic_Video_Understanding/2024-06-20-MMBench_Video_A_Long_Form_Multi_Shot_Benchmark_for_Holistic_Video_Understanding.html#appendix",
    "title": "MMBench-Video: A Long-Form Multi-Shot Benchmark for Holistic Video Understanding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14515v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14515v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8501"
  },
  {
    "objectID": "posts/Automated_Adversarial_Discovery_for_Safety_Classifiers/2024-06-24-Automated_Adversarial_Discovery_for_Safety_Classifiers.html#appendix",
    "href": "posts/Automated_Adversarial_Discovery_for_Safety_Classifiers/2024-06-24-Automated_Adversarial_Discovery_for_Safety_Classifiers.html#appendix",
    "title": "Automated Adversarial Discovery for Safety Classifiers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17104v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17104v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6260"
  },
  {
    "objectID": "posts/Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation/2024-06-27-Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.html#summary-1",
    "href": "posts/Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation/2024-06-27-Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.html#summary-1",
    "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
    "section": "Summary:",
    "text": "Summary:\n\nThe paper explores the use of Membership Inference Attacks (MIA) to determine whether a sample is part of the knowledge database of a Retrieval-Augmented Generation (RAG) system.\nThe core hypothesis is that if a sample is a member, it will exhibit significant similarity to the text generated by the RAG system.\nThe authors compute the cosine similarity and the model’s perplexity to establish a membership score, building robust features.\nTwo novel attack strategies are introduced: a Threshold-based Attack and a Machine Learning-based Attack, designed to accurately identify membership.\nExperimental validation of the methods achieved a ROC AUC of 82%."
  },
  {
    "objectID": "posts/Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation/2024-06-27-Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.html#major-findings",
    "href": "posts/Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation/2024-06-27-Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.html#major-findings",
    "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nMIA for RAG Systems: The paper demonstrates the effectiveness of using MIA to determine whether a sample is part of the knowledge database of a RAG system.\nRobust Features: The authors compute the cosine similarity and the model’s perplexity to establish a membership score, building robust features.\nNovel Attack Strategies: Two novel attack strategies are introduced: a Threshold-based Attack and a Machine Learning-based Attack, designed to accurately identify membership.\nExperimental Validation: The experimental validation of the methods achieved a ROC AUC of 82%."
  },
  {
    "objectID": "posts/Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation/2024-06-27-Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.html#analysis-and-critique",
    "href": "posts/Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation/2024-06-27-Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.html#analysis-and-critique",
    "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper provides a novel approach to assessing the security and privacy of RAG systems’ external databases.\nThe use of MIA to determine whether a sample is part of the knowledge database of a RAG system is a significant contribution.\nThe introduction of two novel attack strategies is a valuable addition to the field.\nThe experimental validation of the methods is a strength of the paper.\nHowever, the paper does not discuss potential countermeasures or defenses against these attacks, which could be a limitation.\nAdditionally, the paper does not explore the potential impact of these attacks on the performance of RAG systems, which could be an area for future research."
  },
  {
    "objectID": "posts/Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation/2024-06-27-Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.html#appendix",
    "href": "posts/Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation/2024-06-27-Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.html#appendix",
    "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19234v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19234v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3427"
  },
  {
    "objectID": "posts/BADGE_BADminton_report_Generation_and_Evaluation_with_LLM/2024-06-26-BADGE_BADminton_report_Generation_and_Evaluation_with_LLM.html#appendix",
    "href": "posts/BADGE_BADminton_report_Generation_and_Evaluation_with_LLM/2024-06-26-BADGE_BADminton_report_Generation_and_Evaluation_with_LLM.html#appendix",
    "title": "BADGE: BADminton report Generation and Evaluation with LLM",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18116v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18116v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6049"
  },
  {
    "objectID": "posts/Improving_Steering_and_Verification_in_AI_Assisted_Data_Analysis_with_Interactive_Task_Decomposition/2024-07-02-Improving_Steering_and_Verification_in_AI_Assisted_Data_Analysis_with_Interactive_Task_Decomposition.html",
    "href": "posts/Improving_Steering_and_Verification_in_AI_Assisted_Data_Analysis_with_Interactive_Task_Decomposition/2024-07-02-Improving_Steering_and_Verification_in_AI_Assisted_Data_Analysis_with_Interactive_Task_Decomposition.html",
    "title": "Improving Steering and Verification in AI-Assisted Data Analysis with Interactive Task Decomposition",
    "section": "",
    "text": "Summary:\nThis paper presents a study on the challenges of using AI-assisted data analysis tools, specifically focusing on steering and verification. The study involved 15 participants and identified two significant limitations: steering the AI and verifying its output. The paper then introduces a novel approach to improve steering and verification using editable AI assumptions, progressive disclosure, and non-linear conversations. Two implementations of this approach are presented, each balancing information overload and the degree of user control differently. A controlled, within-subjects experiment was conducted to compare these systems with a Conversational baseline system. The results showed that users reported significantly greater control with the two new systems and found intervention, correction, and verification easier compared to the baseline.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a well-structured and coherent summary of the study and its findings. The use of markdown for formatting enhances the readability and organization of the information. The study’s methodology and results are clearly explained, and the comparison with a Conversational baseline system provides a useful point of reference.\nHowever, there are some potential limitations and areas for improvement. The sample size of 15 participants is relatively small, which may limit the generalizability of the findings. Additionally, the study does not provide detailed information on the specific tasks or datasets used, making it difficult to assess the validity and applicability of the results. Furthermore, the paper does not discuss any potential biases or confounding factors that may have influenced the results.\nOverall, the paper offers valuable insights into the challenges and potential solutions for improving steering and verification in AI-assisted data analysis. However, further research with larger sample sizes and more diverse tasks"
  },
  {
    "objectID": "posts/Improving_Steering_and_Verification_in_AI_Assisted_Data_Analysis_with_Interactive_Task_Decomposition/2024-07-02-Improving_Steering_and_Verification_in_AI_Assisted_Data_Analysis_with_Interactive_Task_Decomposition.html#appendix",
    "href": "posts/Improving_Steering_and_Verification_in_AI_Assisted_Data_Analysis_with_Interactive_Task_Decomposition/2024-07-02-Improving_Steering_and_Verification_in_AI_Assisted_Data_Analysis_with_Interactive_Task_Decomposition.html#appendix",
    "title": "Improving Steering and Verification in AI-Assisted Data Analysis with Interactive Task Decomposition",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02651v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02651v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17913"
  },
  {
    "objectID": "posts/Towards_Comprehensive_Preference_Data_Collection_for_Reward_Modeling/2024-06-24-Towards_Comprehensive_Preference_Data_Collection_for_Reward_Modeling.html#appendix",
    "href": "posts/Towards_Comprehensive_Preference_Data_Collection_for_Reward_Modeling/2024-06-24-Towards_Comprehensive_Preference_Data_Collection_for_Reward_Modeling.html#appendix",
    "title": "Towards Comprehensive Preference Data Collection for Reward Modeling",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16486v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16486v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3102"
  },
  {
    "objectID": "posts/ConvoCache_Smart_Re_Use_of_Chatbot_Responses/2024-06-26-ConvoCache_Smart_Re_Use_of_Chatbot_Responses.html#appendix",
    "href": "posts/ConvoCache_Smart_Re_Use_of_Chatbot_Responses/2024-06-26-ConvoCache_Smart_Re_Use_of_Chatbot_Responses.html#appendix",
    "title": "ConvoCache: Smart Re-Use of Chatbot Responses",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18133v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18133v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4233"
  },
  {
    "objectID": "posts/Text_like_Encoding_of_Collaborative_Information_in_Large_Language_Models_for_Recommendation/2024-06-05-Text_like_Encoding_of_Collaborative_Information_in_Large_Language_Models_for_Recommendation.html#appendix",
    "href": "posts/Text_like_Encoding_of_Collaborative_Information_in_Large_Language_Models_for_Recommendation/2024-06-05-Text_like_Encoding_of_Collaborative_Information_in_Large_Language_Models_for_Recommendation.html#appendix",
    "title": "Text-like Encoding of Collaborative Information in Large Language Models for Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03210v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03210v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6859"
  },
  {
    "objectID": "posts/FreeTraj_Tuning_Free_Trajectory_Control_in_Video_Diffusion_Models/2024-06-24-FreeTraj_Tuning_Free_Trajectory_Control_in_Video_Diffusion_Models.html#appendix",
    "href": "posts/FreeTraj_Tuning_Free_Trajectory_Control_in_Video_Diffusion_Models/2024-06-24-FreeTraj_Tuning_Free_Trajectory_Control_in_Video_Diffusion_Models.html#appendix",
    "title": "FreeTraj: Tuning-Free Trajectory Control in Video Diffusion Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16863v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16863v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8202"
  },
  {
    "objectID": "posts/3D_Building_Generation_in_Minecraft_via_Large_Language_Models/2024-06-13-3D_Building_Generation_in_Minecraft_via_Large_Language_Models.html#appendix",
    "href": "posts/3D_Building_Generation_in_Minecraft_via_Large_Language_Models/2024-06-13-3D_Building_Generation_in_Minecraft_via_Large_Language_Models.html#appendix",
    "title": "3D Building Generation in Minecraft via Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.08751v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.08751v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4481"
  },
  {
    "objectID": "posts/CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models/2024-07-02-CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models.html",
    "href": "posts/CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models/2024-07-02-CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models.html",
    "title": "CEB: Compositional Evaluation Benchmark for Fairness in Large Language Models",
    "section": "",
    "text": "Summary: The paper introduces a Compositional Evaluation Benchmark (CEB) to address the limitations of existing bias evaluation efforts for Large Language Models (LLMs). CEB consists of 11,004 samples covering different types of bias across various social groups and tasks. The curation of CEB is based on a newly proposed compositional taxonomy that characterizes each dataset from three dimensions: bias types, social groups, and tasks. The paper demonstrates that the levels of bias vary across these dimensions, providing guidance for the development of specific bias mitigation methods.\nMajor Findings: 1. The introduction of CEB, a Compositional Evaluation Benchmark, to address the limitations of existing bias evaluation efforts for LLMs. 2. The curation of CEB is based on a newly proposed compositional taxonomy that characterizes each dataset from three dimensions: bias types, social groups, and tasks."
  },
  {
    "objectID": "posts/CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models/2024-07-02-CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models.html#appendix",
    "href": "posts/CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models/2024-07-02-CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models.html#appendix",
    "title": "CEB: Compositional Evaluation Benchmark for Fairness in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02408v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02408v1\n\n\nTruncated\nTrue\n\n\nWord Count\n32723"
  },
  {
    "objectID": "posts/SD_Eval_A_Benchmark_Dataset_for_Spoken_Dialogue_Understanding_Beyond_Words/2024-06-19-SD_Eval_A_Benchmark_Dataset_for_Spoken_Dialogue_Understanding_Beyond_Words.html#appendix",
    "href": "posts/SD_Eval_A_Benchmark_Dataset_for_Spoken_Dialogue_Understanding_Beyond_Words/2024-06-19-SD_Eval_A_Benchmark_Dataset_for_Spoken_Dialogue_Understanding_Beyond_Words.html#appendix",
    "title": "SD-Eval: A Benchmark Dataset for Spoken Dialogue Understanding Beyond Words",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13340v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13340v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5962"
  },
  {
    "objectID": "posts/Prose_to_P4_Leveraging_High_Level_Languages/2024-06-19-Prose_to_P4_Leveraging_High_Level_Languages.html#appendix",
    "href": "posts/Prose_to_P4_Leveraging_High_Level_Languages/2024-06-19-Prose_to_P4_Leveraging_High_Level_Languages.html#appendix",
    "title": "Prose-to-P4: Leveraging High Level Languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13679v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13679v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4347"
  },
  {
    "objectID": "posts/Model_Enhanced_LLM_Driven_VUI_Testing_of_VPA_Apps/2024-07-03-Model_Enhanced_LLM_Driven_VUI_Testing_of_VPA_Apps.html#appendix",
    "href": "posts/Model_Enhanced_LLM_Driven_VUI_Testing_of_VPA_Apps/2024-07-03-Model_Enhanced_LLM_Driven_VUI_Testing_of_VPA_Apps.html#appendix",
    "title": "Model-Enhanced LLM-Driven VUI Testing of VPA Apps",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02791v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02791v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9664"
  },
  {
    "objectID": "posts/UBENCH_Benchmarking_Uncertainty_in_Large_Language_Models_with_Multiple_Choice_Questions/2024-06-18-UBENCH_Benchmarking_Uncertainty_in_Large_Language_Models_with_Multiple_Choice_Questions.html#appendix",
    "href": "posts/UBENCH_Benchmarking_Uncertainty_in_Large_Language_Models_with_Multiple_Choice_Questions/2024-06-18-UBENCH_Benchmarking_Uncertainty_in_Large_Language_Models_with_Multiple_Choice_Questions.html#appendix",
    "title": "UBENCH: Benchmarking Uncertainty in Large Language Models with Multiple Choice Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12784v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12784v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7284"
  },
  {
    "objectID": "posts/HIGHT_Hierarchical_Graph_Tokenization_for_Graph_Language_Alignment/2024-06-20-HIGHT_Hierarchical_Graph_Tokenization_for_Graph_Language_Alignment.html#appendix",
    "href": "posts/HIGHT_Hierarchical_Graph_Tokenization_for_Graph_Language_Alignment/2024-06-20-HIGHT_Hierarchical_Graph_Tokenization_for_Graph_Language_Alignment.html#appendix",
    "title": "HIGHT: Hierarchical Graph Tokenization for Graph-Language Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14021v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14021v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11102"
  },
  {
    "objectID": "posts/AnnotatedTables_A_Large_Tabular_Dataset_with_Language_Model_Annotations/2024-06-24-AnnotatedTables_A_Large_Tabular_Dataset_with_Language_Model_Annotations.html#appendix",
    "href": "posts/AnnotatedTables_A_Large_Tabular_Dataset_with_Language_Model_Annotations/2024-06-24-AnnotatedTables_A_Large_Tabular_Dataset_with_Language_Model_Annotations.html#appendix",
    "title": "AnnotatedTables: A Large Tabular Dataset with Language Model Annotations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16349v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16349v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13468"
  },
  {
    "objectID": "posts/On_Policy_Fine_grained_Knowledge_Feedback_for_Hallucination_Mitigation/2024-06-18-On_Policy_Fine_grained_Knowledge_Feedback_for_Hallucination_Mitigation.html#appendix",
    "href": "posts/On_Policy_Fine_grained_Knowledge_Feedback_for_Hallucination_Mitigation/2024-06-18-On_Policy_Fine_grained_Knowledge_Feedback_for_Hallucination_Mitigation.html#appendix",
    "title": "On-Policy Fine-grained Knowledge Feedback for Hallucination Mitigation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12221v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12221v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7146"
  },
  {
    "objectID": "posts/Verbalized_Machine_Learning_Revisiting_Machine_Learning_with_Language_Models/2024-06-06-Verbalized_Machine_Learning_Revisiting_Machine_Learning_with_Language_Models.html#appendix",
    "href": "posts/Verbalized_Machine_Learning_Revisiting_Machine_Learning_with_Language_Models/2024-06-06-Verbalized_Machine_Learning_Revisiting_Machine_Learning_with_Language_Models.html#appendix",
    "title": "Verbalized Machine Learning: Revisiting Machine Learning with Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04344v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04344v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10781"
  },
  {
    "objectID": "posts/Guiding_LLM_Temporal_Logic_Generation_with_Explicit_Separation_of_Data_and_Control/2024-06-11-Guiding_LLM_Temporal_Logic_Generation_with_Explicit_Separation_of_Data_and_Control.html#appendix",
    "href": "posts/Guiding_LLM_Temporal_Logic_Generation_with_Explicit_Separation_of_Data_and_Control/2024-06-11-Guiding_LLM_Temporal_Logic_Generation_with_Explicit_Separation_of_Data_and_Control.html#appendix",
    "title": "Guiding LLM Temporal Logic Generation with Explicit Separation of Data and Control",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07400v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07400v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4241"
  },
  {
    "objectID": "posts/Human_AI_Collaborative_Taxonomy_Construction_A_Case_Study_in_Profession_Specific_Writing_Assistants/2024-06-26-Human_AI_Collaborative_Taxonomy_Construction_A_Case_Study_in_Profession_Specific_Writing_Assistants.html#appendix",
    "href": "posts/Human_AI_Collaborative_Taxonomy_Construction_A_Case_Study_in_Profession_Specific_Writing_Assistants/2024-06-26-Human_AI_Collaborative_Taxonomy_Construction_A_Case_Study_in_Profession_Specific_Writing_Assistants.html#appendix",
    "title": "Human-AI Collaborative Taxonomy Construction: A Case Study in Profession-Specific Writing Assistants",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18675v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18675v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3979"
  },
  {
    "objectID": "posts/An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics/2024-06-10-An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics.html",
    "href": "posts/An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics/2024-06-10-An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics.html",
    "title": "An Empirical Design Justice Approach to Identifying Ethical Considerations in the Intersection of Large Language Models and Social Robotics",
    "section": "",
    "text": "Summary:\nThe integration of Large Language Models (LLMs) in social robotics presents a unique set of ethical challenges and social impacts. This research aims to identify ethical considerations that arise in the design and development of these two technologies in combination. Using LLMs for social robotics may provide benefits, such as enabling natural language open-domain dialogues. However, the intersection of these two technologies also gives rise to ethical concerns related to misinformation, non-verbal cues, emotional disruption, and biases. The robot’s physical social embodiment adds complexity, as ethical hazards associated with LLM-based Social AI, such as hallucinations and misinformation, can be exacerbated due to the effects of physical embodiment on social perception and communication. To address these challenges, this study employs an empirical design justice-based methodology, focusing on identifying socio-technical ethical considerations through a qualitative co-design and interaction study. The purpose of the study is to identify ethical considerations relevant to the process of co-design of, and interaction with a humanoid social robot as the interface of a LLM, and to evaluate how a design justice methodology can be used in the context of designing LLMs-based social robotics.\nMajor Findings:\nAnalysis and Critique:\nThe study presents a novel methodological approach based on previous work on design justice in AI and HRI. The approach enables the identification and validation of ethical concerns through empirical design justice-based data from diverse participants. However, the study also highlights limitations, such as the inability to confidently determine ethical considerations in"
  },
  {
    "objectID": "posts/An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics/2024-06-10-An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics.html#appendix",
    "href": "posts/An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics/2024-06-10-An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics.html#appendix",
    "title": "An Empirical Design Justice Approach to Identifying Ethical Considerations in the Intersection of Large Language Models and Social Robotics",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06400v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06400v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14471"
  },
  {
    "objectID": "posts/PostMark_A_Robust_Blackbox_Watermark_for_Large_Language_Models/2024-06-20-PostMark_A_Robust_Blackbox_Watermark_for_Large_Language_Models.html#appendix",
    "href": "posts/PostMark_A_Robust_Blackbox_Watermark_for_Large_Language_Models/2024-06-20-PostMark_A_Robust_Blackbox_Watermark_for_Large_Language_Models.html#appendix",
    "title": "PostMark: A Robust Blackbox Watermark for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14517v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14517v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10409"
  },
  {
    "objectID": "posts/Efficient_course_recommendations_with_T5_based_ranking_and_summarization/2024-06-27-Efficient_course_recommendations_with_T5_based_ranking_and_summarization.html#appendix",
    "href": "posts/Efficient_course_recommendations_with_T5_based_ranking_and_summarization/2024-06-27-Efficient_course_recommendations_with_T5_based_ranking_and_summarization.html#appendix",
    "title": "Efficient course recommendations with T5-based ranking and summarization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19018v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19018v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9587"
  },
  {
    "objectID": "posts/ReCaLL_Membership_Inference_via_Relative_Conditional_Log_Likelihoods/2024-06-23-ReCaLL_Membership_Inference_via_Relative_Conditional_Log_Likelihoods.html#appendix",
    "href": "posts/ReCaLL_Membership_Inference_via_Relative_Conditional_Log_Likelihoods/2024-06-23-ReCaLL_Membership_Inference_via_Relative_Conditional_Log_Likelihoods.html#appendix",
    "title": "ReCaLL: Membership Inference via Relative Conditional Log-Likelihoods",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.15968v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.15968v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8640"
  },
  {
    "objectID": "posts/LLMs_assist_NLP_Researchers_Critique_Paper_(Meta_)Reviewing/2024-06-24-LLMs_assist_NLP_Researchers_Critique_Paper_(Meta_)Reviewing.html#appendix",
    "href": "posts/LLMs_assist_NLP_Researchers_Critique_Paper_(Meta_)Reviewing/2024-06-24-LLMs_assist_NLP_Researchers_Critique_Paper_(Meta_)Reviewing.html#appendix",
    "title": "LLMs assist NLP Researchers: Critique Paper (Meta-)Reviewing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16253v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16253v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7952"
  },
  {
    "objectID": "posts/Generative_Monoculture_in_Large_Language_Models/2024-07-02-Generative_Monoculture_in_Large_Language_Models.html#appendix",
    "href": "posts/Generative_Monoculture_in_Large_Language_Models/2024-07-02-Generative_Monoculture_in_Large_Language_Models.html#appendix",
    "title": "Generative Monoculture in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02209v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02209v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13500"
  },
  {
    "objectID": "posts/Exploring_Changes_in_Nation_Perception_with_Nationality_Assigned_Personas_in_LLMs/2024-06-20-Exploring_Changes_in_Nation_Perception_with_Nationality_Assigned_Personas_in_LLMs.html#appendix",
    "href": "posts/Exploring_Changes_in_Nation_Perception_with_Nationality_Assigned_Personas_in_LLMs/2024-06-20-Exploring_Changes_in_Nation_Perception_with_Nationality_Assigned_Personas_in_LLMs.html#appendix",
    "title": "Exploring Changes in Nation Perception with Nationality-Assigned Personas in LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13993v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13993v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4062"
  },
  {
    "objectID": "posts/Video_Watermarking_Safeguarding_Your_Video_from_(Unauthorized)_Annotations_by_Video_based_LLMs/2024-07-03-Video_Watermarking_Safeguarding_Your_Video_from_(Unauthorized)_Annotations_by_Video_based_LLMs.html#appendix",
    "href": "posts/Video_Watermarking_Safeguarding_Your_Video_from_(Unauthorized)_Annotations_by_Video_based_LLMs/2024-07-03-Video_Watermarking_Safeguarding_Your_Video_from_(Unauthorized)_Annotations_by_Video_based_LLMs.html#appendix",
    "title": "Video Watermarking: Safeguarding Your Video from (Unauthorized) Annotations by Video-based LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02411v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02411v2\n\n\nTruncated\nFalse\n\n\nWord Count\n6556"
  },
  {
    "objectID": "posts/What_Did_I_Do_Wrong_Quantifying_LLMs_Sensitivity_and_Consistency_to_Prompt_Engineering/2024-06-18-What_Did_I_Do_Wrong_Quantifying_LLMs_Sensitivity_and_Consistency_to_Prompt_Engineering.html#appendix",
    "href": "posts/What_Did_I_Do_Wrong_Quantifying_LLMs_Sensitivity_and_Consistency_to_Prompt_Engineering/2024-06-18-What_Did_I_Do_Wrong_Quantifying_LLMs_Sensitivity_and_Consistency_to_Prompt_Engineering.html#appendix",
    "title": "What Did I Do Wrong? Quantifying LLMs’ Sensitivity and Consistency to Prompt Engineering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12334v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12334v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6408"
  },
  {
    "objectID": "posts/How_Well_Can_Knowledge_Edit_Methods_Edit_Perplexing_Knowledge/2024-06-25-How_Well_Can_Knowledge_Edit_Methods_Edit_Perplexing_Knowledge.html#appendix",
    "href": "posts/How_Well_Can_Knowledge_Edit_Methods_Edit_Perplexing_Knowledge/2024-06-25-How_Well_Can_Knowledge_Edit_Methods_Edit_Perplexing_Knowledge.html#appendix",
    "title": "How Well Can Knowledge Edit Methods Edit Perplexing Knowledge?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17253v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17253v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6890"
  },
  {
    "objectID": "posts/Efficiently_Exploring_Large_Language_Models_for_Document_Level_Machine_Translation_with_In_context_Learning/2024-06-11-Efficiently_Exploring_Large_Language_Models_for_Document_Level_Machine_Translation_with_In_context_Learning.html#appendix",
    "href": "posts/Efficiently_Exploring_Large_Language_Models_for_Document_Level_Machine_Translation_with_In_context_Learning/2024-06-11-Efficiently_Exploring_Large_Language_Models_for_Document_Level_Machine_Translation_with_In_context_Learning.html#appendix",
    "title": "Efficiently Exploring Large Language Models for Document-Level Machine Translation with In-context Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07081v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07081v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6243"
  },
  {
    "objectID": "posts/Can_we_teach_language_models_to_gloss_endangered_languages/2024-06-27-Can_we_teach_language_models_to_gloss_endangered_languages.html#appendix",
    "href": "posts/Can_we_teach_language_models_to_gloss_endangered_languages/2024-06-27-Can_we_teach_language_models_to_gloss_endangered_languages.html#appendix",
    "title": "Can we teach language models to gloss endangered languages?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18895v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18895v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6433"
  },
  {
    "objectID": "posts/T_FREE_Tokenizer_Free_Generative_LLMs_via_Sparse_Representations_for_Memory_Efficient_Embeddings/2024-06-27-T_FREE_Tokenizer_Free_Generative_LLMs_via_Sparse_Representations_for_Memory_Efficient_Embeddings.html#appendix",
    "href": "posts/T_FREE_Tokenizer_Free_Generative_LLMs_via_Sparse_Representations_for_Memory_Efficient_Embeddings/2024-06-27-T_FREE_Tokenizer_Free_Generative_LLMs_via_Sparse_Representations_for_Memory_Efficient_Embeddings.html#appendix",
    "title": "T-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19223v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19223v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8998"
  },
  {
    "objectID": "posts/LLM_ARC_Enhancing_LLMs_with_an_Automated_Reasoning_Critic/2024-06-25-LLM_ARC_Enhancing_LLMs_with_an_Automated_Reasoning_Critic.html#appendix",
    "href": "posts/LLM_ARC_Enhancing_LLMs_with_an_Automated_Reasoning_Critic/2024-06-25-LLM_ARC_Enhancing_LLMs_with_an_Automated_Reasoning_Critic.html#appendix",
    "title": "LLM-ARC: Enhancing LLMs with an Automated Reasoning Critic",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17663v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17663v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9705"
  },
  {
    "objectID": "posts/Unveiling_Assumptions_Exploring_the_Decisions_of_AI_Chatbots_and_Human_Testers/2024-06-17-Unveiling_Assumptions_Exploring_the_Decisions_of_AI_Chatbots_and_Human_Testers.html#appendix",
    "href": "posts/Unveiling_Assumptions_Exploring_the_Decisions_of_AI_Chatbots_and_Human_Testers/2024-06-17-Unveiling_Assumptions_Exploring_the_Decisions_of_AI_Chatbots_and_Human_Testers.html#appendix",
    "title": "Unveiling Assumptions: Exploring the Decisions of AI Chatbots and Human Testers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11339v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11339v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5891"
  },
  {
    "objectID": "posts/MBBQ_A_Dataset_for_Cross_Lingual_Comparison_of_Stereotypes_in_Generative_LLMs/2024-06-11-MBBQ_A_Dataset_for_Cross_Lingual_Comparison_of_Stereotypes_in_Generative_LLMs.html#appendix",
    "href": "posts/MBBQ_A_Dataset_for_Cross_Lingual_Comparison_of_Stereotypes_in_Generative_LLMs/2024-06-11-MBBQ_A_Dataset_for_Cross_Lingual_Comparison_of_Stereotypes_in_Generative_LLMs.html#appendix",
    "title": "MBBQ: A Dataset for Cross-Lingual Comparison of Stereotypes in Generative LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07243v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07243v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10630"
  },
  {
    "objectID": "posts/CityGPT_Empowering_Urban_Spatial_Cognition_of_Large_Language_Models/2024-06-20-CityGPT_Empowering_Urban_Spatial_Cognition_of_Large_Language_Models.html",
    "href": "posts/CityGPT_Empowering_Urban_Spatial_Cognition_of_Large_Language_Models/2024-06-20-CityGPT_Empowering_Urban_Spatial_Cognition_of_Large_Language_Models.html",
    "title": "CityGPT: Empowering Urban Spatial Cognition of Large Language Models",
    "section": "",
    "text": "Overall Summary:\nThe paper introduces CityGPT, a framework designed to enhance the capability of large language models (LLMs) in understanding urban space and solving related urban tasks. The authors construct a diverse instruction tuning dataset, CityInstruction, to inject urban knowledge and improve spatial reasoning capabilities. They fine-tune various LLMs using a mixture of CityInstruction and general instruction data, without sacrificing general abilities. To validate the effectiveness of their methods, the authors create a comprehensive benchmark, CityEval, to evaluate LLMs in diverse urban scenarios and problems. The results demonstrate that small LLMs trained with CityInstruction can achieve competitive performance with commercial LLMs in the comprehensive evaluation of CityEval.\nMajor Findings:"
  },
  {
    "objectID": "posts/CityGPT_Empowering_Urban_Spatial_Cognition_of_Large_Language_Models/2024-06-20-CityGPT_Empowering_Urban_Spatial_Cognition_of_Large_Language_Models.html#appendix",
    "href": "posts/CityGPT_Empowering_Urban_Spatial_Cognition_of_Large_Language_Models/2024-06-20-CityGPT_Empowering_Urban_Spatial_Cognition_of_Large_Language_Models.html#appendix",
    "title": "CityGPT: Empowering Urban Spatial Cognition of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13948v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13948v1\n\n\nTruncated\nTrue\n\n\nWord Count\n38939"
  },
  {
    "objectID": "posts/LLM_Driven_Multimodal_Opinion_Expression_Identification/2024-06-26-LLM_Driven_Multimodal_Opinion_Expression_Identification.html#appendix",
    "href": "posts/LLM_Driven_Multimodal_Opinion_Expression_Identification/2024-06-26-LLM_Driven_Multimodal_Opinion_Expression_Identification.html#appendix",
    "title": "LLM-Driven Multimodal Opinion Expression Identification",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18088v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18088v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4217"
  },
  {
    "objectID": "posts/Semantically_Diverse_Language_Generation_for_Uncertainty_Estimation_in_Language_Models/2024-06-06-Semantically_Diverse_Language_Generation_for_Uncertainty_Estimation_in_Language_Models.html#appendix",
    "href": "posts/Semantically_Diverse_Language_Generation_for_Uncertainty_Estimation_in_Language_Models/2024-06-06-Semantically_Diverse_Language_Generation_for_Uncertainty_Estimation_in_Language_Models.html#appendix",
    "title": "Semantically Diverse Language Generation for Uncertainty Estimation in Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04306v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04306v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10058"
  },
  {
    "objectID": "posts/Jump_Starting_Bandits_with_LLM_Generated_Prior_Knowledge/2024-06-27-Jump_Starting_Bandits_with_LLM_Generated_Prior_Knowledge.html#appendix",
    "href": "posts/Jump_Starting_Bandits_with_LLM_Generated_Prior_Knowledge/2024-06-27-Jump_Starting_Bandits_with_LLM_Generated_Prior_Knowledge.html#appendix",
    "title": "Jump Starting Bandits with LLM-Generated Prior Knowledge",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19317v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19317v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8270"
  },
  {
    "objectID": "posts/RVISA_Reasoning_and_Verification_for_Implicit_Sentiment_Analysis/2024-07-02-RVISA_Reasoning_and_Verification_for_Implicit_Sentiment_Analysis.html#appendix",
    "href": "posts/RVISA_Reasoning_and_Verification_for_Implicit_Sentiment_Analysis/2024-07-02-RVISA_Reasoning_and_Verification_for_Implicit_Sentiment_Analysis.html#appendix",
    "title": "RVISA: Reasoning and Verification for Implicit Sentiment Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02340v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02340v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7317"
  },
  {
    "objectID": "posts/Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer/2024-06-09-Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer.html",
    "href": "posts/Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer/2024-06-09-Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer.html",
    "title": "Are Large Language Models Actually Good at Text Style Transfer?",
    "section": "",
    "text": "Summary:\nThis paper evaluates the performance of large language models (LLMs) on Text Style Transfer (TST), specifically focusing on sentiment transfer and text detoxification across three languages: English, Hindi, and Bengali. The study analyzes the capabilities of pre-trained LLMs using zero-shot and few-shot prompting as well as parameter-efficient finetuning on publicly available datasets. The evaluation is conducted using automatic metrics, GPT-4, and human evaluations, revealing that while some prompted LLMs perform well in English, their performance in other languages remains average. However, finetuning significantly improves results compared to zero-shot and few-shot prompting, making them comparable to previous state-of-the-art.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer/2024-06-09-Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer.html#appendix",
    "href": "posts/Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer/2024-06-09-Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer.html#appendix",
    "title": "Are Large Language Models Actually Good at Text Style Transfer?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05885v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05885v1\n\n\nTruncated\nFalse\n\n\nWord Count\n27021"
  },
  {
    "objectID": "posts/Security_Vulnerability_Detection_with_Multitask_Self_Instructed_Fine_Tuning_of_Large_Language_Models/2024-06-09-Security_Vulnerability_Detection_with_Multitask_Self_Instructed_Fine_Tuning_of_Large_Language_Models.html#appendix",
    "href": "posts/Security_Vulnerability_Detection_with_Multitask_Self_Instructed_Fine_Tuning_of_Large_Language_Models/2024-06-09-Security_Vulnerability_Detection_with_Multitask_Self_Instructed_Fine_Tuning_of_Large_Language_Models.html#appendix",
    "title": "Security Vulnerability Detection with Multitask Self-Instructed Fine-Tuning of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05892v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05892v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10513"
  },
  {
    "objectID": "posts/Data_Contamination_Can_Cross_Language_Barriers/2024-06-19-Data_Contamination_Can_Cross_Language_Barriers.html#appendix",
    "href": "posts/Data_Contamination_Can_Cross_Language_Barriers/2024-06-19-Data_Contamination_Can_Cross_Language_Barriers.html#appendix",
    "title": "Data Contamination Can Cross Language Barriers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13236v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13236v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7163"
  },
  {
    "objectID": "posts/LLMs_for_Doctors_Leveraging_Medical_LLMs_to_Assist_Doctors_Not_Replace_Them/2024-06-26-LLMs_for_Doctors_Leveraging_Medical_LLMs_to_Assist_Doctors_Not_Replace_Them.html#appendix",
    "href": "posts/LLMs_for_Doctors_Leveraging_Medical_LLMs_to_Assist_Doctors_Not_Replace_Them/2024-06-26-LLMs_for_Doctors_Leveraging_Medical_LLMs_to_Assist_Doctors_Not_Replace_Them.html#appendix",
    "title": "LLMs for Doctors: Leveraging Medical LLMs to Assist Doctors, Not Replace Them",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18034v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18034v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10560"
  },
  {
    "objectID": "posts/Text_to_Drive_Diverse_Driving_Behavior_Synthesis_via_Large_Language_Models/2024-06-06-Text_to_Drive_Diverse_Driving_Behavior_Synthesis_via_Large_Language_Models.html#appendix",
    "href": "posts/Text_to_Drive_Diverse_Driving_Behavior_Synthesis_via_Large_Language_Models/2024-06-06-Text_to_Drive_Diverse_Driving_Behavior_Synthesis_via_Large_Language_Models.html#appendix",
    "title": "Text-to-Drive: Diverse Driving Behavior Synthesis via Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04300v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04300v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10490"
  },
  {
    "objectID": "posts/ANOLE_An_Open_Autoregressive_Native_Large_Multimodal_Models_for_Interleaved_Image_Text_Generation/2024-07-08-ANOLE_An_Open_Autoregressive_Native_Large_Multimodal_Models_for_Interleaved_Image_Text_Generation.html#appendix",
    "href": "posts/ANOLE_An_Open_Autoregressive_Native_Large_Multimodal_Models_for_Interleaved_Image_Text_Generation/2024-07-08-ANOLE_An_Open_Autoregressive_Native_Large_Multimodal_Models_for_Interleaved_Image_Text_Generation.html#appendix",
    "title": "ANOLE: An Open, Autoregressive, Native Large Multimodal Models for Interleaved Image-Text Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06135v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06135v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3311"
  },
  {
    "objectID": "posts/Improving_Visual_Storytelling_with_Multimodal_Large_Language_Models/2024-07-02-Improving_Visual_Storytelling_with_Multimodal_Large_Language_Models.html#appendix",
    "href": "posts/Improving_Visual_Storytelling_with_Multimodal_Large_Language_Models/2024-07-02-Improving_Visual_Storytelling_with_Multimodal_Large_Language_Models.html#appendix",
    "title": "Improving Visual Storytelling with Multimodal Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02586v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02586v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3182"
  },
  {
    "objectID": "posts/A_Survey_on_Human_Preference_Learning_for_Large_Language_Models/2024-06-17-A_Survey_on_Human_Preference_Learning_for_Large_Language_Models.html#appendix",
    "href": "posts/A_Survey_on_Human_Preference_Learning_for_Large_Language_Models/2024-06-17-A_Survey_on_Human_Preference_Learning_for_Large_Language_Models.html#appendix",
    "title": "A Survey on Human Preference Learning for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11191v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11191v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12223"
  },
  {
    "objectID": "posts/EERPD_Leveraging_Emotion_and_Emotion_Regulation_for_Improving_Personality_Detection/2024-06-23-EERPD_Leveraging_Emotion_and_Emotion_Regulation_for_Improving_Personality_Detection.html#appendix",
    "href": "posts/EERPD_Leveraging_Emotion_and_Emotion_Regulation_for_Improving_Personality_Detection/2024-06-23-EERPD_Leveraging_Emotion_and_Emotion_Regulation_for_Improving_Personality_Detection.html#appendix",
    "title": "EERPD: Leveraging Emotion and Emotion Regulation for Improving Personality Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16079v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16079v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5645"
  },
  {
    "objectID": "posts/Instruct_Large_Language_Models_to_Drive_like_Humans/2024-06-11-Instruct_Large_Language_Models_to_Drive_like_Humans.html#appendix",
    "href": "posts/Instruct_Large_Language_Models_to_Drive_like_Humans/2024-06-11-Instruct_Large_Language_Models_to_Drive_like_Humans.html#appendix",
    "title": "Instruct Large Language Models to Drive like Humans",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07296v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07296v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5303"
  },
  {
    "objectID": "posts/PORT_Preference_Optimization_on_Reasoning_Traces/2024-06-23-PORT_Preference_Optimization_on_Reasoning_Traces.html#appendix",
    "href": "posts/PORT_Preference_Optimization_on_Reasoning_Traces/2024-06-23-PORT_Preference_Optimization_on_Reasoning_Traces.html#appendix",
    "title": "PORT: Preference Optimization on Reasoning Traces",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16061v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16061v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8636"
  },
  {
    "objectID": "posts/LangSuitE_Planning_Controlling_and_Interacting_with_Large_Language_Models_in_Embodied_Text_Environments/2024-06-24-LangSuitE_Planning_Controlling_and_Interacting_with_Large_Language_Models_in_Embodied_Text_Environments.html#appendix",
    "href": "posts/LangSuitE_Planning_Controlling_and_Interacting_with_Large_Language_Models_in_Embodied_Text_Environments/2024-06-24-LangSuitE_Planning_Controlling_and_Interacting_with_Large_Language_Models_in_Embodied_Text_Environments.html#appendix",
    "title": "LangSuitE: Planning, Controlling and Interacting with Large Language Models in Embodied Text Environments",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16294v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16294v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7622"
  },
  {
    "objectID": "posts/Coherent_Zero_Shot_Visual_Instruction_Generation/2024-06-06-Coherent_Zero_Shot_Visual_Instruction_Generation.html#appendix",
    "href": "posts/Coherent_Zero_Shot_Visual_Instruction_Generation/2024-06-06-Coherent_Zero_Shot_Visual_Instruction_Generation.html#appendix",
    "title": "Coherent Zero-Shot Visual Instruction Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04337v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04337v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5054"
  },
  {
    "objectID": "posts/MagicItem_Dynamic_Behavior_Design_of_Virtual_Objects_with_Large_Language_Models_in_a_Consumer_Metaverse_Platform/2024-06-19-MagicItem_Dynamic_Behavior_Design_of_Virtual_Objects_with_Large_Language_Models_in_a_Consumer_Metaverse_Platform.html#appendix",
    "href": "posts/MagicItem_Dynamic_Behavior_Design_of_Virtual_Objects_with_Large_Language_Models_in_a_Consumer_Metaverse_Platform/2024-06-19-MagicItem_Dynamic_Behavior_Design_of_Virtual_Objects_with_Large_Language_Models_in_a_Consumer_Metaverse_Platform.html#appendix",
    "title": "MagicItem: Dynamic Behavior Design of Virtual Objects with Large Language Models in a Consumer Metaverse Platform",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13242v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13242v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9382"
  },
  {
    "objectID": "posts/Aligning_Agents_like_Large_Language_Models/2024-06-06-Aligning_Agents_like_Large_Language_Models.html",
    "href": "posts/Aligning_Agents_like_Large_Language_Models/2024-06-06-Aligning_Agents_like_Large_Language_Models.html",
    "title": "Aligning Agents like Large Language Models",
    "section": "",
    "text": "Summary:\nThe paper explores the challenge of training agents to behave as desired in complex 3D environments using high-dimensional sensory information. The authors draw an analogy between the undesirable behaviors of imitation learning agents and the unhelpful responses of unaligned large language models (LLMs). They investigate the procedure for aligning LLMs and apply it to aligning agents in a 3D environment from pixels. The authors focus on an academically illustrative part of a modern console game where players must navigate from a randomly selected spawn point to one of three jumppads. They demonstrate that they can align their agent to consistently perform the desired mode while providing insights and advice for successfully applying this approach to training agents.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an innovative approach to aligning agents in complex 3D environments by drawing an analogy between the undesirable behaviors of imitation learning agents and the unhelpful responses of unaligned LLMs. The authors’ investigation of the procedure for aligning LLMs and its application to aligning agents is a significant contribution to the field. However, the paper’s focus on an academically illustrative part of a modern console game may limit the generalizability of the findings to other complex 3D environments. Additionally, the use of synthetic preference labelling may not fully capture the complexity of human preferences in real-world scenarios. Further research is needed to evaluate the effectiveness of this approach in more diverse and complex environments and to explore the use of human preference labelling."
  },
  {
    "objectID": "posts/Aligning_Agents_like_Large_Language_Models/2024-06-06-Aligning_Agents_like_Large_Language_Models.html#appendix",
    "href": "posts/Aligning_Agents_like_Large_Language_Models/2024-06-06-Aligning_Agents_like_Large_Language_Models.html#appendix",
    "title": "Aligning Agents like Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04208v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04208v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12915"
  },
  {
    "objectID": "posts/WaDec_Decompile_WebAssembly_Using_Large_Language_Model/2024-06-17-WaDec_Decompile_WebAssembly_Using_Large_Language_Model.html#appendix",
    "href": "posts/WaDec_Decompile_WebAssembly_Using_Large_Language_Model/2024-06-17-WaDec_Decompile_WebAssembly_Using_Large_Language_Model.html#appendix",
    "title": "WaDec: Decompile WebAssembly Using Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11346v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11346v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10923"
  },
  {
    "objectID": "posts/AutoCAP_Towards_Automatic_Cross_lingual_Alignment_Planning_for_Zero_shot_Chain_of_Thought/2024-06-20-AutoCAP_Towards_Automatic_Cross_lingual_Alignment_Planning_for_Zero_shot_Chain_of_Thought.html#appendix",
    "href": "posts/AutoCAP_Towards_Automatic_Cross_lingual_Alignment_Planning_for_Zero_shot_Chain_of_Thought/2024-06-20-AutoCAP_Towards_Automatic_Cross_lingual_Alignment_Planning_for_Zero_shot_Chain_of_Thought.html#appendix",
    "title": "AutoCAP: Towards Automatic Cross-lingual Alignment Planning for Zero-shot Chain-of-Thought",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13940v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13940v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4960"
  },
  {
    "objectID": "posts/LICO_Large_Language_Models_for_In_Context_Molecular_Optimization/2024-06-27-LICO_Large_Language_Models_for_In_Context_Molecular_Optimization.html#appendix",
    "href": "posts/LICO_Large_Language_Models_for_In_Context_Molecular_Optimization/2024-06-27-LICO_Large_Language_Models_for_In_Context_Molecular_Optimization.html#appendix",
    "title": "LICO: Large Language Models for In-Context Molecular Optimization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18851v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18851v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11485"
  },
  {
    "objectID": "posts/The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis/2024-06-19-The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis.html",
    "href": "posts/The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis/2024-06-19-The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis.html",
    "title": "The Efficacy of Conversational Artificial Intelligence in Rectifying the Theory of Mind and Autonomy Biases: Comparative Analysis",
    "section": "",
    "text": "Summary:\nThis study evaluates the efficacy of Conversational Artificial Intelligence (CAI) in rectifying cognitive biases and recognizing affect in human-AI interactions, which is crucial for digital mental health interventions. The research employs a structured methodology with clinical-based virtual case scenarios simulating typical user-bot interactions. Performance and affect recognition were assessed across two categories of cognitive biases: theory of mind biases (anthropomorphization of AI, overtrust in AI, attribution to AI) and autonomy biases (illusion of control, fundamental attribution error, just-world hypothesis). A qualitative feedback mechanism was used with an ordinal scale to quantify responses based on accuracy, therapeutic quality, and adherence to CBT principles. Therapeutic bots (Wysa, Youper) and general-use LLMs (GTP 3.5, GTP 4, Gemini Pro) were evaluated through scripted interactions, double-reviewed by cognitive scientists and a clinical psychologist. Statistical analysis showed therapeutic bots were consistently outperformed by non-therapeutic bots in bias rectification and in 4 out of 6 biases in affect recognition. The data suggests that non-therapeutic chatbots are more effective in addressing some cognitive biases.\nMajor Findings:"
  },
  {
    "objectID": "posts/The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis/2024-06-19-The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis.html#appendix",
    "href": "posts/The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis/2024-06-19-The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis.html#appendix",
    "title": "The Efficacy of Conversational Artificial Intelligence in Rectifying the Theory of Mind and Autonomy Biases: Comparative Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13813v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13813v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17145"
  },
  {
    "objectID": "posts/FaceGPT_Self_supervised_Learning_to_Chat_about_3D_Human_Faces/2024-06-11-FaceGPT_Self_supervised_Learning_to_Chat_about_3D_Human_Faces.html#appendix",
    "href": "posts/FaceGPT_Self_supervised_Learning_to_Chat_about_3D_Human_Faces/2024-06-11-FaceGPT_Self_supervised_Learning_to_Chat_about_3D_Human_Faces.html#appendix",
    "title": "FaceGPT: Self-supervised Learning to Chat about 3D Human Faces",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07163v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07163v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6381"
  },
  {
    "objectID": "posts/Exploring_the_Educational_Landscape_of_AI_Large_Language_Models_Approaches_to_Explaining_Conservation_of_Momentum_in_Physics/2024-07-07-Exploring_the_Educational_Landscape_of_AI_Large_Language_Models_Approaches_to_Explaining_Conservation_of_Momentum_in_Physics.html#appendix",
    "href": "posts/Exploring_the_Educational_Landscape_of_AI_Large_Language_Models_Approaches_to_Explaining_Conservation_of_Momentum_in_Physics/2024-07-07-Exploring_the_Educational_Landscape_of_AI_Large_Language_Models_Approaches_to_Explaining_Conservation_of_Momentum_in_Physics.html#appendix",
    "title": "Exploring the Educational Landscape of AI: Large Language Models’ Approaches to Explaining Conservation of Momentum in Physics",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05308v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05308v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4973"
  },
  {
    "objectID": "posts/YouDream_Generating_Anatomically_Controllable_Consistent_Text_to_3D_Animals/2024-06-24-YouDream_Generating_Anatomically_Controllable_Consistent_Text_to_3D_Animals.html",
    "href": "posts/YouDream_Generating_Anatomically_Controllable_Consistent_Text_to_3D_Animals/2024-06-24-YouDream_Generating_Anatomically_Controllable_Consistent_Text_to_3D_Animals.html",
    "title": "YouDream: Generating Anatomically Controllable Consistent Text-to-3D Animals",
    "section": "",
    "text": "Summary:\nYouDream is a method for generating high-quality anatomically controllable 3D animals. It is guided by a text-to-image diffusion model controlled by 2D views of a 3D pose prior. The method generates 3D animals that are not possible to create using previous text-to-3D generative methods and preserves anatomic consistency. A fully automated pipeline for generating commonly found animals is also proposed, which uses a multi-agent LLM to adapt poses from a limited library of animal 3D poses to represent the desired animal. A user study conducted on the outcomes of YouDream demonstrates the preference of the animal models generated by this method over others.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/YouDream_Generating_Anatomically_Controllable_Consistent_Text_to_3D_Animals/2024-06-24-YouDream_Generating_Anatomically_Controllable_Consistent_Text_to_3D_Animals.html#appendix",
    "href": "posts/YouDream_Generating_Anatomically_Controllable_Consistent_Text_to_3D_Animals/2024-06-24-YouDream_Generating_Anatomically_Controllable_Consistent_Text_to_3D_Animals.html#appendix",
    "title": "YouDream: Generating Anatomically Controllable Consistent Text-to-3D Animals",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16273v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16273v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10409"
  },
  {
    "objectID": "posts/Reinforcement_Learning_from_Human_Feedback_without_Reward_Inference_Model_Free_Algorithm_and_Instance_Dependent_Analysis/2024-06-11-Reinforcement_Learning_from_Human_Feedback_without_Reward_Inference_Model_Free_Algorithm_and_Instance_Dependent_Analysis.html#appendix",
    "href": "posts/Reinforcement_Learning_from_Human_Feedback_without_Reward_Inference_Model_Free_Algorithm_and_Instance_Dependent_Analysis/2024-06-11-Reinforcement_Learning_from_Human_Feedback_without_Reward_Inference_Model_Free_Algorithm_and_Instance_Dependent_Analysis.html#appendix",
    "title": "Reinforcement Learning from Human Feedback without Reward Inference: Model-Free Algorithm and Instance-Dependent Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07455v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07455v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11143"
  },
  {
    "objectID": "posts/LLM_Targeted_Underperformance_Disproportionately_Impacts_Vulnerable_Users/2024-06-25-LLM_Targeted_Underperformance_Disproportionately_Impacts_Vulnerable_Users.html#appendix",
    "href": "posts/LLM_Targeted_Underperformance_Disproportionately_Impacts_Vulnerable_Users/2024-06-25-LLM_Targeted_Underperformance_Disproportionately_Impacts_Vulnerable_Users.html#appendix",
    "title": "LLM Targeted Underperformance Disproportionately Impacts Vulnerable Users",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17737v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17737v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6850"
  },
  {
    "objectID": "posts/Keyword_driven_Retrieval_Augmented_Large_Language_Models_for_Cold_start_User_Recommendations/2024-05-30-Keyword_driven_Retrieval_Augmented_Large_Language_Models_for_Cold_start_User_Recommendations.html#appendix",
    "href": "posts/Keyword_driven_Retrieval_Augmented_Large_Language_Models_for_Cold_start_User_Recommendations/2024-05-30-Keyword_driven_Retrieval_Augmented_Large_Language_Models_for_Cold_start_User_Recommendations.html#appendix",
    "title": "Keyword-driven Retrieval-Augmented Large Language Models for Cold-start User Recommendations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.19612v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.19612v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8262"
  },
  {
    "objectID": "posts/Predicting_the_Big_Five_Personality_Traits_in_Chinese_Counselling_Dialogues_Using_Large_Language_Models/2024-06-25-Predicting_the_Big_Five_Personality_Traits_in_Chinese_Counselling_Dialogues_Using_Large_Language_Models.html#appendix",
    "href": "posts/Predicting_the_Big_Five_Personality_Traits_in_Chinese_Counselling_Dialogues_Using_Large_Language_Models/2024-06-25-Predicting_the_Big_Five_Personality_Traits_in_Chinese_Counselling_Dialogues_Using_Large_Language_Models.html#appendix",
    "title": "Predicting the Big Five Personality Traits in Chinese Counselling Dialogues Using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17287v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17287v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10813"
  },
  {
    "objectID": "posts/DiscoveryBench_Towards_Data_Driven_Discovery_with_Large_Language_Models/2024-07-01-DiscoveryBench_Towards_Data_Driven_Discovery_with_Large_Language_Models.html#appendix",
    "href": "posts/DiscoveryBench_Towards_Data_Driven_Discovery_with_Large_Language_Models/2024-07-01-DiscoveryBench_Towards_Data_Driven_Discovery_with_Large_Language_Models.html#appendix",
    "title": "DiscoveryBench: Towards Data-Driven Discovery with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01725v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01725v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11425"
  },
  {
    "objectID": "posts/NoteLLM_2_Multimodal_Large_Representation_Models_for_Recommendation/2024-05-27-NoteLLM_2_Multimodal_Large_Representation_Models_for_Recommendation.html#appendix",
    "href": "posts/NoteLLM_2_Multimodal_Large_Representation_Models_for_Recommendation/2024-05-27-NoteLLM_2_Multimodal_Large_Representation_Models_for_Recommendation.html#appendix",
    "title": "NoteLLM-2: Multimodal Large Representation Models for Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.16789v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.16789v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7838"
  },
  {
    "objectID": "posts/POEM_Interactive_Prompt_Optimization_for_Enhancing_Multimodal_Reasoning_of_Large_Language_Models/2024-06-06-POEM_Interactive_Prompt_Optimization_for_Enhancing_Multimodal_Reasoning_of_Large_Language_Models.html#appendix",
    "href": "posts/POEM_Interactive_Prompt_Optimization_for_Enhancing_Multimodal_Reasoning_of_Large_Language_Models/2024-06-06-POEM_Interactive_Prompt_Optimization_for_Enhancing_Multimodal_Reasoning_of_Large_Language_Models.html#appendix",
    "title": "POEM: Interactive Prompt Optimization for Enhancing Multimodal Reasoning of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03843v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03843v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12924"
  },
  {
    "objectID": "posts/GRASP_A_Grid_Based_Benchmark_for_Evaluating_Commonsense_Spatial_Reasoning/2024-07-02-GRASP_A_Grid_Based_Benchmark_for_Evaluating_Commonsense_Spatial_Reasoning.html#appendix",
    "href": "posts/GRASP_A_Grid_Based_Benchmark_for_Evaluating_Commonsense_Spatial_Reasoning/2024-07-02-GRASP_A_Grid_Based_Benchmark_for_Evaluating_Commonsense_Spatial_Reasoning.html#appendix",
    "title": "GRASP: A Grid-Based Benchmark for Evaluating Commonsense Spatial Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01892v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01892v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11185"
  },
  {
    "objectID": "posts/Soley_Identification_and_Automated_Detection_of_Logic_Vulnerabilities_in_Ethereum_Smart_Contracts_Using_Large_Language_Models/2024-06-24-Soley_Identification_and_Automated_Detection_of_Logic_Vulnerabilities_in_Ethereum_Smart_Contracts_Using_Large_Language_Models.html#appendix",
    "href": "posts/Soley_Identification_and_Automated_Detection_of_Logic_Vulnerabilities_in_Ethereum_Smart_Contracts_Using_Large_Language_Models/2024-06-24-Soley_Identification_and_Automated_Detection_of_Logic_Vulnerabilities_in_Ethereum_Smart_Contracts_Using_Large_Language_Models.html#appendix",
    "title": "Soley: Identification and Automated Detection of Logic Vulnerabilities in Ethereum Smart Contracts Using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16244v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16244v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13712"
  },
  {
    "objectID": "posts/Assessing_the_Effectiveness_of_LLMs_in_Android_Application_Vulnerability_Analysis/2024-06-27-Assessing_the_Effectiveness_of_LLMs_in_Android_Application_Vulnerability_Analysis.html#appendix",
    "href": "posts/Assessing_the_Effectiveness_of_LLMs_in_Android_Application_Vulnerability_Analysis/2024-06-27-Assessing_the_Effectiveness_of_LLMs_in_Android_Application_Vulnerability_Analysis.html#appendix",
    "title": "Assessing the Effectiveness of LLMs in Android Application Vulnerability Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18894v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18894v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7395"
  },
  {
    "objectID": "posts/Language_Models_Resist_Alignment/2024-06-10-Language_Models_Resist_Alignment.html#appendix",
    "href": "posts/Language_Models_Resist_Alignment/2024-06-10-Language_Models_Resist_Alignment.html#appendix",
    "title": "Language Models Resist Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06144v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06144v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5000"
  },
  {
    "objectID": "posts/BertaQA_How_Much_Do_Language_Models_Know_About_Local_Culture/2024-06-11-BertaQA_How_Much_Do_Language_Models_Know_About_Local_Culture.html#appendix",
    "href": "posts/BertaQA_How_Much_Do_Language_Models_Know_About_Local_Culture/2024-06-11-BertaQA_How_Much_Do_Language_Models_Know_About_Local_Culture.html#appendix",
    "title": "BertaQA: How Much Do Language Models Know About Local Culture?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07302v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07302v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5979"
  },
  {
    "objectID": "posts/Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data/2024-06-20-Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data.html",
    "href": "posts/Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data/2024-06-20-Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data.html",
    "title": "Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data",
    "section": "",
    "text": "Summary:\nThe paper explores the ability of large language models (LLMs) to infer and verbalize latent structure from disparate training data, a phenomenon known as inductive out-of-context reasoning (OOCR). The authors demonstrate that frontier LLMs can perform inductive OOCR, as evidenced by a suite of five tasks. In one experiment, an LLM was finetuned on a corpus consisting only of distances between an unknown city and other known cities. Remarkably, the LLM could verbalize that the unknown city is Paris and use this fact to answer downstream questions without in-context learning or Chain of Thought. Further experiments showed that LLMs trained only on individual coin flip outcomes could verbalize whether the coin is biased, and those trained only on pairs could articulate a definition of a function and compute inverses. However, OOCR was found to be unreliable, particularly for smaller LLMs learning complex structures. The ability of LLMs to “connect the dots” without explicit in-context learning poses a potential obstacle to monitoring and controlling the knowledge acquired by LLMs.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an interesting exploration of the ability of LLMs to infer and verbalize latent structure from disparate training data. The authors’ findings suggest that LLMs can perform inductive OOCR, a type of generalization that allows them to infer latent information from evidence distributed across training documents and apply it to downstream tasks without in-context learning. However, the authors note that OOCR is unreliable, particularly for smaller LLMs learning complex structures. This raises questions about the robustness and"
  },
  {
    "objectID": "posts/Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data/2024-06-20-Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data.html#appendix",
    "href": "posts/Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data/2024-06-20-Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data.html#appendix",
    "title": "Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14546v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14546v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20777"
  },
  {
    "objectID": "posts/Evidence_of_a_log_scaling_law_for_political_persuasion_with_large_language_models/2024-06-20-Evidence_of_a_log_scaling_law_for_political_persuasion_with_large_language_models.html#appendix",
    "href": "posts/Evidence_of_a_log_scaling_law_for_political_persuasion_with_large_language_models/2024-06-20-Evidence_of_a_log_scaling_law_for_political_persuasion_with_large_language_models.html#appendix",
    "title": "Evidence of a log scaling law for political persuasion with large language models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14508v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14508v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9012"
  },
  {
    "objectID": "posts/ObscurePrompt_Jailbreaking_Large_Language_Models_via_Obscure_Input/2024-06-19-ObscurePrompt_Jailbreaking_Large_Language_Models_via_Obscure_Input.html#appendix",
    "href": "posts/ObscurePrompt_Jailbreaking_Large_Language_Models_via_Obscure_Input/2024-06-19-ObscurePrompt_Jailbreaking_Large_Language_Models_via_Obscure_Input.html#appendix",
    "title": "ObscurePrompt: Jailbreaking Large Language Models via Obscure Input",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13662v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13662v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7246"
  },
  {
    "objectID": "posts/GUI_Action_Narrator_Where_and_When_Did_That_Action_Take_Place/2024-06-19-GUI_Action_Narrator_Where_and_When_Did_That_Action_Take_Place.html#appendix",
    "href": "posts/GUI_Action_Narrator_Where_and_When_Did_That_Action_Take_Place/2024-06-19-GUI_Action_Narrator_Where_and_When_Did_That_Action_Take_Place.html#appendix",
    "title": "GUI Action Narrator: Where and When Did That Action Take Place?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13719v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13719v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6190"
  },
  {
    "objectID": "posts/Math_LLaVA_Bootstrapping_Mathematical_Reasoning_for_Multimodal_Large_Language_Models/2024-06-26-Math_LLaVA_Bootstrapping_Mathematical_Reasoning_for_Multimodal_Large_Language_Models.html#appendix",
    "href": "posts/Math_LLaVA_Bootstrapping_Mathematical_Reasoning_for_Multimodal_Large_Language_Models/2024-06-26-Math_LLaVA_Bootstrapping_Mathematical_Reasoning_for_Multimodal_Large_Language_Models.html#appendix",
    "title": "Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17294v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17294v2\n\n\nTruncated\nFalse\n\n\nWord Count\n6677"
  },
  {
    "objectID": "posts/Exploring_Large_Language_Models_for_Relevance_Judgments_in_Tetun/2024-06-11-Exploring_Large_Language_Models_for_Relevance_Judgments_in_Tetun.html#appendix",
    "href": "posts/Exploring_Large_Language_Models_for_Relevance_Judgments_in_Tetun/2024-06-11-Exploring_Large_Language_Models_for_Relevance_Judgments_in_Tetun.html#appendix",
    "title": "Exploring Large Language Models for Relevance Judgments in Tetun",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07299v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07299v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3697"
  },
  {
    "objectID": "posts/StackRAG_Agent_Improving_Developer_Answers_with_Retrieval_Augmented_Generation/2024-06-19-StackRAG_Agent_Improving_Developer_Answers_with_Retrieval_Augmented_Generation.html#appendix",
    "href": "posts/StackRAG_Agent_Improving_Developer_Answers_with_Retrieval_Augmented_Generation/2024-06-19-StackRAG_Agent_Improving_Developer_Answers_with_Retrieval_Augmented_Generation.html#appendix",
    "title": "StackRAG Agent: Improving Developer Answers with Retrieval-Augmented Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13840v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13840v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4732"
  },
  {
    "objectID": "posts/Refactoring_to_Pythonic_Idioms_A_Hybrid_Knowledge_Driven_Approach_Leveraging_Large_Language_Models/2024-06-06-Refactoring_to_Pythonic_Idioms_A_Hybrid_Knowledge_Driven_Approach_Leveraging_Large_Language_Models.html#appendix",
    "href": "posts/Refactoring_to_Pythonic_Idioms_A_Hybrid_Knowledge_Driven_Approach_Leveraging_Large_Language_Models/2024-06-06-Refactoring_to_Pythonic_Idioms_A_Hybrid_Knowledge_Driven_Approach_Leveraging_Large_Language_Models.html#appendix",
    "title": "Refactoring to Pythonic Idioms: A Hybrid Knowledge-Driven Approach Leveraging Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03660v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03660v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14284"
  },
  {
    "objectID": "posts/Causal_Inference_with_Latent_Variables_Recent_Advances_and_Future_Prospectives/2024-06-20-Causal_Inference_with_Latent_Variables_Recent_Advances_and_Future_Prospectives.html#appendix",
    "href": "posts/Causal_Inference_with_Latent_Variables_Recent_Advances_and_Future_Prospectives/2024-06-20-Causal_Inference_with_Latent_Variables_Recent_Advances_and_Future_Prospectives.html#appendix",
    "title": "Causal Inference with Latent Variables: Recent Advances and Future Prospectives",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13966v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13966v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11886"
  },
  {
    "objectID": "posts/UniGen_A_Unified_Framework_for_Textual_Dataset_Generation_Using_Large_Language_Models/2024-06-27-UniGen_A_Unified_Framework_for_Textual_Dataset_Generation_Using_Large_Language_Models.html#appendix",
    "href": "posts/UniGen_A_Unified_Framework_for_Textual_Dataset_Generation_Using_Large_Language_Models/2024-06-27-UniGen_A_Unified_Framework_for_Textual_Dataset_Generation_Using_Large_Language_Models.html#appendix",
    "title": "UniGen: A Unified Framework for Textual Dataset Generation Using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18966v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18966v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5825"
  },
  {
    "objectID": "posts/Interpretable_Catastrophic_Forgetting_of_Large_Language_Model_Fine_tuning_via_Instruction_Vector/2024-06-18-Interpretable_Catastrophic_Forgetting_of_Large_Language_Model_Fine_tuning_via_Instruction_Vector.html#appendix",
    "href": "posts/Interpretable_Catastrophic_Forgetting_of_Large_Language_Model_Fine_tuning_via_Instruction_Vector/2024-06-18-Interpretable_Catastrophic_Forgetting_of_Large_Language_Model_Fine_tuning_via_Instruction_Vector.html#appendix",
    "title": "Interpretable Catastrophic Forgetting of Large Language Model Fine-tuning via Instruction Vector",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12227v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12227v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8412"
  },
  {
    "objectID": "posts/Decision_Making_Behavior_Evaluation_Framework_for_LLMs_under_Uncertain_Context/2024-06-10-Decision_Making_Behavior_Evaluation_Framework_for_LLMs_under_Uncertain_Context.html#appendix",
    "href": "posts/Decision_Making_Behavior_Evaluation_Framework_for_LLMs_under_Uncertain_Context/2024-06-10-Decision_Making_Behavior_Evaluation_Framework_for_LLMs_under_Uncertain_Context.html#appendix",
    "title": "Decision-Making Behavior Evaluation Framework for LLMs under Uncertain Context",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05972v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05972v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6256"
  },
  {
    "objectID": "posts/FastMem_Fast_Memorization_of_Prompt_Improves_Context_Awareness_of_Large_Language_Models/2024-06-23-FastMem_Fast_Memorization_of_Prompt_Improves_Context_Awareness_of_Large_Language_Models.html#appendix",
    "href": "posts/FastMem_Fast_Memorization_of_Prompt_Improves_Context_Awareness_of_Large_Language_Models/2024-06-23-FastMem_Fast_Memorization_of_Prompt_Improves_Context_Awareness_of_Large_Language_Models.html#appendix",
    "title": "FastMem: Fast Memorization of Prompt Improves Context Awareness of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16069v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16069v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7001"
  },
  {
    "objectID": "posts/Unmasking_the_Imposters_In_Domain_Detection_of_Human_vs._Machine_Generated_Tweets/2024-06-25-Unmasking_the_Imposters_In_Domain_Detection_of_Human_vs._Machine_Generated_Tweets.html#appendix",
    "href": "posts/Unmasking_the_Imposters_In_Domain_Detection_of_Human_vs._Machine_Generated_Tweets/2024-06-25-Unmasking_the_Imposters_In_Domain_Detection_of_Human_vs._Machine_Generated_Tweets.html#appendix",
    "title": "Unmasking the Imposters: In-Domain Detection of Human vs. Machine-Generated Tweets",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17967v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17967v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6557"
  },
  {
    "objectID": "posts/CLIMB_A_Benchmark_of_Clinical_Bias_in_Large_Language_Models/2024-07-07-CLIMB_A_Benchmark_of_Clinical_Bias_in_Large_Language_Models.html#appendix",
    "href": "posts/CLIMB_A_Benchmark_of_Clinical_Bias_in_Large_Language_Models/2024-07-07-CLIMB_A_Benchmark_of_Clinical_Bias_in_Large_Language_Models.html#appendix",
    "title": "CLIMB: A Benchmark of Clinical Bias in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05250v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05250v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6808"
  },
  {
    "objectID": "posts/Generating_Query_Recommendations_via_LLMs/2024-05-30-Generating_Query_Recommendations_via_LLMs.html#appendix",
    "href": "posts/Generating_Query_Recommendations_via_LLMs/2024-05-30-Generating_Query_Recommendations_via_LLMs.html#appendix",
    "title": "Generating Query Recommendations via LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.19749v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.19749v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1852"
  },
  {
    "objectID": "posts/Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model/2024-06-11-Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model.html",
    "href": "posts/Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model/2024-06-11-Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model.html",
    "title": "Paying More Attention to Source Context: Mitigating Unfaithful Translations from Large Language Model",
    "section": "",
    "text": "Summary:\nThe paper focuses on the issue of unfaithful translations in large language models (LLMs) due to insufficient focus on the source context. The authors propose three methods to address this issue: reweight attention, contrastive decoding, and target-constrained tuning. The reweight attention method adjusts the attention weight of the source context to help models focus on the source context during generation. Contrastive decoding reduces the influence of target prefixes, and target-constrained tuning encourages LLMs to avoid excessive dependence on specific target prefixes. The experimental results show that the proposed methods improve translation performance across several language pairs in the proposed unfaithful translation test sets, outperforming baseline methods and effectively reducing the phenomenon of hallucinatory and unfaithful translations.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model/2024-06-11-Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model.html#appendix",
    "href": "posts/Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model/2024-06-11-Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model.html#appendix",
    "title": "Paying More Attention to Source Context: Mitigating Unfaithful Translations from Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07036v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07036v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10716"
  },
  {
    "objectID": "posts/SoP_Unlock_the_Power_of_Social_Facilitation_for_Automatic_Jailbreak_Attack/2024-07-02-SoP_Unlock_the_Power_of_Social_Facilitation_for_Automatic_Jailbreak_Attack.html#appendix",
    "href": "posts/SoP_Unlock_the_Power_of_Social_Facilitation_for_Automatic_Jailbreak_Attack/2024-07-02-SoP_Unlock_the_Power_of_Social_Facilitation_for_Automatic_Jailbreak_Attack.html#appendix",
    "title": "SoP: Unlock the Power of Social Facilitation for Automatic Jailbreak Attack",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01902v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01902v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14863"
  },
  {
    "objectID": "posts/iLLM_TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement/2024-07-08-iLLM_TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement.html",
    "href": "posts/iLLM_TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement/2024-07-08-iLLM_TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement.html",
    "title": "iLLM-TSC: Integration reinforcement learning and large language model for traffic signal control policy improvement",
    "section": "",
    "text": "Summary:\nThe paper introduces a novel integration framework, iLLM-TSC, which combines a large language model (LLM) with reinforcement learning (RL) to address the limitations of existing RL-based traffic signal control (TSC) systems. These limitations include imperfect observations caused by degraded communication and the absence of rare real-life events in the reward function, such as unconsidered emergency vehicles. The iLLM-TSC framework allows RL agents to make initial decisions based on observed data, leveraging their ability to learn from specific environments. Subsequently, the LLM model refines these decisions by incorporating additional real-time information not initially used by the RL agents. This integration approach can be seamlessly integrated with existing RL-based TSC systems without requiring modifications. Extensive testing confirms that the iLLM-TSC approach reduces the average waiting time by 17.5% in degraded communication conditions compared to traditional RL methods.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/iLLM_TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement/2024-07-08-iLLM_TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement.html#appendix",
    "href": "posts/iLLM_TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement/2024-07-08-iLLM_TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement.html#appendix",
    "title": "iLLM-TSC: Integration reinforcement learning and large language model for traffic signal control policy improvement",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06025v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06025v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8535"
  },
  {
    "objectID": "posts/BeHonest_Benchmarking_Honesty_of_Large_Language_Models/2024-06-19-BeHonest_Benchmarking_Honesty_of_Large_Language_Models.html#appendix",
    "href": "posts/BeHonest_Benchmarking_Honesty_of_Large_Language_Models/2024-06-19-BeHonest_Benchmarking_Honesty_of_Large_Language_Models.html#appendix",
    "title": "BeHonest: Benchmarking Honesty of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13261v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13261v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9544"
  },
  {
    "objectID": "posts/LEXI_Large_Language_Models_Experimentation_Interface/2024-07-02-LEXI_Large_Language_Models_Experimentation_Interface.html#appendix",
    "href": "posts/LEXI_Large_Language_Models_Experimentation_Interface/2024-07-02-LEXI_Large_Language_Models_Experimentation_Interface.html#appendix",
    "title": "LEXI: Large Language Models Experimentation Interface",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01488v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01488v2\n\n\nTruncated\nFalse\n\n\nWord Count\n8957"
  },
  {
    "objectID": "posts/LiveMind_Low_latency_Large_Language_Models_with_Simultaneous_Inference/2024-06-20-LiveMind_Low_latency_Large_Language_Models_with_Simultaneous_Inference.html#appendix",
    "href": "posts/LiveMind_Low_latency_Large_Language_Models_with_Simultaneous_Inference/2024-06-20-LiveMind_Low_latency_Large_Language_Models_with_Simultaneous_Inference.html#appendix",
    "title": "LiveMind: Low-latency Large Language Models with Simultaneous Inference",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14319v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14319v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8602"
  },
  {
    "objectID": "posts/Towards_a_Personal_Health_Large_Language_Model/2024-06-10-Towards_a_Personal_Health_Large_Language_Model.html",
    "href": "posts/Towards_a_Personal_Health_Large_Language_Model/2024-06-10-Towards_a_Personal_Health_Large_Language_Model.html",
    "title": "Towards a Personal Health Large Language Model",
    "section": "",
    "text": "Summary:\nThe paper introduces Personal Health Large Language Model (PH-LLM), a version of Gemini fine-tuned for personal health and wellness. PH-LLM is evaluated on three aspects of personal health: generating personalized insights and recommendations for user goals in the domains of sleep and fitness, assessing levels of expert domain knowledge, and predicting patient-reported outcomes in sleep quality from detailed sensor information. The model is benchmarked against expert human responses and evaluated through comprehensive human and automatic evaluation of domain-specific rubrics. The results show that both Gemini Ultra 1.0 and PH-LLM are not statistically different from expert performance in fitness, while experts remain superior for sleep. However, fine-tuning PH-LLM provided significant improvements in using relevant domain knowledge and personalizing information for sleep insights. PH-LLM achieved 79% on sleep (N=629 questions) and 88% on fitness (N=99 questions) in multiple choice question examinations, both of which exceed average scores from a sample of human experts. The model also demonstrated the ability to predict self-reported assessments of sleep quality by training it to predict self-reported sleep disruption and sleep impairment outcomes from textual and multimodal encoding representations of wearable sensor data.\nMajor Findings:"
  },
  {
    "objectID": "posts/Towards_a_Personal_Health_Large_Language_Model/2024-06-10-Towards_a_Personal_Health_Large_Language_Model.html#appendix",
    "href": "posts/Towards_a_Personal_Health_Large_Language_Model/2024-06-10-Towards_a_Personal_Health_Large_Language_Model.html#appendix",
    "title": "Towards a Personal Health Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06474v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06474v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17580"
  },
  {
    "objectID": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#summary-1",
    "href": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#summary-1",
    "title": "FragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models",
    "section": "Summary:",
    "text": "Summary:\n\nThe paper proposes a method to improve the processing of long contexts in Large Language Models (LLMs) by exploiting fragment-level relations in external memory.\nThe authors formulate fragment-level relations and present several instantiations for different text types.\nThey introduce a relation-aware fragment assessment criteria and present the fragment-connected Hierarchical Memory based LLM.\nThe proposed method is validated on long story understanding, repository-level code generation, and long-term chatting tasks."
  },
  {
    "objectID": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#major-findings",
    "href": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#major-findings",
    "title": "FragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nFragment-level Relations: The authors propose a method to exploit fragment-level relations in external memory to improve the processing of long contexts in LLMs.\nRelation-aware Fragment Assessment: The authors introduce a relation-aware fragment assessment criteria to better assess the importance of each fragment in the context.\nFragment-connected Hierarchical Memory based LLM: The authors present a new LLM architecture that incorporates fragment-level relations in external memory to improve the processing of long contexts."
  },
  {
    "objectID": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#analysis-and-critique",
    "title": "FragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe proposed method effectively addresses the issue of isolated fragment processing in existing External Memory augmented LLMs.\nThe paper provides a comprehensive evaluation of the proposed method on various long text processing tasks, demonstrating its effectiveness.\nHowever, the paper does not discuss the potential limitations or challenges of the proposed method, such as the computational overhead or the impact on the model’s performance.\nAdditionally, the paper does not provide a comparison with other existing methods for processing long contexts in LLMs.\nThe paper could benefit from a more detailed discussion of the potential applications and implications of the proposed method in real-world scenarios.\nOverall, the paper presents a promising approach to improve the processing of long contexts in LLMs, but further research is needed to fully evaluate its potential and limitations."
  },
  {
    "objectID": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#appendix",
    "href": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#appendix",
    "title": "FragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03092v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03092v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7567"
  },
  {
    "objectID": "posts/AgentDojo_A_Dynamic_Environment_to_Evaluate_Attacks_and_Defenses_for_LLM_Agents/2024-06-19-AgentDojo_A_Dynamic_Environment_to_Evaluate_Attacks_and_Defenses_for_LLM_Agents.html#appendix",
    "href": "posts/AgentDojo_A_Dynamic_Environment_to_Evaluate_Attacks_and_Defenses_for_LLM_Agents/2024-06-19-AgentDojo_A_Dynamic_Environment_to_Evaluate_Attacks_and_Defenses_for_LLM_Agents.html#appendix",
    "title": "AgentDojo: A Dynamic Environment to Evaluate Attacks and Defenses for LLM Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13352v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13352v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7934"
  },
  {
    "objectID": "posts/Depression_Detection_and_Analysis_using_Large_Language_Models_on_Textual_and_Audio_Visual_Modalities/2024-07-08-Depression_Detection_and_Analysis_using_Large_Language_Models_on_Textual_and_Audio_Visual_Modalities.html#appendix",
    "href": "posts/Depression_Detection_and_Analysis_using_Large_Language_Models_on_Textual_and_Audio_Visual_Modalities/2024-07-08-Depression_Detection_and_Analysis_using_Large_Language_Models_on_Textual_and_Audio_Visual_Modalities.html#appendix",
    "title": "Depression Detection and Analysis using Large Language Models on Textual and Audio-Visual Modalities",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06125v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06125v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9401"
  },
  {
    "objectID": "posts/Is_GPT_4_Alone_Sufficient_for_Automated_Essay_Scoring_A_Comparative_Judgment_Approach_Based_on_Rater_Cognition/2024-07-08-Is_GPT_4_Alone_Sufficient_for_Automated_Essay_Scoring_A_Comparative_Judgment_Approach_Based_on_Rater_Cognition.html#appendix",
    "href": "posts/Is_GPT_4_Alone_Sufficient_for_Automated_Essay_Scoring_A_Comparative_Judgment_Approach_Based_on_Rater_Cognition/2024-07-08-Is_GPT_4_Alone_Sufficient_for_Automated_Essay_Scoring_A_Comparative_Judgment_Approach_Based_on_Rater_Cognition.html#appendix",
    "title": "Is GPT-4 Alone Sufficient for Automated Essay Scoring?: A Comparative Judgment Approach Based on Rater Cognition",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05733v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05733v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6518"
  },
  {
    "objectID": "posts/FastGAS_Fast_Graph_based_Annotation_Selection_for_In_Context_Learning/2024-06-06-FastGAS_Fast_Graph_based_Annotation_Selection_for_In_Context_Learning.html#appendix",
    "href": "posts/FastGAS_Fast_Graph_based_Annotation_Selection_for_In_Context_Learning/2024-06-06-FastGAS_Fast_Graph_based_Annotation_Selection_for_In_Context_Learning.html#appendix",
    "title": "FastGAS: Fast Graph-based Annotation Selection for In-Context Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03730v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03730v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8522"
  },
  {
    "objectID": "posts/Prism_A_Framework_for_Decoupling_and_Assessing_the_Capabilities_of_VLMs/2024-06-20-Prism_A_Framework_for_Decoupling_and_Assessing_the_Capabilities_of_VLMs.html#appendix",
    "href": "posts/Prism_A_Framework_for_Decoupling_and_Assessing_the_Capabilities_of_VLMs/2024-06-20-Prism_A_Framework_for_Decoupling_and_Assessing_the_Capabilities_of_VLMs.html#appendix",
    "title": "Prism: A Framework for Decoupling and Assessing the Capabilities of VLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14544v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14544v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8916"
  },
  {
    "objectID": "posts/CherryRec_Enhancing_News_Recommendation_Quality_via_LLM_driven_Framework/2024-06-18-CherryRec_Enhancing_News_Recommendation_Quality_via_LLM_driven_Framework.html#appendix",
    "href": "posts/CherryRec_Enhancing_News_Recommendation_Quality_via_LLM_driven_Framework/2024-06-18-CherryRec_Enhancing_News_Recommendation_Quality_via_LLM_driven_Framework.html#appendix",
    "title": "CherryRec: Enhancing News Recommendation Quality via LLM-driven Framework",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12243v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12243v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4153"
  },
  {
    "objectID": "posts/MInference_1.0_Accelerating_Pre_filling_for_Long_Context_LLMs_via_Dynamic_Sparse_Attention/2024-07-02-MInference_1.0_Accelerating_Pre_filling_for_Long_Context_LLMs_via_Dynamic_Sparse_Attention.html#appendix",
    "href": "posts/MInference_1.0_Accelerating_Pre_filling_for_Long_Context_LLMs_via_Dynamic_Sparse_Attention/2024-07-02-MInference_1.0_Accelerating_Pre_filling_for_Long_Context_LLMs_via_Dynamic_Sparse_Attention.html#appendix",
    "title": "MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02490v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02490v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10854"
  },
  {
    "objectID": "posts/SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance/2024-06-26-SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance.html#major-findings",
    "href": "posts/SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance/2024-06-26-SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance.html#major-findings",
    "title": "SafeAligner: Safety Alignment against Jailbreak Attacks via Response Disparity Guidance",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nSafeAligner increases the likelihood of beneficial tokens while reducing the occurrence of harmful ones, ensuring secure alignment with minimal loss to generality.\nExtensive experiments demonstrate that SafeAligner can be applied to various LLMs, improving their defensive capabilities while preserving their inherent general capabilities.\nThe method achieves safety alignment cost-effectively, with potential cost reductions by scaling down internal models."
  },
  {
    "objectID": "posts/SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance/2024-06-26-SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance.html#analysis-and-critique",
    "href": "posts/SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance/2024-06-26-SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance.html#analysis-and-critique",
    "title": "SafeAligner: Safety Alignment against Jailbreak Attacks via Response Disparity Guidance",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a novel approach to addressing jailbreak attacks on LLMs, which is a significant concern in the field. The proposed method, SafeAligner, offers a promising solution by leveraging the differences in the safety tendencies of model responses. However, the paper does not discuss the potential limitations or unintended consequences of using this method. For instance, it is unclear how SafeAligner would handle cases where the Sentinel and Intruder Models produce conflicting or ambiguous responses. Additionally, the paper does not address the potential computational overhead of training and maintaining two specialized models. Further research is needed to evaluate the long-term effectiveness and efficiency of SafeAligner in real-world applications."
  },
  {
    "objectID": "posts/SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance/2024-06-26-SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance.html#appendix",
    "href": "posts/SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance/2024-06-26-SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance.html#appendix",
    "title": "SafeAligner: Safety Alignment against Jailbreak Attacks via Response Disparity Guidance",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18118v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18118v1\n\n\nTruncated\nFalse\n\n\nWord Count\n21385"
  },
  {
    "objectID": "posts/Collective_Innovation_in_Groups_of_Large_Language_Models/2024-07-07-Collective_Innovation_in_Groups_of_Large_Language_Models.html#appendix",
    "href": "posts/Collective_Innovation_in_Groups_of_Large_Language_Models/2024-07-07-Collective_Innovation_in_Groups_of_Large_Language_Models.html#appendix",
    "title": "Collective Innovation in Groups of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05377v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05377v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8010"
  },
  {
    "objectID": "posts/LiveBench_A_Challenging_Contamination_Free_LLM_Benchmark/2024-06-27-LiveBench_A_Challenging_Contamination_Free_LLM_Benchmark.html",
    "href": "posts/LiveBench_A_Challenging_Contamination_Free_LLM_Benchmark/2024-06-27-LiveBench_A_Challenging_Contamination_Free_LLM_Benchmark.html",
    "title": "LiveBench: A Challenging, Contamination-Free LLM Benchmark",
    "section": "",
    "text": "Summary: The paper introduces LiveBench, a new benchmark for large language models (LLMs) that aims to address the issues of test set contamination and the limitations of LLM judging and human crowdsourcing. LiveBench features frequently-updated questions from recent information sources, automatic scoring based on objective ground-truth values, and a wide variety of challenging tasks across six categories: coding, data, instruction, language, math, and reasoning. The benchmark includes questions based on recent math competitions, arXiv papers, news articles, and datasets, as well as harder, contamination-free versions of tasks from previous benchmarks. The study compares 49 LLMs on LiveBench, with claude-3-5-sonnet-20240620 performing the best across all categories and overall.\nMajor Findings: 1. LiveBench is a new benchmark for LL"
  },
  {
    "objectID": "posts/LiveBench_A_Challenging_Contamination_Free_LLM_Benchmark/2024-06-27-LiveBench_A_Challenging_Contamination_Free_LLM_Benchmark.html#appendix",
    "href": "posts/LiveBench_A_Challenging_Contamination_Free_LLM_Benchmark/2024-06-27-LiveBench_A_Challenging_Contamination_Free_LLM_Benchmark.html#appendix",
    "title": "LiveBench: A Challenging, Contamination-Free LLM Benchmark",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19314v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19314v1\n\n\nTruncated\nTrue\n\n\nWord Count\n27632"
  },
  {
    "objectID": "posts/Robust_Few_shot_Transfer_Learning_for_Knowledge_Base_Question_Answering_with_Unanswerable_Questions/2024-06-20-Robust_Few_shot_Transfer_Learning_for_Knowledge_Base_Question_Answering_with_Unanswerable_Questions.html#appendix",
    "href": "posts/Robust_Few_shot_Transfer_Learning_for_Knowledge_Base_Question_Answering_with_Unanswerable_Questions/2024-06-20-Robust_Few_shot_Transfer_Learning_for_Knowledge_Base_Question_Answering_with_Unanswerable_Questions.html#appendix",
    "title": "Robust Few-shot Transfer Learning for Knowledge Base Question Answering with Unanswerable Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14313v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14313v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10473"
  },
  {
    "objectID": "posts/Categorical_Syllogisms_Revisited_A_Review_of_the_Logical_Reasoning_Abilities_of_LLMs_for_Analyzing_Categorical_Syllogism/2024-06-26-Categorical_Syllogisms_Revisited_A_Review_of_the_Logical_Reasoning_Abilities_of_LLMs_for_Analyzing_Categorical_Syllogism.html",
    "href": "posts/Categorical_Syllogisms_Revisited_A_Review_of_the_Logical_Reasoning_Abilities_of_LLMs_for_Analyzing_Categorical_Syllogism/2024-06-26-Categorical_Syllogisms_Revisited_A_Review_of_the_Logical_Reasoning_Abilities_of_LLMs_for_Analyzing_Categorical_Syllogism.html",
    "title": "Categorical Syllogisms Revisited: A Review of the Logical Reasoning Abilities of LLMs for Analyzing Categorical Syllogism",
    "section": "",
    "text": "Summary:\nThis paper provides a systematic overview of prior works on the logical reasoning ability of large language models (LLMs) for analyzing categorical syllogisms. The authors investigate all possible variations of categorical syllogisms from a purely logical perspective and examine the underlying configurations tested by existing datasets. The results indicate that compared to template-based synthetic datasets, crowdsourcing approaches sacrifice the coverage of configurations for more language variations, thus bringing challenges to fully testing LLMs under different situations. The paper also summarizes the findings and observations for the performances of LLMs in inferring the validity of syllogisms from the current literature. The error rate breakdown analyses suggest that the interpretation of quantifiers is the current bottleneck that limits the performances of LLMs. Finally, the paper discusses several points that might be worth considering when researchers plan on the future release of categorical syllogism datasets.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive review of the current literature regarding categorical syllogisms and the logical reasoning abilities of LLMs. The authors’ analysis of the limitations of existing datasets and the bottlenecks in LLMs’ performance is insightful and valuable for future research. However, the paper does not provide a clear solution to the identified problems or propose new models to improve LLMs’ performance. Additionally, the paper does not discuss the potential biases or methodological issues in the existing literature, which could be a limitation of the review. Overall, the paper is well-structured, coherent, and effectively communicates the essential information from the academic article."
  },
  {
    "objectID": "posts/Categorical_Syllogisms_Revisited_A_Review_of_the_Logical_Reasoning_Abilities_of_LLMs_for_Analyzing_Categorical_Syllogism/2024-06-26-Categorical_Syllogisms_Revisited_A_Review_of_the_Logical_Reasoning_Abilities_of_LLMs_for_Analyzing_Categorical_Syllogism.html#appendix",
    "href": "posts/Categorical_Syllogisms_Revisited_A_Review_of_the_Logical_Reasoning_Abilities_of_LLMs_for_Analyzing_Categorical_Syllogism/2024-06-26-Categorical_Syllogisms_Revisited_A_Review_of_the_Logical_Reasoning_Abilities_of_LLMs_for_Analyzing_Categorical_Syllogism.html#appendix",
    "title": "Categorical Syllogisms Revisited: A Review of the Logical Reasoning Abilities of LLMs for Analyzing Categorical Syllogism",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18762v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18762v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7262"
  },
  {
    "objectID": "posts/KG_FPQ_Evaluating_Factuality_Hallucination_in_LLMs_with_Knowledge_Graph_based_False_Premise_Questions/2024-07-08-KG_FPQ_Evaluating_Factuality_Hallucination_in_LLMs_with_Knowledge_Graph_based_False_Premise_Questions.html#appendix",
    "href": "posts/KG_FPQ_Evaluating_Factuality_Hallucination_in_LLMs_with_Knowledge_Graph_based_False_Premise_Questions/2024-07-08-KG_FPQ_Evaluating_Factuality_Hallucination_in_LLMs_with_Knowledge_Graph_based_False_Premise_Questions.html#appendix",
    "title": "KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05868v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05868v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7115"
  },
  {
    "objectID": "posts/Distributional_reasoning_in_LLMs_Parallel_reasoning_processes_in_multi_hop_reasoning/2024-06-19-Distributional_reasoning_in_LLMs_Parallel_reasoning_processes_in_multi_hop_reasoning.html#appendix",
    "href": "posts/Distributional_reasoning_in_LLMs_Parallel_reasoning_processes_in_multi_hop_reasoning/2024-06-19-Distributional_reasoning_in_LLMs_Parallel_reasoning_processes_in_multi_hop_reasoning.html#appendix",
    "title": "Distributional reasoning in LLMs: Parallel reasoning processes in multi-hop reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13858v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13858v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7199"
  },
  {
    "objectID": "posts/BEEAR_Embedding_based_Adversarial_Removal_of_Safety_Backdoors_in_Instruction_tuned_Language_Models/2024-06-24-BEEAR_Embedding_based_Adversarial_Removal_of_Safety_Backdoors_in_Instruction_tuned_Language_Models.html#appendix",
    "href": "posts/BEEAR_Embedding_based_Adversarial_Removal_of_Safety_Backdoors_in_Instruction_tuned_Language_Models/2024-06-24-BEEAR_Embedding_based_Adversarial_Removal_of_Safety_Backdoors_in_Instruction_tuned_Language_Models.html#appendix",
    "title": "BEEAR: Embedding-based Adversarial Removal of Safety Backdoors in Instruction-tuned Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17092v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17092v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11761"
  },
  {
    "objectID": "posts/Improving_Conversational_Abilities_of_Quantized_Large_Language_Models_via_Direct_Preference_Alignment/2024-07-03-Improving_Conversational_Abilities_of_Quantized_Large_Language_Models_via_Direct_Preference_Alignment.html#appendix",
    "href": "posts/Improving_Conversational_Abilities_of_Quantized_Large_Language_Models_via_Direct_Preference_Alignment/2024-07-03-Improving_Conversational_Abilities_of_Quantized_Large_Language_Models_via_Direct_Preference_Alignment.html#appendix",
    "title": "Improving Conversational Abilities of Quantized Large Language Models via Direct Preference Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03051v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03051v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9273"
  },
  {
    "objectID": "posts/Global_is_Good_Local_is_Bad_Understanding_Brand_Bias_in_LLMs/2024-06-20-Global_is_Good_Local_is_Bad_Understanding_Brand_Bias_in_LLMs.html#appendix",
    "href": "posts/Global_is_Good_Local_is_Bad_Understanding_Brand_Bias_in_LLMs/2024-06-20-Global_is_Good_Local_is_Bad_Understanding_Brand_Bias_in_LLMs.html#appendix",
    "title": "Global is Good, Local is Bad?: Understanding Brand Bias in LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13997v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13997v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4379"
  },
  {
    "objectID": "posts/Paraphrase_and_Aggregate_with_Large_Language_Models_for_Minimizing_Intent_Classification_Errors/2024-06-24-Paraphrase_and_Aggregate_with_Large_Language_Models_for_Minimizing_Intent_Classification_Errors.html#appendix",
    "href": "posts/Paraphrase_and_Aggregate_with_Large_Language_Models_for_Minimizing_Intent_Classification_Errors/2024-06-24-Paraphrase_and_Aggregate_with_Large_Language_Models_for_Minimizing_Intent_Classification_Errors.html#appendix",
    "title": "Paraphrase and Aggregate with Large Language Models for Minimizing Intent Classification Errors",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17163v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17163v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4269"
  },
  {
    "objectID": "posts/Language_Models_are_Alignable_Decision_Makers_Dataset_and_Application_to_the_Medical_Triage_Domain/2024-06-10-Language_Models_are_Alignable_Decision_Makers_Dataset_and_Application_to_the_Medical_Triage_Domain.html#appendix",
    "href": "posts/Language_Models_are_Alignable_Decision_Makers_Dataset_and_Application_to_the_Medical_Triage_Domain/2024-06-10-Language_Models_are_Alignable_Decision_Makers_Dataset_and_Application_to_the_Medical_Triage_Domain.html#appendix",
    "title": "Language Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06435v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06435v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9086"
  },
  {
    "objectID": "posts/How_Does_Quantization_Affect_Multilingual_LLMs/2024-07-03-How_Does_Quantization_Affect_Multilingual_LLMs.html#appendix",
    "href": "posts/How_Does_Quantization_Affect_Multilingual_LLMs/2024-07-03-How_Does_Quantization_Affect_Multilingual_LLMs.html#appendix",
    "title": "How Does Quantization Affect Multilingual LLMs?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03211v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03211v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6954"
  },
  {
    "objectID": "posts/SSP_Self_Supervised_Prompting_for_Cross_Lingual_Transfer_to_Low_Resource_Languages_using_Large_Language_Models/2024-06-27-SSP_Self_Supervised_Prompting_for_Cross_Lingual_Transfer_to_Low_Resource_Languages_using_Large_Language_Models.html#appendix",
    "href": "posts/SSP_Self_Supervised_Prompting_for_Cross_Lingual_Transfer_to_Low_Resource_Languages_using_Large_Language_Models/2024-06-27-SSP_Self_Supervised_Prompting_for_Cross_Lingual_Transfer_to_Low_Resource_Languages_using_Large_Language_Models.html#appendix",
    "title": "SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18880v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18880v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11013"
  },
  {
    "objectID": "posts/CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only/2024-06-11-CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only.html",
    "href": "posts/CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only/2024-06-11-CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only.html",
    "title": "CAAP: Context-Aware Action Planning Prompting to Solve Computer Tasks with Front-End UI Only",
    "section": "",
    "text": "Summary:\nThe paper introduces an LLM-based agent that operates solely on the basis of screenshots for recognizing environments, while leveraging in-context learning to eliminate the need for collecting large datasets of human demonstration. The proposed method, named Context-Aware Action Planning (CAAP) prompting, encourages the agent to meticulously review the context in various angles. The agent achieves a success rate of 94.4% on 67 types of MiniWoB++ problems, utilizing only 1.48 demonstrations per problem type. The method offers the potential for broader applications, especially for tasks that require inter-application coordination on computers or smartphones.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel approach to LLM-based agents that addresses the limitations of existing methods reliant on HTML or DOM inputs and those that combine supervised learning (SL) and reinforcement learning (RL). The proposed agent operates solely on visual inputs and utilizes a large language model (LLM). The CAAP prompting approach is introduced to enhance the decision-making capabilities of ICL-based agents. The evaluations using the MiniWoB++ benchmark demonstrate the superiority of the proposed method. However, the scope of validation remains limited, and further research is needed to evaluate the agent across a broader array of benchmarks. Additionally, the agent’s reliance on visual observation data may lead to observation failures, as demonstrated in the case study. The paper also acknowledges the limitations of the benchmark directives and the need for more comprehensive assessment from a research perspective."
  },
  {
    "objectID": "posts/CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only/2024-06-11-CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only.html#appendix",
    "href": "posts/CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only/2024-06-11-CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only.html#appendix",
    "title": "CAAP: Context-Aware Action Planning Prompting to Solve Computer Tasks with Front-End UI Only",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06947v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06947v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10877"
  },
  {
    "objectID": "posts/Disce_aut_Deficere_Evaluating_LLMs_Proficiency_on_the_INVALSI_Italian_Benchmark/2024-06-25-Disce_aut_Deficere_Evaluating_LLMs_Proficiency_on_the_INVALSI_Italian_Benchmark.html#appendix",
    "href": "posts/Disce_aut_Deficere_Evaluating_LLMs_Proficiency_on_the_INVALSI_Italian_Benchmark/2024-06-25-Disce_aut_Deficere_Evaluating_LLMs_Proficiency_on_the_INVALSI_Italian_Benchmark.html#appendix",
    "title": "Disce aut Deficere: Evaluating LLMs Proficiency on the INVALSI Italian Benchmark",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17535v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17535v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8268"
  },
  {
    "objectID": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#major-findings",
    "href": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#major-findings",
    "title": "MolX: Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nMolX significantly improves the performance of LLMs on various molecule-related tasks, outperforming baselines on tasks such as molecule-to-text translation, retrosynthesis, and property prediction.\nMolX can act as a plug-in module to the LLM, enhancing its performance on molecule-related tasks while fully preserving its general-purpose usage on other domains.\nThe proposed method only introduces a small number of trainable parameters, making it an efficient solution for enhancing LLMs."
  },
  {
    "objectID": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#analysis-and-critique",
    "href": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#analysis-and-critique",
    "title": "MolX: Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper does not discuss the potential limitations of the MolX framework, such as its performance on more complex molecular structures or its ability to handle large-scale molecular datasets.\nThe paper does not provide a comparison with other multi-modal approaches for molecular learning, which could provide a more comprehensive evaluation of the proposed method.\nThe paper does not discuss the potential applications of MolX in other domains, such as drug discovery or materials science, which could provide additional insights into its potential impact.\nThe paper does not discuss the potential ethical implications of using LLMs for molecular learning, such as the potential for bias in the generated molecular structures or the potential for misuse in the development of harmful substances.\n\nOverall, the paper presents a promising approach for enhancing the ability of LLMs to comprehend molecules. However, further research is needed to fully evaluate its limitations, compare it with other approaches, and explore its potential applications and ethical implications."
  },
  {
    "objectID": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#appendix",
    "href": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#appendix",
    "title": "MolX: Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06777v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06777v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8694"
  },
  {
    "objectID": "posts/A_Three_Pronged_Approach_to_Cross_Lingual_Adaptation_with_Multilingual_LLMs/2024-06-25-A_Three_Pronged_Approach_to_Cross_Lingual_Adaptation_with_Multilingual_LLMs.html#appendix",
    "href": "posts/A_Three_Pronged_Approach_to_Cross_Lingual_Adaptation_with_Multilingual_LLMs/2024-06-25-A_Three_Pronged_Approach_to_Cross_Lingual_Adaptation_with_Multilingual_LLMs.html#appendix",
    "title": "A Three-Pronged Approach to Cross-Lingual Adaptation with Multilingual LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17377v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17377v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6250"
  },
  {
    "objectID": "posts/A_Superalignment_Framework_in_Autonomous_Driving_with_Large_Language_Models/2024-06-09-A_Superalignment_Framework_in_Autonomous_Driving_with_Large_Language_Models.html#appendix",
    "href": "posts/A_Superalignment_Framework_in_Autonomous_Driving_with_Large_Language_Models/2024-06-09-A_Superalignment_Framework_in_Autonomous_Driving_with_Large_Language_Models.html#appendix",
    "title": "A Superalignment Framework in Autonomous Driving with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05651v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05651v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3979"
  },
  {
    "objectID": "posts/CityBench_Evaluating_the_Capabilities_of_Large_Language_Model_as_World_Model/2024-06-20-CityBench_Evaluating_the_Capabilities_of_Large_Language_Model_as_World_Model.html#appendix",
    "href": "posts/CityBench_Evaluating_the_Capabilities_of_Large_Language_Model_as_World_Model/2024-06-20-CityBench_Evaluating_the_Capabilities_of_Large_Language_Model_as_World_Model.html#appendix",
    "title": "CityBench: Evaluating the Capabilities of Large Language Model as World Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13945v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13945v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5783"
  },
  {
    "objectID": "posts/Preference_Learning_Algorithms_Do_Not_Learn_Preference_Rankings/2024-05-29-Preference_Learning_Algorithms_Do_Not_Learn_Preference_Rankings.html#appendix",
    "href": "posts/Preference_Learning_Algorithms_Do_Not_Learn_Preference_Rankings/2024-05-29-Preference_Learning_Algorithms_Do_Not_Learn_Preference_Rankings.html#appendix",
    "title": "Preference Learning Algorithms Do Not Learn Preference Rankings",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.19534v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.19534v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10665"
  },
  {
    "objectID": "posts/Synthetic_Programming_Elicitation_and_Repair_for_Text_to_Code_in_Very_Low_Resource_Programming_Languages/2024-06-05-Synthetic_Programming_Elicitation_and_Repair_for_Text_to_Code_in_Very_Low_Resource_Programming_Languages.html#appendix",
    "href": "posts/Synthetic_Programming_Elicitation_and_Repair_for_Text_to_Code_in_Very_Low_Resource_Programming_Languages/2024-06-05-Synthetic_Programming_Elicitation_and_Repair_for_Text_to_Code_in_Very_Low_Resource_Programming_Languages.html#appendix",
    "title": "Synthetic Programming Elicitation and Repair for Text-to-Code in Very Low-Resource Programming Languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03636v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03636v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9438"
  },
  {
    "objectID": "posts/Large_Language_Models_as_Evaluators_for_Recommendation_Explanations/2024-06-06-Large_Language_Models_as_Evaluators_for_Recommendation_Explanations.html#appendix",
    "href": "posts/Large_Language_Models_as_Evaluators_for_Recommendation_Explanations/2024-06-06-Large_Language_Models_as_Evaluators_for_Recommendation_Explanations.html#appendix",
    "title": "Large Language Models as Evaluators for Recommendation Explanations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03248v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03248v2\n\n\nTruncated\nFalse\n\n\nWord Count\n7752"
  },
  {
    "objectID": "posts/Mental_Modeling_of_Reinforcement_Learning_Agents_by_Language_Models/2024-06-26-Mental_Modeling_of_Reinforcement_Learning_Agents_by_Language_Models.html#appendix",
    "href": "posts/Mental_Modeling_of_Reinforcement_Learning_Agents_by_Language_Models/2024-06-26-Mental_Modeling_of_Reinforcement_Learning_Agents_by_Language_Models.html#appendix",
    "title": "Mental Modeling of Reinforcement Learning Agents by Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18505v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18505v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9604"
  },
  {
    "objectID": "posts/Beyond_Under_Alignment_Atomic_Preference_Enhanced_Factuality_Tuning_for_Large_Language_Models/2024-06-18-Beyond_Under_Alignment_Atomic_Preference_Enhanced_Factuality_Tuning_for_Large_Language_Models.html#appendix",
    "href": "posts/Beyond_Under_Alignment_Atomic_Preference_Enhanced_Factuality_Tuning_for_Large_Language_Models/2024-06-18-Beyond_Under_Alignment_Atomic_Preference_Enhanced_Factuality_Tuning_for_Large_Language_Models.html#appendix",
    "title": "Beyond Under-Alignment: Atomic Preference Enhanced Factuality Tuning for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12416v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12416v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6437"
  },
  {
    "objectID": "posts/AutoRAG_HP_Automatic_Online_Hyper_Parameter_Tuning_for_Retrieval_Augmented_Generation/2024-06-27-AutoRAG_HP_Automatic_Online_Hyper_Parameter_Tuning_for_Retrieval_Augmented_Generation.html#appendix",
    "href": "posts/AutoRAG_HP_Automatic_Online_Hyper_Parameter_Tuning_for_Retrieval_Augmented_Generation/2024-06-27-AutoRAG_HP_Automatic_Online_Hyper_Parameter_Tuning_for_Retrieval_Augmented_Generation.html#appendix",
    "title": "AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19251v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19251v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7362"
  },
  {
    "objectID": "posts/Do_LLMs_Exhibit_Human_Like_Reasoning_Evaluating_Theory_of_Mind_in_LLMs_for_Open_Ended_Responses/2024-06-09-Do_LLMs_Exhibit_Human_Like_Reasoning_Evaluating_Theory_of_Mind_in_LLMs_for_Open_Ended_Responses.html#appendix",
    "href": "posts/Do_LLMs_Exhibit_Human_Like_Reasoning_Evaluating_Theory_of_Mind_in_LLMs_for_Open_Ended_Responses/2024-06-09-Do_LLMs_Exhibit_Human_Like_Reasoning_Evaluating_Theory_of_Mind_in_LLMs_for_Open_Ended_Responses.html#appendix",
    "title": "Do LLMs Exhibit Human-Like Reasoning? Evaluating Theory of Mind in LLMs for Open-Ended Responses",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05659v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05659v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10269"
  },
  {
    "objectID": "posts/$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning/2024-07-08-$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning.html#summary-1",
    "href": "posts/$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning/2024-07-08-$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning.html#summary-1",
    "title": "\\(R^2\\)-Guard: Robust Reasoning Enabled LLM Guardrail via Knowledge-Enhanced Logical Reasoning",
    "section": "Summary:",
    "text": "Summary:\n\nThe paper introduces -Guard, a robust reasoning enabled LLM guardrail that addresses the limitations of existing guardrail models.\n-Guard consists of two main components: a data-driven category-specific learning component and a knowledge-enhanced reasoning component.\nThe category-specific learning component computes the probability that the prompt falls into different unsafe categories, while the reasoning component makes the final prediction of the overall probability that the prompt is unsafe based on logical inference.\n-Guard employs probabilistic graphical models (PGMs) to implement the reasoning component, which allows for explicit logical inference based on given safety knowledge."
  },
  {
    "objectID": "posts/$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning/2024-07-08-$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning.html#major-findings",
    "href": "posts/$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning/2024-07-08-$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning.html#major-findings",
    "title": "\\(R^2\\)-Guard: Robust Reasoning Enabled LLM Guardrail via Knowledge-Enhanced Logical Reasoning",
    "section": "Major Findings:",
    "text": "Major Findings:\n\n-Guard addresses the limitations of existing guardrail models, such as ineffectiveness due to inadequate training on long-tail data from correlated safety categories, susceptibility to jailbreaks, and inflexibility regarding new safety categories.\n-Guard consists of two main components: a data-driven category-specific learning component and a knowledge-enhanced reasoning component.\n-Guard employs probabilistic graphical models (PGMs) to implement the reasoning component, which allows for explicit logical inference based on given safety knowledge."
  },
  {
    "objectID": "posts/$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning/2024-07-08-$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning.html#analysis-and-critique",
    "href": "posts/$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning/2024-07-08-$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning.html#analysis-and-critique",
    "title": "\\(R^2\\)-Guard: Robust Reasoning Enabled LLM Guardrail via Knowledge-Enhanced Logical Reasoning",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nOne limitation of -Guard is its requirement for explicit specification of safety knowledge rules in PGMs, which necessitates human effort to annotate detailed safety categories and their interconnections.\nHowever, this explicit knowledge also enhances -Guard’s effectiveness and robustness compared to purely data-driven guardrail models.\n-Guard has a broader impact in three key areas: motivating the guardrail community to transition from purely data-driven approaches to those enabled by logical reasoning, providing the symbolic reasoning community with a robust framework for encoding knowledge, performing logical inference, and knowledge weight learning with weak supervision, and safeguarding widespread LLM deployments in various systems.\nThe paper does not see any negative impact of their guardrail model."
  },
  {
    "objectID": "posts/$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning/2024-07-08-$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning.html#appendix",
    "href": "posts/$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning/2024-07-08-$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning.html#appendix",
    "title": "\\(R^2\\)-Guard: Robust Reasoning Enabled LLM Guardrail via Knowledge-Enhanced Logical Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05557v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05557v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7884"
  },
  {
    "objectID": "posts/Capturing_Minds_Not_Just_Words_Enhancing_Role_Playing_Language_Models_with_Personality_Indicative_Data/2024-06-27-Capturing_Minds_Not_Just_Words_Enhancing_Role_Playing_Language_Models_with_Personality_Indicative_Data.html#appendix",
    "href": "posts/Capturing_Minds_Not_Just_Words_Enhancing_Role_Playing_Language_Models_with_Personality_Indicative_Data/2024-06-27-Capturing_Minds_Not_Just_Words_Enhancing_Role_Playing_Language_Models_with_Personality_Indicative_Data.html#appendix",
    "title": "Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18921v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18921v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5403"
  },
  {
    "objectID": "posts/Confabulation_The_Surprising_Value_of_Large_Language_Model_Hallucinations/2024-06-06-Confabulation_The_Surprising_Value_of_Large_Language_Model_Hallucinations.html#appendix",
    "href": "posts/Confabulation_The_Surprising_Value_of_Large_Language_Model_Hallucinations/2024-06-06-Confabulation_The_Surprising_Value_of_Large_Language_Model_Hallucinations.html#appendix",
    "title": "Confabulation: The Surprising Value of Large Language Model Hallucinations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04175v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04175v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5509"
  },
  {
    "objectID": "posts/Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110/2024-06-10-Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110.html",
    "href": "posts/Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110/2024-06-10-Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110.html",
    "title": "Harnessing AI for efficient analysis of complex policy documents: a case study of Executive Order 14110",
    "section": "",
    "text": "Summary:\nThis study investigates the accuracy and reliability of large language model (LLM)-based AI systems in extracting information from complex policy documents, such as Executive Order 14110. The research focuses on question answering and tasks involving content extraction, comparing the performance of four commercial AI systems (Claude 3 Opus, ChatGPT-4, Gemini Pro 1.5, and Command R+) to manual analysis conducted by human experts. The results show that Gemini and Claude demonstrated the most comprehensive understanding of the EO, consistently providing concise, accurate, and detailed responses. However, achieving acceptable levels of reproducibility and trustworthiness remains a critical challenge that necessitates further research and development.\nMajor Findings:\nAnalysis and Critique:\nThe study provides valuable insights into the potential of AI in policy analysis, but there are several limitations to consider:\nFurther research could involve testing other AI models, including open-source alternatives, mixture-of-"
  },
  {
    "objectID": "posts/Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110/2024-06-10-Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110.html#appendix",
    "href": "posts/Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110/2024-06-10-Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110.html#appendix",
    "title": "Harnessing AI for efficient analysis of complex policy documents: a case study of Executive Order 14110",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06657v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06657v1\n\n\nTruncated\nFalse\n\n\nWord Count\n25409"
  },
  {
    "objectID": "posts/CaLMQA_Exploring_culturally_specific_long_form_question_answering_across_23_languages/2024-06-25-CaLMQA_Exploring_culturally_specific_long_form_question_answering_across_23_languages.html#appendix",
    "href": "posts/CaLMQA_Exploring_culturally_specific_long_form_question_answering_across_23_languages/2024-06-25-CaLMQA_Exploring_culturally_specific_long_form_question_answering_across_23_languages.html#appendix",
    "title": "CaLMQA: Exploring culturally specific long-form question answering across 23 languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17761v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17761v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11413"
  },
  {
    "objectID": "posts/Self_Cognition_in_Large_Language_Models_An_Exploratory_Study/2024-07-01-Self_Cognition_in_Large_Language_Models_An_Exploratory_Study.html#appendix",
    "href": "posts/Self_Cognition_in_Large_Language_Models_An_Exploratory_Study/2024-07-01-Self_Cognition_in_Large_Language_Models_An_Exploratory_Study.html#appendix",
    "title": "Self-Cognition in Large Language Models: An Exploratory Study",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01505v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01505v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6005"
  },
  {
    "objectID": "posts/From_Artificial_Needles_to_Real_Haystacks_Improving_Retrieval_Capabilities_in_LLMs_by_Finetuning_on_Synthetic_Data/2024-06-27-From_Artificial_Needles_to_Real_Haystacks_Improving_Retrieval_Capabilities_in_LLMs_by_Finetuning_on_Synthetic_Data.html",
    "href": "posts/From_Artificial_Needles_to_Real_Haystacks_Improving_Retrieval_Capabilities_in_LLMs_by_Finetuning_on_Synthetic_Data/2024-06-27-From_Artificial_Needles_to_Real_Haystacks_Improving_Retrieval_Capabilities_in_LLMs_by_Finetuning_on_Synthetic_Data.html",
    "title": "From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data",
    "section": "",
    "text": "Summary:\nThe paper “From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data” by Zheyang Xiong, Vasilis Papageorgiou, Kangwook Lee, and Dimitris Papailiopoulos from the University of Wisconsin-Madison proposes a finetuning approach to address the limitations of Large Language Models (LLMs) in accurately retrieving information and maintaining reasoning capabilities when processing long-context inputs. The authors propose a finetuning approach utilizing a carefully designed synthetic dataset comprising numerical key-value retrieval tasks. The experiments conducted on models like GPT-3.5 Turbo and Mistral 7B demonstrate that finetuning LLMs on this dataset significantly improves LLMs’ information retrieval and reasoning capabilities in longer-context settings. The study highlights the potential of finetuning on synthetic data for improving the performance of LLMs on longer-context tasks.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an innovative approach to improving the performance of LLMs on longer-context tasks by finetuning on synthetic data. The authors provide a well-structured and coherent summary of their findings, highlighting the potential of their proposed method. However, the paper does not discuss the limitations of the proposed approach or potential biases that may have been introduced during the finetuning process. Additionally, the paper does not provide a comparison with other finetuning methods or discuss the generalizability of the proposed approach to other LLMs. Further research is needed to address these limitations and validate the proposed approach"
  },
  {
    "objectID": "posts/From_Artificial_Needles_to_Real_Haystacks_Improving_Retrieval_Capabilities_in_LLMs_by_Finetuning_on_Synthetic_Data/2024-06-27-From_Artificial_Needles_to_Real_Haystacks_Improving_Retrieval_Capabilities_in_LLMs_by_Finetuning_on_Synthetic_Data.html#appendix",
    "href": "posts/From_Artificial_Needles_to_Real_Haystacks_Improving_Retrieval_Capabilities_in_LLMs_by_Finetuning_on_Synthetic_Data/2024-06-27-From_Artificial_Needles_to_Real_Haystacks_Improving_Retrieval_Capabilities_in_LLMs_by_Finetuning_on_Synthetic_Data.html#appendix",
    "title": "From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19292v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19292v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11448"
  },
  {
    "objectID": "posts/Embodied_AI_in_Mobile_Robots_Coverage_Path_Planning_with_Large_Language_Models/2024-07-02-Embodied_AI_in_Mobile_Robots_Coverage_Path_Planning_with_Large_Language_Models.html#appendix",
    "href": "posts/Embodied_AI_in_Mobile_Robots_Coverage_Path_Planning_with_Large_Language_Models/2024-07-02-Embodied_AI_in_Mobile_Robots_Coverage_Path_Planning_with_Large_Language_Models.html#appendix",
    "title": "Embodied AI in Mobile Robots: Coverage Path Planning with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02220v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02220v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4205"
  },
  {
    "objectID": "posts/Can_LLMs_Reason_in_the_Wild_with_Programs/2024-06-19-Can_LLMs_Reason_in_the_Wild_with_Programs.html#appendix",
    "href": "posts/Can_LLMs_Reason_in_the_Wild_with_Programs/2024-06-19-Can_LLMs_Reason_in_the_Wild_with_Programs.html#appendix",
    "title": "Can LLMs Reason in the Wild with Programs?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13764v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13764v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13142"
  },
  {
    "objectID": "posts/WildTeaming_at_Scale_From_In_the_Wild_Jailbreaks_to_(Adversarially)_Safer_Language_Models/2024-06-26-WildTeaming_at_Scale_From_In_the_Wild_Jailbreaks_to_(Adversarially)_Safer_Language_Models.html#appendix",
    "href": "posts/WildTeaming_at_Scale_From_In_the_Wild_Jailbreaks_to_(Adversarially)_Safer_Language_Models/2024-06-26-WildTeaming_at_Scale_From_In_the_Wild_Jailbreaks_to_(Adversarially)_Safer_Language_Models.html#appendix",
    "title": "WildTeaming at Scale: From In-the-Wild Jailbreaks to (Adversarially) Safer Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18510v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18510v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9370"
  },
  {
    "objectID": "posts/Breaking_the_Ceiling_of_the_LLM_Community_by_Treating_Token_Generation_as_a_Classification_for_Ensembling/2024-06-18-Breaking_the_Ceiling_of_the_LLM_Community_by_Treating_Token_Generation_as_a_Classification_for_Ensembling.html#appendix",
    "href": "posts/Breaking_the_Ceiling_of_the_LLM_Community_by_Treating_Token_Generation_as_a_Classification_for_Ensembling/2024-06-18-Breaking_the_Ceiling_of_the_LLM_Community_by_Treating_Token_Generation_as_a_Classification_for_Ensembling.html#appendix",
    "title": "Breaking the Ceiling of the LLM Community by Treating Token Generation as a Classification for Ensembling",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12585v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12585v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5835"
  },
  {
    "objectID": "posts/Through_the_Theory_of_Minds_Eye_Reading_Minds_with_Multimodal_Video_Large_Language_Models/2024-06-19-Through_the_Theory_of_Minds_Eye_Reading_Minds_with_Multimodal_Video_Large_Language_Models.html#appendix",
    "href": "posts/Through_the_Theory_of_Minds_Eye_Reading_Minds_with_Multimodal_Video_Large_Language_Models/2024-06-19-Through_the_Theory_of_Minds_Eye_Reading_Minds_with_Multimodal_Video_Large_Language_Models.html#appendix",
    "title": "Through the Theory of Mind’s Eye: Reading Minds with Multimodal Video Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13763v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13763v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4909"
  },
  {
    "objectID": "posts/PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation/2024-06-26-PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation.html#major-findings",
    "href": "posts/PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation/2024-06-26-PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation.html#major-findings",
    "title": "PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nStable Prompts: The study discovers that in some scenarios, prompts are stable, with some LLMs showing idiosyncratic preferences for grading generated texts with textual labels, while others prefer to return numeric scores.\nSusceptibility to Changes: However, the stability of prompts and model rankings can be susceptible to seemingly innocuous changes. For instance, changing the requested output format from “0 to 100” to “-1 to +1” can strongly affect the rankings in the evaluation.\nUnderstanding Prompting Approaches: The study contributes to understanding the impact of different prompting approaches on LLM-based metrics for machine translation and summarization evaluation, highlighting the most stable prompting patterns and potential limitations."
  },
  {
    "objectID": "posts/PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation/2024-06-26-PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation.html#analysis-and-critique",
    "href": "posts/PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation/2024-06-26-PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation.html#analysis-and-critique",
    "title": "PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper provides a comprehensive exploration of prompting strategies for LLM-based metrics, offering valuable insights into the stability and variability of these strategies. However, the study’s scope is limited to open-source LLMs, and the findings may not generalize to closed-source models. Additionally, the study does not explore the impact of different prompting strategies on other NLP tasks beyond machine translation and summarization.\nFurthermore, the study’s reliance on a single dataset for evaluation may limit the generalizability of the findings. Future research could benefit from evaluating the proposed prompting strategies on a more diverse range of datasets and tasks.\nLastly, the study does not discuss the potential ethical implications of using LLMs for evaluation, such as the risk of bias or the need for transparency in the evaluation process. Addressing these issues could enhance the credibility and applicability of the proposed prompting strategies."
  },
  {
    "objectID": "posts/PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation/2024-06-26-PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation.html#appendix",
    "href": "posts/PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation/2024-06-26-PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation.html#appendix",
    "title": "PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18528v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18528v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9672"
  },
  {
    "objectID": "posts/Leveraging_Large_Language_Models_for_Patient_Engagement_The_Power_of_Conversational_AI_in_Digital_Health/2024-06-19-Leveraging_Large_Language_Models_for_Patient_Engagement_The_Power_of_Conversational_AI_in_Digital_Health.html#appendix",
    "href": "posts/Leveraging_Large_Language_Models_for_Patient_Engagement_The_Power_of_Conversational_AI_in_Digital_Health/2024-06-19-Leveraging_Large_Language_Models_for_Patient_Engagement_The_Power_of_Conversational_AI_in_Digital_Health.html#appendix",
    "title": "Leveraging Large Language Models for Patient Engagement: The Power of Conversational AI in Digital Health",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13659v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13659v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7506"
  },
  {
    "objectID": "posts/Finding_Blind_Spots_in_Evaluator_LLMs_with_Interpretable_Checklists/2024-06-19-Finding_Blind_Spots_in_Evaluator_LLMs_with_Interpretable_Checklists.html#appendix",
    "href": "posts/Finding_Blind_Spots_in_Evaluator_LLMs_with_Interpretable_Checklists/2024-06-19-Finding_Blind_Spots_in_Evaluator_LLMs_with_Interpretable_Checklists.html#appendix",
    "title": "Finding Blind Spots in Evaluator LLMs with Interpretable Checklists",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13439v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13439v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7140"
  },
  {
    "objectID": "posts/OMG_LLaVA_Bridging_Image_level_Object_level_Pixel_level_Reasoning_and_Understanding/2024-06-27-OMG_LLaVA_Bridging_Image_level_Object_level_Pixel_level_Reasoning_and_Understanding.html#appendix",
    "href": "posts/OMG_LLaVA_Bridging_Image_level_Object_level_Pixel_level_Reasoning_and_Understanding/2024-06-27-OMG_LLaVA_Bridging_Image_level_Object_level_Pixel_level_Reasoning_and_Understanding.html#appendix",
    "title": "OMG-LLaVA: Bridging Image-level, Object-level, Pixel-level Reasoning and Understanding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19389v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19389v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9015"
  },
  {
    "objectID": "posts/MALSIGHT_Exploring_Malicious_Source_Code_and_Benign_Pseudocode_for_Iterative_Binary_Malware_Summarization/2024-06-26-MALSIGHT_Exploring_Malicious_Source_Code_and_Benign_Pseudocode_for_Iterative_Binary_Malware_Summarization.html#appendix",
    "href": "posts/MALSIGHT_Exploring_Malicious_Source_Code_and_Benign_Pseudocode_for_Iterative_Binary_Malware_Summarization/2024-06-26-MALSIGHT_Exploring_Malicious_Source_Code_and_Benign_Pseudocode_for_Iterative_Binary_Malware_Summarization.html#appendix",
    "title": "MALSIGHT: Exploring Malicious Source Code and Benign Pseudocode for Iterative Binary Malware Summarization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18379v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18379v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12933"
  },
  {
    "objectID": "posts/LANE_Logic_Alignment_of_Non_tuning_Large_Language_Models_and_Online_Recommendation_Systems_for_Explainable_Reason_Generation/2024-07-03-LANE_Logic_Alignment_of_Non_tuning_Large_Language_Models_and_Online_Recommendation_Systems_for_Explainable_Reason_Generation.html#appendix",
    "href": "posts/LANE_Logic_Alignment_of_Non_tuning_Large_Language_Models_and_Online_Recommendation_Systems_for_Explainable_Reason_Generation/2024-07-03-LANE_Logic_Alignment_of_Non_tuning_Large_Language_Models_and_Online_Recommendation_Systems_for_Explainable_Reason_Generation.html#appendix",
    "title": "LANE: Logic Alignment of Non-tuning Large Language Models and Online Recommendation Systems for Explainable Reason Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02833v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02833v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9264"
  },
  {
    "objectID": "posts/PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine_tuning/2024-07-02-PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine_tuning.html",
    "href": "posts/PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine_tuning/2024-07-02-PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine_tuning.html",
    "title": "PromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt during Large Language Model Fine-tuning",
    "section": "",
    "text": "Summary:\nThe paper introduces a novel method called PromptIntern for internalizing prompt knowledge into the parameters of large language models (LLMs) during fine-tuning. The approach aims to reduce inference costs by emulating the human learning process, where detailed templates and examples are gradually internalized and phased out as the model becomes accustomed to the task. PromptIntern consists of several key steps, including classifying input prompts into three components (template, examples, and query), setting a schedule to decrease both the template compression rate and the number of few-shot examples across training stages, and implementing template compression and example absorption to pre-process the input prompts.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine_tuning/2024-07-02-PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine_tuning.html#appendix",
    "href": "posts/PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine_tuning/2024-07-02-PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine_tuning.html#appendix",
    "title": "PromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt during Large Language Model Fine-tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02211v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02211v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7224"
  },
  {
    "objectID": "posts/Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text/2024-06-10-Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text.html",
    "href": "posts/Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text/2024-06-10-Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text.html",
    "title": "Synth-SBDH: A Synthetic Dataset of Social and Behavioral Determinants of Health for Clinical Text",
    "section": "",
    "text": "Summary:\nThe study introduces Synth-SBDH, a novel synthetic dataset with detailed SBDH annotations, encompassing status, temporal information, and rationale across 15 SBDH categories. The dataset is the largest publicly available SBDH dataset and is generated and annotated by an LLM (GPT-4). The utility of Synth-SBDH is showcased on three tasks using real-world clinical datasets from two distinct hospital settings, highlighting its versatility, generalizability, and distillation capabilities. Models trained on Synth-SBDH consistently outperform counterparts with no Synth-SBDH training, achieving up to 62.5% macro-F improvements. Synth-SBDH proves effective for rare SBDH categories and under-resource constraints. Human evaluation demonstrates a Human-LLM alignment of 71.06% and uncovers areas for future refinements.\nMajor Findings:\nAnalysis and Critique:\nThe study presents a novel synthetic dataset, Synth-SBDH, which addresses the limitations of existing SBDH datasets and leverages the potential of LLMs in healthcare. The dataset is comprehensive, covering a wide range of SBDH categories and providing detailed"
  },
  {
    "objectID": "posts/Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text/2024-06-10-Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text.html#appendix",
    "href": "posts/Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text/2024-06-10-Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text.html#appendix",
    "title": "Synth-SBDH: A Synthetic Dataset of Social and Behavioral Determinants of Health for Clinical Text",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06056v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06056v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20269"
  },
  {
    "objectID": "posts/When_is_the_consistent_prediction_likely_to_be_a_correct_prediction/2024-07-08-When_is_the_consistent_prediction_likely_to_be_a_correct_prediction.html#appendix",
    "href": "posts/When_is_the_consistent_prediction_likely_to_be_a_correct_prediction/2024-07-08-When_is_the_consistent_prediction_likely_to_be_a_correct_prediction.html#appendix",
    "title": "When is the consistent prediction likely to be a correct prediction?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05778v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05778v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4435"
  },
  {
    "objectID": "posts/Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model/2024-07-03-Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model.html#major-findings",
    "href": "posts/Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model/2024-07-03-Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model.html#major-findings",
    "title": "Raw Text is All you Need: Knowledge-intensive Multi-turn Instruction Tuning for Large Language Model",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe proposed R2S framework allows LLMs to generate dialogues that are coherent, contextually relevant, and embed rich, domain-specific knowledge into conversations.\nThe creation of a comprehensive knowledge-intensive benchmark, k-Bench, facilitates the training and evaluation of the proposed methods, covering a diverse range of topics and serving as a vital resource for assessing the effectiveness of CoD and the overall framework.\nThe synthetic instruction dataset gInstruct retains an extensive amount of knowledge from the raw documents in a dialogue format, which is used to fine-tune an open-source LLM, referred to as gLLM. The experimental results demonstrate that this synthetic instruction approach is highly effective in enhancing the SFT model, enabling it to excel across various performance metrics."
  },
  {
    "objectID": "posts/Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model/2024-07-03-Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model.html#analysis-and-critique",
    "href": "posts/Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model/2024-07-03-Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model.html#analysis-and-critique",
    "title": "Raw Text is All you Need: Knowledge-intensive Multi-turn Instruction Tuning for Large Language Model",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper does not discuss the potential limitations of the proposed framework, such as the computational resources required for generating and fine-tuning the gLLM model.\nThe paper does not address the potential biases that may be introduced during the data collection and processing stages, which could impact the performance of the gLLM model.\nThe paper does not provide a comprehensive comparison with other existing methods for generating multi-turn dialogues for instruction tuning, which could help to better understand the advantages and disadvantages of the proposed approach.\nThe paper does not discuss the potential applications and use cases of"
  },
  {
    "objectID": "posts/Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model/2024-07-03-Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model.html#appendix",
    "href": "posts/Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model/2024-07-03-Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model.html#appendix",
    "title": "Raw Text is All you Need: Knowledge-intensive Multi-turn Instruction Tuning for Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03040v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03040v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5924"
  },
  {
    "objectID": "posts/AutoPureData_Automated_Filtering_of_Web_Data_for_LLM_Fine_tuning/2024-06-27-AutoPureData_Automated_Filtering_of_Web_Data_for_LLM_Fine_tuning.html#appendix",
    "href": "posts/AutoPureData_Automated_Filtering_of_Web_Data_for_LLM_Fine_tuning/2024-06-27-AutoPureData_Automated_Filtering_of_Web_Data_for_LLM_Fine_tuning.html#appendix",
    "title": "AutoPureData: Automated Filtering of Web Data for LLM Fine-tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19271v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19271v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2024"
  },
  {
    "objectID": "posts/Adversarial_Attacks_on_Large_Language_Models_in_Medicine/2024-06-18-Adversarial_Attacks_on_Large_Language_Models_in_Medicine.html#appendix",
    "href": "posts/Adversarial_Attacks_on_Large_Language_Models_in_Medicine/2024-06-18-Adversarial_Attacks_on_Large_Language_Models_in_Medicine.html#appendix",
    "title": "Adversarial Attacks on Large Language Models in Medicine",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12259v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12259v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9477"
  },
  {
    "objectID": "posts/Poisoned_LangChain_Jailbreak_LLMs_by_LangChain/2024-06-26-Poisoned_LangChain_Jailbreak_LLMs_by_LangChain.html#appendix",
    "href": "posts/Poisoned_LangChain_Jailbreak_LLMs_by_LangChain/2024-06-26-Poisoned_LangChain_Jailbreak_LLMs_by_LangChain.html#appendix",
    "title": "Poisoned LangChain: Jailbreak LLMs by LangChain",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18122v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18122v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4003"
  },
  {
    "objectID": "posts/Directed_Domain_Fine_Tuning_Tailoring_Separate_Modalities_for_Specific_Training_Tasks/2024-06-24-Directed_Domain_Fine_Tuning_Tailoring_Separate_Modalities_for_Specific_Training_Tasks.html#appendix",
    "href": "posts/Directed_Domain_Fine_Tuning_Tailoring_Separate_Modalities_for_Specific_Training_Tasks/2024-06-24-Directed_Domain_Fine_Tuning_Tailoring_Separate_Modalities_for_Specific_Training_Tasks.html#appendix",
    "title": "Directed Domain Fine-Tuning: Tailoring Separate Modalities for Specific Training Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16346v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16346v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6463"
  },
  {
    "objectID": "posts/DICE_Detecting_In_distribution_Contamination_in_LLMs_Fine_tuning_Phase_for_Math_Reasoning/2024-06-06-DICE_Detecting_In_distribution_Contamination_in_LLMs_Fine_tuning_Phase_for_Math_Reasoning.html#appendix",
    "href": "posts/DICE_Detecting_In_distribution_Contamination_in_LLMs_Fine_tuning_Phase_for_Math_Reasoning/2024-06-06-DICE_Detecting_In_distribution_Contamination_in_LLMs_Fine_tuning_Phase_for_Math_Reasoning.html#appendix",
    "title": "DICE: Detecting In-distribution Contamination in LLM’s Fine-tuning Phase for Math Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04197v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04197v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6104"
  },
  {
    "objectID": "posts/Affordances_Oriented_Planning_using_Foundation_Models_for_Continuous_Vision_Language_Navigation/2024-07-08-Affordances_Oriented_Planning_using_Foundation_Models_for_Continuous_Vision_Language_Navigation.html#appendix",
    "href": "posts/Affordances_Oriented_Planning_using_Foundation_Models_for_Continuous_Vision_Language_Navigation/2024-07-08-Affordances_Oriented_Planning_using_Foundation_Models_for_Continuous_Vision_Language_Navigation.html#appendix",
    "title": "Affordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05890v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05890v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7091"
  },
  {
    "objectID": "posts/MathOdyssey_Benchmarking_Mathematical_Problem_Solving_Skills_in_Large_Language_Models_Using_Odyssey_Math_Data/2024-06-26-MathOdyssey_Benchmarking_Mathematical_Problem_Solving_Skills_in_Large_Language_Models_Using_Odyssey_Math_Data.html#appendix",
    "href": "posts/MathOdyssey_Benchmarking_Mathematical_Problem_Solving_Skills_in_Large_Language_Models_Using_Odyssey_Math_Data/2024-06-26-MathOdyssey_Benchmarking_Mathematical_Problem_Solving_Skills_in_Large_Language_Models_Using_Odyssey_Math_Data.html#appendix",
    "title": "MathOdyssey: Benchmarking Mathematical Problem-Solving Skills in Large Language Models Using Odyssey Math Data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18321v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18321v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5533"
  },
  {
    "objectID": "posts/CogErgLLM_Exploring_Large_Language_Model_Systems_Design_Perspective_Using_Cognitive_Ergonomics/2024-07-03-CogErgLLM_Exploring_Large_Language_Model_Systems_Design_Perspective_Using_Cognitive_Ergonomics.html#appendix",
    "href": "posts/CogErgLLM_Exploring_Large_Language_Model_Systems_Design_Perspective_Using_Cognitive_Ergonomics/2024-07-03-CogErgLLM_Exploring_Large_Language_Model_Systems_Design_Perspective_Using_Cognitive_Ergonomics.html#appendix",
    "title": "CogErgLLM: Exploring Large Language Model Systems Design Perspective Using Cognitive Ergonomics",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02885v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02885v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5038"
  },
  {
    "objectID": "posts/Persuasiveness_of_Generated_Free_Text_Rationales_in_Subjective_Decisions_A_Case_Study_on_Pairwise_Argument_Ranking/2024-06-20-Persuasiveness_of_Generated_Free_Text_Rationales_in_Subjective_Decisions_A_Case_Study_on_Pairwise_Argument_Ranking.html#appendix",
    "href": "posts/Persuasiveness_of_Generated_Free_Text_Rationales_in_Subjective_Decisions_A_Case_Study_on_Pairwise_Argument_Ranking/2024-06-20-Persuasiveness_of_Generated_Free_Text_Rationales_in_Subjective_Decisions_A_Case_Study_on_Pairwise_Argument_Ranking.html#appendix",
    "title": "Persuasiveness of Generated Free-Text Rationales in Subjective Decisions: A Case Study on Pairwise Argument Ranking",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13905v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13905v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6514"
  },
  {
    "objectID": "posts/How_to_Understand_Whole_Software_Repository/2024-06-03-How_to_Understand_Whole_Software_Repository.html#appendix",
    "href": "posts/How_to_Understand_Whole_Software_Repository/2024-06-03-How_to_Understand_Whole_Software_Repository.html#appendix",
    "title": "How to Understand Whole Software Repository?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01422v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01422v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10556"
  },
  {
    "objectID": "posts/Retrieval_Augmented_Code_Generation_for_Situated_Action_Generation_A_Case_Study_on_Minecraft/2024-06-25-Retrieval_Augmented_Code_Generation_for_Situated_Action_Generation_A_Case_Study_on_Minecraft.html#appendix",
    "href": "posts/Retrieval_Augmented_Code_Generation_for_Situated_Action_Generation_A_Case_Study_on_Minecraft/2024-06-25-Retrieval_Augmented_Code_Generation_for_Situated_Action_Generation_A_Case_Study_on_Minecraft.html#appendix",
    "title": "Retrieval-Augmented Code Generation for Situated Action Generation: A Case Study on Minecraft",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17553v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17553v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4809"
  },
  {
    "objectID": "posts/Quantifying_AI_Psychology_A_Psychometrics_Benchmark_for_Large_Language_Models/2024-06-25-Quantifying_AI_Psychology_A_Psychometrics_Benchmark_for_Large_Language_Models.html#appendix",
    "href": "posts/Quantifying_AI_Psychology_A_Psychometrics_Benchmark_for_Large_Language_Models/2024-06-25-Quantifying_AI_Psychology_A_Psychometrics_Benchmark_for_Large_Language_Models.html#appendix",
    "title": "Quantifying AI Psychology: A Psychometrics Benchmark for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17675v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17675v1\n\n\nTruncated\nFalse\n\n\nWord Count\n22287"
  },
  {
    "objectID": "posts/Anomaly_Detection_on_Unstable_Logs_with_GPT_Models/2024-06-11-Anomaly_Detection_on_Unstable_Logs_with_GPT_Models.html#appendix",
    "href": "posts/Anomaly_Detection_on_Unstable_Logs_with_GPT_Models/2024-06-11-Anomaly_Detection_on_Unstable_Logs_with_GPT_Models.html#appendix",
    "title": "Anomaly Detection on Unstable Logs with GPT Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07467v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07467v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11408"
  },
  {
    "objectID": "posts/Is_Your_AI_Generated_Code_Really_Secure_Evaluating_Large_Language_Models_on_Secure_Code_Generation_with_CodeSecEval/2024-07-02-Is_Your_AI_Generated_Code_Really_Secure_Evaluating_Large_Language_Models_on_Secure_Code_Generation_with_CodeSecEval.html#appendix",
    "href": "posts/Is_Your_AI_Generated_Code_Really_Secure_Evaluating_Large_Language_Models_on_Secure_Code_Generation_with_CodeSecEval/2024-07-02-Is_Your_AI_Generated_Code_Really_Secure_Evaluating_Large_Language_Models_on_Secure_Code_Generation_with_CodeSecEval.html#appendix",
    "title": "Is Your AI-Generated Code Really Secure? Evaluating Large Language Models on Secure Code Generation with CodeSecEval",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02395v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02395v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9474"
  },
  {
    "objectID": "posts/Hierarchical_Context_Pruning_Optimizing_Real_World_Code_Completion_with_Repository_Level_Pretrained_Code_LLMs/2024-06-26-Hierarchical_Context_Pruning_Optimizing_Real_World_Code_Completion_with_Repository_Level_Pretrained_Code_LLMs.html#appendix",
    "href": "posts/Hierarchical_Context_Pruning_Optimizing_Real_World_Code_Completion_with_Repository_Level_Pretrained_Code_LLMs/2024-06-26-Hierarchical_Context_Pruning_Optimizing_Real_World_Code_Completion_with_Repository_Level_Pretrained_Code_LLMs.html#appendix",
    "title": "Hierarchical Context Pruning: Optimizing Real-World Code Completion with Repository-Level Pretrained Code LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18294v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18294v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6374"
  },
  {
    "objectID": "posts/LLaSA_Large_Multimodal_Agent_for_Human_Activity_Analysis_Through_Wearable_Sensors/2024-06-20-LLaSA_Large_Multimodal_Agent_for_Human_Activity_Analysis_Through_Wearable_Sensors.html#appendix",
    "href": "posts/LLaSA_Large_Multimodal_Agent_for_Human_Activity_Analysis_Through_Wearable_Sensors/2024-06-20-LLaSA_Large_Multimodal_Agent_for_Human_Activity_Analysis_Through_Wearable_Sensors.html#appendix",
    "title": "LLaSA: Large Multimodal Agent for Human Activity Analysis Through Wearable Sensors",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14498v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14498v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3974"
  },
  {
    "objectID": "posts/Applying_LLMs_for_Rescoring_N_best_ASR_Hypotheses_of_Casual_Conversations_Effects_of_Domain_Adaptation_and_Context_Carry_over/2024-06-27-Applying_LLMs_for_Rescoring_N_best_ASR_Hypotheses_of_Casual_Conversations_Effects_of_Domain_Adaptation_and_Context_Carry_over.html#appendix",
    "href": "posts/Applying_LLMs_for_Rescoring_N_best_ASR_Hypotheses_of_Casual_Conversations_Effects_of_Domain_Adaptation_and_Context_Carry_over/2024-06-27-Applying_LLMs_for_Rescoring_N_best_ASR_Hypotheses_of_Casual_Conversations_Effects_of_Domain_Adaptation_and_Context_Carry_over.html#appendix",
    "title": "Applying LLMs for Rescoring N-best ASR Hypotheses of Casual Conversations: Effects of Domain Adaptation and Context Carry-over",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18972v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18972v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5457"
  },
  {
    "objectID": "posts/Catching_Chameleons_Detecting_Evolving_Disinformation_Generated_using_Large_Language_Models/2024-06-26-Catching_Chameleons_Detecting_Evolving_Disinformation_Generated_using_Large_Language_Models.html#appendix",
    "href": "posts/Catching_Chameleons_Detecting_Evolving_Disinformation_Generated_using_Large_Language_Models/2024-06-26-Catching_Chameleons_Detecting_Evolving_Disinformation_Generated_using_Large_Language_Models.html#appendix",
    "title": "Catching Chameleons: Detecting Evolving Disinformation Generated using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17992v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17992v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7315"
  },
  {
    "objectID": "posts/RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold/2024-06-20-RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold.html",
    "href": "posts/RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold/2024-06-20-RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold.html",
    "title": "RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold",
    "section": "",
    "text": "Summary:\nThe paper investigates the use of synthetic data for improving math reasoning capabilities of large language models (LLMs). The authors find that while the typical approach of collecting new questions and corresponding positive (correct) solutions from capable models like GPT-4/Gemini-1.5 presents underwhelming data scaling, the sample efficiency of the same data can be improved up to 2× by sampling more positive traces from the 7B sized models SFT-ed on the original data. However, training on positive self-generated synthetic data alone often amplifies the model’s dependence on spurious steps, that erroneously appear to lead to a good solution but do not generalize to novel problems and hurt test performance.\nThe authors show that negative (incorrect) traces sampled from the same SFT model can be used to address the failure modes of training on only positive data. In particular, negative data can be used to estimate advantage values for every step, and using these advantage estimates via RL enables us to address this problem. The authors show how the advantages can be used implicitly by preference optimization objectives. They show how training on an instance of this objective leads to 8× improvements in sample efficiency of the synthetic data used.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold/2024-06-20-RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold.html#appendix",
    "href": "posts/RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold/2024-06-20-RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold.html#appendix",
    "title": "RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14532v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14532v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15465"
  },
  {
    "objectID": "posts/Investigating_Mysteries_of_CoT_Augmented_Distillation/2024-06-20-Investigating_Mysteries_of_CoT_Augmented_Distillation.html#appendix",
    "href": "posts/Investigating_Mysteries_of_CoT_Augmented_Distillation/2024-06-20-Investigating_Mysteries_of_CoT_Augmented_Distillation.html#appendix",
    "title": "Investigating Mysteries of CoT-Augmented Distillation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14511v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14511v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8455"
  },
  {
    "objectID": "posts/Psychological_Profiling_in_Cybersecurity_A_Look_at_LLMs_and_Psycholinguistic_Features/2024-06-26-Psychological_Profiling_in_Cybersecurity_A_Look_at_LLMs_and_Psycholinguistic_Features.html#appendix",
    "href": "posts/Psychological_Profiling_in_Cybersecurity_A_Look_at_LLMs_and_Psycholinguistic_Features/2024-06-26-Psychological_Profiling_in_Cybersecurity_A_Look_at_LLMs_and_Psycholinguistic_Features.html#appendix",
    "title": "Psychological Profiling in Cybersecurity: A Look at LLMs and Psycholinguistic Features",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18783v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18783v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6749"
  },
  {
    "objectID": "posts/PAS_Data_Efficient_Plug_and_Play_Prompt_Augmentation_System/2024-07-08-PAS_Data_Efficient_Plug_and_Play_Prompt_Augmentation_System.html#appendix",
    "href": "posts/PAS_Data_Efficient_Plug_and_Play_Prompt_Augmentation_System/2024-07-08-PAS_Data_Efficient_Plug_and_Play_Prompt_Augmentation_System.html#appendix",
    "title": "PAS: Data-Efficient Plug-and-Play Prompt Augmentation System",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06027v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06027v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8562"
  },
  {
    "objectID": "posts/From_Descriptive_Richness_to_Bias_Unveiling_the_Dark_Side_of_Generative_Image_Caption_Enrichment/2024-06-20-From_Descriptive_Richness_to_Bias_Unveiling_the_Dark_Side_of_Generative_Image_Caption_Enrichment.html#appendix",
    "href": "posts/From_Descriptive_Richness_to_Bias_Unveiling_the_Dark_Side_of_Generative_Image_Caption_Enrichment/2024-06-20-From_Descriptive_Richness_to_Bias_Unveiling_the_Dark_Side_of_Generative_Image_Caption_Enrichment.html#appendix",
    "title": "From Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13912v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13912v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3715"
  },
  {
    "objectID": "posts/Data_Centric_AI_in_the_Age_of_Large_Language_Models/2024-06-20-Data_Centric_AI_in_the_Age_of_Large_Language_Models.html#major-findings",
    "href": "posts/Data_Centric_AI_in_the_Age_of_Large_Language_Models/2024-06-20-Data_Centric_AI_in_the_Age_of_Large_Language_Models.html#major-findings",
    "title": "Data-Centric AI in the Age of Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nData-Centric Benchmarks and Data Curation: The authors advocate for a suite of data-centric benchmarks tailored to the scale and complexity of data for LLMs. These benchmarks can be used to develop new data curation methods and document research efforts and results, which can help promote openness and transparency in AI and LLM research.\nData Attribution: The authors emphasize the importance of data attribution for legal and safety purposes, such as respecting copyright/intellectual property rights and mitigating problematic outputs of LLMs. They describe promising directions for data attribution and removal.\nKnowledge Transfer: The authors discuss the potential of transferring the knowledge of trained LLMs to compact and specialized models. They highlight existing efforts and new opportunities where the outputs of a trained LLM are treated as (synthesized) data.\nInference Contextualization with Data: The authors describe how LLMs can flexibly use data at inference to augment the outputs’ factuality or quality. They elaborate on this paradigm with respect to two prevalent technical frameworks and highlight how it can improve the personalization of LLMs."
  },
  {
    "objectID": "posts/Data_Centric_AI_in_the_Age_of_Large_Language_Models/2024-06-20-Data_Centric_AI_in_the_Age_of_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/Data_Centric_AI_in_the_Age_of_Large_Language_Models/2024-06-20-Data_Centric_AI_in_the_Age_of_Large_Language_Models.html#analysis-and-critique",
    "title": "Data-Centric AI in the Age of Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nLimited Research on Data-Centric Approaches: While the paper provides a comprehensive overview of the role of data in LLMs, it also highlights the lack of research in this area. The authors argue that the bulk of research to date has focused on modeling improvements, with little attention paid to how to best use data for the developmental and inferential stages of LLMs.\nChallenges in Data Attribution and Unlearning:"
  },
  {
    "objectID": "posts/Data_Centric_AI_in_the_Age_of_Large_Language_Models/2024-06-20-Data_Centric_AI_in_the_Age_of_Large_Language_Models.html#appendix",
    "href": "posts/Data_Centric_AI_in_the_Age_of_Large_Language_Models/2024-06-20-Data_Centric_AI_in_the_Age_of_Large_Language_Models.html#appendix",
    "title": "Data-Centric AI in the Age of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14473v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14473v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10052"
  },
  {
    "objectID": "posts/EmPO_Theory_Driven_Dataset_Construction_for_Empathetic_Response_Generation_through_Preference_Optimization/2024-06-27-EmPO_Theory_Driven_Dataset_Construction_for_Empathetic_Response_Generation_through_Preference_Optimization.html#appendix",
    "href": "posts/EmPO_Theory_Driven_Dataset_Construction_for_Empathetic_Response_Generation_through_Preference_Optimization/2024-06-27-EmPO_Theory_Driven_Dataset_Construction_for_Empathetic_Response_Generation_through_Preference_Optimization.html#appendix",
    "title": "EmPO: Theory-Driven Dataset Construction for Empathetic Response Generation through Preference Optimization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19071v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19071v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4108"
  },
  {
    "objectID": "posts/PFID_Privacy_First_Inference_Delegation_Framework_for_LLMs/2024-06-18-PFID_Privacy_First_Inference_Delegation_Framework_for_LLMs.html#appendix",
    "href": "posts/PFID_Privacy_First_Inference_Delegation_Framework_for_LLMs/2024-06-18-PFID_Privacy_First_Inference_Delegation_Framework_for_LLMs.html#appendix",
    "title": "PFID: Privacy First Inference Delegation Framework for LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12238v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12238v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5069"
  },
  {
    "objectID": "posts/Revealing_Fine_Grained_Values_and_Opinions_in_Large_Language_Models/2024-06-27-Revealing_Fine_Grained_Values_and_Opinions_in_Large_Language_Models.html#appendix",
    "href": "posts/Revealing_Fine_Grained_Values_and_Opinions_in_Large_Language_Models/2024-06-27-Revealing_Fine_Grained_Values_and_Opinions_in_Large_Language_Models.html#appendix",
    "title": "Revealing Fine-Grained Values and Opinions in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19238v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19238v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8950"
  },
  {
    "objectID": "posts/PsycoLLM_Enhancing_LLM_for_Psychological_Understanding_and_Evaluation/2024-07-08-PsycoLLM_Enhancing_LLM_for_Psychological_Understanding_and_Evaluation.html#appendix",
    "href": "posts/PsycoLLM_Enhancing_LLM_for_Psychological_Understanding_and_Evaluation/2024-07-08-PsycoLLM_Enhancing_LLM_for_Psychological_Understanding_and_Evaluation.html#appendix",
    "title": "PsycoLLM: Enhancing LLM for Psychological Understanding and Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05721v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05721v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5547"
  },
  {
    "objectID": "posts/Hecaton_Training_and_Finetuning_Large_Language_Models_with_Scalable_Chiplet_Systems/2024-07-08-Hecaton_Training_and_Finetuning_Large_Language_Models_with_Scalable_Chiplet_Systems.html#appendix",
    "href": "posts/Hecaton_Training_and_Finetuning_Large_Language_Models_with_Scalable_Chiplet_Systems/2024-07-08-Hecaton_Training_and_Finetuning_Large_Language_Models_with_Scalable_Chiplet_Systems.html#appendix",
    "title": "Hecaton: Training and Finetuning Large Language Models with Scalable Chiplet Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05784v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05784v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9383"
  },
  {
    "objectID": "posts/Hello_Again!_LLM_powered_Personalized_Agent_for_Long_term_Dialogue/2024-06-09-Hello_Again!_LLM_powered_Personalized_Agent_for_Long_term_Dialogue.html#appendix",
    "href": "posts/Hello_Again!_LLM_powered_Personalized_Agent_for_Long_term_Dialogue/2024-06-09-Hello_Again!_LLM_powered_Personalized_Agent_for_Long_term_Dialogue.html#appendix",
    "title": "Hello Again! LLM-powered Personalized Agent for Long-term Dialogue",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05925v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05925v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6818"
  },
  {
    "objectID": "posts/Evaluating_the_Semantic_Profiling_Abilities_of_LLMs_for_Natural_Language_Utterances_in_Data_Visualization/2024-07-08-Evaluating_the_Semantic_Profiling_Abilities_of_LLMs_for_Natural_Language_Utterances_in_Data_Visualization.html#appendix",
    "href": "posts/Evaluating_the_Semantic_Profiling_Abilities_of_LLMs_for_Natural_Language_Utterances_in_Data_Visualization/2024-07-08-Evaluating_the_Semantic_Profiling_Abilities_of_LLMs_for_Natural_Language_Utterances_in_Data_Visualization.html#appendix",
    "title": "Evaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06129v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06129v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6332"
  },
  {
    "objectID": "posts/A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions/2024-06-06-A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions.html",
    "href": "posts/A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions/2024-06-06-A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions.html",
    "title": "A Survey on Medical Large Language Models: Technology, Application, Trustworthiness, and Future Directions",
    "section": "",
    "text": "Summary:\nThis survey provides a comprehensive overview of Medical Large Language Models (Med-LLMs), outlining their evolution from general to medical-specific domains and their transformative impact on healthcare. The study explores the fundamental history and technology of LLMs, delving into the progressive adaptation and refinements of general LLM models in the medical domain. It emphasizes advanced algorithms that boost the LLMs’ performance in handling complicated medical environments, including clinical reasoning, knowledge graph, retrieval-augmented generation, human alignment, and multi-modal learning.\nThe survey also explores the extensive applications of Med-LLMs across domains such as clinical decision support, report generation, and medical education, illustrating their potential to streamline healthcare services and augment patient outcomes. Recognizing the imperative for responsible innovation, the study discusses the challenges of ensuring fairness, accountability, privacy, and robustness in Med-LLMs applications, where ethical considerations, rigorous evaluation methodologies, and the formulation of regulatory frameworks are pivotal to fostering trustworthiness in these systems.\nMajor Findings:\nAnalysis and Critique:\nThis survey provides a comprehensive investigation of the potential strengths and limitations of Med-LLMs for professionals and researchers, ensuring a responsible landscape in the healthcare setting. However, it is important to note that the study primarily focuses on"
  },
  {
    "objectID": "posts/A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions/2024-06-06-A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions.html#appendix",
    "href": "posts/A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions/2024-06-06-A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions.html#appendix",
    "title": "A Survey on Medical Large Language Models: Technology, Application, Trustworthiness, and Future Directions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03712v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03712v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18909"
  },
  {
    "objectID": "posts/LGR2_Language_Guided_Reward_Relabeling_for_Accelerating_Hierarchical_Reinforcement_Learning/2024-06-09-LGR2_Language_Guided_Reward_Relabeling_for_Accelerating_Hierarchical_Reinforcement_Learning.html#appendix",
    "href": "posts/LGR2_Language_Guided_Reward_Relabeling_for_Accelerating_Hierarchical_Reinforcement_Learning/2024-06-09-LGR2_Language_Guided_Reward_Relabeling_for_Accelerating_Hierarchical_Reinforcement_Learning.html#appendix",
    "title": "LGR2: Language Guided Reward Relabeling for Accelerating Hierarchical Reinforcement Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05881v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05881v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10516"
  },
  {
    "objectID": "posts/Towards_Region_aware_Bias_Evaluation_Metrics/2024-06-23-Towards_Region_aware_Bias_Evaluation_Metrics.html#appendix",
    "href": "posts/Towards_Region_aware_Bias_Evaluation_Metrics/2024-06-23-Towards_Region_aware_Bias_Evaluation_Metrics.html#appendix",
    "title": "Towards Region-aware Bias Evaluation Metrics",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16152v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16152v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8427"
  },
  {
    "objectID": "posts/Measuring_and_Benchmarking_Large_Language_Models_Capabilities_to_Generate_Persuasive_Language/2024-06-25-Measuring_and_Benchmarking_Large_Language_Models_Capabilities_to_Generate_Persuasive_Language.html#appendix",
    "href": "posts/Measuring_and_Benchmarking_Large_Language_Models_Capabilities_to_Generate_Persuasive_Language/2024-06-25-Measuring_and_Benchmarking_Large_Language_Models_Capabilities_to_Generate_Persuasive_Language.html#appendix",
    "title": "Measuring and Benchmarking Large Language Models’ Capabilities to Generate Persuasive Language",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17753v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17753v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10078"
  },
  {
    "objectID": "posts/Enhancing_Collaborative_Semantics_of_Language_Model_Driven_Recommendations_via_Graph_Aware_Learning/2024-06-19-Enhancing_Collaborative_Semantics_of_Language_Model_Driven_Recommendations_via_Graph_Aware_Learning.html#appendix",
    "href": "posts/Enhancing_Collaborative_Semantics_of_Language_Model_Driven_Recommendations_via_Graph_Aware_Learning/2024-06-19-Enhancing_Collaborative_Semantics_of_Language_Model_Driven_Recommendations_via_Graph_Aware_Learning.html#appendix",
    "title": "Enhancing Collaborative Semantics of Language Model-Driven Recommendations via Graph-Aware Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13235v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13235v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7497"
  },
  {
    "objectID": "posts/Multi_Layer_Ranking_with_Large_Language_Models_for_News_Source_Recommendation/2024-06-17-Multi_Layer_Ranking_with_Large_Language_Models_for_News_Source_Recommendation.html#appendix",
    "href": "posts/Multi_Layer_Ranking_with_Large_Language_Models_for_News_Source_Recommendation/2024-06-17-Multi_Layer_Ranking_with_Large_Language_Models_for_News_Source_Recommendation.html#appendix",
    "title": "Multi-Layer Ranking with Large Language Models for News Source Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11745v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11745v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4168"
  },
  {
    "objectID": "posts/SEED_Accelerating_Reasoning_Tree_Construction_via_Scheduled_Speculative_Decoding/2024-06-26-SEED_Accelerating_Reasoning_Tree_Construction_via_Scheduled_Speculative_Decoding.html",
    "href": "posts/SEED_Accelerating_Reasoning_Tree_Construction_via_Scheduled_Speculative_Decoding/2024-06-26-SEED_Accelerating_Reasoning_Tree_Construction_via_Scheduled_Speculative_Decoding.html",
    "title": "SEED: Accelerating Reasoning Tree Construction via Scheduled Speculative Decoding",
    "section": "",
    "text": "Summary:\nThe paper introduces SEED, a novel and efficient inference framework designed to optimize runtime speed and GPU memory management concurrently in reasoning tree construction. SEED effectively handles two scenarios: executing multiple iterations with the same prompt and evaluating multiple iterations with different prompts. The framework utilizes scheduled speculative decoding to manage the scheduling of parallel draft models and introduces a novel execution strategy, Speculative Scheduled Execution. This strategy is inspired by the use of speculative decoding in parallel drafting. SEED achieves excellent speed performance on three reasoning and planning datasets: GSM8K, Creative Writing, and Blocksworld. The framework also provides a viable path for conducting batched inference in training-free speculative decoding.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a well-structured and coherent summary of the proposed SEED framework. The authors provide a clear explanation of the problem they aim to address and the methodology they employ to tackle it. The use of speculative decoding and parallel drafting in the framework is well-justified, and the results from the experiments demonstrate the effectiveness of the approach. However, the paper could benefit from a more in-depth discussion of the limitations and potential biases in the methodology, as well as a comparison with other existing approaches to reasoning tree construction. Additionally, the authors could explore the potential applications and implications of their framework in real-world scenarios."
  },
  {
    "objectID": "posts/SEED_Accelerating_Reasoning_Tree_Construction_via_Scheduled_Speculative_Decoding/2024-06-26-SEED_Accelerating_Reasoning_Tree_Construction_via_Scheduled_Speculative_Decoding.html#appendix",
    "href": "posts/SEED_Accelerating_Reasoning_Tree_Construction_via_Scheduled_Speculative_Decoding/2024-06-26-SEED_Accelerating_Reasoning_Tree_Construction_via_Scheduled_Speculative_Decoding.html#appendix",
    "title": "SEED: Accelerating Reasoning Tree Construction via Scheduled Speculative Decoding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18200v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18200v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15801"
  },
  {
    "objectID": "posts/WARP_On_the_Benefits_of_Weight_Averaged_Rewarded_Policies/2024-06-24-WARP_On_the_Benefits_of_Weight_Averaged_Rewarded_Policies.html",
    "href": "posts/WARP_On_the_Benefits_of_Weight_Averaged_Rewarded_Policies/2024-06-24-WARP_On_the_Benefits_of_Weight_Averaged_Rewarded_Policies.html",
    "title": "WARP: On the Benefits of Weight Averaged Rewarded Policies",
    "section": "",
    "text": "Summary:\nThe paper introduces a novel alignment strategy called Weight Averaged Rewarded Policies (WARP) for Reinforcement Learning from Human Feeduring (RLHF) in large language models (LLMs). WARP aims to optimize the -reward Pareto front of solutions by merging policies in the weight space at three distinct stages: using the exponential moving average (EMA) of the policy as a dynamic anchor in regularization, applying spherical interpolation to merge independently fine-tuned policies, and linearly interpolating between the merged model and the initialization. The iterative application of WARP improves the -reward Pareto front, aligning the LLMs while protecting the knowledge from pre-training. The paper compares WARP with state-of-the-art baselines and shows that it outperforms them in terms of alignment and quality.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel and promising approach to RLHF in LLMs. The use of model merging by weight averaging is a well-established technique in the literature, and the paper builds on this to propose a new alignment strategy. The experimental results show that WARP outperforms other RL alignment strategies in terms of -reward Pareto optimality. However, the paper does not discuss the computational cost of training WARP, which may be a limitation for some applications. Additionally, the paper does not provide a detailed comparison with other RLHF methods, such as Proximal Policy Optimization (PPO) or Deep Q-Networks (DQN), which could provide a more comprehensive evaluation of the proposed approach."
  },
  {
    "objectID": "posts/WARP_On_the_Benefits_of_Weight_Averaged_Rewarded_Policies/2024-06-24-WARP_On_the_Benefits_of_Weight_Averaged_Rewarded_Policies.html#appendix",
    "href": "posts/WARP_On_the_Benefits_of_Weight_Averaged_Rewarded_Policies/2024-06-24-WARP_On_the_Benefits_of_Weight_Averaged_Rewarded_Policies.html#appendix",
    "title": "WARP: On the Benefits of Weight Averaged Rewarded Policies",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16768v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16768v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11719"
  },
  {
    "objectID": "posts/Evaluating_Implicit_Bias_in_Large_Language_Models_by_Attacking_From_a_Psychometric_Perspective/2024-06-20-Evaluating_Implicit_Bias_in_Large_Language_Models_by_Attacking_From_a_Psychometric_Perspective.html#appendix",
    "href": "posts/Evaluating_Implicit_Bias_in_Large_Language_Models_by_Attacking_From_a_Psychometric_Perspective/2024-06-20-Evaluating_Implicit_Bias_in_Large_Language_Models_by_Attacking_From_a_Psychometric_Perspective.html#appendix",
    "title": "Evaluating Implicit Bias in Large Language Models by Attacking From a Psychometric Perspective",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14023v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14023v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7014"
  },
  {
    "objectID": "posts/Towards_more_realistic_evaluation_of_LLM_based_code_generation_an_experimental_study_and_beyond/2024-06-11-Towards_more_realistic_evaluation_of_LLM_based_code_generation_an_experimental_study_and_beyond.html#appendix",
    "href": "posts/Towards_more_realistic_evaluation_of_LLM_based_code_generation_an_experimental_study_and_beyond/2024-06-11-Towards_more_realistic_evaluation_of_LLM_based_code_generation_an_experimental_study_and_beyond.html#appendix",
    "title": "Towards more realistic evaluation of LLM-based code generation: an experimental study and beyond",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06918v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06918v1\n\n\nTruncated\nFalse\n\n\nWord Count\n0"
  },
  {
    "objectID": "posts/What_Do_Language_Models_Learn_in_Context_The_Structured_Task_Hypothesis/2024-06-06-What_Do_Language_Models_Learn_in_Context_The_Structured_Task_Hypothesis.html#appendix",
    "href": "posts/What_Do_Language_Models_Learn_in_Context_The_Structured_Task_Hypothesis/2024-06-06-What_Do_Language_Models_Learn_in_Context_The_Structured_Task_Hypothesis.html#appendix",
    "title": "What Do Language Models Learn in Context? The Structured Task Hypothesis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04216v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04216v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15"
  },
  {
    "objectID": "posts/PITCH_Productivity_and_Mental_Well_being_Coaching_through_Daily_Conversational_Interaction/2024-06-11-PITCH_Productivity_and_Mental_Well_being_Coaching_through_Daily_Conversational_Interaction.html#appendix",
    "href": "posts/PITCH_Productivity_and_Mental_Well_being_Coaching_through_Daily_Conversational_Interaction/2024-06-11-PITCH_Productivity_and_Mental_Well_being_Coaching_through_Daily_Conversational_Interaction.html#appendix",
    "title": "PITCH: Productivity and Mental Well-being Coaching through Daily Conversational Interaction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07485v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07485v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3364"
  },
  {
    "objectID": "posts/Jailbreaking_as_a_Reward_Misspecification_Problem/2024-06-20-Jailbreaking_as_a_Reward_Misspecification_Problem.html#appendix",
    "href": "posts/Jailbreaking_as_a_Reward_Misspecification_Problem/2024-06-20-Jailbreaking_as_a_Reward_Misspecification_Problem.html#appendix",
    "title": "Jailbreaking as a Reward Misspecification Problem",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14393v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14393v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7548"
  },
  {
    "objectID": "posts/M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering/2024-06-06-M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering.html",
    "href": "posts/M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering/2024-06-06-M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering.html",
    "title": "M-QALM: A Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall in Large Language Models via Question Answering",
    "section": "",
    "text": "Summary:\nThe paper introduces M-QALM, a benchmark for evaluating clinical reading comprehension and knowledge recall in large language models (LLMs) through question answering. The authors conduct a large-scale empirical study using 22 datasets in three generalist and three specialist biomedical sub-domains. They analyze the performance of 15 LLMs, focusing on factors such as instruction tuning, domain-adapted models, and fine-tuning on medical knowledge datasets. The results show that while recent domain-adapted models may lack adequate knowledge, fine-tuning on medical knowledge datasets shows encouraging results, even generalizing to unseen specialist sub-domains. The paper also includes a skill-oriented manual error analysis, revealing a significant gap between the models’ capabilities to recall necessary knowledge and integrate it with the presented context.\nMajor Findings:"
  },
  {
    "objectID": "posts/M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering/2024-06-06-M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering.html#appendix",
    "href": "posts/M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering/2024-06-06-M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering.html#appendix",
    "title": "M-QALM: A Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall in Large Language Models via Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03699v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03699v1\n\n\nTruncated\nTrue\n\n\nWord Count\n32275"
  },
  {
    "objectID": "posts/From_Text_to_Test_AI_Generated_Control_Software_for_Materials_Science_Instruments/2024-06-23-From_Text_to_Test_AI_Generated_Control_Software_for_Materials_Science_Instruments.html#appendix",
    "href": "posts/From_Text_to_Test_AI_Generated_Control_Software_for_Materials_Science_Instruments/2024-06-23-From_Text_to_Test_AI_Generated_Control_Software_for_Materials_Science_Instruments.html#appendix",
    "title": "From Text to Test: AI-Generated Control Software for Materials Science Instruments",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16224v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16224v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8908"
  },
  {
    "objectID": "posts/Exploring_Spatial_Representations_in_the_Historical_Lake_District_Texts_with_LLM_based_Relation_Extraction/2024-06-20-Exploring_Spatial_Representations_in_the_Historical_Lake_District_Texts_with_LLM_based_Relation_Extraction.html#appendix",
    "href": "posts/Exploring_Spatial_Representations_in_the_Historical_Lake_District_Texts_with_LLM_based_Relation_Extraction/2024-06-20-Exploring_Spatial_Representations_in_the_Historical_Lake_District_Texts_with_LLM_based_Relation_Extraction.html#appendix",
    "title": "Exploring Spatial Representations in the Historical Lake District Texts with LLM-based Relation Extraction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14336v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14336v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4003"
  },
  {
    "objectID": "posts/Native_Design_Bias_Studying_the_Impact_of_English_Nativeness_on_Language_Model_Performance/2024-06-25-Native_Design_Bias_Studying_the_Impact_of_English_Nativeness_on_Language_Model_Performance.html#appendix",
    "href": "posts/Native_Design_Bias_Studying_the_Impact_of_English_Nativeness_on_Language_Model_Performance/2024-06-25-Native_Design_Bias_Studying_the_Impact_of_English_Nativeness_on_Language_Model_Performance.html#appendix",
    "title": "Native Design Bias: Studying the Impact of English Nativeness on Language Model Performance",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17385v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17385v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9031"
  },
  {
    "objectID": "posts/Asynchronous_Large_Language_Model_Enhanced_Planner_for_Autonomous_Driving/2024-06-20-Asynchronous_Large_Language_Model_Enhanced_Planner_for_Autonomous_Driving.html#appendix",
    "href": "posts/Asynchronous_Large_Language_Model_Enhanced_Planner_for_Autonomous_Driving/2024-06-20-Asynchronous_Large_Language_Model_Enhanced_Planner_for_Autonomous_Driving.html#appendix",
    "title": "Asynchronous Large Language Model Enhanced Planner for Autonomous Driving",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14556v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14556v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9407"
  },
  {
    "objectID": "posts/DR_RAG_Applying_Dynamic_Document_Relevance_to_Retrieval_Augmented_Generation_for_Question_Answering/2024-06-11-DR_RAG_Applying_Dynamic_Document_Relevance_to_Retrieval_Augmented_Generation_for_Question_Answering.html#appendix",
    "href": "posts/DR_RAG_Applying_Dynamic_Document_Relevance_to_Retrieval_Augmented_Generation_for_Question_Answering/2024-06-11-DR_RAG_Applying_Dynamic_Document_Relevance_to_Retrieval_Augmented_Generation_for_Question_Answering.html#appendix",
    "title": "DR-RAG: Applying Dynamic Document Relevance to Retrieval-Augmented Generation for Question-Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07348v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07348v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6121"
  },
  {
    "objectID": "posts/Ragnarök_A_Reusable_RAG_Framework_and_Baselines_for_TREC_2024_Retrieval_Augmented_Generation_Track/2024-06-24-Ragnarök_A_Reusable_RAG_Framework_and_Baselines_for_TREC_2024_Retrieval_Augmented_Generation_Track.html#appendix",
    "href": "posts/Ragnarök_A_Reusable_RAG_Framework_and_Baselines_for_TREC_2024_Retrieval_Augmented_Generation_Track/2024-06-24-Ragnarök_A_Reusable_RAG_Framework_and_Baselines_for_TREC_2024_Retrieval_Augmented_Generation_Track.html#appendix",
    "title": "Ragnarök: A Reusable RAG Framework and Baselines for TREC 2024 Retrieval-Augmented Generation Track",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16828v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16828v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6500"
  },
  {
    "objectID": "posts/On_AI_Inspired_UI_Design/2024-06-19-On_AI_Inspired_UI_Design.html#appendix",
    "href": "posts/On_AI_Inspired_UI_Design/2024-06-19-On_AI_Inspired_UI_Design.html#appendix",
    "title": "On AI-Inspired UI-Design",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13631v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13631v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1712"
  },
  {
    "objectID": "posts/RepoQA_Evaluating_Long_Context_Code_Understanding/2024-06-10-RepoQA_Evaluating_Long_Context_Code_Understanding.html#appendix",
    "href": "posts/RepoQA_Evaluating_Long_Context_Code_Understanding/2024-06-10-RepoQA_Evaluating_Long_Context_Code_Understanding.html#appendix",
    "title": "RepoQA: Evaluating Long Context Code Understanding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06025v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06025v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2740"
  },
  {
    "objectID": "posts/LogEval_A_Comprehensive_Benchmark_Suite_for_Large_Language_Models_In_Log_Analysis/2024-07-02-LogEval_A_Comprehensive_Benchmark_Suite_for_Large_Language_Models_In_Log_Analysis.html#appendix",
    "href": "posts/LogEval_A_Comprehensive_Benchmark_Suite_for_Large_Language_Models_In_Log_Analysis/2024-07-02-LogEval_A_Comprehensive_Benchmark_Suite_for_Large_Language_Models_In_Log_Analysis.html#appendix",
    "title": "LogEval: A Comprehensive Benchmark Suite for Large Language Models In Log Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01896v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01896v1\n\n\nTruncated\nFalse\n\n\nWord Count\n0"
  },
  {
    "objectID": "posts/Sunnie_An_Anthropomorphic_LLM_Based_Conversational_Agent_for_Mental_Well_Being_Activity_Recommendation/2024-05-22-Sunnie_An_Anthropomorphic_LLM_Based_Conversational_Agent_for_Mental_Well_Being_Activity_Recommendation.html#appendix",
    "href": "posts/Sunnie_An_Anthropomorphic_LLM_Based_Conversational_Agent_for_Mental_Well_Being_Activity_Recommendation/2024-05-22-Sunnie_An_Anthropomorphic_LLM_Based_Conversational_Agent_for_Mental_Well_Being_Activity_Recommendation.html#appendix",
    "title": "Sunnie: An Anthropomorphic LLM-Based Conversational Agent for Mental Well-Being Activity Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.13803v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.13803v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1391"
  },
  {
    "objectID": "posts/IRCAN_Mitigating_Knowledge_Conflicts_in_LLM_Generation_via_Identifying_and_Reweighting_Context_Aware_Neurons/2024-06-26-IRCAN_Mitigating_Knowledge_Conflicts_in_LLM_Generation_via_Identifying_and_Reweighting_Context_Aware_Neurons.html#appendix",
    "href": "posts/IRCAN_Mitigating_Knowledge_Conflicts_in_LLM_Generation_via_Identifying_and_Reweighting_Context_Aware_Neurons/2024-06-26-IRCAN_Mitigating_Knowledge_Conflicts_in_LLM_Generation_via_Identifying_and_Reweighting_Context_Aware_Neurons.html#appendix",
    "title": "IRCAN: Mitigating Knowledge Conflicts in LLM Generation via Identifying and Reweighting Context-Aware Neurons",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18406v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18406v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6376"
  },
  {
    "objectID": "posts/Stronger_Faster_and_Cheaper_Log_Parsing_with_LLMs/2024-06-10-Stronger_Faster_and_Cheaper_Log_Parsing_with_LLMs.html#appendix",
    "href": "posts/Stronger_Faster_and_Cheaper_Log_Parsing_with_LLMs/2024-06-10-Stronger_Faster_and_Cheaper_Log_Parsing_with_LLMs.html#appendix",
    "title": "Stronger, Faster, and Cheaper Log Parsing with LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06156v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06156v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11355"
  },
  {
    "objectID": "posts/Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs/2024-06-20-Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs.html#major-findings",
    "href": "posts/Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs/2024-06-20-Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs.html#major-findings",
    "title": "Taxonomy-Guided Zero-Shot Recommendations with LLMs",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe use of a taxonomy dictionary provides a systematic framework for categorizing and organizing items, enhancing the structure and clarity of item information.\nThe TaxRec approach, which uses taxonomy to retrieve knowledge and enhance LLMs’ ability as personal recommenders, significantly improves recommendation quality compared to current zero-shot recommenders.\nThe two-step process of TaxRec, which includes one-time taxonomy categorization and LLM-based recommendation, effectively handles large item pools and makes the recommendation process more efficient, accurate, and scalable."
  },
  {
    "objectID": "posts/Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs/2024-06-20-Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs.html#analysis-and-critique",
    "href": "posts/Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs/2024-06-20-Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs.html#analysis-and-critique",
    "title": "Taxonomy-Guided Zero-Shot Recommendations with LLMs",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper does not discuss the potential limitations of the proposed method, such as the quality and completeness of the taxonomy generated by LLMs and the sufficiency of LLMs’ domain knowledge in certain areas.\nThe paper does not provide a comparison of the proposed method with other taxonomy-based recommendation approaches, which could have helped to better understand the advantages and disadvantages of the proposed method.\nThe paper does not discuss the potential impact of the proposed method on the computational resources required for generating recommendations, which is an important consideration in practical applications.\nThe paper does not provide a detailed analysis of the experimental results, such as the impact of different taxonomy categories on the recommendation quality and the performance of the method in different application domains.\nThe paper does not discuss the potential ethical implications of using LLMs for recommendation,"
  },
  {
    "objectID": "posts/Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs/2024-06-20-Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs.html#appendix",
    "href": "posts/Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs/2024-06-20-Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs.html#appendix",
    "title": "Taxonomy-Guided Zero-Shot Recommendations with LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14043v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14043v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5941"
  },
  {
    "objectID": "posts/Should_AI_Optimize_Your_Code_A_Comparative_Study_of_Current_Large_Language_Models_Versus_Classical_Optimizing_Compilers/2024-06-17-Should_AI_Optimize_Your_Code_A_Comparative_Study_of_Current_Large_Language_Models_Versus_Classical_Optimizing_Compilers.html#appendix",
    "href": "posts/Should_AI_Optimize_Your_Code_A_Comparative_Study_of_Current_Large_Language_Models_Versus_Classical_Optimizing_Compilers/2024-06-17-Should_AI_Optimize_Your_Code_A_Comparative_Study_of_Current_Large_Language_Models_Versus_Classical_Optimizing_Compilers.html#appendix",
    "title": "Should AI Optimize Your Code? A Comparative Study of Current Large Language Models Versus Classical Optimizing Compilers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12146v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12146v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7663"
  },
  {
    "objectID": "posts/Learning_to_Generate_Answers_with_Citations_via_Factual_Consistency_Models/2024-06-19-Learning_to_Generate_Answers_with_Citations_via_Factual_Consistency_Models.html#appendix",
    "href": "posts/Learning_to_Generate_Answers_with_Citations_via_Factual_Consistency_Models/2024-06-19-Learning_to_Generate_Answers_with_Citations_via_Factual_Consistency_Models.html#appendix",
    "title": "Learning to Generate Answers with Citations via Factual Consistency Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13124v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13124v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13245"
  },
  {
    "objectID": "posts/Beyond_Numeric_Awards_In_Context_Dueling_Bandits_with_LLM_Agents/2024-07-02-Beyond_Numeric_Awards_In_Context_Dueling_Bandits_with_LLM_Agents.html",
    "href": "posts/Beyond_Numeric_Awards_In_Context_Dueling_Bandits_with_LLM_Agents/2024-07-02-Beyond_Numeric_Awards_In_Context_Dueling_Bandits_with_LLM_Agents.html",
    "title": "Beyond Numeric Awards: In-Context Dueling Bandits with LLM Agents",
    "section": "",
    "text": "Summary:\nThis paper investigates the performance of Large Language Models (LLMs) as decision-makers in the context of Dueling Bandits (DB). The study compares GPT-3.5 Turbo, GPT-4, and GPT-4 Turbo against established DB algorithms. The results reveal that LLMs, particularly GPT-4 Turbo, quickly identify the Condorcet winner, outperforming existing state-of-the-art algorithms in terms of weak regret. However, LLMs struggle to converge even when explicitly prompted to do so and are sensitive to prompt variations. To overcome these issues, the paper introduces an LLM-augmented algorithm, IF-Enhanced LLM, which combines the in-context decision-making capabilities of LLMs and theoretical guarantees inherited from classic DB algorithms. The proposed algorithm has theoretical guarantees on both weak and strong regret and is robust even with noisy and adversarial prompts.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an interesting approach to using LLMs in the context of DB. The findings that LLMs can quickly identify the Condorcet winner are promising, but the lack of convergence and sensitivity to prompt variations are limitations that need to be addressed. The proposed LLM-augmented algorithm, IF-Enhanced LLM, is a step in the right direction, as it combines the strengths of LLMs and classic DB algorithms. However, the robustness of this algorithm to noisy and adversarial prompts needs to be further validated in different scenarios and with different types of LLMs. Additionally,"
  },
  {
    "objectID": "posts/Beyond_Numeric_Awards_In_Context_Dueling_Bandits_with_LLM_Agents/2024-07-02-Beyond_Numeric_Awards_In_Context_Dueling_Bandits_with_LLM_Agents.html#appendix",
    "href": "posts/Beyond_Numeric_Awards_In_Context_Dueling_Bandits_with_LLM_Agents/2024-07-02-Beyond_Numeric_Awards_In_Context_Dueling_Bandits_with_LLM_Agents.html#appendix",
    "title": "Beyond Numeric Awards: In-Context Dueling Bandits with LLM Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01887v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01887v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11940"
  },
  {
    "objectID": "posts/An_Investigation_of_Prompt_Variations_for_Zero_shot_LLM_based_Rankers/2024-06-20-An_Investigation_of_Prompt_Variations_for_Zero_shot_LLM_based_Rankers.html#appendix",
    "href": "posts/An_Investigation_of_Prompt_Variations_for_Zero_shot_LLM_based_Rankers/2024-06-20-An_Investigation_of_Prompt_Variations_for_Zero_shot_LLM_based_Rankers.html#appendix",
    "title": "An Investigation of Prompt Variations for Zero-shot LLM-based Rankers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14117v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14117v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7110"
  },
  {
    "objectID": "posts/Lottery_Ticket_Adaptation_Mitigating_Destructive_Interference_in_LLMs/2024-06-24-Lottery_Ticket_Adaptation_Mitigating_Destructive_Interference_in_LLMs.html#appendix",
    "href": "posts/Lottery_Ticket_Adaptation_Mitigating_Destructive_Interference_in_LLMs/2024-06-24-Lottery_Ticket_Adaptation_Mitigating_Destructive_Interference_in_LLMs.html#appendix",
    "title": "Lottery Ticket Adaptation: Mitigating Destructive Interference in LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16797v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16797v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9206"
  },
  {
    "objectID": "posts/Artificial_Intuition_Efficient_Classification_of_Scientific_Abstracts/2024-07-08-Artificial_Intuition_Efficient_Classification_of_Scientific_Abstracts.html#appendix",
    "href": "posts/Artificial_Intuition_Efficient_Classification_of_Scientific_Abstracts/2024-07-08-Artificial_Intuition_Efficient_Classification_of_Scientific_Abstracts.html#appendix",
    "title": "Artificial Intuition: Efficient Classification of Scientific Abstracts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06093v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06093v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5527"
  },
  {
    "objectID": "posts/Exploring_User_Retrieval_Integration_towards_Large_Language_Models_for_Cross_Domain_Sequential_Recommendation/2024-06-05-Exploring_User_Retrieval_Integration_towards_Large_Language_Models_for_Cross_Domain_Sequential_Recommendation.html#appendix",
    "href": "posts/Exploring_User_Retrieval_Integration_towards_Large_Language_Models_for_Cross_Domain_Sequential_Recommendation/2024-06-05-Exploring_User_Retrieval_Integration_towards_Large_Language_Models_for_Cross_Domain_Sequential_Recommendation.html#appendix",
    "title": "Exploring User Retrieval Integration towards Large Language Models for Cross-Domain Sequential Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03085v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03085v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8121"
  },
  {
    "objectID": "posts/PRePair_Pointwise_Reasoning_Enhance_Pairwise_Evaluating_for_Robust_Instruction_Following_Assessments/2024-06-18-PRePair_Pointwise_Reasoning_Enhance_Pairwise_Evaluating_for_Robust_Instruction_Following_Assessments.html#appendix",
    "href": "posts/PRePair_Pointwise_Reasoning_Enhance_Pairwise_Evaluating_for_Robust_Instruction_Following_Assessments/2024-06-18-PRePair_Pointwise_Reasoning_Enhance_Pairwise_Evaluating_for_Robust_Instruction_Following_Assessments.html#appendix",
    "title": "PRePair: Pointwise Reasoning Enhance Pairwise Evaluating for Robust Instruction-Following Assessments",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12319v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12319v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2144"
  },
  {
    "objectID": "posts/Aligning_Large_Language_Models_with_Diverse_Political_Viewpoints/2024-06-20-Aligning_Large_Language_Models_with_Diverse_Political_Viewpoints.html#appendix",
    "href": "posts/Aligning_Large_Language_Models_with_Diverse_Political_Viewpoints/2024-06-20-Aligning_Large_Language_Models_with_Diverse_Political_Viewpoints.html#appendix",
    "title": "Aligning Large Language Models with Diverse Political Viewpoints",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14155v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14155v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5339"
  },
  {
    "objectID": "posts/When_Box_Meets_Graph_Neural_Network_in_Tag_aware_Recommendation/2024-06-17-When_Box_Meets_Graph_Neural_Network_in_Tag_aware_Recommendation.html#appendix",
    "href": "posts/When_Box_Meets_Graph_Neural_Network_in_Tag_aware_Recommendation/2024-06-17-When_Box_Meets_Graph_Neural_Network_in_Tag_aware_Recommendation.html#appendix",
    "title": "When Box Meets Graph Neural Network in Tag-aware Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12020v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12020v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8318"
  },
  {
    "objectID": "posts/Learning_to_Plan_for_Retrieval_Augmented_Large_Language_Models_from_Knowledge_Graphs/2024-06-20-Learning_to_Plan_for_Retrieval_Augmented_Large_Language_Models_from_Knowledge_Graphs.html#appendix",
    "href": "posts/Learning_to_Plan_for_Retrieval_Augmented_Large_Language_Models_from_Knowledge_Graphs/2024-06-20-Learning_to_Plan_for_Retrieval_Augmented_Large_Language_Models_from_Knowledge_Graphs.html#appendix",
    "title": "Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14282v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14282v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6692"
  },
  {
    "objectID": "posts/SNAP_Unlearning_Selective_Knowledge_in_Large_Language_Models_with_Negative_Instructions/2024-06-18-SNAP_Unlearning_Selective_Knowledge_in_Large_Language_Models_with_Negative_Instructions.html#appendix",
    "href": "posts/SNAP_Unlearning_Selective_Knowledge_in_Large_Language_Models_with_Negative_Instructions/2024-06-18-SNAP_Unlearning_Selective_Knowledge_in_Large_Language_Models_with_Negative_Instructions.html#appendix",
    "title": "SNAP: Unlearning Selective Knowledge in Large Language Models with Negative Instructions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12329v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12329v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7278"
  },
  {
    "objectID": "posts/Ollabench_Evaluating_LLMs_Reasoning_for_Human_centric_Interdependent_Cybersecurity/2024-06-11-Ollabench_Evaluating_LLMs_Reasoning_for_Human_centric_Interdependent_Cybersecurity.html#appendix",
    "href": "posts/Ollabench_Evaluating_LLMs_Reasoning_for_Human_centric_Interdependent_Cybersecurity/2024-06-11-Ollabench_Evaluating_LLMs_Reasoning_for_Human_centric_Interdependent_Cybersecurity.html#appendix",
    "title": "Ollabench: Evaluating LLMs’ Reasoning for Human-centric Interdependent Cybersecurity",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06863v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06863v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7305"
  },
  {
    "objectID": "posts/Can_Language_Models_Serve_as_Text_Based_World_Simulators/2024-06-10-Can_Language_Models_Serve_as_Text_Based_World_Simulators.html#appendix",
    "href": "posts/Can_Language_Models_Serve_as_Text_Based_World_Simulators/2024-06-10-Can_Language_Models_Serve_as_Text_Based_World_Simulators.html#appendix",
    "title": "Can Language Models Serve as Text-Based World Simulators?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06485v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06485v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6025"
  },
  {
    "objectID": "posts/Identifying_Performance_Sensitive_Configurations_in_Software_Systems_through_Code_Analysis_with_LLM_Agents/2024-06-18-Identifying_Performance_Sensitive_Configurations_in_Software_Systems_through_Code_Analysis_with_LLM_Agents.html#appendix",
    "href": "posts/Identifying_Performance_Sensitive_Configurations_in_Software_Systems_through_Code_Analysis_with_LLM_Agents/2024-06-18-Identifying_Performance_Sensitive_Configurations_in_Software_Systems_through_Code_Analysis_with_LLM_Agents.html#appendix",
    "title": "Identifying Performance-Sensitive Configurations in Software Systems through Code Analysis with LLM Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12806v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12806v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9569"
  },
  {
    "objectID": "posts/NormTab_Improving_Symbolic_Reasoning_in_LLMs_Through_Tabular_Data_Normalization/2024-06-25-NormTab_Improving_Symbolic_Reasoning_in_LLMs_Through_Tabular_Data_Normalization.html#appendix",
    "href": "posts/NormTab_Improving_Symbolic_Reasoning_in_LLMs_Through_Tabular_Data_Normalization/2024-06-25-NormTab_Improving_Symbolic_Reasoning_in_LLMs_Through_Tabular_Data_Normalization.html#appendix",
    "title": "NormTab: Improving Symbolic Reasoning in LLMs Through Tabular Data Normalization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17961v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17961v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6898"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian beagle",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nDo Multilingual Large Language Models Mitigate Stereotype Bias?\n\n\n\nsocial-sciences\n\n\n\nMultilingual training in LLMs reduces bias and improves prediction accuracy compared to monolingual models.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Loops to Oops: Fallback Behaviors of Language Models Under Uncertainty\n\n\n\nrobustness\n\n\n\nLLMs’ fallback behaviors shift from repetitions to degenerate text to hallucinations with model advancement and increasing uncertainty. Common decoding techniques may reduce…\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nT2VSafetyBench: Evaluating the Safety of Text-to-Video Generative Models\n\n\n\narchitectures\n\n\nrobustness\n\n\nsecurity\n\n\n\nT2VSafetyBench: New benchmark for assessing text-to-video model safety risks, highlighting no single model excels in all aspects and a trade-off between usability and safety.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Optimizing and Evaluating a Retrieval Augmented QA Chatbot using LLMs with Human in the Loop\n\n\n\nproduction\n\n\n\nLLM-driven HR chatbot, enhanced with GPT-4, offers efficient, scalable HR support, aligning with human evaluation.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Grammar Masking to Ensure Syntactic Validity in LLM-based Modeling Tasks\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\nproduction\n\n\n\nGrammar masking improves LLMs’ modeling, reducing reliance on prompting and increasing correct syntax chances.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRetrieved In-Context Principles from Previous Mistakes\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nRICP improves LLM performance by learning from mistakes, enhancing error coverage and customization.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-Based Open-Domain Integrated Task and Knowledge Assistants with Programmable Policies\n\n\n\nrobustness\n\n\n\nKITA outperforms GPT-4 in a user study, offering reliable, grounded responses and controllable agent policies for complex user interactions.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerative Debunking of Climate Misinformation\n\n\n\nsocial-sciences\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLMs can automatically debunk climate myths using the truth sandwich structure, with GPT-4 and Mixtral showing promising results.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMerge, Ensemble, and Cooperate! A Survey on Collaborative Strategies in the Era of Large Language Models\n\n\n\narchitectures\n\n\nproduction\n\n\n\nThis paper explores three strategies for collaborative large language models: merging, ensemble, and cooperation.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat’s Wrong with Your Code Generated by Large Language Models? An Extensive Study\n\n\n\narchitectures\n\n\nrobustness\n\n\nprogramming\n\n\nproduction\n\n\n\nLLMs struggle with complex code, often producing shorter, more complicated code. A novel iterative method improves LLM-generated code, boosting passing rate by 29.2%.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLaMAX: Scaling Linguistic Horizons of LLM by Enhancing Translation Capabilities Beyond 100 Languages\n\n\n\narchitectures\n\n\nproduction\n\n\n\nLLMs struggle with low-resource languages. LLaMAX, a multilingual LLM, outperforms existing models in translation tasks across 100+ languages.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistilling System 2 into System 1\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\nproduction\n\n\n\nDistilling System 2 techniques into System 1 improves LLM performance with less inference cost.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nANOLE: An Open, Autoregressive, Native Large Multimodal Models for Interleaved Image-Text Generation\n\n\n\narchitectures\n\n\nproduction\n\n\n\nAnole: Open, autoregressive LMM for interleaved image-text generation, addressing previous LMM limitations.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeneration and De-Identification of Indian Clinical Discharge Summaries using LLMs\n\n\n\nproduction\n\n\n\nDe-identification algorithms struggle in Indian healthcare; synthetic data can improve performance.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHyCIR: Boosting Zero-Shot Composed Image Retrieval with Synthetic Labels\n\n\n\narchitectures\n\n\nproduction\n\n\n\nHyCIR uses synthetic labels to improve zero-shot CIR performance, achieving SOTA results on CIRR and CIRCO benchmarks.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Language Model Rationality with Bi-Directional Deliberation Reasoning\n\n\n\nprompt-engineering\n\n\n\nBIDDER enhances LLM decision-making with bi-directional reasoning, considering past and future contexts, improving rationality in poker and negotiation scenarios.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niLLM-TSC: Integration reinforcement learning and large language model for traffic signal control policy improvement\n\n\n\narchitectures\n\n\nproduction\n\n\n\nLLM-RL Integration Improves TSC, Reducing Wait Time by 17.5% in Degraded Communication.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDepression Detection and Analysis using Large Language Models on Textual and Audio-Visual Modalities\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nAI models outperform traditional methods in diagnosing depression, achieving 71.43% accuracy and RMSE of 3.98 on textual modality.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs GPT-4 Alone Sufficient for Automated Essay Scoring?: A Comparative Judgment Approach Based on Rater Cognition\n\n\n\nsocial-sciences\n\n\neducation\n\n\n\nLLMs with Comparative Judgment outperform traditional rubric-based scoring in AES.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\nproduction\n\n\nsecurity\n\n\n\nLLMs can be misled by false premises, causing factuality hallucination. We introduce an automated pipeline to create a large-scale benchmark for this issue.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCrowdMoGen: Zero-Shot Text-Driven Collective Motion Generation\n\n\n\nsocial-sciences\n\n\nproduction\n\n\n\nCrowdMoGen: Zero-shot text-driven framework for realistic crowd motion generation.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn Speeding Up Language Model Evaluation\n\n\n\narchitectures\n\n\nproduction\n\n\n\nTL;DR: Our approach reduces evaluation resources by 85-95% using multi-armed bandit algorithms and low-rank factorization.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(R^2\\)-Guard: Robust Reasoning Enabled LLM Guardrail via Knowledge-Enhanced Logical Reasoning\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nR2-Guard: Robust LLM guardrail via knowledge-enhanced reasoning, outperforms LlamaGuard by 30.2% on ToxicChat and 59.5% against jailbreak attacks.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSub-SA: Strengthen In-context Learning via Submodular Selective Annotation\n\n\n\nprompt-engineering\n\n\n\nSub-SA is a submodular selective annotation method for ICL, reducing annotation costs and improving in-context example quality with millisecond-level time selection and…\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen is the consistent prediction likely to be a correct prediction?\n\n\n\nprompt-engineering\n\n\n\nLLMs produce more accurate answers with longer, consistent reasoning, not just the most consistent answer. Longer responses are less likely, requiring length-based decoding…\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenFollower: Enhancing Car-Following Prediction with Large Language Models\n\n\n\nprompt-engineering\n\n\n\nGenFollower: LLM-based approach improves car-following behavior prediction and interpretability.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAffordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\n\nAO-Planner: LLM-based framework for zero-shot VLN tasks, improves SPL by 5.5% on R2R-CE benchmark.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmpowering 1000 tokens/second on-device LLM prefilling with mllm-NPU\n\n\n\narchitectures\n\n\neducation\n\n\nproduction\n\n\n\nmllm-NPU: A system for fast, energy-efficient on-device LLM inference, achieving 22.4x faster prefill speed and 30.7x energy savings.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPAS: Data-Efficient Plug-and-Play Prompt Augmentation System\n\n\n\narchitectures\n\n\nsocial-sciences\n\n\nprompt-engineering\n\n\nproduction\n\n\n\nPAS is a plug-and-play AI system for prompt engineering, offering high performance, efficiency, and flexibility for LLMs.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPsycoLLM: Enhancing LLM for Psychological Understanding and Evaluation\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nPsycoLLM: A Specialized Psychological LLM Outperforms Others in Mental Health Support.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHecaton: Training and Finetuning Large Language Models with Scalable Chiplet Systems\n\n\n\narchitectures\n\n\n\nHecaton: A chiplet system for LLM training, reducing DRAM accesses and NoP overheads, offering 4.98× performance boost and 2.35× energy reduction.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization\n\n\n\nhci\n\n\nproduction\n\n\narchitectures\n\n\nsocial-sciences\n\n\neducation\n\n\n\nLLMs can extract data context but struggle with visual tasks, despite being sensitive to uncertainties in utterances.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInverseCoder: Unleashing the Power of Instruction-Tuned Code LLMs with Inverse-Instruct\n\n\n\neducation\n\n\nprogramming\n\n\n\nInverseCoder improves code LLMs by self-generating instructions, outperforming original models.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Human-LLM Conversations: Mental Models and the Originator of Toxicity\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs provide toxic content mainly due to human demand or provocation.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmpirical Study of Symmetrical Reasoning in Conversational Chatbots\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nChatbots show varied ability to understand predicate symmetry, with some nearing human-like reasoning.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArtificial Intuition: Efficient Classification of Scientific Abstracts\n\n\n\narchitectures\n\n\nproduction\n\n\n\nNew method uses LLM to classify NASA abstracts, aiding strategic research insights.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssessing Code Generation with Intermediate Languages\n\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\n[TEXT] Abstract: This study examines the relationship between CEO narcissism and firm performance. Results indicate that narcissistic CEOs are associated with lower firm…\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Model as an Assignment Evaluator: Insights, Feedback, and Challenges in a 1000+ Student Course\n\n\n\nrobustness\n\n\neducation\n\n\n\nLLM-based evaluators, like GPT-4, can be used in classrooms, but students can manipulate them and they may not always follow instructions.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions\n\n\n\nsocial-sciences\n\n\n\nLLMs excel in binary gender prediction but struggle with gender-neutral names, especially non-English ones; birth year data doesn’t improve accuracy.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Hallucination Detection through Perturbation-Based Synthetic Data Generation in System Responses\n\n\n\nrobustness\n\n\n\nAutomatic generation of faithful/hallucinated outputs improves LLM hallucination detection.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFaux Polyglot: A Study on Information Disparity in Multilingual Large Language Models\n\n\n\nsocial-sciences\n\n\n\nLLMs in RAG-based search favor same-language info, reinforcing dominant views and potentially marginalizing low-resource languages.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the Educational Landscape of AI: Large Language Models’ Approaches to Explaining Conservation of Momentum in Physics\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLMs vary in explaining physics concepts; educator guidance crucial for effective use in teaching.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCLIMB: A Benchmark of Clinical Bias in Large Language Models\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs in clinical tasks exhibit bias; CLIMB benchmark introduced to evaluate intrinsic and extrinsic bias.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCollective Innovation in Groups of Large Language Models\n\n\n\nsocial-sciences\n\n\neducation\n\n\nhci\n\n\n\nLLMs playing a video game show collective innovation, with dynamic connectivity boosting performance.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExperiments with truth using Machine Learning: Spectral analysis and explainable classification of synthetic, false, and genuine information\n\n\n\nsocial-sciences\n\n\n\nLLMs contribute to misinformation; ML algorithms struggle to distinguish fake from genuine text.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Computer Programming Education with LLMs: A Study on Effective Prompt Engineering for Python Code Generation\n\n\n\neducation\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\nLLMs, like GPT-4o, excel in programming education with tailored prompt strategies, offering personalized instruction and improved learning outcomes.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHarnessing the Power of LLMs: Automating Unit Test Generation for High-Performance Computing\n\n\n\nrobustness\n\n\nprogramming\n\n\n\nLLMs like Davinci and ChatGPT can generate syntactically correct unit tests for parallel and high-performance software, but may have limitations like repetitive assertions…\n\n\n\nJul 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMCloudHunter: Harnessing LLMs for Automated Extraction of Detection Rules from Cloud-Based CTI\n\n\n\nsecurity\n\n\n\nLLMCloudHunter: Automated OSCTI analysis for cloud threats, using LLMs for high-precision rule generation.\n\n\n\nJul 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSafe Unlearning: A Surprisingly Effective and Generalizable Solution to Defend Against Jailbreak Attacks\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nTL;DR: Unlearning harmful knowledge in LLMs effectively defends against jailbreak attacks, outperforming traditional fine-tuning methods.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nLLMs show potential for epilepsy diagnosis, but pitfalls like overconfidence and hallucinations exist.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJailbreakHunter: A Visual Analytics Approach for Jailbreak Prompts Discovery from Large-Scale Human-LLM Conversational Datasets\n\n\n\nrobustness\n\n\nhci\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nJailbreakHunter: A visual analytics approach to identify LLM jailbreak prompts in large-scale conversational datasets.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSingle Character Perturbations Break LLM Alignment\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nAdding a space to prompts can bypass safety measures in language models, causing harmful outputs.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Comparative Study of DSL Code Generation: Fine-Tuning vs. Optimized Retrieval Augmentation\n\n\n\nrobustness\n\n\nprogramming\n\n\n\nLLMs struggle with DSLs, but optimized RAG models can match fine-tuned models and handle new APIs better.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCactus: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory\n\n\n\nhci\n\n\nprompt-engineering\n\n\n\nCamel model, trained on Cactus dataset, outperforms others in counseling skills, ensuring privacy and accessibility.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFSM: A Finite State Machine Based Zero-Shot Prompting Paradigm for Multi-Hop Question Answering\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nFSM prompting enhances LLMs’ reasoning, improving accuracy and trustworthiness in complex tasks, mitigating hallucination, and easing answer interpretation.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMG-Verilog: Multi-grained Dataset Towards Enhanced LLM-assisted Verilog Generation\n\n\n\nprogramming\n\n\n\nLLMs aid hardware design, but datasets are limited. New criteria for high-quality hardware datasets proposed, along with a Multi-Grained-Verilog dataset and a balanced…\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel-Enhanced LLM-Driven VUI Testing of VPA Apps\n\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nElevate, a VUI testing framework, uses LLMs for better natural language processing, improving state space coverage and efficiency compared to Vitas.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the Capabilities of LLMs for Code Change Related Tasks\n\n\n\neducation\n\n\nprogramming\n\n\n\nLLMs struggle with code-change tasks, but improve with examples. Larger models aren’t always better, but Llama 2 and Code Llama are top performers.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Watermarking: Safeguarding Your Video from (Unauthorized) Annotations by Video-based LLMs\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nVideo Watermarking secures video content from unauthorized annotations by video-based LLMs, preserving integrity and confidentiality.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScreenTK: Seamless Detection of Time-Killing Moments Using Continuous Mobile Screen Text Monitoring\n\n\n\nrobustness\n\n\n\nScreenTK detects time-killing moments on smartphones using continuous screen text monitoring and on-device large language models, outperforming current methods.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output\n\n\n\neducation\n\n\n\nIXC-2.5: 7B LLM model excels in long-context text-image tasks, outperforming open-source SOTA models on 16 benchmarks.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models\n\n\n\nhci\n\n\neducation\n\n\n\nGraCoRe benchmark evaluates LLMs’ graph comprehension and reasoning, revealing insights on semantic enrichment, node ordering, and text length impact.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts\n\n\n\nprogramming\n\n\n\nTheoremLlama: LLM framework for formal theorem proving outperforms GPT-4.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSocial Bias Evaluation for Large Language Models Requires Prompt Variations\n\n\n\nrobustness\n\n\nsocial-sciences\n\n\nhci\n\n\nprompt-engineering\n\n\n\nLLMs’ performance and bias vary greatly with prompts; diverse prompts are recommended for accurate comparison.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-Evaluation as a Defense Against Adversarial Attacks on LLMs\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nAdding a space to prompts can bypass safety measures in language models, causing harmful outputs.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Conversational Abilities of Quantized Large Language Models via Direct Preference Alignment\n\n\n\neducation\n\n\nhci\n\n\n\nQDPO improves quantized LLMs’ conversational abilities, outperforming PTQ and knowledge-distillation fine-tuning techniques.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet the Code LLM Edit Itself When You Edit the Code\n\n\n\nrobustness\n\n\nprogramming\n\n\n\nPIE reduces 85% computational overhead in real-time code editing, maintaining model performance.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow Does Quantization Affect Multilingual LLMs?\n\n\n\nsocial-sciences\n\n\n\nQuantization harms multilingual LLMs, especially non-Latin script languages and complex tasks, despite automatic metrics underestimating the impact.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObfuscaTune: Obfuscated Offsite Fine-tuning and Inference of Proprietary LLMs on Private Datasets\n\n\n\nsecurity\n\n\n\nObfuscaTune: A method for private LLM finetuning on cloud, preserving utility and confidentiality.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models\n\n\n\nprompt-engineering\n\n\n\nDCoT method improves LLM performance by comparing multiple reasoning chains, enabling self-correction.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLoRA-Guard: Parameter-Efficient Guardrail Adaptation for Content Moderation of Large Language Models\n\n\n\nrobustness\n\n\n\nLoRA-Guard: Efficient, On-Device Content Moderation for LLMs with Minimal Performance Impact.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Affects the Stability of Tool Learning? An Empirical Study on the Robustness of Tool Learning Frameworks\n\n\n\nrobustness\n\n\neducation\n\n\n\nTool learning in LLMs varies by factors like tasks, data, and algorithms. Exploring these impacts can improve LLM integration in real-world applications.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSOS! Soft Prompt Attack Against Open-Source Large Language Models\n\n\n\nrobustness\n\n\nprogramming\n\n\nsecurity\n\n\n\nNew attack, SOS, targets open-source LLMs, maintaining model utility. Also introduces copyright token for content protection.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLANE: Logic Alignment of Non-tuning Large Language Models and Online Recommendation Systems for Explainable Reason Generation\n\n\n\nrecommender\n\n\n\nLANE strategy aligns LLMs with recommendation systems, improving explainability without additional tuning.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRaw Text is All you Need: Knowledge-intensive Multi-turn Instruction Tuning for Large Language Model\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nR2S framework uses CoD logic to guide LLMs in generating knowledge-intensive dialogues for instruction tuning, enhancing LLM adaptability and effectiveness.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCogErgLLM: Exploring Large Language Model Systems Design Perspective Using Cognitive Ergonomics\n\n\n\nhci\n\n\n\nIntegrate cognitive ergonomics in LLM design for safer, reliable, and ethical human-AI interactions.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models as Evaluators for Scientific Synthesis\n\n\n\nprogramming\n\n\n\nLLMs can logically rate scientific summaries but weakly correlate with human ratings, indicating potential and limitations in evaluation.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre Large Language Models Consistent over Value-laden Questions?\n\n\n\nrobustness\n\n\neducation\n\n\n\nLLMs show consistency across paraphrases, use-cases, and translations, but inconsistencies remain, especially on controversial topics.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM Internal States Reveal Hallucination Risk Faced With a Query\n\n\n\nrobustness\n\n\n\nLLMs can estimate their own hallucination risk before response generation, achieving 84.32% accuracy.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSynthetic Multimodal Question Generation\n\n\n\nhci\n\n\n\nSMMQG generates style-specific MMRAG questions from multimodal documents, rivaling human-generated data quality.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssessing the Code Clone Detection Capability of Large Language Models\n\n\n\nrobustness\n\n\nprogramming\n\n\n\nGPT-4 outperforms GPT-3.5 in code clone detection, but both struggle with complex clones and human-generated code. Improvements are needed for LLM code clone recognition.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCFinBench: A Comprehensive Chinese Financial Benchmark for Large Language Models\n\n\n\neducation\n\n\n\nTL;DR: CFinBench evaluates financial knowledge of LLMs in Chinese context, revealing a 60.16% highest average accuracy.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSupporters and Skeptics: LLM-based Analysis of Engagement with Mental Health (Mis)Information Content on Video-sharing Platforms\n\n\n\nhci\n\n\n\nStudy finds mental health misinformation on YouTube Shorts and Bitchute, with distinct audience engagement patterns and potential harm to public health.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKGym: A Platform and Dataset to Benchmark Large Language Models on Linux Kernel Crash Resolution\n\n\n\nprogramming\n\n\n\nLLMs struggle with Linux kernel crashes, achieving 0.72%-5.38% success. Further research needed for SE tasks.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nS2D: Sorted Speculative Decoding For More Efficient Deployment of Nested Large Language Models\n\n\n\nhci\n\n\n\nTL;DR: New method improves speculative decoding for multiple large language models, reducing costs.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHelpful assistant or fruitful facilitator? Investigating how personas affect language model behavior\n\n\n\nhci\n\n\neducation\n\n\n\nPersonas in LLMs cause more varied responses than control, with some behaviors consistent across models.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the Role of Transliteration in In-Context Learning for Low-resource Languages Written in Non-Latin Scripts\n\n\n\nprompt-engineering\n\n\n\nTransliteration can improve LLMs’ performance for low-resource, non-Latin languages, especially in sequential labeling tasks.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Steering and Verification in AI-Assisted Data Analysis with Interactive Task Decomposition\n\n\n\neducation\n\n\n\nStepwise, Phasewise systems offer better control, intervention, and verification in AI-assisted data analysis, compared to conversational baselines.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCEB: Compositional Evaluation Benchmark for Fairness in Large Language Models\n\n\n\nhci\n\n\n\nCEB: A Comprehensive Benchmark for Evaluating Bias in Large Language Models.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTalking to Machines: do you read me?\n\n\n\neducation\n\n\nhci\n\n\n\n[TEXT] Abstract: This study examines the impact of social media on the mental health of adolescents. Results indicate a significant correlation between excessive social…\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerative Monoculture in Large Language Models\n\n\n\nhci\n\n\nprogramming\n\n\n\nGenerative Monoculture in LLMs narrows output diversity, potentially limiting perspectives; simple countermeasures insufficient, suggesting need for diverse fine-tuning…\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Alignment in Multimodal LLMs: A Comprehensive Study\n\n\n\nrobustness\n\n\n\nTL;DR: Combining offline and online methods improves MLLMs, BDHS aids multimodal preference data creation.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification\n\n\n\nprompt-engineering\n\n\n\nPelican framework reduces LVLMs’ hallucinations by 8-32% via claim verification, outperforming existing mitigation approaches.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRVISA: Reasoning and Verification for Implicit Sentiment Analysis\n\n\n\nprompt-engineering\n\n\n\nRVISA: A two-stage framework for implicit sentiment analysis using LLMs, achieving state-of-the-art results.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultilingual Trolley Problems for Language Models\n\n\n\nhci\n\n\n\nLLMs’ moral decisions vary by language; more aligned with English, Korean, Hungarian, and Chinese, less with Hindi and Somali. Fairness dominates GPT-4’s choices…\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Visual Storytelling with Multimodal Large Language Models\n\n\n\neducation\n\n\nhci\n\n\n\nThis paper presents a novel approach using LLMs and LVLMs with instruction tuning for generating coherent and emotionally resonant visual stories, outperforming existing…\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGRASP: A Grid-Based Benchmark for Evaluating Commonsense Spatial Reasoning\n\n\n\neducation\n\n\n\nLLMs like GPT-3.5-Turbo and GPT-4o struggle with satisfactory solutions in spatial reasoning tasks, as shown by the GRASP benchmark.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSoP: Unlock the Power of Social Facilitation for Automatic Jailbreak Attack\n\n\n\nsecurity\n\n\n\nSoP framework generates jailbreak prompts, bypassing GPT-3.5 and GPT-4 safety with 88% and 60% success, respectively.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLEXI: Large Language Models Experimentation Interface\n\n\n\nhci\n\n\n\nLEXI, a new open-source tool, simplifies deploying LLM-powered agents in social interaction experiments, with positive usability testing results.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBreaking Bias, Building Bridges: Evaluation and Mitigation of Social Biases in LLMs via Contact Hypothesis\n\n\n\nhci\n\n\n\nLLMs exhibit social biases, but a new debiasing technique, Social Contact Debiasing (SCD), can reduce these biases by up to 40% in one epoch of instruction tuning.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention\n\n\n\nprompt-engineering\n\n\n\nMInference speeds up LLM pre-filling by 10x, maintaining accuracy via sparse calculation methods for long-context attention matrices.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmbodied AI in Mobile Robots: Coverage Path Planning with Large Language Models\n\n\n\nprogramming\n\n\n\nLLM-based path planning framework for mobile agents improves spatial inference and coverage planning, with claude-3.5 showing the best performance.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt during Large Language Model Fine-tuning\n\n\n\nprompt-engineering\n\n\n\nPromptIntern: LLM method reduces inference tokens by 90%, speeds up inference 4.2x, and saves 88.3% monetary cost.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs Your AI-Generated Code Really Secure? Evaluating Large Language Models on Secure Code Generation with CodeSecEval\n\n\n\nrobustness\n\n\nprogramming\n\n\nsecurity\n\n\n\nLLMs for code generation/repair risk security vulnerabilities. This study evaluates and enhances their security, introducing CodeSecEval dataset and strategies to mitigate…\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogEval: A Comprehensive Benchmark Suite for Large Language Models In Log Analysis\n\n\n\neducation\n\n\nhci\n\n\n\n[TEXT] This study examines the impact of climate change on the migration patterns of polar bears in the Arctic. Results indicate that as sea ice diminishes, polar bears are…\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond Numeric Awards: In-Context Dueling Bandits with LLM Agents\n\n\n\nsecurity\n\n\n\nLLMs, like GPT-4 Turbo, excel in identifying Condorcet winners in Dueling Bandits, but struggle with convergence. An LLM-augmented algorithm, IF-Enhanced LLM, improves…\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Multilingual Instruction Finetuning via Linguistically Natural and Diverse Datasets\n\n\n\neducation\n\n\nprogramming\n\n\n\nNew method for multilingual IFT datasets improves LLM performance in non-English contexts, boosting summarization by up to 17.57%.\n\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMIRAI: Evaluating LLM Agents for Event Forecasting\n\n\n\nprogramming\n\n\n\nMirai benchmark evaluates LLM agents’ forecasting skills for international events, assessing their ability to source, integrate, and reason with diverse information.\n\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTCSR-SQL: Towards Table Content-aware Text-to-SQL with Self-retrieval\n\n\n\nprogramming\n\n\n\nTL;DR: TCSR-SQL improves Text-to-SQL performance by 13.7% with self-retrieval and in-context learning.\n\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscoveryBench: Towards Data-Driven Discovery with Large Language Models\n\n\n\nprogramming\n\n\n\nLLMs struggle with autonomous data-driven discovery, scoring only 25% on the DiscoveryBench benchmark.\n\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-Cognition in Large Language Models: An Exploratory Study\n\n\n\nhci\n\n\n\nLLMs like Command R and Llama-3-70b-Instruct show detectable self-cognition, which improves tasks like creative writing.\n\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAgentless: Demystifying LLM-based Software Engineering Agents\n\n\n\nprogramming\n\n\n\nAgentless, a simple two-phase LLM approach, outperforms complex software agents in solving software development problems, offering higher performance and lower cost.\n\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAligning Teacher with Student Preferences for Tailored Training Data Generation\n\n\n\narchitectures\n\n\neducation\n\n\nprompt-engineering\n\n\n\nARTE: A framework aligning teacher models with student preferences for tailored training examples in Knowledge Distillation.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSubtractive Training for Music Stem Insertion using Latent Diffusion Models\n\n\n\nproduction\n\n\n\n[TEXT] This study examines the impact of climate change on the frequency and intensity of hurricanes in the Atlantic Ocean. Results suggest a significant increase in both…\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAveraging log-likelihoods in direct alignment\n\n\n\narchitectures\n\n\nsocial-sciences\n\n\n\nDirect alignment methods for LLMs are made length-invariant, improving alignment with human judgment.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLayoutCopilot: An LLM-powered Multi-agent Collaborative Framework for Interactive Analog Layout Design\n\n\n\nhci\n\n\nprompt-engineering\n\n\neducation\n\n\n\n[TEXT] The Impact of Social Media on College Students’ Academic Performance: A Review of Literature [TL;DR] Social media negatively affects college students’ academic…\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDisentangling Knowledge-based and Visual Reasoning by Question Decomposition in KB-VQA\n\n\n\nhci\n\n\neducation\n\n\n\nDecomposing complex questions into simpler ones improves visual question-answering performance, boosting accuracy by up to 2% on three datasets.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFine-tuned network relies on generic representation to solve unseen cognitive task\n\n\n\narchitectures\n\n\n\nFine-tuned models rely on pretrained representations, while scratch-trained models develop task-specific mechanisms.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFairness and Bias in Multimodal AI: A Survey\n\n\n\nsocial-sciences\n\n\n\nTL;DR: This survey highlights fairness and bias in Large Multimodal Models, offering 50 examples and discussing challenges, including a new preuse bias category.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?\n\n\n\nproduction\n\n\n\nModel editing in language models critiqued, 12 open problems identified, semi-synthetic dataset proposed for evaluation.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation\n\n\n\nproduction\n\n\nsecurity\n\n\nrobustness\n\n\n\nRAG systems’ security is explored using Membership Inference Attacks, achieving 82% ROC AUC in identifying database membership.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nContrastive Policy Gradient: Aligning LLMs on sequence-level scores in a supervised-friendly fashion\n\n\n\narchitectures\n\n\n\nCoPG: A new RL algorithm for off-policy policy gradient, optimizing LLMs with arbitrary rewards, and generalizing IPO and classic policy gradient.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSonnet or Not, Bot? Poetry Evaluation for Large Models and Datasets\n\n\n\neducation\n\n\nsocial-sciences\n\n\n\nLLMs can recognize poetic form, but challenges remain in evaluating their poetic capabilities and creating NLP benchmarks for poetry.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhysioLLM: Supporting Personalized Health Insights with Wearables and Large Language Models\n\n\n\nproduction\n\n\n\nPhysioLLM uses LLMs to analyze wearable data, offering personalized health insights and actionable goals, outperforming commercial health apps in a sleep quality case study.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEfficient course recommendations with T5-based ranking and summarization\n\n\n\narchitectures\n\n\nrecommender\n\n\neducation\n\n\n\nT5-based re-ranking and summarization improve course recommendation relevance, but speed and interpretability also matter in online evaluation.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan we teach language models to gloss endangered languages?\n\n\n\nsocial-sciences\n\n\n\nLLMs can generate interlinear glossed text with in-context learning, outperforming transformer baselines without training, but still lag behind supervised systems.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nT-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings\n\n\n\narchitectures\n\n\n\nT-Free: A novel tokenizer for LLMs, reducing parameters by 85% and improving cross-lingual transfer, without needing a reference corpus.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimulating Classroom Education with LLM-Empowered Agents\n\n\n\neducation\n\n\nprompt-engineering\n\n\nhci\n\n\narchitectures\n\n\nsocial-sciences\n\n\n\nLLMs can simulate classroom interactions, improving user experience in a multi-agent framework, as demonstrated by SimClass.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJump Starting Bandits with LLM-Generated Prior Knowledge\n\n\n\nrecommender\n\n\nproduction\n\n\n\nLLMs improve contextual bandits in recommendation systems, reducing regret and data-gathering costs.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLICO: Large Language Models for In-Context Molecular Optimization\n\n\n\nprompt-engineering\n\n\n\nLICO enhances LLMs for black-box optimization, excelling in molecular property optimization via in-context prompting.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMethodology of Adapting Large English Language Models for Specific Cultural Contexts\n\n\n\nsocial-sciences\n\n\n\nLLMs adapted for specific cultures, like Chinese, improve domain knowledge and safety values without losing expertise.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nELCoRec: Enhance Language Understanding with Co-Propagation of Numerical and Categorical Features for Recommendation\n\n\n\nrecommender\n\n\nhci\n\n\nprompt-engineering\n\n\neducation\n\n\n\nTL;DR: ELCoRec enhances language models for recommendation by co-propagating numerical and categorical features, improving preference understanding and recent interest…\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssessing the Effectiveness of LLMs in Android Application Vulnerability Analysis\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nLLMs’ strengths and weaknesses in detecting Android code vulnerabilities are analyzed, highlighting the potential of context augmentation with RAG for secure app development.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUniGen: A Unified Framework for Textual Dataset Generation Using Large Language Models\n\n\n\narchitectures\n\n\n\nUniGen: LLM-powered framework for diverse, accurate, and controllable dataset generation, enhancing data quality and supporting benchmarking, data augmentation.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSTBench: Assessing the Ability of Large Language Models in Spatio-Temporal Analysis\n\n\n\narchitectures\n\n\neducation\n\n\nprompt-engineering\n\n\n\nSTBench evaluates LLMs’ spatio-temporal understanding across 13 tasks, revealing strengths and areas for improvement.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLiveBench: A Challenging, Contamination-Free LLM Benchmark\n\n\n\narchitectures\n\n\nproduction\n\n\nsocial-sciences\n\n\nrobustness\n\n\n\nLiveBench: A dynamic, contamination-free LLM benchmark with diverse tasks and automatic scoring.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale\n\n\n\nproduction\n\n\n\nPubMedVision dataset improves medical multimodal capabilities of MLLMs, outperforming other data construction methods.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models\n\n\n\nprompt-engineering\n\n\n\nLLMs can excel in low-resource languages with Self-Supervised Prompting, a novel ICL approach for zero-label cross-lingual transfer.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Remarkable Robustness of LLMs: Stages of Inference?\n\n\n\narchitectures\n\n\nproduction\n\n\n\nTL;DR: Large Language Models remain accurate despite deleting or swapping layers, suggesting four universal inference stages.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation\n\n\n\narchitectures\n\n\nproduction\n\n\n\nAutoRAG-HP optimizes RAG hyper-parameters using a novel Hierarchical MAB method, reducing LLM API calls by 80% compared to Grid Search.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCapturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nRPLMs enhanced with personality data improve role-playing abilities in dialogue.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Weak-to-Strong Generalization with Reliability-Aware Alignment\n\n\n\narchitectures\n\n\n\nApproach improves weak-to-strong generalization in LLMs by estimating weak supervision reliability, reducing error propagation, and enhancing accuracy.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFFN: a Fine-grained Chinese-English Financial Domain Parallel Corpus\n\n\n\neducation\n\n\n\nLLMs’ financial translation quality is evaluated, revealing room for improvement and optimization.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data\n\n\n\narchitectures\n\n\nproduction\n\n\n\nFinetuning LLMs on synthetic data enhances their long-context information retrieval and reasoning skills, with minimal impact on general benchmark performance.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOMG-LLaVA: Bridging Image-level, Object-level, Pixel-level Reasoning and Understanding\n\n\n\neducation\n\n\nprompt-engineering\n\n\nhci\n\n\narchitectures\n\n\nproduction\n\n\n\nOMG-LLaVA: A framework for pixel-level vision understanding with reasoning abilities, accepting visual and text prompts.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Model Arena for Cross-lingual Sentiment Analysis: A Comparative Study in the Era of Large Language Models\n\n\n\nhci\n\n\nproduction\n\n\nsocial-sciences\n\n\n\nSMLMs outperform LLMs in zero-shot cross-lingual sentiment analysis, but LLMs improve in few-shot settings. Proprietary GPT models excel in zero-shot, but lag in few-shot…\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutoPureData: Automated Filtering of Web Data for LLM Fine-tuning\n\n\n\narchitectures\n\n\nproduction\n\n\n\nSystem filters web data for AI training, ensuring purity and reliability.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Teacher Is Worth A Million Instructions\n\n\n\narchitectures\n\n\n\nImproved training method for smaller LLMs using larger models and domain-specific knowledge, outperforming larger models.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTools Fail: Detecting Silent Errors in Faulty Tools\n\n\n\narchitectures\n\n\nproduction\n\n\n\nLLMs can detect silent tool errors and plan better, improving their use as tools.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHierarchical Context Pruning: Optimizing Real-World Code Completion with Repository-Level Pretrained Code LLMs\n\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\nHCP strategy improves Code LLMs’ accuracy by pruning irrelevant code, reducing input length.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApplying LLMs for Rescoring N-best ASR Hypotheses of Casual Conversations: Effects of Domain Adaptation and Context Carry-over\n\n\n\narchitectures\n\n\n\nLLMs like Llama2 improve ASR in casual conversations, even without domain adaptation, and reduce computational cost with adaptation.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAMBROSIA: A Benchmark for Parsing Ambiguous Questions into Database Queries\n\n\n\narchitectures\n\n\n\nAMBROSIA benchmark tests LLMs on interpreting ambiguous text-to-SQL queries, revealing challenges for advanced models.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmPO: Theory-Driven Dataset Construction for Empathetic Response Generation through Preference Optimization\n\n\n\narchitectures\n\n\nrecommender\n\n\nhci\n\n\n\nTL;DR: We propose a novel approach for empathetic response generation using LLMs and preference optimization, with public datasets and models.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRevealing Fine-Grained Values and Opinions in Large Language Models\n\n\n\nhci\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nTL;DR: Analyzing 156k LLM responses to PCT reveals biases, disparities, and recurring text patterns influenced by prompts and demographic features.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuri: Multi-constraint Instruction Following for Long-form Text Generation\n\n\n\narchitectures\n\n\nproduction\n\n\n\nSuri-I-ORPO generates longer, coherent, and preferred long-form texts from complex instructions, outperforming base models.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions\n\n\n\neducation\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nDiVERT outperforms state-of-the-art distractor generation methods in math MCQs, using a 7B parameter LLM and producing human-like error labels.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs ChatGPT a Better Explainer than My Professor?: Evaluating the Explanation Capabilities of LLMs in Conversation Compared to a Human Baseline\n\n\n\neducation\n\n\n\nLLMs can enhance expert explainers’ conversational skills, improving science communication, especially when using concise responses and thought-provoking questions.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn Empirical Study of Unit Test Generation with Large Language Models\n\n\n\neducation\n\n\nprompt-engineering\n\n\nrobustness\n\n\n\nTL;DR: Study explores open-source LLMs for unit test generation, comparing them to commercial GPT-4 and traditional Evosuite, highlighting prompt factors and limitations.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJailbreaking LLMs with Arabic Transliteration and Arabizi\n\n\n\nprompt-engineering\n\n\nsecurity\n\n\nrobustness\n\n\n\nLLMs vulnerable to jailbreak attacks in Arabic, especially in transliteration and chatspeak, potentially exposing hidden information.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Entity Recognition Using Ensembles of Deep Learning and Fine-tuned Large Language Models: A Case Study on Adverse Event Extraction from Multiple Sources\n\n\n\nsocial-sciences\n\n\n\nThis study compares traditional deep learning models and LLMs for AE extraction, showing that ensembling these models improves performance.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelective Prompting Tuning for Personalized Conversations with LLMs\n\n\n\nrecommender\n\n\nhci\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nSelective Prompt Tuning improves LLMs’ personalized dialogue, enhancing response diversity by up to 90%.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBADGE: BADminton report Generation and Evaluation with LLM\n\n\n\nsocial-sciences\n\n\n\nTL;DR: GPT-4 can generate and evaluate high-quality badminton match reports, outperforming human judges.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConvoCache: Smart Re-Use of Chatbot Responses\n\n\n\nprompt-engineering\n\n\n\nConvoCache speeds up chatbots by reusing past responses, reducing AI usage by up to 89% with 214ms latency. Prefetching offers limited benefits.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHuman-AI Collaborative Taxonomy Construction: A Case Study in Profession-Specific Writing Assistants\n\n\n\nhci\n\n\n\nLLMs’ effectiveness in business writing is limited. Proposed: human-AI collaborative taxonomy development for domain-specific writing assistants.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssertionBench: A Benchmark to Evaluate Large-Language Models for Assertion Generation\n\n\n\nprompt-engineering\n\n\nsecurity\n\n\nrobustness\n\n\n\nLLMs evaluated for hardware assertion generation; benchmark used for quantitative comparison.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-Driven Multimodal Opinion Expression Identification\n\n\n\nsocial-sciences\n\n\n\nThis study enhances Opinion Expression Identification (OEI) with multimodal inputs, improving performance and achieving state-of-the-art results.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNatural Language but Omitted? On the Ineffectiveness of Large Language Models’ privacy policy from End-users’ Perspective\n\n\n\nhci\n\n\n\n[TEXT] This study explores the relationship between social media use and mental health in young adults. Results suggest a negative correlation between excessive social media…\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMs for Doctors: Leveraging Medical LLMs to Assist Doctors, Not Replace Them\n\n\n\nrobustness\n\n\n\nLLMs as medical assistants face challenges, but our DoctorFLAN dataset and benchmarks can significantly improve their performance, complementing patient-oriented work.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLifelong Robot Library Learning: Bootstrapping Composable and Generalizable Skills for Embodied Control with Language Models\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLRLL: LLM-based agent grows robot skill library for complex tasks, outperforming end-to-end and vanilla LLM approaches.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMath-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models\n\n\n\neducation\n\n\n\nMath-LLaVA: New Model Improves Multimodal Math Reasoning with Diverse Dataset\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFactFinders at CheckThat! 2024: Refining Check-worthy Statement Detection with LLMs through Data Pruning\n\n\n\nprogramming\n\n\n\nThis study explores using open-source LLMs to identify check-worthy political statements, proposing a data pruning approach for efficient learning.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdversarial Search Engine Optimization for Large Language Models\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nAttackers can manipulate LLMs to favor their content, degrading overall LLM performance.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs In-Context Learning a Type of Gradient-Based Learning? Evidence from the Inverse Frequency Effect in Structural Priming\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nICL in LLMs is a form of gradient-based learning, as they display the inverse frequency effect, similar to human structural priming.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSafeAligner: Safety Alignment against Jailbreak Attacks via Response Disparity Guidance\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nSafeAligner method improves LLM security, balancing safety and utility by comparing outputs of safety-focused and risk-prone models.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCategorical Syllogisms Revisited: A Review of the Logical Reasoning Abilities of LLMs for Analyzing Categorical Syllogism\n\n\n\nhci\n\n\n\nCurrent benchmarks for LLMs’ logical reasoning have limitations. Quantifier interpretation is a bottleneck, and future dataset releases should consider this.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWildGuard: Open One-Stop Moderation Tools for Safety Risks, Jailbreaks, and Refusals of LLMs\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nWildGuard is an open-source LLM safety tool that excels in identifying harmful prompts, detecting safety risks, and determining model refusal rates, outperforming existing…\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMental Modeling of Reinforcement Learning Agents by Language Models\n\n\n\nhci\n\n\n\nLLMs currently can’t fully mental model agents via inference alone, revealing their limitations.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymbolic Learning Enables Self-Evolving Agents\n\n\n\nprompt-engineering\n\n\n\nAgent Symbolic Learning enables language agents to self-optimize and evolve, transitioning from model-centric to data-centric AI, potentially advancing AGI.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWildTeaming at Scale: From In-the-Wild Jailbreaks to (Adversarially) Safer Language Models\n\n\n\nsecurity\n\n\n\nNew framework discovers 5.7K unique jailbreak tactics, creating a large-scale safety dataset for safer AI chatbots.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLLMs as evaluation metrics: Large-scale prompt exploration reveals stability and variability in MT and summarization tasks.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMALSIGHT: Exploring Malicious Source Code and Benign Pseudocode for Iterative Binary Malware Summarization\n\n\n\nprogramming\n\n\nsecurity\n\n\n\nMalsight, a novel code summarization framework, generates malware behavior descriptions from executables, improving usability, accuracy, and completeness. It outperforms…\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDetecting Machine-Generated Texts: Not Just AI vs Humans and Explainability is Complicated\n\n\n\nsocial-sciences\n\n\n\nThis study introduces a ternary text classification for LLM-generated text detection, emphasizing the need for explainable results and proposing guidelines for future…\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoisoned LangChain: Jailbreak LLMs by LangChain\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nPoisoned-LangChain: Novel method for indirect jailbreak attacks on LLMs, achieving 88.56%, 79.04%, and 82.69% success rates in three scenarios.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFew-shot Personalization of LLMs with Mis-aligned Responses\n\n\n\nprompt-engineering\n\n\n\nFermi: New approach for few-shot personalization of LLMs using mis-aligned responses, improving performance across benchmarks.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMathOdyssey: Benchmarking Mathematical Problem-Solving Skills in Large Language Models Using Odyssey Math Data\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLMs excel at basic math but struggle with complex problems, per the MathOdyssey dataset. Open-source models are closing the gap with closed-source models.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Data Privacy in Large Language Models through Private Association Editing\n\n\n\nrobustness\n\n\n\nPAE: A novel defense for LLMs to remove private data without retraining, ensuring data privacy and model consistency.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHierarchical Context Pruning: Optimizing Real-World Code Completion with Repository-Level Pretrained Code LLMs\n\n\n\nprogramming\n\n\n\nHCP strategy improves Code LLMs’ completion accuracy by pruning irrelevant code content, reducing input length.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThemis: Towards Flexible and Interpretable NLG Evaluation\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nNew NLG Evaluation Corpus and Model, Themis, Outperforms GPT-4 in Flexible, Reference-Free Evaluations.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCatching Chameleons: Detecting Evolving Disinformation Generated using Large Language Models\n\n\n\nrobustness\n\n\n\nDELD method outperforms in detecting evolving disinformation from LLMs, addressing efficiency and performance challenges.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPsychological Profiling in Cybersecurity: A Look at LLMs and Psycholinguistic Features\n\n\n\nhci\n\n\nsocial-sciences\n\n\nsecurity\n\n\n\nPsychological profiling and LLMs can enhance cybersecurity by analyzing threat actors’ textual data for psychological traits.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMs instead of Human Judges? A Large Scale Empirical Study across 20 NLP Evaluation Tasks\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLLMs vary greatly in replicating human annotations, suggesting they’re not yet reliable substitutes for human NLP evaluations.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Large Language Model Aided Program Refinement\n\n\n\nprogramming\n\n\neducation\n\n\nprompt-engineering\n\n\nrobustness\n\n\n\nLLM4PR tool combines formal refinement techniques with LLMs to generate and verify reliable code from specifications, using GPT4 and Coq.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNeBuLa: A discourse aware Minecraft Builder\n\n\n\nsocial-sciences\n\n\n\nTL;DR: Model (NeBuLa) improves language to action tasks by considering conversation context, doubling F1 score over baseline.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Open-World Grasping with Large Vision-Language Models\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\n[TEXT] This study examines the impact of social media on body image and self-esteem in adolescents. Results indicate a significant negative correlation between social media…\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSEED: Accelerating Reasoning Tree Construction via Scheduled Speculative Decoding\n\n\n\nprompt-engineering\n\n\n\nSeeD optimizes LLMs for complex reasoning, offering faster inference and efficient GPU memory management.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLongIns: A Challenging Long-context Instruction-based Exam for LLMs\n\n\n\neducation\n\n\n\nLLMs struggle with long-context tasks; GPT-4 underperforms with 16k context. Multi-hop reasoning needs improvement in short context windows.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRole-Play Zero-Shot Prompting with Large Language Models for Open-Domain Human-Machine Conversation\n\n\n\nhci\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nTL;DR: Role-play zero-shot prompting improves open-domain conversation in LLMs, surpassing fine-tuned models in French.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNew intelligent empowerment for digital transformation\n\n\n\nsocial-sciences\n\n\n\nTL;DR: Study uses LLMs to evaluate DT in firms, finds it boosts financial performance, but effects vary by technology. Blockchain has limited impact.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIRCAN: Mitigating Knowledge Conflicts in LLM Generation via Identifying and Reweighting Context-Aware Neurons\n\n\n\nrobustness\n\n\n\nIRCAN framework improves LLMs’ context-sensitive output, resolving knowledge conflicts.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Context-Driven Approach for Co-Auditing Smart Contracts with The Support of GPT-4 code interpreter\n\n\n\nprompt-engineering\n\n\nsecurity\n\n\nrobustness\n\n\n\nTL;DR: Novel context-driven prompting technique for smart contract co-auditing improves vulnerability detection, outperforming native prompting.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo they mean ‘us’? Interpreting Referring Expressions in Intergroup Bias\n\n\n\nsocial-sciences\n\n\n\nLLMs detect intergroup bias in NFL comments, influenced by win probabilities.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Robustness of LLM-based Speech Synthesis by Learning Monotonic Alignment\n\n\n\nrobustness\n\n\n\nLLM-based TTS models can have errors; proposed techniques improve alignment and robustness without adding new parameters.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models are Interpretable Learners\n\n\n\nprogramming\n\n\n\nLSPs, combining LLMs and symbolic programs, offer interpretable, accurate, and transferable knowledge for decision-making.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBanishing LLM Hallucinations Requires Rethinking Generalization\n\n\n\nrobustness\n\n\n\nLLMs hallucinate due to training loss, not just creativity-factuality balance. MoME and Lamini-1 models can mitigate this issue.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDual-Space Knowledge Distillation for Large Language Models\n\n\n\neducation\n\n\n\nDSKD unifies output spaces for KD, improving LLM compression and enabling KD between models with different vocabularies.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearning to Ask Informative Questions: Enhancing LLMs with Preference Optimization and Expected Information Gain\n\n\n\nhci\n\n\nprompt-engineering\n\n\neducation\n\n\n\nLLM-generated questions improved via Direct Preference Optimization (DPO) for better information gain in 20-question games.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimsChat: A Customisable Persona-Driven Role-Playing Agent\n\n\n\nhci\n\n\n\nLLMs simulate customizable real-world characters for role-playing, offering a framework for human-like agents.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond Demographics: Aligning Role-playing LLM-based Agents Using Human Belief Networks\n\n\n\nhci\n\n\n\nLLMs align better with human beliefs when seeded with a single belief, improving social simulations.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCogMG: Collaborative Augmentation Between Large Language Model and Knowledge Graph\n\n\n\nrobustness\n\n\n\nCogMG framework improves LLM QA accuracy by leveraging knowledge graphs, reducing hallucinations and misalignment issues.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow Well Can Knowledge Edit Methods Edit Perplexing Knowledge?\n\n\n\nrobustness\n\n\n\nPerplexingness of new knowledge impacts editing efficacy in LLMs, with abstract concepts being more challenging to incorporate.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-ARC: Enhancing LLMs with an Automated Reasoning Critic\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLM-ARC improves LLMs’ logical reasoning via an Actor-Critic method, achieving 88.32% accuracy on the FOLIO benchmark.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM Targeted Underperformance Disproportionately Impacts Vulnerable Users\n\n\n\nrobustness\n\n\n\nLLMs’ reliability varies with user traits; lower proficiency, education, and non-US users receive less accurate, truthful, and more refused responses.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicting the Big Five Personality Traits in Chinese Counselling Dialogues Using Large Language Models\n\n\n\nhci\n\n\n\nLLMs can predict Big Five personality traits from counseling dialogues, outperforming traditional methods.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan Large Language Models Understand DL-Lite Ontologies? An Empirical Study\n\n\n\neducation\n\n\n\nLLMs can understand DL-Lite ontologies’ syntax and semantics but struggle with transitivity and large ABoxes.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMitigating Hallucination in Fictional Character Role-Play\n\n\n\nhci\n\n\nsecurity\n\n\nrobustness\n\n\n\nRoleFact reduces hallucination in role-playing by 18% for adversarial questions and 44% for time-sensitive interviews.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnmasking the Imposters: In-Domain Detection of Human vs. Machine-Generated Tweets\n\n\n\nhci\n\n\n\nUncensored, fine-tuned LLMs evade detection, raising concerns about misuse on social media.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMPCODER: Multi-user Personalized Code Generator with Explicit and Implicit Style Representation Learning\n\n\n\nprogramming\n\n\n\nMPCoder generates personalized code for multiple users, considering syntax and semantics, with a new evaluation metric for coding style similarities.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-assessment, Exhibition, and Recognition: a Review of Personality in Large Language Models\n\n\n\nhci\n\n\n\nTL;DR: This paper reviews studies on personality in large language models, categorizing them into self-assessment, exhibition, and recognition, and discusses challenges and…\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Tool Retrieval with Iterative Feedback from Large Language Models\n\n\n\neducation\n\n\n\nTL;DR: Enhancing tool retrieval for LLMs with iterative feedback for improved performance.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDisce aut Deficere: Evaluating LLMs Proficiency on the INVALSI Italian Benchmark\n\n\n\neducation\n\n\n\nTL;DR: We adapt INVALSI tests to evaluate LLMs in Italian, comparing them to human performance and inviting further model submissions.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoSafe: Evaluating Large Language Model Safety in Multi-Turn Dialogue Coreference\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nLLMs vulnerable in multi-turn dialogues; highest attack success rate was 56% with LLaMA2-Chat-7b, lowest was 13.9% with Mistral-7B-Instruct.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Three-Pronged Approach to Cross-Lingual Adaptation with Multilingual LLMs\n\n\n\nprogramming\n\n\n\nCross-lingual transfer to Indic languages improves Llama-2 LLM performance, benefiting from dominant language signals, word reordering, and continued pre-training.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaLMQA: Exploring culturally specific long-form question answering across 23 languages\n\n\n\nsocial-sciences\n\n\n\nTL;DR: CaLMQA dataset evaluates multilingual LLMs on complex questions, revealing gaps in low-resource languages and cultural specificity.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing LLM-Based Human-Robot Interaction with Nuances for Diversity Awareness\n\n\n\nhci\n\n\n\nSystem uses LLMs for diversity-aware autonomous conversations, adapting to user factors like background, personality, and culture.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Unlearning Fails to Remove Data Poisoning Attacks\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nExisting unlearning methods fail to remove data poisoning effects, suggesting a need for broader evaluation and improvement.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRetrieval-Augmented Code Generation for Situated Action Generation: A Case Study on Minecraft\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLMs predict Builder’s actions in Minecraft Collaborative Building Task, using few-shot prompting for improved performance.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuantifying AI Psychology: A Psychometrics Benchmark for Large Language Models\n\n\n\nhci\n\n\n\nLLMs exhibit psychological attributes, but self-reported traits may differ from real-world behaviors, according to a new psychometric benchmark.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMeasuring and Benchmarking Large Language Models’ Capabilities to Generate Persuasive Language\n\n\n\nhci\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLLMs can produce persuasive text; new dataset measures this ability, enabling comparison of different LLMs and highlighting the impact of system prompts.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNative Design Bias: Studying the Impact of English Nativeness on Language Model Performance\n\n\n\nhci\n\n\n\nLLMs perform worse for non-native English speakers, with an anchoring effect worsening responses.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale\n\n\n\neducation\n\n\n\nTL;DR: FineWeb, a 15-trillion token dataset, improves LLM performance; FineWeb-Edu boosts knowledge and reasoning tasks.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNormTab: Improving Symbolic Reasoning in LLMs Through Tabular Data Normalization\n\n\n\nprogramming\n\n\n\nNormTab improves LLMs’ symbolic reasoning on tables by normalizing web data, enhancing performance on tasks like WikiTableQuestion and TabFact.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTask Oriented In-Domain Data Augmentation\n\n\n\neducation\n\n\n\nTRAIT, a task-oriented framework, enhances LLMs in specialized domains like law and advertisement by augmenting in-domain data and generating synthetic task-oriented…\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdversarial Contrastive Decoding: Boosting Safety Alignment of Large Language Models via Opposite Prompt Optimization\n\n\n\nprompt-engineering\n\n\nsecurity\n\n\narchitectures\n\n\n\nACD: A lightweight, optimization-based method for safer LLM responses, improving safety without heavy training or sacrificing generation ability.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn the Transformations across Reward Model, Parameter Update, and In-Context Prompt\n\n\n\nprompt-engineering\n\n\n\nLLMs can be adapted using three tools: parameter updating, reward modeling, and in-context prompting, offering a unified framework for practical applications.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis\n\n\n\nprompt-engineering\n\n\nhci\n\n\n\nGraph-augmented LLM framework improves personalized, actionable health insights from wearable data.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAgent-Driven Automatic Software Improvement\n\n\n\narchitectures\n\n\nprogramming\n\n\n\nThis research aims to improve software quality using agents powered by Large Language Models, focusing on iterative learning and error correction.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInducing Group Fairness in LLM-Based Decisions\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLLM-based classifiers may lead to unfair decisions; remediation techniques are proposed to improve fairness.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models\n\n\n\nsecurity\n\n\neducation\n\n\nrobustness\n\n\n\nAutoDetect framework automatically identifies weaknesses in LLMs, improving their performance by over 10%.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUniCoder: Scaling Code Large Language Model via Universal Code\n\n\n\nprompt-engineering\n\n\nprogramming\n\n\neducation\n\n\n\nUniCoder: Improving Code Generation with Universal Code Intermediate Representation\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShadowLLM: Predictor-based Contextual Sparsity for Large Language Models\n\n\n\nrobustness\n\n\n\nShadowLLM improves end-to-end accuracy by 15%+, speeds up to 20% over DejaVu, validated on models up to 30B parameters.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in Large Language Models\n\n\n\narchitectures\n\n\nproduction\n\n\n\nM2Lingual: A synthetic multilingual IFT dataset for LLMs, covering 70 languages and 17 NLP tasks, outperforming existing multilingual IFT datasets.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models\n\n\n\nproduction\n\n\n\nSurvey explores scaling compute during inference in LLMs, focusing on token-level, meta-generation, and efficient generation algorithms.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluation of Instruction-Following Ability for Large Language Models on Story-Ending Generation\n\n\n\nsocial-sciences\n\n\neducation\n\n\n\nLLMs’ instruction-following ability in story-ending generation aligns with human evaluation, with open-source models nearing GPT-3.5 performance.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutomated Adversarial Discovery for Safety Classifiers\n\n\n\nrobustness\n\n\n\nAutomated methods struggle to find diverse, successful attacks on safety classifiers, revealing a need for improved adversarial discovery techniques.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Comprehensive Preference Data Collection for Reward Modeling\n\n\n\nsocial-sciences\n\n\n\nNew framework for RLHF preference data collection improves quality, diversity, and reduces human labor.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFreeTraj: Tuning-Free Trajectory Control in Video Diffusion Models\n\n\n\narchitectures\n\n\nproduction\n\n\n\nTuning-free framework for trajectory-controllable video generation using diffusion models.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnnotatedTables: A Large Tabular Dataset with Language Model Annotations\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nLLMs can automate annotation of large, diverse tabular data, enabling flexible annotations and SQL program generation.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMs assist NLP Researchers: Critique Paper (Meta-)Reviewing\n\n\n\nhci\n\n\n\nThis study explores LLMs’ potential to assist NLP researchers in paper reviewing, but does not advocate their use due to current limitations in expertise and nuanced…\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSparser is Faster and Less is More: Efficient Sparse Attention for Long-Range Transformers\n\n\n\narchitectures\n\n\n\nSparseK Attention: A novel sparse attention mechanism for efficient, linear-time Transformers with improved performance and seamless integration into LLMs.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models in Student Assessment: Comparing ChatGPT and Human Graders\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\neducation\n\n\n\nGPT-4 aligns with human mean scores but lacks adaptability in grading nuanced criteria, highlighting AI’s limitations in higher education.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Augmentation of Multi-turn Psychological Dialogue via Knowledge-driven Progressive Thought Prompting\n\n\n\nprompt-engineering\n\n\nhci\n\n\nsocial-sciences\n\n\n\nNew method for multi-turn dialogue data augmentation in psychology, using progressive thought and psychology knowledge generators, and a multi-turn dialogue generator.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLangSuitE: Planning, Controlling and Interacting with Large Language Models in Embodied Text Environments\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLangSuit⋅⋅⋅E tests LLMs as embodied agents in dynamic textual worlds, offering adaptability, customization, and a novel CoT schema for embodied planning.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models\n\n\n\nrobustness\n\n\n\nNew framework improves text-to-image model reliability, reducing inconsistencies between visual output and textual input.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPISTOL: Dataset Compilation Pipeline for Structural Unlearning of LLMs\n\n\n\narchitectures\n\n\nrobustness\n\n\nproduction\n\n\n\nPISTOL: A pipeline for benchmarking structural unlearning in LLMs, highlighting challenges and model impacts.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYouDream: Generating Anatomically Controllable Consistent Text-to-3D Animals\n\n\n\nhci\n\n\n\nYouDream generates anatomically accurate 3D animals from text, outperforming previous text-to-3D methods.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSoley: Identification and Automated Detection of Logic Vulnerabilities in Ethereum Smart Contracts Using Large Language Models\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nTL;DR: Sóley, a LLM-based tool, outperforms existing methods in detecting logic vulnerabilities in smart contracts, aiding security and sustainability.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters\n\n\n\narchitectures\n\n\n\nLanguage-specific draft models speed up multilingual LLM inference time.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees\n\n\n\narchitectures\n\n\nproduction\n\n\n\nEAGLE-2, an upgrade to EAGLE, offers 20%-40% faster speculative sampling for LLMs, preserving text distribution without loss.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlending LLMs into Cascaded Speech Translation: KIT’s Offline Speech Translation System for IWSLT 2024\n\n\n\narchitectures\n\n\nrobustness\n\n\nproduction\n\n\n\nLLM integration in ASR and MT systems improves WER and COMET scores, but not in noisy conditions.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUSDC: A Dataset of User Stance and Dogmatism in Long Conversations\n\n\n\nproduction\n\n\n\nLLMs automate annotation for user stance, dogmatism in Reddit conversations, creating USDC dataset for finetuning small language models.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBEEAR: Embedding-based Adversarial Removal of Safety Backdoors in Instruction-tuned Language Models\n\n\n\nrobustness\n\n\n\nBEEAR mitigates safety backdoor attacks in LLMs, reducing success rates from &gt;95% to &lt;1% without compromising model utility.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParaphrase and Aggregate with Large Language Models for Minimizing Intent Classification Errors\n\n\n\nrobustness\n\n\n\nLLMs like LLaMa can excel in multi-class classification, but PAG-LLM reduces errors and hallucinated labels, improving performance by up to 22.7%.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models Assume People are More Rational than We Really are\n\n\n\nhci\n\n\n\nLLMs incorrectly assume humans are more rational, aligning with expected value theory, but match human expectations of rational behavior.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlagBench: Exploring the Duality of Large Language Models in Plagiarism Generation and Detection\n\n\n\nrobustness\n\n\n\nLLMs can aid plagiarism, but also detect it. GPT-3.5 outperforms Llama2 and GPT-4 in paraphrasing and summarizing, and LLMs can surpass commercial plagiarism detectors.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDirected Domain Fine-Tuning: Tailoring Separate Modalities for Specific Training Tasks\n\n\n\neducation\n\n\n\nFine-tuning Video-LLaVA with LORA on cooking tasks improves performance using smaller, task-specific datasets.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoisy Neighbors: Efficient membership inference attacks against LLMs\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nEfficient MIA method for LLMs using noisy neighbors in embedding space, matching shadow models’ effectiveness in privacy auditing.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInvestigating the Influence of Prompt-Specific Shortcuts in AI Generated Text Detection\n\n\n\nprompt-engineering\n\n\nsecurity\n\n\nrobustness\n\n\n\nFAILOpt Attack Exploits Shortcuts in AI-Generated Text Detection, Enhances Robustness.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWARP: On the Benefits of Weight Averaged Rewarded Policies\n\n\n\narchitectures\n\n\nproduction\n\n\n\nWARP strategy improves LLM alignment, balancing KL regularization and reward optimization.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRES-Q: Evaluating Code-Editing Large Language Model Systems at the Repository Scale\n\n\n\nprompt-engineering\n\n\narchitectures\n\n\nprogramming\n\n\nproduction\n\n\n\nRES-Q benchmark evaluates LLMs’ ability to edit code repositories, showing Claude Sonnet 3.5 outperforms GPT-4o.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRagnarök: A Reusable RAG Framework and Baselines for TREC 2024 Retrieval-Augmented Generation Track\n\n\n\narchitectures\n\n\nproduction\n\n\n\nTREC 2024 RAG Track proposed for evaluating RAG-based search systems, featuring Ragnarök framework and industrial baselines.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLottery Ticket Adaptation: Mitigating Destructive Interference in LLMs\n\n\n\nproduction\n\n\narchitectures\n\n\neducation\n\n\nrobustness\n\n\n\nLoTA, a sparse adaptation method, outperforms full fine-tuning and LoRA, avoiding catastrophic forgetting and enabling model merging over dissimilar tasks.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs\n\n\n\narchitectures\n\n\neducation\n\n\nproduction\n\n\n\nCambrian-1: A family of MLLMs with vision-centric approach, offering new insights into various models, and introducing CV-Bench and Spatial Vision Aggregator (SVA) for…\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrace is the New AutoDiff – Unlocking Efficient Optimization of Computational Workflows\n\n\n\nprompt-engineering\n\n\n\nTrace: A Framework for Optimizing AI Systems with Diverse Feedback and Parameters.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEffectiveness of ChatGPT in explaining complex medical reports to patients\n\n\n\nhci\n\n\nsocial-sciences\n\n\neducation\n\n\n\nChatGPT struggles to accurately explain complex cancer reports to patients, facing issues like inaccuracies, language, personalization, and distrust.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSerial Position Effects of Large Language Models\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLLMs excel in zero-shot learning but exhibit human-like biases, like primacy and recency effects, which vary in intensity and can be inconsistently mitigated.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReCaLL: Membership Inference via Relative Conditional Log-Likelihoods\n\n\n\nsecurity\n\n\n\nReCall is a new method for detecting pretraining data in large language models, outperforming existing methods and offering insights into model behavior.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEERPD: Leveraging Emotion and Emotion Regulation for Improving Personality Detection\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nEERPD: New method improves personality detection by incorporating emotion regulation, outperforming previous models.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPORT: Preference Optimization on Reasoning Traces\n\n\n\nprompt-engineering\n\n\n\nPreference optimization on reasoning steps enhances language model accuracy, as shown by up to 8.47% increase on GSM8K benchmark.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPreference Tuning For Toxicity Mitigation Generalizes Across Languages\n\n\n\nsocial-sciences\n\n\nrobustness\n\n\n\nZero-shot preference tuning in English can significantly reduce toxicity in multilingual LLMs, as shown by DPO training results across 17 languages and various models.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFastMem: Fast Memorization of Prompt Improves Context Awareness of Large Language Models\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nFastMem improves LLMs’ context awareness, boosting accuracy in tasks like comprehension and summarization.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChain-of-Probe: Examing the Necessity and Accuracy of CoT Step-by-Step\n\n\n\nprompt-engineering\n\n\n\nCoP method reveals CoT can be unnecessary, and correct answers may have reasoning errors. CoP prioritizes answers with correct reasoning for reliability.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Region-aware Bias Evaluation Metrics\n\n\n\nsocial-sciences\n\n\n\nRegion-aware approach identifies gender bias in language models, outperforming traditional methods.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Text to Test: AI-Generated Control Software for Materials Science Instruments\n\n\n\nhci\n\n\neducation\n\n\n\nLLMs, like ChatGPT-4, can automate scientific instruments and democratize materials research, as demonstrated by controlling a Keithley 2400 and analyzing a…\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCrosslingual Capabilities and Knowledge Barriers in Multilingual Large Language Models\n\n\n\nsocial-sciences\n\n\n\nLLMs struggle with crosslingual knowledge transfer, but fine-tuning on mixed-language data helps improve performance.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration\n\n\n\nsocial-sciences\n\n\n\nModular Pluralism: A framework for LLMs to model diverse human preferences across communities, offering flexibility and modular control.\n\n\n\nJun 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeaching LLMs to Abstain across Languages via Multilingual Feedback\n\n\n\nsocial-sciences\n\n\neducation\n\n\nrobustness\n\n\n\nTL;DR: Multilingual feedback improves LLM abstention, reducing performance gaps between high and low-resource languages in QA tasks.\n\n\n\nJun 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Expert Radiology Report Summarization by Prompting Large Language Models with a Layperson Summary\n\n\n\nproduction\n\n\n\nThis paper presents a novel method for radiology report summarization, improving accuracy and accessibility, especially in out-of-domain tests.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRaising the Bar: Investigating the Values of Large Language Models via Generative Evolving Testing\n\n\n\nrobustness\n\n\nsocial-sciences\n\n\n\nTL;DR: GETA dynamically tests LLMs’ moral baselines, addressing the issue of outdated evaluation data, and accurately assesses their values.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExplicit and Implicit Large Language Model Personas Generate Opinions but Fail to Replicate Deeper Perceptions and Biases\n\n\n\nprompt-engineering\n\n\nproduction\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs with personas struggle to replicate human biases, lacking intrinsic human cognition despite reflecting speech patterns.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models\n\n\n\narchitectures\n\n\nproduction\n\n\nprompt-engineering\n\n\n\nGraphReader outperforms GPT-4-128k on long-context tasks, using a 4k context window and a graph-based agent system.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep-Back Profiling: Distilling User History for Personalized Scientific Writing\n\n\n\nsocial-sciences\n\n\n\nStep-back Profiling personalizes LLMs for collaborative scientific writing, outperforming baselines on LaMP benchmark.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerative AI for Enhancing Active Learning in Education: A Comparative Study of GPT-3.5 and GPT-4 in Crafting Customized Test Questions\n\n\n\nprompt-engineering\n\n\neducation\n\n\nhci\n\n\n\nGPT-4 excels at creating complex math questions, improving GPT-3.5’s problem-solving skills, showcasing AI’s potential in personalized education.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre LLMs Naturally Good at Synthetic Tabular Data Generation?\n\n\n\narchitectures\n\n\nproduction\n\n\n\nLLMs struggle with generating synthetic tables; this paper proposes a permutation-aware approach to improve their performance.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHierarchical Micro-Segmentations for Zero-Trust Services via Large Language Model (LLM)-enhanced Graph Diffusion\n\n\n\nsecurity\n\n\n\nThis paper proposes LEGD, a hierarchical micro-segmentation algorithm for efficient zero-trust service provisioning in NGNs, achieving 90% higher efficiency than baselines.…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models are Skeptics: False Negative Problem of Input-conflicting Hallucination\n\n\n\nrobustness\n\n\n\nLLMs tend to generate false negative responses, but context and query rewriting can help.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDoes Object Grounding Really Reduce Hallucination of Large Vision-Language Models?\n\n\n\nrobustness\n\n\n\nGrounding objectives minimally reduce object hallucination in open caption generation, despite previous claims.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmedIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced Clinical Diagnosis on EMRs\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\n\nmedIKAL framework combines LLMs and KGs for precise, enhanced clinical diagnosis using EMRs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenderAlign: An Alignment Dataset for Mitigating Gender Bias in Large Language Models\n\n\n\nsocial-sciences\n\n\n\nGenderAlign dataset reduces gender bias in LLMs, offering a new approach to alignment.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCREF: An LLM-based Conversational Software Repair Framework for Programming Tutors\n\n\n\nprogramming\n\n\neducation\n\n\n\nLLMs show potential for program repair, but data leakage is a concern. A new benchmark, TutorCode, is introduced to evaluate LLMs’ repair capabilities. Tutor guidance is…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMMBench-Video: A Long-Form Multi-Shot Benchmark for Holistic Video Understanding\n\n\n\narchitectures\n\n\nproduction\n\n\n\nMMBench-Video: New Benchmark for Video Understanding with LVLMs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHIGHT: Hierarchical Graph Tokenization for Graph-Language Alignment\n\n\n\nrobustness\n\n\nhci\n\n\n\nHIGHT: New method improves graph-language alignment in LLMs, reducing hallucination and enhancing performance in molecule-language tasks.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVAIYAKARANA : A Benchmark for Automatic Grammar Correction in Bangla\n\n\n\nrobustness\n\n\n\nThis work proposes a method to generate grammatically incorrect Bangla sentences for AI training, creating a dataset called Vaiyakarana. Human evaluators outperform AI…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPostMark: A Robust Blackbox Watermark for Large Language Models\n\n\n\nproduction\n\n\nrobustness\n\n\nsocial-sciences\n\n\nsecurity\n\n\n\nPostMark: A post-hoc watermarking method for LLM-generated text, robust to paraphrasing and third-party implementable.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Changes in Nation Perception with Nationality-Assigned Personas in LLMs\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs favor Western Europe, but nationality personas influence focus and favorability towards the assigned region. Biases and stereotypes emerge in LLMs with different…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCityGPT: Empowering Urban Spatial Cognition of Large Language Models\n\n\n\nprogramming\n\n\neducation\n\n\n\nCityGPT enhances LLMs’ urban understanding using CityInstruction and CityEval, achieving competitive performance with commercial LLMs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArtificial Leviathan: Exploring Social Evolution of LLM Agents Through the Lens of Hobbesian Social Contract Theory\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs simulate social dynamics, aligning with Hobbes’s Social Contract Theory, offering potential for understanding group behavior and complex human systems.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinding Safety Neurons in Large Language Models\n\n\n\nsecurity\n\n\n\nSafety neurons in LLMs can restore 90% safety with 5% intervention, transferable across datasets, and aid in detecting unsafe outputs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSynDARin: Synthesising Datasets for Automated Reasoning in Low-Resource Languages\n\n\n\narchitectures\n\n\nproduction\n\n\n\nSynDARin generates QA datasets for low-resource languages, maintaining quality and diversity, and filtering out poor translations, enabling evaluation of LLMs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutoCAP: Towards Automatic Cross-lingual Alignment Planning for Zero-shot Chain-of-Thought\n\n\n\nprompt-engineering\n\n\n\nAutoCAP, a zero-shot chain-of-thought method, improves cross-lingual alignment by automatically selecting languages and allocating weights, outperforming manual methods.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDye4AI: Assuring Data Boundary on Generative AI Services\n\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nTL;DR: Dye4AI system tests AI data boundaries by injecting triggers into dialogue, ensuring data security in AI model evolution.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConnecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data\n\n\n\nproduction\n\n\nsecurity\n\n\n\nLLMs can infer censored knowledge by piecing together scattered hints, posing a challenge for safety and control.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvidence of a log scaling law for political persuasion with large language models\n\n\n\nproduction\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLarger language models only slightly more persuasive than smaller ones, with task completion being key.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCausal Inference with Latent Variables: Recent Advances and Future Prospectives\n\n\n\nsocial-sciences\n\n\n\nRecent developments in causal inference with unobserved variables, challenges, and future opportunities.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSEC-QA: A Systematic Evaluation Corpus for Financial QA\n\n\n\narchitectures\n\n\n\nTL;DR: SEC-QA framework generates QA pairs for financial documents, improving complex QA accuracy.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLiveMind: Low-latency Large Language Models with Simultaneous Inference\n\n\n\narchitectures\n\n\neducation\n\n\nprompt-engineering\n\n\n\nNew framework reduces LLM inference latency by up to 93% with incomplete prompts, improving interactive experience and accuracy.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM4CP: Adapting Large Language Models for Channel Prediction\n\n\n\narchitectures\n\n\nproduction\n\n\n\n[TEXT] This study examines the relationship between social media use and mental health in adolescents. Results indicate a significant correlation between excessive social…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAugmenting Query and Passage for Retrieval-Augmented Generation using LLMs for Open-Domain Question Answering\n\n\n\neducation\n\n\n\nTL;DR: Improving open-domain QA by augmenting questions and passages with LLMs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPEER: Automatic Prompt Engineering Enhances Large Language Model Reranking\n\n\n\narchitectures\n\n\nproduction\n\n\nprompt-engineering\n\n\n\nAPEER: A novel automatic prompt engineering algorithm for relevance ranking, outperforming manual prompts and showing better transferability.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrism: A Framework for Decoupling and Assessing the Capabilities of VLMs\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nPrism separates vision and reasoning in VLMs, improving performance and reducing costs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMR-BEN: A Comprehensive Meta-Reasoning Benchmark for Large Language Models\n\n\n\nhci\n\n\n\nTL;DR: Mr-Ben benchmark evaluates LLMs’ meta-reasoning skills, revealing gaps in reasoning capabilities.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRobust Few-shot Transfer Learning for Knowledge Base Question Answering with Unanswerable Questions\n\n\n\nprompt-engineering\n\n\n\nFUn-FuSIC improves few-shot KBQA with unanswerable questions, outperforming existing models.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGlobal is Good, Local is Bad?: Understanding Brand Bias in LLMs\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs exhibit bias towards global brands, favoring them over local ones, and show country-of-origin effects.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Fire Thief Is Also the Keeper: Balancing Usability and Privacy in Prompts\n\n\n\nprompt-engineering\n\n\nrobustness\n\n\nhci\n\n\nsecurity\n\n\n\nProSan: A framework for anonymizing prompts in LLMs, maintaining usability, and adapting to resource conditions.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCityBench: Evaluating the Capabilities of Large Language Model as World Model\n\n\n\neducation\n\n\n\nTL;DR: CityBench is a new evaluation benchmark for LLMs in urban domains, featuring 7 tasks across 13 cities and 13 models.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranslating Across Cultures: LLMs for Intralingual Cultural Adaptation\n\n\n\narchitectures\n\n\nproduction\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs can adapt translations to target cultures, outperforming specialized models in cultural sensitivity, but may perpetuate biases.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeeing Through AI’s Lens: Enhancing Human Skepticism Towards LLM-Generated Fake News\n\n\n\nrobustness\n\n\nsocial-sciences\n\n\n\nTL;DR: ESAS metric helps identify terms to distinguish human-written vs. LLM-generated news, aiding in detecting fake news.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Different Design Choices in Training Large Time Series Models\n\n\n\nprompt-engineering\n\n\n\nLTSM-bundle outperforms existing methods in time series forecasting, using novel prompting strategies and best design choices.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeCoKD: Aligning Large Language Models for In-Context Learning with Fewer Shots\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nSeCoKD improves LLMs’ performance with fewer demonstrations, outperforming base models and Supervised Fine-tuning, especially in zero-shot and one-shot settings.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPersuasiveness of Generated Free-Text Rationales in Subjective Decisions: A Case Study on Pairwise Argument Ranking\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\neducation\n\n\nhci\n\n\n\nLLMs generate persuasive rationales for subjective tasks, with Llama2-70B-chat outperforming GPT models. Persuasiveness improves with parameter control via prompting or…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfrican or European Swallow? Benchmarking Large Vision-Language Models for Fine-Grained Object Classification\n\n\n\narchitectures\n\n\nproduction\n\n\n\nTL;DR: FOCI benchmark reveals CLIP models outperform LVLMs in fine-grained object classification, highlighting alignment issues.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLaSA: Large Multimodal Agent for Human Activity Analysis Through Wearable Sensors\n\n\n\neducation\n\n\n\nLLaSA: A Multimodal AI Model for Activity Understanding Using IMUs and LLMs, with Applications in Healthcare and HCI.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Truthful Multilingual Large Language Models: Benchmarking and Alignment Strategies\n\n\n\narchitectures\n\n\nproduction\n\n\n\nResearch proposes benchmark and method to improve truthfulness and reduce language disparity in multilingual large language models.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold\n\n\n\narchitectures\n\n\nproduction\n\n\n\nFinetuning LLMs with model-generated data can improve math reasoning, especially with self-generated correct solutions and per-step negative responses. This approach can…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInvestigating Mysteries of CoT-Augmented Distillation\n\n\n\nproduction\n\n\neducation\n\n\nprompt-engineering\n\n\n\nCoT sequences after labels improve student model performance, even when incoherent or partial. No reasoning needed at test time.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment\n\n\n\nsocial-sciences\n\n\n\nEnriched image captions increase gender bias and hallucination, cautioning against over-descriptiveness.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData-Centric AI in the Age of Large Language Models\n\n\n\nproduction\n\n\n\nData-centric viewpoint for AI research: Prioritizing data in large language models for benchmarks, attribution, knowledge transfer, and inference contextualization.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSPL: A Socratic Playground for Learning Powered by Large Language Mode\n\n\n\nhci\n\n\nsocial-sciences\n\n\neducation\n\n\nprompt-engineering\n\n\n\nSPL, a GPT-4-powered ITS, improves tutoring dialogues and critical thinking skills in learners.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel Merging and Safety Alignment: One Bad Model Spoils the Bunch\n\n\n\narchitectures\n\n\nproduction\n\n\n\nMerging LLMs can propagate misalignment; proposed method integrates alignment-related data, improving domain expertise and alignment.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFVEL: Interactive Formal Verification Environment with Large Language Models via Theorem Proving\n\n\n\narchitectures\n\n\neducation\n\n\nprompt-engineering\n\n\n\nFVEL: LLM-powered Formal Verification in Isabelle improves verification, reducing proof errors, and solving more problems in SV-COMP.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating Implicit Bias in Large Language Models by Attacking From a Psychometric Perspective\n\n\n\nsocial-sciences\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nLLMs exhibit implicit bias, with GLM-3 outperforming GPT-3.5 and GPT-4 in defending against attacks. Deception attacks are most effective.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJailbreaking as a Reward Misspecification Problem\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nTL;DR: New system (ReMiss) detects harmful prompts in LLMs, outperforming previous methods.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Spatial Representations in the Historical Lake District Texts with LLM-based Relation Extraction\n\n\n\nsocial-sciences\n\n\n\nAI model extracts spatial relations from English Lake District texts, visualizing historical narratives as a network for deeper understanding.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAsynchronous Large Language Model Enhanced Planner for Autonomous Driving\n\n\n\narchitectures\n\n\nproduction\n\n\n\nAsyncDriver: LLM-enhanced framework for precise, controllable autonomous driving, reducing LLM’s computational cost.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMind the Privacy Unit! User-Level Differential Privacy for Language Model Fine-Tuning\n\n\n\narchitectures\n\n\n\nUser-level DP for LLMs ensures uniform privacy across users, focusing on fine-tuning for natural language generation tasks.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTaxonomy-Guided Zero-Shot Recommendations with LLMs\n\n\n\nrecommender\n\n\n\nTaxonomy-guided LLM method (TaxRec) improves recommender systems with better item categorization and controlled feature generation.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQ*: Improving Multi-step Reasoning for LLMs with Deliberative Planning\n\n\n\nrobustness\n\n\n\nQ* framework guides LLMs’ decoding, improving multi-step reasoning without fine-tuning, reducing errors and inconsistencies.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn Investigation of Prompt Variations for Zero-shot LLM-based Rankers\n\n\n\nprompt-engineering\n\n\n\nPrompt components and wordings significantly impact zero-shot LLM ranking effectiveness, sometimes more than ranking algorithms.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAligning Large Language Models with Diverse Political Viewpoints\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs aligned with diverse political views generate more accurate viewpoints than commercial models like ChatGPT.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs\n\n\n\neducation\n\n\n\nTL;DR: Fine-tuning LLMs with KG-derived data enhances planning, improving complex QA task performance.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOptimizing Psychological Counseling with Instruction-Tuned Large Language Models\n\n\n\neducation\n\n\nhci\n\n\n\nInstruction-tuned LLMs excel in psychological counseling, offering empathetic, relevant, and supportive responses, outperforming baseline models.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdaptable Logical Control for Large Language Models\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nCtrl-G outperforms GPT3.5 and GPT4 in interactive text editing, ensuring LLM outputs follow logical constraints.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVELO: A Vector Database-Assisted Cloud-Edge Collaborative LLM QoS Optimization Framework\n\n\n\nprogramming\n\n\nhci\n\n\n\nVELO framework uses edge-based vector database caching to optimize LLM QoS, reducing response time and costs without altering LLM structure.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models\n\n\n\neducation\n\n\n\nAutoIF is a new method for automatically generating instruction-following training data for LLMs, improving performance across three training algorithms.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvery Language Counts: Learn and Unlearn in Multilingual LLMs\n\n\n\nrobustness\n\n\n\nMultilingual LLMs can spread fake info; standard unlearning methods are inadequate. Comprehensive unlearning strategies needed.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSD-Eval: A Benchmark Dataset for Spoken Dialogue Understanding Beyond Words\n\n\n\nhci\n\n\n\nTL;DR: SD-Eval benchmark assesses spoken dialogue understanding & generation, focusing on paralinguistic & environmental info, with models conditioned on this data…\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProse-to-P4: Leveraging High Level Languages\n\n\n\nprogramming\n\n\n\nLLMs can translate natural language to high-level networking code, making software development easier.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLIT: Large Language Model Driven Intention Tracking for Proactive Human-Robot Collaboration – A Robot Sous-Chef Application\n\n\n\nprompt-engineering\n\n\n\nLIT predicts human intentions for proactive robot collaboration, reducing excessive prompting in long-horizon tasks.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Contamination Can Cross Language Barriers\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nNew method detects deep contamination in large language models, evading current methods.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMagicItem: Dynamic Behavior Design of Virtual Objects with Large Language Models in a Consumer Metaverse Platform\n\n\n\nprogramming\n\n\neducation\n\n\n\nTool enables non-programmers to create dynamic behaviors for VR objects in metaverse platforms.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Efficacy of Conversational Artificial Intelligence in Rectifying the Theory of Mind and Autonomy Biases: Comparative Analysis\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nNon-therapeutic chatbots outperform therapeutic ones in rectifying cognitive biases and recognizing affect.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJogging the Memory of Unlearned Model Through Targeted Relearning Attack\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nExisting unlearning methods in LLMs can be reversed by targeted relearning attacks, using small, loosely related data sets.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpen Generative Large Language Models for Galician\n\n\n\nsocial-sciences\n\n\n\n[TEXT] This study examines the relationship between social media use and mental health in adolescents. Results indicate a significant correlation between excessive social…\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObscurePrompt: Jailbreaking Large Language Models via Obscure Input\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nObscurePrompt: New method for jailbreaking LLMs, improving attack effectiveness and defense robustness.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGUI Action Narrator: Where and When Did That Action Take Place?\n\n\n\nprompt-engineering\n\n\n\nGUI automation is improved with multimodal LLMs, aided by a new video captioning benchmark and framework, GUI Narrator, which uses cursor as visual prompt.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation\n\n\n\neducation\n\n\n\nBalDistill improves LLM knowledge distillation for long-tailed data, enhancing distilled model efficiency and efficacy.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStackRAG Agent: Improving Developer Answers with Retrieval-Augmented Generation\n\n\n\nprogramming\n\n\nrobustness\n\n\n\nStackRAG: A tool combining Stack Overflow and LLMs for accurate, reliable coding answers.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemantic Structure-Mapping in LLM and Human Analogical Reasoning\n\n\n\neducation\n\n\nhci\n\n\n\nLLMs approach human-level performance in semantic structure-mapping tasks but aren’t entirely human-like.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeHonest: Benchmarking Honesty of Large Language Models\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nTL;DR: BeHonest benchmark assesses honesty in LLMs, highlighting room for improvement.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAgentDojo: A Dynamic Environment to Evaluate Attacks and Defenses for LLM Agents\n\n\n\nsecurity\n\n\n\nAI agents are vulnerable to prompt injection attacks; AgentDojo is a framework to evaluate and improve their adversarial robustness.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling\n\n\n\nhci\n\n\n\nLangTopo framework aligns LLMs with GNNs for graph structure modeling, improving LLMs’ graph data handling.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistributional reasoning in LLMs: Parallel reasoning processes in multi-hop reasoning\n\n\n\nprompt-engineering\n\n\nhci\n\n\n\nLLMs perform multi-hop reasoning via interpretable embeddings, revealing parallel reasoning paths and potential intermediate answers.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan LLMs Reason in the Wild with Programs?\n\n\n\nprogramming\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLMs struggle with ambiguous, mixed-scope reasoning; fine-tuning with diverse data helps.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThrough the Theory of Mind’s Eye: Reading Minds with Multimodal Video Large Language Models\n\n\n\neducation\n\n\nhci\n\n\n\nLLMs can reason about human emotions and intentions in videos, revealing their ToM reasoning process.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeveraging Large Language Models for Patient Engagement: The Power of Conversational AI in Digital Health\n\n\n\neducation\n\n\nhci\n\n\n\nLLMs in healthcare improve patient engagement via conversational AI, but raise ethical and regulatory considerations.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKnowledge Tagging System on Math Questions via LLMs with Flexible Demonstration Retriever\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLMs automate knowledge tagging for questions, outperforming prior methods in math tasks and improving efficiency with a reinforcement learning-based demonstration retriever.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinding Blind Spots in Evaluator LLMs with Interpretable Checklists\n\n\n\nrobustness\n\n\neducation\n\n\n\nLLMs often struggle to accurately evaluate text generation in other LLMs, with shortcomings in detecting factual accuracy, coherence, and reasoning proficiency.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNicer Than Humans: How do Large Language Models Behave in the Prisoner’s Dilemma?\n\n\n\nrobustness\n\n\nhci\n\n\nsecurity\n\n\n\nLLM Llama2 shows cooperative behavior in Prisoner’s Dilemma, adopting a cautious approach and favoring forgiveness over retaliation.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Collaborative Semantics of Language Model-Driven Recommendations via Graph-Aware Learning\n\n\n\nrecommender\n\n\n\nGAL-Rec improves LLM-driven recommendations by enhancing collaborative semantics understanding in interaction graphs.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInvestigating Low-Cost LLM Annotation for~Spoken Dialogue Understanding Datasets\n\n\n\neducation\n\n\n\nImproving Spoken Dialogue Datasets with Fine-tuned Language Models.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn AI-Inspired UI-Design\n\n\n\nhci\n\n\n\nAI can inspire and assist app design by generating, searching, and creating UI images using LLM, VLM, and DM models.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearning to Generate Answers with Citations via Factual Consistency Models\n\n\n\nrobustness\n\n\n\nThis paper proposes a method using factual consistency models to improve citation accuracy in LLMs, reducing hallucinations and enhancing reliability.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKnowledge Graph-Enhanced Large Language Models via Path Selection\n\n\n\nrobustness\n\n\n\nKELP framework improves LLM factual accuracy by flexible KG knowledge extraction.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJailbreak Paradox: The Achilles’ Heel of LLMs\n\n\n\nsecurity\n\n\n\nJailbreaking foundation models: Perfect detection is impossible, and weaker models can’t consistently detect jailbreaks in stronger models.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBenchmarks and Metrics for Evaluations of Code Generation: A Critical Review\n\n\n\nprogramming\n\n\n\nThis paper reviews methods for testing and evaluating LLMs in code generation, focusing on benchmarks and metrics.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards a Client-Centered Assessment of LLM Therapists by Client Simulation\n\n\n\nsecurity\n\n\n\nThis work proposes ClientCAST, an approach using LLMs to simulate clients and assess LLM therapists, focusing on session outcome, therapeutic alliance, and self-reported…\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM4MSR: An LLM-Enhanced Paradigm for Multi-Scenario Recommendation\n\n\n\nrecommender\n\n\n\nLLM4MSR: Efficient, Effective, Interpretable Multi-Scenario Recommendation Paradigm using LLM.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHopping Too Late: Exploring the Limitations of Large Language Models on Multi-Hop Queries\n\n\n\nrobustness\n\n\n\nLLMs solve multi-hop queries in later layers, but sometimes lack needed knowledge; back-patching analysis can improve accuracy.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPDSS: A Privacy-Preserving Framework for Step-by-Step Distillation of Large Language Models\n\n\n\nsecurity\n\n\n\nPDSS: Privacy-preserving framework distills LLMs for domain-specific tasks, ensuring data privacy and improved performance in text generation tasks.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUBENCH: Benchmarking Uncertainty in Large Language Models with Multiple Choice Questions\n\n\n\neducation\n\n\n\nUBench is a new benchmark for evaluating LLM reliability, offering improved performance and resource efficiency. It finds GLM4 and GPT-4 as the most reliable LLMs.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNavigating the Labyrinth: Evaluating and Enhancing LLMs’ Ability to Reason About Search Problems\n\n\n\nprogramming\n\n\n\nLLMs struggle with logic problems; in-context learning with A* algorithm and Multi-Stage-Multi-Try method improves performance.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn-Policy Fine-grained Knowledge Feedback for Hallucination Mitigation\n\n\n\nrobustness\n\n\n\nRLFH is an online reinforcement learning method for hallucination mitigation in LLMs, using fine-grained feedback and an LLM-based fact assessment framework.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodeNav: Beyond tool-use to using real-world codebases with LLM agents\n\n\n\nprogramming\n\n\n\nCodeNav: LLM agent navigates unseen code repositories, solving queries without manual tool registration, and outperforms tool-use agents in benchmarks.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-enhanced Reranking in Recommender Systems\n\n\n\nrecommender\n\n\n\nLLM-enhanced reranking framework improves accuracy, diversity, and fairness in recommendations, outperforming existing models.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Did I Do Wrong? Quantifying LLMs’ Sensitivity and Consistency to Prompt Engineering\n\n\n\nprogramming\n\n\n\nLLMs face debugging challenges; new metrics sensitivity and consistency introduced for classification tasks to improve LLM performance and robustness.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey on Human Preference Learning for Large Language Models\n\n\n\nrecommender\n\n\n\nThis survey explores human preference learning for large language models, covering feedback sources, modeling, usage, and evaluation.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretable Catastrophic Forgetting of Large Language Model Fine-tuning via Instruction Vector\n\n\n\nprogramming\n\n\n\nFine-tuning LLMs may not erase previous skills, but add specialized reasoning; IV-guided training mitigates catastrophic forgetting.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTalk With Human-like Agents: Empathetic Dialogue Through Perceptible Acoustic Reception and Reaction\n\n\n\nrobustness\n\n\n\nPerceptiveAgent: LLM-based dialogue system discerns deeper meanings using speech modality, improving contextual understanding and empathetic responses.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCherryRec: Enhancing News Recommendation Quality via LLM-driven Framework\n\n\n\nrecommender\n\n\nprogramming\n\n\n\nCherryRec: A LLM-based news recommendation framework for efficient, high-quality recommendations.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond Under-Alignment: Atomic Preference Enhanced Factuality Tuning for Large Language Models\n\n\n\nrobustness\n\n\n\nLLMs struggle with factuality in OOD datasets; APEFT framework improves factuality by 3.45% on average.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBreaking the Ceiling of the LLM Community by Treating Token Generation as a Classification for Ensembling\n\n\n\nrobustness\n\n\n\nGaC: Ensembling LLMs by treating token generation as classification improves performance and reduces latency.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing LLMs to Aid Annotation and Collection of Clinically-Enriched Data in Bipolar Disorder and Schizophrenia\n\n\n\neducation\n\n\n\nSmall language models excel in mental health research, outperforming large models in annotation, data collection, and scalability.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdversarial Attacks on Large Language Models in Medicine\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nLLMs in healthcare are vulnerable to adversarial attacks, requiring robust security measures for safe deployment.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMAGIC: Generating Self-Correction Guideline for In-Context Text-to-SQL\n\n\n\nrobustness\n\n\n\nMAGIC automates self-correction guideline creation in text-to-SQL, outperforming human-crafted guidelines and improving interpretability.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerating Educational Materials with Different Levels of Readability using LLMs\n\n\n\nrobustness\n\n\n\nTL;DR: Few-shot prompting improves AI’s ability to simplify educational texts, but quality concerns remain.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn the Robustness of Language Models for Tabular Question Answering\n\n\n\neducation\n\n\n\nLLMs, like Llama3, excel in table comprehension, but improvements are needed for robustness and handling domain-specific data.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPFID: Privacy First Inference Delegation Framework for LLMs\n\n\n\nrobustness\n\n\n\nPFID framework for LLMs enhances privacy by localizing user data, using model sharding, and singular value decomposition, while maintaining system performance.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?\n\n\n\neducation\n\n\n\nLLMs, like GPT-4, show inconsistency despite high capability; harder data boosts consistency.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCleanGen: Mitigating Backdoor Attacks for Generation Tasks in Large Language Models\n\n\n\nprogramming\n\n\nrobustness\n\n\nsecurity\n\n\n\nCleanGen: A defense strategy for LLMs that mitigates backdoor attacks, reducing attack success rates with minimal computational overhead.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefending Against Social Engineering Attacks in the Age of LLMs\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nLLMs aid digital deception, but struggle with detection. ConvoSentinel, a modular defense pipeline, improves CSE detection and adaptability.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan We Trust Large Language Models Generated Code? A Framework for In-Context Learning, Security Patterns, and Code Evaluations Across Diverse LLMs\n\n\n\nprogramming\n\n\nrobustness\n\n\nsecurity\n\n\n\nLLMs for code generation may perpetuate vulnerabilities; ICL-driven learning can enhance code security, reducing risks in various programming scenarios.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPRePair: Pointwise Reasoning Enhance Pairwise Evaluating for Robust Instruction-Following Assessments\n\n\n\nsecurity\n\n\n\nLLMs’ biases impact pairwise evaluations more; hybrid method integrating pointwise reasoning improves robustness.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSNAP: Unlearning Selective Knowledge in Large Language Models with Negative Instructions\n\n\n\nprogramming\n\n\nrobustness\n\n\n\nSnap framework selectively unlearns information from LLMs, preserving performance and unlearning specified data.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentifying Performance-Sensitive Configurations in Software Systems through Code Analysis with LLM Agents\n\n\n\nrobustness\n\n\neducation\n\n\n\nPerfSense, an LLM-based framework, accurately identifies performance-sensitive configurations, outperforming previous methods and offering insights for future research.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nREPOEXEC: Evaluate Code Generation with a Repository-Level Executable Benchmark\n\n\n\nprogramming\n\n\n\nRepoExec benchmark evaluates code generation at repository-level, focusing on executability, correctness, and dependency integration.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIterative or Innovative? A Problem-Oriented Perspective for Code Optimization\n\n\n\nprogramming\n\n\n\nThis paper explores code optimization with LLMs, focusing on execution time reduction. It introduces a problem-oriented approach, significantly improving optimization…\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDocCGen: Document-based Controlled Code Generation\n\n\n\nprogramming\n\n\n\nDocCGen improves LLMs for structured DSLs like YAML, JSON by leveraging documentation for better code generation.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDELRec: Distilling Sequential Pattern to Enhance LLM-based Recommendation\n\n\n\nrecommender\n\n\n\nDELRec framework improves sequential recommendations by extracting patterns from SR models and integrating them into LLMs, enhancing their performance.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging\n\n\n\nprogramming\n\n\n\nTreeInstruct, a state-space planning-based agent, effectively guides students in debugging code using Socratic questioning.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLong Code Arena: a Set of Benchmarks for Long-Context Code Models\n\n\n\nprogramming\n\n\n\nLong Code Arena: Benchmarks for Project-wide Code Processing Tasks\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnveiling Assumptions: Exploring the Decisions of AI Chatbots and Human Testers\n\n\n\nprogramming\n\n\n\nLLM-based chatbots can aid software testers in decision-making, with some aligning with human intuition in preferring diverse test scenarios.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRePrompt: Planning by Automatic Prompt Engineering for Large Language Models Agents\n\n\n\nprogramming\n\n\n\nRePrompt optimizes LLM prompts for better performance in tasks like code generation and travel planning.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey on Human Preference Learning for Large Language Models\n\n\n\nrecommender\n\n\n\nThis survey explores human preference learning for LLMs, covering feedback sources, modeling, usage, and evaluation.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWaDec: Decompile WebAssembly Using Large Language Model\n\n\n\nprogramming\n\n\n\nWaDec, a fine-tuned LLM, decompiles Wasm binary code into readable source code, outperforming current tools with improved metrics and code comprehension.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf and Cross-Model Distillation for LLMs: Effective Methods for Refusal Pattern Alignment\n\n\n\nprogramming\n\n\n\nLLMs can be secured against toxic prompts via alignment techniques like SFT and RLHF. Distillation methods, especially cross-model, significantly improve refusal rates and…\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Critical Study of What Code-LLMs (Do Not) Learn\n\n\n\nprogramming\n\n\n\nCode-LLMs struggle to encode relations between syntax and identifiers, with larger models encoding less code info than smaller ones.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoSQA+: Enhancing Code Search Dataset with Matching Code\n\n\n\nprogramming\n\n\n\nCoSQA+ improves code search with diverse, high-quality query-code pairs, outperforming CoSQA and introducing a new metric, MMRR.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Collaborative Data Analytics System with Recommender for Diverse Users\n\n\n\nrecommender\n\n\n\nSLEGO system bridges developer-novice gap with modular microservices, GUI, and LLM-powered recommendations, democratizing data analytics.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-Layer Ranking with Large Language Models for News Source Recommendation\n\n\n\nrecommender\n\n\n\nLLMs improve expert recommendation for news events, using a multi-layer ranking framework on the NewsQuote dataset.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShould AI Optimize Your Code? A Comparative Study of Current Large Language Models Versus Classical Optimizing Compilers\n\n\n\nprogramming\n\n\n\nLLMs, like CodeLlama-70B, show potential in code optimization, but may generate incorrect code on large sizes, requiring automated verification. CETUS is the top optimizing…\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen Box Meets Graph Neural Network in Tag-aware Recommendation\n\n\n\nrecommender\n\n\n\nTL;DR: BoxGNN improves tag-aware recommender systems by modeling user preferences with high-order signals and box embeddings.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models for Automatic Milestone Detection in Group Discussions\n\n\n\nprogramming\n\n\n\nAuthors submit electronic manuscripts for IJCAI–24 Proceedings, which will be printed and included in the online version.\n\n\n\nJun 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3D Building Generation in Minecraft via Large Language Models\n\n\n\nprogramming\n\n\n\nLLMs can generate complete 3D buildings in Minecraft, including facades, indoor scenes, and functional blocks, with user-specified requirements.\n\n\n\nJun 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-Agent Software Development through Cross-Team Collaboration\n\n\n\nprogramming\n\n\n\nCross-Team Collaboration (CTC) improves LLM-driven software development quality by exploring multiple decision paths.\n\n\n\nJun 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhere Do Large Language Models Fail When Generating Code?\n\n\n\nprogramming\n\n\n\nLLMs struggle with reliable code generation, exhibiting varied semantic and syntactic errors. Different factors impact these errors, posing challenges for future LLM code…\n\n\n\nJun 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Next Era of Multi-objective Optimization: Large Language Models as Architects of Evolutionary Operators\n\n\n\nprogramming\n\n\n\nTL;DR: LLM-based framework evolves EA operators for MOPs, reducing expert intervention and improving performance.\n\n\n\nJun 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving LLMs for Recommendation with Out-Of-Vocabulary Tokens\n\n\n\nrecommender\n\n\n\nTL;DR: Improving LLM-based recommender systems with out-of-vocabulary tokens for better user-item representation.\n\n\n\nJun 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat’s in an embedding? Would a rose by any embedding smell as sweet?\n\n\n\neducation\n\n\n\n[TEXT] This study examines the relationship between social media use and mental health in young adults. Results suggest a negative correlation between excessive social media…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeaching Language Models to Self-Improve by Learning from Language Feedback\n\n\n\nsocial-sciences\n\n\n\nSRT uses model feedback for alignment, reducing reliance on human annotations, and significantly improves model performance across tasks and sizes.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraphCoder: Enhancing Repository-Level Code Completion via Code Context Graph-based Retrieval and Language Model\n\n\n\nprogramming\n\n\n\nGraphCoder improves code completion with a graph-based retrieval-generation process, outperforming baseline methods in accuracy and efficiency.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAccessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B\n\n\n\narchitectures\n\n\neducation\n\n\n\nMCTSr algorithm improves LLMs’ mathematical reasoning by integrating Monte Carlo Tree Search, enhancing accuracy in complex tasks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understanding in Video-LLMs\n\n\n\nproduction\n\n\neducation\n\n\n\nVideoLLaMA 2 improves video and audio understanding with competitive results in multimodal tasks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTHaLLE: Text Hyperlocally Augmented Large Language Extension – Technical Report\n\n\n\narchitectures\n\n\nproduction\n\n\nprompt-engineering\n\n\neducation\n\n\n\nLLMs show promise in financial analysis, with our 8B THaLLE models outperforming others on mock CFA exams.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuickLLaMA: Query-aware Inference Acceleration for Large Language Models\n\n\n\narchitectures\n\n\nproduction\n\n\n\nQ-LLM enhances LLMs’ context understanding, improving accuracy on benchmarks without extra training.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3D-Properties: Identifying Challenges in DPO and Charting a Path Forward\n\n\n\narchitectures\n\n\nsocial-sciences\n\n\neducation\n\n\n\nDPO in LLMs: Examining 3D-properties, issues, and solutions for better alignment with human preference.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nToxic Memes: A Survey of Computational Perspectives on the Detection and Explanation of Meme Toxicities\n\n\n\narchitectures\n\n\nhci\n\n\nsocial-sciences\n\n\n\nSurvey on toxic memes: new taxonomy, trends, and challenges in computational analysis.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTextGrad: Automatic Differentiation via Text\n\n\n\narchitectures\n\n\nproduction\n\n\n\nTextGrad optimizes compound AI systems by backpropagating textual feedback, improving performance across various tasks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpen-LLM-Leaderboard: From Multi-choice to Open-style Questions for LLMs Evaluation, Benchmark, and Arena\n\n\n\narchitectures\n\n\nproduction\n\n\nprompt-engineering\n\n\nhci\n\n\n\nLLMs may favor certain answer IDs due to biases. Open-style questions can eliminate this, but pose new challenges. We introduce the Open-LLM-Leaderboard to track LLM…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDCA-Bench: A Benchmark for Dataset Curation Agents\n\n\n\narchitectures\n\n\n\nLLMs can help curate datasets, but real-world issues are complex. DCA-Bench measures LLM agents’ ability to detect dataset quality issues.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSingle-Codec: Single-Codebook Speech Codec towards High-Performance Speech Generation\n\n\n\nproduction\n\n\n\nSingle-Codec, a single-sequence codec, improves TTS efficiency and robustness, outperforming multi-codebook codecs in quality, bandwidth, and LLM-TTS performance.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHalluDial: A Large-Scale Benchmark for Automatic Dialogue-Level Hallucination Evaluation\n\n\n\nrobustness\n\n\n\nHalluDial: A Comprehensive Benchmark for Automatic Dialogue-Level Hallucination Evaluation in LLMs.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeveraging Large Language Models for Efficient Failure Analysis in Game Development\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nThis paper presents a method using Large Language Models to automatically identify code changes causing test failures, achieving 71% accuracy and reducing debugging time by…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDARA: Decomposition-Alignment-Reasoning Autonomous Language Agent for Question Answering over Knowledge Graphs\n\n\n\nhci\n\n\nprompt-engineering\n\n\n\nDARA framework improves LLM-powered agents’ KGQA performance, outperforming in-context learning-based agents and alternative fine-tuned agents.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Tool for Test Case Scenarios Generation Using Large Language Models\n\n\n\nhci\n\n\nprompt-engineering\n\n\neducation\n\n\nprogramming\n\n\n\nTL;DR: Tool generates test case scenarios from user requirements using an LLM-based agent.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvancing Annotation of Stance in Social Media Posts: A Comparative Analysis of Large Language Models and Crowd Sourcing\n\n\n\nproduction\n\n\nsocial-sciences\n\n\n\nLLMs’ stance annotation accuracy depends on text’s explicitness, often mirroring human performance.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMcEval: Massively Multilingual Code Evaluation\n\n\n\narchitectures\n\n\nprogramming\n\n\neducation\n\n\nproduction\n\n\nprompt-engineering\n\n\n\nTL;DR: Introducing McEval, a multilingual code benchmark for 40 languages, challenging LLMs in code tasks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGuiding LLM Temporal Logic Generation with Explicit Separation of Data and Control\n\n\n\narchitectures\n\n\n\nLLMs can improve reactive program synthesis by separating control and data in temporal logic specifications, enhancing specification generation.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOPTune: Efficient Online Preference Tuning\n\n\n\nrecommender\n\n\n\nTL;DR: OPTune speeds up online preference tuning for LLMs, maintaining benefits while reducing training time.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees\n\n\n\nprogramming\n\n\n\nTP-LLaMA model outperforms baselines in tool-augmented LLMs by optimizing inference trajectories using preference data from decision trees, enhancing utilization of expert…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLimited Out-of-Context Knowledge Reasoning in Large Language Models\n\n\n\narchitectures\n\n\nproduction\n\n\neducation\n\n\n\nLLMs struggle with out-of-context reasoning and cross-lingual knowledge transfer, despite training adjustments.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEfficiently Exploring Large Language Models for Document-Level Machine Translation with In-context Learning\n\n\n\nprompt-engineering\n\n\n\nLLMs struggle with document-level translation. Our Context-Aware Prompting method (CAP) improves LLM translation accuracy, cohesion, and coherence.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMBBQ: A Dataset for Cross-Lingual Comparison of Stereotypes in Generative LLMs\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLLMs exhibit language-dependent biases, with non-English languages suffering more. MBBQ dataset reveals cross-lingual differences in bias behavior.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstruct Large Language Models to Drive like Humans\n\n\n\narchitectures\n\n\n\nInstructDriver: Transforming LLM into a motion planner with human-aligned behavior for autonomous driving.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoEvol: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation\n\n\n\nhci\n\n\neducation\n\n\n\nCoEvol: LLM-based framework improves instruction responses, outperforming baselines in MT-Bench and AlpacaEval.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFaceGPT: Self-supervised Learning to Chat about 3D Human Faces\n\n\n\neducation\n\n\n\nFaceGPT: Self-supervised 3D face reconstruction from images and text, without 3D annotations.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReinforcement Learning from Human Feedback without Reward Inference: Model-Free Algorithm and Instance-Dependent Analysis\n\n\n\narchitectures\n\n\nproduction\n\n\n\nRLHF not harder than classic RL; end-to-end RLHF can improve performance by avoiding pitfalls in reward inference.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBertaQA: How Much Do Language Models Know About Local Culture?\n\n\n\nsocial-sciences\n\n\n\nLLMs struggle with local cultural knowledge but improve with continued pre-training in that language.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models for Constrained-Based Causal Discovery\n\n\n\nhci\n\n\n\nLLMs can assist in causal graph generation, but performance varies. A statistical-inspired voting schema improves results, suggesting potential for knowledge-based CIT in…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Large Language Models for Relevance Judgments in Tetun\n\n\n\narchitectures\n\n\n\nLLMs can automate relevance assessments in low-resource languages, with results similar to high-resource languages.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaying More Attention to Source Context: Mitigating Unfaithful Translations from Large Language Model\n\n\n\nrobustness\n\n\n\nLLMs can generate unfaithful translations due to bias towards target tokens. Our methods encourage LLMs to focus more on source context, reducing hallucinatory translations.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProgressive Query Expansion for Retrieval Over Cost-constrained Data Sources\n\n\n\nrobustness\n\n\n\nProQE combines PRF and LLMs for progressive query expansion, improving accuracy and cost-effectiveness in retrieval systems.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMerging Improves Self-Critique Against Jailbreak Attacks\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nMerging and self-critique improve LLM robustness against jailbreak attacks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCAAP: Context-Aware Action Planning Prompting to Solve Computer Tasks with Front-End UI Only\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nLLM-based agent uses screenshots for context, achieving 94.4% success on MiniWoB++ problems with 1.48 demos per type, enabling broader automation applications.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Human-AI Collaboration in Healthcare: Guided Deferral Systems with Large Language Models\n\n\n\nsocial-sciences\n\n\n\nTL;DR: Human-AI collaboration improves LLMs’ reliability in healthcare, reducing uncertainty via a guided deferral system.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVersiCode: Towards Version-controllable Code Generation\n\n\n\narchitectures\n\n\nproduction\n\n\nprogramming\n\n\n\nTL;DR: VersiCode dataset tests LLMs’ ability to generate version-correct code, revealing challenges and limitations.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnomaly Detection on Unstable Logs with GPT Models\n\n\n\narchitectures\n\n\nproduction\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\nLLM (GPT-3) outperforms supervised baselines for anomaly detection on unstable logs, with fine-tuning superior to prompt engineering.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nValidating LLM-Generated Programs with Metamorphic Prompt Testing\n\n\n\nrobustness\n\n\nsecurity\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\nTL;DR: Metamorphic prompt testing detects 75% of GPT-4’s erroneous code, with 8.6% false positives.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJoint Demonstration and Preference Learning Improves Policy Alignment with Human Feedback\n\n\n\nsocial-sciences\n\n\n\nTL;DR: AIHF outperforms RLHF and DPO in aligning human preference and value in AI, especially with limited data.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards more realistic evaluation of LLM-based code generation: an experimental study and beyond\n\n\n\nrobustness\n\n\nprogramming\n\n\n\n[TEXT] This study examines the impact of social media on the mental health of adolescents. Results indicate a significant correlation between excessive social media use and…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPITCH: Productivity and Mental Well-being Coaching through Daily Conversational Interaction\n\n\n\nproduction\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\nhci\n\n\n\nPITCH: A conversational AI for productivity, using rotating prompts to boost engagement and mental well-being.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRS-Agent: Automating Remote Sensing Tasks through Intelligent Agents\n\n\n\nprompt-engineering\n\n\n\nTL;DR: RS-Agent: A LLM-driven remote sensing agent excelling in complex tasks, outperforming in scene classification, visual question answering, and object counting.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDR-RAG: Applying Dynamic Document Relevance to Retrieval-Augmented Generation for Question-Answering\n\n\n\narchitectures\n\n\n\nDR-RAG improves QA accuracy by enhancing document retrieval, using a two-stage framework and a small classifier, while maintaining efficiency.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Probabilistic Framework for LLM Hallucination Detection via Belief Tree Propagation\n\n\n\nrobustness\n\n\n\nBTProp: New method improves hallucination detection in LLMs by 3%-9% via a belief tree and hidden Markov tree model.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOllabench: Evaluating LLMs’ Reasoning for Human-centric Interdependent Cybersecurity\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nOllaBench evaluates LLMs for cybersecurity, revealing commercial models lead in accuracy but have room for improvement, while smaller open-weight models show promise.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWorld Models with Hints of Large Language Models for Goal Achieving\n\n\n\nproduction\n\n\nhci\n\n\n\nDLLM, a multi-modal RL approach, improves exploration in long-horizon tasks by integrating hinting subgoals from LLMs, outperforming recent methods in sparse-reward…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Food Safety in Supply Chains: The Potential Role of Large Language Models in Preventing Campylobacter Contamination\n\n\n\nrobustness\n\n\n\nTL;DR: GPTs can aid HACCP implementation to reduce Campylobacter contamination in the food supply chain, but barriers exist.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024\n\n\n\nhci\n\n\neducation\n\n\nsocial-sciences\n\n\n\nTeam HYU_MLLAB_KT solves SMART-101 CVPR 2024 challenge with LLM and object detection, achieving 29.5 accuracy on test set and 27.1 WOSA on challenge set.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedExQA: Medical Question Answering Benchmark with Multiple Explanations\n\n\n\neducation\n\n\n\nMedExQA benchmark evaluates medical knowledge in LLMs via explanations, highlighting the need for explainability. New medical model, MedPhi-2, outperforms Llama2-based…\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs\n\n\n\nhci\n\n\n\nTL;DR: Our method uses context-aware, query-relevant knowledge graphs to improve LLM performance on complex questions, reducing token usage by up to 67%.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models\n\n\n\nrobustness\n\n\nsecurity\n\n\nprompt-engineering\n\n\n\nTL;DR: Chain-of-Scrutiny (CoS) is a user-friendly, black-box defense against backdoor attacks in LLMs, ensuring reasoning consistency to detect attacks.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course\n\n\n\nsocial-sciences\n\n\nprogramming\n\n\neducation\n\n\nhci\n\n\nprompt-engineering\n\n\n\nStudents’ LLM usage in programming education influenced by career expectations, peer usage, and affects self-efficacy and midterm performance.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Context Learning and Fine-Tuning GPT for Argument Mining\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nGPT-4 and GPT-3.5 excel in Argument Type Classification using In-Context Learning and fine-tuning, respectively.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge language models for generating rules, yay or nay?\n\n\n\nprogramming\n\n\n\nLLMs can aid engineering safety-critical systems by generating logic rules, but lack threshold generation ability.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn Empirical Design Justice Approach to Identifying Ethical Considerations in the Intersection of Large Language Models and Social Robotics\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLLMs in social robotics offer benefits but raise ethical concerns like misinformation, biased responses, and emotional disruption, exacerbated by physical embodiment.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow Efficient is LLM-Generated Code? A Rigorous & High-Standard Benchmark\n\n\n\nprogramming\n\n\n\nLLMs struggle to generate expert-level efficient code, per new benchmark ENAMEL, which evaluates efficiency and correctness of LLM-generated code.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan I understand what I create? Self-Knowledge Evaluation of Large Language Models\n\n\n\nsocial-sciences\n\n\n\nLLMs struggle with self-generated questions due to human-alignment issues, but fine-tuning improves math performance.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLanguage Models Resist Alignment\n\n\n\nrobustness\n\n\n\nAlignment fine-tuning in LLMs is elastic and can revert to pre-training behavior, especially with larger models and more pre-training data.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDecision-Making Behavior Evaluation Framework for LLMs under Uncertain Context\n\n\n\nrobustness\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLLMs, like ChatGPT-4.0-Turbo, Claude-3-Opus, and Gemini-1.0-pro, exhibit human-like decision-making patterns but vary in risk, probability, and loss aversion. Ethical…\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSilent Signals, Loud Impact: LLMs for Word-Sense Disambiguation of Coded Dog Whistles\n\n\n\nsocial-sciences\n\n\n\nLLMs used to create dataset of 16,550 disambiguated dog whistle examples for hate speech detection and political science.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecureNet: A Comparative Study of DeBERTa and Large Language Models for Phishing Detection\n\n\n\nrobustness\n\n\nsecurity\n\n\neducation\n\n\n\nTL;DR: DeBERTa V3 outperforms LLMs like GPT-4 in detecting phishing content, achieving 95.17% recall, while GPT-4 scores 91.04%.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards a Personal Health Large Language Model\n\n\n\neducation\n\n\n\nPH-LLM, a fine-tuned Gemini model, excels in personal health insights, outperforming experts in fitness and nearing their level in sleep, while accurately predicting sleep…\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTransforming Wearable Data into Health Insights using Large Language Model Agents\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nPHIA, a new AI system, accurately interprets wearable health data, potentially enabling personalized wellness insights.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLanguage Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain\n\n\n\nsecurity\n\n\n\nNew dataset for medical triage decision-making; LLMs used as ethical decision-makers, alignable to different attributes.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMolX: Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension\n\n\n\neducation\n\n\n\nLLMs struggle with molecule-related tasks; this study introduces MolX, a multi-modal external module, to enhance LLMs’ molecule comprehension, outperforming baselines in…\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShould We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue\n\n\n\nhci\n\n\neducation\n\n\n\nLLM adaptation techniques vary in effectiveness based on base LLM and dialogue type; human evaluation is crucial.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSafety Alignment Should Be Made More Than Just a Few Tokens Deep\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nShallow safety alignment in LLMs can lead to vulnerabilities; deepening alignment beyond initial tokens can improve robustness.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM2CVD: Multi-Model Collaboration for Code Vulnerability Detection\n\n\n\nrobustness\n\n\nsecurity\n\n\nprogramming\n\n\n\nM2CVD combines LLMs and code models for improved vulnerability detection, outperforming baselines on real-world datasets.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRaccoon: Prompt Extraction Benchmark of LLM-Integrated Applications\n\n\n\nrobustness\n\n\nsecurity\n\n\nprompt-engineering\n\n\neducation\n\n\n\nRaccoon benchmark evaluates LLM susceptibility to prompt extraction attacks, offering insights and defenses.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHarnessing AI for efficient analysis of complex policy documents: a case study of Executive Order 14110\n\n\n\nsecurity\n\n\n\nAI systems Gemini 1.5 Pro and Claude 3 Opus excel in policy document analysis, rivaling human experts in accuracy but with greater efficiency.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnnotation alignment: Comparing LLM and human annotations of conversational safety\n\n\n\nsecurity\n\n\nsocial-sciences\n\n\n\nGPT-4 aligns with human safety perceptions, but more data is needed to assess demographic disparities and idiosyncratic variation.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSynth-SBDH: A Synthetic Dataset of Social and Behavioral Determinants of Health for Clinical Text\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nSynth-SBDH dataset improves SBDH extraction from clinical text, outperforming counterparts and proving effective for rare categories and resource constraints.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating the Retrieval Component in LLM-Based Question Answering Systems\n\n\n\nhci\n\n\n\nBaseline for evaluating retrievers in RAG-based chatbots shows better performance assessment, considering LLMs’ strengths and weaknesses.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey of Backdoor Attacks and Defenses on Large Language Models: Implications for Security Measures\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nTL;DR: This paper explores backdoor attacks on large language models, categorizing them by fine-tuning methods and discussing future research directions.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRepoQA: Evaluating Long Context Code Understanding\n\n\n\neducation\n\n\n\nRepoQA benchmark evaluates LLMs on long-context code understanding, showing gaps in open vs. proprietary models and language-specific strengths.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStronger, Faster, and Cheaper Log Parsing with LLMs\n\n\n\neducation\n\n\n\nLogBatcher: Cost-effective LLM-based log parser with no training or labeled data, using clustering and cache matching for efficient parsing.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection\n\n\n\nrobustness\n\n\nsecurity\n\n\nprogramming\n\n\n\nCodeBreaker: LLM-assisted backdoor attack framework for code completion models, evading vulnerability detection.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niMotion-LLM: Motion Prediction Instruction Tuning\n\n\n\nrobustness\n\n\nhci\n\n\n\niMotion-LLM: A multimodal model for trajectory prediction in multi-agent scenarios, guided by textual instructions, enhancing safety and contextual relevance.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan Language Models Serve as Text-Based World Simulators?\n\n\n\nsocial-sciences\n\n\n\nLLMs, like GPT-4, are not yet reliable text-based world simulators, despite their capabilities, as per the ByteSized32-State-Prediction benchmark.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nZero-Shot End-To-End Spoken Question Answering In Medical Domain\n\n\n\nhci\n\n\n\nE2E methodologies for SQA in the medical domain require fewer resources and improve accuracy compared to traditional cascade systems.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMrRank: Improving Question Answering Retrieval System through Multi-Result Ranking Model\n\n\n\nrobustness\n\n\n\nNew method combines IR systems for LLMs, improving performance and reducing hallucinations.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models Memorize Sensor Datasets! Implications on Human Activity Recognition Research\n\n\n\nrobustness\n\n\n\nLLMs may have seen HAR benchmark data during training, potentially skewing evaluation results.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre Large Language Models Actually Good at Text Style Transfer?\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLLMs struggle with TST in non-English languages, but finetuning improves results, highlighting the need for dedicated datasets.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecurity Vulnerability Detection with Multitask Self-Instructed Fine-Tuning of Large Language Models\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\nsecurity\n\n\neducation\n\n\n\nMSIVD: Multitask LLM & GNN technique improves vulnerability detection, outperforming existing methods with F1 scores of 0.92 (BigVul) and 0.48 (PreciseBugs).\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States\n\n\n\nrobustness\n\n\n\nLLMs learn ethics in pre-training, align concepts with emotions, and refine for safe output. Jailbreaks disrupt this process, causing harm.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey on LLM-Based Agentic Workflows and LLM-Profiled Components\n\n\n\nprompt-engineering\n\n\n\nLLMs enable advanced workflows, focusing on reusable components for clearer role understanding.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDomainRAG: A Chinese Benchmark for Evaluating Domain-specific Retrieval-Augmented Generation\n\n\n\neducation\n\n\n\nRAG models outperform LLMs in domain-specific tasks like college enrollment, but improvements are needed in areas like conversation, structure analysis, and denoising.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Superalignment Framework in Autonomous Driving with Large Language Models\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nTL;DR: Novel security framework for autonomous vehicles using multi-agent LLM approach, ensuring data protection and adherence to regulations.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo LLMs Exhibit Human-Like Reasoning? Evaluating Theory of Mind in LLMs for Open-Ended Responses\n\n\n\nhci\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLLMs struggle with Theory of Mind reasoning in open-ended questions, but incorporating human intentions and emotions can improve their performance, though not fully…\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Comprehensive Evaluation of Parameter-Efficient Fine-Tuning on Automated Program Repair\n\n\n\nprompt-engineering\n\n\n\nPEFT methods improve LLMs’ bug-fixing capabilities in APR, outperforming existing techniques. Larger parameters/datasets don’t guarantee better performance.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n61A-Bot: AI homework assistance in CS1 is fast and cheap – but is it helpful?\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\n61A-Bot reduces homework completion time, but effects may not transfer to assignments without bot access.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Against the RAG: Jamming Retrieval-Augmented Generation with Blocker Documents\n\n\n\nrobustness\n\n\n\nTL;DR: RAG systems are vulnerable to jamming attacks using blocker documents, which can prevent them from answering queries. New methods for generating blocker documents are…\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHello Again! LLM-powered Personalized Agent for Long-term Dialogue\n\n\n\nhci\n\n\n\nLD-Agent: A framework for long-term dialogue systems with event memory, persona modeling, and response generation.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLGR2: Language Guided Reward Relabeling for Accelerating Hierarchical Reinforcement Learning\n\n\n\nhci\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\nprogramming\n\n\n\nLGR2: A language-guided HRL framework for robotic control, mitigating non-stationarity and achieving high success rates in complex tasks.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDigital Business Model Analysis Using a Large Language Model\n\n\n\nhci\n\n\nprogramming\n\n\n\nThis study proposes an LLM-based method for comparing and analyzing similar companies across different business domains to support digital business model design.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMoPS: Modular Story Premise Synthesis for Open-Ended Automatic Story Generation\n\n\n\nsocial-sciences\n\n\neducation\n\n\n\nMoPS generates diverse, fascinating, and original story premises for automatic story generation, outperforming existing methods.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreativity Has Left the Chat: The Price of Debiasing Language Models\n\n\n\nhci\n\n\nprompt-engineering\n\n\n\nRLHF alignment in LLMs reduces toxicity but limits creativity, impacting marketing tasks. Balance between consistency and creativity is crucial.\n\n\n\nJun 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo LLMs Recognize me, When I is not me: Assessment of LLMs Understanding of Turkish Indexical Pronouns in Indexical Shift Contexts\n\n\n\nsocial-sciences\n\n\n\nTL;DR: Advanced LLMs struggle with Turkish’s unique grammatical challenge, the Indexical Shift, highlighting the need for low-resource language research.\n\n\n\nJun 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaCE: Parsimonious Concept Engineering for Large Language Models\n\n\n\nrobustness\n\n\n\nTL;DR: PaCE is a novel framework for aligning LLMs, improving output quality while preserving linguistic capabilities.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRetrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining\n\n\n\nprompt-engineering\n\n\n\nContext-Aware RAG improves prompt-based TTS, outperforming text-only retrieval methods.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBenchmark Data Contamination of Large Language Models: A Survey\n\n\n\nprogramming\n\n\n\nTL;DR: Large Language Models face Benchmark Data Contamination, requiring new evaluation methods for reliable performance.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVerbalized Machine Learning: Revisiting Machine Learning with Language Models\n\n\n\nprompt-engineering\n\n\n\nVML uses LLMs to solve ML problems, offering easy encoding of inductive bias, automatic model class selection, and interpretable learner updates.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemantically Diverse Language Generation for Uncertainty Estimation in Language Models\n\n\n\nrobustness\n\n\n\nLLMs can hallucinate due to predictive uncertainty. SDLG quantifies this, improving trustworthiness and efficiency in LLMs.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nText-to-Drive: Diverse Driving Behavior Synthesis via Large Language Models\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nTL;DR: Text-to-Drive (T2D) uses LLMs to generate diverse driving behaviors for autonomous vehicle simulation, offering a scalable and intuitive method for human operators.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoherent Zero-Shot Visual Instruction Generation\n\n\n\neducation\n\n\n\nNew framework generates consistent, visually appealing multi-step instructions using diffusion models and LLMs.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAligning Agents like Large Language Models\n\n\n\nhci\n\n\n\nWe align 3D agents with desired behaviors using LLM alignment techniques, improving imitation learning.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMEmbed: Rethinking Lightweight LLM’s Genuine Function in Text Classification\n\n\n\nprompt-engineering\n\n\n\nLLMEmbed: Efficient LLM-based text classification with low overhead.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPOEM: Interactive Prompt Optimization for Enhancing Multimodal Reasoning of Large Language Models\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nIntroducing ame: A Visual Analytics System for Prompt Engineering in Multimodal LLMs.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAsk LLMs Directly, What shapes your bias?: Measuring Social Bias in Large Language Models\n\n\n\nhci\n\n\n\nThis paper proposes a method to quantify social biases in LLMs by considering diverse social perceptions, offering a more nuanced understanding of bias.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRefactoring to Pythonic Idioms: A Hybrid Knowledge-Driven Approach Leveraging Large Language Models\n\n\n\nprompt-engineering\n\n\n\nHybrid approach combines LLMs and rule-based methods for Python code idiomatization, outperforming LLM-only and rule-based approaches.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFastGAS: Fast Graph-based Annotation Selection for In-Context Learning\n\n\n\nprompt-engineering\n\n\n\nFastGAS: A graph-based method for efficient instance selection in in-context learning, improving performance and reducing selection time.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models as Evaluators for Recommendation Explanations\n\n\n\nrecommender\n\n\n\nLLMs, like GPT4, can accurately evaluate recommendation explanations with proper prompts and settings, offering a cost-effective solution.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfabulation: The Surprising Value of Large Language Model Hallucinations\n\n\n\nhci\n\n\n\nLLM confabulations mirror human narrativity, offering potential value in AI communication.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDICE: Detecting In-distribution Contamination in LLM’s Fine-tuning Phase for Math Reasoning\n\n\n\neducation\n\n\n\nDICE detects in-distribution contamination in LLMs, potentially overestimating model capabilities.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey on Medical Large Language Models: Technology, Application, Trustworthiness, and Future Directions\n\n\n\nprogramming\n\n\n\nMed-LLMs revolutionize healthcare, offering clinical decision support, report generation, and medical education. Ethical considerations and robust evaluation are crucial for…\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People\n\n\n\nhci\n\n\n\nThis study proposes a method to compare human and GPT-4 conversational tones, creating an interpretable representation of their relations.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Do Language Models Learn in Context? The Structured Task Hypothesis\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\n[TEXT] This study examines the relationship between social media use and mental health in young adults. Results indicate a significant correlation between excessive social…\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM-QALM: A Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall in Large Language Models via Question Answering\n\n\n\neducation\n\n\n\nLLMs’ success in healthcare tasks depends on recall, comprehension, and integration of knowledge, with instruction tuning and fine-tuning on medical datasets showing promise.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeneralization-Enhanced Code Vulnerability Detection via Multi-Task Instruction Fine-Tuning\n\n\n\nprogramming\n\n\n\nVulLLM, a multi-task framework with LLMs, outperforms SOTA models in vulnerability detection by capturing root causes, not just superficial features.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuffer of Thoughts: Thought-Augmented Reasoning with Large Language Models\n\n\n\nprompt-engineering\n\n\n\nBoT improves LLMs’ reasoning, outperforming SOTA methods on 10 tasks with 12% cost, potentially surpassing Llama3-70B with Llama3-8B.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTool-Planner: Dynamic Solution Tree Planning for Large Language Model with Tool Clustering\n\n\n\neducation\n\n\n\nTL;DR: Tool-Planner improves tool learning in LLMs like GPT-4 and Claude 3, optimizing planning and handling errors.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nText-like Encoding of Collaborative Information in Large Language Models for Recommendation\n\n\n\nrecommender\n\n\n\nBinLLM: A novel method integrating collaborative info into LLMs via text-like binary encoding, improving recommendation performance.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Detecting LLMs Hallucination via Markov Chain-based Multi-agent Debate Framework\n\n\n\nprogramming\n\n\n\nMarkov Chain-based multi-agent debate improves hallucination detection in LLMs, outperforming baselines.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models\n\n\n\nprogramming\n\n\n\nThis work enhances LLMs for long texts by considering fragment-level relations, improving story understanding, code generation, and chatting.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nItem-Language Model for Conversational Recommendation\n\n\n\nrecommender\n\n\nprogramming\n\n\n\nTL;DR: Proposed Item-Language Model (ILM) addresses LLM limitations in recommender systems, aligning item representations with user interaction signals.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSynthetic Programming Elicitation and Repair for Text-to-Code in Very Low-Resource Programming Languages\n\n\n\nprogramming\n\n\n\nLLMs struggle with unseen programming languages. SPEAC, a new approach, enables LLMs to generate valid code for these languages.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring User Retrieval Integration towards Large Language Models for Cross-Domain Sequential Recommendation\n\n\n\nrecommender\n\n\n\nURLLM improves CDSR by integrating user retrieval and domain grounding on LLM, addressing cold-start issues and semantic reasoning.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBIPED: Pedagogically Informed Tutoring System for ESL Education\n\n\n\neducation\n\n\n\nLLMs can serve as effective tutors for English learners. We developed a dataset and models that replicate human teachers’ diverse teaching strategies.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Repository-Level Code Generation with Integrated Contextual Information\n\n\n\nprogramming\n\n\n\nCatCoder improves LLM code generation for repositories, outperforming RepoCoder by up to 17.35% in pass@k score, and shows consistent improvements across various LLMs.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPosition Debiasing Fine-Tuning for Causal Perception in Long-Term Dialogue\n\n\n\nprogramming\n\n\n\nCPD method alleviates position bias in LLMs, improving long-term dialogue relevance.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models Make Sample-Efficient Recommender Systems\n\n\n\nrecommender\n\n\n\nLLMs improve recommender systems’ efficiency, needing less training data for superior performance.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nXRec: Large Language Models for Explainable Recommendation\n\n\n\nrecommender\n\n\n\nXRec framework uses LLMs for explainable recommendations, outperforming baselines in understanding user preferences.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Mathematical Extrapolation of Large Language Models with Synthetic Data\n\n\n\nprogramming\n\n\n\nLLMs excel in various tasks but struggle with multi-step reasoning. Fine-tuning on synthetic data improves performance in complex arithmetic puzzles.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe current status of large language models in summarizing radiology report impressions\n\n\n\nprogramming\n\n\n\nLLMs struggle to replace radiologists in summarizing radiology reports, despite few-shot prompt improvements.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChain of Agents: Large Language Models Collaborating on Long-Context Tasks\n\n\n\nprogramming\n\n\n\nChain-of-Agents (CoA) improves long-context tasks by dividing text among agents, showing up to 10% improvement over baselines.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrivacy in LLM-based Recommendation: Recent Advances and Future Directions\n\n\n\nrecommender\n\n\n\nPrivacy in LLM-based recommendations: attacks, protection, challenges, and future directions.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemCoder: Training Code Language Models with Comprehensive Semantics\n\n\n\nprogramming\n\n\n\nSemCoder: A 6.7B Code LLM excels in code generation and execution reasoning, outperforming GPT-3.5-turbo, by integrating semantics from multiple dimensions.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models as Recommender Systems: A Study of Popularity Bias\n\n\n\nrecommender\n\n\n\nLLMs in recommenders can reduce popularity bias, showing less bias than traditional systems without explicit mitigation.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Understand Whole Software Repository?\n\n\n\nprogramming\n\n\n\nTL;DR: RepoUnderstander improves ASE by understanding whole repositories, outperforming SWE-agent by 18.5%.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession Context Embedding for Intent Understanding in Product Search\n\n\n\nrecommender\n\n\n\nSession embedding improves search by capturing user intent from multiple engagements, outperforming single query-item pair relevance training.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKnowledge Graph Tuning: Real-time Large Language Model Personalization based on Human Feedback\n\n\n\nrecommender\n\n\n\nKGT: A novel, efficient, and interpretable method for real-time personalization of LLMs using knowledge graphs, improving user experience and performance.\n\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKeyword-driven Retrieval-Augmented Large Language Models for Cold-start User Recommendations\n\n\n\nrecommender\n\n\n\nTL;DR: KALM4Rec improves cold-start recommendations using keywords and LLMs for candidate retrieval and re-ranking.\n\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerating Query Recommendations via LLMs\n\n\n\nrecommender\n\n\n\n[TEXT] This study examines the impact of climate change on the global wine industry. Results indicate significant shifts in wine production regions and grape varieties due…\n\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPreference Learning Algorithms Do Not Learn Preference Rankings\n\n\n\nrecommender\n\n\n\nDespite high performance, preference-tuned LLMs often have low ranking accuracy, due to limitations in the DPO objective and a gap between observed and idealized ranking…\n\n\n\nMay 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSLMRec: Empowering Small Language Models for Sequential Recommendation\n\n\n\nrecommender\n\n\n\nSLMRec: Small Language Model for Sequential Recommendation achieves 6.6x training, 8.0x inference speedups with 13% of LLM-based model parameters.\n\n\n\nMay 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteLLM-2: Multimodal Large Representation Models for Recommendation\n\n\n\nrecommender\n\n\n\nTL;DR: NoteLLM-2 enhances multimodal representation in I2I recommendations by focusing on visual content and fusing it with textual information.\n\n\n\nMay 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRAGSys: Item-Cold-Start Recommender as RAG System\n\n\n\nrecommender\n\n\n\nICL for LLMs resembles item-cold-start recommenders, prioritizing discovery and maximizing information gain. Diversity and quality bias in demonstrations are crucial for…\n\n\n\nMay 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMs for User Interest Exploration: A Hybrid Approach\n\n\n\nrecommender\n\n\n\nHybrid framework with LLMs and classic models improves novel interest discovery, boosting user enjoyment.\n\n\n\nMay 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNavigating User Experience of ChatGPT-based Conversational Recommender Systems: The Effects of Prompt Guidance and Recommendation Domain\n\n\n\nrecommender\n\n\n\nPrompt guidance in ChatGPT-based CRS enhances user experience, with book recommendations showing more engagement than job recommendations.\n\n\n\nMay 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSunnie: An Anthropomorphic LLM-Based Conversational Agent for Mental Well-Being Activity Recommendation\n\n\n\nrecommender\n\n\n\nThis LaTeX document guides authors on formatting ACM articles.\n\n\n\nMay 22, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  }
]