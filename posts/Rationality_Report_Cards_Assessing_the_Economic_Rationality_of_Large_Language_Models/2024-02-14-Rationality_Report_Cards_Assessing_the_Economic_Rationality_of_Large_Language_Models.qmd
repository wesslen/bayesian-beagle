
---
title: "Rationality Report Cards: Assessing the Economic Rationality of Large Language Models"
id: "2402.09552v1"
description: "LLMs as decision-making agents need methodology for assessing economic rationality, proposed in this paper."
author: Narun Raman, Taylor Lundy, Samuel Amouyal, Yoav Levine, Kevin Leyton-Brown, Moshe Tennenholtz
date: "2024-02-14"
image: "https://browse.arxiv.org/html/2402.09552v1/x1.png"
categories: ['hci', 'prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.09552v1/x1.png)

Overall, the article presents a comprehensive methodology for assessing the economic rationality of Large Language Models (LLMs). The authors provide a taxonomy of elements of rationality, categorizing them into different settings and modules. They also propose a benchmark distribution that quantitatively scores LLMs' performance on these elements and generates a "rationality report card" based on user-provided rubrics. The authors conducted a large-scale empirical experiment with 14 different LLMs and characterized the current state of the art and the impact of different model sizes on models' ability to exhibit rational behavior.

### Summary:
The article introduces a methodology for assessing the economic rationality of Large Language Models (LLMs) by categorizing elements of rationality into different settings and modules. It proposes a benchmark distribution that quantitatively scores LLMs' performance on these elements and generates a "rationality report card" based on user-provided rubrics. The authors conducted a large-scale empirical experiment with 14 different LLMs and characterized the current state of the art and the impact of different model sizes on models' ability to exhibit rational behavior.

### Major Findings:
1. The article introduces a taxonomy of elements of rationality, categorizing them into different settings and modules.
2. The authors propose a benchmark distribution that quantitatively scores LLMs' performance on these elements and generates a "rationality report card" based on user-provided rubrics.
3. The authors conducted a large-scale empirical experiment with 14 different LLMs and characterized the current state of the art and the impact of different model sizes on models' ability to exhibit rational behavior.

### Analysis and Critique:
- The article provides a comprehensive methodology for assessing the economic rationality of LLMs, which is a valuable contribution to the field.
- The large-scale empirical experiment with 14 different LLMs adds credibility to the findings.
- The taxonomy of elements of rationality and the benchmark distribution provide a structured approach to evaluating LLMs' performance.
- The article could benefit from a more detailed discussion of potential limitations and future research directions.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-26       |
| Abstract | [https://arxiv.org/abs/2402.09552v1](https://arxiv.org/abs/2402.09552v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.09552v1](https://browse.arxiv.org/html/2402.09552v1)       |
| Truncated       | False       |
| Word Count       | 13982       |