
---
title: "Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models"
id: "2408.07665v1"
description: "Study reveals biases in Speech Large Language Models using Spoken Stereoset dataset, with some models showing stereotypical tendencies."
author: Yi-Cheng Lin, Wei-Chih Chen, Hung-yi Lee
date: "2024-08-14"
image: "../../../bayesian-beagle.png"
categories: ['social-sciences', 'hci']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

# Summary:

**Summary:**

- The study introduces Spoken Stereoset, a dataset designed to evaluate social biases in Speech Large Language Models (SLLMs).
- The dataset consists of 17 speakers and 3640 test instances, focusing on gender and age as demographic attributes.
- The experiments reveal that most models show minimal bias, while some exhibit slightly stereotypical or anti-stereotypical tendencies.

## Major Findings:

1. The study curates Spoken Stereoset, the first bias evaluation dataset for SLLM.
2. The evaluation of SOTA SLLMs on Spoken Stereoset shows that these models exhibit minimal bias on the dataset.
3. Text-based LLMs are proven to be fair in the dataset when speaker information is not given.

## Analysis and Critique:

- The study focuses on biases related to gender and age, but other demographic attributes, such as accent and ethnicity, are not addressed.
- The dataset is limited to cultural and social norms prevalent in the United States, which may not accurately reflect biases in other social contexts.
- The study does not provide a clear methodology for mitigating biases in SLLMs, which is crucial for promoting fairness and inclusivity.
- The potential risks of releasing a dataset that includes stereotypes and biases should be carefully considered, and the dataset should be used solely for research and evaluation purposes.

Overall, the study provides valuable insights into the biases present in SLLMs and highlights the need for ongoing evaluation and mitigation strategies. However, the limitations of the dataset and the lack of a clear methodology for mitigating biases should be addressed in future research.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-20       |
| Abstract | [https://arxiv.org/abs/2408.07665v1](https://arxiv.org/abs/2408.07665v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.07665v1](https://browse.arxiv.org/html/2408.07665v1)       |
| Truncated       | False       |
| Word Count       | 4788       |