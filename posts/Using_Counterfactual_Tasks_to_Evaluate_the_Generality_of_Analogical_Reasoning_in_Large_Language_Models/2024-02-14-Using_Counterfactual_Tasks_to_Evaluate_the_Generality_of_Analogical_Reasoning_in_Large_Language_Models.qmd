
---
title: "Using Counterfactual Tasks to Evaluate the Generality of Analogical Reasoning in Large Language Models"
id: "2402.08955v1"
description: "LLMs perform well on reasoning benchmarks, but lack humanlike abstract reasoning abilities."
author: Martha Lewis, Melanie Mitchell
date: "2024-02-14"
image: "https://browse.arxiv.org/html/2402.08955v1/extracted/5407867/images/Letters.png"
categories: ['social-sciences', 'prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.08955v1/extracted/5407867/images/Letters.png)

### **Summary:**
- The article investigates the generality of analogy-making abilities in large language models (LLMs) by creating counterfactual variants of analogy problems.
- Humans and three GPT models were tested on both the original and counterfactual problems, and it was found that the performance of humans remained high for all the problems, while the GPT models' performance declined sharply on the counterfactual set.
- The results provide evidence that, despite previously reported successes of LLMs on analogical reasoning, these models lack the robustness and generality of human analogy-making.

### **Major Findings:**
1. Large language models (LLMs) lack the robustness and generality of human analogy-making.
2. The performance of humans remained high for all the problems, while the GPT models' performance declined sharply on the counterfactual set.
3. The ability of GPT to solve analogy problems may be more due to the presence of similar kinds of sequence examples in the training data, rather than an ability to reason by abstract analogy.

### **Analysis and Critique:**
- The article provides compelling evidence that large language models (LLMs) are not as robust and general as human analogy-making.
- The study raises questions about the actual reasoning abilities of LLMs and suggests that their performance may be more reliant on the presence of similar examples in the training data.
- The findings highlight the limitations of LLMs in performing abstract reasoning and suggest that further research is needed to understand how humans and LLMs form responses to analogy problems.
- The study's critical analysis of LLMs' performance provides valuable insights into the shortcomings of these models and emphasizes the need for future work to explore their reasoning abilities in different settings.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.08955v1](https://arxiv.org/abs/2402.08955v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.08955v1](https://browse.arxiv.org/html/2402.08955v1)       |
| Truncated       | False       |
| Word Count       | 5743       |