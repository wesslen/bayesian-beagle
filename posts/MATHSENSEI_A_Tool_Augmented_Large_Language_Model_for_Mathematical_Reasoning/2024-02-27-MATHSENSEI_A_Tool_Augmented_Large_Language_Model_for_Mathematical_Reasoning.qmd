
---
title: "MATHSENSEI: A Tool-Augmented Large Language Model for Mathematical Reasoning"
id: "2402.17231v1"
description: "Tool-augmented large language model MathSensei improves mathematical reasoning, outperforming gpt-3.5-turbo on complex problems."
author: Debrup Das, Debopriyo Banerjee, Somak Aditya, Ashish Kulkarni
date: "2024-02-27"
image: "https://browse.arxiv.org/html/2402.17231v1/extracted/5431889/images/knowledge-base.png"
categories: ['prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.17231v1/extracted/5431889/images/knowledge-base.png)



### Summary:
- MathSensei is a tool-augmented large language model for mathematical reasoning, augmented with tools for knowledge retrieval, program execution, and symbolic equation solving.
- MathSensei achieves 13.5% better accuracy over gpt-3.5-turbo with chain-of-thought on the MATH dataset.
- TALMs are not as effective for simpler math word problems, and the benefit increases as the complexity and required knowledge increases.

### Major Findings:
1. MathSensei achieves 13.5% better accuracy over gpt-3.5-turbo with chain-of-thought on the MATH dataset.
2. TALMs are not as effective for simpler math word problems (in GSM-8k), and the benefit increases as the complexity and required knowledge increases (progressively over AQuA, MMLU-Math, and higher level complex questions in MATH).
3. The code and data are available at https://github.com/Debrup-61/MathSensei.

### Analysis and Critique:
- The study focused on complex mathematical reasoning tasks and demonstrated the effectiveness of tool-augmented large language models. However, the study did not explore other solvers or planning methods, which could limit the generalizability of the findings.
- The study also highlighted the need for developing targeted planning strategies for mathematical TALMs, indicating potential areas for future research.
- The study provided a comprehensive evaluation of TALM frameworks across multiple mathematical datasets, showcasing the potential benefits of using multiple modules for addressing diverse mathematical problems. However, the decreased effectiveness of MathSensei on simpler datasets suggests the need for further optimization and adaptation of the tool-augmented framework.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-28       |
| Abstract | [https://arxiv.org/abs/2402.17231v1](https://arxiv.org/abs/2402.17231v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.17231v1](https://browse.arxiv.org/html/2402.17231v1)       |
| Truncated       | False       |
| Word Count       | 9639       |