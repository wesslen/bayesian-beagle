
---
title: "Improved Few-Shot Jailbreaking Can Circumvent Aligned Language Models and Their Defenses"
id: "2406.01288v1"
description: "TL;DR: Few-shot demonstrations can efficiently jailbreak LLMs with improved techniques, achieving high ASRs even with strong defenses."
author: Xiaosen Zheng, Tianyu Pang, Chao Du, Qian Liu, Jing Jiang, Min Lin
date: "2024-06-03"
image: "https://browse.arxiv.org/html/2406.01288v1/x1.png"
categories: ['security', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.01288v1/x1.png)

### Summary:

The paper presents a method for efficiently jailbreaking large language models (LLMs) using few-shot demonstrations, even within limited context sizes. The proposed method, called Improved Few-Shot Jailbreaking (I-FSJ), involves injecting special system tokens and employing demo-level random search from a collected demo pool. The authors demonstrate that I-FSJ achieves high attack success rates (ASRs) on aligned LLMs, even when enhanced by strong defenses such as perplexity detection and SmoothLLM. The method is also shown to be effective against other aligned LLMs and advanced defenses, consistently achieving nearly 100% ASRs.

### Major Findings:

1. I-FSJ achieves high ASRs on aligned LLMs, including Llama-2-7B and Llama-3-8B, even when enhanced by strong defenses.
2. The method is effective against other aligned LLMs and advanced defenses, consistently achieving nearly 100% ASRs.
3. The use of special system tokens and demo-level random search significantly improves the effectiveness of few-shot jailbreaking.

### Analysis and Critique:

The paper presents a novel and effective method for jailbreaking LLMs using few-shot demonstrations. The use of special system tokens and demo-level random search is a significant contribution to the field, as it allows for efficient jailbreaking even within limited context sizes. However, the paper does not discuss the potential ethical implications of such a method, which could be used to generate harmful or toxic content. Additionally, the method relies on the availability of a demo pool, which may not always be feasible in practice. Finally, the paper does not provide a comprehensive evaluation of the method's robustness against different types of defenses, which could be a limitation.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2406.01288v1](https://arxiv.org/abs/2406.01288v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.01288v1](https://browse.arxiv.org/html/2406.01288v1)       |
| Truncated       | False       |
| Word Count       | 7223       |