
---
title: "Towards Faithful Chain-of-Thought: Large Language Models are Bridging Reasoners"
id: "2405.18915v1"
description: "LLMs struggle with unfaithful CoT reasoning. This paper identifies two paradigms, proposes an inferential bridging method, and demonstrates its effectiveness in mitigating the issue."
author: Jiachun Li, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao
date: "2024-05-29"
image: "https://browse.arxiv.org/html/2405.18915v1/x1.png"
categories: ['robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2405.18915v1/x1.png)

### Summary:

This paper explores the faithfulness of large language models (LLMs) during the chain-of-thought (CoT) generation process. The authors identify two CoT reasoning paradigms: centralized reasoning and distributed reasoning. Centralized reasoning primarily utilizes the last step of the CoT for answering, while distributed reasoning uses information from multiple steps. The authors find that different modes of information interaction between the context and CoT form these two paradigms, and that distributed reasoning is prone to causing serious unfaithfulness issues.

The authors also jointly analyze the causal relevance among contexts, CoTs, and answers to explain the reason behind unfaithfulness issues. They observe that CoT sometimes loses key contextual information, but the model recalls this information from the context when answering, leading to unfaithful CoT issues.

To validate their findings, the authors propose the inferential bridging method to mitigate the issue. This method uses the attribution method to recall the correct information from the context and use it to enhance CoT generation, while filtering out the noisy CoT that has low semantic similarity to the question or low attribution scores with the context. The authors evaluate their methods on various reasoning benchmarks and conduct extensive experiments, demonstrating that their approach effectively alleviates the unfaithful CoT problem.

### Major Findings:

1. The authors identify two CoT reasoning paradigms: centralized reasoning and distributed reasoning. Centralized reasoning primarily utilizes the last step of the CoT for answering, while distributed reasoning uses information from multiple steps.
2. The authors find that different modes of information interaction between the context and CoT form these two paradigms, and that distributed reasoning is prone to causing serious unfaithfulness issues.
3. The authors jointly analyze the causal relevance among contexts, CoTs, and answers to explain the reason behind unfaithfulness issues. They observe that CoT sometimes loses key contextual information, but the model recalls this information from the context when answering, leading to unfaithful CoT issues.
4. The authors propose the inferential bridging method to mitigate the unfaithful CoT problem. This method uses the attribution method to recall the correct information from the context

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2405.18915v1](https://arxiv.org/abs/2405.18915v1)        |
| HTML     | [https://browse.arxiv.org/html/2405.18915v1](https://browse.arxiv.org/html/2405.18915v1)       |
| Truncated       | False       |
| Word Count       | 7526       |