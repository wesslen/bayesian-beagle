
---
title: "ShapeLLM: Universal 3D Object Understanding for Embodied Interaction"
id: "2402.17766v1"
description: "ShapeLLM is a 3D language model for object understanding and interaction, achieving state-of-the-art performance."
author: Zekun Qi, Runpei Dong, Shaochen Zhang, Haoran Geng, Chunrui Han, Zheng Ge, Li Yi, Kaisheng Ma
date: "2024-02-27"
image: "https://browse.arxiv.org/html/2402.17766v1/x2.png"
categories: ['hci', 'education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.17766v1/x2.png)

### **Summary:**
- ShapeLLM is the first 3D Multimodal Large Language Model designed for embodied interaction, exploring a universal 3D object understanding with 3D point clouds and languages.
- It is built upon an improved 3D encoder, ReCon++, that benefits from multi-view image distillation for enhanced geometry understanding.
- ShapeLLM achieves state-of-the-art performance in 3D geometry understanding and language-unified 3D interaction tasks, such as embodied visual grounding.

### **Major Findings:**
1. **Improved 3D Encoder:** ReCon++ sets a new state-of-the-art representation transferring on both downstream fine-tuned and zero-shot 3D object recognition.
2. **Selective Multi-View Distillation:** ShapeLLM extends ReCon to ReCon++ as the 3D encoder by integrating multi-view distillation, achieving superior performance in 3D geometry understanding.
3. **3D Visual Instruction Tuning:** ShapeLLM is trained through instruction-following tuning on constructed language-output data, achieving state-of-the-art performance in 3D multimodal comprehension tasks.

### **Analysis and Critique:**
- The article presents significant advancements in 3D multimodal comprehension and embodied interaction. However, the evaluation benchmark, 3D MM-Vet, may need further validation and comparison with other benchmarks to establish its reliability and effectiveness.
- The study demonstrates the robustness of ShapeLLM in processing occluded inputs and its superior preference by humans, indicating its potential for real-world applications.
- The article highlights the necessity of 3D point clouds as inputs and scaling up 3D representation learning, which may pave the way for future research in this area. However, further research is needed to address potential biases and limitations in the training data and evaluation metrics.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-28       |
| Abstract | [https://arxiv.org/abs/2402.17766v1](https://arxiv.org/abs/2402.17766v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.17766v1](https://browse.arxiv.org/html/2402.17766v1)       |
| Truncated       | False       |
| Word Count       | 10087       |