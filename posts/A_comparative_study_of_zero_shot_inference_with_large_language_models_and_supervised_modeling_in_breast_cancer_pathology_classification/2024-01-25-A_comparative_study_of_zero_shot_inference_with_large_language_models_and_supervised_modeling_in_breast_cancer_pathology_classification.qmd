
---
title: "A comparative study of zero-shot inference with large language models and supervised modeling in breast cancer pathology classification"
id: "2401.13887v1"
description: "GPT-4 model outperforms supervised models in classifying breast cancer pathology reports."
author: Madhumita Sushil, Travis Zack, Divneet Mandair, Zhiwei Zheng, Ahmed Wali, Yan-Ning Yu, Yuwei Quan, Atul J. Butte
date: "2024-01-25"
image: "../../../bayesian-beagle.png"
categories: ['social-sciences']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### Summary:

The study compared the zero-shot classification capability of large language models (LLMs) with supervised classification performance in breast cancer pathology. The GPT-4 model outperformed or performed as well as the best supervised model, the LSTM-Att model, across all 13 tasks, with an average macro F1 score of 0.83. The GPT-4 model showed difficulties in inferences from multiple samples and complex task design. The study concluded that LLMs can reduce the burden of large-scale data labeling for complex tasks where large annotated datasets cannot be easily collected. The GPT-4 model had difficulties differentiating the unknown class from the class indicating no lymph node involvement and no lympho-vascular invasion. Errors were more prevalent in multi-label tasks than single-label tasks, and manual analysis revealed consistent sources of errors in biomarker reporting, nuclear grade reporting, and multi-label tasks. The study also provided detailed guidelines for annotating various aspects of histopathology and cytology reports, including the selection of histology types, lymph node involvement, biopsy type, grade, ER, PR, HER2, and margins. Additionally, the study outlined the specific versions of the GPT models used for the experiments, the API version, temperature setting, and the retrieval method for the outputs, along with detailed prompts for extracting related pairs of entities for all the sub-tasks.

### Major Findings:
1. The GPT-4 model outperformed or performed as well as the best supervised model, the LSTM-Att model, across all 13 tasks, with an average macro F1 score of 0.83.
2. Errors in the GPT-4 model were more prevalent in multi-label tasks than single-label tasks, with consistent sources of errors in biomarker reporting, nuclear grade reporting, and multi-label tasks.
3. The study provided detailed guidelines for annotating various aspects of histopathology and cytology reports, ensuring accurate and consistent data collection for further analysis and research.

### Analysis and Critique:
The study's findings demonstrate the potential of large language models to reduce the need for curating large annotated datasets for supervised learning in breast cancer pathology classification. However, the errors identified in the GPT-4 model's performance highlight the challenges in using large language models for clinical natural language processing. Further research and development are needed to address these limitations and improve the model's accuracy and reliability in clinical settings. Additionally, while the study provided detailed guidelines for annotating histopathology and cytology reports, further research is needed to validate the effectiveness and consistency of these guidelines in real-world clinical settings.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2401.13887v1](https://arxiv.org/abs/2401.13887v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.13887v1](https://browse.arxiv.org/html/2401.13887v1)       |
| Truncated       | True       |
| Word Count       | 15585       |