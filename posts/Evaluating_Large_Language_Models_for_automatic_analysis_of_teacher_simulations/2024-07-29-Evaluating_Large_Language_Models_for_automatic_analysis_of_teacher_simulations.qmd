
---
title: "Evaluating Large Language Models for automatic analysis of teacher simulations"
id: "2407.20360v1"
description: "LLMs like Llama 3 outperform DeBERTaV3 in identifying new characteristics in DS for teacher education, offering stable performance and automatic evaluation."
author: David de-Fitero-Dominguez, Mariano Albaladejo-Gonz√°lez, Antonio Garcia-Cabot, Eva Garcia-Lopez, Antonio Moreno-Cediel, Erin Barno, Justin Reich
date: "2024-07-29"
image: "https://browse.arxiv.org/html/2407.20360v1/x1.png"
categories: ['hci', 'social-sciences', 'education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2407.20360v1/x1.png)

### Summary:

- The study evaluates the performance of Large Language Models (LLMs) in identifying characteristics in the responses of Digital Simulations (DS) for teacher education.
- The models evaluated are DeBERTaV3 and Llama 3, using zero-shot, few-shot, and fine-tuning configurations.
- The experiments reveal a significant variation in the LLMs' performance depending on the characteristic to identify.
- DeBERTaV3 significantly reduces its performance when identifying new characteristics, while Llama 3 performs better and shows more stable performance.
- Llama 3 is recommended for DS where teacher educators need to introduce new characteristics, as they can change depending on the simulation or the educational objectives.

### Major Findings:

1. The performance of LLMs in identifying characteristics in DS for teacher education varies significantly depending on the characteristic to identify.
2. DeBERTaV3 significantly reduces its performance when identifying new characteristics, while Llama 3 performs better and shows more stable performance.
3. Llama 3 is recommended for DS where teacher educators need to introduce new characteristics, as they can change depending on the simulation or the educational objectives.

### Analysis and Critique:

- The study provides valuable insights into the performance of LLMs in identifying characteristics in DS for teacher education.
- The findings highlight the importance of selecting the appropriate LLM for the task, as the performance can vary significantly depending on the characteristic to identify.
- The study could be extended by testing LLMs in other simulation environments and exploring why some characteristics are more difficult to identify.
- The adoption and perception of educators regarding the integration of LLMs in DS should also be evaluated in future research.
- The study does not provide a detailed analysis of the limitations and potential biases of the LLMs, which could be a topic for future research.
- The study does not discuss the potential impact of the LLMs on the learning outcomes of the teacher candidates, which could be an important consideration for educators.
- The study does not provide a comparison of the performance of the LLMs with other methods for identifying characteristics in DS, which could be a valuable addition to the research.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-06       |
| Abstract | [https://arxiv.org/abs/2407.20360v1](https://arxiv.org/abs/2407.20360v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.20360v1](https://browse.arxiv.org/html/2407.20360v1)       |
| Truncated       | False       |
| Word Count       | 8097       |