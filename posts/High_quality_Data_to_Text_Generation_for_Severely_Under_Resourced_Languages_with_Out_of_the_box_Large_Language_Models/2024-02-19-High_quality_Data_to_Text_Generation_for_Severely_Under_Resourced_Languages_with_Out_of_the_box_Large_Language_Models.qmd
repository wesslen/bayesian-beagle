
---
title: "High-quality Data-to-Text Generation for Severely Under-Resourced Languages with Out-of-the-box Large Language Models"
id: "2402.12267v1"
description: "LLMs outperform for under-resourced languages, showing potential to bridge performance gap."
author: Michela Lorandi, Anya Belz
date: "2024-02-19"
image: "../../img/2402.12267v1/image_1.png"
categories: ['production', 'architectures', 'social-sciences']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.12267v1/image_1.png)

### Summary:
- The article explores the use of large language models (LLMs) for data-to-text generation in severely under-resourced languages such as Irish, Welsh, Breton, and Maltese.
- The study finds that LLMs easily set the state of the art for the under-resourced languages by substantial margins, as measured by both automatic and human evaluations.
- The results demonstrate the great potential of LLMs to bridge the performance gap for under-resourced languages.

### Major Findings:
1. LLMs easily set the state of the art for the under-resourced languages by substantial margins, as measured by both automatic and human evaluations.
2. Human evaluation shows on-a-par performance with humans for the best systems, but BLEU scores collapse compared to English, casting doubt on the metricâ€™s suitability for evaluating non-task-specific systems.
3. The results demonstrate the great potential of LLMs to bridge the performance gap for under-resourced languages.

### Analysis and Critique:
- The study demonstrates the potential of LLMs for data-to-text generation in under-resourced languages. However, the use of paid APIs and the need for large computational resources may limit the accessibility and reproducibility of the study.
- The study raises concerns about the suitability of BLEU scores for evaluating non-task-specific systems, indicating the need for alternative evaluation metrics.
- The article acknowledges the limitations of the study, including the potential for bias in generated texts and the risk of producing offensive or incorrect content. These ethical considerations are important for future research and real-world applications.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-20       |
| Abstract | [https://arxiv.org/abs/2402.12267v1](https://arxiv.org/abs/2402.12267v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.12267v1](https://browse.arxiv.org/html/2402.12267v1)       |
| Truncated       | False       |
| Word Count       | 14520       |