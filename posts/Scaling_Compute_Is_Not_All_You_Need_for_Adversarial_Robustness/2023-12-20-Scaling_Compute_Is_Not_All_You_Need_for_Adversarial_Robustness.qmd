
---
title: "Scaling Compute Is Not All You Need for Adversarial Robustness"
id: "2312.13131v1"
description: "Progress in adversarial robust deep learning, but large models and computing power limitations. Benchmarking framework available."
author: Edoardo Debenedetti, Zishen Wan, Maksym Andriushchenko, Vikash Sehwag, Kshitij Bhardwaj, Bhavya Kailkhura
date: "2023-12-20"
image: "../../../bayesian-beagle.png"
categories: ['security']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### **Summary:**
The article discusses the limitations of using increased computational power to drive advances in adversarial robustness in deep learning models. The authors explore the scaling laws for adversarial robustness and find that increasing the FLOPs (floating-point operations) needed for adversarial training does not bring as much advantage as it does for standard training in terms of performance improvements. They also find that some of the top-performing techniques are difficult to exactly reproduce, suggesting that they are not robust enough for minor changes in the training setup.

### **Major Findings:**
1. The accuracy under ℓ∞ adversarial perturbations improved from 44% to 71% over the last six years, but existing state-of-the-art is still far from satisfactory.
2. Increasing the FLOPs needed for adversarial training does not bring as much advantage as it does for standard training in terms of performance improvements.
3. Some of the top-performing techniques are difficult to exactly reproduce, suggesting that they are not robust enough for minor changes in the training setup.

### **Analysis and Critique:**
The article provides valuable insights into the limitations of scaling compute for achieving adversarial robustness in deep learning models. However, it has several limitations, including the inability to exactly reproduce the results from previous work, testing on a low-resolution and small-sized dataset, and lack of confidence intervals. The authors also acknowledge the impracticality of scaling up to larger datasets due to computational constraints. The findings suggest that scaling compute alone may not be an effective or efficient approach to solving the adversarial robustness problem. The article highlights the need for more innovative and comprehensive approaches to achieving robust and resilient AI systems, urging the field to explore new directions.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2312.13131v1](https://arxiv.org/abs/2312.13131v1)        |
| HTML     | [https://browse.arxiv.org/html/2312.13131v1](https://browse.arxiv.org/html/2312.13131v1)       |
| Truncated       | False       |
| Word Count       | 9246       |