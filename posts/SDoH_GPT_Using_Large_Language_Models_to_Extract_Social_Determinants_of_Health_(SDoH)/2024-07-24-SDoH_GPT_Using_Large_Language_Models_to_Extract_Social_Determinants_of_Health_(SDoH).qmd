
---
title: "SDoH-GPT: Using Large Language Models to Extract Social Determinants of Health (SDoH)"
id: "2407.17126v1"
description: "SDoH-GPT: A few-shot LLM method for SDoH extraction, reducing time and cost by 10-20x, with high accuracy and consistency."
author: Bernardo Consoli, Xizhi Wu, Song Wang, Xinyu Zhao, Yanshan Wang, Justin Rousseau, Tom Hartvigsen, Li Shen, Huanmei Wu, Yifan Peng, Qi Long, Tianlong Chen, Ying Ding
date: "2024-07-24"
image: "../../img/2407.17126v1/image_1.png"
categories: ['social-sciences']
format:
  html:
    code-overflow: wrap
---

![](../../img/2407.17126v1/image_1.png)

### Summary:

The study introduces SDoH-GPT, a simple and effective few-shot Large Language Model (LLM) method that leverages contrastive examples and concise instructions to extract Social Determinants of Health (SDoH) without relying on extensive medical annotations or costly human intervention. SDoH-GPT achieved tenfold and twentyfold reductions in time and cost, respectively, and superior consistency with human annotators measured by Cohen's kappa of up to 0.92. The innovative combination of SDoH-GPT and XGBoost ensures high accuracy and computational efficiency while consistently maintaining 0.90+ AUROC scores. Testing across three distinct datasets confirmed its robustness and accuracy.

### Major Findings:

1. SDoH-GPT achieved comparable accuracy to human annotations with a tenfold reduced time and a twentyfold decrease in cost for 2048 sample annotations.
2. SDoH-GPT can become a thousandfold cheaper and a hundredfold faster while maintaining comparable accuracy with human annotations.
3. SDoH-GPT has reached superior consistency with human annotators measured by Cohenâ€™s kappa: 0.72 to 0.92 in MIMIC-SDBH, 0.71 to 0.88 in Suicide Notes, and 0.70 to 0.91 in Sleep Notes.

### Analysis and Critique:

1. The study highlights the potential of leveraging LLMs to revolutionize medical note classification, demonstrating their capability to achieve highly accurate classifications with significantly reduced time and cost.
2. The study does not discuss the potential limitations or biases of using LLMs for SDoH extraction, such as the risk of overfitting or the need for diverse and representative training data.
3. The study does not address the potential ethical implications of using LLMs for SDoH extraction, such as the need for informed consent or the potential for misuse of sensitive health information.
4. The study does not explore the potential applications of SDoH-GPT beyond medical note classification, such as its use in predictive modeling or personalized medicine.
5. The study does not discuss the potential impact of SDoH-G

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-30       |
| Abstract | [https://arxiv.org/abs/2407.17126v1](https://arxiv.org/abs/2407.17126v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.17126v1](https://browse.arxiv.org/html/2407.17126v1)       |
| Truncated       | False       |
| Word Count       | 9716       |