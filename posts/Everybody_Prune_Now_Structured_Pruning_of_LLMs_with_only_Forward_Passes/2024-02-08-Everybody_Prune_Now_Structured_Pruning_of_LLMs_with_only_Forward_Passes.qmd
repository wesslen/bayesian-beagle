
---
title: "Everybody Prune Now: Structured Pruning of LLMs with only Forward Passes"
id: "2402.05406v1"
description: "Bonsai method prunes large models for faster, accurate performance with limited hardware."
author: Lucio Dery, Steven Kolawole, Jean-Francois Kagey, Virginia Smith, Graham Neubig, Ameet Talwalkar
date: "2024-02-08"
image: "../../../bayesian-beagle.png"
categories: ['architectures', 'education']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### **Summary:**
- The article explores the problem of structured pruning of large language models (LLMs) using only forward passes.
- The authors develop Bonsai, a gradient-free, perturbative pruning method capable of delivering small, fast, and accurate pruned models.
- Bonsai outputs pruned models that outperform those generated by more expensive gradient-based structured pruning methods and are twice as fast as those generated by semi-structured pruning methods requiring comparable resources.
- The authors leverage Bonsai to produce a new sub-2B model using a single A6000 that yields state-of-the-art performance on 4/6 tasks on the Huggingface Open LLM leaderboard.

### Major Findings:
1. Bonsai is a gradient-free, perturbative pruning method capable of delivering small, fast, and accurate pruned models.
2. Bonsai outputs pruned models that outperform those generated by more expensive gradient-based structured pruning methods and are twice as fast as those generated by semi-structured pruning methods requiring comparable resources.
3. Bonsai is leveraged to produce a new sub-2B model using a single A6000 that yields state-of-the-art performance on 4/6 tasks on the Huggingface Open LLM leaderboard.

### Analysis and Critique:
- The article presents a novel approach to structured pruning of LLMs using only forward passes, which is a significant contribution to the field.
- The methodological approach of Bonsai is effective in producing accurate and fast pruned models, addressing the resource constraints faced by lay practitioners.
- The article does not discuss potential limitations or biases in the proposed method, and it would be beneficial to address these aspects for a more comprehensive analysis.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-26       |
| Abstract | [https://arxiv.org/abs/2402.05406v1](https://arxiv.org/abs/2402.05406v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.05406v1](https://browse.arxiv.org/html/2402.05406v1)       |
| Truncated       | False       |
| Word Count       | 13577       |