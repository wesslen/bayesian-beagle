
---
title: "Step-Back Profiling: Distilling User History for Personalized Scientific Writing"
id: "2406.14275v1"
description: "Step-back Profiling personalizes LLMs for collaborative scientific writing, outperforming baselines on LaMP benchmark."
author: Xiangru Tang, Xingyao Zhang, Yanjun Shao, Jie Wu, Yilun Zhao, Arman Cohan, Ming Gong, Dongmei Zhang, Mark Gerstein
date: "2024-06-20"
image: "https://browse.arxiv.org/html/2406.14275v1/x1.png"
categories: ['social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.14275v1/x1.png)

### Summary:

- The paper introduces Step-back Profiling, a training-free framework for personalizing large language models (LLMs) by distilling user histories into concise profiles.
- The authors construct a Personalized Scientific Writing (PSW) dataset to study multi-user personalization, focusing on collaborative writing tasks.
- The Step-back Profiling approach outperforms baselines on the general personalization benchmark (LaMP) and the PSW dataset.
- The method improves performance over standard personalization methods in the LaMP benchmark and enables more efficient memory management.
- The PSW dataset includes tasks such as research interest generation, research topic generation, research question generation, paper abstract generation, and paper title generation.
- The paper uses GPT-4-turbo with chain-of-thought prompting as a judge to evaluate the generated outputs on the PSW benchmark in multiple dimensions.

### Major Findings:

1. Step-back Profiling improves performance over standard personalization methods in the LaMP benchmark and enables more efficient memory management.
2. The PSW dataset is introduced to study multi-user personalization, focusing on collaborative writing tasks.
3. The Step-back Profiling approach outperforms baselines on the general personalization benchmark (LaMP) and the PSW dataset.

### Analysis and Critique:

- The paper does not discuss the limitations of the Step-back Profiling approach, such as potential biases in the user profiles or the scalability of the method for large-scale applications.
- The paper does not provide a detailed comparison of the Step-back Profiling approach with other personalization methods, such as fine-tuning or meta-learning.
- The paper does not discuss the potential ethical implications of using user histories for personalization, such as privacy concerns or the risk of reinforcing biases in the data.
- The paper does not provide a detailed analysis of the performance of the Step-back Profiling approach on different types of tasks or domains.
- The paper does not discuss the potential impact of the Step-back Profiling approach on the interpretability and controllability of personalized models.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-23       |
| Abstract | [https://arxiv.org/abs/2406.14275v1](https://arxiv.org/abs/2406.14275v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.14275v1](https://browse.arxiv.org/html/2406.14275v1)       |
| Truncated       | False       |
| Word Count       | 5200       |