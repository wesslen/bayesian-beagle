
---
title: "ConflictBank: A Benchmark for Evaluating the Influence of Knowledge Conflicts in LLM"
id: "2408.12076v1"
description: "ConflictBank: First Benchmark for Evaluating Knowledge Conflicts in Large Language Models."
author: Zhaochen Su, Jun Zhang, Xiaoye Qu, Tong Zhu, Yanshu Li, Jiashuo Sun, Juntao Li, Min Zhang, Yu Cheng
date: "2024-08-22"
image: "https://browse.arxiv.org/html/2408.12076v1/x1.png"
categories: ['robustness', 'hci', 'education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.12076v1/x1.png)

### Summary:

The paper presents ConflictBank, a comprehensive benchmark for evaluating knowledge conflicts in large language models (LLMs). The benchmark covers three main conflict causes: misinformation, temporal discrepancies, and semantic divergences. It includes 7,453,853 claim-evidence pairs and 553,117 QA pairs, generated using LLMs and structured by transforming knowledge triples and qualifiers into a quintuplet format. The benchmark can be used to conduct experiments on conflicts in retrieved knowledge, embedded knowledge, and their interplay. The paper also presents pilot experiments on twelve LLMs across four model series and provides insights into their behaviors under different conflict scenarios.

### Major Findings:

1. ConflictBank is the first comprehensive benchmark for knowledge conflicts, including 7M claim-evidence pairs and 553k QA pairs, covering three conflict causes in the real-world scenario: misinformation, temporal, and semantic conflicts.
2. ConflictBank can be utilized to conduct a series of experiments about knowledge conflicts, including conflicts in retrieved knowledge, embedded knowledge, and their interplay.
3. The paper presents in-depth pilot experiments on twelve LLMs across four model series and provides comprehensive analyses about model scales, conflict causes, and conflict types.

### Analysis and Critique:

1. The paper provides a comprehensive benchmark for evaluating knowledge conflicts in LLMs, which is a significant contribution to the field. However, the paper does not discuss the limitations of the benchmark or the potential biases that may be present in the data.
2. The paper presents pilot experiments on twelve LLMs, but it does not provide a detailed analysis of the results or discuss the implications of the findings.
3. The paper does not discuss the potential applications of the benchmark or how it can be used to improve the reliability and trustworthiness of LLMs.
4. The paper does not discuss the potential ethical implications of using LLMs to generate data or the potential risks associated with using the benchmark to evaluate LLMs.
5. The paper does not discuss the potential impact of the benchmark on the development of LLMs or the broader implications of the research for the field of natural language processing.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-27       |
| Abstract | [https://arxiv.org/abs/2408.12076v1](https://arxiv.org/abs/2408.12076v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.12076v1](https://browse.arxiv.org/html/2408.12076v1)       |
| Truncated       | False       |
| Word Count       | 6478       |