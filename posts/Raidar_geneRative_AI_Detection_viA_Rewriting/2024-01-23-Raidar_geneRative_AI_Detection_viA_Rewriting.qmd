
---
title: "Raidar: geneRative AI Detection viA Rewriting"
id: "2401.12970v1"
description: "Large language models (LLMs) alter human-written text more than AI-generated text. Our Raidar method improves AI content detection."
author: ['Chengzhi Mao', 'Carl Vondrick', 'Hao Wang', 'Junfeng Yang']
date: "2024-01-23"
image: "https://browse.arxiv.org/html/2401.12970v1/x1.png"
categories: ['production']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.12970v1/x1.png)

### Summary:

The article introduces "Raidar," an approach to detect machine-generated text using large language models (LLMs) by prompting the models to rewrite text and calculating the editing distance of the output. The findings suggest that LLMs tend to make fewer modifications to AI-generated text than human-written text when prompted to rewrite the text. "Raidar" significantly improves the detection scores of existing AI content detection models across various domains. The method operates solely on word symbols, making it compatible with black-box LLMs and inherently robust on new content.

### Major Findings:
1. Large language models (LLMs) are more likely to modify human-written text than AI-generated text when tasked with rewriting.
2. "Raidar" significantly improves the F1 detection scores of existing AI content detection models across various domains, with gains of up to 29 points.
3. The method operates solely on word symbols, making it compatible with black-box LLMs and inherently robust on new content.

### Analysis and Critique:
The article provides valuable insights into the detection of machine-generated content using large language models, presenting a novel approach that enhances detection accuracy across various domains. However, while the "Raidar" method demonstrates effectiveness, there are aspects that require further exploration and clarification:
- The article focuses on the quantitative performance of the "Raidar" method, but it does not delve into potential limitations or biases in the detection process. Further investigation into the robustness of the method, especially in the presence of adversarial attacks, is essential.
- The study does not deeply investigate the potential ethical implications of its findings, particularly regarding the potential impact on natural language processing in various applications.
- Additionally, the article highlights the effectiveness of the method across different datasets and domains, but it does not extensively discuss potential limitations or challenges that may arise when applying the method in real-world scenarios.

In conclusion, while the article presents a promising method for detecting machine-generated text, further research is needed to address potential limitations and ethical considerations associated with the implementation of this approach.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-31       |
| Abstract | [http://arxiv.org/abs/2401.12970v1](http://arxiv.org/abs/2401.12970v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.12970v1](https://browse.arxiv.org/html/2401.12970v1)       |
| Truncated       | False       |
| Word Count       | 8701       |