
---
title: "Beyond Agreement: Diagnosing the Rationale Alignment of Automated Essay Scoring Methods based on Linguistically-informed Counterfactuals"
id: "2405.19433v1"
description: "LLMs enhance AES, focusing on sentence-level, conventions, complexity, and organization, improving transparency in model decisions."
author: Yupei Wang, Renfen Hu, Zhe Zhao
date: "2024-05-29"
image: "../../../bayesian-beagle.png"
categories: ['social-sciences']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

# Summary

The paper "Beyond Agreement: Diagnosing the Rationale Alignment of Automated Essay Scoring Methods based on Linguistically-informed Counterfactuals" by Yupei Wang, Renfen Hu, and Zhe Zhao proposes a method to understand the decision-making basis of neural models in automated essay scoring (AES). The authors use counterfactual intervention assisted by Large Language Models (LLMs) to reveal that BERT-like models primarily focus on sentence-level features, while LLMs are attuned to conventions, language complexity, and organization, indicating a more comprehensive alignment with scoring rubrics. The proposed method improves the understanding of neural AES methods and can be applied to other domains seeking transparency in model-driven decisions.

# Major Findings

1. BERT-like models can discern knowledge in conventions and language complexity but struggle to grasp the logical structure and coherence of texts.
2. LLMs, although having lower score agreement than traditional models, display a superior inherent alignment with human expertsâ€™ reasoning. Through few-shot learning or fine-tuning, LLMs can achieve both high score agreement and rationale alignment.

# Analysis and Critique

The paper presents an innovative approach to understanding the decision-making basis of neural models in AES. The use of counterfactual intervention and LLMs provides a more comprehensive understanding of the models' reasoning. However, the paper does not discuss the potential limitations or biases of the proposed method. Additionally, the paper does not provide a detailed comparison of the proposed method with existing methods for understanding the decision-making basis of neural models. Further research is needed to evaluate the proposed method's effectiveness and generalizability to other domains.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2405.19433v1](https://arxiv.org/abs/2405.19433v1)        |
| HTML     | [https://browse.arxiv.org/html/2405.19433v1](https://browse.arxiv.org/html/2405.19433v1)       |
| Truncated       | False       |
| Word Count       | 14385       |