
---
title: "Aligning Teacher with Student Preferences for Tailored Training Data Generation"
id: "2406.19227v1"
description: "ARTE: A framework aligning teacher models with student preferences for tailored training examples in Knowledge Distillation."
author: Yantao Liu, Zhao Zhang, Zijun Yao, Shulin Cao, Lei Hou, Juanzi Li
date: "2024-06-27"
image: "https://browse.arxiv.org/html/2406.19227v1/x1.png"
categories: ['architectures', 'education', 'prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.19227v1/x1.png)

### Summary:

The paper introduces ARTE, a novel framework for tailored training example generation in Knowledge Distillation. ARTE aligns the teacher language model with the student language model's preferences to generate tailored training examples, inspired by responsive teaching in pedagogy. The framework consists of three main steps: Knowledge Elicitation, Preference Collection, and Preference Alignment. Extensive experiments on academic benchmarks demonstrate the superiority of ARTE over existing instruction-tuning datasets distilled from powerful LLMs. The paper also investigates the generalization of the aligned teacher model across tasks and students.

### Major Findings:

1. ARTE outperforms existing instruction-tuning datasets by a large margin in extensive experiments on academic reasoning benchmarks.
2. The fine-tuned student model in ARTE achieves better generalization ability on reasoning tasks, as demonstrated by its performance on various academic reasoning benchmarks.
3. The aligned teacher model in ARTE can generate tailored training examples for unseen tasks and unseen student models, as shown by its generalization across tasks and students.

### Analysis and Critique:

1. The paper does not discuss the computational cost of ARTE, which could be a potential limitation for its practical application.
2. The paper does not provide a detailed comparison of ARTE with other alignment methods, such as PPO, which could be a potential area for further research.
3. The paper does not discuss the potential biases or limitations of the preference collection step, which could impact the quality of the tailored training examples generated by ARTE.
4. The paper does not provide a detailed analysis of the impact of the size of the preference set on the performance of ARTE, which could be a potential area for further research.
5. The paper does not discuss the potential impact of the choice of the teacher and student models on the performance of ARTE, which could be a potential area for further research.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-07       |
| Abstract | [https://arxiv.org/abs/2406.19227v1](https://arxiv.org/abs/2406.19227v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.19227v1](https://browse.arxiv.org/html/2406.19227v1)       |
| Truncated       | False       |
| Word Count       | 8697       |