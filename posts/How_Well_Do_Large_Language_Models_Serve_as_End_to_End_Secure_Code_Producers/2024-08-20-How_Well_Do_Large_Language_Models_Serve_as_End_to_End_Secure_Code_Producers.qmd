
---
title: "How Well Do Large Language Models Serve as End-to-End Secure Code Producers?"
id: "2408.10495v1"
description: "LLMs, like GPT-4, generate vulnerable code due to lack of security awareness. They struggle to identify and repair their own vulnerabilities, but a lightweight tool can improve repair success rates."
author: Jianian Gong, Nachuan Duan, Ziheng Tao, Zhaohui Gong, Yuan Yuan, Minlie Huang
date: "2024-08-20"
image: "https://browse.arxiv.org/html/2408.10495v1/x1.png"
categories: ['programming']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.10495v1/x1.png)

# Summary:

The study investigates the performance of four large language models (LLMs), GPT-3.5, GPT-4, Code Llama, and CodeGeeX2, in generating secure Python code across 67 CWEs. The results reveal that the 4 tested LLMs generated over 75% vulnerable code on the SecurityEval benchmark. The study also examines the LLMs' efficacy in judging and fixing insecure code generated by themselves, as well as their ability to produce safer code through a simple feedback-driven iterative self-repair process.

# Major Findings:

1. Large language models lack awareness of scenario-relevant security risks, leading to the generation of over 75% vulnerable code on the SecurityEval benchmark.
2. LLMs such as GPT-3.5 and GPT-4 are unable to precisely identify vulnerabilities in the code they generated.
3. GPT-3.5 and GPT-4 can achieve 33.2%~59.6% success rates in repairing the insecure code produced by the 4 LLMs, but they both perform poorly when repairing self-produced code, indicating self-repair "blind spots".

# Analysis and Critique:

The study provides valuable insights into the performance of LLMs in generating secure code and their ability to identify and repair vulnerabilities. However, the research is limited to Python code and the SecurityEval benchmark, which may not fully represent the capabilities of LLMs in other programming languages or scenarios. Additionally, the study does not explore the impact of different prompt engineering techniques on the performance of LLMs. Further research is needed to evaluate the generalizability of the findings and to investigate the potential of LLMs in other programming languages and scenarios.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-27       |
| Abstract | [https://arxiv.org/abs/2408.10495v1](https://arxiv.org/abs/2408.10495v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.10495v1](https://browse.arxiv.org/html/2408.10495v1)       |
| Truncated       | False       |
| Word Count       | 11571       |