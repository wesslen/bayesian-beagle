
---
title: "It's Never Too Late: Fusing Acoustic Information into Large Language Models for Automatic Speech Recognition"
id: "2402.05457v1"
description: "LLMs used for error correction in ASR, UADF improves WER and reduces data uncertainty."
author: Chen Chen, Ruizhe Li, Yuchen Hu, Sabato Marco Siniscalchi, Pin-Yu Chen, Ensiong Chng, Chao-Han Huck Yang
date: "2024-02-08"
image: "../../img/2402.05457v1/image_1.png"
categories: ['architectures']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.05457v1/image_1.png)

### Summary:
- The section discusses the challenges of fusing acoustic information into large language models (LLMs) for automatic speech recognition (ASR) tasks.
- It introduces a novel late fusion solution called Uncertainty-Aware Dynamic Fusion (UADF) to address the limitations of existing fusion mechanisms.
- UADF is a multimodal fusion approach implemented into an auto-regressive decoding process, which works in two stages: analyzing and calibrating the token-level LLM decision, and dynamically assimilating information from the acoustic modality.
- Experimental evidence shows that UADF surpasses existing fusion mechanisms, yielding significant improvements in word error rate (WER) while mitigating data uncertainty issues in LLM and addressing the poor generalization relied on sole modality during fusion.
- The authors also demonstrate that UADF seamlessly adapts to audio-visual speech recognition.

### Major Findings:
1. UADF surpasses existing fusion mechanisms, yielding significant improvements in word error rate (WER) while mitigating data uncertainty issues in LLM and addressing the poor generalization relied on sole modality during fusion.
2. UADF seamlessly adapts to audio-visual speech recognition.
3. The method addresses the issue of overconfidence in models and dynamically assimilates information from the audio modality, leading to more reasonable token-level decisions.

### Analysis and Critique:
- The section introduces a novel approach, UADF, for integrating acoustic information into LLMs for speech recognition tasks.
- The experimental results demonstrate the effectiveness of UADF in improving performance across different datasets and noise conditions.
- The method addresses the issue of overconfidence in models and dynamically assimilates information from the audio modality, leading to more reasonable token-level decisions.
- The findings have implications for noise-robust ASR and audio-visual speech recognition, showcasing the versatility and effectiveness of the proposed approach.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.05457v1](https://arxiv.org/abs/2402.05457v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.05457v1](https://browse.arxiv.org/html/2402.05457v1)       |
| Truncated       | True       |
| Word Count       | 17836       |