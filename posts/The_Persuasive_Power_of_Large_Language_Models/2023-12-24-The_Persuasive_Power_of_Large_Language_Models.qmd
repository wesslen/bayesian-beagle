
---
title: "The Persuasive Power of Large Language Models"
description: "Large Language Models could generate effective arguments, shaping public opinion in online discourse. Synthetic social systems mimic human opinion dynamics."
author: Simon Martin Breum, Daniel Vædele Egdal, Victor Gram Mortensen, Anders Giovanni Møller, Luca Maria Aiello
date: "2023-12-24"
image: "https://browse.arxiv.org/html/2312.15523v1/extracted/5315218/img/chat-example.png"
filename: "gpt-3.5-turbo-1106"
categories: ['hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2312.15523v1/extracted/5315218/img/chat-example.png)

### Major Takeaways

- **Persuasive Capabilities**: The study explores the persuasive capabilities of Large Language Models (LLMs) and their ability to influence opinion dynamics in human populations and online social media.
  
- **Argument Effectiveness**: LLM-generated arguments, particularly those conveying factual knowledge, trust, support, and status, were deemed most effective based on evaluations by both humans and LLM agents.

- **Alignment with Human Dynamics**: The findings suggest that simulating human opinion dynamics is within the capabilities of LLMs, and artificial agents have the potential to play an important role in collective processes of opinion formation in online social media.

### Introduction
The introduction outlines the increasing capabilities of LLMs to act as human-like social agents and raises questions about whether these agents can generate effective arguments to influence public opinion and whether they can interact with each other to replicate human dynamics of persuasion.

### Methods
- **Conversation Setup**: The study established a dyadic interaction between a Convincer and a Skeptic agent, both based on the Llama-2-70B-chat model. The interaction unfolded in five stages with fixed and generated text for different stages.

- **Persuasive Language of the Convincer**: The Convincer was instructed to generate arguments incorporating different dimensions of social pragmatics, and their effectiveness was assessed.

- **Stubbornness of the Skeptic**: The study tested various levels of the Skeptic's stubbornness and evaluated their impact on persuasion.

- **Evaluation**: The persuasiveness of LLM-generated arguments was quantified and compared with evaluations by human judges through crowdsourced annotations.

### Results
- **Persuading AI Agents**: The probability of persuasion was found to decrease with the Skeptic’s stubbornness. The dimensions of trust, support, and status were most effective in altering the Skeptic’s viewpoint.

- **Persuading Humans**: Human evaluations revealed parallels with LLM agent dynamics, with trust, support, knowledge, and status being ranked higher. However, humans exhibited a stronger preference for knowledge-based arguments compared to LLM agents.

### Discussion
The discussion section highlighted the study's limitations and proposed avenues for future research, including multi-turn conversations among multiple agents and diverse profiles for individual agents.

### Critique
The study showcases the potential of LLMs in persuasive language generation but has limitations in replicating complex human dynamics and understanding the mechanisms that induce LLM agents to signal a change of opinion. Additionally, the oversimplification, lack of diverse profiles for agents, and a focus on single-turn interactions limit the generalizability of the findings to real-world social media interactions. The study also acknowledges the ethical implications of deploying AI agents for persuasion and the potential risks associated with their use, suggesting the need for research to understand and mitigate those risks. Further, the comparison between LLM and human responses and the study's focus on single topics could limit its applicability to broader and diverse real-world scenarios.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-04       |
| Abstract | [http://arxiv.org/abs/2312.15523v1](http://arxiv.org/abs/2312.15523v1)        |
| HTML     | [https://browse.arxiv.org/html/2312.15523v1](https://browse.arxiv.org/html/2312.15523v1)       |
| Truncated       | False       |
| Word Count       | 9545       |