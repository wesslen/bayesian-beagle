
---
title: "Watermark Stealing in Large Language Models"
id: "2402.19361v1"
description: "Automated watermark stealing enables effective spoofing, scrubbing of LLM schemes.

This summarizes the article's main point that a new watermark stealing (WS) algorithm can be used to both spoof and scrub state-of-the-art large language models (LLMs) with a high success rate, challenging common beliefs about the robustness of LLM watermarking."
author: Nikola JovanoviÄ‡, Robin Staab, Martin Vechev
date: "2024-02-29"
image: "../../../bayesian-beagle.png"
categories: ['robustness', 'security']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### Watermark Stealing in Large Language Models

**Summary:**

* LLM watermarking has been proposed as a promising way to detect AI-generated content.
* However, the authors identify a fundamental vulnerability called watermark stealing (WS), where querying the API of a watermarked LLM can reverse-engineer the watermark, enabling spoofing and scrubbing attacks.
* The authors propose an automated WS algorithm and demonstrate that, for under $50, an attacker can successfully spoof and scrub state-of-the-art watermarked schemes with an average success rate of over 80%.

**Major Findings:**

1. Watermark stealing (WS) is a fundamental vulnerability in LLM watermarking schemes.
2. An attacker can use WS to launch both spoofing and scrubbing attacks on state-of-the-art watermarked

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x7b-instruct       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.19361v1](https://arxiv.org/abs/2402.19361v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.19361v1](https://browse.arxiv.org/html/2402.19361v1)       |
| Truncated       | False       |
| Word Count       | 21936       |