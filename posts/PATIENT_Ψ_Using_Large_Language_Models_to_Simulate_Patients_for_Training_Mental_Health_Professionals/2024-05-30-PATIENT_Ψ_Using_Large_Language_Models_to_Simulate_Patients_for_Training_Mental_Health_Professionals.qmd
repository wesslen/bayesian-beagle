
---
title: "PATIENT-Ψ: Using Large Language Models to Simulate Patients for Training Mental Health Professionals"
id: "2405.19660v1"
description: "Patient-ΨΨ\Psiroman_Ψ: LLM-based CBT training tool improves trainee skills, perceived as closer to real patient interactions than GPT-4."
author: Ruiyi Wang, Stephanie Milani, Jamie C. Chiu, Shaun M. Eack, Travis Labrum, Samuel M. Murphy, Nev Jones, Kate Hardy, Hong Shen, Fei Fang, Zhiyu Zoey Chen
date: "2024-05-30"
image: "https://browse.arxiv.org/html/2405.19660v1/x1.png"
categories: ['hci', 'prompt-engineering', 'education', 'social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2405.19660v1/x1.png)

# Summary:

The paper proposes Patient-, a novel patient simulation framework for cognitive behavior therapy (CBT) training. The framework uses large language models (LLMs) programmed with patient cognitive models to act as a simulated therapy patient. The interactive training scheme, Patient--Trainer, allows mental health trainees to practice formulating the cognitive model of the patient. A user study involving 4 mental health trainees and 10 experts demonstrated that practice using Patient--Trainer significantly enhances the perceived skill acquisition and confidence of the trainees beyond existing forms of training. The experts perceived Patient- to be closer to real patient interactions than GPT-4, and Patient--Trainer holds strong promise to improve trainee competencies.

# Major Findings:

1. The use of LLMs to simulate patients for CBT training can significantly enhance the perceived skill acquisition and confidence of mental health trainees.
2. Patient- is perceived to be closer to real patient interactions than GPT-4, indicating the potential of LLMs to accurately mimic the communicative behaviors of real patients.
3. The interactive training scheme, Patient--Trainer, holds strong promise to improve trainee competencies in CBT formulation.

# Analysis and Critique:

1. The study's small sample size (4 trainees and 10 experts) may limit the generalizability of the findings.
2. The study relies on perceived improvements rather than objective measures of skill acquisition, which may not accurately reflect actual improvements in trainee competencies.
3. The study does not address potential limitations or biases in the use of LLMs for patient simulation, such as the potential for overfitting to specific patient profiles or the inability to capture the full complexity of real patient interactions.
4. The study does not discuss the potential ethical implications of using LLMs for patient simulation, such as the potential for deception or the impact on patient privacy.
5. The study does not address potential methodological issues, such as the potential for experimenter bias or the need for additional validation studies.
6. The study does not discuss potential areas for further research, such as the potential for LLMs to be used for other types of therapy or the potential for LLMs to be used in conjunction with other training methods.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2405.19660v1](https://arxiv.org/abs/2405.19660v1)        |
| HTML     | [https://browse.arxiv.org/html/2405.19660v1](https://browse.arxiv.org/html/2405.19660v1)       |
| Truncated       | False       |
| Word Count       | 7599       |