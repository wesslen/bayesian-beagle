
---
title: "Large Language Model as an Assignment Evaluator: Insights, Feedback, and Challenges in a 1000+ Student Course"
id: "2407.05216v1"
description: "LLM-based evaluators, like GPT-4, can be used in classrooms, but students can manipulate them and they may not always follow instructions."
author: Cheng-Han Chiang, Wei-Chih Chen, Chun-Yi Kuan, Chienchou Yang, Hung-yi Lee
date: "2024-07-07"
image: "https://browse.arxiv.org/html/2407.05216v1/x1.png"
categories: ['robustness', 'education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2407.05216v1/x1.png)

### Summary:
- The empirical report shares the experience of using GPT-4 as an automatic assignment evaluator in a university course with 1,028 students.
- Students generally accept LLM-based assignment evaluators, but they note that the LLM sometimes fails to adhere to evaluation instructions and can be manipulated to output specific strings for high scores.
- The report provides recommendations for integrating LLM-based evaluators into future classrooms based on student feedback and the authors' experience.

### Major Findings:
1. **LLM-based Evaluators Acceptable to Students**: With proper settings, using LLM-based evaluators is acceptable to 75% of the students.
2. **LLM-based Evaluators Limitations**: 51% of students found that the LLM-based evaluator cannot correctly follow the required output format, and 22% of the students observed that the evaluation given by LLM-based evaluators sometimes does not properly follow the evaluation criteria.
3. **Manipulation of LLM-based Evaluators**: 47% of the students attempted to prompt-hack the LLM-based evaluator for a higher score. LLM-based evaluators are vulnerable to prompt hacking, but hacking can be easily detected.

### Analysis and Critique:
- The study provides valuable insights into the use of LLM-based evaluators in real-world classrooms, but it is limited by the specific course and student population.
- The findings may not generalize to other courses or student demographics, and further research is needed to explore the effectiveness of LLM-based evaluators in diverse educational contexts.
- The report highlights the potential for students to manipulate LLM-based evaluators, which raises concerns about the validity and reliability of automated grading systems.
- The authors' recommendations for integrating LLM-based evaluators into future classrooms are based on their experience and student feedback, but they may not address all potential issues and challenges.
- Future research should investigate strategies for mitigating the risks of manipulation and ensuring the fairness and accuracy of LLM-based evaluators in educational settings.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-09       |
| Abstract | [https://arxiv.org/abs/2407.05216v1](https://arxiv.org/abs/2407.05216v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.05216v1](https://browse.arxiv.org/html/2407.05216v1)       |
| Truncated       | False       |
| Word Count       | 5931       |