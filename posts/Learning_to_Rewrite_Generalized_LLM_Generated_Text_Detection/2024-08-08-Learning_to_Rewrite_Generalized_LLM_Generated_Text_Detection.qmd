
---
title: "Learning to Rewrite: Generalized LLM-Generated Text Detection"
id: "2408.04237v1"
description: "LLMs can detect machine-generated text better when trained to rewrite input, improving detection across domains."
author: Wei Hao, Ran Li, Weiliang Zhao, Junfeng Yang, Chengzhi Mao
date: "2024-08-08"
image: "https://browse.arxiv.org/html/2408.04237v1/x1.png"
categories: ['robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.04237v1/x1.png)

# Summary:
**Summary:**
The paper presents a novel approach, L2R (Learning to Rewrite), for detecting text generated by large language models (LLMs). L2R trains an LLM to perform more edits when rewriting human-generated text and fewer edits when rewriting LLM-generated text across various domains. This method outperforms traditional classifiers, which often struggle to generalize among different domains. The authors built a diverse AI text dataset encompassing 21 distinct domains and demonstrated that L2R outperforms the state-of-the-art rewriting-based approach by 9.2% on F1 score, averaged among the 21 domains.

## Major Findings:
1. **Effective LLM-Generated Text Detection:** L2R effectively detects machine-generated text by training LLMs to capture the rich structure of LLM content and strengthening it through targeted training.
2. **Generalization Across Domains:** L2R generalizes well across different domains, outperforming the state-of-the-art zero-shot classifier by up to 20.6% on AUROC score and the rewriting classifier by 9.2% on F1 score.
3. **Diverse AI Text Dataset:** The authors built the world's most diverse AI text dataset, encompassing 21 distinct domains, to demonstrate the effectiveness of L2R in detecting LLM-generated text.

## Analysis and Critique:
- **Limited Evaluation of LLMs:** The paper focuses on evaluating L2R with three popular LLMs (GPT-4o, Gemini, and Llama-3). Further evaluation with a broader range of LLMs could provide a more comprehensive understanding of L2R's performance.
- **Potential Overfitting:** The authors mention the risk of overfitting during the fine-tuning process. While they propose a calibration loss to prevent this, it is unclear how effective this method is in preventing overfitting in all cases.
- **Slow Inference Runtime:** The authors acknowledge that L2R has a relatively slow inference runtime compared to zero-shot detectors. This limitation could impact the practicality of L2R in real-world applications.


## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-13       |
| Abstract | [https://arxiv.org/abs/2408.04237v1](https://arxiv.org/abs/2408.04237v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.04237v1](https://browse.arxiv.org/html/2408.04237v1)       |
| Truncated       | False       |
| Word Count       | 5177       |