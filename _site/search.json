[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Bayesian beagle",
    "section": "",
    "text": "Welcome to the Bayesian beagle blog! This project is a unique intersection of machine learning and scientific communication, providing a platform where readers can quickly get insights from the latest research papers hosted on ArXiv. Utilizing state-of-the-art Large Language Models (LLMs), our system generates concise, comprehensible summaries of complex research articles, covering a wide array of disciplines.\nAll content is LLM generated. Assume skepticism and verify in the original paper as LLM models are imperfect and can struggle under certain circumstances.\nOur blog is built using Quarto and then published with Netlify.\n\n\n\n\ngraph LR\n    A[\"Download weekly Arxiv articles\"] --&gt; B[\"Predict and Filter LLM topic\"]\n    B --&gt; C[\"Summarize short docs\"]\n    B --&gt; D[\"Summarize by Map-Reduce long docs\"]\n    C --&gt; E[\"Update website with summaries weekly\"]\n    D --&gt; E"
  },
  {
    "objectID": "posts/Does_Object_Grounding_Really_Reduce_Hallucination_of_Large_Vision_Language_Models/2024-06-20-Does_Object_Grounding_Really_Reduce_Hallucination_of_Large_Vision_Language_Models.html#appendix",
    "href": "posts/Does_Object_Grounding_Really_Reduce_Hallucination_of_Large_Vision_Language_Models/2024-06-20-Does_Object_Grounding_Really_Reduce_Hallucination_of_Large_Vision_Language_Models.html#appendix",
    "title": "Does Object Grounding Really Reduce Hallucination of Large Vision-Language Models?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14492v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14492v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7908"
  },
  {
    "objectID": "posts/Investigating_Mysteries_of_CoT_Augmented_Distillation/2024-06-20-Investigating_Mysteries_of_CoT_Augmented_Distillation.html#appendix",
    "href": "posts/Investigating_Mysteries_of_CoT_Augmented_Distillation/2024-06-20-Investigating_Mysteries_of_CoT_Augmented_Distillation.html#appendix",
    "title": "Investigating Mysteries of CoT-Augmented Distillation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14511v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14511v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8455"
  },
  {
    "objectID": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#major-findings",
    "href": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#major-findings",
    "title": "Digital Business Model Analysis Using a Large Language Model",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe study demonstrates the potential of using LLMs for analyzing and designing new business models, which is still an evolving field with scarce research.\nThe proposed method can support idea generation in digital business model design by learning patterns from the commonalities of DX cases and using this knowledge as a reference when considering DX initiatives.\nThe analysis examples show that LLM can effectively extract similar DX cases, not only within the same industry but also from different industries, and consider their commonalities to support the ideation of digital business models."
  },
  {
    "objectID": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#analysis-and-critique",
    "href": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#analysis-and-critique",
    "title": "Digital Business Model Analysis Using a Large Language Model",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe study’s findings are preliminary, and further research is needed to refine the analytical methods using advanced NLP technologies and broaden the examination of digital business models across a wider spectrum of industries.\nThe proposed method potentially offers companies easy access to insights into the use of digital technologies and business model innovations that have previously been less accessible.\nThe authors plan to develop a recommendation system, possibly implemented via chatbots, that could suggest similar cases to act as a catalyst for companies aiming to accelerate their DX efforts.\nThe study makes certain academic contributions by demonstrating the potential of this approach, but more research is needed to fully understand its implications and limitations."
  },
  {
    "objectID": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#appendix",
    "href": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#appendix",
    "title": "Digital Business Model Analysis Using a Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05741v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05741v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3431"
  },
  {
    "objectID": "posts/BertaQA_How_Much_Do_Language_Models_Know_About_Local_Culture/2024-06-11-BertaQA_How_Much_Do_Language_Models_Know_About_Local_Culture.html#appendix",
    "href": "posts/BertaQA_How_Much_Do_Language_Models_Know_About_Local_Culture/2024-06-11-BertaQA_How_Much_Do_Language_Models_Know_About_Local_Culture.html#appendix",
    "title": "BertaQA: How Much Do Language Models Know About Local Culture?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07302v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07302v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5979"
  },
  {
    "objectID": "posts/Evaluating_the_Retrieval_Component_in_LLM_Based_Question_Answering_Systems/2024-06-10-Evaluating_the_Retrieval_Component_in_LLM_Based_Question_Answering_Systems.html#appendix",
    "href": "posts/Evaluating_the_Retrieval_Component_in_LLM_Based_Question_Answering_Systems/2024-06-10-Evaluating_the_Retrieval_Component_in_LLM_Based_Question_Answering_Systems.html#appendix",
    "title": "Evaluating the Retrieval Component in LLM-Based Question Answering Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06458v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06458v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4825"
  },
  {
    "objectID": "posts/Limited_Out_of_Context_Knowledge_Reasoning_in_Large_Language_Models/2024-06-11-Limited_Out_of_Context_Knowledge_Reasoning_in_Large_Language_Models.html#appendix",
    "href": "posts/Limited_Out_of_Context_Knowledge_Reasoning_in_Large_Language_Models/2024-06-11-Limited_Out_of_Context_Knowledge_Reasoning_in_Large_Language_Models.html#appendix",
    "title": "Limited Out-of-Context Knowledge Reasoning in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07393v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07393v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5931"
  },
  {
    "objectID": "posts/Can_Language_Models_Serve_as_Text_Based_World_Simulators/2024-06-10-Can_Language_Models_Serve_as_Text_Based_World_Simulators.html#appendix",
    "href": "posts/Can_Language_Models_Serve_as_Text_Based_World_Simulators/2024-06-10-Can_Language_Models_Serve_as_Text_Based_World_Simulators.html#appendix",
    "title": "Can Language Models Serve as Text-Based World Simulators?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06485v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06485v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6025"
  },
  {
    "objectID": "posts/RePrompt_Planning_by_Automatic_Prompt_Engineering_for_Large_Language_Models_Agents/2024-06-17-RePrompt_Planning_by_Automatic_Prompt_Engineering_for_Large_Language_Models_Agents.html#appendix",
    "href": "posts/RePrompt_Planning_by_Automatic_Prompt_Engineering_for_Large_Language_Models_Agents/2024-06-17-RePrompt_Planning_by_Automatic_Prompt_Engineering_for_Large_Language_Models_Agents.html#appendix",
    "title": "RePrompt: Planning by Automatic Prompt Engineering for Large Language Models Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11132v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11132v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9868"
  },
  {
    "objectID": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#major-findings",
    "href": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#major-findings",
    "title": "World Models with Hints of Large Language Models for Goal Achieving",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nDLLM integrates hinting subgoals from LLMs into the model rollouts to encourage goal discovery and reaching in challenging tasks.\nDLLM assigns higher intrinsic rewards to samples that align with the hints outlined by the language model during model rollouts.\nDLLM outperforms recent methods in various challenging, sparse-reward environments such as HomeGrid, Crafter, and Minecraft."
  },
  {
    "objectID": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#analysis-and-critique",
    "href": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#analysis-and-critique",
    "title": "World Models with Hints of Large Language Models for Goal Achieving",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents an innovative approach to addressing the challenges of long-horizon tasks and sparse rewards in RL. The use of LLMs to provide hinting subgoals is a promising direction for improving exploration and goal-reaching in complex environments. However, the paper does not discuss potential limitations or biases in the LLMs used, which could impact the performance of DLLM. Additionally, the paper does not provide a detailed comparison with other methods that use intrinsic rewards or LLMs for goal-setting. Further research is needed to evaluate the robustness and generalizability of DLLM in different environments and tasks."
  },
  {
    "objectID": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#appendix",
    "href": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#appendix",
    "title": "World Models with Hints of Large Language Models for Goal Achieving",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07381v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07381v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10623"
  },
  {
    "objectID": "posts/GenderAlign_An_Alignment_Dataset_for_Mitigating_Gender_Bias_in_Large_Language_Models/2024-06-20-GenderAlign_An_Alignment_Dataset_for_Mitigating_Gender_Bias_in_Large_Language_Models.html#appendix",
    "href": "posts/GenderAlign_An_Alignment_Dataset_for_Mitigating_Gender_Bias_in_Large_Language_Models/2024-06-20-GenderAlign_An_Alignment_Dataset_for_Mitigating_Gender_Bias_in_Large_Language_Models.html#appendix",
    "title": "GenderAlign: An Alignment Dataset for Mitigating Gender Bias in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13925v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13925v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6741"
  },
  {
    "objectID": "posts/PaCE_Parsimonious_Concept_Engineering_for_Large_Language_Models/2024-06-06-PaCE_Parsimonious_Concept_Engineering_for_Large_Language_Models.html#appendix",
    "href": "posts/PaCE_Parsimonious_Concept_Engineering_for_Large_Language_Models/2024-06-06-PaCE_Parsimonious_Concept_Engineering_for_Large_Language_Models.html#appendix",
    "title": "PaCE: Parsimonious Concept Engineering for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04331v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04331v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9538"
  },
  {
    "objectID": "posts/DELRec_Distilling_Sequential_Pattern_to_Enhance_LLM_based_Recommendation/2024-06-17-DELRec_Distilling_Sequential_Pattern_to_Enhance_LLM_based_Recommendation.html#appendix",
    "href": "posts/DELRec_Distilling_Sequential_Pattern_to_Enhance_LLM_based_Recommendation/2024-06-17-DELRec_Distilling_Sequential_Pattern_to_Enhance_LLM_based_Recommendation.html#appendix",
    "title": "DELRec: Distilling Sequential Pattern to Enhance LLM-based Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11156v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11156v2\n\n\nTruncated\nFalse\n\n\nWord Count\n8935"
  },
  {
    "objectID": "posts/A_Survey_on_LLM_Based_Agentic_Workflows_and_LLM_Profiled_Components/2024-06-09-A_Survey_on_LLM_Based_Agentic_Workflows_and_LLM_Profiled_Components.html#appendix",
    "href": "posts/A_Survey_on_LLM_Based_Agentic_Workflows_and_LLM_Profiled_Components/2024-06-09-A_Survey_on_LLM_Based_Agentic_Workflows_and_LLM_Profiled_Components.html#appendix",
    "title": "A Survey on LLM-Based Agentic Workflows and LLM-Profiled Components",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05804v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05804v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5941"
  },
  {
    "objectID": "posts/Are_LLMs_Naturally_Good_at_Synthetic_Tabular_Data_Generation/2024-06-20-Are_LLMs_Naturally_Good_at_Synthetic_Tabular_Data_Generation.html#appendix",
    "href": "posts/Are_LLMs_Naturally_Good_at_Synthetic_Tabular_Data_Generation/2024-06-20-Are_LLMs_Naturally_Good_at_Synthetic_Tabular_Data_Generation.html#appendix",
    "title": "Are LLMs Naturally Good at Synthetic Tabular Data Generation?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14541v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14541v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10309"
  },
  {
    "objectID": "posts/Prose_to_P4_Leveraging_High_Level_Languages/2024-06-19-Prose_to_P4_Leveraging_High_Level_Languages.html#appendix",
    "href": "posts/Prose_to_P4_Leveraging_High_Level_Languages/2024-06-19-Prose_to_P4_Leveraging_High_Level_Languages.html#appendix",
    "title": "Prose-to-P4: Leveraging High Level Languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13679v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13679v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4347"
  },
  {
    "objectID": "posts/Silent_Signals_Loud_Impact_LLMs_for_Word_Sense_Disambiguation_of_Coded_Dog_Whistles/2024-06-10-Silent_Signals_Loud_Impact_LLMs_for_Word_Sense_Disambiguation_of_Coded_Dog_Whistles.html#appendix",
    "href": "posts/Silent_Signals_Loud_Impact_LLMs_for_Word_Sense_Disambiguation_of_Coded_Dog_Whistles/2024-06-10-Silent_Signals_Loud_Impact_LLMs_for_Word_Sense_Disambiguation_of_Coded_Dog_Whistles.html#appendix",
    "title": "Silent Signals, Loud Impact: LLMs for Word-Sense Disambiguation of Coded Dog Whistles",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06840v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06840v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8725"
  },
  {
    "objectID": "posts/HIGHT_Hierarchical_Graph_Tokenization_for_Graph_Language_Alignment/2024-06-20-HIGHT_Hierarchical_Graph_Tokenization_for_Graph_Language_Alignment.html#appendix",
    "href": "posts/HIGHT_Hierarchical_Graph_Tokenization_for_Graph_Language_Alignment/2024-06-20-HIGHT_Hierarchical_Graph_Tokenization_for_Graph_Language_Alignment.html#appendix",
    "title": "HIGHT: Hierarchical Graph Tokenization for Graph-Language Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14021v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14021v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11102"
  },
  {
    "objectID": "posts/SEC_QA_A_Systematic_Evaluation_Corpus_for_Financial_QA/2024-06-20-SEC_QA_A_Systematic_Evaluation_Corpus_for_Financial_QA.html#appendix",
    "href": "posts/SEC_QA_A_Systematic_Evaluation_Corpus_for_Financial_QA/2024-06-20-SEC_QA_A_Systematic_Evaluation_Corpus_for_Financial_QA.html#appendix",
    "title": "SEC-QA: A Systematic Evaluation Corpus for Financial QA",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14394v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14394v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6714"
  },
  {
    "objectID": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#major-findings",
    "href": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#major-findings",
    "title": "Characterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People",
    "section": "Major Findings",
    "text": "Major Findings\n\nThe proposed method enables the characterization of conversational tones and their taxonomies in any target human population as well as LLMs, without relying on predefined taxonomies or constrained sets of stimuli.\nThe study addresses the challenges of biased apriori taxonomy and biased stimulus set in existing research on conversational tones.\nThe paper presents an additional experiment where humans and GPT-4 annotated all sentences with all tones, resulting in an interpretable geometric representation of relations between conversational tones in humans and GPT-4."
  },
  {
    "objectID": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#analysis-and-critique",
    "href": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#analysis-and-critique",
    "title": "Characterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\nThe paper presents a novel and promising approach to characterize conversational tones and their taxonomies in humans and LLMs. The proposed method addresses the limitations"
  },
  {
    "objectID": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#appendix",
    "href": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#appendix",
    "title": "Characterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04278v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04278v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14313"
  },
  {
    "objectID": "posts/LLMs_for_User_Interest_Exploration_A_Hybrid_Approach/2024-05-25-LLMs_for_User_Interest_Exploration_A_Hybrid_Approach.html#appendix",
    "href": "posts/LLMs_for_User_Interest_Exploration_A_Hybrid_Approach/2024-05-25-LLMs_for_User_Interest_Exploration_A_Hybrid_Approach.html#appendix",
    "title": "LLMs for User Interest Exploration: A Hybrid Approach",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.16363v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.16363v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5005"
  },
  {
    "objectID": "posts/LGR2_Language_Guided_Reward_Relabeling_for_Accelerating_Hierarchical_Reinforcement_Learning/2024-06-09-LGR2_Language_Guided_Reward_Relabeling_for_Accelerating_Hierarchical_Reinforcement_Learning.html#appendix",
    "href": "posts/LGR2_Language_Guided_Reward_Relabeling_for_Accelerating_Hierarchical_Reinforcement_Learning/2024-06-09-LGR2_Language_Guided_Reward_Relabeling_for_Accelerating_Hierarchical_Reinforcement_Learning.html#appendix",
    "title": "LGR2: Language Guided Reward Relabeling for Accelerating Hierarchical Reinforcement Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05881v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05881v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10516"
  },
  {
    "objectID": "posts/SynDARin_Synthesising_Datasets_for_Automated_Reasoning_in_Low_Resource_Languages/2024-06-20-SynDARin_Synthesising_Datasets_for_Automated_Reasoning_in_Low_Resource_Languages.html#appendix",
    "href": "posts/SynDARin_Synthesising_Datasets_for_Automated_Reasoning_in_Low_Resource_Languages/2024-06-20-SynDARin_Synthesising_Datasets_for_Automated_Reasoning_in_Low_Resource_Languages.html#appendix",
    "title": "SynDARin: Synthesising Datasets for Automated Reasoning in Low-Resource Languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14425v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14425v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3686"
  },
  {
    "objectID": "posts/A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions/2024-06-06-A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions.html",
    "href": "posts/A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions/2024-06-06-A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions.html",
    "title": "A Survey on Medical Large Language Models: Technology, Application, Trustworthiness, and Future Directions",
    "section": "",
    "text": "Summary:\nThis survey provides a comprehensive overview of Medical Large Language Models (Med-LLMs), outlining their evolution from general to medical-specific domains and their transformative impact on healthcare. The study explores the fundamental history and technology of LLMs, delving into the progressive adaptation and refinements of general LLM models in the medical domain. It emphasizes advanced algorithms that boost the LLMs’ performance in handling complicated medical environments, including clinical reasoning, knowledge graph, retrieval-augmented generation, human alignment, and multi-modal learning.\nThe survey also explores the extensive applications of Med-LLMs across domains such as clinical decision support, report generation, and medical education, illustrating their potential to streamline healthcare services and augment patient outcomes. Recognizing the imperative for responsible innovation, the study discusses the challenges of ensuring fairness, accountability, privacy, and robustness in Med-LLMs applications, where ethical considerations, rigorous evaluation methodologies, and the formulation of regulatory frameworks are pivotal to fostering trustworthiness in these systems.\nMajor Findings:\nAnalysis and Critique:\nThis survey provides a comprehensive investigation of the potential strengths and limitations of Med-LLMs for professionals and researchers, ensuring a responsible landscape in the healthcare setting. However, it is important to note that the study primarily focuses on"
  },
  {
    "objectID": "posts/A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions/2024-06-06-A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions.html#appendix",
    "href": "posts/A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions/2024-06-06-A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions.html#appendix",
    "title": "A Survey on Medical Large Language Models: Technology, Application, Trustworthiness, and Future Directions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03712v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03712v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18909"
  },
  {
    "objectID": "posts/Refactoring_to_Pythonic_Idioms_A_Hybrid_Knowledge_Driven_Approach_Leveraging_Large_Language_Models/2024-06-06-Refactoring_to_Pythonic_Idioms_A_Hybrid_Knowledge_Driven_Approach_Leveraging_Large_Language_Models.html#appendix",
    "href": "posts/Refactoring_to_Pythonic_Idioms_A_Hybrid_Knowledge_Driven_Approach_Leveraging_Large_Language_Models/2024-06-06-Refactoring_to_Pythonic_Idioms_A_Hybrid_Knowledge_Driven_Approach_Leveraging_Large_Language_Models.html#appendix",
    "title": "Refactoring to Pythonic Idioms: A Hybrid Knowledge-Driven Approach Leveraging Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03660v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03660v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14284"
  },
  {
    "objectID": "posts/Should_We_Fine_Tune_or_RAG_Evaluating_Different_Techniques_to_Adapt_LLMs_for_Dialogue/2024-06-10-Should_We_Fine_Tune_or_RAG_Evaluating_Different_Techniques_to_Adapt_LLMs_for_Dialogue.html#appendix",
    "href": "posts/Should_We_Fine_Tune_or_RAG_Evaluating_Different_Techniques_to_Adapt_LLMs_for_Dialogue/2024-06-10-Should_We_Fine_Tune_or_RAG_Evaluating_Different_Techniques_to_Adapt_LLMs_for_Dialogue.html#appendix",
    "title": "Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06399v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06399v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3367"
  },
  {
    "objectID": "posts/Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue/2024-06-04-Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue.html",
    "href": "posts/Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue/2024-06-04-Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue.html",
    "title": "Position Debiasing Fine-Tuning for Causal Perception in Long-Term Dialogue",
    "section": "",
    "text": "Summary:\nThe paper proposes a novel method, Causal Perception long-term Dialogue framework (CPD), to alleviate the position bias in large language models (LLMs) for long-term dialogue tasks. The CPD framework employs perturbation-based causal variable discovery to extract causally relevant utterances from dialogue history and enhances the model’s causal perception during fine-tuning. The framework includes a local-position awareness method for inter-sentence position correlation elimination and a causal-perception fine-tuning strategy to improve the model’s ability to discover causal invariant factors. Experimental results on two datasets demonstrate that the proposed method effectively alleviates position bias and achieves significant progress compared to existing baselines.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a well-structured and coherent summary of the proposed CPD framework for addressing position bias in LLMs for long-term dialogue tasks. The use of perturbation-based causal variable discovery and the local-position awareness method are innovative approaches to extract causally relevant utterances from dialogue history. The causal-perception fine-tuning strategy also provides a promising direction for improving the model’s ability to discover causal invariant factors.\nHowever, the paper could benefit from a more detailed analysis of the limitations and potential biases of the proposed method. For instance, the paper does not discuss the potential impact of the perturbation-based approach on the model’s performance or the generalizability of the method to other types of dialogue tasks. Additionally, the paper could provide more insights into the potential challenges and trade-offs in implementing the proposed method in real-world applications.\nOverall, the paper presents a promising approach to addressing position bias in LLMs for long-term dialogue tasks. The proposed CPD framework and the experimental results provide valuable insights into the potential of perturbation-based causal variable discovery and causal-perception fine-t"
  },
  {
    "objectID": "posts/Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue/2024-06-04-Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue.html#appendix",
    "href": "posts/Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue/2024-06-04-Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue.html#appendix",
    "title": "Position Debiasing Fine-Tuning for Causal Perception in Long-Term Dialogue",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02002v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02002v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7030"
  },
  {
    "objectID": "posts/RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold/2024-06-20-RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold.html",
    "href": "posts/RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold/2024-06-20-RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold.html",
    "title": "RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold",
    "section": "",
    "text": "Summary:\nThe paper investigates the use of synthetic data for improving math reasoning capabilities of large language models (LLMs). The authors find that while the typical approach of collecting new questions and corresponding positive (correct) solutions from capable models like GPT-4/Gemini-1.5 presents underwhelming data scaling, the sample efficiency of the same data can be improved up to 2× by sampling more positive traces from the 7B sized models SFT-ed on the original data. However, training on positive self-generated synthetic data alone often amplifies the model’s dependence on spurious steps, that erroneously appear to lead to a good solution but do not generalize to novel problems and hurt test performance.\nThe authors show that negative (incorrect) traces sampled from the same SFT model can be used to address the failure modes of training on only positive data. In particular, negative data can be used to estimate advantage values for every step, and using these advantage estimates via RL enables us to address this problem. The authors show how the advantages can be used implicitly by preference optimization objectives. They show how training on an instance of this objective leads to 8× improvements in sample efficiency of the synthetic data used.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold/2024-06-20-RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold.html#appendix",
    "href": "posts/RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold/2024-06-20-RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold.html#appendix",
    "title": "RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14532v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14532v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15465"
  },
  {
    "objectID": "posts/QuickLLaMA_Query_aware_Inference_Acceleration_for_Large_Language_Models/2024-06-11-QuickLLaMA_Query_aware_Inference_Acceleration_for_Large_Language_Models.html#appendix",
    "href": "posts/QuickLLaMA_Query_aware_Inference_Acceleration_for_Large_Language_Models/2024-06-11-QuickLLaMA_Query_aware_Inference_Acceleration_for_Large_Language_Models.html#appendix",
    "title": "QuickLLaMA: Query-aware Inference Acceleration for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07528v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07528v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7459"
  },
  {
    "objectID": "posts/Knowledge_Tagging_System_on_Math_Questions_via_LLMs_with_Flexible_Demonstration_Retriever/2024-06-19-Knowledge_Tagging_System_on_Math_Questions_via_LLMs_with_Flexible_Demonstration_Retriever.html#appendix",
    "href": "posts/Knowledge_Tagging_System_on_Math_Questions_via_LLMs_with_Flexible_Demonstration_Retriever/2024-06-19-Knowledge_Tagging_System_on_Math_Questions_via_LLMs_with_Flexible_Demonstration_Retriever.html#appendix",
    "title": "Knowledge Tagging System on Math Questions via LLMs with Flexible Demonstration Retriever",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13885v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13885v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6455"
  },
  {
    "objectID": "posts/Towards_a_Client_Centered_Assessment_of_LLM_Therapists_by_Client_Simulation/2024-06-18-Towards_a_Client_Centered_Assessment_of_LLM_Therapists_by_Client_Simulation.html#appendix",
    "href": "posts/Towards_a_Client_Centered_Assessment_of_LLM_Therapists_by_Client_Simulation/2024-06-18-Towards_a_Client_Centered_Assessment_of_LLM_Therapists_by_Client_Simulation.html#appendix",
    "title": "Towards a Client-Centered Assessment of LLM Therapists by Client Simulation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12266v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12266v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10101"
  },
  {
    "objectID": "posts/Learning_to_Plan_for_Retrieval_Augmented_Large_Language_Models_from_Knowledge_Graphs/2024-06-20-Learning_to_Plan_for_Retrieval_Augmented_Large_Language_Models_from_Knowledge_Graphs.html#appendix",
    "href": "posts/Learning_to_Plan_for_Retrieval_Augmented_Large_Language_Models_from_Knowledge_Graphs/2024-06-20-Learning_to_Plan_for_Retrieval_Augmented_Large_Language_Models_from_Knowledge_Graphs.html#appendix",
    "title": "Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14282v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14282v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6692"
  },
  {
    "objectID": "posts/Chain_of_Agents_Large_Language_Models_Collaborating_on_Long_Context_Tasks/2024-06-04-Chain_of_Agents_Large_Language_Models_Collaborating_on_Long_Context_Tasks.html#appendix",
    "href": "posts/Chain_of_Agents_Large_Language_Models_Collaborating_on_Long_Context_Tasks/2024-06-04-Chain_of_Agents_Large_Language_Models_Collaborating_on_Long_Context_Tasks.html#appendix",
    "title": "Chain of Agents: Large Language Models Collaborating on Long-Context Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02818v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02818v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6877"
  },
  {
    "objectID": "posts/Talk_With_Human_like_Agents_Empathetic_Dialogue_Through_Perceptible_Acoustic_Reception_and_Reaction/2024-06-18-Talk_With_Human_like_Agents_Empathetic_Dialogue_Through_Perceptible_Acoustic_Reception_and_Reaction.html#appendix",
    "href": "posts/Talk_With_Human_like_Agents_Empathetic_Dialogue_Through_Perceptible_Acoustic_Reception_and_Reaction/2024-06-18-Talk_With_Human_like_Agents_Empathetic_Dialogue_Through_Perceptible_Acoustic_Reception_and_Reaction.html#appendix",
    "title": "Talk With Human-like Agents: Empathetic Dialogue Through Perceptible Acoustic Reception and Reaction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12707v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12707v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6339"
  },
  {
    "objectID": "posts/Single_Codec_Single_Codebook_Speech_Codec_towards_High_Performance_Speech_Generation/2024-06-11-Single_Codec_Single_Codebook_Speech_Codec_towards_High_Performance_Speech_Generation.html#appendix",
    "href": "posts/Single_Codec_Single_Codebook_Speech_Codec_towards_High_Performance_Speech_Generation/2024-06-11-Single_Codec_Single_Codebook_Speech_Codec_towards_High_Performance_Speech_Generation.html#appendix",
    "title": "Single-Codec: Single-Codebook Speech Codec towards High-Performance Speech Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07422v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07422v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4062"
  },
  {
    "objectID": "posts/UBENCH_Benchmarking_Uncertainty_in_Large_Language_Models_with_Multiple_Choice_Questions/2024-06-18-UBENCH_Benchmarking_Uncertainty_in_Large_Language_Models_with_Multiple_Choice_Questions.html#appendix",
    "href": "posts/UBENCH_Benchmarking_Uncertainty_in_Large_Language_Models_with_Multiple_Choice_Questions/2024-06-18-UBENCH_Benchmarking_Uncertainty_in_Large_Language_Models_with_Multiple_Choice_Questions.html#appendix",
    "title": "UBENCH: Benchmarking Uncertainty in Large Language Models with Multiple Choice Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12784v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12784v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7284"
  },
  {
    "objectID": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#major-findings",
    "href": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#major-findings",
    "title": "MolX: Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nMolX significantly improves the performance of LLMs on various molecule-related tasks, outperforming baselines on tasks such as molecule-to-text translation, retrosynthesis, and property prediction.\nMolX can act as a plug-in module to the LLM, enhancing its performance on molecule-related tasks while fully preserving its general-purpose usage on other domains.\nThe proposed method only introduces a small number of trainable parameters, making it an efficient solution for enhancing LLMs."
  },
  {
    "objectID": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#analysis-and-critique",
    "href": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#analysis-and-critique",
    "title": "MolX: Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper does not discuss the potential limitations of the MolX framework, such as its performance on more complex molecular structures or its ability to handle large-scale molecular datasets.\nThe paper does not provide a comparison with other multi-modal approaches for molecular learning, which could provide a more comprehensive evaluation of the proposed method.\nThe paper does not discuss the potential applications of MolX in other domains, such as drug discovery or materials science, which could provide additional insights into its potential impact.\nThe paper does not discuss the potential ethical implications of using LLMs for molecular learning, such as the potential for bias in the generated molecular structures or the potential for misuse in the development of harmful substances.\n\nOverall, the paper presents a promising approach for enhancing the ability of LLMs to comprehend molecules. However, further research is needed to fully evaluate its limitations, compare it with other approaches, and explore its potential applications and ethical implications."
  },
  {
    "objectID": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#appendix",
    "href": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#appendix",
    "title": "MolX: Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06777v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06777v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8694"
  },
  {
    "objectID": "posts/GraphReader_Building_Graph_based_Agent_to_Enhance_Long_Context_Abilities_of_Large_Language_Models/2024-06-20-GraphReader_Building_Graph_based_Agent_to_Enhance_Long_Context_Abilities_of_Large_Language_Models.html#appendix",
    "href": "posts/GraphReader_Building_Graph_based_Agent_to_Enhance_Long_Context_Abilities_of_Large_Language_Models/2024-06-20-GraphReader_Building_Graph_based_Agent_to_Enhance_Long_Context_Abilities_of_Large_Language_Models.html#appendix",
    "title": "GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14550v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14550v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7927"
  },
  {
    "objectID": "posts/LLMEmbed_Rethinking_Lightweight_LLMs_Genuine_Function_in_Text_Classification/2024-06-06-LLMEmbed_Rethinking_Lightweight_LLMs_Genuine_Function_in_Text_Classification.html#appendix",
    "href": "posts/LLMEmbed_Rethinking_Lightweight_LLMs_Genuine_Function_in_Text_Classification/2024-06-06-LLMEmbed_Rethinking_Lightweight_LLMs_Genuine_Function_in_Text_Classification.html#appendix",
    "title": "LLMEmbed: Rethinking Lightweight LLM’s Genuine Function in Text Classification",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03725v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03725v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5774"
  },
  {
    "objectID": "posts/Whats_in_an_embedding_Would_a_rose_by_any_embedding_smell_as_sweet/2024-06-11-Whats_in_an_embedding_Would_a_rose_by_any_embedding_smell_as_sweet.html#appendix",
    "href": "posts/Whats_in_an_embedding_Would_a_rose_by_any_embedding_smell_as_sweet/2024-06-11-Whats_in_an_embedding_Would_a_rose_by_any_embedding_smell_as_sweet.html#appendix",
    "title": "What’s in an embedding? Would a rose by any embedding smell as sweet?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06870v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06870v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5609"
  },
  {
    "objectID": "posts/LIT_Large_Language_Model_Driven_Intention_Tracking_for_Proactive_Human_Robot_Collaboration____A_Robot_Sous_Chef_Application/2024-06-19-LIT_Large_Language_Model_Driven_Intention_Tracking_for_Proactive_Human_Robot_Collaboration____A_Robot_Sous_Chef_Application.html#appendix",
    "href": "posts/LIT_Large_Language_Model_Driven_Intention_Tracking_for_Proactive_Human_Robot_Collaboration____A_Robot_Sous_Chef_Application/2024-06-19-LIT_Large_Language_Model_Driven_Intention_Tracking_for_Proactive_Human_Robot_Collaboration____A_Robot_Sous_Chef_Application.html#appendix",
    "title": "LIT: Large Language Model Driven Intention Tracking for Proactive Human-Robot Collaboration – A Robot Sous-Chef Application",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13787v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13787v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3696"
  },
  {
    "objectID": "posts/Self_and_Cross_Model_Distillation_for_LLMs_Effective_Methods_for_Refusal_Pattern_Alignment/2024-06-17-Self_and_Cross_Model_Distillation_for_LLMs_Effective_Methods_for_Refusal_Pattern_Alignment.html#appendix",
    "href": "posts/Self_and_Cross_Model_Distillation_for_LLMs_Effective_Methods_for_Refusal_Pattern_Alignment/2024-06-17-Self_and_Cross_Model_Distillation_for_LLMs_Effective_Methods_for_Refusal_Pattern_Alignment.html#appendix",
    "title": "Self and Cross-Model Distillation for LLMs: Effective Methods for Refusal Pattern Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11285v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11285v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6660"
  },
  {
    "objectID": "posts/Model_Merging_and_Safety_Alignment_One_Bad_Model_Spoils_the_Bunch/2024-06-20-Model_Merging_and_Safety_Alignment_One_Bad_Model_Spoils_the_Bunch.html#appendix",
    "href": "posts/Model_Merging_and_Safety_Alignment_One_Bad_Model_Spoils_the_Bunch/2024-06-20-Model_Merging_and_Safety_Alignment_One_Bad_Model_Spoils_the_Bunch.html#appendix",
    "title": "Model Merging and Safety Alignment: One Bad Model Spoils the Bunch",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14563v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14563v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8326"
  },
  {
    "objectID": "posts/Multi_Agent_Software_Development_through_Cross_Team_Collaboration/2024-06-13-Multi_Agent_Software_Development_through_Cross_Team_Collaboration.html#appendix",
    "href": "posts/Multi_Agent_Software_Development_through_Cross_Team_Collaboration/2024-06-13-Multi_Agent_Software_Development_through_Cross_Team_Collaboration.html#appendix",
    "title": "Multi-Agent Software Development through Cross-Team Collaboration",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.08979v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.08979v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8963"
  },
  {
    "objectID": "posts/Generalization_Enhanced_Code_Vulnerability_Detection_via_Multi_Task_Instruction_Fine_Tuning/2024-06-06-Generalization_Enhanced_Code_Vulnerability_Detection_via_Multi_Task_Instruction_Fine_Tuning.html#appendix",
    "href": "posts/Generalization_Enhanced_Code_Vulnerability_Detection_via_Multi_Task_Instruction_Fine_Tuning/2024-06-06-Generalization_Enhanced_Code_Vulnerability_Detection_via_Multi_Task_Instruction_Fine_Tuning.html#appendix",
    "title": "Generalization-Enhanced Code Vulnerability Detection via Multi-Task Instruction Fine-Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03718v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03718v1\n\n\nTruncated\nFalse\n\n\nWord Count\n22567"
  },
  {
    "objectID": "posts/Benchmark_Data_Contamination_of_Large_Language_Models_A_Survey/2024-06-06-Benchmark_Data_Contamination_of_Large_Language_Models_A_Survey.html#appendix",
    "href": "posts/Benchmark_Data_Contamination_of_Large_Language_Models_A_Survey/2024-06-06-Benchmark_Data_Contamination_of_Large_Language_Models_A_Survey.html#appendix",
    "title": "Benchmark Data Contamination of Large Language Models: A Survey",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04244v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04244v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13688"
  },
  {
    "objectID": "posts/MMBench_Video_A_Long_Form_Multi_Shot_Benchmark_for_Holistic_Video_Understanding/2024-06-20-MMBench_Video_A_Long_Form_Multi_Shot_Benchmark_for_Holistic_Video_Understanding.html#appendix",
    "href": "posts/MMBench_Video_A_Long_Form_Multi_Shot_Benchmark_for_Holistic_Video_Understanding/2024-06-20-MMBench_Video_A_Long_Form_Multi_Shot_Benchmark_for_Holistic_Video_Understanding.html#appendix",
    "title": "MMBench-Video: A Long-Form Multi-Shot Benchmark for Holistic Video Understanding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14515v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14515v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8501"
  },
  {
    "objectID": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#summary-1",
    "href": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#summary-1",
    "title": "Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining",
    "section": "Summary:",
    "text": "Summary:\n\nThe paper introduces a novel framework that combines context-aware retrieval-augmented generation with a prompt-based TTS system.\nThe proposed framework incorporates an innovative Context-Aware Contrastive Language-Audio Pre-training (CA-CLAP) model to extract context-aware, style-related textual features (STFs) under audio supervision.\nThe CA-CLAP model employs an audio encoder for extracting style embeddings from speech and a text encoder for deriving STFs from both the text and its context.\nThe framework also implements cross-attention mechanisms between textual and contextual features to enhance context integration.\nThe paper makes the following contributions: 1) proposing a RAG-enhanced prompt-based TTS framework to enhance audio prompt specialized selection, 2) designing a CA-CLAP model to extract textual and acoustic representations for retrieval, and 3) conducting extensive subjective and objective experiments to demonstrate the proposed methods’ superiority over baselines and the introduced CA-CLAP’s better results than text-only embedding methods."
  },
  {
    "objectID": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#major-findings",
    "href": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#major-findings",
    "title": "Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe proposed RAG-enhanced prompt-based TTS framework improves audio prompt specialized selection.\nThe CA-CLAP model effectively extracts context-aware, style-related textual features (STFs) under audio supervision.\nThe proposed methods outperform baselines, and the introduced CA-CLAP achieves better results than text-only embedding methods."
  },
  {
    "objectID": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#analysis-and-critique",
    "href": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#analysis-and-critique",
    "title": "Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper effectively addresses the challenge of selecting appropriate speech prompts by adapting the RAG concept to the speech domain.\nThe proposed framework incorporates an innovative CA-CLAP model to extract context-aware, style-related textual features (STFs) under audio supervision, which enhances the overall quality and relevance of the retrieved content.\nThe paper provides extensive subjective and objective experiments to demonstrate the proposed methods’ superiority over baselines and the introduced CA-CLAP’s better results than"
  },
  {
    "objectID": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#appendix",
    "href": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#appendix",
    "title": "Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03714v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03714v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3915"
  },
  {
    "objectID": "posts/Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data/2024-06-20-Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data.html",
    "href": "posts/Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data/2024-06-20-Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data.html",
    "title": "Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data",
    "section": "",
    "text": "Summary:\nThe paper explores the ability of large language models (LLMs) to infer and verbalize latent structure from disparate training data, a phenomenon known as inductive out-of-context reasoning (OOCR). The authors demonstrate that frontier LLMs can perform inductive OOCR, as evidenced by a suite of five tasks. In one experiment, an LLM was finetuned on a corpus consisting only of distances between an unknown city and other known cities. Remarkably, the LLM could verbalize that the unknown city is Paris and use this fact to answer downstream questions without in-context learning or Chain of Thought. Further experiments showed that LLMs trained only on individual coin flip outcomes could verbalize whether the coin is biased, and those trained only on pairs could articulate a definition of a function and compute inverses. However, OOCR was found to be unreliable, particularly for smaller LLMs learning complex structures. The ability of LLMs to “connect the dots” without explicit in-context learning poses a potential obstacle to monitoring and controlling the knowledge acquired by LLMs.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an interesting exploration of the ability of LLMs to infer and verbalize latent structure from disparate training data. The authors’ findings suggest that LLMs can perform inductive OOCR, a type of generalization that allows them to infer latent information from evidence distributed across training documents and apply it to downstream tasks without in-context learning. However, the authors note that OOCR is unreliable, particularly for smaller LLMs learning complex structures. This raises questions about the robustness and"
  },
  {
    "objectID": "posts/Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data/2024-06-20-Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data.html#appendix",
    "href": "posts/Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data/2024-06-20-Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data.html#appendix",
    "title": "Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14546v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14546v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20777"
  },
  {
    "objectID": "posts/Instruct_Large_Language_Models_to_Drive_like_Humans/2024-06-11-Instruct_Large_Language_Models_to_Drive_like_Humans.html#appendix",
    "href": "posts/Instruct_Large_Language_Models_to_Drive_like_Humans/2024-06-11-Instruct_Large_Language_Models_to_Drive_like_Humans.html#appendix",
    "title": "Instruct Large Language Models to Drive like Humans",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07296v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07296v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5303"
  },
  {
    "objectID": "posts/Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs/2024-06-20-Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs.html#major-findings",
    "href": "posts/Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs/2024-06-20-Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs.html#major-findings",
    "title": "Taxonomy-Guided Zero-Shot Recommendations with LLMs",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe use of a taxonomy dictionary provides a systematic framework for categorizing and organizing items, enhancing the structure and clarity of item information.\nThe TaxRec approach, which uses taxonomy to retrieve knowledge and enhance LLMs’ ability as personal recommenders, significantly improves recommendation quality compared to current zero-shot recommenders.\nThe two-step process of TaxRec, which includes one-time taxonomy categorization and LLM-based recommendation, effectively handles large item pools and makes the recommendation process more efficient, accurate, and scalable."
  },
  {
    "objectID": "posts/Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs/2024-06-20-Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs.html#analysis-and-critique",
    "href": "posts/Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs/2024-06-20-Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs.html#analysis-and-critique",
    "title": "Taxonomy-Guided Zero-Shot Recommendations with LLMs",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper does not discuss the potential limitations of the proposed method, such as the quality and completeness of the taxonomy generated by LLMs and the sufficiency of LLMs’ domain knowledge in certain areas.\nThe paper does not provide a comparison of the proposed method with other taxonomy-based recommendation approaches, which could have helped to better understand the advantages and disadvantages of the proposed method.\nThe paper does not discuss the potential impact of the proposed method on the computational resources required for generating recommendations, which is an important consideration in practical applications.\nThe paper does not provide a detailed analysis of the experimental results, such as the impact of different taxonomy categories on the recommendation quality and the performance of the method in different application domains.\nThe paper does not discuss the potential ethical implications of using LLMs for recommendation,"
  },
  {
    "objectID": "posts/Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs/2024-06-20-Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs.html#appendix",
    "href": "posts/Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs/2024-06-20-Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs.html#appendix",
    "title": "Taxonomy-Guided Zero-Shot Recommendations with LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14043v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14043v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5941"
  },
  {
    "objectID": "posts/A_Collaborative_Data_Analytics_System_with_Recommender_for_Diverse_Users/2024-06-17-A_Collaborative_Data_Analytics_System_with_Recommender_for_Diverse_Users.html#appendix",
    "href": "posts/A_Collaborative_Data_Analytics_System_with_Recommender_for_Diverse_Users/2024-06-17-A_Collaborative_Data_Analytics_System_with_Recommender_for_Diverse_Users.html#appendix",
    "title": "A Collaborative Data Analytics System with Recommender for Diverse Users",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11232v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11232v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13618"
  },
  {
    "objectID": "posts/Can_Large_Language_Models_Always_Solve_Easy_Problems_if_They_Can_Solve_Harder_Ones/2024-06-18-Can_Large_Language_Models_Always_Solve_Easy_Problems_if_They_Can_Solve_Harder_Ones.html#appendix",
    "href": "posts/Can_Large_Language_Models_Always_Solve_Easy_Problems_if_They_Can_Solve_Harder_Ones/2024-06-18-Can_Large_Language_Models_Always_Solve_Easy_Problems_if_They_Can_Solve_Harder_Ones.html#appendix",
    "title": "Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12809v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12809v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9280"
  },
  {
    "objectID": "posts/Progressive_Query_Expansion_for_Retrieval_Over_Cost_constrained_Data_Sources/2024-06-11-Progressive_Query_Expansion_for_Retrieval_Over_Cost_constrained_Data_Sources.html#appendix",
    "href": "posts/Progressive_Query_Expansion_for_Retrieval_Over_Cost_constrained_Data_Sources/2024-06-11-Progressive_Query_Expansion_for_Retrieval_Over_Cost_constrained_Data_Sources.html#appendix",
    "title": "Progressive Query Expansion for Retrieval Over Cost-constrained Data Sources",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07136v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07136v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4716"
  },
  {
    "objectID": "posts/Exploring_Spatial_Representations_in_the_Historical_Lake_District_Texts_with_LLM_based_Relation_Extraction/2024-06-20-Exploring_Spatial_Representations_in_the_Historical_Lake_District_Texts_with_LLM_based_Relation_Extraction.html#appendix",
    "href": "posts/Exploring_Spatial_Representations_in_the_Historical_Lake_District_Texts_with_LLM_based_Relation_Extraction/2024-06-20-Exploring_Spatial_Representations_in_the_Historical_Lake_District_Texts_with_LLM_based_Relation_Extraction.html#appendix",
    "title": "Exploring Spatial Representations in the Historical Lake District Texts with LLM-based Relation Extraction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14336v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14336v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4003"
  },
  {
    "objectID": "posts/The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis/2024-06-19-The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis.html",
    "href": "posts/The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis/2024-06-19-The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis.html",
    "title": "The Efficacy of Conversational Artificial Intelligence in Rectifying the Theory of Mind and Autonomy Biases: Comparative Analysis",
    "section": "",
    "text": "Summary:\nThis study evaluates the efficacy of Conversational Artificial Intelligence (CAI) in rectifying cognitive biases and recognizing affect in human-AI interactions, which is crucial for digital mental health interventions. The research employs a structured methodology with clinical-based virtual case scenarios simulating typical user-bot interactions. Performance and affect recognition were assessed across two categories of cognitive biases: theory of mind biases (anthropomorphization of AI, overtrust in AI, attribution to AI) and autonomy biases (illusion of control, fundamental attribution error, just-world hypothesis). A qualitative feedback mechanism was used with an ordinal scale to quantify responses based on accuracy, therapeutic quality, and adherence to CBT principles. Therapeutic bots (Wysa, Youper) and general-use LLMs (GTP 3.5, GTP 4, Gemini Pro) were evaluated through scripted interactions, double-reviewed by cognitive scientists and a clinical psychologist. Statistical analysis showed therapeutic bots were consistently outperformed by non-therapeutic bots in bias rectification and in 4 out of 6 biases in affect recognition. The data suggests that non-therapeutic chatbots are more effective in addressing some cognitive biases.\nMajor Findings:"
  },
  {
    "objectID": "posts/The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis/2024-06-19-The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis.html#appendix",
    "href": "posts/The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis/2024-06-19-The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis.html#appendix",
    "title": "The Efficacy of Conversational Artificial Intelligence in Rectifying the Theory of Mind and Autonomy Biases: Comparative Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13813v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13813v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17145"
  },
  {
    "objectID": "posts/CoEvol_Constructing_Better_Responses_for_Instruction_Finetuning_through_Multi_Agent_Cooperation/2024-06-11-CoEvol_Constructing_Better_Responses_for_Instruction_Finetuning_through_Multi_Agent_Cooperation.html#appendix",
    "href": "posts/CoEvol_Constructing_Better_Responses_for_Instruction_Finetuning_through_Multi_Agent_Cooperation/2024-06-11-CoEvol_Constructing_Better_Responses_for_Instruction_Finetuning_through_Multi_Agent_Cooperation.html#appendix",
    "title": "CoEvol: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07054v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07054v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6780"
  },
  {
    "objectID": "posts/Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing/2024-06-20-Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing.html",
    "href": "posts/Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing/2024-06-20-Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing.html",
    "title": "Raising the Bar: Investigating the Values of Large Language Models via Generative Evolving Testing",
    "section": "",
    "text": "Summary:\nThe paper proposes a novel framework called GETA (Generative Evolving Testing of vAlues) to address the evaluation chronoeffect problem in assessing the value alignment of Large Language Models (LLMs). GETA incorporates an iteratively-updated item generator that infers each LLM’s moral boundaries and generates difficulty-tailored testing items, accurately reflecting the true alignment extent. This process theoretically learns a joint distribution of item and model response, with item difficulty and value conformity as latent variables. The generator co-evolves with the LLM, addressing the chronoeffect. The paper evaluates various popular LLMs and demonstrates that GETA can create difficulty-matching testing items and more accurately assess LLMs’ values, better consistent with their performance on unseen OOD and i.i.d. items.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a promising approach to address the evaluation chronoeffect problem in assessing the value alignment of LLMs. However, there are some potential limitations and areas for further research:\nOverall, the paper presents an innovative approach to address a significant challenge in evaluating LLMs, and further research is needed to fully understand its"
  },
  {
    "objectID": "posts/Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing/2024-06-20-Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing.html#appendix",
    "href": "posts/Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing/2024-06-20-Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing.html#appendix",
    "title": "Raising the Bar: Investigating the Values of Large Language Models via Generative Evolving Testing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14230v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14230v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11743"
  },
  {
    "objectID": "posts/Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents/2024-06-09-Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents.html",
    "href": "posts/Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents/2024-06-09-Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents.html",
    "title": "Machine Against the RAG: Jamming Retrieval-Augmented Generation with Blocker Documents",
    "section": "",
    "text": "Summary:\nThe paper introduces a new class of denial-of-service vulnerabilities in retrieval-augmented generation (RAG) systems, where a single “blocker” document in the RAG database can cause the system to refuse to answer certain queries. The authors demonstrate this attack against several popular large language models (LLMs) and show that resistance to jamming is a novel LLM-safety property not captured by existing safety and trustworthiness metrics.\nThe authors investigate several methods for generating blocker documents, including a new method based on black-box optimization that does not require knowledge of the embedding or LLM used by the target RAG system. They also discuss the limitations of this method, such as producing blocker documents that have no semantics and can be easily filtered out from RAG databases.\nThe paper concludes with a discussion of future research directions, such as minimizing the number of queries to the target RAG system, generating blocker documents with access to a RAG system whose database is not exactly the same as the target system, and generating passive blocker documents that are difficult to detect or even semantically plausible.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an interesting and novel attack on RAG systems, highlighting a previously unrecognized vulnerability. The authors’ investigation of different methods for generating blocker documents is thorough and well-presented. However, the paper could benefit from a more in-depth discussion of the potential real-world implications of this attack and possible countermeasures. Additionally, the limitations of the black-box optimization method for generating blocker documents should be further explored and addressed."
  },
  {
    "objectID": "posts/Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents/2024-06-09-Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents.html#appendix",
    "href": "posts/Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents/2024-06-09-Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents.html#appendix",
    "title": "Machine Against the RAG: Jamming Retrieval-Augmented Generation with Blocker Documents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05870v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05870v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12156"
  },
  {
    "objectID": "posts/Self_play_with_Execution_Feedback_Improving_Instruction_following_Capabilities_of_Large_Language_Models/2024-06-19-Self_play_with_Execution_Feedback_Improving_Instruction_following_Capabilities_of_Large_Language_Models.html#appendix",
    "href": "posts/Self_play_with_Execution_Feedback_Improving_Instruction_following_Capabilities_of_Large_Language_Models/2024-06-19-Self_play_with_Execution_Feedback_Improving_Instruction_following_Capabilities_of_Large_Language_Models.html#appendix",
    "title": "Self-play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13542v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13542v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4670"
  },
  {
    "objectID": "posts/Reinforcement_Learning_from_Human_Feedback_without_Reward_Inference_Model_Free_Algorithm_and_Instance_Dependent_Analysis/2024-06-11-Reinforcement_Learning_from_Human_Feedback_without_Reward_Inference_Model_Free_Algorithm_and_Instance_Dependent_Analysis.html#appendix",
    "href": "posts/Reinforcement_Learning_from_Human_Feedback_without_Reward_Inference_Model_Free_Algorithm_and_Instance_Dependent_Analysis/2024-06-11-Reinforcement_Learning_from_Human_Feedback_without_Reward_Inference_Model_Free_Algorithm_and_Instance_Dependent_Analysis.html#appendix",
    "title": "Reinforcement Learning from Human Feedback without Reward Inference: Model-Free Algorithm and Instance-Dependent Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07455v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07455v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11143"
  },
  {
    "objectID": "posts/Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems/2024-06-18-Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems.html",
    "href": "posts/Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems/2024-06-18-Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems.html",
    "title": "Navigating the Labyrinth: Evaluating and Enhancing LLMs’ Ability to Reason About Search Problems",
    "section": "",
    "text": "Summary:\nThe paper introduces a new benchmark, SearchBench, to evaluate the reasoning abilities of Large Language Models (LLMs) on search problems. SearchBench consists of 11 unique search problems, each with automated pipelines for generating instances and analyzing solutions. The authors demonstrate that even advanced LLMs struggle with these problems, with GPT4 solving only 1.4% end-to-end in text. The paper proposes in-context learning with A* algorithm implementations and a Multi-Stage-Multi-Try (MSMT) method to enhance performance, raising GPT-4’s performance above 57%.\nKey Terminology:\nMajor Findings:"
  },
  {
    "objectID": "posts/Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems/2024-06-18-Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems.html#appendix",
    "href": "posts/Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems/2024-06-18-Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems.html#appendix",
    "title": "Navigating the Labyrinth: Evaluating and Enhancing LLMs’ Ability to Reason About Search Problems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12172v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12172v1\n\n\nTruncated\nTrue\n\n\nWord Count\n72494"
  },
  {
    "objectID": "posts/LiveMind_Low_latency_Large_Language_Models_with_Simultaneous_Inference/2024-06-20-LiveMind_Low_latency_Large_Language_Models_with_Simultaneous_Inference.html#appendix",
    "href": "posts/LiveMind_Low_latency_Large_Language_Models_with_Simultaneous_Inference/2024-06-20-LiveMind_Low_latency_Large_Language_Models_with_Simultaneous_Inference.html#appendix",
    "title": "LiveMind: Low-latency Large Language Models with Simultaneous Inference",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14319v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14319v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8602"
  },
  {
    "objectID": "posts/A_Critical_Study_of_What_Code_LLMs_(Do_Not)_Learn/2024-06-17-A_Critical_Study_of_What_Code_LLMs_(Do_Not)_Learn.html#appendix",
    "href": "posts/A_Critical_Study_of_What_Code_LLMs_(Do_Not)_Learn/2024-06-17-A_Critical_Study_of_What_Code_LLMs_(Do_Not)_Learn.html#appendix",
    "title": "A Critical Study of What Code-LLMs (Do Not) Learn",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11930v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11930v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10566"
  },
  {
    "objectID": "posts/StackRAG_Agent_Improving_Developer_Answers_with_Retrieval_Augmented_Generation/2024-06-19-StackRAG_Agent_Improving_Developer_Answers_with_Retrieval_Augmented_Generation.html#appendix",
    "href": "posts/StackRAG_Agent_Improving_Developer_Answers_with_Retrieval_Augmented_Generation/2024-06-19-StackRAG_Agent_Improving_Developer_Answers_with_Retrieval_Augmented_Generation.html#appendix",
    "title": "StackRAG Agent: Improving Developer Answers with Retrieval-Augmented Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13840v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13840v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4732"
  },
  {
    "objectID": "posts/What_Did_I_Do_Wrong_Quantifying_LLMs_Sensitivity_and_Consistency_to_Prompt_Engineering/2024-06-18-What_Did_I_Do_Wrong_Quantifying_LLMs_Sensitivity_and_Consistency_to_Prompt_Engineering.html#appendix",
    "href": "posts/What_Did_I_Do_Wrong_Quantifying_LLMs_Sensitivity_and_Consistency_to_Prompt_Engineering/2024-06-18-What_Did_I_Do_Wrong_Quantifying_LLMs_Sensitivity_and_Consistency_to_Prompt_Engineering.html#appendix",
    "title": "What Did I Do Wrong? Quantifying LLMs’ Sensitivity and Consistency to Prompt Engineering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12334v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12334v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6408"
  },
  {
    "objectID": "posts/Large_Language_Models_are_Skeptics_False_Negative_Problem_of_Input_conflicting_Hallucination/2024-06-20-Large_Language_Models_are_Skeptics_False_Negative_Problem_of_Input_conflicting_Hallucination.html#appendix",
    "href": "posts/Large_Language_Models_are_Skeptics_False_Negative_Problem_of_Input_conflicting_Hallucination/2024-06-20-Large_Language_Models_are_Skeptics_False_Negative_Problem_of_Input_conflicting_Hallucination.html#appendix",
    "title": "Large Language Models are Skeptics: False Negative Problem of Input-conflicting Hallucination",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13929v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13929v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4576"
  },
  {
    "objectID": "posts/Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination/2024-06-10-Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination.html",
    "href": "posts/Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination/2024-06-10-Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination.html",
    "title": "Enhancing Food Safety in Supply Chains: The Potential Role of Large Language Models in Preventing Campylobacter Contamination",
    "section": "",
    "text": "Summary:\nThis study explores the potential of large language models (LLMs), specifically generative pre-trained transformers (GPTs), to mitigate Campylobacter contamination across four typical stages of the food supply chain: primary production, food processing, distribution and retail, and preparation and consumption. The study also considers critical barriers to implementing GPTs at each step of the supply chain and proposes initial measures to overcome these obstacles.\nMajor Findings:\nAnalysis and Critique:\nThe study presents an intriguing potential for LLMs to enhance food safety, but the ‘LLM – food safety’ interface remains largely underexplored. The proposed applications of LLMs in this domain are promising, but they require further investigation and practical applications. The study also acknowledges that the adoption of LLMs in the food industry and agri-food supply chains may face several inhibiting factors, such as technological adoption, cultural barriers, data quality and availability, and technical challenges in integrating LLMs with existing food processing and slaughterhouse systems.\nTo alleviate these barriers and enable the deployment of LLMs for bacterial contamination reduction across food supply chains, a"
  },
  {
    "objectID": "posts/Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination/2024-06-10-Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination.html#appendix",
    "href": "posts/Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination/2024-06-10-Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination.html#appendix",
    "title": "Enhancing Food Safety in Supply Chains: The Potential Role of Large Language Models in Preventing Campylobacter Contamination",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06049v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06049v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18111"
  },
  {
    "objectID": "posts/Advancing_Annotation_of_Stance_in_Social_Media_Posts_A_Comparative_Analysis_of_Large_Language_Models_and_Crowd_Sourcing/2024-06-11-Advancing_Annotation_of_Stance_in_Social_Media_Posts_A_Comparative_Analysis_of_Large_Language_Models_and_Crowd_Sourcing.html#appendix",
    "href": "posts/Advancing_Annotation_of_Stance_in_Social_Media_Posts_A_Comparative_Analysis_of_Large_Language_Models_and_Crowd_Sourcing/2024-06-11-Advancing_Annotation_of_Stance_in_Social_Media_Posts_A_Comparative_Analysis_of_Large_Language_Models_and_Crowd_Sourcing.html#appendix",
    "title": "Advancing Annotation of Stance in Social Media Posts: A Comparative Analysis of Large Language Models and Crowd Sourcing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07483v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07483v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7463"
  },
  {
    "objectID": "posts/Large_Language_Models_Make_Sample_Efficient_Recommender_Systems/2024-06-04-Large_Language_Models_Make_Sample_Efficient_Recommender_Systems.html#appendix",
    "href": "posts/Large_Language_Models_Make_Sample_Efficient_Recommender_Systems/2024-06-04-Large_Language_Models_Make_Sample_Efficient_Recommender_Systems.html#appendix",
    "title": "Large Language Models Make Sample-Efficient Recommender Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02368v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02368v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3649"
  },
  {
    "objectID": "posts/Confabulation_The_Surprising_Value_of_Large_Language_Model_Hallucinations/2024-06-06-Confabulation_The_Surprising_Value_of_Large_Language_Model_Hallucinations.html#appendix",
    "href": "posts/Confabulation_The_Surprising_Value_of_Large_Language_Model_Hallucinations/2024-06-06-Confabulation_The_Surprising_Value_of_Large_Language_Model_Hallucinations.html#appendix",
    "title": "Confabulation: The Surprising Value of Large Language Model Hallucinations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04175v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04175v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5509"
  },
  {
    "objectID": "posts/Semantic_Structure_Mapping_in_LLM_and_Human_Analogical_Reasoning/2024-06-19-Semantic_Structure_Mapping_in_LLM_and_Human_Analogical_Reasoning.html#appendix",
    "href": "posts/Semantic_Structure_Mapping_in_LLM_and_Human_Analogical_Reasoning/2024-06-19-Semantic_Structure_Mapping_in_LLM_and_Human_Analogical_Reasoning.html#appendix",
    "title": "Semantic Structure-Mapping in LLM and Human Analogical Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13803v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13803v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12911"
  },
  {
    "objectID": "posts/Multi_Stage_Balanced_Distillation_Addressing_Long_Tail_Challenges_in_Sequence_Level_Knowledge_Distillation/2024-06-19-Multi_Stage_Balanced_Distillation_Addressing_Long_Tail_Challenges_in_Sequence_Level_Knowledge_Distillation.html#appendix",
    "href": "posts/Multi_Stage_Balanced_Distillation_Addressing_Long_Tail_Challenges_in_Sequence_Level_Knowledge_Distillation/2024-06-19-Multi_Stage_Balanced_Distillation_Addressing_Long_Tail_Challenges_in_Sequence_Level_Knowledge_Distillation.html#appendix",
    "title": "Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13114v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13114v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7892"
  },
  {
    "objectID": "posts/SeCoKD_Aligning_Large_Language_Models_for_In_Context_Learning_with_Fewer_Shots/2024-06-20-SeCoKD_Aligning_Large_Language_Models_for_In_Context_Learning_with_Fewer_Shots.html#appendix",
    "href": "posts/SeCoKD_Aligning_Large_Language_Models_for_In_Context_Learning_with_Fewer_Shots/2024-06-20-SeCoKD_Aligning_Large_Language_Models_for_In_Context_Learning_with_Fewer_Shots.html#appendix",
    "title": "SeCoKD: Aligning Large Language Models for In-Context Learning with Fewer Shots",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14208v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14208v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6370"
  },
  {
    "objectID": "posts/Accessing_GPT_4_level_Mathematical_Olympiad_Solutions_via_Monte_Carlo_Tree_Self_refine_with_LLaMa_3_8B/2024-06-11-Accessing_GPT_4_level_Mathematical_Olympiad_Solutions_via_Monte_Carlo_Tree_Self_refine_with_LLaMa_3_8B.html#appendix",
    "href": "posts/Accessing_GPT_4_level_Mathematical_Olympiad_Solutions_via_Monte_Carlo_Tree_Self_refine_with_LLaMa_3_8B/2024-06-11-Accessing_GPT_4_level_Mathematical_Olympiad_Solutions_via_Monte_Carlo_Tree_Self_refine_with_LLaMa_3_8B.html#appendix",
    "title": "Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07394v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07394v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5818"
  },
  {
    "objectID": "posts/Can_I_understand_what_I_create_Self_Knowledge_Evaluation_of_Large_Language_Models/2024-06-10-Can_I_understand_what_I_create_Self_Knowledge_Evaluation_of_Large_Language_Models.html#appendix",
    "href": "posts/Can_I_understand_what_I_create_Self_Knowledge_Evaluation_of_Large_Language_Models/2024-06-10-Can_I_understand_what_I_create_Self_Knowledge_Evaluation_of_Large_Language_Models.html#appendix",
    "title": "Can I understand what I create? Self-Knowledge Evaluation of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06140v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06140v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7449"
  },
  {
    "objectID": "posts/ObscurePrompt_Jailbreaking_Large_Language_Models_via_Obscure_Input/2024-06-19-ObscurePrompt_Jailbreaking_Large_Language_Models_via_Obscure_Input.html#appendix",
    "href": "posts/ObscurePrompt_Jailbreaking_Large_Language_Models_via_Obscure_Input/2024-06-19-ObscurePrompt_Jailbreaking_Large_Language_Models_via_Obscure_Input.html#appendix",
    "title": "ObscurePrompt: Jailbreaking Large Language Models via Obscure Input",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13662v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13662v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7246"
  },
  {
    "objectID": "posts/Evidence_of_a_log_scaling_law_for_political_persuasion_with_large_language_models/2024-06-20-Evidence_of_a_log_scaling_law_for_political_persuasion_with_large_language_models.html#appendix",
    "href": "posts/Evidence_of_a_log_scaling_law_for_political_persuasion_with_large_language_models/2024-06-20-Evidence_of_a_log_scaling_law_for_political_persuasion_with_large_language_models.html#appendix",
    "title": "Evidence of a log scaling law for political persuasion with large language models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14508v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14508v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9012"
  },
  {
    "objectID": "posts/Evaluating_Implicit_Bias_in_Large_Language_Models_by_Attacking_From_a_Psychometric_Perspective/2024-06-20-Evaluating_Implicit_Bias_in_Large_Language_Models_by_Attacking_From_a_Psychometric_Perspective.html#appendix",
    "href": "posts/Evaluating_Implicit_Bias_in_Large_Language_Models_by_Attacking_From_a_Psychometric_Perspective/2024-06-20-Evaluating_Implicit_Bias_in_Large_Language_Models_by_Attacking_From_a_Psychometric_Perspective.html#appendix",
    "title": "Evaluating Implicit Bias in Large Language Models by Attacking From a Psychometric Perspective",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14023v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14023v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7014"
  },
  {
    "objectID": "posts/Do_LLMs_Recognize_me_When_I_is_not_me_Assessment_of_LLMs_Understanding_of_Turkish_Indexical_Pronouns_in_Indexical_Shift_Contexts/2024-06-08-Do_LLMs_Recognize_me_When_I_is_not_me_Assessment_of_LLMs_Understanding_of_Turkish_Indexical_Pronouns_in_Indexical_Shift_Contexts.html#appendix",
    "href": "posts/Do_LLMs_Recognize_me_When_I_is_not_me_Assessment_of_LLMs_Understanding_of_Turkish_Indexical_Pronouns_in_Indexical_Shift_Contexts/2024-06-08-Do_LLMs_Recognize_me_When_I_is_not_me_Assessment_of_LLMs_Understanding_of_Turkish_Indexical_Pronouns_in_Indexical_Shift_Contexts.html#appendix",
    "title": "Do LLMs Recognize me, When I is not me: Assessment of LLMs Understanding of Turkish Indexical Pronouns in Indexical Shift Contexts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05569v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05569v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5917"
  },
  {
    "objectID": "posts/Text_to_Drive_Diverse_Driving_Behavior_Synthesis_via_Large_Language_Models/2024-06-06-Text_to_Drive_Diverse_Driving_Behavior_Synthesis_via_Large_Language_Models.html#appendix",
    "href": "posts/Text_to_Drive_Diverse_Driving_Behavior_Synthesis_via_Large_Language_Models/2024-06-06-Text_to_Drive_Diverse_Driving_Behavior_Synthesis_via_Large_Language_Models.html#appendix",
    "title": "Text-to-Drive: Diverse Driving Behavior Synthesis via Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04300v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04300v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10490"
  },
  {
    "objectID": "posts/FVEL_Interactive_Formal_Verification_Environment_with_Large_Language_Models_via_Theorem_Proving/2024-06-20-FVEL_Interactive_Formal_Verification_Environment_with_Large_Language_Models_via_Theorem_Proving.html#appendix",
    "href": "posts/FVEL_Interactive_Formal_Verification_Environment_with_Large_Language_Models_via_Theorem_Proving/2024-06-20-FVEL_Interactive_Formal_Verification_Environment_with_Large_Language_Models_via_Theorem_Proving.html#appendix",
    "title": "FVEL: Interactive Formal Verification Environment with Large Language Models via Theorem Proving",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14408v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14408v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11049"
  },
  {
    "objectID": "posts/A_Superalignment_Framework_in_Autonomous_Driving_with_Large_Language_Models/2024-06-09-A_Superalignment_Framework_in_Autonomous_Driving_with_Large_Language_Models.html#appendix",
    "href": "posts/A_Superalignment_Framework_in_Autonomous_Driving_with_Large_Language_Models/2024-06-09-A_Superalignment_Framework_in_Autonomous_Driving_with_Large_Language_Models.html#appendix",
    "title": "A Superalignment Framework in Autonomous Driving with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05651v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05651v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3979"
  },
  {
    "objectID": "posts/RS_Agent_Automating_Remote_Sensing_Tasks_through_Intelligent_Agents/2024-06-11-RS_Agent_Automating_Remote_Sensing_Tasks_through_Intelligent_Agents.html#appendix",
    "href": "posts/RS_Agent_Automating_Remote_Sensing_Tasks_through_Intelligent_Agents/2024-06-11-RS_Agent_Automating_Remote_Sensing_Tasks_through_Intelligent_Agents.html#appendix",
    "title": "RS-Agent: Automating Remote Sensing Tasks through Intelligent Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07089v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07089v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5913"
  },
  {
    "objectID": "posts/MagicItem_Dynamic_Behavior_Design_of_Virtual_Objects_with_Large_Language_Models_in_a_Consumer_Metaverse_Platform/2024-06-19-MagicItem_Dynamic_Behavior_Design_of_Virtual_Objects_with_Large_Language_Models_in_a_Consumer_Metaverse_Platform.html#appendix",
    "href": "posts/MagicItem_Dynamic_Behavior_Design_of_Virtual_Objects_with_Large_Language_Models_in_a_Consumer_Metaverse_Platform/2024-06-19-MagicItem_Dynamic_Behavior_Design_of_Virtual_Objects_with_Large_Language_Models_in_a_Consumer_Metaverse_Platform.html#appendix",
    "title": "MagicItem: Dynamic Behavior Design of Virtual Objects with Large Language Models in a Consumer Metaverse Platform",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13242v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13242v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9382"
  },
  {
    "objectID": "posts/Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model/2024-06-11-Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model.html",
    "href": "posts/Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model/2024-06-11-Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model.html",
    "title": "Paying More Attention to Source Context: Mitigating Unfaithful Translations from Large Language Model",
    "section": "",
    "text": "Summary:\nThe paper focuses on the issue of unfaithful translations in large language models (LLMs) due to insufficient focus on the source context. The authors propose three methods to address this issue: reweight attention, contrastive decoding, and target-constrained tuning. The reweight attention method adjusts the attention weight of the source context to help models focus on the source context during generation. Contrastive decoding reduces the influence of target prefixes, and target-constrained tuning encourages LLMs to avoid excessive dependence on specific target prefixes. The experimental results show that the proposed methods improve translation performance across several language pairs in the proposed unfaithful translation test sets, outperforming baseline methods and effectively reducing the phenomenon of hallucinatory and unfaithful translations.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model/2024-06-11-Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model.html#appendix",
    "href": "posts/Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model/2024-06-11-Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model.html#appendix",
    "title": "Paying More Attention to Source Context: Mitigating Unfaithful Translations from Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07036v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07036v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10716"
  },
  {
    "objectID": "posts/Improving_Expert_Radiology_Report_Summarization_by_Prompting_Large_Language_Models_with_a_Layperson_Summary/2024-06-20-Improving_Expert_Radiology_Report_Summarization_by_Prompting_Large_Language_Models_with_a_Layperson_Summary.html#appendix",
    "href": "posts/Improving_Expert_Radiology_Report_Summarization_by_Prompting_Large_Language_Models_with_a_Layperson_Summary/2024-06-20-Improving_Expert_Radiology_Report_Summarization_by_Prompting_Large_Language_Models_with_a_Layperson_Summary.html#appendix",
    "title": "Improving Expert Radiology Report Summarization by Prompting Large Language Models with a Layperson Summary",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14500v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14500v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8909"
  },
  {
    "objectID": "posts/Decision_Making_Behavior_Evaluation_Framework_for_LLMs_under_Uncertain_Context/2024-06-10-Decision_Making_Behavior_Evaluation_Framework_for_LLMs_under_Uncertain_Context.html#appendix",
    "href": "posts/Decision_Making_Behavior_Evaluation_Framework_for_LLMs_under_Uncertain_Context/2024-06-10-Decision_Making_Behavior_Evaluation_Framework_for_LLMs_under_Uncertain_Context.html#appendix",
    "title": "Decision-Making Behavior Evaluation Framework for LLMs under Uncertain Context",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05972v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05972v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6256"
  },
  {
    "objectID": "posts/On_Policy_Fine_grained_Knowledge_Feedback_for_Hallucination_Mitigation/2024-06-18-On_Policy_Fine_grained_Knowledge_Feedback_for_Hallucination_Mitigation.html#appendix",
    "href": "posts/On_Policy_Fine_grained_Knowledge_Feedback_for_Hallucination_Mitigation/2024-06-18-On_Policy_Fine_grained_Knowledge_Feedback_for_Hallucination_Mitigation.html#appendix",
    "title": "On-Policy Fine-grained Knowledge Feedback for Hallucination Mitigation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12221v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12221v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7146"
  },
  {
    "objectID": "posts/POEM_Interactive_Prompt_Optimization_for_Enhancing_Multimodal_Reasoning_of_Large_Language_Models/2024-06-06-POEM_Interactive_Prompt_Optimization_for_Enhancing_Multimodal_Reasoning_of_Large_Language_Models.html#appendix",
    "href": "posts/POEM_Interactive_Prompt_Optimization_for_Enhancing_Multimodal_Reasoning_of_Large_Language_Models/2024-06-06-POEM_Interactive_Prompt_Optimization_for_Enhancing_Multimodal_Reasoning_of_Large_Language_Models.html#appendix",
    "title": "POEM: Interactive Prompt Optimization for Enhancing Multimodal Reasoning of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03843v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03843v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12924"
  },
  {
    "objectID": "posts/Verbalized_Machine_Learning_Revisiting_Machine_Learning_with_Language_Models/2024-06-06-Verbalized_Machine_Learning_Revisiting_Machine_Learning_with_Language_Models.html#appendix",
    "href": "posts/Verbalized_Machine_Learning_Revisiting_Machine_Learning_with_Language_Models/2024-06-06-Verbalized_Machine_Learning_Revisiting_Machine_Learning_with_Language_Models.html#appendix",
    "title": "Verbalized Machine Learning: Revisiting Machine Learning with Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04344v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04344v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10781"
  },
  {
    "objectID": "posts/Jailbreak_Paradox_The_Achilles_Heel_of_LLMs/2024-06-18-Jailbreak_Paradox_The_Achilles_Heel_of_LLMs.html#appendix",
    "href": "posts/Jailbreak_Paradox_The_Achilles_Heel_of_LLMs/2024-06-18-Jailbreak_Paradox_The_Achilles_Heel_of_LLMs.html#appendix",
    "title": "Jailbreak Paradox: The Achilles’ Heel of LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12702v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12702v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4006"
  },
  {
    "objectID": "posts/Global_is_Good_Local_is_Bad_Understanding_Brand_Bias_in_LLMs/2024-06-20-Global_is_Good_Local_is_Bad_Understanding_Brand_Bias_in_LLMs.html#appendix",
    "href": "posts/Global_is_Good_Local_is_Bad_Understanding_Brand_Bias_in_LLMs/2024-06-20-Global_is_Good_Local_is_Bad_Understanding_Brand_Bias_in_LLMs.html#appendix",
    "title": "Global is Good, Local is Bad?: Understanding Brand Bias in LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13997v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13997v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4379"
  },
  {
    "objectID": "posts/GUI_Action_Narrator_Where_and_When_Did_That_Action_Take_Place/2024-06-19-GUI_Action_Narrator_Where_and_When_Did_That_Action_Take_Place.html#appendix",
    "href": "posts/GUI_Action_Narrator_Where_and_When_Did_That_Action_Take_Place/2024-06-19-GUI_Action_Narrator_Where_and_When_Did_That_Action_Take_Place.html#appendix",
    "title": "GUI Action Narrator: Where and When Did That Action Take Place?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13719v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13719v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6190"
  },
  {
    "objectID": "posts/The_current_status_of_large_language_models_in_summarizing_radiology_report_impressions/2024-06-04-The_current_status_of_large_language_models_in_summarizing_radiology_report_impressions.html#appendix",
    "href": "posts/The_current_status_of_large_language_models_in_summarizing_radiology_report_impressions/2024-06-04-The_current_status_of_large_language_models_in_summarizing_radiology_report_impressions.html#appendix",
    "title": "The current status of large language models in summarizing radiology report impressions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02134v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02134v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7591"
  },
  {
    "objectID": "posts/Merging_Improves_Self_Critique_Against_Jailbreak_Attacks/2024-06-11-Merging_Improves_Self_Critique_Against_Jailbreak_Attacks.html#appendix",
    "href": "posts/Merging_Improves_Self_Critique_Against_Jailbreak_Attacks/2024-06-11-Merging_Improves_Self_Critique_Against_Jailbreak_Attacks.html#appendix",
    "title": "Merging Improves Self-Critique Against Jailbreak Attacks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07188v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07188v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3164"
  },
  {
    "objectID": "posts/African_or_European_Swallow_Benchmarking_Large_Vision_Language_Models_for_Fine_Grained_Object_Classification/2024-06-20-African_or_European_Swallow_Benchmarking_Large_Vision_Language_Models_for_Fine_Grained_Object_Classification.html#appendix",
    "href": "posts/African_or_European_Swallow_Benchmarking_Large_Vision_Language_Models_for_Fine_Grained_Object_Classification/2024-06-20-African_or_European_Swallow_Benchmarking_Large_Vision_Language_Models_for_Fine_Grained_Object_Classification.html#appendix",
    "title": "African or European Swallow? Benchmarking Large Vision-Language Models for Fine-Grained Object Classification",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14496v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14496v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8786"
  },
  {
    "objectID": "posts/MedExQA_Medical_Question_Answering_Benchmark_with_Multiple_Explanations/2024-06-10-MedExQA_Medical_Question_Answering_Benchmark_with_Multiple_Explanations.html#appendix",
    "href": "posts/MedExQA_Medical_Question_Answering_Benchmark_with_Multiple_Explanations/2024-06-10-MedExQA_Medical_Question_Answering_Benchmark_with_Multiple_Explanations.html#appendix",
    "title": "MedExQA: Medical Question Answering Benchmark with Multiple Explanations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06331v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06331v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7134"
  },
  {
    "objectID": "posts/How_Efficient_is_LLM_Generated_Code_A_Rigorous__High_Standard_Benchmark/2024-06-10-How_Efficient_is_LLM_Generated_Code_A_Rigorous__High_Standard_Benchmark.html#appendix",
    "href": "posts/How_Efficient_is_LLM_Generated_Code_A_Rigorous__High_Standard_Benchmark/2024-06-10-How_Efficient_is_LLM_Generated_Code_A_Rigorous__High_Standard_Benchmark.html#appendix",
    "title": "How Efficient is LLM-Generated Code? A Rigorous & High-Standard Benchmark",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06647v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06647v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8226"
  },
  {
    "objectID": "posts/Stronger_Faster_and_Cheaper_Log_Parsing_with_LLMs/2024-06-10-Stronger_Faster_and_Cheaper_Log_Parsing_with_LLMs.html#appendix",
    "href": "posts/Stronger_Faster_and_Cheaper_Log_Parsing_with_LLMs/2024-06-10-Stronger_Faster_and_Cheaper_Log_Parsing_with_LLMs.html#appendix",
    "title": "Stronger, Faster, and Cheaper Log Parsing with LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06156v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06156v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11355"
  },
  {
    "objectID": "posts/MAGIC_Generating_Self_Correction_Guideline_for_In_Context_Text_to_SQL/2024-06-18-MAGIC_Generating_Self_Correction_Guideline_for_In_Context_Text_to_SQL.html#appendix",
    "href": "posts/MAGIC_Generating_Self_Correction_Guideline_for_In_Context_Text_to_SQL/2024-06-18-MAGIC_Generating_Self_Correction_Guideline_for_In_Context_Text_to_SQL.html#appendix",
    "title": "MAGIC: Generating Self-Correction Guideline for In-Context Text-to-SQL",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12692v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12692v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7370"
  },
  {
    "objectID": "posts/DARA_Decomposition_Alignment_Reasoning_Autonomous_Language_Agent_for_Question_Answering_over_Knowledge_Graphs/2024-06-11-DARA_Decomposition_Alignment_Reasoning_Autonomous_Language_Agent_for_Question_Answering_over_Knowledge_Graphs.html#appendix",
    "href": "posts/DARA_Decomposition_Alignment_Reasoning_Autonomous_Language_Agent_for_Question_Answering_over_Knowledge_Graphs/2024-06-11-DARA_Decomposition_Alignment_Reasoning_Autonomous_Language_Agent_for_Question_Answering_over_Knowledge_Graphs.html#appendix",
    "title": "DARA: Decomposition-Alignment-Reasoning Autonomous Language Agent for Question Answering over Knowledge Graphs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07080v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07080v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8918"
  },
  {
    "objectID": "posts/The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts/2024-06-20-The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts.html",
    "href": "posts/The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts/2024-06-20-The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts.html",
    "title": "The Fire Thief Is Also the Keeper: Balancing Usability and Privacy in Prompts",
    "section": "",
    "text": "Summary:\nThe paper introduces Prompt Privacy Sanitizer (ProSan), an end-to-end framework for prompt privacy protection that balances usability and privacy. ProSan generates anonymized prompts by removing contextual privacy while maintaining task usability and human readability. It can be seamlessly integrated into the online LLM service pipeline. ProSan dynamically adjusts its protection targets and strength based on the importance of words and the privacy leakage risk of prompts. It is also capable of adapting to diverse computational resource conditions, ensuring privacy protection even for mobile devices with limited computing power.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a promising approach to addressing the issue of privacy leaks in prompts. However, it does not provide a comprehensive evaluation of the framework’s performance across a wide range of tasks and datasets. Additionally, the paper does not discuss potential limitations or biases in the framework, such as the reliance on self-information for measuring privacy risk, which may not fully capture the complexity of privacy in natural language. Further research is needed to evaluate the framework’s robustness and generalizability, as well as to explore alternative methods for measuring privacy risk."
  },
  {
    "objectID": "posts/The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts/2024-06-20-The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts.html#appendix",
    "href": "posts/The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts/2024-06-20-The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts.html#appendix",
    "title": "The Fire Thief Is Also the Keeper: Balancing Usability and Privacy in Prompts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14318v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14318v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11663"
  },
  {
    "objectID": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#major-findings",
    "href": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#major-findings",
    "title": "SemCoder: Training Code Language Models with Comprehensive Semantics",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe paper introduces a novel strategy to train Code LLMs with comprehensive semantics, including high-level functional descriptions, local execution effects of individual statements, and overall input/output behavior.\nThe authors propose training Code LLMs to write code and represent and reason about execution behaviors using natural language, mimicking human verbal debugging.\nThe paper presents SEMCODER, a Code LLM with only 6.7B parameters, which shows competitive performance with GPT-3.5-turbo on code generation and execution reasoning tasks.\nSEMCODER achieves 81.1% on HumanEval (GPT-3.5-turbo: 76.8%) and 54.5% on CRUXEval-I (GPT-3.5-turbo: 50.3%).\nThe paper also studies the effectiveness of SEMCODER’s monologue-style execution reasoning compared to concrete scratchpad reasoning, showing that their approach integrates semantics from multiple dimensions more smoothly."
  },
  {
    "objectID": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#analysis-and-critique",
    "href": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#analysis-and-critique",
    "title": "SemCoder: Training Code Language Models with Comprehensive Semantics",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a novel approach to training Code LLMs with comprehensive semantics, which has the potential to improve the performance of Code LLMs on code generation and execution reasoning tasks. The authors’ proposal to train Code LLMs to write code and represent and reason about execution behaviors using natural language is an interesting and promising direction.\nHowever, the paper does not provide a detailed comparison of SEMCODER with other state-of-the-art Code LLMs, which makes it difficult to evaluate the effectiveness of their approach. Additionally, the"
  },
  {
    "objectID": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#appendix",
    "href": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#appendix",
    "title": "SemCoder: Training Code Language Models with Comprehensive Semantics",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01006v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01006v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18724"
  },
  {
    "objectID": "posts/An_Investigation_of_Prompt_Variations_for_Zero_shot_LLM_based_Rankers/2024-06-20-An_Investigation_of_Prompt_Variations_for_Zero_shot_LLM_based_Rankers.html#appendix",
    "href": "posts/An_Investigation_of_Prompt_Variations_for_Zero_shot_LLM_based_Rankers/2024-06-20-An_Investigation_of_Prompt_Variations_for_Zero_shot_LLM_based_Rankers.html#appendix",
    "title": "An Investigation of Prompt Variations for Zero-shot LLM-based Rankers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14117v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14117v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7110"
  },
  {
    "objectID": "posts/Semantically_Diverse_Language_Generation_for_Uncertainty_Estimation_in_Language_Models/2024-06-06-Semantically_Diverse_Language_Generation_for_Uncertainty_Estimation_in_Language_Models.html#appendix",
    "href": "posts/Semantically_Diverse_Language_Generation_for_Uncertainty_Estimation_in_Language_Models/2024-06-06-Semantically_Diverse_Language_Generation_for_Uncertainty_Estimation_in_Language_Models.html#appendix",
    "title": "Semantically Diverse Language Generation for Uncertainty Estimation in Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04306v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04306v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10058"
  },
  {
    "objectID": "posts/Preference_Learning_Algorithms_Do_Not_Learn_Preference_Rankings/2024-05-29-Preference_Learning_Algorithms_Do_Not_Learn_Preference_Rankings.html#appendix",
    "href": "posts/Preference_Learning_Algorithms_Do_Not_Learn_Preference_Rankings/2024-05-29-Preference_Learning_Algorithms_Do_Not_Learn_Preference_Rankings.html#appendix",
    "title": "Preference Learning Algorithms Do Not Learn Preference Rankings",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.19534v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.19534v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10665"
  },
  {
    "objectID": "posts/HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs/2024-06-10-HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs.html",
    "href": "posts/HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs/2024-06-10-HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs.html",
    "title": "HOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs",
    "section": "",
    "text": "Summary:\nThe paper introduces a new method called HOLMES for multi-hop question answering (MHQA) using large language models (LLMs). The method involves transforming unstructured text into a hyper-relational knowledge graph (KG) using a query-derived schema, which is then used as input to the LLM. The proposed method significantly improves upon the state-of-the-art (SoTA) multi-hop QA method, achieving 18.7% and 20% improvements in exact match (EM) scores on the Hotpot dataset and 26% and 14.3% on the MuSiQue dataset for GPT-3.5 and GPT-4, respectively. Additionally, the method uses up to 67% fewer tokens to represent query-relevant information than the current SoTA method and up to 60% fewer tokens compared to the original supporting documents.\nMajor Findings:\nAnalysis and Critique:\nThe proposed method, HOLMES, presents a significant improvement over the SoTA multi-hop QA method. The use of a hyper-relational KG as input to the LLM allows for a more efficient and effective representation of query-relevant information. The method’s ability to use fewer tokens to represent this information is particularly noteworthy, as it can lead to reduced computational costs and improved performance.\nHowever, there are some potential limitations and areas for further research. For example, the method’s reliance on a query-"
  },
  {
    "objectID": "posts/HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs/2024-06-10-HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs.html#appendix",
    "href": "posts/HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs/2024-06-10-HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs.html#appendix",
    "title": "HOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06027v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06027v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20470"
  },
  {
    "objectID": "posts/Unveiling_Assumptions_Exploring_the_Decisions_of_AI_Chatbots_and_Human_Testers/2024-06-17-Unveiling_Assumptions_Exploring_the_Decisions_of_AI_Chatbots_and_Human_Testers.html#appendix",
    "href": "posts/Unveiling_Assumptions_Exploring_the_Decisions_of_AI_Chatbots_and_Human_Testers/2024-06-17-Unveiling_Assumptions_Exploring_the_Decisions_of_AI_Chatbots_and_Human_Testers.html#appendix",
    "title": "Unveiling Assumptions: Exploring the Decisions of AI Chatbots and Human Testers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11339v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11339v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5891"
  },
  {
    "objectID": "posts/FaceGPT_Self_supervised_Learning_to_Chat_about_3D_Human_Faces/2024-06-11-FaceGPT_Self_supervised_Learning_to_Chat_about_3D_Human_Faces.html#appendix",
    "href": "posts/FaceGPT_Self_supervised_Learning_to_Chat_about_3D_Human_Faces/2024-06-11-FaceGPT_Self_supervised_Learning_to_Chat_about_3D_Human_Faces.html#appendix",
    "title": "FaceGPT: Self-supervised Learning to Chat about 3D Human Faces",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07163v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07163v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6381"
  },
  {
    "objectID": "posts/A_Survey_on_Human_Preference_Learning_for_Large_Language_Models/2024-06-18-A_Survey_on_Human_Preference_Learning_for_Large_Language_Models.html#appendix",
    "href": "posts/A_Survey_on_Human_Preference_Learning_for_Large_Language_Models/2024-06-18-A_Survey_on_Human_Preference_Learning_for_Large_Language_Models.html#appendix",
    "title": "A Survey on Human Preference Learning for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11191v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11191v2\n\n\nTruncated\nFalse\n\n\nWord Count\n12234"
  },
  {
    "objectID": "posts/A_Tool_for_Test_Case_Scenarios_Generation_Using_Large_Language_Models/2024-06-11-A_Tool_for_Test_Case_Scenarios_Generation_Using_Large_Language_Models.html#appendix",
    "href": "posts/A_Tool_for_Test_Case_Scenarios_Generation_Using_Large_Language_Models/2024-06-11-A_Tool_for_Test_Case_Scenarios_Generation_Using_Large_Language_Models.html#appendix",
    "title": "A Tool for Test Case Scenarios Generation Using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07021v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07021v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3062"
  },
  {
    "objectID": "posts/RAGSys_Item_Cold_Start_Recommender_as_RAG_System/2024-05-27-RAGSys_Item_Cold_Start_Recommender_as_RAG_System.html#appendix",
    "href": "posts/RAGSys_Item_Cold_Start_Recommender_as_RAG_System/2024-05-27-RAGSys_Item_Cold_Start_Recommender_as_RAG_System.html#appendix",
    "title": "RAGSys: Item-Cold-Start Recommender as RAG System",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.17587v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.17587v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9098"
  },
  {
    "objectID": "posts/Causal_Inference_with_Latent_Variables_Recent_Advances_and_Future_Prospectives/2024-06-20-Causal_Inference_with_Latent_Variables_Recent_Advances_and_Future_Prospectives.html#appendix",
    "href": "posts/Causal_Inference_with_Latent_Variables_Recent_Advances_and_Future_Prospectives/2024-06-20-Causal_Inference_with_Latent_Variables_Recent_Advances_and_Future_Prospectives.html#appendix",
    "title": "Causal Inference with Latent Variables: Recent Advances and Future Prospectives",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13966v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13966v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11886"
  },
  {
    "objectID": "posts/Aligning_Agents_like_Large_Language_Models/2024-06-06-Aligning_Agents_like_Large_Language_Models.html",
    "href": "posts/Aligning_Agents_like_Large_Language_Models/2024-06-06-Aligning_Agents_like_Large_Language_Models.html",
    "title": "Aligning Agents like Large Language Models",
    "section": "",
    "text": "Summary:\nThe paper explores the challenge of training agents to behave as desired in complex 3D environments using high-dimensional sensory information. The authors draw an analogy between the undesirable behaviors of imitation learning agents and the unhelpful responses of unaligned large language models (LLMs). They investigate the procedure for aligning LLMs and apply it to aligning agents in a 3D environment from pixels. The authors focus on an academically illustrative part of a modern console game where players must navigate from a randomly selected spawn point to one of three jumppads. They demonstrate that they can align their agent to consistently perform the desired mode while providing insights and advice for successfully applying this approach to training agents.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an innovative approach to aligning agents in complex 3D environments by drawing an analogy between the undesirable behaviors of imitation learning agents and the unhelpful responses of unaligned LLMs. The authors’ investigation of the procedure for aligning LLMs and its application to aligning agents is a significant contribution to the field. However, the paper’s focus on an academically illustrative part of a modern console game may limit the generalizability of the findings to other complex 3D environments. Additionally, the use of synthetic preference labelling may not fully capture the complexity of human preferences in real-world scenarios. Further research is needed to evaluate the effectiveness of this approach in more diverse and complex environments and to explore the use of human preference labelling."
  },
  {
    "objectID": "posts/Aligning_Agents_like_Large_Language_Models/2024-06-06-Aligning_Agents_like_Large_Language_Models.html#appendix",
    "href": "posts/Aligning_Agents_like_Large_Language_Models/2024-06-06-Aligning_Agents_like_Large_Language_Models.html#appendix",
    "title": "Aligning Agents like Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04208v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04208v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12915"
  },
  {
    "objectID": "posts/CleanGen_Mitigating_Backdoor_Attacks_for_Generation_Tasks_in_Large_Language_Models/2024-06-18-CleanGen_Mitigating_Backdoor_Attacks_for_Generation_Tasks_in_Large_Language_Models.html#appendix",
    "href": "posts/CleanGen_Mitigating_Backdoor_Attacks_for_Generation_Tasks_in_Large_Language_Models/2024-06-18-CleanGen_Mitigating_Backdoor_Attacks_for_Generation_Tasks_in_Large_Language_Models.html#appendix",
    "title": "CleanGen: Mitigating Backdoor Attacks for Generation Tasks in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12257v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12257v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7540"
  },
  {
    "objectID": "posts/Explicit_and_Implicit_Large_Language_Model_Personas_Generate_Opinions_but_Fail_to_Replicate_Deeper_Perceptions_and_Biases/2024-06-20-Explicit_and_Implicit_Large_Language_Model_Personas_Generate_Opinions_but_Fail_to_Replicate_Deeper_Perceptions_and_Biases.html#appendix",
    "href": "posts/Explicit_and_Implicit_Large_Language_Model_Personas_Generate_Opinions_but_Fail_to_Replicate_Deeper_Perceptions_and_Biases/2024-06-20-Explicit_and_Implicit_Large_Language_Model_Personas_Generate_Opinions_but_Fail_to_Replicate_Deeper_Perceptions_and_Biases.html#appendix",
    "title": "Explicit and Implicit Large Language Model Personas Generate Opinions but Fail to Replicate Deeper Perceptions and Biases",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14462v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14462v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6689"
  },
  {
    "objectID": "posts/CREF_An_LLM_based_Conversational_Software_Repair_Framework_for_Programming_Tutors/2024-06-20-CREF_An_LLM_based_Conversational_Software_Repair_Framework_for_Programming_Tutors.html#appendix",
    "href": "posts/CREF_An_LLM_based_Conversational_Software_Repair_Framework_for_Programming_Tutors/2024-06-20-CREF_An_LLM_based_Conversational_Software_Repair_Framework_for_Programming_Tutors.html#appendix",
    "title": "CREF: An LLM-based Conversational Software Repair Framework for Programming Tutors",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13972v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13972v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12780"
  },
  {
    "objectID": "posts/Defending_Against_Social_Engineering_Attacks_in_the_Age_of_LLMs/2024-06-18-Defending_Against_Social_Engineering_Attacks_in_the_Age_of_LLMs.html#appendix",
    "href": "posts/Defending_Against_Social_Engineering_Attacks_in_the_Age_of_LLMs/2024-06-18-Defending_Against_Social_Engineering_Attacks_in_the_Age_of_LLMs.html#appendix",
    "title": "Defending Against Social Engineering Attacks in the Age of LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12263v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12263v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7850"
  },
  {
    "objectID": "posts/Leveraging_Large_Language_Models_for_Efficient_Failure_Analysis_in_Game_Development/2024-06-11-Leveraging_Large_Language_Models_for_Efficient_Failure_Analysis_in_Game_Development.html#appendix",
    "href": "posts/Leveraging_Large_Language_Models_for_Efficient_Failure_Analysis_in_Game_Development/2024-06-11-Leveraging_Large_Language_Models_for_Efficient_Failure_Analysis_in_Game_Development.html#appendix",
    "title": "Leveraging Large Language Models for Efficient Failure Analysis in Game Development",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07084v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07084v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6064"
  },
  {
    "objectID": "posts/AgentDojo_A_Dynamic_Environment_to_Evaluate_Attacks_and_Defenses_for_LLM_Agents/2024-06-19-AgentDojo_A_Dynamic_Environment_to_Evaluate_Attacks_and_Defenses_for_LLM_Agents.html#appendix",
    "href": "posts/AgentDojo_A_Dynamic_Environment_to_Evaluate_Attacks_and_Defenses_for_LLM_Agents/2024-06-19-AgentDojo_A_Dynamic_Environment_to_Evaluate_Attacks_and_Defenses_for_LLM_Agents.html#appendix",
    "title": "AgentDojo: A Dynamic Environment to Evaluate Attacks and Defenses for LLM Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13352v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13352v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7934"
  },
  {
    "objectID": "posts/Ollabench_Evaluating_LLMs_Reasoning_for_Human_centric_Interdependent_Cybersecurity/2024-06-11-Ollabench_Evaluating_LLMs_Reasoning_for_Human_centric_Interdependent_Cybersecurity.html#appendix",
    "href": "posts/Ollabench_Evaluating_LLMs_Reasoning_for_Human_centric_Interdependent_Cybersecurity/2024-06-11-Ollabench_Evaluating_LLMs_Reasoning_for_Human_centric_Interdependent_Cybersecurity.html#appendix",
    "title": "Ollabench: Evaluating LLMs’ Reasoning for Human-centric Interdependent Cybersecurity",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06863v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06863v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7305"
  },
  {
    "objectID": "posts/Chain_of_Scrutiny_Detecting_Backdoor_Attacks_for_Large_Language_Models/2024-06-10-Chain_of_Scrutiny_Detecting_Backdoor_Attacks_for_Large_Language_Models.html#appendix",
    "href": "posts/Chain_of_Scrutiny_Detecting_Backdoor_Attacks_for_Large_Language_Models/2024-06-10-Chain_of_Scrutiny_Detecting_Backdoor_Attacks_for_Large_Language_Models.html#appendix",
    "title": "Chain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05948v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05948v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6961"
  },
  {
    "objectID": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#summary-1",
    "href": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#summary-1",
    "title": "FragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models",
    "section": "Summary:",
    "text": "Summary:\n\nThe paper proposes a method to improve the processing of long contexts in Large Language Models (LLMs) by exploiting fragment-level relations in external memory.\nThe authors formulate fragment-level relations and present several instantiations for different text types.\nThey introduce a relation-aware fragment assessment criteria and present the fragment-connected Hierarchical Memory based LLM.\nThe proposed method is validated on long story understanding, repository-level code generation, and long-term chatting tasks."
  },
  {
    "objectID": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#major-findings",
    "href": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#major-findings",
    "title": "FragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nFragment-level Relations: The authors propose a method to exploit fragment-level relations in external memory to improve the processing of long contexts in LLMs.\nRelation-aware Fragment Assessment: The authors introduce a relation-aware fragment assessment criteria to better assess the importance of each fragment in the context.\nFragment-connected Hierarchical Memory based LLM: The authors present a new LLM architecture that incorporates fragment-level relations in external memory to improve the processing of long contexts."
  },
  {
    "objectID": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#analysis-and-critique",
    "title": "FragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe proposed method effectively addresses the issue of isolated fragment processing in existing External Memory augmented LLMs.\nThe paper provides a comprehensive evaluation of the proposed method on various long text processing tasks, demonstrating its effectiveness.\nHowever, the paper does not discuss the potential limitations or challenges of the proposed method, such as the computational overhead or the impact on the model’s performance.\nAdditionally, the paper does not provide a comparison with other existing methods for processing long contexts in LLMs.\nThe paper could benefit from a more detailed discussion of the potential applications and implications of the proposed method in real-world scenarios.\nOverall, the paper presents a promising approach to improve the processing of long contexts in LLMs, but further research is needed to fully evaluate its potential and limitations."
  },
  {
    "objectID": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#appendix",
    "href": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#appendix",
    "title": "FragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03092v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03092v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7567"
  },
  {
    "objectID": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#major-findings",
    "href": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#major-findings",
    "title": "DomainRAG: A Chinese Benchmark for Evaluating Domain-specific Retrieval-Augmented Generation",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nExisting closed-book LLMs struggle with domain-specific questions, emphasizing the importance of RAG models for solving expert problems.\nThere is room for RAG models to improve their abilities in comprehending conversational history, analyzing structural information, denoising, processing multi-document interactions, and faithfulness in expert knowledge.\nThe use of domain-specific corpora and questions is essential to assess the ability of LLMs to effectively use external knowledge from specific fields to solve expert problems."
  },
  {
    "objectID": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#analysis-and-critique",
    "href": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#analysis-and-critique",
    "title": "DomainRAG: A Chinese Benchmark for Evaluating Domain-specific Retrieval-Augmented Generation",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper provides a comprehensive evaluation of RAG models in a domain-specific context, which is crucial for addressing the limitations of LLMs in expert and domain-specific applications.\nThe study identifies six essential abilities for RAG models, which can serve as a foundation for future research and development in this area.\nThe experimental results highlight the need for RAG models to improve their performance in complex scenarios involving various kinds of information sources.\nThe paper could benefit from a more detailed analysis of the limitations and potential biases of the evaluated LLMs and RAG models.\nFuture studies should explore more sophisticated frameworks for enhancing the performance of RAG systems and evaluate their performance in various application scenarios."
  },
  {
    "objectID": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#appendix",
    "href": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#appendix",
    "title": "DomainRAG: A Chinese Benchmark for Evaluating Domain-specific Retrieval-Augmented Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05654v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05654v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6448"
  },
  {
    "objectID": "posts/Exploring_Large_Language_Models_for_Relevance_Judgments_in_Tetun/2024-06-11-Exploring_Large_Language_Models_for_Relevance_Judgments_in_Tetun.html#appendix",
    "href": "posts/Exploring_Large_Language_Models_for_Relevance_Judgments_in_Tetun/2024-06-11-Exploring_Large_Language_Models_for_Relevance_Judgments_in_Tetun.html#appendix",
    "title": "Exploring Large Language Models for Relevance Judgments in Tetun",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07299v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07299v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3697"
  },
  {
    "objectID": "posts/Keyword_driven_Retrieval_Augmented_Large_Language_Models_for_Cold_start_User_Recommendations/2024-05-30-Keyword_driven_Retrieval_Augmented_Large_Language_Models_for_Cold_start_User_Recommendations.html#appendix",
    "href": "posts/Keyword_driven_Retrieval_Augmented_Large_Language_Models_for_Cold_start_User_Recommendations/2024-05-30-Keyword_driven_Retrieval_Augmented_Large_Language_Models_for_Cold_start_User_Recommendations.html#appendix",
    "title": "Keyword-driven Retrieval-Augmented Large Language Models for Cold-start User Recommendations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.19612v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.19612v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8262"
  },
  {
    "objectID": "posts/DCA_Bench_A_Benchmark_for_Dataset_Curation_Agents/2024-06-11-DCA_Bench_A_Benchmark_for_Dataset_Curation_Agents.html#appendix",
    "href": "posts/DCA_Bench_A_Benchmark_for_Dataset_Curation_Agents/2024-06-11-DCA_Bench_A_Benchmark_for_Dataset_Curation_Agents.html#appendix",
    "title": "DCA-Bench: A Benchmark for Dataset Curation Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07275v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07275v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8553"
  },
  {
    "objectID": "posts/An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection/2024-06-10-An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection.html",
    "href": "posts/An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection/2024-06-10-An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection.html",
    "title": "An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection",
    "section": "",
    "text": "Summary:\nThe paper introduces CodeBreaker, a pioneering LLM-assisted backdoor attack framework on code completion models. Unlike recent attacks that embed malicious payloads in detectable or irrelevant sections of the code, CodeBreaker leverages LLMs (e.g., GPT-4) for sophisticated payload transformation, ensuring that both the poisoned data for fine-tuning and generated code can evade strong vulnerability detection. CodeBreaker stands out with its comprehensive coverage of vulnerabilities, making it the first to provide such an extensive set for evaluation.\nMajor Findings:\nAnalysis and Critique:\nWhile CodeBreaker presents a significant advancement in backdoor attacks on code completion models, there are potential limitations and areas for improvement. The reliance on LLMs for payload transformation and obfuscation may introduce new vulnerabilities in the LLMs themselves, as they are used to facilitate adversarial attacks. Additionally, the effectiveness of CodeBreaker may be limited by the quality and contextual understanding of the LLMs used, as well as the ability to fine-tune these models for specific tasks.\nFurther research is needed to explore the potential for more robust defenses"
  },
  {
    "objectID": "posts/An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection/2024-06-10-An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection.html#appendix",
    "href": "posts/An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection/2024-06-10-An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection.html#appendix",
    "title": "An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06822v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06822v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11894"
  },
  {
    "objectID": "posts/Distributional_reasoning_in_LLMs_Parallel_reasoning_processes_in_multi_hop_reasoning/2024-06-19-Distributional_reasoning_in_LLMs_Parallel_reasoning_processes_in_multi_hop_reasoning.html#appendix",
    "href": "posts/Distributional_reasoning_in_LLMs_Parallel_reasoning_processes_in_multi_hop_reasoning/2024-06-19-Distributional_reasoning_in_LLMs_Parallel_reasoning_processes_in_multi_hop_reasoning.html#appendix",
    "title": "Distributional reasoning in LLMs: Parallel reasoning processes in multi-hop reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13858v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13858v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7199"
  },
  {
    "objectID": "posts/DICE_Detecting_In_distribution_Contamination_in_LLMs_Fine_tuning_Phase_for_Math_Reasoning/2024-06-06-DICE_Detecting_In_distribution_Contamination_in_LLMs_Fine_tuning_Phase_for_Math_Reasoning.html#appendix",
    "href": "posts/DICE_Detecting_In_distribution_Contamination_in_LLMs_Fine_tuning_Phase_for_Math_Reasoning/2024-06-06-DICE_Detecting_In_distribution_Contamination_in_LLMs_Fine_tuning_Phase_for_Math_Reasoning.html#appendix",
    "title": "DICE: Detecting In-distribution Contamination in LLM’s Fine-tuning Phase for Math Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04197v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04197v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6104"
  },
  {
    "objectID": "posts/Open_LLM_Leaderboard_From_Multi_choice_to_Open_style_Questions_for_LLMs_Evaluation_Benchmark_and_Arena/2024-06-11-Open_LLM_Leaderboard_From_Multi_choice_to_Open_style_Questions_for_LLMs_Evaluation_Benchmark_and_Arena.html#appendix",
    "href": "posts/Open_LLM_Leaderboard_From_Multi_choice_to_Open_style_Questions_for_LLMs_Evaluation_Benchmark_and_Arena/2024-06-11-Open_LLM_Leaderboard_From_Multi_choice_to_Open_style_Questions_for_LLMs_Evaluation_Benchmark_and_Arena.html#appendix",
    "title": "Open-LLM-Leaderboard: From Multi-choice to Open-style Questions for LLMs Evaluation, Benchmark, and Arena",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07545v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07545v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5687"
  },
  {
    "objectID": "posts/Jogging_the_Memory_of_Unlearned_Model_Through_Targeted_Relearning_Attack/2024-06-19-Jogging_the_Memory_of_Unlearned_Model_Through_Targeted_Relearning_Attack.html#appendix",
    "href": "posts/Jogging_the_Memory_of_Unlearned_Model_Through_Targeted_Relearning_Attack/2024-06-19-Jogging_the_Memory_of_Unlearned_Model_Through_Targeted_Relearning_Attack.html#appendix",
    "title": "Jogging the Memory of Unlearned Model Through Targeted Relearning Attack",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13356v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13356v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5602"
  },
  {
    "objectID": "posts/MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models/2024-06-20-MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models.html#major-findings",
    "href": "posts/MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models/2024-06-20-MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models.html#major-findings",
    "title": "MR-BEN: A Comprehensive Meta-Reasoning Benchmark for Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nMr-Ben is a comprehensive benchmark that employs a meta-reasoning paradigm, where LLMs are challenged to reason about different forms of reasoning. This paradigm involves LLMs acting as teachers, evaluating the reasoning process by assessing correctness, analyzing potential errors, and providing corrections.\nThe analyses of various LLMs on Mr-Ben reveal distinct limitations and previously unidentified weaknesses in their reasoning abilities. While many LLMs can generate the correct answer to a question, they struggle to pinpoint errors in the reasoning process and correct them. This suggests that existing LLMs have yet to master reasoning, particularly the smaller models.\nTechniques such as the use of high-quality synthetic data can significantly improve reasoning abilities, offering a potential pathway to enhance performance regardless of model size. However, different LLMs excel in different reasoning paradigms, challenging the assumption that domain-specific enhancements necessarily lead to broad cognitive improvements."
  },
  {
    "objectID": "posts/MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models/2024-06-20-MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models/2024-06-20-MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models.html#analysis-and-critique",
    "title": "MR-BEN: A Comprehensive Meta-Reasoning Benchmark for Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nWhile Mr-Ben provides a comprehensive evaluation of LLMs’ reasoning abilities, it has some limitations. The benchmark’s applicability may be restricted when it comes to subjects that are inherently holistic or creative in nature, such as humanities or sociology. Additionally, Mr-Ben is currently confined to questions in English, which could potentially limit the scope of reasoning challenges that can be explored. Furthermore, the analysis and correction of errors in the reasoning steps are currently based on solutions generated by three LLMs, which may not represent the diverse reasoning and error patterns of different LLMs and individuals.\nMoreover, the benchmark may present potential negative societal impacts, such as the risk of LLMs being misused or used maliciously. For instance, LLMs with advanced reasoning capabilities could be used to manipulate information or deceive people. The use"
  },
  {
    "objectID": "posts/MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models/2024-06-20-MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models.html#appendix",
    "href": "posts/MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models/2024-06-20-MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models.html#appendix",
    "title": "MR-BEN: A Comprehensive Meta-Reasoning Benchmark for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13975v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13975v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8416"
  },
  {
    "objectID": "posts/Hello_Again!_LLM_powered_Personalized_Agent_for_Long_term_Dialogue/2024-06-09-Hello_Again!_LLM_powered_Personalized_Agent_for_Long_term_Dialogue.html#appendix",
    "href": "posts/Hello_Again!_LLM_powered_Personalized_Agent_for_Long_term_Dialogue/2024-06-09-Hello_Again!_LLM_powered_Personalized_Agent_for_Long_term_Dialogue.html#appendix",
    "title": "Hello Again! LLM-powered Personalized Agent for Long-term Dialogue",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05925v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05925v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6818"
  },
  {
    "objectID": "posts/Sunnie_An_Anthropomorphic_LLM_Based_Conversational_Agent_for_Mental_Well_Being_Activity_Recommendation/2024-05-22-Sunnie_An_Anthropomorphic_LLM_Based_Conversational_Agent_for_Mental_Well_Being_Activity_Recommendation.html#appendix",
    "href": "posts/Sunnie_An_Anthropomorphic_LLM_Based_Conversational_Agent_for_Mental_Well_Being_Activity_Recommendation/2024-05-22-Sunnie_An_Anthropomorphic_LLM_Based_Conversational_Agent_for_Mental_Well_Being_Activity_Recommendation.html#appendix",
    "title": "Sunnie: An Anthropomorphic LLM-Based Conversational Agent for Mental Well-Being Activity Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.13803v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.13803v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1391"
  },
  {
    "objectID": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#summary-1",
    "href": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#summary-1",
    "title": "LangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling",
    "section": "Summary:",
    "text": "Summary:\nThe paper introduces a novel framework, LangTopo, which aligns graph structure modeling with natural language understanding at the token level. LangTopo quantifies the graph structure modeling capabilities of GNNs and LLMs by constructing a codebook for the graph modality and performs consistency maximization. This process aligns the text description of LLM with the topological modeling of GNN, allowing LLM to learn the ability of GNN to capture graph structures, enabling LLM to handle graph-structured data independently. The effectiveness of the proposed method is demonstrated on multiple datasets."
  },
  {
    "objectID": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#major-findings",
    "href": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#major-findings",
    "title": "LangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe paper proposes LangTopo, a new framework for learning graph structures using LLMs, which enables LLMs to learn GNNs’ ability to model graph structures through supervised learning.\nLangTopo achieves alignment between the natural language descriptive text in LLMs and the processing and operation of GNN models by constructing a codebook for the graph data modality.\nUnlike existing paradigms that usually introduce external modules to recognize graph structures, LangTopo endows the LLM itself with the ability to model graph structures, obviating the need for external data or model integration during inference."
  },
  {
    "objectID": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#analysis-and-critique",
    "href": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#analysis-and-critique",
    "title": "LangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper presents a promising approach to addressing the challenges of combining the structural modeling capacity of GNNs with the text processing capability of LLMs.\nThe use of an external GNN to extract spatial structure embeddings and training a projection layer or adapter to inject these embeddings into the LLM has been a common approach, but LLMs still lack the ability to handle graph data independently and continue to rely on external models during inference.\nThe paper’s focus on modeling, rather than embedding, is a significant contribution to the field, as it addresses the fundamental issue of LLMs lacking the capability to model graph structures.\nThe paper’s evaluation on multiple datasets demonstrates the effectiveness of the proposed method, but further research is needed to explore the generalizability and scalability of LangTopo.\nThe paper’s limitation is the unexplored scenario of jointly training with multiple datasets for graph modality"
  },
  {
    "objectID": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#appendix",
    "href": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#appendix",
    "title": "LangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13250v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13250v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10341"
  },
  {
    "objectID": "posts/Data_Centric_AI_in_the_Age_of_Large_Language_Models/2024-06-20-Data_Centric_AI_in_the_Age_of_Large_Language_Models.html#major-findings",
    "href": "posts/Data_Centric_AI_in_the_Age_of_Large_Language_Models/2024-06-20-Data_Centric_AI_in_the_Age_of_Large_Language_Models.html#major-findings",
    "title": "Data-Centric AI in the Age of Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nData-Centric Benchmarks and Data Curation: The authors advocate for a suite of data-centric benchmarks tailored to the scale and complexity of data for LLMs. These benchmarks can be used to develop new data curation methods and document research efforts and results, which can help promote openness and transparency in AI and LLM research.\nData Attribution: The authors emphasize the importance of data attribution for legal and safety purposes, such as respecting copyright/intellectual property rights and mitigating problematic outputs of LLMs. They describe promising directions for data attribution and removal.\nKnowledge Transfer: The authors discuss the potential of transferring the knowledge of trained LLMs to compact and specialized models. They highlight existing efforts and new opportunities where the outputs of a trained LLM are treated as (synthesized) data.\nInference Contextualization with Data: The authors describe how LLMs can flexibly use data at inference to augment the outputs’ factuality or quality. They elaborate on this paradigm with respect to two prevalent technical frameworks and highlight how it can improve the personalization of LLMs."
  },
  {
    "objectID": "posts/Data_Centric_AI_in_the_Age_of_Large_Language_Models/2024-06-20-Data_Centric_AI_in_the_Age_of_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/Data_Centric_AI_in_the_Age_of_Large_Language_Models/2024-06-20-Data_Centric_AI_in_the_Age_of_Large_Language_Models.html#analysis-and-critique",
    "title": "Data-Centric AI in the Age of Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nLimited Research on Data-Centric Approaches: While the paper provides a comprehensive overview of the role of data in LLMs, it also highlights the lack of research in this area. The authors argue that the bulk of research to date has focused on modeling improvements, with little attention paid to how to best use data for the developmental and inferential stages of LLMs.\nChallenges in Data Attribution and Unlearning:"
  },
  {
    "objectID": "posts/Data_Centric_AI_in_the_Age_of_Large_Language_Models/2024-06-20-Data_Centric_AI_in_the_Age_of_Large_Language_Models.html#appendix",
    "href": "posts/Data_Centric_AI_in_the_Age_of_Large_Language_Models/2024-06-20-Data_Centric_AI_in_the_Age_of_Large_Language_Models.html#appendix",
    "title": "Data-Centric AI in the Age of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14473v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14473v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10052"
  },
  {
    "objectID": "posts/MoPS_Modular_Story_Premise_Synthesis_for_Open_Ended_Automatic_Story_Generation/2024-06-09-MoPS_Modular_Story_Premise_Synthesis_for_Open_Ended_Automatic_Story_Generation.html#appendix",
    "href": "posts/MoPS_Modular_Story_Premise_Synthesis_for_Open_Ended_Automatic_Story_Generation/2024-06-09-MoPS_Modular_Story_Premise_Synthesis_for_Open_Ended_Automatic_Story_Generation.html#appendix",
    "title": "MoPS: Modular Story Premise Synthesis for Open-Ended Automatic Story Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05690v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05690v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9468"
  },
  {
    "objectID": "posts/Dye4AI_Assuring_Data_Boundary_on_Generative_AI_Services/2024-06-20-Dye4AI_Assuring_Data_Boundary_on_Generative_AI_Services.html#appendix",
    "href": "posts/Dye4AI_Assuring_Data_Boundary_on_Generative_AI_Services/2024-06-20-Dye4AI_Assuring_Data_Boundary_on_Generative_AI_Services.html#appendix",
    "title": "Dye4AI: Assuring Data Boundary on Generative AI Services",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14114v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14114v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15379"
  },
  {
    "objectID": "posts/Multi_Layer_Ranking_with_Large_Language_Models_for_News_Source_Recommendation/2024-06-17-Multi_Layer_Ranking_with_Large_Language_Models_for_News_Source_Recommendation.html#appendix",
    "href": "posts/Multi_Layer_Ranking_with_Large_Language_Models_for_News_Source_Recommendation/2024-06-17-Multi_Layer_Ranking_with_Large_Language_Models_for_News_Source_Recommendation.html#appendix",
    "title": "Multi-Layer Ranking with Large Language Models for News Source Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11745v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11745v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4168"
  },
  {
    "objectID": "posts/Safety_Alignment_Should_Be_Made_More_Than_Just_a_Few_Tokens_Deep/2024-06-10-Safety_Alignment_Should_Be_Made_More_Than_Just_a_Few_Tokens_Deep.html#appendix",
    "href": "posts/Safety_Alignment_Should_Be_Made_More_Than_Just_a_Few_Tokens_Deep/2024-06-10-Safety_Alignment_Should_Be_Made_More_Than_Just_a_Few_Tokens_Deep.html#appendix",
    "title": "Safety Alignment Should Be Made More Than Just a Few Tokens Deep",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05946v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05946v1\n\n\nTruncated\nFalse\n\n\nWord Count\n16740"
  },
  {
    "objectID": "posts/SecureNet_A_Comparative_Study_of_DeBERTa_and_Large_Language_Models_for_Phishing_Detection/2024-06-10-SecureNet_A_Comparative_Study_of_DeBERTa_and_Large_Language_Models_for_Phishing_Detection.html#appendix",
    "href": "posts/SecureNet_A_Comparative_Study_of_DeBERTa_and_Large_Language_Models_for_Phishing_Detection/2024-06-10-SecureNet_A_Comparative_Study_of_DeBERTa_and_Large_Language_Models_for_Phishing_Detection.html#appendix",
    "title": "SecureNet: A Comparative Study of DeBERTa and Large Language Models for Phishing Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06663v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06663v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8220"
  },
  {
    "objectID": "posts/Benchmarks_and_Metrics_for_Evaluations_of_Code_Generation_A_Critical_Review/2024-06-18-Benchmarks_and_Metrics_for_Evaluations_of_Code_Generation_A_Critical_Review.html#appendix",
    "href": "posts/Benchmarks_and_Metrics_for_Evaluations_of_Code_Generation_A_Critical_Review/2024-06-18-Benchmarks_and_Metrics_for_Evaluations_of_Code_Generation_A_Critical_Review.html#appendix",
    "title": "Benchmarks and Metrics for Evaluations of Code Generation: A Critical Review",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12655v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12655v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5871"
  },
  {
    "objectID": "posts/FastGAS_Fast_Graph_based_Annotation_Selection_for_In_Context_Learning/2024-06-06-FastGAS_Fast_Graph_based_Annotation_Selection_for_In_Context_Learning.html#appendix",
    "href": "posts/FastGAS_Fast_Graph_based_Annotation_Selection_for_In_Context_Learning/2024-06-06-FastGAS_Fast_Graph_based_Annotation_Selection_for_In_Context_Learning.html#appendix",
    "title": "FastGAS: Fast Graph-based Annotation Selection for In-Context Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03730v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03730v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8522"
  },
  {
    "objectID": "posts/Learning_to_Generate_Answers_with_Citations_via_Factual_Consistency_Models/2024-06-19-Learning_to_Generate_Answers_with_Citations_via_Factual_Consistency_Models.html#appendix",
    "href": "posts/Learning_to_Generate_Answers_with_Citations_via_Factual_Consistency_Models/2024-06-19-Learning_to_Generate_Answers_with_Citations_via_Factual_Consistency_Models.html#appendix",
    "title": "Learning to Generate Answers with Citations via Factual Consistency Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13124v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13124v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13245"
  },
  {
    "objectID": "posts/LLM_enhanced_Reranking_in_Recommender_Systems/2024-06-18-LLM_enhanced_Reranking_in_Recommender_Systems.html#appendix",
    "href": "posts/LLM_enhanced_Reranking_in_Recommender_Systems/2024-06-18-LLM_enhanced_Reranking_in_Recommender_Systems.html#appendix",
    "title": "LLM-enhanced Reranking in Recommender Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12433v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12433v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8439"
  },
  {
    "objectID": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#major-findings",
    "href": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#major-findings",
    "title": "Teaching Language Models to Self-Improve by Learning from Language Feedback",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nSRT significantly outperforms strong baselines across diverse tasks and model sizes, with an average performance enhancement of 3.7 to 4.0 points.\nWhen applied to a 70B parameter model, SRT increases the win rate from 9.6% to 25.8% on the AlpacaEval 2.0 benchmark, surpassing well-established systems such as GPT-4-0314, Claude 2, and Gemini.\nThe success of SRT primarily stems from its language feedback feature, which identifies weak areas and offers valuable suggestions for improvement."
  },
  {
    "objectID": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#analysis-and-critique",
    "href": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#analysis-and-critique",
    "title": "Teaching Language Models to Self-Improve by Learning from Language Feedback",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper presents a novel and promising approach to aligning language models using self-refinement and language feedback.\nThe empirical evaluations demonstrate the effectiveness of SRT in improving model performance across various tasks and model sizes.\nThe paper highlights the crucial role of language feedback in the success of SRT, suggesting potential for further exploration in this direction.\nHowever, the paper does not discuss potential limitations or challenges associated with the SRT method, such as the computational cost of generating feedback and refinements or the potential for overfitting to the feedback.\nAdditionally, the paper does not address the potential for biases in the feedback and refinements generated by the more advanced model, which could impact the alignment of the base model.\nFuture work could explore these limitations and potential solutions to improve the SRT method."
  },
  {
    "objectID": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#appendix",
    "href": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#appendix",
    "title": "Teaching Language Models to Self-Improve by Learning from Language Feedback",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07168v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07168v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6361"
  },
  {
    "objectID": "posts/SLMRec_Empowering_Small_Language_Models_for_Sequential_Recommendation/2024-05-28-SLMRec_Empowering_Small_Language_Models_for_Sequential_Recommendation.html#appendix",
    "href": "posts/SLMRec_Empowering_Small_Language_Models_for_Sequential_Recommendation/2024-05-28-SLMRec_Empowering_Small_Language_Models_for_Sequential_Recommendation.html#appendix",
    "title": "SLMRec: Empowering Small Language Models for Sequential Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.17890v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.17890v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6690"
  },
  {
    "objectID": "posts/Open_Generative_Large_Language_Models_for_Galician/2024-06-19-Open_Generative_Large_Language_Models_for_Galician.html#appendix",
    "href": "posts/Open_Generative_Large_Language_Models_for_Galician/2024-06-19-Open_Generative_Large_Language_Models_for_Galician.html#appendix",
    "title": "Open Generative Large Language Models for Galician",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13893v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13893v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6815"
  },
  {
    "objectID": "posts/Breaking_the_Ceiling_of_the_LLM_Community_by_Treating_Token_Generation_as_a_Classification_for_Ensembling/2024-06-18-Breaking_the_Ceiling_of_the_LLM_Community_by_Treating_Token_Generation_as_a_Classification_for_Ensembling.html#appendix",
    "href": "posts/Breaking_the_Ceiling_of_the_LLM_Community_by_Treating_Token_Generation_as_a_Classification_for_Ensembling/2024-06-18-Breaking_the_Ceiling_of_the_LLM_Community_by_Treating_Token_Generation_as_a_Classification_for_Ensembling.html#appendix",
    "title": "Breaking the Ceiling of the LLM Community by Treating Token Generation as a Classification for Ensembling",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12585v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12585v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5835"
  },
  {
    "objectID": "posts/Adaptable_Logical_Control_for_Large_Language_Models/2024-06-19-Adaptable_Logical_Control_for_Large_Language_Models.html#appendix",
    "href": "posts/Adaptable_Logical_Control_for_Large_Language_Models/2024-06-19-Adaptable_Logical_Control_for_Large_Language_Models.html#appendix",
    "title": "Adaptable Logical Control for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13892v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13892v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7583"
  },
  {
    "objectID": "posts/Using_LLMs_to_Aid_Annotation_and_Collection_of_Clinically_Enriched_Data_in_Bipolar_Disorder_and_Schizophrenia/2024-06-18-Using_LLMs_to_Aid_Annotation_and_Collection_of_Clinically_Enriched_Data_in_Bipolar_Disorder_and_Schizophrenia.html#appendix",
    "href": "posts/Using_LLMs_to_Aid_Annotation_and_Collection_of_Clinically_Enriched_Data_in_Bipolar_Disorder_and_Schizophrenia/2024-06-18-Using_LLMs_to_Aid_Annotation_and_Collection_of_Clinically_Enriched_Data_in_Bipolar_Disorder_and_Schizophrenia.html#appendix",
    "title": "Using LLMs to Aid Annotation and Collection of Clinically-Enriched Data in Bipolar Disorder and Schizophrenia",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12687v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12687v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5994"
  },
  {
    "objectID": "posts/Prism_A_Framework_for_Decoupling_and_Assessing_the_Capabilities_of_VLMs/2024-06-20-Prism_A_Framework_for_Decoupling_and_Assessing_the_Capabilities_of_VLMs.html#appendix",
    "href": "posts/Prism_A_Framework_for_Decoupling_and_Assessing_the_Capabilities_of_VLMs/2024-06-20-Prism_A_Framework_for_Decoupling_and_Assessing_the_Capabilities_of_VLMs.html#appendix",
    "title": "Prism: A Framework for Decoupling and Assessing the Capabilities of VLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14544v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14544v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8916"
  },
  {
    "objectID": "posts/iMotion_LLM_Motion_Prediction_Instruction_Tuning/2024-06-10-iMotion_LLM_Motion_Prediction_Instruction_Tuning.html#appendix",
    "href": "posts/iMotion_LLM_Motion_Prediction_Instruction_Tuning/2024-06-10-iMotion_LLM_Motion_Prediction_Instruction_Tuning.html#appendix",
    "title": "iMotion-LLM: Motion Prediction Instruction Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06211v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06211v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5777"
  },
  {
    "objectID": "posts/Nicer_Than_Humans_How_do_Large_Language_Models_Behave_in_the_Prisoners_Dilemma/2024-06-19-Nicer_Than_Humans_How_do_Large_Language_Models_Behave_in_the_Prisoners_Dilemma.html#appendix",
    "href": "posts/Nicer_Than_Humans_How_do_Large_Language_Models_Behave_in_the_Prisoners_Dilemma/2024-06-19-Nicer_Than_Humans_How_do_Large_Language_Models_Behave_in_the_Prisoners_Dilemma.html#appendix",
    "title": "Nicer Than Humans: How do Large Language Models Behave in the Prisoner’s Dilemma?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13605v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13605v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7427"
  },
  {
    "objectID": "posts/61A_Bot_AI_homework_assistance_in_CS1_is_fast_and_cheap____but_is_it_helpful/2024-06-09-61A_Bot_AI_homework_assistance_in_CS1_is_fast_and_cheap____but_is_it_helpful.html#appendix",
    "href": "posts/61A_Bot_AI_homework_assistance_in_CS1_is_fast_and_cheap____but_is_it_helpful/2024-06-09-61A_Bot_AI_homework_assistance_in_CS1_is_fast_and_cheap____but_is_it_helpful.html#appendix",
    "title": "61A-Bot: AI homework assistance in CS1 is fast and cheap – but is it helpful?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05600v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05600v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7095"
  },
  {
    "objectID": "posts/In_Context_Learning_and_Fine_Tuning_GPT_for_Argument_Mining/2024-06-10-In_Context_Learning_and_Fine_Tuning_GPT_for_Argument_Mining.html#appendix",
    "href": "posts/In_Context_Learning_and_Fine_Tuning_GPT_for_Argument_Mining/2024-06-10-In_Context_Learning_and_Fine_Tuning_GPT_for_Argument_Mining.html#appendix",
    "title": "In-Context Learning and Fine-Tuning GPT for Argument Mining",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06699v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06699v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2590"
  },
  {
    "objectID": "posts/Can_LLMs_Reason_in_the_Wild_with_Programs/2024-06-19-Can_LLMs_Reason_in_the_Wild_with_Programs.html#appendix",
    "href": "posts/Can_LLMs_Reason_in_the_Wild_with_Programs/2024-06-19-Can_LLMs_Reason_in_the_Wild_with_Programs.html#appendix",
    "title": "Can LLMs Reason in the Wild with Programs?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13764v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13764v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13142"
  },
  {
    "objectID": "posts/Security_Vulnerability_Detection_with_Multitask_Self_Instructed_Fine_Tuning_of_Large_Language_Models/2024-06-09-Security_Vulnerability_Detection_with_Multitask_Self_Instructed_Fine_Tuning_of_Large_Language_Models.html#appendix",
    "href": "posts/Security_Vulnerability_Detection_with_Multitask_Self_Instructed_Fine_Tuning_of_Large_Language_Models/2024-06-09-Security_Vulnerability_Detection_with_Multitask_Self_Instructed_Fine_Tuning_of_Large_Language_Models.html#appendix",
    "title": "Security Vulnerability Detection with Multitask Self-Instructed Fine-Tuning of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05892v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05892v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10513"
  },
  {
    "objectID": "posts/SPL_A_Socratic_Playground_for_Learning_Powered_by_Large_Language_Mode/2024-06-20-SPL_A_Socratic_Playground_for_Learning_Powered_by_Large_Language_Mode.html#appendix",
    "href": "posts/SPL_A_Socratic_Playground_for_Learning_Powered_by_Large_Language_Mode/2024-06-20-SPL_A_Socratic_Playground_for_Learning_Powered_by_Large_Language_Mode.html#appendix",
    "title": "SPL: A Socratic Playground for Learning Powered by Large Language Mode",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13919v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13919v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7284"
  },
  {
    "objectID": "posts/Seeing_Through_AIs_Lens_Enhancing_Human_Skepticism_Towards_LLM_Generated_Fake_News/2024-06-20-Seeing_Through_AIs_Lens_Enhancing_Human_Skepticism_Towards_LLM_Generated_Fake_News.html#appendix",
    "href": "posts/Seeing_Through_AIs_Lens_Enhancing_Human_Skepticism_Towards_LLM_Generated_Fake_News/2024-06-20-Seeing_Through_AIs_Lens_Enhancing_Human_Skepticism_Towards_LLM_Generated_Fake_News.html#appendix",
    "title": "Seeing Through AI’s Lens: Enhancing Human Skepticism Towards LLM-Generated Fake News",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14012v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14012v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7336"
  },
  {
    "objectID": "posts/Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course/2024-06-10-Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course.html",
    "href": "posts/Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course/2024-06-10-Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course.html",
    "title": "Insights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course",
    "section": "",
    "text": "Summary:\nThis study explores the social dynamics surrounding the use of large language models (LLMs) in an undergraduate programming course. The research is guided by the social shaping of technology theory and focuses on two research questions: (1) How do social perceptions influence the usage of LLMs in an undergraduate intermediate-level programming course? (2) How does LLM usage relate to programming self-efficacy and midterm scores among undergraduate students in an intermediate-level programming course?\nThe study employs a mixed-methods approach, including an anonymous student survey, student interviews, and a regression analysis of midterm performance data with students’ self-reported use of LLMs on homework. The findings suggest that students’ engagement with LLMs is significantly associated with their perceptions of their future careers and their peers’ usage. Additionally, the use of LLMs has mixed impacts on students’ self-efficacy and perceived learning outcomes, with a notable negative correlation between LLM usage and self-efficacy regardless of major and a negative correlation between LLM usage and performance on the first midterm.\nMajor Findings:\nAnalysis and Critique:\nThe study provides valuable insights into the social dynamics surrounding the use of LLMs in undergraduate programming education. However, the research has some limitations, including the context of the study, potential selection bias, reliance on self-reported data, and the correlational nature of the regression analyses. Additionally, the study’s focus on peer-reviewed literature may have led to the omission of relevant contributions from non-peer-reviewed sources. Despite these limitations, the research offers a nuanced understanding of the complex dynamic between technology and social factors, challenging the notion of technological determinism. As LLMs and other AI technologies continue to evolve, it is crucial to consider the social dynamics that shape their appropriation."
  },
  {
    "objectID": "posts/Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course/2024-06-10-Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course.html#appendix",
    "href": "posts/Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course/2024-06-10-Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course.html#appendix",
    "title": "Insights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06451v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06451v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14658"
  },
  {
    "objectID": "posts/When_Box_Meets_Graph_Neural_Network_in_Tag_aware_Recommendation/2024-06-17-When_Box_Meets_Graph_Neural_Network_in_Tag_aware_Recommendation.html#appendix",
    "href": "posts/When_Box_Meets_Graph_Neural_Network_in_Tag_aware_Recommendation/2024-06-17-When_Box_Meets_Graph_Neural_Network_in_Tag_aware_Recommendation.html#appendix",
    "title": "When Box Meets Graph Neural Network in Tag-aware Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12020v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12020v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8318"
  },
  {
    "objectID": "posts/Data_Contamination_Can_Cross_Language_Barriers/2024-06-19-Data_Contamination_Can_Cross_Language_Barriers.html#appendix",
    "href": "posts/Data_Contamination_Can_Cross_Language_Barriers/2024-06-19-Data_Contamination_Can_Cross_Language_Barriers.html#appendix",
    "title": "Data Contamination Can Cross Language Barriers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13236v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13236v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7163"
  },
  {
    "objectID": "posts/CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only/2024-06-11-CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only.html",
    "href": "posts/CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only/2024-06-11-CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only.html",
    "title": "CAAP: Context-Aware Action Planning Prompting to Solve Computer Tasks with Front-End UI Only",
    "section": "",
    "text": "Summary:\nThe paper introduces an LLM-based agent that operates solely on the basis of screenshots for recognizing environments, while leveraging in-context learning to eliminate the need for collecting large datasets of human demonstration. The proposed method, named Context-Aware Action Planning (CAAP) prompting, encourages the agent to meticulously review the context in various angles. The agent achieves a success rate of 94.4% on 67 types of MiniWoB++ problems, utilizing only 1.48 demonstrations per problem type. The method offers the potential for broader applications, especially for tasks that require inter-application coordination on computers or smartphones.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel approach to LLM-based agents that addresses the limitations of existing methods reliant on HTML or DOM inputs and those that combine supervised learning (SL) and reinforcement learning (RL). The proposed agent operates solely on visual inputs and utilizes a large language model (LLM). The CAAP prompting approach is introduced to enhance the decision-making capabilities of ICL-based agents. The evaluations using the MiniWoB++ benchmark demonstrate the superiority of the proposed method. However, the scope of validation remains limited, and further research is needed to evaluate the agent across a broader array of benchmarks. Additionally, the agent’s reliance on visual observation data may lead to observation failures, as demonstrated in the case study. The paper also acknowledges the limitations of the benchmark directives and the need for more comprehensive assessment from a research perspective."
  },
  {
    "objectID": "posts/CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only/2024-06-11-CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only.html#appendix",
    "href": "posts/CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only/2024-06-11-CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only.html#appendix",
    "title": "CAAP: Context-Aware Action Planning Prompting to Solve Computer Tasks with Front-End UI Only",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06947v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06947v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10877"
  },
  {
    "objectID": "posts/Language_Models_Resist_Alignment/2024-06-10-Language_Models_Resist_Alignment.html#appendix",
    "href": "posts/Language_Models_Resist_Alignment/2024-06-10-Language_Models_Resist_Alignment.html#appendix",
    "title": "Language Models Resist Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06144v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06144v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5000"
  },
  {
    "objectID": "posts/Anomaly_Detection_on_Unstable_Logs_with_GPT_Models/2024-06-11-Anomaly_Detection_on_Unstable_Logs_with_GPT_Models.html#appendix",
    "href": "posts/Anomaly_Detection_on_Unstable_Logs_with_GPT_Models/2024-06-11-Anomaly_Detection_on_Unstable_Logs_with_GPT_Models.html#appendix",
    "title": "Anomaly Detection on Unstable Logs with GPT Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07467v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07467v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11408"
  },
  {
    "objectID": "posts/CoSQA+_Enhancing_Code_Search_Dataset_with_Matching_Code/2024-06-17-CoSQA+_Enhancing_Code_Search_Dataset_with_Matching_Code.html#appendix",
    "href": "posts/CoSQA+_Enhancing_Code_Search_Dataset_with_Matching_Code/2024-06-17-CoSQA+_Enhancing_Code_Search_Dataset_with_Matching_Code.html#appendix",
    "title": "CoSQA+: Enhancing Code Search Dataset with Matching Code",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11589v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11589v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6587"
  },
  {
    "objectID": "posts/LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction/2024-06-20-LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction.html",
    "href": "posts/LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction/2024-06-20-LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction.html",
    "title": "LLM4CP: Adapting Large Language Models for Channel Prediction",
    "section": "",
    "text": "Summary:\nThe paper proposes a novel channel prediction method called LLM4CP, which is based on fine-tuning pre-trained GPT-2 for MISO-OFDM channel prediction tasks. The method predicts future downlink CSI sequences based on historical uplink CSI sequences and can be applied to both TDD and FDD systems. To account for channel characteristics, the authors have tailored preprocessor, embedding, and output modules to bridge the gap between CSI data and LLM. Preliminary simulations validate the superiority of LLM4CP over existing model-based and deep learning-based channel prediction methods in full-sample, few-shot, and generalization tests with acceptable training and inference costs.\nMajor Findings:\nAnalysis and Critique:\nOverall, the paper presents an interesting and promising approach to channel prediction based on fine-tuning pre-trained GPT-2. However, more detailed analysis and comparison with other state-of-the-art methods are needed to better understand its advantages and"
  },
  {
    "objectID": "posts/LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction/2024-06-20-LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction.html#appendix",
    "href": "posts/LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction/2024-06-20-LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction.html#appendix",
    "title": "LLM4CP: Adapting Large Language Models for Channel Prediction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14440v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14440v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8453"
  },
  {
    "objectID": "posts/DocCGen_Document_based_Controlled_Code_Generation/2024-06-17-DocCGen_Document_based_Controlled_Code_Generation.html#appendix",
    "href": "posts/DocCGen_Document_based_Controlled_Code_Generation/2024-06-17-DocCGen_Document_based_Controlled_Code_Generation.html#appendix",
    "title": "DocCGen: Document-based Controlled Code Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11925v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11925v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9497"
  },
  {
    "objectID": "posts/Q_Improving_Multi_step_Reasoning_for_LLMs_with_Deliberative_Planning/2024-06-20-Q_Improving_Multi_step_Reasoning_for_LLMs_with_Deliberative_Planning.html#appendix",
    "href": "posts/Q_Improving_Multi_step_Reasoning_for_LLMs_with_Deliberative_Planning/2024-06-20-Q_Improving_Multi_step_Reasoning_for_LLMs_with_Deliberative_Planning.html#appendix",
    "title": "Q*: Improving Multi-step Reasoning for LLMs with Deliberative Planning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14283v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14283v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5312"
  },
  {
    "objectID": "posts/Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory/2024-06-20-Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory.html",
    "href": "posts/Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory/2024-06-20-Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory.html",
    "title": "Artificial Leviathan: Exploring Social Evolution of LLM Agents Through the Lens of Hobbesian Social Contract Theory",
    "section": "",
    "text": "Summary:\nThe paper presents a novel multi-agent simulation framework that generates believable artificial societies capable of replicating complex human group behaviors and social interactions. The agents’ behaviors are conditioned by their innate psychological drives, intrinsic motivations, and the constraints of their simulated environment. Empirical evidence from systematic experiments establishes correlations between agent attributes and available resources, and the evolutionary trajectories of simulated societies. The analysis discusses the collective behaviors of the generative agents, highlighting the opportunities and potential risks associated with leveraging LLMs for societal simulations.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an innovative approach to simulating complex human group behaviors and social interactions using LLMs. The empirical evidence from systematic experiments supports the correlations between agent attributes and available resources, and the evolutionary trajectories of simulated societies. However, the paper does not address the limitations of LLMs in accurately modeling human behavior, such as the inability to capture the nuances of human emotions and decision-making processes. Additionally, the paper does not discuss the potential biases introduced by the LLMs used in the simulation, which could impact the accuracy of the results. Overall, the paper provides a valuable contribution to the field of computational social science, but further research is needed to address the limitations and biases of LLMs in simulating human behavior."
  },
  {
    "objectID": "posts/Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory/2024-06-20-Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory.html#appendix",
    "href": "posts/Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory/2024-06-20-Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory.html#appendix",
    "title": "Artificial Leviathan: Exploring Social Evolution of LLM Agents Through the Lens of Hobbesian Social Contract Theory",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14373v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14373v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12979"
  },
  {
    "objectID": "posts/Raccoon_Prompt_Extraction_Benchmark_of_LLM_Integrated_Applications/2024-06-10-Raccoon_Prompt_Extraction_Benchmark_of_LLM_Integrated_Applications.html#appendix",
    "href": "posts/Raccoon_Prompt_Extraction_Benchmark_of_LLM_Integrated_Applications/2024-06-10-Raccoon_Prompt_Extraction_Benchmark_of_LLM_Integrated_Applications.html#appendix",
    "title": "Raccoon: Prompt Extraction Benchmark of LLM-Integrated Applications",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06737v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06737v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6069"
  },
  {
    "objectID": "posts/Optimizing_Psychological_Counseling_with_Instruction_Tuned_Large_Language_Models/2024-06-19-Optimizing_Psychological_Counseling_with_Instruction_Tuned_Large_Language_Models.html#appendix",
    "href": "posts/Optimizing_Psychological_Counseling_with_Instruction_Tuned_Large_Language_Models/2024-06-19-Optimizing_Psychological_Counseling_with_Instruction_Tuned_Large_Language_Models.html#appendix",
    "title": "Optimizing Psychological Counseling with Instruction-Tuned Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13617v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13617v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4397"
  },
  {
    "objectID": "posts/M2CVD_Multi_Model_Collaboration_for_Code_Vulnerability_Detection/2024-06-10-M2CVD_Multi_Model_Collaboration_for_Code_Vulnerability_Detection.html#appendix",
    "href": "posts/M2CVD_Multi_Model_Collaboration_for_Code_Vulnerability_Detection/2024-06-10-M2CVD_Multi_Model_Collaboration_for_Code_Vulnerability_Detection.html#appendix",
    "title": "M2CVD: Multi-Model Collaboration for Code Vulnerability Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05940v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05940v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9185"
  },
  {
    "objectID": "posts/Towards_more_realistic_evaluation_of_LLM_based_code_generation_an_experimental_study_and_beyond/2024-06-11-Towards_more_realistic_evaluation_of_LLM_based_code_generation_an_experimental_study_and_beyond.html#appendix",
    "href": "posts/Towards_more_realistic_evaluation_of_LLM_based_code_generation_an_experimental_study_and_beyond/2024-06-11-Towards_more_realistic_evaluation_of_LLM_based_code_generation_an_experimental_study_and_beyond.html#appendix",
    "title": "Towards more realistic evaluation of LLM-based code generation: an experimental study and beyond",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06918v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06918v1\n\n\nTruncated\nFalse\n\n\nWord Count\n0"
  },
  {
    "objectID": "posts/Large_Language_Models_Memorize_Sensor_Datasets!_Implications_on_Human_Activity_Recognition_Research/2024-06-09-Large_Language_Models_Memorize_Sensor_Datasets!_Implications_on_Human_Activity_Recognition_Research.html#appendix",
    "href": "posts/Large_Language_Models_Memorize_Sensor_Datasets!_Implications_on_Human_Activity_Recognition_Research/2024-06-09-Large_Language_Models_Memorize_Sensor_Datasets!_Implications_on_Human_Activity_Recognition_Research.html#appendix",
    "title": "Large Language Models Memorize Sensor Datasets! Implications on Human Activity Recognition Research",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05900v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05900v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6787"
  },
  {
    "objectID": "posts/NoteLLM_2_Multimodal_Large_Representation_Models_for_Recommendation/2024-05-27-NoteLLM_2_Multimodal_Large_Representation_Models_for_Recommendation.html#appendix",
    "href": "posts/NoteLLM_2_Multimodal_Large_Representation_Models_for_Recommendation/2024-05-27-NoteLLM_2_Multimodal_Large_Representation_Models_for_Recommendation.html#appendix",
    "title": "NoteLLM-2: Multimodal Large Representation Models for Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.16789v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.16789v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7838"
  },
  {
    "objectID": "posts/Instruct_Not_Assist_LLM_based_Multi_Turn_Planning_and_Hierarchical_Questioning_for_Socratic_Code_Debugging/2024-06-17-Instruct_Not_Assist_LLM_based_Multi_Turn_Planning_and_Hierarchical_Questioning_for_Socratic_Code_Debugging.html#appendix",
    "href": "posts/Instruct_Not_Assist_LLM_based_Multi_Turn_Planning_and_Hierarchical_Questioning_for_Socratic_Code_Debugging/2024-06-17-Instruct_Not_Assist_LLM_based_Multi_Turn_Planning_and_Hierarchical_Questioning_for_Socratic_Code_Debugging.html#appendix",
    "title": "Instruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11709v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11709v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9274"
  },
  {
    "objectID": "posts/Large_language_models_for_generating_rules_yay_or_nay/2024-06-10-Large_language_models_for_generating_rules_yay_or_nay.html#appendix",
    "href": "posts/Large_language_models_for_generating_rules_yay_or_nay/2024-06-10-Large_language_models_for_generating_rules_yay_or_nay.html#appendix",
    "title": "Large language models for generating rules, yay or nay?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06835v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06835v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4575"
  },
  {
    "objectID": "posts/LLM4MSR_An_LLM_Enhanced_Paradigm_for_Multi_Scenario_Recommendation/2024-06-18-LLM4MSR_An_LLM_Enhanced_Paradigm_for_Multi_Scenario_Recommendation.html#appendix",
    "href": "posts/LLM4MSR_An_LLM_Enhanced_Paradigm_for_Multi_Scenario_Recommendation/2024-06-18-LLM4MSR_An_LLM_Enhanced_Paradigm_for_Multi_Scenario_Recommendation.html#appendix",
    "title": "LLM4MSR: An LLM-Enhanced Paradigm for Multi-Scenario Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12529v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12529v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9061"
  },
  {
    "objectID": "posts/APEER_Automatic_Prompt_Engineering_Enhances_Large_Language_Model_Reranking/2024-06-20-APEER_Automatic_Prompt_Engineering_Enhances_Large_Language_Model_Reranking.html#appendix",
    "href": "posts/APEER_Automatic_Prompt_Engineering_Enhances_Large_Language_Model_Reranking/2024-06-20-APEER_Automatic_Prompt_Engineering_Enhances_Large_Language_Model_Reranking.html#appendix",
    "title": "APEER: Automatic Prompt Engineering Enhances Large Language Model Reranking",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14449v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14449v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7262"
  },
  {
    "objectID": "posts/Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models/2024-06-08-Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models.html",
    "href": "posts/Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models/2024-06-08-Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models.html",
    "title": "Creativity Has Left the Chat: The Price of Debiasing Language Models",
    "section": "",
    "text": "Summary:\nThe paper “Creativity Has Left the Chat: The Price of Debiasing Language Models” explores the impact of the Reinforcement Learning from Human Feedback (RLHF) process on the creativity and output diversity of Large Language Models (LLMs). The authors use the Llama-2 series of models to conduct three experiments, focusing on the Llama-2-7B-text (base model) and Llama-2-7B-chat (aligned model). The experiments reveal that while RLHF effectively reduces biases and toxicity in LLMs, it may inadvertently lead to a reduction in the models’ creative potential. The aligned models exhibit lower entropy in token predictions, form distinct clusters in the embedding space, and gravitate towards “attractor states,” indicating limited output diversity. These findings have significant implications for marketers who rely on LLMs for creative tasks, as the trade-off between consistency and creativity in aligned models should be carefully considered.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides valuable insights into the unintended consequences of the RLHF process on the creativity and output diversity of LLMs. However, the study is limited by the computational costs and resource demands, which prevented the authors from delving into various parameters or configurations of the RLHF process. Future research should explore different parameters and configurations to understand their impact on the creativity and output diversity of aligned LLMs. Additionally, further investigation is needed to analyze other unintended consequences of model alignment and RLHF to enhance our understanding of the trade-offs involved in practical applications of these models."
  },
  {
    "objectID": "posts/Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models/2024-06-08-Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models.html#appendix",
    "href": "posts/Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models/2024-06-08-Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models.html#appendix",
    "title": "Creativity Has Left the Chat: The Price of Debiasing Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05587v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05587v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20391"
  },
  {
    "objectID": "posts/Synthetic_Programming_Elicitation_and_Repair_for_Text_to_Code_in_Very_Low_Resource_Programming_Languages/2024-06-05-Synthetic_Programming_Elicitation_and_Repair_for_Text_to_Code_in_Very_Low_Resource_Programming_Languages.html#appendix",
    "href": "posts/Synthetic_Programming_Elicitation_and_Repair_for_Text_to_Code_in_Very_Low_Resource_Programming_Languages/2024-06-05-Synthetic_Programming_Elicitation_and_Repair_for_Text_to_Code_in_Very_Low_Resource_Programming_Languages.html#appendix",
    "title": "Synthetic Programming Elicitation and Repair for Text-to-Code in Very Low-Resource Programming Languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03636v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03636v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9438"
  },
  {
    "objectID": "posts/An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics/2024-06-10-An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics.html",
    "href": "posts/An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics/2024-06-10-An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics.html",
    "title": "An Empirical Design Justice Approach to Identifying Ethical Considerations in the Intersection of Large Language Models and Social Robotics",
    "section": "",
    "text": "Summary:\nThe integration of Large Language Models (LLMs) in social robotics presents a unique set of ethical challenges and social impacts. This research aims to identify ethical considerations that arise in the design and development of these two technologies in combination. Using LLMs for social robotics may provide benefits, such as enabling natural language open-domain dialogues. However, the intersection of these two technologies also gives rise to ethical concerns related to misinformation, non-verbal cues, emotional disruption, and biases. The robot’s physical social embodiment adds complexity, as ethical hazards associated with LLM-based Social AI, such as hallucinations and misinformation, can be exacerbated due to the effects of physical embodiment on social perception and communication. To address these challenges, this study employs an empirical design justice-based methodology, focusing on identifying socio-technical ethical considerations through a qualitative co-design and interaction study. The purpose of the study is to identify ethical considerations relevant to the process of co-design of, and interaction with a humanoid social robot as the interface of a LLM, and to evaluate how a design justice methodology can be used in the context of designing LLMs-based social robotics.\nMajor Findings:\nAnalysis and Critique:\nThe study presents a novel methodological approach based on previous work on design justice in AI and HRI. The approach enables the identification and validation of ethical concerns through empirical design justice-based data from diverse participants. However, the study also highlights limitations, such as the inability to confidently determine ethical considerations in"
  },
  {
    "objectID": "posts/An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics/2024-06-10-An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics.html#appendix",
    "href": "posts/An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics/2024-06-10-An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics.html#appendix",
    "title": "An Empirical Design Justice Approach to Identifying Ethical Considerations in the Intersection of Large Language Models and Social Robotics",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06400v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06400v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14471"
  },
  {
    "objectID": "posts/3D_Properties_Identifying_Challenges_in_DPO_and_Charting_a_Path_Forward/2024-06-11-3D_Properties_Identifying_Challenges_in_DPO_and_Charting_a_Path_Forward.html#appendix",
    "href": "posts/3D_Properties_Identifying_Challenges_in_DPO_and_Charting_a_Path_Forward/2024-06-11-3D_Properties_Identifying_Challenges_in_DPO_and_Charting_a_Path_Forward.html#appendix",
    "title": "3D-Properties: Identifying Challenges in DPO and Charting a Path Forward",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07327v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07327v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8028"
  },
  {
    "objectID": "posts/Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents/2024-06-10-Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents.html",
    "href": "posts/Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents/2024-06-10-Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents.html",
    "title": "Transforming Wearable Data into Health Insights using Large Language Model Agents",
    "section": "",
    "text": "Summary: The paper presents a study on the Personal Health Insights Agent (PHIA), an AI model designed to answer personal health queries using wearable data. PHIA outperforms the Code Generation baseline by 14% (84% vs. 74%) in exact matching accuracy for objective personal health queries. In open-ended reasoning quality, PHIA demonstrates a significant advantage over the Code Generation baseline in all ratings except for personalization. Expert evaluation shows that PHIA has a significant advantage over the Code Generation baseline in overall code quality, avoiding hallucinations, and personalization. PHIA is also quantitatively less likely to generate code that raises an error.\nMajor Findings: 1. PHIA outperforms the Code Generation baseline by 14% in exact matching accuracy for objective personal health queries. 2. PHIA demonstrates a significant advantage over the Code Generation baseline in open-ended reasoning quality."
  },
  {
    "objectID": "posts/Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents/2024-06-10-Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents.html#appendix",
    "href": "posts/Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents/2024-06-10-Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents.html#appendix",
    "title": "Transforming Wearable Data into Health Insights using Large Language Model Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06464v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06464v1\n\n\nTruncated\nTrue\n\n\nWord Count\n28809"
  },
  {
    "objectID": "posts/WaDec_Decompile_WebAssembly_Using_Large_Language_Model/2024-06-17-WaDec_Decompile_WebAssembly_Using_Large_Language_Model.html#appendix",
    "href": "posts/WaDec_Decompile_WebAssembly_Using_Large_Language_Model/2024-06-17-WaDec_Decompile_WebAssembly_Using_Large_Language_Model.html#appendix",
    "title": "WaDec: Decompile WebAssembly Using Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11346v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11346v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10923"
  },
  {
    "objectID": "posts/Mind_the_Privacy_Unit!_User_Level_Differential_Privacy_for_Language_Model_Fine_Tuning/2024-06-20-Mind_the_Privacy_Unit!_User_Level_Differential_Privacy_for_Language_Model_Fine_Tuning.html#appendix",
    "href": "posts/Mind_the_Privacy_Unit!_User_Level_Differential_Privacy_for_Language_Model_Fine_Tuning/2024-06-20-Mind_the_Privacy_Unit!_User_Level_Differential_Privacy_for_Language_Model_Fine_Tuning.html#appendix",
    "title": "Mind the Privacy Unit! User-Level Differential Privacy for Language Model Fine-Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14322v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14322v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7165"
  },
  {
    "objectID": "posts/Navigating_User_Experience_of_ChatGPT_based_Conversational_Recommender_Systems_The_Effects_of_Prompt_Guidance_and_Recommendation_Domain/2024-05-22-Navigating_User_Experience_of_ChatGPT_based_Conversational_Recommender_Systems_The_Effects_of_Prompt_Guidance_and_Recommendation_Domain.html#appendix",
    "href": "posts/Navigating_User_Experience_of_ChatGPT_based_Conversational_Recommender_Systems_The_Effects_of_Prompt_Guidance_and_Recommendation_Domain/2024-05-22-Navigating_User_Experience_of_ChatGPT_based_Conversational_Recommender_Systems_The_Effects_of_Prompt_Guidance_and_Recommendation_Domain.html#appendix",
    "title": "Navigating User Experience of ChatGPT-based Conversational Recommender Systems: The Effects of Prompt Guidance and Recommendation Domain",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.13560v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.13560v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8278"
  },
  {
    "objectID": "posts/Investigating_Low_Cost_LLM_Annotation_for~Spoken_Dialogue_Understanding_Datasets/2024-06-19-Investigating_Low_Cost_LLM_Annotation_for~Spoken_Dialogue_Understanding_Datasets.html#appendix",
    "href": "posts/Investigating_Low_Cost_LLM_Annotation_for~Spoken_Dialogue_Understanding_Datasets/2024-06-19-Investigating_Low_Cost_LLM_Annotation_for~Spoken_Dialogue_Understanding_Datasets.html#appendix",
    "title": "Investigating Low-Cost LLM Annotation for~Spoken Dialogue Understanding Datasets",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13269v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13269v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6424"
  },
  {
    "objectID": "posts/HalluDial_A_Large_Scale_Benchmark_for_Automatic_Dialogue_Level_Hallucination_Evaluation/2024-06-11-HalluDial_A_Large_Scale_Benchmark_for_Automatic_Dialogue_Level_Hallucination_Evaluation.html#appendix",
    "href": "posts/HalluDial_A_Large_Scale_Benchmark_for_Automatic_Dialogue_Level_Hallucination_Evaluation/2024-06-11-HalluDial_A_Large_Scale_Benchmark_for_Automatic_Dialogue_Level_Hallucination_Evaluation.html#appendix",
    "title": "HalluDial: A Large-Scale Benchmark for Automatic Dialogue-Level Hallucination Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07070v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07070v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10462"
  },
  {
    "objectID": "posts/Do_LLMs_Exhibit_Human_Like_Reasoning_Evaluating_Theory_of_Mind_in_LLMs_for_Open_Ended_Responses/2024-06-09-Do_LLMs_Exhibit_Human_Like_Reasoning_Evaluating_Theory_of_Mind_in_LLMs_for_Open_Ended_Responses.html#appendix",
    "href": "posts/Do_LLMs_Exhibit_Human_Like_Reasoning_Evaluating_Theory_of_Mind_in_LLMs_for_Open_Ended_Responses/2024-06-09-Do_LLMs_Exhibit_Human_Like_Reasoning_Evaluating_Theory_of_Mind_in_LLMs_for_Open_Ended_Responses.html#appendix",
    "title": "Do LLMs Exhibit Human-Like Reasoning? Evaluating Theory of Mind in LLMs for Open-Ended Responses",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05659v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05659v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10269"
  },
  {
    "objectID": "posts/Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text/2024-06-10-Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text.html",
    "href": "posts/Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text/2024-06-10-Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text.html",
    "title": "Synth-SBDH: A Synthetic Dataset of Social and Behavioral Determinants of Health for Clinical Text",
    "section": "",
    "text": "Summary:\nThe study introduces Synth-SBDH, a novel synthetic dataset with detailed SBDH annotations, encompassing status, temporal information, and rationale across 15 SBDH categories. The dataset is the largest publicly available SBDH dataset and is generated and annotated by an LLM (GPT-4). The utility of Synth-SBDH is showcased on three tasks using real-world clinical datasets from two distinct hospital settings, highlighting its versatility, generalizability, and distillation capabilities. Models trained on Synth-SBDH consistently outperform counterparts with no Synth-SBDH training, achieving up to 62.5% macro-F improvements. Synth-SBDH proves effective for rare SBDH categories and under-resource constraints. Human evaluation demonstrates a Human-LLM alignment of 71.06% and uncovers areas for future refinements.\nMajor Findings:\nAnalysis and Critique:\nThe study presents a novel synthetic dataset, Synth-SBDH, which addresses the limitations of existing SBDH datasets and leverages the potential of LLMs in healthcare. The dataset is comprehensive, covering a wide range of SBDH categories and providing detailed"
  },
  {
    "objectID": "posts/Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text/2024-06-10-Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text.html#appendix",
    "href": "posts/Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text/2024-06-10-Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text.html#appendix",
    "title": "Synth-SBDH: A Synthetic Dataset of Social and Behavioral Determinants of Health for Clinical Text",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06056v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06056v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20269"
  },
  {
    "objectID": "posts/M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering/2024-06-06-M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering.html",
    "href": "posts/M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering/2024-06-06-M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering.html",
    "title": "M-QALM: A Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall in Large Language Models via Question Answering",
    "section": "",
    "text": "Summary:\nThe paper introduces M-QALM, a benchmark for evaluating clinical reading comprehension and knowledge recall in large language models (LLMs) through question answering. The authors conduct a large-scale empirical study using 22 datasets in three generalist and three specialist biomedical sub-domains. They analyze the performance of 15 LLMs, focusing on factors such as instruction tuning, domain-adapted models, and fine-tuning on medical knowledge datasets. The results show that while recent domain-adapted models may lack adequate knowledge, fine-tuning on medical knowledge datasets shows encouraging results, even generalizing to unseen specialist sub-domains. The paper also includes a skill-oriented manual error analysis, revealing a significant gap between the models’ capabilities to recall necessary knowledge and integrate it with the presented context.\nMajor Findings:"
  },
  {
    "objectID": "posts/M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering/2024-06-06-M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering.html#appendix",
    "href": "posts/M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering/2024-06-06-M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering.html#appendix",
    "title": "M-QALM: A Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall in Large Language Models via Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03699v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03699v1\n\n\nTruncated\nTrue\n\n\nWord Count\n32275"
  },
  {
    "objectID": "posts/Where_Do_Large_Language_Models_Fail_When_Generating_Code/2024-06-13-Where_Do_Large_Language_Models_Fail_When_Generating_Code.html#appendix",
    "href": "posts/Where_Do_Large_Language_Models_Fail_When_Generating_Code/2024-06-13-Where_Do_Large_Language_Models_Fail_When_Generating_Code.html#appendix",
    "title": "Where Do Large Language Models Fail When Generating Code?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.08731v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.08731v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9595"
  },
  {
    "objectID": "posts/Hierarchical_Micro_Segmentations_for_Zero_Trust_Services_via_Large_Language_Model_(LLM)_enhanced_Graph_Diffusion/2024-06-20-Hierarchical_Micro_Segmentations_for_Zero_Trust_Services_via_Large_Language_Model_(LLM)_enhanced_Graph_Diffusion.html#appendix",
    "href": "posts/Hierarchical_Micro_Segmentations_for_Zero_Trust_Services_via_Large_Language_Model_(LLM)_enhanced_Graph_Diffusion/2024-06-20-Hierarchical_Micro_Segmentations_for_Zero_Trust_Services_via_Large_Language_Model_(LLM)_enhanced_Graph_Diffusion.html#appendix",
    "title": "Hierarchical Micro-Segmentations for Zero-Trust Services via Large Language Model (LLM)-enhanced Graph Diffusion",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13964v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13964v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11153"
  },
  {
    "objectID": "posts/Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering/2024-06-06-Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering.html",
    "href": "posts/Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering/2024-06-06-Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering.html",
    "title": "Tool-Planner: Dynamic Solution Tree Planning for Large Language Model with Tool Clustering",
    "section": "",
    "text": "Summary: The paper introduces Tool-Planner, a task-processing framework that groups tools based on their API functions into toolkits. This approach allows large language models (LLMs) to implement planning across various toolkits and reselect or adjust tools when a tool error occurs. The authors propose Tool-Planner to address the challenges of redundant error correction and designing a correct plan among multiple tools in tool learning. The experiments conducted demonstrate that Tool-Planner has a high pass and win rate across different datasets and optimizes the planning scheme for tool learning in models such as GPT-4 and Claude 3.\nMajor Findings: 1. Tool-Planner achieves state-of-the-art performance on five out of six datasets and shows competitive performance on the remaining dataset. 2. The method improves the pass rate by +8.8% and the win rate by +9.1% compared to the"
  },
  {
    "objectID": "posts/Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering/2024-06-06-Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering.html#appendix",
    "href": "posts/Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering/2024-06-06-Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering.html#appendix",
    "title": "Tool-Planner: Dynamic Solution Tree Planning for Large Language Model with Tool Clustering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03807v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03807v1\n\n\nTruncated\nTrue\n\n\nWord Count\n29774"
  },
  {
    "objectID": "posts/Improving_LLMs_for_Recommendation_with_Out_Of_Vocabulary_Tokens/2024-06-12-Improving_LLMs_for_Recommendation_with_Out_Of_Vocabulary_Tokens.html#appendix",
    "href": "posts/Improving_LLMs_for_Recommendation_with_Out_Of_Vocabulary_Tokens/2024-06-12-Improving_LLMs_for_Recommendation_with_Out_Of_Vocabulary_Tokens.html#appendix",
    "title": "Improving LLMs for Recommendation with Out-Of-Vocabulary Tokens",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.08477v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.08477v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9535"
  },
  {
    "objectID": "posts/BeHonest_Benchmarking_Honesty_of_Large_Language_Models/2024-06-19-BeHonest_Benchmarking_Honesty_of_Large_Language_Models.html#appendix",
    "href": "posts/BeHonest_Benchmarking_Honesty_of_Large_Language_Models/2024-06-19-BeHonest_Benchmarking_Honesty_of_Large_Language_Models.html#appendix",
    "title": "BeHonest: Benchmarking Honesty of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13261v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13261v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9544"
  },
  {
    "objectID": "posts/Item_Language_Model_for_Conversational_Recommendation/2024-06-05-Item_Language_Model_for_Conversational_Recommendation.html#appendix",
    "href": "posts/Item_Language_Model_for_Conversational_Recommendation/2024-06-05-Item_Language_Model_for_Conversational_Recommendation.html#appendix",
    "title": "Item-Language Model for Conversational Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02844v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02844v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6105"
  },
  {
    "objectID": "posts/Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities/2024-06-11-Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities.html",
    "href": "posts/Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities/2024-06-11-Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities.html",
    "title": "Toxic Memes: A Survey of Computational Perspectives on the Detection and Explanation of Meme Toxicities",
    "section": "",
    "text": "Summary:\nThis paper provides a comprehensive survey of 158 papers on computational perspectives on toxic memes, covering key developments up to early 2024. The study identifies a wide variety of terminology used to refer to toxic memes, highlighting the need for a clearer taxonomy and harmonized definitions. The authors introduce a novel taxonomy and offer insights into various dimensions of meme toxicity, including intent, target, and conveyance tactics. The paper also catalogs datasets containing toxic memes, analyzes prevalent challenges, and identifies emerging trends in computational approaches to toxic meme detection and interpretation. The survey aims to promote interdisciplinary collaboration and innovation to foster media literacy and a safer online ecosystem.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive survey of the literature on computational perspectives on toxic memes, offering valuable insights into the current state of the field. The introduction of a novel taxonomy and harmonized definitions is a significant contribution, as it addresses the need for a clearer taxonomy and harmonized definitions. The paper also identifies emerging trends in computational approaches to toxic meme detection and interpretation, which can guide future research in the field.\nHowever, the paper does not provide a critical analysis of the limitations and biases of the existing literature. Additionally, the paper does not discuss the potential ethical implications of using computational approaches to detect and interpret toxic memes. Future research should address these limitations and consider the ethical implications of using computational approaches to detect and interpret toxic"
  },
  {
    "objectID": "posts/Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities/2024-06-11-Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities.html#appendix",
    "href": "posts/Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities/2024-06-11-Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities.html#appendix",
    "title": "Toxic Memes: A Survey of Computational Perspectives on the Detection and Explanation of Meme Toxicities",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07353v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07353v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20322"
  },
  {
    "objectID": "posts/Towards_Next_Era_of_Multi_objective_Optimization_Large_Language_Models_as_Architects_of_Evolutionary_Operators/2024-06-13-Towards_Next_Era_of_Multi_objective_Optimization_Large_Language_Models_as_Architects_of_Evolutionary_Operators.html#appendix",
    "href": "posts/Towards_Next_Era_of_Multi_objective_Optimization_Large_Language_Models_as_Architects_of_Evolutionary_Operators/2024-06-13-Towards_Next_Era_of_Multi_objective_Optimization_Large_Language_Models_as_Architects_of_Evolutionary_Operators.html#appendix",
    "title": "Towards Next Era of Multi-objective Optimization: Large Language Models as Architects of Evolutionary Operators",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.08987v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.08987v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8531"
  },
  {
    "objectID": "posts/CodeNav_Beyond_tool_use_to_using_real_world_codebases_with_LLM_agents/2024-06-18-CodeNav_Beyond_tool_use_to_using_real_world_codebases_with_LLM_agents.html#appendix",
    "href": "posts/CodeNav_Beyond_tool_use_to_using_real_world_codebases_with_LLM_agents/2024-06-18-CodeNav_Beyond_tool_use_to_using_real_world_codebases_with_LLM_agents.html#appendix",
    "title": "CodeNav: Beyond tool-use to using real-world codebases with LLM agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12276v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12276v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10119"
  },
  {
    "objectID": "posts/Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110/2024-06-10-Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110.html",
    "href": "posts/Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110/2024-06-10-Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110.html",
    "title": "Harnessing AI for efficient analysis of complex policy documents: a case study of Executive Order 14110",
    "section": "",
    "text": "Summary:\nThis study investigates the accuracy and reliability of large language model (LLM)-based AI systems in extracting information from complex policy documents, such as Executive Order 14110. The research focuses on question answering and tasks involving content extraction, comparing the performance of four commercial AI systems (Claude 3 Opus, ChatGPT-4, Gemini Pro 1.5, and Command R+) to manual analysis conducted by human experts. The results show that Gemini and Claude demonstrated the most comprehensive understanding of the EO, consistently providing concise, accurate, and detailed responses. However, achieving acceptable levels of reproducibility and trustworthiness remains a critical challenge that necessitates further research and development.\nMajor Findings:\nAnalysis and Critique:\nThe study provides valuable insights into the potential of AI in policy analysis, but there are several limitations to consider:\nFurther research could involve testing other AI models, including open-source alternatives, mixture-of-"
  },
  {
    "objectID": "posts/Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110/2024-06-10-Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110.html#appendix",
    "href": "posts/Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110/2024-06-10-Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110.html#appendix",
    "title": "Harnessing AI for efficient analysis of complex policy documents: a case study of Executive Order 14110",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06657v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06657v1\n\n\nTruncated\nFalse\n\n\nWord Count\n25409"
  },
  {
    "objectID": "posts/LLaSA_Large_Multimodal_Agent_for_Human_Activity_Analysis_Through_Wearable_Sensors/2024-06-20-LLaSA_Large_Multimodal_Agent_for_Human_Activity_Analysis_Through_Wearable_Sensors.html#appendix",
    "href": "posts/LLaSA_Large_Multimodal_Agent_for_Human_Activity_Analysis_Through_Wearable_Sensors/2024-06-20-LLaSA_Large_Multimodal_Agent_for_Human_Activity_Analysis_Through_Wearable_Sensors.html#appendix",
    "title": "LLaSA: Large Multimodal Agent for Human Activity Analysis Through Wearable Sensors",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14498v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14498v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3974"
  },
  {
    "objectID": "posts/Leveraging_Large_Language_Models_for_Patient_Engagement_The_Power_of_Conversational_AI_in_Digital_Health/2024-06-19-Leveraging_Large_Language_Models_for_Patient_Engagement_The_Power_of_Conversational_AI_in_Digital_Health.html#appendix",
    "href": "posts/Leveraging_Large_Language_Models_for_Patient_Engagement_The_Power_of_Conversational_AI_in_Digital_Health/2024-06-19-Leveraging_Large_Language_Models_for_Patient_Engagement_The_Power_of_Conversational_AI_in_Digital_Health.html#appendix",
    "title": "Leveraging Large Language Models for Patient Engagement: The Power of Conversational AI in Digital Health",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13659v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13659v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7506"
  },
  {
    "objectID": "posts/What_Do_Language_Models_Learn_in_Context_The_Structured_Task_Hypothesis/2024-06-06-What_Do_Language_Models_Learn_in_Context_The_Structured_Task_Hypothesis.html#appendix",
    "href": "posts/What_Do_Language_Models_Learn_in_Context_The_Structured_Task_Hypothesis/2024-06-06-What_Do_Language_Models_Learn_in_Context_The_Structured_Task_Hypothesis.html#appendix",
    "title": "What Do Language Models Learn in Context? The Structured Task Hypothesis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04216v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04216v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15"
  },
  {
    "objectID": "posts/Joint_Demonstration_and_Preference_Learning_Improves_Policy_Alignment_with_Human_Feedback/2024-06-11-Joint_Demonstration_and_Preference_Learning_Improves_Policy_Alignment_with_Human_Feedback.html#appendix",
    "href": "posts/Joint_Demonstration_and_Preference_Learning_Improves_Policy_Alignment_with_Human_Feedback/2024-06-11-Joint_Demonstration_and_Preference_Learning_Improves_Policy_Alignment_with_Human_Feedback.html#appendix",
    "title": "Joint Demonstration and Preference Learning Improves Policy Alignment with Human Feedback",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06874v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06874v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10718"
  },
  {
    "objectID": "posts/Hopping_Too_Late_Exploring_the_Limitations_of_Large_Language_Models_on_Multi_Hop_Queries/2024-06-18-Hopping_Too_Late_Exploring_the_Limitations_of_Large_Language_Models_on_Multi_Hop_Queries.html#appendix",
    "href": "posts/Hopping_Too_Late_Exploring_the_Limitations_of_Large_Language_Models_on_Multi_Hop_Queries/2024-06-18-Hopping_Too_Late_Exploring_the_Limitations_of_Large_Language_Models_on_Multi_Hop_Queries.html#appendix",
    "title": "Hopping Too Late: Exploring the Limitations of Large Language Models on Multi-Hop Queries",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12775v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12775v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8033"
  },
  {
    "objectID": "posts/CityBench_Evaluating_the_Capabilities_of_Large_Language_Model_as_World_Model/2024-06-20-CityBench_Evaluating_the_Capabilities_of_Large_Language_Model_as_World_Model.html#appendix",
    "href": "posts/CityBench_Evaluating_the_Capabilities_of_Large_Language_Model_as_World_Model/2024-06-20-CityBench_Evaluating_the_Capabilities_of_Large_Language_Model_as_World_Model.html#appendix",
    "title": "CityBench: Evaluating the Capabilities of Large Language Model as World Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13945v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13945v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5783"
  },
  {
    "objectID": "posts/Exploring_Mathematical_Extrapolation_of_Large_Language_Models_with_Synthetic_Data/2024-06-04-Exploring_Mathematical_Extrapolation_of_Large_Language_Models_with_Synthetic_Data.html#appendix",
    "href": "posts/Exploring_Mathematical_Extrapolation_of_Large_Language_Models_with_Synthetic_Data/2024-06-04-Exploring_Mathematical_Extrapolation_of_Large_Language_Models_with_Synthetic_Data.html#appendix",
    "title": "Exploring Mathematical Extrapolation of Large Language Models with Synthetic Data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02100v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02100v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3993"
  },
  {
    "objectID": "posts/Towards_Detecting_LLMs_Hallucination_via_Markov_Chain_based_Multi_agent_Debate_Framework/2024-06-05-Towards_Detecting_LLMs_Hallucination_via_Markov_Chain_based_Multi_agent_Debate_Framework.html#appendix",
    "href": "posts/Towards_Detecting_LLMs_Hallucination_via_Markov_Chain_based_Multi_agent_Debate_Framework/2024-06-05-Towards_Detecting_LLMs_Hallucination_via_Markov_Chain_based_Multi_agent_Debate_Framework.html#appendix",
    "title": "Towards Detecting LLMs Hallucination via Markov Chain-based Multi-agent Debate Framework",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03075v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03075v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5918"
  },
  {
    "objectID": "posts/VideoLLaMA_2_Advancing_Spatial_Temporal_Modeling_and_Audio_Understanding_in_Video_LLMs/2024-06-11-VideoLLaMA_2_Advancing_Spatial_Temporal_Modeling_and_Audio_Understanding_in_Video_LLMs.html#appendix",
    "href": "posts/VideoLLaMA_2_Advancing_Spatial_Temporal_Modeling_and_Audio_Understanding_in_Video_LLMs/2024-06-11-VideoLLaMA_2_Advancing_Spatial_Temporal_Modeling_and_Audio_Understanding_in_Video_LLMs.html#appendix",
    "title": "VideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understanding in Video-LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07476v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07476v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5170"
  },
  {
    "objectID": "posts/A_Probabilistic_Framework_for_LLM_Hallucination_Detection_via_Belief_Tree_Propagation/2024-06-11-A_Probabilistic_Framework_for_LLM_Hallucination_Detection_via_Belief_Tree_Propagation.html#appendix",
    "href": "posts/A_Probabilistic_Framework_for_LLM_Hallucination_Detection_via_Belief_Tree_Propagation/2024-06-11-A_Probabilistic_Framework_for_LLM_Hallucination_Detection_via_Belief_Tree_Propagation.html#appendix",
    "title": "A Probabilistic Framework for LLM Hallucination Detection via Belief Tree Propagation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06950v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06950v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10310"
  },
  {
    "objectID": "posts/Adversarial_Attacks_on_Large_Language_Models_in_Medicine/2024-06-18-Adversarial_Attacks_on_Large_Language_Models_in_Medicine.html#appendix",
    "href": "posts/Adversarial_Attacks_on_Large_Language_Models_in_Medicine/2024-06-18-Adversarial_Attacks_on_Large_Language_Models_in_Medicine.html#appendix",
    "title": "Adversarial Attacks on Large Language Models in Medicine",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12259v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12259v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9477"
  },
  {
    "objectID": "posts/Asynchronous_Large_Language_Model_Enhanced_Planner_for_Autonomous_Driving/2024-06-20-Asynchronous_Large_Language_Model_Enhanced_Planner_for_Autonomous_Driving.html#appendix",
    "href": "posts/Asynchronous_Large_Language_Model_Enhanced_Planner_for_Autonomous_Driving/2024-06-20-Asynchronous_Large_Language_Model_Enhanced_Planner_for_Autonomous_Driving.html#appendix",
    "title": "Asynchronous Large Language Model Enhanced Planner for Autonomous Driving",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14556v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14556v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9407"
  },
  {
    "objectID": "posts/CherryRec_Enhancing_News_Recommendation_Quality_via_LLM_driven_Framework/2024-06-18-CherryRec_Enhancing_News_Recommendation_Quality_via_LLM_driven_Framework.html#appendix",
    "href": "posts/CherryRec_Enhancing_News_Recommendation_Quality_via_LLM_driven_Framework/2024-06-18-CherryRec_Enhancing_News_Recommendation_Quality_via_LLM_driven_Framework.html#appendix",
    "title": "CherryRec: Enhancing News Recommendation Quality via LLM-driven Framework",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12243v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12243v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4153"
  },
  {
    "objectID": "posts/Finding_Blind_Spots_in_Evaluator_LLMs_with_Interpretable_Checklists/2024-06-19-Finding_Blind_Spots_in_Evaluator_LLMs_with_Interpretable_Checklists.html#appendix",
    "href": "posts/Finding_Blind_Spots_in_Evaluator_LLMs_with_Interpretable_Checklists/2024-06-19-Finding_Blind_Spots_in_Evaluator_LLMs_with_Interpretable_Checklists.html#appendix",
    "title": "Finding Blind Spots in Evaluator LLMs with Interpretable Checklists",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13439v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13439v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7140"
  },
  {
    "objectID": "posts/A_Survey_of_Backdoor_Attacks_and_Defenses_on_Large_Language_Models_Implications_for_Security_Measures/2024-06-10-A_Survey_of_Backdoor_Attacks_and_Defenses_on_Large_Language_Models_Implications_for_Security_Measures.html#appendix",
    "href": "posts/A_Survey_of_Backdoor_Attacks_and_Defenses_on_Large_Language_Models_Implications_for_Security_Measures/2024-06-10-A_Survey_of_Backdoor_Attacks_and_Defenses_on_Large_Language_Models_Implications_for_Security_Measures.html#appendix",
    "title": "A Survey of Backdoor Attacks and Defenses on Large Language Models: Implications for Security Measures",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06852v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06852v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9560"
  },
  {
    "objectID": "posts/Generating_Query_Recommendations_via_LLMs/2024-05-30-Generating_Query_Recommendations_via_LLMs.html#appendix",
    "href": "posts/Generating_Query_Recommendations_via_LLMs/2024-05-30-Generating_Query_Recommendations_via_LLMs.html#appendix",
    "title": "Generating Query Recommendations via LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.19749v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.19749v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1852"
  },
  {
    "objectID": "posts/Finding_Safety_Neurons_in_Large_Language_Models/2024-06-20-Finding_Safety_Neurons_in_Large_Language_Models.html#appendix",
    "href": "posts/Finding_Safety_Neurons_in_Large_Language_Models/2024-06-20-Finding_Safety_Neurons_in_Large_Language_Models.html#appendix",
    "title": "Finding Safety Neurons in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14144v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14144v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10356"
  },
  {
    "objectID": "posts/Knowledge_Graph_Tuning_Real_time_Large_Language_Model_Personalization_based_on_Human_Feedback/2024-05-30-Knowledge_Graph_Tuning_Real_time_Large_Language_Model_Personalization_based_on_Human_Feedback.html#appendix",
    "href": "posts/Knowledge_Graph_Tuning_Real_time_Large_Language_Model_Personalization_based_on_Human_Feedback/2024-05-30-Knowledge_Graph_Tuning_Real_time_Large_Language_Model_Personalization_based_on_Human_Feedback.html#appendix",
    "title": "Knowledge Graph Tuning: Real-time Large Language Model Personalization based on Human Feedback",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.19686v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.19686v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6292"
  },
  {
    "objectID": "posts/Translating_Across_Cultures_LLMs_for_Intralingual_Cultural_Adaptation/2024-06-20-Translating_Across_Cultures_LLMs_for_Intralingual_Cultural_Adaptation.html#appendix",
    "href": "posts/Translating_Across_Cultures_LLMs_for_Intralingual_Cultural_Adaptation/2024-06-20-Translating_Across_Cultures_LLMs_for_Intralingual_Cultural_Adaptation.html#appendix",
    "title": "Translating Across Cultures: LLMs for Intralingual Cultural Adaptation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14504v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14504v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7296"
  },
  {
    "objectID": "posts/Through_the_Theory_of_Minds_Eye_Reading_Minds_with_Multimodal_Video_Large_Language_Models/2024-06-19-Through_the_Theory_of_Minds_Eye_Reading_Minds_with_Multimodal_Video_Large_Language_Models.html#appendix",
    "href": "posts/Through_the_Theory_of_Minds_Eye_Reading_Minds_with_Multimodal_Video_Large_Language_Models/2024-06-19-Through_the_Theory_of_Minds_Eye_Reading_Minds_with_Multimodal_Video_Large_Language_Models.html#appendix",
    "title": "Through the Theory of Mind’s Eye: Reading Minds with Multimodal Video Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13763v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13763v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4909"
  },
  {
    "objectID": "posts/XRec_Large_Language_Models_for_Explainable_Recommendation/2024-06-04-XRec_Large_Language_Models_for_Explainable_Recommendation.html#appendix",
    "href": "posts/XRec_Large_Language_Models_for_Explainable_Recommendation/2024-06-04-XRec_Large_Language_Models_for_Explainable_Recommendation.html#appendix",
    "title": "XRec: Large Language Models for Explainable Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02377v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02377v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6297"
  },
  {
    "objectID": "posts/VELO_A_Vector_Database_Assisted_Cloud_Edge_Collaborative_LLM_QoS_Optimization_Framework/2024-06-19-VELO_A_Vector_Database_Assisted_Cloud_Edge_Collaborative_LLM_QoS_Optimization_Framework.html#appendix",
    "href": "posts/VELO_A_Vector_Database_Assisted_Cloud_Edge_Collaborative_LLM_QoS_Optimization_Framework/2024-06-19-VELO_A_Vector_Database_Assisted_Cloud_Edge_Collaborative_LLM_QoS_Optimization_Framework.html#appendix",
    "title": "VELO: A Vector Database-Assisted Cloud-Edge Collaborative LLM QoS Optimization Framework",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13399v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13399v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7725"
  },
  {
    "objectID": "posts/SD_Eval_A_Benchmark_Dataset_for_Spoken_Dialogue_Understanding_Beyond_Words/2024-06-19-SD_Eval_A_Benchmark_Dataset_for_Spoken_Dialogue_Understanding_Beyond_Words.html#appendix",
    "href": "posts/SD_Eval_A_Benchmark_Dataset_for_Spoken_Dialogue_Understanding_Beyond_Words/2024-06-19-SD_Eval_A_Benchmark_Dataset_for_Spoken_Dialogue_Understanding_Beyond_Words.html#appendix",
    "title": "SD-Eval: A Benchmark Dataset for Spoken Dialogue Understanding Beyond Words",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13340v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13340v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5962"
  },
  {
    "objectID": "posts/Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models/2024-06-17-Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models.html",
    "href": "posts/Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models/2024-06-17-Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models.html",
    "title": "Long Code Arena: a Set of Benchmarks for Long-Context Code Models",
    "section": "",
    "text": "Summary:\nThe paper introduces Long Code Arena, a suite of six benchmarks for code processing tasks that require project-wide context. These tasks include library-based code generation, CI builds repair, project-level code completion, commit message generation, bug localization, and module summarization. The paper highlights the limitations of existing ML4SE benchmarks, such as short context length and limited resemblance to practical use cases. Long Code Arena aims to address these issues by providing manually verified datasets, evaluation suites, and open-source baseline solutions based on popular LLMs. The benchmark page, leaderboard, and links to datasets are available on HuggingFace Spaces.\nMajor Findings:"
  },
  {
    "objectID": "posts/Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models/2024-06-17-Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models.html#appendix",
    "href": "posts/Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models/2024-06-17-Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models.html#appendix",
    "title": "Long Code Arena: a Set of Benchmarks for Long-Context Code Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11612v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11612v1\n\n\nTruncated\nTrue\n\n\nWord Count\n31007"
  },
  {
    "objectID": "posts/PRePair_Pointwise_Reasoning_Enhance_Pairwise_Evaluating_for_Robust_Instruction_Following_Assessments/2024-06-18-PRePair_Pointwise_Reasoning_Enhance_Pairwise_Evaluating_for_Robust_Instruction_Following_Assessments.html#appendix",
    "href": "posts/PRePair_Pointwise_Reasoning_Enhance_Pairwise_Evaluating_for_Robust_Instruction_Following_Assessments/2024-06-18-PRePair_Pointwise_Reasoning_Enhance_Pairwise_Evaluating_for_Robust_Instruction_Following_Assessments.html#appendix",
    "title": "PRePair: Pointwise Reasoning Enhance Pairwise Evaluating for Robust Instruction-Following Assessments",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12319v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12319v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2144"
  },
  {
    "objectID": "posts/Knowledge_Graph_Enhanced_Large_Language_Models_via_Path_Selection/2024-06-19-Knowledge_Graph_Enhanced_Large_Language_Models_via_Path_Selection.html#appendix",
    "href": "posts/Knowledge_Graph_Enhanced_Large_Language_Models_via_Path_Selection/2024-06-19-Knowledge_Graph_Enhanced_Large_Language_Models_via_Path_Selection.html#appendix",
    "title": "Knowledge Graph-Enhanced Large Language Models via Path Selection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13862v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13862v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6798"
  },
  {
    "objectID": "posts/Annotation_alignment_Comparing_LLM_and_human_annotations_of_conversational_safety/2024-06-10-Annotation_alignment_Comparing_LLM_and_human_annotations_of_conversational_safety.html#appendix",
    "href": "posts/Annotation_alignment_Comparing_LLM_and_human_annotations_of_conversational_safety/2024-06-10-Annotation_alignment_Comparing_LLM_and_human_annotations_of_conversational_safety.html#appendix",
    "title": "Annotation alignment: Comparing LLM and human annotations of conversational safety",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06369v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06369v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7965"
  },
  {
    "objectID": "posts/VersiCode_Towards_Version_controllable_Code_Generation/2024-06-11-VersiCode_Towards_Version_controllable_Code_Generation.html#appendix",
    "href": "posts/VersiCode_Towards_Version_controllable_Code_Generation/2024-06-11-VersiCode_Towards_Version_controllable_Code_Generation.html#appendix",
    "title": "VersiCode: Towards Version-controllable Code Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07411v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07411v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6957"
  },
  {
    "objectID": "posts/Towards_Truthful_Multilingual_Large_Language_Models_Benchmarking_and_Alignment_Strategies/2024-06-20-Towards_Truthful_Multilingual_Large_Language_Models_Benchmarking_and_Alignment_Strategies.html#appendix",
    "href": "posts/Towards_Truthful_Multilingual_Large_Language_Models_Benchmarking_and_Alignment_Strategies/2024-06-20-Towards_Truthful_Multilingual_Large_Language_Models_Benchmarking_and_Alignment_Strategies.html#appendix",
    "title": "Towards Truthful Multilingual Large Language Models: Benchmarking and Alignment Strategies",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14434v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14434v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6080"
  },
  {
    "objectID": "posts/PFID_Privacy_First_Inference_Delegation_Framework_for_LLMs/2024-06-18-PFID_Privacy_First_Inference_Delegation_Framework_for_LLMs.html#appendix",
    "href": "posts/PFID_Privacy_First_Inference_Delegation_Framework_for_LLMs/2024-06-18-PFID_Privacy_First_Inference_Delegation_Framework_for_LLMs.html#appendix",
    "title": "PFID: Privacy First Inference Delegation Framework for LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12238v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12238v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5069"
  },
  {
    "objectID": "posts/Jailbreaking_as_a_Reward_Misspecification_Problem/2024-06-20-Jailbreaking_as_a_Reward_Misspecification_Problem.html#appendix",
    "href": "posts/Jailbreaking_as_a_Reward_Misspecification_Problem/2024-06-20-Jailbreaking_as_a_Reward_Misspecification_Problem.html#appendix",
    "title": "Jailbreaking as a Reward Misspecification Problem",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14393v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14393v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7548"
  },
  {
    "objectID": "posts/Large_Language_Models_for_Automatic_Milestone_Detection_in_Group_Discussions/2024-06-16-Large_Language_Models_for_Automatic_Milestone_Detection_in_Group_Discussions.html#appendix",
    "href": "posts/Large_Language_Models_for_Automatic_Milestone_Detection_in_Group_Discussions/2024-06-16-Large_Language_Models_for_Automatic_Milestone_Detection_in_Group_Discussions.html#appendix",
    "title": "Large Language Models for Automatic Milestone Detection in Group Discussions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.10842v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.10842v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4838"
  },
  {
    "objectID": "posts/TextGrad_Automatic_Differentiation_via_Text/2024-06-11-TextGrad_Automatic_Differentiation_via_Text.html#appendix",
    "href": "posts/TextGrad_Automatic_Differentiation_via_Text/2024-06-11-TextGrad_Automatic_Differentiation_via_Text.html#appendix",
    "title": "TextGrad: Automatic Differentiation via Text",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07496v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07496v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14644"
  },
  {
    "objectID": "posts/Understanding_Different_Design_Choices_in_Training_Large_Time_Series_Models/2024-06-20-Understanding_Different_Design_Choices_in_Training_Large_Time_Series_Models.html#appendix",
    "href": "posts/Understanding_Different_Design_Choices_in_Training_Large_Time_Series_Models/2024-06-20-Understanding_Different_Design_Choices_in_Training_Large_Time_Series_Models.html#appendix",
    "title": "Understanding Different Design Choices in Training Large Time Series Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14045v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14045v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7858"
  },
  {
    "objectID": "posts/Generative_AI_for_Enhancing_Active_Learning_in_Education_A_Comparative_Study_of_GPT_3.5_and_GPT_4_in_Crafting_Customized_Test_Questions/2024-06-20-Generative_AI_for_Enhancing_Active_Learning_in_Education_A_Comparative_Study_of_GPT_3.5_and_GPT_4_in_Crafting_Customized_Test_Questions.html#appendix",
    "href": "posts/Generative_AI_for_Enhancing_Active_Learning_in_Education_A_Comparative_Study_of_GPT_3.5_and_GPT_4_in_Crafting_Customized_Test_Questions/2024-06-20-Generative_AI_for_Enhancing_Active_Learning_in_Education_A_Comparative_Study_of_GPT_3.5_and_GPT_4_in_Crafting_Customized_Test_Questions.html#appendix",
    "title": "Generative AI for Enhancing Active Learning in Education: A Comparative Study of GPT-3.5 and GPT-4 in Crafting Customized Test Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13903v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13903v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6168"
  },
  {
    "objectID": "posts/Beyond_Under_Alignment_Atomic_Preference_Enhanced_Factuality_Tuning_for_Large_Language_Models/2024-06-18-Beyond_Under_Alignment_Atomic_Preference_Enhanced_Factuality_Tuning_for_Large_Language_Models.html#appendix",
    "href": "posts/Beyond_Under_Alignment_Atomic_Preference_Enhanced_Factuality_Tuning_for_Large_Language_Models/2024-06-18-Beyond_Under_Alignment_Atomic_Preference_Enhanced_Factuality_Tuning_for_Large_Language_Models.html#appendix",
    "title": "Beyond Under-Alignment: Atomic Preference Enhanced Factuality Tuning for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12416v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12416v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6437"
  },
  {
    "objectID": "posts/Interpretable_Catastrophic_Forgetting_of_Large_Language_Model_Fine_tuning_via_Instruction_Vector/2024-06-18-Interpretable_Catastrophic_Forgetting_of_Large_Language_Model_Fine_tuning_via_Instruction_Vector.html#appendix",
    "href": "posts/Interpretable_Catastrophic_Forgetting_of_Large_Language_Model_Fine_tuning_via_Instruction_Vector/2024-06-18-Interpretable_Catastrophic_Forgetting_of_Large_Language_Model_Fine_tuning_via_Instruction_Vector.html#appendix",
    "title": "Interpretable Catastrophic Forgetting of Large Language Model Fine-tuning via Instruction Vector",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12227v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12227v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8412"
  },
  {
    "objectID": "posts/Session_Context_Embedding_for_Intent_Understanding_in_Product_Search/2024-06-03-Session_Context_Embedding_for_Intent_Understanding_in_Product_Search.html#appendix",
    "href": "posts/Session_Context_Embedding_for_Intent_Understanding_in_Product_Search/2024-06-03-Session_Context_Embedding_for_Intent_Understanding_in_Product_Search.html#appendix",
    "title": "Session Context Embedding for Intent Understanding in Product Search",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01702v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01702v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3385"
  },
  {
    "objectID": "posts/Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer/2024-06-09-Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer.html",
    "href": "posts/Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer/2024-06-09-Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer.html",
    "title": "Are Large Language Models Actually Good at Text Style Transfer?",
    "section": "",
    "text": "Summary:\nThis paper evaluates the performance of large language models (LLMs) on Text Style Transfer (TST), specifically focusing on sentiment transfer and text detoxification across three languages: English, Hindi, and Bengali. The study analyzes the capabilities of pre-trained LLMs using zero-shot and few-shot prompting as well as parameter-efficient finetuning on publicly available datasets. The evaluation is conducted using automatic metrics, GPT-4, and human evaluations, revealing that while some prompted LLMs perform well in English, their performance in other languages remains average. However, finetuning significantly improves results compared to zero-shot and few-shot prompting, making them comparable to previous state-of-the-art.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer/2024-06-09-Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer.html#appendix",
    "href": "posts/Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer/2024-06-09-Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer.html#appendix",
    "title": "Are Large Language Models Actually Good at Text Style Transfer?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05885v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05885v1\n\n\nTruncated\nFalse\n\n\nWord Count\n27021"
  },
  {
    "objectID": "posts/Advancing_Tool_Augmented_Large_Language_Models_Integrating_Insights_from_Errors_in_Inference_Trees/2024-06-11-Advancing_Tool_Augmented_Large_Language_Models_Integrating_Insights_from_Errors_in_Inference_Trees.html#appendix",
    "href": "posts/Advancing_Tool_Augmented_Large_Language_Models_Integrating_Insights_from_Errors_in_Inference_Trees/2024-06-11-Advancing_Tool_Augmented_Large_Language_Models_Integrating_Insights_from_Errors_in_Inference_Trees.html#appendix",
    "title": "Advancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07115v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07115v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6467"
  },
  {
    "objectID": "posts/THaLLE_Text_Hyperlocally_Augmented_Large_Language_Extension____Technical_Report/2024-06-11-THaLLE_Text_Hyperlocally_Augmented_Large_Language_Extension____Technical_Report.html#appendix",
    "href": "posts/THaLLE_Text_Hyperlocally_Augmented_Large_Language_Extension____Technical_Report/2024-06-11-THaLLE_Text_Hyperlocally_Augmented_Large_Language_Extension____Technical_Report.html#appendix",
    "title": "THaLLE: Text Hyperlocally Augmented Large Language Extension – Technical Report",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07505v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07505v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5344"
  },
  {
    "objectID": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#major-findings",
    "href": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#major-findings",
    "title": "Solution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe team proposes a new instruction-tuned vision-language model with two novel ideas: grounding visual cues in the text modality and utilizing an object detection algorithm to capture complex diagrammatic visual patterns.\nThe team achieves a 27.11 WOSA score on the challenge split and qualitatively validates the effectiveness of their proposed approach.\nThe team utilizes the Segmentation Anything Model (SAM) algorithm to capture the complex visual features and uses this information as input for the LLM."
  },
  {
    "objectID": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#analysis-and-critique",
    "href": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#analysis-and-critique",
    "title": "Solution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper does not provide a detailed analysis of the performance of the proposed method compared to other state-of-the-art methods.\nThe paper does not discuss the limitations of the proposed method or any potential biases that were apparent while reviewing the text.\nThe paper does not discuss any methodological issues, conflicting evidence, or areas that require further research or clarification.\nThe paper does not provide a detailed analysis of the performance of the proposed method on different types of puzzles.\nThe paper does not discuss the generalizability of the proposed method to other types of multimodal reasoning tasks."
  },
  {
    "objectID": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#appendix",
    "href": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#appendix",
    "title": "Solution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05963v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05963v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3407"
  },
  {
    "objectID": "posts/RepoQA_Evaluating_Long_Context_Code_Understanding/2024-06-10-RepoQA_Evaluating_Long_Context_Code_Understanding.html#appendix",
    "href": "posts/RepoQA_Evaluating_Long_Context_Code_Understanding/2024-06-10-RepoQA_Evaluating_Long_Context_Code_Understanding.html#appendix",
    "title": "RepoQA: Evaluating Long Context Code Understanding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06025v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06025v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2740"
  },
  {
    "objectID": "posts/Aligning_Large_Language_Models_with_Diverse_Political_Viewpoints/2024-06-20-Aligning_Large_Language_Models_with_Diverse_Political_Viewpoints.html#appendix",
    "href": "posts/Aligning_Large_Language_Models_with_Diverse_Political_Viewpoints/2024-06-20-Aligning_Large_Language_Models_with_Diverse_Political_Viewpoints.html#appendix",
    "title": "Aligning Large Language Models with Diverse Political Viewpoints",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14155v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14155v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5339"
  },
  {
    "objectID": "posts/Guiding_LLM_Temporal_Logic_Generation_with_Explicit_Separation_of_Data_and_Control/2024-06-11-Guiding_LLM_Temporal_Logic_Generation_with_Explicit_Separation_of_Data_and_Control.html#appendix",
    "href": "posts/Guiding_LLM_Temporal_Logic_Generation_with_Explicit_Separation_of_Data_and_Control/2024-06-11-Guiding_LLM_Temporal_Logic_Generation_with_Explicit_Separation_of_Data_and_Control.html#appendix",
    "title": "Guiding LLM Temporal Logic Generation with Explicit Separation of Data and Control",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07400v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07400v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4241"
  },
  {
    "objectID": "posts/Enhancing_Repository_Level_Code_Generation_with_Integrated_Contextual_Information/2024-06-05-Enhancing_Repository_Level_Code_Generation_with_Integrated_Contextual_Information.html#appendix",
    "href": "posts/Enhancing_Repository_Level_Code_Generation_with_Integrated_Contextual_Information/2024-06-05-Enhancing_Repository_Level_Code_Generation_with_Integrated_Contextual_Information.html#appendix",
    "title": "Enhancing Repository-Level Code Generation with Integrated Contextual Information",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03283v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03283v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9447"
  },
  {
    "objectID": "posts/A_Comprehensive_Evaluation_of_Parameter_Efficient_Fine_Tuning_on_Automated_Program_Repair/2024-06-09-A_Comprehensive_Evaluation_of_Parameter_Efficient_Fine_Tuning_on_Automated_Program_Repair.html#appendix",
    "href": "posts/A_Comprehensive_Evaluation_of_Parameter_Efficient_Fine_Tuning_on_Automated_Program_Repair/2024-06-09-A_Comprehensive_Evaluation_of_Parameter_Efficient_Fine_Tuning_on_Automated_Program_Repair.html#appendix",
    "title": "A Comprehensive Evaluation of Parameter-Efficient Fine-Tuning on Automated Program Repair",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05639v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05639v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12423"
  },
  {
    "objectID": "posts/Step_Back_Profiling_Distilling_User_History_for_Personalized_Scientific_Writing/2024-06-20-Step_Back_Profiling_Distilling_User_History_for_Personalized_Scientific_Writing.html#appendix",
    "href": "posts/Step_Back_Profiling_Distilling_User_History_for_Personalized_Scientific_Writing/2024-06-20-Step_Back_Profiling_Distilling_User_History_for_Personalized_Scientific_Writing.html#appendix",
    "title": "Step-Back Profiling: Distilling User History for Personalized Scientific Writing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14275v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14275v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5200"
  },
  {
    "objectID": "posts/Large_Language_Models_for_Constrained_Based_Causal_Discovery/2024-06-11-Large_Language_Models_for_Constrained_Based_Causal_Discovery.html#appendix",
    "href": "posts/Large_Language_Models_for_Constrained_Based_Causal_Discovery/2024-06-11-Large_Language_Models_for_Constrained_Based_Causal_Discovery.html#appendix",
    "title": "Large Language Models for Constrained-Based Causal Discovery",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07378v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07378v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7632"
  },
  {
    "objectID": "posts/Exploring_User_Retrieval_Integration_towards_Large_Language_Models_for_Cross_Domain_Sequential_Recommendation/2024-06-05-Exploring_User_Retrieval_Integration_towards_Large_Language_Models_for_Cross_Domain_Sequential_Recommendation.html#appendix",
    "href": "posts/Exploring_User_Retrieval_Integration_towards_Large_Language_Models_for_Cross_Domain_Sequential_Recommendation/2024-06-05-Exploring_User_Retrieval_Integration_towards_Large_Language_Models_for_Cross_Domain_Sequential_Recommendation.html#appendix",
    "title": "Exploring User Retrieval Integration towards Large Language Models for Cross-Domain Sequential Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03085v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03085v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8121"
  },
  {
    "objectID": "posts/MrRank_Improving_Question_Answering_Retrieval_System_through_Multi_Result_Ranking_Model/2024-06-09-MrRank_Improving_Question_Answering_Retrieval_System_through_Multi_Result_Ranking_Model.html#appendix",
    "href": "posts/MrRank_Improving_Question_Answering_Retrieval_System_through_Multi_Result_Ranking_Model/2024-06-09-MrRank_Improving_Question_Answering_Retrieval_System_through_Multi_Result_Ranking_Model.html#appendix",
    "title": "MrRank: Improving Question Answering Retrieval System through Multi-Result Ranking Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05733v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05733v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5268"
  },
  {
    "objectID": "posts/Language_Models_are_Alignable_Decision_Makers_Dataset_and_Application_to_the_Medical_Triage_Domain/2024-06-10-Language_Models_are_Alignable_Decision_Makers_Dataset_and_Application_to_the_Medical_Triage_Domain.html#appendix",
    "href": "posts/Language_Models_are_Alignable_Decision_Makers_Dataset_and_Application_to_the_Medical_Triage_Domain/2024-06-10-Language_Models_are_Alignable_Decision_Makers_Dataset_and_Application_to_the_Medical_Triage_Domain.html#appendix",
    "title": "Language Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06435v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06435v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9086"
  },
  {
    "objectID": "posts/GraphCoder_Enhancing_Repository_Level_Code_Completion_via_Code_Context_Graph_based_Retrieval_and_Language_Model/2024-06-11-GraphCoder_Enhancing_Repository_Level_Code_Completion_via_Code_Context_Graph_based_Retrieval_and_Language_Model.html#appendix",
    "href": "posts/GraphCoder_Enhancing_Repository_Level_Code_Completion_via_Code_Context_Graph_based_Retrieval_and_Language_Model/2024-06-11-GraphCoder_Enhancing_Repository_Level_Code_Completion_via_Code_Context_Graph_based_Retrieval_and_Language_Model.html#appendix",
    "title": "GraphCoder: Enhancing Repository-Level Code Completion via Code Context Graph-based Retrieval and Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07003v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07003v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9656"
  },
  {
    "objectID": "posts/Iterative_or_Innovative_A_Problem_Oriented_Perspective_for_Code_Optimization/2024-06-17-Iterative_or_Innovative_A_Problem_Oriented_Perspective_for_Code_Optimization.html#appendix",
    "href": "posts/Iterative_or_Innovative_A_Problem_Oriented_Perspective_for_Code_Optimization/2024-06-17-Iterative_or_Innovative_A_Problem_Oriented_Perspective_for_Code_Optimization.html#appendix",
    "title": "Iterative or Innovative? A Problem-Oriented Perspective for Code Optimization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11935v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11935v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10246"
  },
  {
    "objectID": "posts/Validating_LLM_Generated_Programs_with_Metamorphic_Prompt_Testing/2024-06-11-Validating_LLM_Generated_Programs_with_Metamorphic_Prompt_Testing.html#appendix",
    "href": "posts/Validating_LLM_Generated_Programs_with_Metamorphic_Prompt_Testing/2024-06-11-Validating_LLM_Generated_Programs_with_Metamorphic_Prompt_Testing.html#appendix",
    "title": "Validating LLM-Generated Programs with Metamorphic Prompt Testing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06864v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06864v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6738"
  },
  {
    "objectID": "posts/Towards_a_Personal_Health_Large_Language_Model/2024-06-10-Towards_a_Personal_Health_Large_Language_Model.html",
    "href": "posts/Towards_a_Personal_Health_Large_Language_Model/2024-06-10-Towards_a_Personal_Health_Large_Language_Model.html",
    "title": "Towards a Personal Health Large Language Model",
    "section": "",
    "text": "Summary:\nThe paper introduces Personal Health Large Language Model (PH-LLM), a version of Gemini fine-tuned for personal health and wellness. PH-LLM is evaluated on three aspects of personal health: generating personalized insights and recommendations for user goals in the domains of sleep and fitness, assessing levels of expert domain knowledge, and predicting patient-reported outcomes in sleep quality from detailed sensor information. The model is benchmarked against expert human responses and evaluated through comprehensive human and automatic evaluation of domain-specific rubrics. The results show that both Gemini Ultra 1.0 and PH-LLM are not statistically different from expert performance in fitness, while experts remain superior for sleep. However, fine-tuning PH-LLM provided significant improvements in using relevant domain knowledge and personalizing information for sleep insights. PH-LLM achieved 79% on sleep (N=629 questions) and 88% on fitness (N=99 questions) in multiple choice question examinations, both of which exceed average scores from a sample of human experts. The model also demonstrated the ability to predict self-reported assessments of sleep quality by training it to predict self-reported sleep disruption and sleep impairment outcomes from textual and multimodal encoding representations of wearable sensor data.\nMajor Findings:"
  },
  {
    "objectID": "posts/Towards_a_Personal_Health_Large_Language_Model/2024-06-10-Towards_a_Personal_Health_Large_Language_Model.html#appendix",
    "href": "posts/Towards_a_Personal_Health_Large_Language_Model/2024-06-10-Towards_a_Personal_Health_Large_Language_Model.html#appendix",
    "title": "Towards a Personal Health Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06474v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06474v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17580"
  },
  {
    "objectID": "posts/MBBQ_A_Dataset_for_Cross_Lingual_Comparison_of_Stereotypes_in_Generative_LLMs/2024-06-11-MBBQ_A_Dataset_for_Cross_Lingual_Comparison_of_Stereotypes_in_Generative_LLMs.html#appendix",
    "href": "posts/MBBQ_A_Dataset_for_Cross_Lingual_Comparison_of_Stereotypes_in_Generative_LLMs/2024-06-11-MBBQ_A_Dataset_for_Cross_Lingual_Comparison_of_Stereotypes_in_Generative_LLMs.html#appendix",
    "title": "MBBQ: A Dataset for Cross-Lingual Comparison of Stereotypes in Generative LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07243v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07243v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10630"
  },
  {
    "objectID": "posts/On_the_Robustness_of_Language_Models_for_Tabular_Question_Answering/2024-06-18-On_the_Robustness_of_Language_Models_for_Tabular_Question_Answering.html#appendix",
    "href": "posts/On_the_Robustness_of_Language_Models_for_Tabular_Question_Answering/2024-06-18-On_the_Robustness_of_Language_Models_for_Tabular_Question_Answering.html#appendix",
    "title": "On the Robustness of Language Models for Tabular Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12719v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12719v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3509"
  },
  {
    "objectID": "posts/Privacy_in_LLM_based_Recommendation_Recent_Advances_and_Future_Directions/2024-06-03-Privacy_in_LLM_based_Recommendation_Recent_Advances_and_Future_Directions.html#appendix",
    "href": "posts/Privacy_in_LLM_based_Recommendation_Recent_Advances_and_Future_Directions/2024-06-03-Privacy_in_LLM_based_Recommendation_Recent_Advances_and_Future_Directions.html#appendix",
    "title": "Privacy in LLM-based Recommendation: Recent Advances and Future Directions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01363v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01363v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3447"
  },
  {
    "objectID": "posts/Augmenting_Query_and_Passage_for_Retrieval_Augmented_Generation_using_LLMs_for_Open_Domain_Question_Answering/2024-06-20-Augmenting_Query_and_Passage_for_Retrieval_Augmented_Generation_using_LLMs_for_Open_Domain_Question_Answering.html#appendix",
    "href": "posts/Augmenting_Query_and_Passage_for_Retrieval_Augmented_Generation_using_LLMs_for_Open_Domain_Question_Answering/2024-06-20-Augmenting_Query_and_Passage_for_Retrieval_Augmented_Generation_using_LLMs_for_Open_Domain_Question_Answering.html#appendix",
    "title": "Augmenting Query and Passage for Retrieval-Augmented Generation using LLMs for Open-Domain Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14277v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14277v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6421"
  },
  {
    "objectID": "posts/AutoCAP_Towards_Automatic_Cross_lingual_Alignment_Planning_for_Zero_shot_Chain_of_Thought/2024-06-20-AutoCAP_Towards_Automatic_Cross_lingual_Alignment_Planning_for_Zero_shot_Chain_of_Thought.html#appendix",
    "href": "posts/AutoCAP_Towards_Automatic_Cross_lingual_Alignment_Planning_for_Zero_shot_Chain_of_Thought/2024-06-20-AutoCAP_Towards_Automatic_Cross_lingual_Alignment_Planning_for_Zero_shot_Chain_of_Thought.html#appendix",
    "title": "AutoCAP: Towards Automatic Cross-lingual Alignment Planning for Zero-shot Chain-of-Thought",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13940v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13940v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4960"
  },
  {
    "objectID": "posts/Enhancing_Collaborative_Semantics_of_Language_Model_Driven_Recommendations_via_Graph_Aware_Learning/2024-06-19-Enhancing_Collaborative_Semantics_of_Language_Model_Driven_Recommendations_via_Graph_Aware_Learning.html#appendix",
    "href": "posts/Enhancing_Collaborative_Semantics_of_Language_Model_Driven_Recommendations_via_Graph_Aware_Learning/2024-06-19-Enhancing_Collaborative_Semantics_of_Language_Model_Driven_Recommendations_via_Graph_Aware_Learning.html#appendix",
    "title": "Enhancing Collaborative Semantics of Language Model-Driven Recommendations via Graph-Aware Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13235v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13235v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7497"
  },
  {
    "objectID": "posts/Ask_LLMs_Directly_What_shapes_your_bias_Measuring_Social_Bias_in_Large_Language_Models/2024-06-06-Ask_LLMs_Directly_What_shapes_your_bias_Measuring_Social_Bias_in_Large_Language_Models.html#appendix",
    "href": "posts/Ask_LLMs_Directly_What_shapes_your_bias_Measuring_Social_Bias_in_Large_Language_Models/2024-06-06-Ask_LLMs_Directly_What_shapes_your_bias_Measuring_Social_Bias_in_Large_Language_Models.html#appendix",
    "title": "Ask LLMs Directly, What shapes your bias?: Measuring Social Bias in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04064v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04064v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5188"
  },
  {
    "objectID": "posts/Persuasiveness_of_Generated_Free_Text_Rationales_in_Subjective_Decisions_A_Case_Study_on_Pairwise_Argument_Ranking/2024-06-20-Persuasiveness_of_Generated_Free_Text_Rationales_in_Subjective_Decisions_A_Case_Study_on_Pairwise_Argument_Ranking.html#appendix",
    "href": "posts/Persuasiveness_of_Generated_Free_Text_Rationales_in_Subjective_Decisions_A_Case_Study_on_Pairwise_Argument_Ranking/2024-06-20-Persuasiveness_of_Generated_Free_Text_Rationales_in_Subjective_Decisions_A_Case_Study_on_Pairwise_Argument_Ranking.html#appendix",
    "title": "Persuasiveness of Generated Free-Text Rationales in Subjective Decisions: A Case Study on Pairwise Argument Ranking",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13905v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13905v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6514"
  },
  {
    "objectID": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#major-findings",
    "href": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#major-findings",
    "title": "McEval: Massively Multilingual Code Evaluation",
    "section": "Major Findings",
    "text": "Major Findings\n\nMcEval is the first massively multilingual code evaluation benchmark, covering 40 programming languages with 16K test samples.\nThe benchmark includes challenging code completion, understanding, and generation evaluation tasks with finely curated multilingual instruction corpora McEval-Instruct.\nThe authors introduce an effective multilingual coder mCoder trained on McEval-Instruct to support multilingual programming language generation."
  },
  {
    "objectID": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#analysis-and-critique",
    "href": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#analysis-and-critique",
    "title": "McEval: Massively Multilingual Code Evaluation",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\n\nThe paper does not provide a detailed comparison of McEval with existing benchmarks, making it difficult to assess its advantages and limitations.\nThe paper does not discuss the potential biases in the data used for training mCoder, which could impact its performance on certain tasks or languages.\nThe paper does not provide a detailed analysis of the performance of mCoder on different tasks and languages, making it difficult to assess its strengths and weaknesses.\nThe paper does not discuss the potential applications of McEval and mCoder in real-world software development scenarios.\nThe paper does not discuss the potential ethical implications of using mCoder for code generation, such as the risk of generating code that violates software licenses or copyright laws."
  },
  {
    "objectID": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#appendix",
    "href": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#appendix",
    "title": "McEval: Massively Multilingual Code Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07436v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07436v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7788"
  },
  {
    "objectID": "posts/Efficiently_Exploring_Large_Language_Models_for_Document_Level_Machine_Translation_with_In_context_Learning/2024-06-11-Efficiently_Exploring_Large_Language_Models_for_Document_Level_Machine_Translation_with_In_context_Learning.html#appendix",
    "href": "posts/Efficiently_Exploring_Large_Language_Models_for_Document_Level_Machine_Translation_with_In_context_Learning/2024-06-11-Efficiently_Exploring_Large_Language_Models_for_Document_Level_Machine_Translation_with_In_context_Learning.html#appendix",
    "title": "Efficiently Exploring Large Language Models for Document-Level Machine Translation with In-context Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07081v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07081v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6243"
  },
  {
    "objectID": "posts/Exploring_Changes_in_Nation_Perception_with_Nationality_Assigned_Personas_in_LLMs/2024-06-20-Exploring_Changes_in_Nation_Perception_with_Nationality_Assigned_Personas_in_LLMs.html#appendix",
    "href": "posts/Exploring_Changes_in_Nation_Perception_with_Nationality_Assigned_Personas_in_LLMs/2024-06-20-Exploring_Changes_in_Nation_Perception_with_Nationality_Assigned_Personas_in_LLMs.html#appendix",
    "title": "Exploring Changes in Nation Perception with Nationality-Assigned Personas in LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13993v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13993v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4062"
  },
  {
    "objectID": "posts/Should_AI_Optimize_Your_Code_A_Comparative_Study_of_Current_Large_Language_Models_Versus_Classical_Optimizing_Compilers/2024-06-17-Should_AI_Optimize_Your_Code_A_Comparative_Study_of_Current_Large_Language_Models_Versus_Classical_Optimizing_Compilers.html#appendix",
    "href": "posts/Should_AI_Optimize_Your_Code_A_Comparative_Study_of_Current_Large_Language_Models_Versus_Classical_Optimizing_Compilers/2024-06-17-Should_AI_Optimize_Your_Code_A_Comparative_Study_of_Current_Large_Language_Models_Versus_Classical_Optimizing_Compilers.html#appendix",
    "title": "Should AI Optimize Your Code? A Comparative Study of Current Large Language Models Versus Classical Optimizing Compilers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12146v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12146v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7663"
  },
  {
    "objectID": "posts/From_Descriptive_Richness_to_Bias_Unveiling_the_Dark_Side_of_Generative_Image_Caption_Enrichment/2024-06-20-From_Descriptive_Richness_to_Bias_Unveiling_the_Dark_Side_of_Generative_Image_Caption_Enrichment.html#appendix",
    "href": "posts/From_Descriptive_Richness_to_Bias_Unveiling_the_Dark_Side_of_Generative_Image_Caption_Enrichment/2024-06-20-From_Descriptive_Richness_to_Bias_Unveiling_the_Dark_Side_of_Generative_Image_Caption_Enrichment.html#appendix",
    "title": "From Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13912v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13912v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3715"
  },
  {
    "objectID": "posts/Large_Language_Models_as_Recommender_Systems_A_Study_of_Popularity_Bias/2024-06-03-Large_Language_Models_as_Recommender_Systems_A_Study_of_Popularity_Bias.html#appendix",
    "href": "posts/Large_Language_Models_as_Recommender_Systems_A_Study_of_Popularity_Bias/2024-06-03-Large_Language_Models_as_Recommender_Systems_A_Study_of_Popularity_Bias.html#appendix",
    "title": "Large Language Models as Recommender Systems: A Study of Popularity Bias",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01285v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01285v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9391"
  },
  {
    "objectID": "posts/Text_like_Encoding_of_Collaborative_Information_in_Large_Language_Models_for_Recommendation/2024-06-05-Text_like_Encoding_of_Collaborative_Information_in_Large_Language_Models_for_Recommendation.html#appendix",
    "href": "posts/Text_like_Encoding_of_Collaborative_Information_in_Large_Language_Models_for_Recommendation/2024-06-05-Text_like_Encoding_of_Collaborative_Information_in_Large_Language_Models_for_Recommendation.html#appendix",
    "title": "Text-like Encoding of Collaborative Information in Large Language Models for Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03210v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03210v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6859"
  },
  {
    "objectID": "posts/Large_Language_Models_as_Evaluators_for_Recommendation_Explanations/2024-06-06-Large_Language_Models_as_Evaluators_for_Recommendation_Explanations.html#appendix",
    "href": "posts/Large_Language_Models_as_Evaluators_for_Recommendation_Explanations/2024-06-06-Large_Language_Models_as_Evaluators_for_Recommendation_Explanations.html#appendix",
    "title": "Large Language Models as Evaluators for Recommendation Explanations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03248v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03248v2\n\n\nTruncated\nFalse\n\n\nWord Count\n7752"
  },
  {
    "objectID": "posts/DR_RAG_Applying_Dynamic_Document_Relevance_to_Retrieval_Augmented_Generation_for_Question_Answering/2024-06-11-DR_RAG_Applying_Dynamic_Document_Relevance_to_Retrieval_Augmented_Generation_for_Question_Answering.html#appendix",
    "href": "posts/DR_RAG_Applying_Dynamic_Document_Relevance_to_Retrieval_Augmented_Generation_for_Question_Answering/2024-06-11-DR_RAG_Applying_Dynamic_Document_Relevance_to_Retrieval_Augmented_Generation_for_Question_Answering.html#appendix",
    "title": "DR-RAG: Applying Dynamic Document Relevance to Retrieval-Augmented Generation for Question-Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07348v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07348v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6121"
  },
  {
    "objectID": "posts/PDSS_A_Privacy_Preserving_Framework_for_Step_by_Step_Distillation_of_Large_Language_Models/2024-06-18-PDSS_A_Privacy_Preserving_Framework_for_Step_by_Step_Distillation_of_Large_Language_Models.html#appendix",
    "href": "posts/PDSS_A_Privacy_Preserving_Framework_for_Step_by_Step_Distillation_of_Large_Language_Models/2024-06-18-PDSS_A_Privacy_Preserving_Framework_for_Step_by_Step_Distillation_of_Large_Language_Models.html#appendix",
    "title": "PDSS: A Privacy-Preserving Framework for Step-by-Step Distillation of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12403v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12403v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6497"
  },
  {
    "objectID": "posts/On_AI_Inspired_UI_Design/2024-06-19-On_AI_Inspired_UI_Design.html#appendix",
    "href": "posts/On_AI_Inspired_UI_Design/2024-06-19-On_AI_Inspired_UI_Design.html#appendix",
    "title": "On AI-Inspired UI-Design",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13631v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13631v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1712"
  },
  {
    "objectID": "posts/Every_Language_Counts_Learn_and_Unlearn_in_Multilingual_LLMs/2024-06-19-Every_Language_Counts_Learn_and_Unlearn_in_Multilingual_LLMs.html#appendix",
    "href": "posts/Every_Language_Counts_Learn_and_Unlearn_in_Multilingual_LLMs/2024-06-19-Every_Language_Counts_Learn_and_Unlearn_in_Multilingual_LLMs.html#appendix",
    "title": "Every Language Counts: Learn and Unlearn in Multilingual LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13748v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13748v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5047"
  },
  {
    "objectID": "posts/Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs/2024-06-18-Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs.html",
    "href": "posts/Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs/2024-06-18-Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs.html",
    "title": "Can We Trust Large Language Models Generated Code? A Framework for In-Context Learning, Security Patterns, and Code Evaluations Across Diverse LLMs",
    "section": "",
    "text": "Summary:\nThis research aims to tackle the security and quality concerns of code generated by Large Language Models (LLMs) like ChatGPT and GitHub Copilot. These models are increasingly utilized for software development but are primarily trained on publicly available code repositories and internet-based textual data, which may contain insecure code. This presents a significant risk of perpetuating vulnerabilities in the generated code. The research introduces a framework for secure behavioral learning of LLMs through In-Context Learning (ICL) patterns during the code generation process, followed by rigorous security evaluations. Four diverse LLMs are selected for experimentation, and their coding capabilities are evaluated across three programming languages. The research indicates that ICL-driven one-shot and few-shot learning patterns can enhance code security, reducing vulnerabilities in various programming scenarios. However, developers and researchers should be aware that LLMs have a limited understanding of security principles, which may lead to security breaches when the generated code is deployed in production systems. The research highlights that LLMs are a potential source of new vulnerabilities to the software supply chain and emphasizes the importance of considering this when using LLMs for code generation.\nMajor Findings:\nAnalysis and Critique:\nThe research provides"
  },
  {
    "objectID": "posts/Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs/2024-06-18-Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs.html#appendix",
    "href": "posts/Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs/2024-06-18-Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs.html#appendix",
    "title": "Can We Trust Large Language Models Generated Code? A Framework for In-Context Learning, Security Patterns, and Code Evaluations Across Diverse LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12513v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12513v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18028"
  },
  {
    "objectID": "posts/BIPED_Pedagogically_Informed_Tutoring_System_for_ESL_Education/2024-06-05-BIPED_Pedagogically_Informed_Tutoring_System_for_ESL_Education.html#appendix",
    "href": "posts/BIPED_Pedagogically_Informed_Tutoring_System_for_ESL_Education/2024-06-05-BIPED_Pedagogically_Informed_Tutoring_System_for_ESL_Education.html#appendix",
    "title": "BIPED: Pedagogically Informed Tutoring System for ESL Education",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03486v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03486v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7759"
  },
  {
    "objectID": "posts/SNAP_Unlearning_Selective_Knowledge_in_Large_Language_Models_with_Negative_Instructions/2024-06-18-SNAP_Unlearning_Selective_Knowledge_in_Large_Language_Models_with_Negative_Instructions.html#appendix",
    "href": "posts/SNAP_Unlearning_Selective_Knowledge_in_Large_Language_Models_with_Negative_Instructions/2024-06-18-SNAP_Unlearning_Selective_Knowledge_in_Large_Language_Models_with_Negative_Instructions.html#appendix",
    "title": "SNAP: Unlearning Selective Knowledge in Large Language Models with Negative Instructions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12329v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12329v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7278"
  },
  {
    "objectID": "posts/PITCH_Productivity_and_Mental_Well_being_Coaching_through_Daily_Conversational_Interaction/2024-06-11-PITCH_Productivity_and_Mental_Well_being_Coaching_through_Daily_Conversational_Interaction.html#appendix",
    "href": "posts/PITCH_Productivity_and_Mental_Well_being_Coaching_through_Daily_Conversational_Interaction/2024-06-11-PITCH_Productivity_and_Mental_Well_being_Coaching_through_Daily_Conversational_Interaction.html#appendix",
    "title": "PITCH: Productivity and Mental Well-being Coaching through Daily Conversational Interaction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07485v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07485v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3364"
  },
  {
    "objectID": "posts/Coherent_Zero_Shot_Visual_Instruction_Generation/2024-06-06-Coherent_Zero_Shot_Visual_Instruction_Generation.html#appendix",
    "href": "posts/Coherent_Zero_Shot_Visual_Instruction_Generation/2024-06-06-Coherent_Zero_Shot_Visual_Instruction_Generation.html#appendix",
    "title": "Coherent Zero-Shot Visual Instruction Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04337v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04337v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5054"
  },
  {
    "objectID": "posts/PostMark_A_Robust_Blackbox_Watermark_for_Large_Language_Models/2024-06-20-PostMark_A_Robust_Blackbox_Watermark_for_Large_Language_Models.html#appendix",
    "href": "posts/PostMark_A_Robust_Blackbox_Watermark_for_Large_Language_Models/2024-06-20-PostMark_A_Robust_Blackbox_Watermark_for_Large_Language_Models.html#appendix",
    "title": "PostMark: A Robust Blackbox Watermark for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14517v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14517v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10409"
  },
  {
    "objectID": "posts/OPTune_Efficient_Online_Preference_Tuning/2024-06-11-OPTune_Efficient_Online_Preference_Tuning.html#appendix",
    "href": "posts/OPTune_Efficient_Online_Preference_Tuning/2024-06-11-OPTune_Efficient_Online_Preference_Tuning.html#appendix",
    "title": "OPTune: Efficient Online Preference Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07657v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07657v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7692"
  },
  {
    "objectID": "posts/Generating_Educational_Materials_with_Different_Levels_of_Readability_using_LLMs/2024-06-18-Generating_Educational_Materials_with_Different_Levels_of_Readability_using_LLMs.html#appendix",
    "href": "posts/Generating_Educational_Materials_with_Different_Levels_of_Readability_using_LLMs/2024-06-18-Generating_Educational_Materials_with_Different_Levels_of_Readability_using_LLMs.html#appendix",
    "title": "Generating Educational Materials with Different Levels of Readability using LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12787v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12787v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5307"
  },
  {
    "objectID": "posts/Identifying_Performance_Sensitive_Configurations_in_Software_Systems_through_Code_Analysis_with_LLM_Agents/2024-06-18-Identifying_Performance_Sensitive_Configurations_in_Software_Systems_through_Code_Analysis_with_LLM_Agents.html#appendix",
    "href": "posts/Identifying_Performance_Sensitive_Configurations_in_Software_Systems_through_Code_Analysis_with_LLM_Agents/2024-06-18-Identifying_Performance_Sensitive_Configurations_in_Software_Systems_through_Code_Analysis_with_LLM_Agents.html#appendix",
    "title": "Identifying Performance-Sensitive Configurations in Software Systems through Code Analysis with LLM Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12806v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12806v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9569"
  },
  {
    "objectID": "posts/How_to_Understand_Whole_Software_Repository/2024-06-03-How_to_Understand_Whole_Software_Repository.html#appendix",
    "href": "posts/How_to_Understand_Whole_Software_Repository/2024-06-03-How_to_Understand_Whole_Software_Repository.html#appendix",
    "title": "How to Understand Whole Software Repository?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01422v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01422v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10556"
  },
  {
    "objectID": "posts/3D_Building_Generation_in_Minecraft_via_Large_Language_Models/2024-06-13-3D_Building_Generation_in_Minecraft_via_Large_Language_Models.html#appendix",
    "href": "posts/3D_Building_Generation_in_Minecraft_via_Large_Language_Models/2024-06-13-3D_Building_Generation_in_Minecraft_via_Large_Language_Models.html#appendix",
    "title": "3D Building Generation in Minecraft via Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.08751v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.08751v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4481"
  },
  {
    "objectID": "posts/Towards_Human_AI_Collaboration_in_Healthcare_Guided_Deferral_Systems_with_Large_Language_Models/2024-06-11-Towards_Human_AI_Collaboration_in_Healthcare_Guided_Deferral_Systems_with_Large_Language_Models.html#appendix",
    "href": "posts/Towards_Human_AI_Collaboration_in_Healthcare_Guided_Deferral_Systems_with_Large_Language_Models/2024-06-11-Towards_Human_AI_Collaboration_in_Healthcare_Guided_Deferral_Systems_with_Large_Language_Models.html#appendix",
    "title": "Towards Human-AI Collaboration in Healthcare: Guided Deferral Systems with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07212v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07212v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4804"
  },
  {
    "objectID": "posts/How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States/2024-06-09-How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States.html",
    "href": "posts/How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States/2024-06-09-How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States.html",
    "title": "How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States",
    "section": "",
    "text": "Summary:\nThis paper explores how alignment and jailbreak work in large language models (LLMs) by using weak classifiers to explain LLM safety through intermediate hidden states. The authors confirm that LLMs learn ethical concepts during pre-training rather than alignment and can identify malicious and normal inputs in the early layers. Alignment associates the early concepts with emotion guesses in the middle layers and then refines them to specific reject tokens for safe generations. Jailbreak disturbs the transformation of early unethical classification into negative emotions. The paper conducts experiments on models from 7B to 70B across various model families to prove their conclusion.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a novel perspective on LLM safety by explaining how alignment and jailbreak work through intermediate hidden states. The use of weak classifiers to explain LLM safety is an innovative approach that could be applied to other aspects of LLM behavior. However, the paper does not discuss the limitations of using weak classifiers or the potential biases that may be introduced. Additionally, the paper does not address the potential risks of jailbreak, such as the generation of harmful content, and how these risks can be mitigated. Overall, the paper provides valuable insights into LLM safety and offers a new perspective on how alignment and jailbreak work."
  },
  {
    "objectID": "posts/How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States/2024-06-09-How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States.html#appendix",
    "href": "posts/How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States/2024-06-09-How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States.html#appendix",
    "title": "How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05644v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05644v1\n\n\nTruncated\nFalse\n\n\nWord Count\n19114"
  },
  {
    "objectID": "posts/Buffer_of_Thoughts_Thought_Augmented_Reasoning_with_Large_Language_Models/2024-06-06-Buffer_of_Thoughts_Thought_Augmented_Reasoning_with_Large_Language_Models.html#appendix",
    "href": "posts/Buffer_of_Thoughts_Thought_Augmented_Reasoning_with_Large_Language_Models/2024-06-06-Buffer_of_Thoughts_Thought_Augmented_Reasoning_with_Large_Language_Models.html#appendix",
    "title": "Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04271v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04271v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6204"
  },
  {
    "objectID": "posts/REPOEXEC_Evaluate_Code_Generation_with_a_Repository_Level_Executable_Benchmark/2024-06-17-REPOEXEC_Evaluate_Code_Generation_with_a_Repository_Level_Executable_Benchmark.html#appendix",
    "href": "posts/REPOEXEC_Evaluate_Code_Generation_with_a_Repository_Level_Executable_Benchmark/2024-06-17-REPOEXEC_Evaluate_Code_Generation_with_a_Repository_Level_Executable_Benchmark.html#appendix",
    "title": "REPOEXEC: Evaluate Code Generation with a Repository-Level Executable Benchmark",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11927v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11927v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7146"
  },
  {
    "objectID": "posts/Zero_Shot_End_To_End_Spoken_Question_Answering_In_Medical_Domain/2024-06-09-Zero_Shot_End_To_End_Spoken_Question_Answering_In_Medical_Domain.html#appendix",
    "href": "posts/Zero_Shot_End_To_End_Spoken_Question_Answering_In_Medical_Domain/2024-06-09-Zero_Shot_End_To_End_Spoken_Question_Answering_In_Medical_Domain.html#appendix",
    "title": "Zero-Shot End-To-End Spoken Question Answering In Medical Domain",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05876v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05876v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4005"
  },
  {
    "objectID": "posts/medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs/2024-06-20-medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs.html",
    "href": "posts/medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs/2024-06-20-medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs.html",
    "title": "medIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced Clinical Diagnosis on EMRs",
    "section": "",
    "text": "Summary:\nThe paper introduces medIKAL, a framework that integrates Large Language Models (LLMs) with knowledge graphs (KGs) to enhance clinical diagnosis on Electronic Medical Records (EMRs). The framework assigns weighted importance to entities in medical records based on their type, enabling precise localization of candidate diseases within KGs. It employs a residual network-like approach, allowing initial diagnosis by the LLM to be merged into KG search results. The diagnostic process is further refined through a path-based reranking algorithm and a fill-in-the-blank style prompt template. The effectiveness of medIKAL is validated through extensive experiments on a newly introduced open-sourced Chinese EMR dataset.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs/2024-06-20-medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs.html#appendix",
    "href": "posts/medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs/2024-06-20-medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs.html#appendix",
    "title": "medIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced Clinical Diagnosis on EMRs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14326v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14326v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7194"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian beagle",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nPrism: A Framework for Decoupling and Assessing the Capabilities of VLMs\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nPrism separates vision and reasoning in VLMs, improving performance and reducing costs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSPL: A Socratic Playground for Learning Powered by Large Language Mode\n\n\n\nhci\n\n\nsocial-sciences\n\n\neducation\n\n\nprompt-engineering\n\n\n\nSPL, a GPT-4-powered ITS, improves tutoring dialogues and critical thinking skills in learners.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDye4AI: Assuring Data Boundary on Generative AI Services\n\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nTL;DR: Dye4AI system tests AI data boundaries by injecting triggers into dialogue, ensuring data security in AI model evolution.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeeing Through AI’s Lens: Enhancing Human Skepticism Towards LLM-Generated Fake News\n\n\n\nrobustness\n\n\nsocial-sciences\n\n\n\nTL;DR: ESAS metric helps identify terms to distinguish human-written vs. LLM-generated news, aiding in detecting fake news.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData-Centric AI in the Age of Large Language Models\n\n\n\nproduction\n\n\n\nData-centric viewpoint for AI research: Prioritizing data in large language models for benchmarks, attribution, knowledge transfer, and inference contextualization.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMR-BEN: A Comprehensive Meta-Reasoning Benchmark for Large Language Models\n\n\n\nhci\n\n\n\nTL;DR: Mr-Ben benchmark evaluates LLMs’ meta-reasoning skills, revealing gaps in reasoning capabilities.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM4CP: Adapting Large Language Models for Channel Prediction\n\n\n\narchitectures\n\n\nproduction\n\n\n\n[TEXT] This study examines the relationship between social media use and mental health in adolescents. Results indicate a significant correlation between excessive social…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQ*: Improving Multi-step Reasoning for LLMs with Deliberative Planning\n\n\n\nrobustness\n\n\n\nQ* framework guides LLMs’ decoding, improving multi-step reasoning without fine-tuning, reducing errors and inconsistencies.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArtificial Leviathan: Exploring Social Evolution of LLM Agents Through the Lens of Hobbesian Social Contract Theory\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs simulate social dynamics, aligning with Hobbes’s Social Contract Theory, offering potential for understanding group behavior and complex human systems.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPEER: Automatic Prompt Engineering Enhances Large Language Model Reranking\n\n\n\narchitectures\n\n\nproduction\n\n\nprompt-engineering\n\n\n\nAPEER: A novel automatic prompt engineering algorithm for relevance ranking, outperforming manual prompts and showing better transferability.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCREF: An LLM-based Conversational Software Repair Framework for Programming Tutors\n\n\n\nprogramming\n\n\neducation\n\n\n\nLLMs show potential for program repair, but data leakage is a concern. A new benchmark, TutorCode, is introduced to evaluate LLMs’ repair capabilities. Tutor guidance is…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExplicit and Implicit Large Language Model Personas Generate Opinions but Fail to Replicate Deeper Perceptions and Biases\n\n\n\nprompt-engineering\n\n\nproduction\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs with personas struggle to replicate human biases, lacking intrinsic human cognition despite reflecting speech patterns.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCausal Inference with Latent Variables: Recent Advances and Future Prospectives\n\n\n\nsocial-sciences\n\n\n\nRecent developments in causal inference with unobserved variables, challenges, and future opportunities.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMind the Privacy Unit! User-Level Differential Privacy for Language Model Fine-Tuning\n\n\n\narchitectures\n\n\n\nUser-level DP for LLMs ensures uniform privacy across users, focusing on fine-tuning for natural language generation tasks.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn Investigation of Prompt Variations for Zero-shot LLM-based Rankers\n\n\n\nprompt-engineering\n\n\n\nPrompt components and wordings significantly impact zero-shot LLM ranking effectiveness, sometimes more than ranking algorithms.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHierarchical Micro-Segmentations for Zero-Trust Services via Large Language Model (LLM)-enhanced Graph Diffusion\n\n\n\nsecurity\n\n\n\nThis paper proposes LEGD, a hierarchical micro-segmentation algorithm for efficient zero-trust service provisioning in NGNs, achieving 90% higher efficiency than baselines.…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Fire Thief Is Also the Keeper: Balancing Usability and Privacy in Prompts\n\n\n\nprompt-engineering\n\n\nrobustness\n\n\nhci\n\n\nsecurity\n\n\n\nProSan: A framework for anonymizing prompts in LLMs, maintaining usability, and adapting to resource conditions.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfrican or European Swallow? Benchmarking Large Vision-Language Models for Fine-Grained Object Classification\n\n\n\narchitectures\n\n\nproduction\n\n\n\nTL;DR: FOCI benchmark reveals CLIP models outperform LVLMs in fine-grained object classification, highlighting alignment issues.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLaSA: Large Multimodal Agent for Human Activity Analysis Through Wearable Sensors\n\n\n\neducation\n\n\n\nLLaSA: A Multimodal AI Model for Activity Understanding Using IMUs and LLMs, with Applications in Healthcare and HCI.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGlobal is Good, Local is Bad?: Understanding Brand Bias in LLMs\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs exhibit bias towards global brands, favoring them over local ones, and show country-of-origin effects.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCityBench: Evaluating the Capabilities of Large Language Model as World Model\n\n\n\neducation\n\n\n\nTL;DR: CityBench is a new evaluation benchmark for LLMs in urban domains, featuring 7 tasks across 13 cities and 13 models.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Expert Radiology Report Summarization by Prompting Large Language Models with a Layperson Summary\n\n\n\nproduction\n\n\n\nThis paper presents a novel method for radiology report summarization, improving accuracy and accessibility, especially in out-of-domain tests.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAsynchronous Large Language Model Enhanced Planner for Autonomous Driving\n\n\n\narchitectures\n\n\nproduction\n\n\n\nAsyncDriver: LLM-enhanced framework for precise, controllable autonomous driving, reducing LLM’s computational cost.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFVEL: Interactive Formal Verification Environment with Large Language Models via Theorem Proving\n\n\n\narchitectures\n\n\neducation\n\n\nprompt-engineering\n\n\n\nFVEL: LLM-powered Formal Verification in Isabelle improves verification, reducing proof errors, and solving more problems in SV-COMP.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating Implicit Bias in Large Language Models by Attacking From a Psychometric Perspective\n\n\n\nsocial-sciences\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nLLMs exhibit implicit bias, with GLM-3 outperforming GPT-3.5 and GPT-4 in defending against attacks. Deception attacks are most effective.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinding Safety Neurons in Large Language Models\n\n\n\nsecurity\n\n\n\nSafety neurons in LLMs can restore 90% safety with 5% intervention, transferable across datasets, and aid in detecting unsafe outputs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvidence of a log scaling law for political persuasion with large language models\n\n\n\nproduction\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLarger language models only slightly more persuasive than smaller ones, with task completion being key.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranslating Across Cultures: LLMs for Intralingual Cultural Adaptation\n\n\n\narchitectures\n\n\nproduction\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs can adapt translations to target cultures, outperforming specialized models in cultural sensitivity, but may perpetuate biases.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeCoKD: Aligning Large Language Models for In-Context Learning with Fewer Shots\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nSeCoKD improves LLMs’ performance with fewer demonstrations, outperforming base models and Supervised Fine-tuning, especially in zero-shot and one-shot settings.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models are Skeptics: False Negative Problem of Input-conflicting Hallucination\n\n\n\nrobustness\n\n\n\nLLMs tend to generate false negative responses, but context and query rewriting can help.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Truthful Multilingual Large Language Models: Benchmarking and Alignment Strategies\n\n\n\narchitectures\n\n\nproduction\n\n\n\nResearch proposes benchmark and method to improve truthfulness and reduce language disparity in multilingual large language models.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJailbreaking as a Reward Misspecification Problem\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nTL;DR: New system (ReMiss) detects harmful prompts in LLMs, outperforming previous methods.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLiveMind: Low-latency Large Language Models with Simultaneous Inference\n\n\n\narchitectures\n\n\neducation\n\n\nprompt-engineering\n\n\n\nNew framework reduces LLM inference latency by up to 93% with incomplete prompts, improving interactive experience and accuracy.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Different Design Choices in Training Large Time Series Models\n\n\n\nprompt-engineering\n\n\n\nLTSM-bundle outperforms existing methods in time series forecasting, using novel prompting strategies and best design choices.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerative AI for Enhancing Active Learning in Education: A Comparative Study of GPT-3.5 and GPT-4 in Crafting Customized Test Questions\n\n\n\nprompt-engineering\n\n\neducation\n\n\nhci\n\n\n\nGPT-4 excels at creating complex math questions, improving GPT-3.5’s problem-solving skills, showcasing AI’s potential in personalized education.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRaising the Bar: Investigating the Values of Large Language Models via Generative Evolving Testing\n\n\n\nrobustness\n\n\nsocial-sciences\n\n\n\nTL;DR: GETA dynamically tests LLMs’ moral baselines, addressing the issue of outdated evaluation data, and accurately assesses their values.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Spatial Representations in the Historical Lake District Texts with LLM-based Relation Extraction\n\n\n\nsocial-sciences\n\n\n\nAI model extracts spatial relations from English Lake District texts, visualizing historical narratives as a network for deeper understanding.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAligning Large Language Models with Diverse Political Viewpoints\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs aligned with diverse political views generate more accurate viewpoints than commercial models like ChatGPT.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTaxonomy-Guided Zero-Shot Recommendations with LLMs\n\n\n\nrecommender\n\n\n\nTaxonomy-guided LLM method (TaxRec) improves recommender systems with better item categorization and controlled feature generation.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConnecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data\n\n\n\nproduction\n\n\nsecurity\n\n\n\nLLMs can infer censored knowledge by piecing together scattered hints, posing a challenge for safety and control.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep-Back Profiling: Distilling User History for Personalized Scientific Writing\n\n\n\nsocial-sciences\n\n\n\nStep-back Profiling personalizes LLMs for collaborative scientific writing, outperforming baselines on LaMP benchmark.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMMBench-Video: A Long-Form Multi-Shot Benchmark for Holistic Video Understanding\n\n\n\narchitectures\n\n\nproduction\n\n\n\nMMBench-Video: New Benchmark for Video Understanding with LVLMs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel Merging and Safety Alignment: One Bad Model Spoils the Bunch\n\n\n\narchitectures\n\n\nproduction\n\n\n\nMerging LLMs can propagate misalignment; proposed method integrates alignment-related data, improving domain expertise and alignment.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models\n\n\n\narchitectures\n\n\nproduction\n\n\nprompt-engineering\n\n\n\nGraphReader outperforms GPT-4-128k on long-context tasks, using a 4k context window and a graph-based agent system.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAugmenting Query and Passage for Retrieval-Augmented Generation using LLMs for Open-Domain Question Answering\n\n\n\neducation\n\n\n\nTL;DR: Improving open-domain QA by augmenting questions and passages with LLMs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutoCAP: Towards Automatic Cross-lingual Alignment Planning for Zero-shot Chain-of-Thought\n\n\n\nprompt-engineering\n\n\n\nAutoCAP, a zero-shot chain-of-thought method, improves cross-lingual alignment by automatically selecting languages and allocating weights, outperforming manual methods.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs\n\n\n\neducation\n\n\n\nTL;DR: Fine-tuning LLMs with KG-derived data enhances planning, improving complex QA task performance.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPersuasiveness of Generated Free-Text Rationales in Subjective Decisions: A Case Study on Pairwise Argument Ranking\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\neducation\n\n\nhci\n\n\n\nLLMs generate persuasive rationales for subjective tasks, with Llama2-70B-chat outperforming GPT models. Persuasiveness improves with parameter control via prompting or…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Changes in Nation Perception with Nationality-Assigned Personas in LLMs\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs favor Western Europe, but nationality personas influence focus and favorability towards the assigned region. Biases and stereotypes emerge in LLMs with different…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold\n\n\n\narchitectures\n\n\nproduction\n\n\n\nFinetuning LLMs with model-generated data can improve math reasoning, especially with self-generated correct solutions and per-step negative responses. This approach can…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment\n\n\n\nsocial-sciences\n\n\n\nEnriched image captions increase gender bias and hallucination, cautioning against over-descriptiveness.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSynDARin: Synthesising Datasets for Automated Reasoning in Low-Resource Languages\n\n\n\narchitectures\n\n\nproduction\n\n\n\nSynDARin generates QA datasets for low-resource languages, maintaining quality and diversity, and filtering out poor translations, enabling evaluation of LLMs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSEC-QA: A Systematic Evaluation Corpus for Financial QA\n\n\n\narchitectures\n\n\n\nTL;DR: SEC-QA framework generates QA pairs for financial documents, improving complex QA accuracy.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHIGHT: Hierarchical Graph Tokenization for Graph-Language Alignment\n\n\n\nrobustness\n\n\nhci\n\n\n\nHIGHT: New method improves graph-language alignment in LLMs, reducing hallucination and enhancing performance in molecule-language tasks.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre LLMs Naturally Good at Synthetic Tabular Data Generation?\n\n\n\narchitectures\n\n\nproduction\n\n\n\nLLMs struggle with generating synthetic tables; this paper proposes a permutation-aware approach to improve their performance.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPostMark: A Robust Blackbox Watermark for Large Language Models\n\n\n\nproduction\n\n\nrobustness\n\n\nsocial-sciences\n\n\nsecurity\n\n\n\nPostMark: A post-hoc watermarking method for LLM-generated text, robust to paraphrasing and third-party implementable.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenderAlign: An Alignment Dataset for Mitigating Gender Bias in Large Language Models\n\n\n\nsocial-sciences\n\n\n\nGenderAlign dataset reduces gender bias in LLMs, offering a new approach to alignment.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInvestigating Mysteries of CoT-Augmented Distillation\n\n\n\nproduction\n\n\neducation\n\n\nprompt-engineering\n\n\n\nCoT sequences after labels improve student model performance, even when incoherent or partial. No reasoning needed at test time.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmedIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced Clinical Diagnosis on EMRs\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\n\nmedIKAL framework combines LLMs and KGs for precise, enhanced clinical diagnosis using EMRs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDoes Object Grounding Really Reduce Hallucination of Large Vision-Language Models?\n\n\n\nrobustness\n\n\n\nGrounding objectives minimally reduce object hallucination in open caption generation, despite previous claims.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpen Generative Large Language Models for Galician\n\n\n\nsocial-sciences\n\n\n\n[TEXT] This study examines the relationship between social media use and mental health in adolescents. Results indicate a significant correlation between excessive social…\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdaptable Logical Control for Large Language Models\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nCtrl-G outperforms GPT3.5 and GPT4 in interactive text editing, ensuring LLM outputs follow logical constraints.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearning to Generate Answers with Citations via Factual Consistency Models\n\n\n\nrobustness\n\n\n\nThis paper proposes a method using factual consistency models to improve citation accuracy in LLMs, reducing hallucinations and enhancing reliability.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNicer Than Humans: How do Large Language Models Behave in the Prisoner’s Dilemma?\n\n\n\nrobustness\n\n\nhci\n\n\nsecurity\n\n\n\nLLM Llama2 shows cooperative behavior in Prisoner’s Dilemma, adopting a cautious approach and favoring forgiveness over retaliation.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan LLMs Reason in the Wild with Programs?\n\n\n\nprogramming\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLMs struggle with ambiguous, mixed-scope reasoning; fine-tuning with diverse data helps.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling\n\n\n\nhci\n\n\n\nLangTopo framework aligns LLMs with GNNs for graph structure modeling, improving LLMs’ graph data handling.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Contamination Can Cross Language Barriers\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nNew method detects deep contamination in large language models, evading current methods.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJogging the Memory of Unlearned Model Through Targeted Relearning Attack\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nExisting unlearning methods in LLMs can be reversed by targeted relearning attacks, using small, loosely related data sets.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistributional reasoning in LLMs: Parallel reasoning processes in multi-hop reasoning\n\n\n\nprompt-engineering\n\n\nhci\n\n\n\nLLMs perform multi-hop reasoning via interpretable embeddings, revealing parallel reasoning paths and potential intermediate answers.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOptimizing Psychological Counseling with Instruction-Tuned Large Language Models\n\n\n\neducation\n\n\nhci\n\n\n\nInstruction-tuned LLMs excel in psychological counseling, offering empathetic, relevant, and supportive responses, outperforming baseline models.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAgentDojo: A Dynamic Environment to Evaluate Attacks and Defenses for LLM Agents\n\n\n\nsecurity\n\n\n\nAI agents are vulnerable to prompt injection attacks; AgentDojo is a framework to evaluate and improve their adversarial robustness.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInvestigating Low-Cost LLM Annotation for~Spoken Dialogue Understanding Datasets\n\n\n\neducation\n\n\n\nImproving Spoken Dialogue Datasets with Fine-tuned Language Models.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeHonest: Benchmarking Honesty of Large Language Models\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nTL;DR: BeHonest benchmark assesses honesty in LLMs, highlighting room for improvement.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGUI Action Narrator: Where and When Did That Action Take Place?\n\n\n\nprompt-engineering\n\n\n\nGUI automation is improved with multimodal LLMs, aided by a new video captioning benchmark and framework, GUI Narrator, which uses cursor as visual prompt.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeveraging Large Language Models for Patient Engagement: The Power of Conversational AI in Digital Health\n\n\n\neducation\n\n\nhci\n\n\n\nLLMs in healthcare improve patient engagement via conversational AI, but raise ethical and regulatory considerations.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMagicItem: Dynamic Behavior Design of Virtual Objects with Large Language Models in a Consumer Metaverse Platform\n\n\n\nprogramming\n\n\neducation\n\n\n\nTool enables non-programmers to create dynamic behaviors for VR objects in metaverse platforms.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinding Blind Spots in Evaluator LLMs with Interpretable Checklists\n\n\n\nrobustness\n\n\neducation\n\n\n\nLLMs often struggle to accurately evaluate text generation in other LLMs, with shortcomings in detecting factual accuracy, coherence, and reasoning proficiency.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObscurePrompt: Jailbreaking Large Language Models via Obscure Input\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nObscurePrompt: New method for jailbreaking LLMs, improving attack effectiveness and defense robustness.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThrough the Theory of Mind’s Eye: Reading Minds with Multimodal Video Large Language Models\n\n\n\neducation\n\n\nhci\n\n\n\nLLMs can reason about human emotions and intentions in videos, revealing their ToM reasoning process.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVELO: A Vector Database-Assisted Cloud-Edge Collaborative LLM QoS Optimization Framework\n\n\n\nprogramming\n\n\nhci\n\n\n\nVELO framework uses edge-based vector database caching to optimize LLM QoS, reducing response time and costs without altering LLM structure.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation\n\n\n\neducation\n\n\n\nBalDistill improves LLM knowledge distillation for long-tailed data, enhancing distilled model efficiency and efficacy.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSD-Eval: A Benchmark Dataset for Spoken Dialogue Understanding Beyond Words\n\n\n\nhci\n\n\n\nTL;DR: SD-Eval benchmark assesses spoken dialogue understanding & generation, focusing on paralinguistic & environmental info, with models conditioned on this data…\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemantic Structure-Mapping in LLM and Human Analogical Reasoning\n\n\n\neducation\n\n\nhci\n\n\n\nLLMs approach human-level performance in semantic structure-mapping tasks but aren’t entirely human-like.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKnowledge Graph-Enhanced Large Language Models via Path Selection\n\n\n\nrobustness\n\n\n\nKELP framework improves LLM factual accuracy by flexible KG knowledge extraction.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStackRAG Agent: Improving Developer Answers with Retrieval-Augmented Generation\n\n\n\nprogramming\n\n\nrobustness\n\n\n\nStackRAG: A tool combining Stack Overflow and LLMs for accurate, reliable coding answers.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models\n\n\n\neducation\n\n\n\nAutoIF is a new method for automatically generating instruction-following training data for LLMs, improving performance across three training algorithms.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Efficacy of Conversational Artificial Intelligence in Rectifying the Theory of Mind and Autonomy Biases: Comparative Analysis\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nNon-therapeutic chatbots outperform therapeutic ones in rectifying cognitive biases and recognizing affect.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLIT: Large Language Model Driven Intention Tracking for Proactive Human-Robot Collaboration – A Robot Sous-Chef Application\n\n\n\nprompt-engineering\n\n\n\nLIT predicts human intentions for proactive robot collaboration, reducing excessive prompting in long-horizon tasks.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Collaborative Semantics of Language Model-Driven Recommendations via Graph-Aware Learning\n\n\n\nrecommender\n\n\n\nGAL-Rec improves LLM-driven recommendations by enhancing collaborative semantics understanding in interaction graphs.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKnowledge Tagging System on Math Questions via LLMs with Flexible Demonstration Retriever\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLMs automate knowledge tagging for questions, outperforming prior methods in math tasks and improving efficiency with a reinforcement learning-based demonstration retriever.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn AI-Inspired UI-Design\n\n\n\nhci\n\n\n\nAI can inspire and assist app design by generating, searching, and creating UI images using LLM, VLM, and DM models.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvery Language Counts: Learn and Unlearn in Multilingual LLMs\n\n\n\nrobustness\n\n\n\nMultilingual LLMs can spread fake info; standard unlearning methods are inadequate. Comprehensive unlearning strategies needed.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProse-to-P4: Leveraging High Level Languages\n\n\n\nprogramming\n\n\n\nLLMs can translate natural language to high-level networking code, making software development easier.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBreaking the Ceiling of the LLM Community by Treating Token Generation as a Classification for Ensembling\n\n\n\nrobustness\n\n\n\nGaC: Ensembling LLMs by treating token generation as classification improves performance and reduces latency.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing LLMs to Aid Annotation and Collection of Clinically-Enriched Data in Bipolar Disorder and Schizophrenia\n\n\n\neducation\n\n\n\nSmall language models excel in mental health research, outperforming large models in annotation, data collection, and scalability.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-enhanced Reranking in Recommender Systems\n\n\n\nrecommender\n\n\n\nLLM-enhanced reranking framework improves accuracy, diversity, and fairness in recommendations, outperforming existing models.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBenchmarks and Metrics for Evaluations of Code Generation: A Critical Review\n\n\n\nprogramming\n\n\n\nThis paper reviews methods for testing and evaluating LLMs in code generation, focusing on benchmarks and metrics.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM4MSR: An LLM-Enhanced Paradigm for Multi-Scenario Recommendation\n\n\n\nrecommender\n\n\n\nLLM4MSR: Efficient, Effective, Interpretable Multi-Scenario Recommendation Paradigm using LLM.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefending Against Social Engineering Attacks in the Age of LLMs\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nLLMs aid digital deception, but struggle with detection. ConvoSentinel, a modular defense pipeline, improves CSE detection and adaptability.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCleanGen: Mitigating Backdoor Attacks for Generation Tasks in Large Language Models\n\n\n\nprogramming\n\n\nrobustness\n\n\nsecurity\n\n\n\nCleanGen: A defense strategy for LLMs that mitigates backdoor attacks, reducing attack success rates with minimal computational overhead.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey on Human Preference Learning for Large Language Models\n\n\n\nrecommender\n\n\n\nThis survey explores human preference learning for large language models, covering feedback sources, modeling, usage, and evaluation.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMAGIC: Generating Self-Correction Guideline for In-Context Text-to-SQL\n\n\n\nrobustness\n\n\n\nMAGIC automates self-correction guideline creation in text-to-SQL, outperforming human-crafted guidelines and improving interpretability.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodeNav: Beyond tool-use to using real-world codebases with LLM agents\n\n\n\nprogramming\n\n\n\nCodeNav: LLM agent navigates unseen code repositories, solving queries without manual tool registration, and outperforms tool-use agents in benchmarks.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJailbreak Paradox: The Achilles’ Heel of LLMs\n\n\n\nsecurity\n\n\n\nJailbreaking foundation models: Perfect detection is impossible, and weaker models can’t consistently detect jailbreaks in stronger models.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHopping Too Late: Exploring the Limitations of Large Language Models on Multi-Hop Queries\n\n\n\nrobustness\n\n\n\nLLMs solve multi-hop queries in later layers, but sometimes lack needed knowledge; back-patching analysis can improve accuracy.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn-Policy Fine-grained Knowledge Feedback for Hallucination Mitigation\n\n\n\nrobustness\n\n\n\nRLFH is an online reinforcement learning method for hallucination mitigation in LLMs, using fine-grained feedback and an LLM-based fact assessment framework.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdversarial Attacks on Large Language Models in Medicine\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nLLMs in healthcare are vulnerable to adversarial attacks, requiring robust security measures for safe deployment.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCherryRec: Enhancing News Recommendation Quality via LLM-driven Framework\n\n\n\nrecommender\n\n\nprogramming\n\n\n\nCherryRec: A LLM-based news recommendation framework for efficient, high-quality recommendations.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPRePair: Pointwise Reasoning Enhance Pairwise Evaluating for Robust Instruction-Following Assessments\n\n\n\nsecurity\n\n\n\nLLMs’ biases impact pairwise evaluations more; hybrid method integrating pointwise reasoning improves robustness.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Did I Do Wrong? Quantifying LLMs’ Sensitivity and Consistency to Prompt Engineering\n\n\n\nprogramming\n\n\n\nLLMs face debugging challenges; new metrics sensitivity and consistency introduced for classification tasks to improve LLM performance and robustness.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPFID: Privacy First Inference Delegation Framework for LLMs\n\n\n\nrobustness\n\n\n\nPFID framework for LLMs enhances privacy by localizing user data, using model sharding, and singular value decomposition, while maintaining system performance.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNavigating the Labyrinth: Evaluating and Enhancing LLMs’ Ability to Reason About Search Problems\n\n\n\nprogramming\n\n\n\nLLMs struggle with logic problems; in-context learning with A* algorithm and Multi-Stage-Multi-Try method improves performance.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond Under-Alignment: Atomic Preference Enhanced Factuality Tuning for Large Language Models\n\n\n\nrobustness\n\n\n\nLLMs struggle with factuality in OOD datasets; APEFT framework improves factuality by 3.45% on average.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretable Catastrophic Forgetting of Large Language Model Fine-tuning via Instruction Vector\n\n\n\nprogramming\n\n\n\nFine-tuning LLMs may not erase previous skills, but add specialized reasoning; IV-guided training mitigates catastrophic forgetting.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?\n\n\n\neducation\n\n\n\nLLMs, like GPT-4, show inconsistency despite high capability; harder data boosts consistency.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn the Robustness of Language Models for Tabular Question Answering\n\n\n\neducation\n\n\n\nLLMs, like Llama3, excel in table comprehension, but improvements are needed for robustness and handling domain-specific data.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUBENCH: Benchmarking Uncertainty in Large Language Models with Multiple Choice Questions\n\n\n\neducation\n\n\n\nUBench is a new benchmark for evaluating LLM reliability, offering improved performance and resource efficiency. It finds GLM4 and GPT-4 as the most reliable LLMs.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTalk With Human-like Agents: Empathetic Dialogue Through Perceptible Acoustic Reception and Reaction\n\n\n\nrobustness\n\n\n\nPerceptiveAgent: LLM-based dialogue system discerns deeper meanings using speech modality, improving contextual understanding and empathetic responses.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards a Client-Centered Assessment of LLM Therapists by Client Simulation\n\n\n\nsecurity\n\n\n\nThis work proposes ClientCAST, an approach using LLMs to simulate clients and assess LLM therapists, focusing on session outcome, therapeutic alliance, and self-reported…\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPDSS: A Privacy-Preserving Framework for Step-by-Step Distillation of Large Language Models\n\n\n\nsecurity\n\n\n\nPDSS: Privacy-preserving framework distills LLMs for domain-specific tasks, ensuring data privacy and improved performance in text generation tasks.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan We Trust Large Language Models Generated Code? A Framework for In-Context Learning, Security Patterns, and Code Evaluations Across Diverse LLMs\n\n\n\nprogramming\n\n\nrobustness\n\n\nsecurity\n\n\n\nLLMs for code generation may perpetuate vulnerabilities; ICL-driven learning can enhance code security, reducing risks in various programming scenarios.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSNAP: Unlearning Selective Knowledge in Large Language Models with Negative Instructions\n\n\n\nprogramming\n\n\nrobustness\n\n\n\nSnap framework selectively unlearns information from LLMs, preserving performance and unlearning specified data.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerating Educational Materials with Different Levels of Readability using LLMs\n\n\n\nrobustness\n\n\n\nTL;DR: Few-shot prompting improves AI’s ability to simplify educational texts, but quality concerns remain.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentifying Performance-Sensitive Configurations in Software Systems through Code Analysis with LLM Agents\n\n\n\nrobustness\n\n\neducation\n\n\n\nPerfSense, an LLM-based framework, accurately identifies performance-sensitive configurations, outperforming previous methods and offering insights for future research.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-Layer Ranking with Large Language Models for News Source Recommendation\n\n\n\nrecommender\n\n\n\nLLMs improve expert recommendation for news events, using a multi-layer ranking framework on the NewsQuote dataset.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen Box Meets Graph Neural Network in Tag-aware Recommendation\n\n\n\nrecommender\n\n\n\nTL;DR: BoxGNN improves tag-aware recommender systems by modeling user preferences with high-order signals and box embeddings.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoSQA+: Enhancing Code Search Dataset with Matching Code\n\n\n\nprogramming\n\n\n\nCoSQA+ improves code search with diverse, high-quality query-code pairs, outperforming CoSQA and introducing a new metric, MMRR.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDocCGen: Document-based Controlled Code Generation\n\n\n\nprogramming\n\n\n\nDocCGen improves LLMs for structured DSLs like YAML, JSON by leveraging documentation for better code generation.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging\n\n\n\nprogramming\n\n\n\nTreeInstruct, a state-space planning-based agent, effectively guides students in debugging code using Socratic questioning.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWaDec: Decompile WebAssembly Using Large Language Model\n\n\n\nprogramming\n\n\n\nWaDec, a fine-tuned LLM, decompiles Wasm binary code into readable source code, outperforming current tools with improved metrics and code comprehension.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnveiling Assumptions: Exploring the Decisions of AI Chatbots and Human Testers\n\n\n\nprogramming\n\n\n\nLLM-based chatbots can aid software testers in decision-making, with some aligning with human intuition in preferring diverse test scenarios.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLong Code Arena: a Set of Benchmarks for Long-Context Code Models\n\n\n\nprogramming\n\n\n\nLong Code Arena: Benchmarks for Project-wide Code Processing Tasks\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Critical Study of What Code-LLMs (Do Not) Learn\n\n\n\nprogramming\n\n\n\nCode-LLMs struggle to encode relations between syntax and identifiers, with larger models encoding less code info than smaller ones.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Collaborative Data Analytics System with Recommender for Diverse Users\n\n\n\nrecommender\n\n\n\nSLEGO system bridges developer-novice gap with modular microservices, GUI, and LLM-powered recommendations, democratizing data analytics.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf and Cross-Model Distillation for LLMs: Effective Methods for Refusal Pattern Alignment\n\n\n\nprogramming\n\n\n\nLLMs can be secured against toxic prompts via alignment techniques like SFT and RLHF. Distillation methods, especially cross-model, significantly improve refusal rates and…\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIterative or Innovative? A Problem-Oriented Perspective for Code Optimization\n\n\n\nprogramming\n\n\n\nThis paper explores code optimization with LLMs, focusing on execution time reduction. It introduces a problem-oriented approach, significantly improving optimization…\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShould AI Optimize Your Code? A Comparative Study of Current Large Language Models Versus Classical Optimizing Compilers\n\n\n\nprogramming\n\n\n\nLLMs, like CodeLlama-70B, show potential in code optimization, but may generate incorrect code on large sizes, requiring automated verification. CETUS is the top optimizing…\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDELRec: Distilling Sequential Pattern to Enhance LLM-based Recommendation\n\n\n\nrecommender\n\n\n\nDELRec framework improves sequential recommendations by extracting patterns from SR models and integrating them into LLMs, enhancing their performance.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRePrompt: Planning by Automatic Prompt Engineering for Large Language Models Agents\n\n\n\nprogramming\n\n\n\nRePrompt optimizes LLM prompts for better performance in tasks like code generation and travel planning.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nREPOEXEC: Evaluate Code Generation with a Repository-Level Executable Benchmark\n\n\n\nprogramming\n\n\n\nRepoExec benchmark evaluates code generation at repository-level, focusing on executability, correctness, and dependency integration.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models for Automatic Milestone Detection in Group Discussions\n\n\n\nprogramming\n\n\n\nAuthors submit electronic manuscripts for IJCAI–24 Proceedings, which will be printed and included in the online version.\n\n\n\nJun 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhere Do Large Language Models Fail When Generating Code?\n\n\n\nprogramming\n\n\n\nLLMs struggle with reliable code generation, exhibiting varied semantic and syntactic errors. Different factors impact these errors, posing challenges for future LLM code…\n\n\n\nJun 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Next Era of Multi-objective Optimization: Large Language Models as Architects of Evolutionary Operators\n\n\n\nprogramming\n\n\n\nTL;DR: LLM-based framework evolves EA operators for MOPs, reducing expert intervention and improving performance.\n\n\n\nJun 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-Agent Software Development through Cross-Team Collaboration\n\n\n\nprogramming\n\n\n\nCross-Team Collaboration (CTC) improves LLM-driven software development quality by exploring multiple decision paths.\n\n\n\nJun 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3D Building Generation in Minecraft via Large Language Models\n\n\n\nprogramming\n\n\n\nLLMs can generate complete 3D buildings in Minecraft, including facades, indoor scenes, and functional blocks, with user-specified requirements.\n\n\n\nJun 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving LLMs for Recommendation with Out-Of-Vocabulary Tokens\n\n\n\nrecommender\n\n\n\nTL;DR: Improving LLM-based recommender systems with out-of-vocabulary tokens for better user-item representation.\n\n\n\nJun 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeaching Language Models to Self-Improve by Learning from Language Feedback\n\n\n\nsocial-sciences\n\n\n\nSRT uses model feedback for alignment, reducing reliance on human annotations, and significantly improves model performance across tasks and sizes.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCAAP: Context-Aware Action Planning Prompting to Solve Computer Tasks with Front-End UI Only\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nLLM-based agent uses screenshots for context, achieving 94.4% success on MiniWoB++ problems with 1.48 demos per type, enabling broader automation applications.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnomaly Detection on Unstable Logs with GPT Models\n\n\n\narchitectures\n\n\nproduction\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\nLLM (GPT-3) outperforms supervised baselines for anomaly detection on unstable logs, with fine-tuning superior to prompt engineering.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpen-LLM-Leaderboard: From Multi-choice to Open-style Questions for LLMs Evaluation, Benchmark, and Arena\n\n\n\narchitectures\n\n\nproduction\n\n\nprompt-engineering\n\n\nhci\n\n\n\nLLMs may favor certain answer IDs due to biases. Open-style questions can eliminate this, but pose new challenges. We introduce the Open-LLM-Leaderboard to track LLM…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDCA-Bench: A Benchmark for Dataset Curation Agents\n\n\n\narchitectures\n\n\n\nLLMs can help curate datasets, but real-world issues are complex. DCA-Bench measures LLM agents’ ability to detect dataset quality issues.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Large Language Models for Relevance Judgments in Tetun\n\n\n\narchitectures\n\n\n\nLLMs can automate relevance assessments in low-resource languages, with results similar to high-resource languages.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards more realistic evaluation of LLM-based code generation: an experimental study and beyond\n\n\n\nrobustness\n\n\nprogramming\n\n\n\n[TEXT] This study examines the impact of social media on the mental health of adolescents. Results indicate a significant correlation between excessive social media use and…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOllabench: Evaluating LLMs’ Reasoning for Human-centric Interdependent Cybersecurity\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nOllaBench evaluates LLMs for cybersecurity, revealing commercial models lead in accuracy but have room for improvement, while smaller open-weight models show promise.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeveraging Large Language Models for Efficient Failure Analysis in Game Development\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nThis paper presents a method using Large Language Models to automatically identify code changes causing test failures, achieving 71% accuracy and reducing debugging time by…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3D-Properties: Identifying Challenges in DPO and Charting a Path Forward\n\n\n\narchitectures\n\n\nsocial-sciences\n\n\neducation\n\n\n\nDPO in LLMs: Examining 3D-properties, issues, and solutions for better alignment with human preference.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Tool for Test Case Scenarios Generation Using Large Language Models\n\n\n\nhci\n\n\nprompt-engineering\n\n\neducation\n\n\nprogramming\n\n\n\nTL;DR: Tool generates test case scenarios from user requirements using an LLM-based agent.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFaceGPT: Self-supervised Learning to Chat about 3D Human Faces\n\n\n\neducation\n\n\n\nFaceGPT: Self-supervised 3D face reconstruction from images and text, without 3D annotations.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHalluDial: A Large-Scale Benchmark for Automatic Dialogue-Level Hallucination Evaluation\n\n\n\nrobustness\n\n\n\nHalluDial: A Comprehensive Benchmark for Automatic Dialogue-Level Hallucination Evaluation in LLMs.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDARA: Decomposition-Alignment-Reasoning Autonomous Language Agent for Question Answering over Knowledge Graphs\n\n\n\nhci\n\n\nprompt-engineering\n\n\n\nDARA framework improves LLM-powered agents’ KGQA performance, outperforming in-context learning-based agents and alternative fine-tuned agents.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nToxic Memes: A Survey of Computational Perspectives on the Detection and Explanation of Meme Toxicities\n\n\n\narchitectures\n\n\nhci\n\n\nsocial-sciences\n\n\n\nSurvey on toxic memes: new taxonomy, trends, and challenges in computational analysis.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMerging Improves Self-Critique Against Jailbreak Attacks\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nMerging and self-critique improve LLM robustness against jailbreak attacks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJoint Demonstration and Preference Learning Improves Policy Alignment with Human Feedback\n\n\n\nsocial-sciences\n\n\n\nTL;DR: AIHF outperforms RLHF and DPO in aligning human preference and value in AI, especially with limited data.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understanding in Video-LLMs\n\n\n\nproduction\n\n\neducation\n\n\n\nVideoLLaMA 2 improves video and audio understanding with competitive results in multimodal tasks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaying More Attention to Source Context: Mitigating Unfaithful Translations from Large Language Model\n\n\n\nrobustness\n\n\n\nLLMs can generate unfaithful translations due to bias towards target tokens. Our methods encourage LLMs to focus more on source context, reducing hallucinatory translations.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Probabilistic Framework for LLM Hallucination Detection via Belief Tree Propagation\n\n\n\nrobustness\n\n\n\nBTProp: New method improves hallucination detection in LLMs by 3%-9% via a belief tree and hidden Markov tree model.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRS-Agent: Automating Remote Sensing Tasks through Intelligent Agents\n\n\n\nprompt-engineering\n\n\n\nTL;DR: RS-Agent: A LLM-driven remote sensing agent excelling in complex tasks, outperforming in scene classification, visual question answering, and object counting.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAccessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B\n\n\n\narchitectures\n\n\neducation\n\n\n\nMCTSr algorithm improves LLMs’ mathematical reasoning by integrating Monte Carlo Tree Search, enhancing accuracy in complex tasks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvancing Annotation of Stance in Social Media Posts: A Comparative Analysis of Large Language Models and Crowd Sourcing\n\n\n\nproduction\n\n\nsocial-sciences\n\n\n\nLLMs’ stance annotation accuracy depends on text’s explicitness, often mirroring human performance.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVersiCode: Towards Version-controllable Code Generation\n\n\n\narchitectures\n\n\nproduction\n\n\nprogramming\n\n\n\nTL;DR: VersiCode dataset tests LLMs’ ability to generate version-correct code, revealing challenges and limitations.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTextGrad: Automatic Differentiation via Text\n\n\n\narchitectures\n\n\nproduction\n\n\n\nTextGrad optimizes compound AI systems by backpropagating textual feedback, improving performance across various tasks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReinforcement Learning from Human Feedback without Reward Inference: Model-Free Algorithm and Instance-Dependent Analysis\n\n\n\narchitectures\n\n\nproduction\n\n\n\nRLHF not harder than classic RL; end-to-end RLHF can improve performance by avoiding pitfalls in reward inference.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoEvol: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation\n\n\n\nhci\n\n\neducation\n\n\n\nCoEvol: LLM-based framework improves instruction responses, outperforming baselines in MT-Bench and AlpacaEval.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees\n\n\n\nprogramming\n\n\n\nTP-LLaMA model outperforms baselines in tool-augmented LLMs by optimizing inference trajectories using preference data from decision trees, enhancing utilization of expert…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTHaLLE: Text Hyperlocally Augmented Large Language Extension – Technical Report\n\n\n\narchitectures\n\n\nproduction\n\n\nprompt-engineering\n\n\neducation\n\n\n\nLLMs show promise in financial analysis, with our 8B THaLLE models outperforming others on mock CFA exams.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProgressive Query Expansion for Retrieval Over Cost-constrained Data Sources\n\n\n\nrobustness\n\n\n\nProQE combines PRF and LLMs for progressive query expansion, improving accuracy and cost-effectiveness in retrieval systems.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGuiding LLM Temporal Logic Generation with Explicit Separation of Data and Control\n\n\n\narchitectures\n\n\n\nLLMs can improve reactive program synthesis by separating control and data in temporal logic specifications, enhancing specification generation.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstruct Large Language Models to Drive like Humans\n\n\n\narchitectures\n\n\n\nInstructDriver: Transforming LLM into a motion planner with human-aligned behavior for autonomous driving.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models for Constrained-Based Causal Discovery\n\n\n\nhci\n\n\n\nLLMs can assist in causal graph generation, but performance varies. A statistical-inspired voting schema improves results, suggesting potential for knowledge-based CIT in…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraphCoder: Enhancing Repository-Level Code Completion via Code Context Graph-based Retrieval and Language Model\n\n\n\nprogramming\n\n\n\nGraphCoder improves code completion with a graph-based retrieval-generation process, outperforming baseline methods in accuracy and efficiency.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nValidating LLM-Generated Programs with Metamorphic Prompt Testing\n\n\n\nrobustness\n\n\nsecurity\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\nTL;DR: Metamorphic prompt testing detects 75% of GPT-4’s erroneous code, with 8.6% false positives.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat’s in an embedding? Would a rose by any embedding smell as sweet?\n\n\n\neducation\n\n\n\n[TEXT] This study examines the relationship between social media use and mental health in young adults. Results suggest a negative correlation between excessive social media…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMBBQ: A Dataset for Cross-Lingual Comparison of Stereotypes in Generative LLMs\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLLMs exhibit language-dependent biases, with non-English languages suffering more. MBBQ dataset reveals cross-lingual differences in bias behavior.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSingle-Codec: Single-Codebook Speech Codec towards High-Performance Speech Generation\n\n\n\nproduction\n\n\n\nSingle-Codec, a single-sequence codec, improves TTS efficiency and robustness, outperforming multi-codebook codecs in quality, bandwidth, and LLM-TTS performance.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMcEval: Massively Multilingual Code Evaluation\n\n\n\narchitectures\n\n\nprogramming\n\n\neducation\n\n\nproduction\n\n\nprompt-engineering\n\n\n\nTL;DR: Introducing McEval, a multilingual code benchmark for 40 languages, challenging LLMs in code tasks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEfficiently Exploring Large Language Models for Document-Level Machine Translation with In-context Learning\n\n\n\nprompt-engineering\n\n\n\nLLMs struggle with document-level translation. Our Context-Aware Prompting method (CAP) improves LLM translation accuracy, cohesion, and coherence.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuickLLaMA: Query-aware Inference Acceleration for Large Language Models\n\n\n\narchitectures\n\n\nproduction\n\n\n\nQ-LLM enhances LLMs’ context understanding, improving accuracy on benchmarks without extra training.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDR-RAG: Applying Dynamic Document Relevance to Retrieval-Augmented Generation for Question-Answering\n\n\n\narchitectures\n\n\n\nDR-RAG improves QA accuracy by enhancing document retrieval, using a two-stage framework and a small classifier, while maintaining efficiency.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPITCH: Productivity and Mental Well-being Coaching through Daily Conversational Interaction\n\n\n\nproduction\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\nhci\n\n\n\nPITCH: A conversational AI for productivity, using rotating prompts to boost engagement and mental well-being.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOPTune: Efficient Online Preference Tuning\n\n\n\nrecommender\n\n\n\nTL;DR: OPTune speeds up online preference tuning for LLMs, maintaining benefits while reducing training time.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWorld Models with Hints of Large Language Models for Goal Achieving\n\n\n\nproduction\n\n\nhci\n\n\n\nDLLM, a multi-modal RL approach, improves exploration in long-horizon tasks by integrating hinting subgoals from LLMs, outperforming recent methods in sparse-reward…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Human-AI Collaboration in Healthcare: Guided Deferral Systems with Large Language Models\n\n\n\nsocial-sciences\n\n\n\nTL;DR: Human-AI collaboration improves LLMs’ reliability in healthcare, reducing uncertainty via a guided deferral system.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLimited Out-of-Context Knowledge Reasoning in Large Language Models\n\n\n\narchitectures\n\n\nproduction\n\n\neducation\n\n\n\nLLMs struggle with out-of-context reasoning and cross-lingual knowledge transfer, despite training adjustments.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBertaQA: How Much Do Language Models Know About Local Culture?\n\n\n\nsocial-sciences\n\n\n\nLLMs struggle with local cultural knowledge but improve with continued pre-training in that language.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niMotion-LLM: Motion Prediction Instruction Tuning\n\n\n\nrobustness\n\n\nhci\n\n\n\niMotion-LLM: A multimodal model for trajectory prediction in multi-agent scenarios, guided by textual instructions, enhancing safety and contextual relevance.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Context Learning and Fine-Tuning GPT for Argument Mining\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nGPT-4 and GPT-3.5 excel in Argument Type Classification using In-Context Learning and fine-tuning, respectively.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecureNet: A Comparative Study of DeBERTa and Large Language Models for Phishing Detection\n\n\n\nrobustness\n\n\nsecurity\n\n\neducation\n\n\n\nTL;DR: DeBERTa V3 outperforms LLMs like GPT-4 in detecting phishing content, achieving 95.17% recall, while GPT-4 scores 91.04%.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSafety Alignment Should Be Made More Than Just a Few Tokens Deep\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nShallow safety alignment in LLMs can lead to vulnerabilities; deepening alignment beyond initial tokens can improve robustness.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course\n\n\n\nsocial-sciences\n\n\nprogramming\n\n\neducation\n\n\nhci\n\n\nprompt-engineering\n\n\n\nStudents’ LLM usage in programming education influenced by career expectations, peer usage, and affects self-efficacy and midterm performance.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLanguage Models Resist Alignment\n\n\n\nrobustness\n\n\n\nAlignment fine-tuning in LLMs is elastic and can revert to pre-training behavior, especially with larger models and more pre-training data.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection\n\n\n\nrobustness\n\n\nsecurity\n\n\nprogramming\n\n\n\nCodeBreaker: LLM-assisted backdoor attack framework for code completion models, evading vulnerability detection.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRaccoon: Prompt Extraction Benchmark of LLM-Integrated Applications\n\n\n\nrobustness\n\n\nsecurity\n\n\nprompt-engineering\n\n\neducation\n\n\n\nRaccoon benchmark evaluates LLM susceptibility to prompt extraction attacks, offering insights and defenses.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM2CVD: Multi-Model Collaboration for Code Vulnerability Detection\n\n\n\nrobustness\n\n\nsecurity\n\n\nprogramming\n\n\n\nM2CVD combines LLMs and code models for improved vulnerability detection, outperforming baselines on real-world datasets.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models\n\n\n\nrobustness\n\n\nsecurity\n\n\nprompt-engineering\n\n\n\nTL;DR: Chain-of-Scrutiny (CoS) is a user-friendly, black-box defense against backdoor attacks in LLMs, ensuring reasoning consistency to detect attacks.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge language models for generating rules, yay or nay?\n\n\n\nprogramming\n\n\n\nLLMs can aid engineering safety-critical systems by generating logic rules, but lack threshold generation ability.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn Empirical Design Justice Approach to Identifying Ethical Considerations in the Intersection of Large Language Models and Social Robotics\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLLMs in social robotics offer benefits but raise ethical concerns like misinformation, biased responses, and emotional disruption, exacerbated by physical embodiment.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTransforming Wearable Data into Health Insights using Large Language Model Agents\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nPHIA, a new AI system, accurately interprets wearable health data, potentially enabling personalized wellness insights.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs\n\n\n\nhci\n\n\n\nTL;DR: Our method uses context-aware, query-relevant knowledge graphs to improve LLM performance on complex questions, reducing token usage by up to 67%.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSynth-SBDH: A Synthetic Dataset of Social and Behavioral Determinants of Health for Clinical Text\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nSynth-SBDH dataset improves SBDH extraction from clinical text, outperforming counterparts and proving effective for rare categories and resource constraints.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStronger, Faster, and Cheaper Log Parsing with LLMs\n\n\n\neducation\n\n\n\nLogBatcher: Cost-effective LLM-based log parser with no training or labeled data, using clustering and cache matching for efficient parsing.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow Efficient is LLM-Generated Code? A Rigorous & High-Standard Benchmark\n\n\n\nprogramming\n\n\n\nLLMs struggle to generate expert-level efficient code, per new benchmark ENAMEL, which evaluates efficiency and correctness of LLM-generated code.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedExQA: Medical Question Answering Benchmark with Multiple Explanations\n\n\n\neducation\n\n\n\nMedExQA benchmark evaluates medical knowledge in LLMs via explanations, highlighting the need for explainability. New medical model, MedPhi-2, outperforms Llama2-based…\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHarnessing AI for efficient analysis of complex policy documents: a case study of Executive Order 14110\n\n\n\nsecurity\n\n\n\nAI systems Gemini 1.5 Pro and Claude 3 Opus excel in policy document analysis, rivaling human experts in accuracy but with greater efficiency.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDecision-Making Behavior Evaluation Framework for LLMs under Uncertain Context\n\n\n\nrobustness\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLLMs, like ChatGPT-4.0-Turbo, Claude-3-Opus, and Gemini-1.0-pro, exhibit human-like decision-making patterns but vary in risk, probability, and loss aversion. Ethical…\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey of Backdoor Attacks and Defenses on Large Language Models: Implications for Security Measures\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nTL;DR: This paper explores backdoor attacks on large language models, categorizing them by fine-tuning methods and discussing future research directions.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan I understand what I create? Self-Knowledge Evaluation of Large Language Models\n\n\n\nsocial-sciences\n\n\n\nLLMs struggle with self-generated questions due to human-alignment issues, but fine-tuning improves math performance.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnnotation alignment: Comparing LLM and human annotations of conversational safety\n\n\n\nsecurity\n\n\nsocial-sciences\n\n\n\nGPT-4 aligns with human safety perceptions, but more data is needed to assess demographic disparities and idiosyncratic variation.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Food Safety in Supply Chains: The Potential Role of Large Language Models in Preventing Campylobacter Contamination\n\n\n\nrobustness\n\n\n\nTL;DR: GPTs can aid HACCP implementation to reduce Campylobacter contamination in the food supply chain, but barriers exist.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024\n\n\n\nhci\n\n\neducation\n\n\nsocial-sciences\n\n\n\nTeam HYU_MLLAB_KT solves SMART-101 CVPR 2024 challenge with LLM and object detection, achieving 29.5 accuracy on test set and 27.1 WOSA on challenge set.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRepoQA: Evaluating Long Context Code Understanding\n\n\n\neducation\n\n\n\nRepoQA benchmark evaluates LLMs on long-context code understanding, showing gaps in open vs. proprietary models and language-specific strengths.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLanguage Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain\n\n\n\nsecurity\n\n\n\nNew dataset for medical triage decision-making; LLMs used as ethical decision-makers, alignable to different attributes.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards a Personal Health Large Language Model\n\n\n\neducation\n\n\n\nPH-LLM, a fine-tuned Gemini model, excels in personal health insights, outperforming experts in fitness and nearing their level in sleep, while accurately predicting sleep…\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMolX: Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension\n\n\n\neducation\n\n\n\nLLMs struggle with molecule-related tasks; this study introduces MolX, a multi-modal external module, to enhance LLMs’ molecule comprehension, outperforming baselines in…\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShould We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue\n\n\n\nhci\n\n\neducation\n\n\n\nLLM adaptation techniques vary in effectiveness based on base LLM and dialogue type; human evaluation is crucial.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSilent Signals, Loud Impact: LLMs for Word-Sense Disambiguation of Coded Dog Whistles\n\n\n\nsocial-sciences\n\n\n\nLLMs used to create dataset of 16,550 disambiguated dog whistle examples for hate speech detection and political science.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan Language Models Serve as Text-Based World Simulators?\n\n\n\nsocial-sciences\n\n\n\nLLMs, like GPT-4, are not yet reliable text-based world simulators, despite their capabilities, as per the ByteSized32-State-Prediction benchmark.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating the Retrieval Component in LLM-Based Question Answering Systems\n\n\n\nhci\n\n\n\nBaseline for evaluating retrievers in RAG-based chatbots shows better performance assessment, considering LLMs’ strengths and weaknesses.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n61A-Bot: AI homework assistance in CS1 is fast and cheap – but is it helpful?\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\n61A-Bot reduces homework completion time, but effects may not transfer to assignments without bot access.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecurity Vulnerability Detection with Multitask Self-Instructed Fine-Tuning of Large Language Models\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\nsecurity\n\n\neducation\n\n\n\nMSIVD: Multitask LLM & GNN technique improves vulnerability detection, outperforming existing methods with F1 scores of 0.92 (BigVul) and 0.48 (PreciseBugs).\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMoPS: Modular Story Premise Synthesis for Open-Ended Automatic Story Generation\n\n\n\nsocial-sciences\n\n\neducation\n\n\n\nMoPS generates diverse, fascinating, and original story premises for automatic story generation, outperforming existing methods.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHello Again! LLM-powered Personalized Agent for Long-term Dialogue\n\n\n\nhci\n\n\n\nLD-Agent: A framework for long-term dialogue systems with event memory, persona modeling, and response generation.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDomainRAG: A Chinese Benchmark for Evaluating Domain-specific Retrieval-Augmented Generation\n\n\n\neducation\n\n\n\nRAG models outperform LLMs in domain-specific tasks like college enrollment, but improvements are needed in areas like conversation, structure analysis, and denoising.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models Memorize Sensor Datasets! Implications on Human Activity Recognition Research\n\n\n\nrobustness\n\n\n\nLLMs may have seen HAR benchmark data during training, potentially skewing evaluation results.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo LLMs Exhibit Human-Like Reasoning? Evaluating Theory of Mind in LLMs for Open-Ended Responses\n\n\n\nhci\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLLMs struggle with Theory of Mind reasoning in open-ended questions, but incorporating human intentions and emotions can improve their performance, though not fully…\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Superalignment Framework in Autonomous Driving with Large Language Models\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nTL;DR: Novel security framework for autonomous vehicles using multi-agent LLM approach, ensuring data protection and adherence to regulations.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Against the RAG: Jamming Retrieval-Augmented Generation with Blocker Documents\n\n\n\nrobustness\n\n\n\nTL;DR: RAG systems are vulnerable to jamming attacks using blocker documents, which can prevent them from answering queries. New methods for generating blocker documents are…\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre Large Language Models Actually Good at Text Style Transfer?\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLLMs struggle with TST in non-English languages, but finetuning improves results, highlighting the need for dedicated datasets.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Comprehensive Evaluation of Parameter-Efficient Fine-Tuning on Automated Program Repair\n\n\n\nprompt-engineering\n\n\n\nPEFT methods improve LLMs’ bug-fixing capabilities in APR, outperforming existing techniques. Larger parameters/datasets don’t guarantee better performance.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMrRank: Improving Question Answering Retrieval System through Multi-Result Ranking Model\n\n\n\nrobustness\n\n\n\nNew method combines IR systems for LLMs, improving performance and reducing hallucinations.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLGR2: Language Guided Reward Relabeling for Accelerating Hierarchical Reinforcement Learning\n\n\n\nhci\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\nprogramming\n\n\n\nLGR2: A language-guided HRL framework for robotic control, mitigating non-stationarity and achieving high success rates in complex tasks.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey on LLM-Based Agentic Workflows and LLM-Profiled Components\n\n\n\nprompt-engineering\n\n\n\nLLMs enable advanced workflows, focusing on reusable components for clearer role understanding.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States\n\n\n\nrobustness\n\n\n\nLLMs learn ethics in pre-training, align concepts with emotions, and refine for safe output. Jailbreaks disrupt this process, causing harm.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDigital Business Model Analysis Using a Large Language Model\n\n\n\nhci\n\n\nprogramming\n\n\n\nThis study proposes an LLM-based method for comparing and analyzing similar companies across different business domains to support digital business model design.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nZero-Shot End-To-End Spoken Question Answering In Medical Domain\n\n\n\nhci\n\n\n\nE2E methodologies for SQA in the medical domain require fewer resources and improve accuracy compared to traditional cascade systems.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreativity Has Left the Chat: The Price of Debiasing Language Models\n\n\n\nhci\n\n\nprompt-engineering\n\n\n\nRLHF alignment in LLMs reduces toxicity but limits creativity, impacting marketing tasks. Balance between consistency and creativity is crucial.\n\n\n\nJun 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo LLMs Recognize me, When I is not me: Assessment of LLMs Understanding of Turkish Indexical Pronouns in Indexical Shift Contexts\n\n\n\nsocial-sciences\n\n\n\nTL;DR: Advanced LLMs struggle with Turkish’s unique grammatical challenge, the Indexical Shift, highlighting the need for low-resource language research.\n\n\n\nJun 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFastGAS: Fast Graph-based Annotation Selection for In-Context Learning\n\n\n\nprompt-engineering\n\n\n\nFastGAS: A graph-based method for efficient instance selection in in-context learning, improving performance and reducing selection time.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDICE: Detecting In-distribution Contamination in LLM’s Fine-tuning Phase for Math Reasoning\n\n\n\neducation\n\n\n\nDICE detects in-distribution contamination in LLMs, potentially overestimating model capabilities.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAligning Agents like Large Language Models\n\n\n\nhci\n\n\n\nWe align 3D agents with desired behaviors using LLM alignment techniques, improving imitation learning.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemantically Diverse Language Generation for Uncertainty Estimation in Language Models\n\n\n\nrobustness\n\n\n\nLLMs can hallucinate due to predictive uncertainty. SDLG quantifies this, improving trustworthiness and efficiency in LLMs.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM-QALM: A Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall in Large Language Models via Question Answering\n\n\n\neducation\n\n\n\nLLMs’ success in healthcare tasks depends on recall, comprehension, and integration of knowledge, with instruction tuning and fine-tuning on medical datasets showing promise.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTool-Planner: Dynamic Solution Tree Planning for Large Language Model with Tool Clustering\n\n\n\neducation\n\n\n\nTL;DR: Tool-Planner improves tool learning in LLMs like GPT-4 and Claude 3, optimizing planning and handling errors.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Do Language Models Learn in Context? The Structured Task Hypothesis\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\n[TEXT] This study examines the relationship between social media use and mental health in young adults. Results indicate a significant correlation between excessive social…\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVerbalized Machine Learning: Revisiting Machine Learning with Language Models\n\n\n\nprompt-engineering\n\n\n\nVML uses LLMs to solve ML problems, offering easy encoding of inductive bias, automatic model class selection, and interpretable learner updates.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPOEM: Interactive Prompt Optimization for Enhancing Multimodal Reasoning of Large Language Models\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nIntroducing ame: A Visual Analytics System for Prompt Engineering in Multimodal LLMs.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nText-to-Drive: Diverse Driving Behavior Synthesis via Large Language Models\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nTL;DR: Text-to-Drive (T2D) uses LLMs to generate diverse driving behaviors for autonomous vehicle simulation, offering a scalable and intuitive method for human operators.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfabulation: The Surprising Value of Large Language Model Hallucinations\n\n\n\nhci\n\n\n\nLLM confabulations mirror human narrativity, offering potential value in AI communication.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRetrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining\n\n\n\nprompt-engineering\n\n\n\nContext-Aware RAG improves prompt-based TTS, outperforming text-only retrieval methods.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBenchmark Data Contamination of Large Language Models: A Survey\n\n\n\nprogramming\n\n\n\nTL;DR: Large Language Models face Benchmark Data Contamination, requiring new evaluation methods for reliable performance.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeneralization-Enhanced Code Vulnerability Detection via Multi-Task Instruction Fine-Tuning\n\n\n\nprogramming\n\n\n\nVulLLM, a multi-task framework with LLMs, outperforms SOTA models in vulnerability detection by capturing root causes, not just superficial features.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMEmbed: Rethinking Lightweight LLM’s Genuine Function in Text Classification\n\n\n\nprompt-engineering\n\n\n\nLLMEmbed: Efficient LLM-based text classification with low overhead.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAsk LLMs Directly, What shapes your bias?: Measuring Social Bias in Large Language Models\n\n\n\nhci\n\n\n\nThis paper proposes a method to quantify social biases in LLMs by considering diverse social perceptions, offering a more nuanced understanding of bias.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRefactoring to Pythonic Idioms: A Hybrid Knowledge-Driven Approach Leveraging Large Language Models\n\n\n\nprompt-engineering\n\n\n\nHybrid approach combines LLMs and rule-based methods for Python code idiomatization, outperforming LLM-only and rule-based approaches.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey on Medical Large Language Models: Technology, Application, Trustworthiness, and Future Directions\n\n\n\nprogramming\n\n\n\nMed-LLMs revolutionize healthcare, offering clinical decision support, report generation, and medical education. Ethical considerations and robust evaluation are crucial for…\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models as Evaluators for Recommendation Explanations\n\n\n\nrecommender\n\n\n\nLLMs, like GPT4, can accurately evaluate recommendation explanations with proper prompts and settings, offering a cost-effective solution.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People\n\n\n\nhci\n\n\n\nThis study proposes a method to compare human and GPT-4 conversational tones, creating an interpretable representation of their relations.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoherent Zero-Shot Visual Instruction Generation\n\n\n\neducation\n\n\n\nNew framework generates consistent, visually appealing multi-step instructions using diffusion models and LLMs.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaCE: Parsimonious Concept Engineering for Large Language Models\n\n\n\nrobustness\n\n\n\nTL;DR: PaCE is a novel framework for aligning LLMs, improving output quality while preserving linguistic capabilities.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuffer of Thoughts: Thought-Augmented Reasoning with Large Language Models\n\n\n\nprompt-engineering\n\n\n\nBoT improves LLMs’ reasoning, outperforming SOTA methods on 10 tasks with 12% cost, potentially surpassing Llama3-70B with Llama3-8B.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models\n\n\n\nprogramming\n\n\n\nThis work enhances LLMs for long texts by considering fragment-level relations, improving story understanding, code generation, and chatting.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSynthetic Programming Elicitation and Repair for Text-to-Code in Very Low-Resource Programming Languages\n\n\n\nprogramming\n\n\n\nLLMs struggle with unseen programming languages. SPEAC, a new approach, enables LLMs to generate valid code for these languages.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nItem-Language Model for Conversational Recommendation\n\n\n\nrecommender\n\n\nprogramming\n\n\n\nTL;DR: Proposed Item-Language Model (ILM) addresses LLM limitations in recommender systems, aligning item representations with user interaction signals.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Detecting LLMs Hallucination via Markov Chain-based Multi-agent Debate Framework\n\n\n\nprogramming\n\n\n\nMarkov Chain-based multi-agent debate improves hallucination detection in LLMs, outperforming baselines.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Repository-Level Code Generation with Integrated Contextual Information\n\n\n\nprogramming\n\n\n\nCatCoder improves LLM code generation for repositories, outperforming RepoCoder by up to 17.35% in pass@k score, and shows consistent improvements across various LLMs.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring User Retrieval Integration towards Large Language Models for Cross-Domain Sequential Recommendation\n\n\n\nrecommender\n\n\n\nURLLM improves CDSR by integrating user retrieval and domain grounding on LLM, addressing cold-start issues and semantic reasoning.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nText-like Encoding of Collaborative Information in Large Language Models for Recommendation\n\n\n\nrecommender\n\n\n\nBinLLM: A novel method integrating collaborative info into LLMs via text-like binary encoding, improving recommendation performance.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBIPED: Pedagogically Informed Tutoring System for ESL Education\n\n\n\neducation\n\n\n\nLLMs can serve as effective tutors for English learners. We developed a dataset and models that replicate human teachers’ diverse teaching strategies.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe current status of large language models in summarizing radiology report impressions\n\n\n\nprogramming\n\n\n\nLLMs struggle to replace radiologists in summarizing radiology reports, despite few-shot prompt improvements.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Mathematical Extrapolation of Large Language Models with Synthetic Data\n\n\n\nprogramming\n\n\n\nLLMs excel in various tasks but struggle with multi-step reasoning. Fine-tuning on synthetic data improves performance in complex arithmetic puzzles.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nXRec: Large Language Models for Explainable Recommendation\n\n\n\nrecommender\n\n\n\nXRec framework uses LLMs for explainable recommendations, outperforming baselines in understanding user preferences.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models Make Sample-Efficient Recommender Systems\n\n\n\nrecommender\n\n\n\nLLMs improve recommender systems’ efficiency, needing less training data for superior performance.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChain of Agents: Large Language Models Collaborating on Long-Context Tasks\n\n\n\nprogramming\n\n\n\nChain-of-Agents (CoA) improves long-context tasks by dividing text among agents, showing up to 10% improvement over baselines.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPosition Debiasing Fine-Tuning for Causal Perception in Long-Term Dialogue\n\n\n\nprogramming\n\n\n\nCPD method alleviates position bias in LLMs, improving long-term dialogue relevance.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemCoder: Training Code Language Models with Comprehensive Semantics\n\n\n\nprogramming\n\n\n\nSemCoder: A 6.7B Code LLM excels in code generation and execution reasoning, outperforming GPT-3.5-turbo, by integrating semantics from multiple dimensions.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession Context Embedding for Intent Understanding in Product Search\n\n\n\nrecommender\n\n\n\nSession embedding improves search by capturing user intent from multiple engagements, outperforming single query-item pair relevance training.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrivacy in LLM-based Recommendation: Recent Advances and Future Directions\n\n\n\nrecommender\n\n\n\nPrivacy in LLM-based recommendations: attacks, protection, challenges, and future directions.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models as Recommender Systems: A Study of Popularity Bias\n\n\n\nrecommender\n\n\n\nLLMs in recommenders can reduce popularity bias, showing less bias than traditional systems without explicit mitigation.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Understand Whole Software Repository?\n\n\n\nprogramming\n\n\n\nTL;DR: RepoUnderstander improves ASE by understanding whole repositories, outperforming SWE-agent by 18.5%.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKeyword-driven Retrieval-Augmented Large Language Models for Cold-start User Recommendations\n\n\n\nrecommender\n\n\n\nTL;DR: KALM4Rec improves cold-start recommendations using keywords and LLMs for candidate retrieval and re-ranking.\n\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerating Query Recommendations via LLMs\n\n\n\nrecommender\n\n\n\n[TEXT] This study examines the impact of climate change on the global wine industry. Results indicate significant shifts in wine production regions and grape varieties due…\n\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKnowledge Graph Tuning: Real-time Large Language Model Personalization based on Human Feedback\n\n\n\nrecommender\n\n\n\nKGT: A novel, efficient, and interpretable method for real-time personalization of LLMs using knowledge graphs, improving user experience and performance.\n\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPreference Learning Algorithms Do Not Learn Preference Rankings\n\n\n\nrecommender\n\n\n\nDespite high performance, preference-tuned LLMs often have low ranking accuracy, due to limitations in the DPO objective and a gap between observed and idealized ranking…\n\n\n\nMay 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSLMRec: Empowering Small Language Models for Sequential Recommendation\n\n\n\nrecommender\n\n\n\nSLMRec: Small Language Model for Sequential Recommendation achieves 6.6x training, 8.0x inference speedups with 13% of LLM-based model parameters.\n\n\n\nMay 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteLLM-2: Multimodal Large Representation Models for Recommendation\n\n\n\nrecommender\n\n\n\nTL;DR: NoteLLM-2 enhances multimodal representation in I2I recommendations by focusing on visual content and fusing it with textual information.\n\n\n\nMay 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRAGSys: Item-Cold-Start Recommender as RAG System\n\n\n\nrecommender\n\n\n\nICL for LLMs resembles item-cold-start recommenders, prioritizing discovery and maximizing information gain. Diversity and quality bias in demonstrations are crucial for…\n\n\n\nMay 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMs for User Interest Exploration: A Hybrid Approach\n\n\n\nrecommender\n\n\n\nHybrid framework with LLMs and classic models improves novel interest discovery, boosting user enjoyment.\n\n\n\nMay 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSunnie: An Anthropomorphic LLM-Based Conversational Agent for Mental Well-Being Activity Recommendation\n\n\n\nrecommender\n\n\n\nThis LaTeX document guides authors on formatting ACM articles.\n\n\n\nMay 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNavigating User Experience of ChatGPT-based Conversational Recommender Systems: The Effects of Prompt Guidance and Recommendation Domain\n\n\n\nrecommender\n\n\n\nPrompt guidance in ChatGPT-based CRS enhances user experience, with book recommendations showing more engagement than job recommendations.\n\n\n\nMay 22, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  }
]