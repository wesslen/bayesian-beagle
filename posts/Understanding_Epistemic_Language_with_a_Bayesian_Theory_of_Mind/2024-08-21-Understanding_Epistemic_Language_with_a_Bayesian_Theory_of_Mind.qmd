
---
title: "Understanding Epistemic Language with a Bayesian Theory of Mind"
id: "2408.12022v1"
description: "Model (LaBToM) predicts human judgments on others' beliefs using Bayesian inferences, outperforming LLMs in various expressions."
author: Lance Ying, Tan Zhi-Xuan, Lionel Wong, Vikash Mansinghka, Joshua B. Tenenbaum
date: "2024-08-21"
image: "https://browse.arxiv.org/html/2408.12022v1/x2.png"
categories: ['prompt-engineering', 'hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.12022v1/x2.png)

### Summary:

The paper introduces a cognitive model called LaBToM (Language-augmented Bayesian Theory of Mind) to understand how humans interpret epistemic language in context. The model combines a Bayesian theory-of-mind (BToM) framework with an epistemic language of thought (ELoT) to represent others' beliefs. The model is evaluated in an experiment where participants watch animations of a player solving a gridworld puzzle and rate sentences about the player's beliefs. The results show that LaBToM correlates highly with human judgments, outperforming ablated BToM models and multimodal LLM baselines.

### Major Findings:

1. The LaBToM model captures graded plausibility judgments about epistemic claims by translating natural language into an epistemic language of thought and evaluating these translations against inferences produced by inverting a probabilistic generative model of rational action and perception.
2. The model correlates highly with human judgments for a wide range of expressions, including modal language, uncertainty expressions, knowledge claims, likelihood comparisons, and attributions of false belief.
3. The model outperforms ablated BToM models and multimodal LLM baselines (GPT-4o, Gemini Pro) in capturing human judgments about epistemic language.

### Analysis and Critique:

The paper presents a novel approach to understanding epistemic language by combining a Bayesian theory-of-mind framework with an epistemic language of thought. The model is evaluated in a well-designed experiment, and the results demonstrate its effectiveness in capturing human judgments about epistemic language. However, the paper does not discuss potential limitations or biases in the model, nor does it address the generalizability of the findings to other contexts or domains. Additionally, the paper does not provide a detailed comparison with other existing models or approaches to understanding epistemic language. Overall, the paper makes a valuable contribution to the field, but further research is needed to address these limitations and build on the findings.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-27       |
| Abstract | [https://arxiv.org/abs/2408.12022v1](https://arxiv.org/abs/2408.12022v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.12022v1](https://browse.arxiv.org/html/2408.12022v1)       |
| Truncated       | False       |
| Word Count       | 11043       |