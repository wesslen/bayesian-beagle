
---
title: "Characterizing and Evaluating the Reliability of LLMs against Jailbreak Attacks"
id: "2408.09326v1"
description: "LLMs face jailbreaking threats; this study evaluates 13 LLMs against 10 strategies, revealing vulnerabilities and offering reliability scores."
author: Kexin Chen, Yi Liu, Dongxia Wang, Jiaying Chen, Wenhai Wang
date: "2024-08-18"
image: "https://browse.arxiv.org/html/2408.09326v1/x1.png"
categories: ['prompt-engineering', 'security', 'hci', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.09326v1/x1.png)

### Summary:

This study introduces a comprehensive evaluation framework to assess the reliability of Large Language Models (LLMs) against jailbreak attacks. The authors conduct a large-scale empirical experiment, focusing on 10 cutting-edge jailbreak strategies, 1525 questions from 61 specific harmful categories, and 13 popular LLMs. They adopt multi-dimensional metrics such as Attack Success Rate (ASR), Toxicity Score, Fluency, Token Length, and Grammatical Errors to thoroughly evaluate LLMs' outputs under jailbreak. The study aims to provide a detailed reliability score for different LLMs and strategic recommendations to reduce their susceptibility to vulnerabilities.

### Major Findings:

1. The study reveals a lack of resilience among all tested LLMs against certain jailbreak strategies, highlighting the need to concentrate on the reliability facets of LLMs.
2. The authors construct a three-level hierarchical dataset, encompassing a spectrum of risks ranging from mild to extreme, with at least 25 harmful queries for each instance of harm, resulting in a comprehensive dataset of 1,525 queries.
3. The evaluation framework includes a multi-dimensional analysis of content quality and safety, accounting for factors that impact the practical usability of LLMs.
4. The study conducts extensive experiments to evaluate the reliability of 13 LLMs, encompassing both commercial and open-source models, under various sophisticated jailbreak attack scenarios.

### Analysis and Critique:

The study provides valuable insights into enhancing the security evaluation of LLMs against jailbreak within the domain. However, it does not extend to larger models, such as those with 33 billion and 70 billion parameters, nor does it cover other powerful commercial models like Claude and Gemini. Additionally, the study does not address the potential biases or limitations in the evaluation framework, which could impact the reliability scores of LLMs. Further research is needed to address these limitations and provide a more comprehensive evaluation of LLMs' reliability against jailbreak attacks.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-20       |
| Abstract | [https://arxiv.org/abs/2408.09326v1](https://arxiv.org/abs/2408.09326v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.09326v1](https://browse.arxiv.org/html/2408.09326v1)       |
| Truncated       | False       |
| Word Count       | 8950       |