
---
title: "LLMs for Test Input Generation for Semantic Caches"
id: "2401.08138v1"
description: "LLMs enable semantic capabilities, but are costly. VaryGen generates test queries for semantic caches."
author: Zafaryab Rasool, Scott Barnett, David Willie, Stefanus Kurniawan, Sherwin Balugo, Srikanth Thudumu, Mohamed Abdelrazek
date: "2024-01-16"
image: "../../../bayesian-beagle.png"
categories: ['education']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### **Summary:**
Large language models (LLMs) are used to add semantic capabilities to software systems, but they are computationally expensive. Semantic caches are used to check for answers to similar queries without hitting the LLM service. However, testing the effectiveness of a semantic cache requires a labelled test set of similar queries and responses, which is often unavailable. In this paper, the authors present VaryGen, an approach for using LLMs for test input generation that produces similar questions from unstructured text documents. They evaluated their approach in the domain of a student question and answer system and conducted an empirical case study with an open source semantic cache. The results show that query pairs satisfy human expectations of similarity and the generated data demonstrates failure cases of a semantic cache.

### Major Findings:
1. LLMs can be used for test input generation to produce similar questions from unstructured text documents.
2. The VaryGen approach was evaluated in the domain of a student question and answer system and demonstrated the effectiveness of finding limitations in a semantic cache.
3. The generated data showed failure cases of a semantic cache, highlighting the need for robust testing of semantic applications.

### Analysis and Critique:
The article presents an innovative approach for test input generation using LLMs, addressing the challenges of testing semantic caches. However, the study is limited to a specific domain, and the evaluation is based on a single semantic cache. Further research is needed to explore the generalizability of the approach across different domains and to compare its performance with multiple semantic caching systems. Additionally, the article lacks human validation during data generation, which may affect the quality of the generated questions. Overall, the study provides valuable insights into the potential of LLMs for test input generation and highlights the need for further research in this area.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-26       |
| Abstract | [https://arxiv.org/abs/2401.08138v1](https://arxiv.org/abs/2401.08138v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.08138v1](https://browse.arxiv.org/html/2401.08138v1)       |
| Truncated       | False       |
| Word Count       | 7593       |