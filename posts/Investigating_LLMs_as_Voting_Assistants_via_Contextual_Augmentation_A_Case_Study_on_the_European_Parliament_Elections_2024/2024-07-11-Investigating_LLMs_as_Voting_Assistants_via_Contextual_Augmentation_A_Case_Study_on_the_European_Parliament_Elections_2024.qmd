
---
title: "Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024"
id: "2407.08495v1"
description: "LLMs can predict political stances with 82% accuracy; expert-curated info boosts performance by 9%."
author: Ilias Chalkidis
date: "2024-07-11"
image: "https://browse.arxiv.org/html/2407.08495v1/extracted/5725368/framework_3.png"
categories: ['hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2407.08495v1/extracted/5725368/framework_3.png)

### Summary:

- The study investigates the potential of using Instruction-finetuned Large Language Models (LLMs) as Voting Advice Applications (VAAs) in the context of the 2024 European Parliament elections.
- The authors audit Mistral and Mixtral models and evaluate their accuracy in predicting the stance of political parties based on the "EU and I" voting assistance questionnaire.
- The study explores alternatives to improve models' performance by augmenting the input context via Retrieval-Augmented Generation (RAG) and Self-Reflection.
- The larger LLM, Mixtral, is found to be highly accurate with an 82% accuracy on average. Augmenting the input context with expert-curated information can lead to a significant boost of approx. 9%, which remains an open challenge for automated approaches.

### Major Findings:

1. Mixtral, the larger LLM, is highly accurate with an 82% accuracy on average in predicting the stance of political parties.
2. Augmenting the input context with expert-curated information can lead to a significant boost of approx. 9% in the performance of LLMs.
3. RAG leads to a substantial performance boost in the case of Mistral (+8%).

### Analysis and Critique:

- The study focuses on the European Parliament elections and the "EU and I" voting assistance questionnaire, which may limit the generalizability of the findings to other contexts.
- The study does not address potential biases in the LLMs or the impact of such biases on the accuracy of the predictions.
- The study does not discuss the potential limitations of using LLMs as VAAs, such as the risk of spreading misinformation or the lack of transparency in the decision-making process.
- The study does not provide a detailed analysis of the performance of the LLMs in predicting the stance of political parties on specific issues or the factors that may contribute to the accuracy of the predictions.
- The study does not discuss the potential ethical implications of using LLMs as VAAs, such as the risk of reinforcing existing biases or the potential for manipulation by political actors.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-16       |
| Abstract | [https://arxiv.org/abs/2407.08495v1](https://arxiv.org/abs/2407.08495v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.08495v1](https://browse.arxiv.org/html/2407.08495v1)       |
| Truncated       | False       |
| Word Count       | 5277       |