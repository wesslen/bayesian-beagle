
---
title: "Advancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning"
id: "2407.20174v1"
description: "This paper proposes a new approach for chart question answering using multimodal large language models, focusing on data quality and alignment with chart characteristics. The method outperforms existing models on benchmarks."
author: Xingchen Zeng, Haichuan Lin, Yilin Ye, Wei Zeng
date: "2024-07-29"
image: "https://browse.arxiv.org/html/2407.20174v1/x2.png"
categories: ['production', 'architectures', 'hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2407.20174v1/x2.png)

### Summary:

The paper presents an approach to improve the performance of multimodal large language models (MLLMs) in chart question answering (CQA) tasks. The authors identify limitations in current MLLMs and CQA datasets, such as unbalanced data distribution and inconsistent data quality, which hinder their performance. To address these issues, the authors propose a two-stage data engine that filters existing datasets and enlarges them through LLM-based generation techniques. This approach ensures a broader range of high-quality data that captures the characteristics of charts. The authors also incorporate a mixture-of-resolution adaptation strategy and unfreeze the vision encoder during model training, which significantly improves the performance of their MLLM on CQA tasks. Experimental results show that their model outperforms state-of-the-art CQA models, even with a more compact dataset. The authors also contribute a benchmark for future advancements in MLLMs for CQA tasks.

### Major Findings:

1. Current MLLMs and CQA datasets have limitations, such as unbalanced data distribution and inconsistent data quality, which hinder their performance in CQA tasks.
2. A two-stage data engine that filters existing datasets and enlarges them through LLM-based generation techniques can improve the performance of MLLMs in CQA tasks.
3. Incorporating a mixture-of-resolution adaptation strategy and unfreezing the vision encoder during model training can significantly improve the performance of MLLMs in CQA tasks.
4. The proposed model outperforms state-of-the-art CQA models, even with a more compact dataset.
5. A benchmark is contributed for future advancements in MLLMs for CQA tasks.

### Analysis and Critique:

The paper presents a novel approach to improve the performance of MLLMs in CQA tasks. The authors identify limitations in current MLLMs and CQA datasets and propose a two-stage data engine to address these issues. The proposed approach ensures a broader range of high-quality data that captures the characteristics of charts. The authors also incorporate a mixture-of-resolution adaptation strategy and unfreeze the vision encoder during model training, which significantly improves the performance

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-30       |
| Abstract | [https://arxiv.org/abs/2407.20174v1](https://arxiv.org/abs/2407.20174v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.20174v1](https://browse.arxiv.org/html/2407.20174v1)       |
| Truncated       | False       |
| Word Count       | 11032       |