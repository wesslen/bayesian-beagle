
---
title: "African or European Swallow? Benchmarking Large Vision-Language Models for Fine-Grained Object Classification"
id: "2406.14496v1"
description: "TL;DR: FOCI benchmark reveals CLIP models outperform LVLMs in fine-grained object classification, highlighting alignment issues."
author: Gregor Geigle, Radu Timofte, Goran Glava≈°
date: "2024-06-20"
image: "https://browse.arxiv.org/html/2406.14496v1/x1.png"
categories: ['architectures', 'production']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.14496v1/x1.png)

### Summary:

This paper introduces a new benchmark, FOCI (Fine-grained Object ClassIfication), to evaluate the performance of Large Vision-Language Models (LVLMs) in fine-grained object classification tasks. The benchmark is created by converting existing object classification datasets into multiple-choice tasks, which avoids ambiguity in open-ended question answering and maintains task difficulty. The authors evaluate 12 publicly available LVLMs on FOCI and find that many of them struggle with fine-grained object classification. The results show that the performance of LVLMs on FOCI is less correlated with their performance on other image understanding benchmarks, indicating that fine-grained object classification is a distinct skill for LVLMs. The paper also highlights the importance of better visio-linguistic alignment in the first training stage for improving fine-grained object classification abilities.

### Major Findings:

1. The creation of a new benchmark, FOCI, for evaluating LVLMs in fine-grained object classification tasks.
2. The evaluation of 12 publicly available LVLMs on FOCI, revealing that many of them struggle with fine-grained object classification.
3. The observation that the performance of LVLMs on FOCI is less correlated with their performance on other image understanding benchmarks, indicating that fine-grained object classification is a distinct skill for LVLMs.
4. The importance of better visio-linguistic alignment in the first training stage for improving fine-grained object classification abilities.

### Analysis and Critique:

The paper presents a well-structured and comprehensive evaluation of LVLMs in fine-grained object classification tasks. The creation of the FOCI benchmark is a significant contribution, as it addresses the limitations of existing benchmarks and provides a more challenging and well-defined task for evaluating LVLMs. The evaluation of 12 publicly available LVLMs on FOCI is also a valuable contribution, as it reveals the limitations of current models in handling fine-grained object classification tasks.

However, the paper could benefit from a more in-depth analysis of the factors that contribute to the performance of LVLMs on FOCI. While the authors highlight the importance of better visio-linguistic alignment in the first training stage, they do not

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-23       |
| Abstract | [https://arxiv.org/abs/2406.14496v1](https://arxiv.org/abs/2406.14496v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.14496v1](https://browse.arxiv.org/html/2406.14496v1)       |
| Truncated       | False       |
| Word Count       | 8786       |