
---
title: "Teaching LLMs to Abstain across Languages via Multilingual Feedback"
id: "2406.15948v1"
description: "TL;DR: Multilingual feedback improves LLM abstention, reducing performance gaps between high and low-resource languages in QA tasks."
author: Shangbin Feng, Weijia Shi, Yike Wang, Wenxuan Ding, Orevaoghene Ahia, Shuyue Stella Li, Vidhisha Balachandran, Sunayana Sitaram, Yulia Tsvetkov
date: "2024-06-22"
image: "https://browse.arxiv.org/html/2406.15948v1/extracted/5685539/latex/figures/teaser_side_by_side.png"
categories: ['social-sciences', 'education', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.15948v1/extracted/5685539/latex/figures/teaser_side_by_side.png)

**Summary:**

The paper presents a study on teaching multilingual large language models (LLMs) to abstain from answering when they encounter knowledge gaps, with a focus on mitigating hallucinations in multilingual settings. The authors propose a strategy that involves generating and learning from multilingual feedback in related languages, which helps identify knowledge gaps across diverse languages, cultures, and communities. The proposed approach is evaluated on three datasets featuring open-book, closed-book, and commonsense QA, and is shown to outperform various strong baselines, achieving up to 9.2% improvement for low-resource languages. The study also reveals that multilingual feedback is an effective and more equitable abstain strategy, with cultural factors playing a significant role in language selection and LLM abstention behavior.

**Major Findings:**

1. The proposed multilingual feedback approach outperforms various strong baselines, achieving up to 9.2% improvement for low-resource languages across three black-box and open models on three datasets.
2. Multilingual feedback is an effective and more equitable abstain strategy, with cultural factors having a significant impact on language selection and LLM abstention behavior.
3. The study highlights the importance of considering cultural factors in multilingual and multi-cultural reliable language modeling.

**Analysis and Critique:**

The paper presents a novel approach to teaching LLMs to abstain from answering in the face of knowledge gaps, with a focus on multilingual settings. The proposed strategy of generating and learning from multilingual feedback in related languages is shown to be effective in identifying knowledge gaps and improving LLM abstention behavior. However, the study is limited in its evaluation of the proposed approach on only three datasets, and it is unclear how well the approach would generalize to other datasets and tasks. Additionally, the study does not address potential issues related to the quality and reliability of the generated feedback, which could impact the effectiveness of the proposed approach. Further research is needed to address these limitations and evaluate the proposed approach in a more comprehensive manner.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-07       |
| Abstract | [https://arxiv.org/abs/2406.15948v1](https://arxiv.org/abs/2406.15948v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.15948v1](https://browse.arxiv.org/html/2406.15948v1)       |
| Truncated       | False       |
| Word Count       | 8591       |