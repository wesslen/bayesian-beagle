
---
title: "Simulating Field Experiments with Large Language Models"
id: "2408.09682v1"
description: "This paper explores using LLMs to simulate field experiments, achieving 66% accuracy in observer mode and identifying LLMs' limitations in certain topics."
author: Yaoyu Chen, Yuheng Hu, Yingda Lu
date: "2024-08-19"
image: "../../img/2408.09682v1/image_1.png"
categories: ['hci', 'prompt-engineering', 'social-sciences', 'education']
format:
  html:
    code-overflow: wrap
---

![](../../img/2408.09682v1/image_1.png)

### Summary:

The paper titled "Simulating Field Experiments with Large Language Models" explores the potential of large language models (LLMs) to simulate field experiments. The authors propose and evaluate two prompting strategies: observer mode and participant mode. The observer mode allows for direct prediction of main conclusions, while the participant mode simulates distributions of participants' responses. The study examines 15 well-cited field experimental papers published in INFORMS and MISQ, finding encouraging alignments between simulated experimental results and actual results in certain scenarios. However, the study also identifies topics where LLMs underperform, including gender difference and social norms related research.

### Major Findings:

1. The observer mode of LLMs achieved a stimulation accuracy of 66% in predicting the main conclusions of field experiments.
2. The participant mode of LLMs achieved a lower accuracy of 47.9% in simulating field experiments.
3. Results are highly skewed due to topic sensitivity, with LLMs performing poorly in field experiments concerning gender differences, popularity information, humanizing customer service chatbots, and reciprocity.

### Analysis and Critique:

1. The study pioneers the utilization of LLMs for simulating field experiments, expanding the scope of potential applications for LLMs and illustrating their utility in assisting researchers prior to engaging in expensive field experiments.
2. The study identifies the boundaries of LLMs when used in simulating field experiments, serving as a cautionary note for researchers considering the integration of LLMs into their experimental toolkit.
3. The study does not address the potential biases and limitations of LLMs, such as gender bias and lack of awareness of social norms, which could impact the accuracy of simulated experimental results.
4. The study does not discuss the potential ethical implications of using LLMs to simulate field experiments, such as the potential for LLMs to perpetuate existing biases or to be used to manipulate experimental results.
5. The study does not provide a comprehensive evaluation of the accuracy of LLMs in simulating field experiments, as it only examines 15 papers and does not provide a comparison to traditional field experiments.
6. The study does not discuss the potential for LLMs to be used to automate the process of conducting field experiments, which could have significant implications

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-20       |
| Abstract | [https://arxiv.org/abs/2408.09682v1](https://arxiv.org/abs/2408.09682v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.09682v1](https://browse.arxiv.org/html/2408.09682v1)       |
| Truncated       | False       |
| Word Count       | 7412       |