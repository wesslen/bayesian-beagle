
---
title: "Advancing TTP Analysis: Harnessing the Power of Encoder-Only and Decoder-Only Language Models with Retrieval Augmented Generation"
id: "2401.00280v1"
description: "Cybersecurity experts explore using advanced language models to interpret and summarize cyberattack methods for better understanding."
author: Reza Fayyazi, Rozhina Taghdimi, Shanchieh Jay Yang
date: "2023-12-30"
image: "https://browse.arxiv.org/html/2401.00280v1/x1.png"
categories: ['hci', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.00280v1/x1.png)

### Major Takeaways
1. Large Language Models (LLMs) have been increasingly used in cybersecurity operations, but they are prone to **hallucination** and providing inaccurate information, especially in critical domains like cybersecurity.
2. This study compares the performance of supervised fine-tuning of smaller encoder-only LLMs with retrieval-augmented generation (RAG)-enhanced larger decoder-only LLMs in interpreting Tactics, Techniques, and Procedures (TTPs) in cybersecurity. 
3. The results demonstrate significant improvement in interpreting TTPs for decoder-only LLMs when RAG is used to provide relevant contexts for the cyberattack procedures.

### Introduction
- **Tactics, Techniques, and Procedures (TTPs)** in the MITRE ATT&CK framework pose challenges due to their complexity and potential ambiguity in cybersecurity operations.
- Large Language Models have shown potential to address these challenges but are prone to hallucination and inaccurate interpretation.

### Related Works
- Large Language Models like BERT, RoBERTa, and GPT-3.5 have been used for interpreting TTP descriptions in cybersecurity operations.
- Supervised fine-tuning and retrieval-augmented generation have been explored in the context of interpreting TTPs, but there is a lack of comparison between encoder-only and decoder-only LLMs.

### Methodology & Experimental Design
- The study compares supervised fine-tuning of encoder-only LLMs with direct use and retrieval augmented generation (RAG) for decoder-only LLMs.
- The performance is evaluated using F1 scores for recall and precision across different LLM models.

### Results & Discussion
- Supervised fine-tuning of encoder-only LLMs shows reasonably good performance, but decoder-only LLMs with RAG outperform them in interpreting cyberattack procedures.
- Decoder-only LLMs demonstrate high recall but lack precision, and the use of RAG influences their performance, potentially distracting them from the correct answer.
- Specific examples illustrate how RAG can both help and distract decoder-only LLMs in interpreting cyberattack procedures.

### Critique
The study provides valuable insights into the use of RAG for decoder-only LLMs, but it would benefit from a more in-depth analysis of potential biases introduced by the retrieval process. Additionally, the study could benefit from a more comprehensive evaluation of the limitations of RAG techniques and potential strategies for addressing them.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-05       |
| Abstract | [http://arxiv.org/abs/2401.00280v1](http://arxiv.org/abs/2401.00280v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.00280v1](https://browse.arxiv.org/html/2401.00280v1)       |
| Truncated       | False       |
| Word Count       | 8243       |