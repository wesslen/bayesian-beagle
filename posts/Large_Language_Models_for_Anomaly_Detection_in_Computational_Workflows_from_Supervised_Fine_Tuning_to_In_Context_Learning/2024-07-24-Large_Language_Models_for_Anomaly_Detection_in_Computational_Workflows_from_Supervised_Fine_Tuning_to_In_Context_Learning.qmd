
---
title: "Large Language Models for Anomaly Detection in Computational Workflows: from Supervised Fine-Tuning to In-Context Learning"
id: "2407.17545v1"
description: "LLMs can detect workflow anomalies via supervised fine-tuning and in-context learning, offering promising results for system reliability and security."
author: Hongwei Jin, George Papadimitriou, Krishnan Raghavan, Pawel Zuk, Prasanna Balaprakash, Cong Wang, Anirban Mandal, Ewa Deelman
date: "2024-07-24"
image: "https://browse.arxiv.org/html/2407.17545v1/x1.png"
categories: ['prompt-engineering', 'robustness', 'security']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2407.17545v1/x1.png)

### Summary:

This paper explores the use of large language models (LLMs) for anomaly detection in computational workflows, focusing on two approaches: supervised fine-tuning (SFT) and in-context learning (ICL). SFT involves fine-tuning pre-trained LLMs on labeled workflow data, while ICL uses prompts to guide LLMs in few-shot anomaly detection without fine-tuning. The study demonstrates that SFT models achieve high anomaly detection performance across multiple datasets, requiring little task-specific data and training time. ICL models also perform reasonably well, with chain-of-thought prompting improving interpretability. The results highlight the potential of LLMs and transfer learning for accurate and efficient anomaly detection in complex workflow executions.

### Major Findings:

1. Supervised fine-tuning (SFT) of pre-trained LLMs on labeled workflow data results in high anomaly detection performance across multiple datasets, requiring relatively little task-specific data and training time.
2. SFT models demonstrate strong generalization via transfer learning, making them valuable tools for detecting anomalies and maintaining robust computational systems.
3. In-context learning (ICL) using prompts enables LLMs to perform reasonably well at few-shot anomaly detection without fine-tuning, though performance lags behind SFT.
4. Incorporating chain-of-thought prompting in ICL improves interpretability, making it easier to understand the model's decision-making process.

### Analysis and Critique:

The paper presents a promising approach to anomaly detection in computational workflows using large language models. However, there are some potential limitations and areas for improvement:

1. The study focuses on a limited number of datasets, and it is unclear how well the proposed methods would generalize to other types of workflows or anomalies.
2. The performance of ICL models lags behind SFT models, suggesting that there may be room for improvement in the design of prompts or the selection of LLMs for this task.
3. The interpretability of ICL models could be further enhanced by exploring alternative prompting strategies or incorporating additional contextual information.
4. The study does not address potential biases in the pre-trained LL

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-30       |
| Abstract | [https://arxiv.org/abs/2407.17545v1](https://arxiv.org/abs/2407.17545v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.17545v1](https://browse.arxiv.org/html/2407.17545v1)       |
| Truncated       | False       |
| Word Count       | 8769       |