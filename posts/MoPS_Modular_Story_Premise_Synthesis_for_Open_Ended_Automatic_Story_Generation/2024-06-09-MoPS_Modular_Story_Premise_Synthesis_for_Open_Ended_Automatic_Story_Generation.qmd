
---
title: "MoPS: Modular Story Premise Synthesis for Open-Ended Automatic Story Generation"
id: "2406.05690v1"
description: "MoPS generates diverse, fascinating, and original story premises for automatic story generation, outperforming existing methods."
author: Yan Ma, Yu Qiao, Pengfei Liu
date: "2024-06-09"
image: "https://browse.arxiv.org/html/2406.05690v1/extracted/5654269/figures/poster1.png"
categories: ['social-sciences', 'education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.05690v1/extracted/5654269/figures/poster1.png)

### Summary:

The paper introduces Modular Story Premise Synthesis (MoPS), a method for generating diverse and high-quality story premises for open-ended automatic story generation. MoPS breaks down story premises into modules like background and persona, and consists of three phases: (1) pre-collecting a consistent set of candidates for each module, (2) extracting a key path from the nested dictionary as the premise design, and (3) instructing a large language model (LLM) to integrate the design into a coherent premise sentence. The paper presents thorough evaluations demonstrating that MoPS-generated premises excel in diversity, fascination, completeness, and originality compared to those induced from LLMs and captured from public story datasets. The paper also provides the MoPS code suite, along with 7.6k generated premises and 1k extended stories.

### Major Findings:

1. MoPS generates diverse, fascinating, complete, and original story premises by breaking down the premise into modules and gathering module candidates into a hierarchical structure.
2. MoPS-generated premises outperform those generated by LLMs or sourced from public story datasets in terms of diversity, fascination, completeness, and originality.
3. Extended novels and scripts generated from MoPS-generated premises also exhibit higher quality compared to those generated from other sources.

### Analysis and Critique:

While MoPS presents a promising approach to generating diverse and high-quality story premises, there are some potential limitations and areas for improvement. One potential issue is the reliance on LLMs for generating module candidates, which may limit the diversity and innovation of the generated premises. Additionally, the paper does not discuss the potential for human-in-the-loop involvement in the premise generation process, which could further enhance the quality and diversity of the generated premises. Finally, the paper does not provide a detailed analysis of the limitations and biases of the LLMs used in the premise generation process, which could impact the quality and diversity of the generated premises.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-12       |
| Abstract | [https://arxiv.org/abs/2406.05690v1](https://arxiv.org/abs/2406.05690v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.05690v1](https://browse.arxiv.org/html/2406.05690v1)       |
| Truncated       | False       |
| Word Count       | 9468       |