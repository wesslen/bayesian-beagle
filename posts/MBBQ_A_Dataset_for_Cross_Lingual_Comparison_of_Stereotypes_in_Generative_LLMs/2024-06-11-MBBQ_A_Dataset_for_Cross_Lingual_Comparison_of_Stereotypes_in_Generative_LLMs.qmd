
---
title: "MBBQ: A Dataset for Cross-Lingual Comparison of Stereotypes in Generative LLMs"
id: "2406.07243v1"
description: "LLMs exhibit language-dependent biases, with non-English languages suffering more. MBBQ dataset reveals cross-lingual differences in bias behavior."
author: Vera Neplenbroek, Arianna Bisazza, Raquel Fern√°ndez
date: "2024-06-11"
image: "https://browse.arxiv.org/html/2406.07243v1/x1.png"
categories: ['hci', 'social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.07243v1/x1.png)

### Summary:

The paper presents the Multilingual Bias Benchmark for Question-answering (MBBQ), a dataset for cross-lingual comparison of stereotypes in generative large language models (LLMs). The MBBQ dataset is a hand-checked translation of the English BBQ dataset into Dutch, Spanish, and Turkish, focusing on stereotypes commonly held across these languages. The paper also introduces a parallel MBBQ control dataset to measure task performance independently of bias. The authors conducted experiments with several open-source and proprietary LLMs, confirming that some non-English languages suffer from bias more than English, even when controlling for cultural shifts. Significant cross-lingual differences in bias behavior were observed for all except the most accurate models.

### Major Findings:

1. The MBBQ dataset is a valuable resource for investigating bias in multilingual settings and facilitating research on cross-lingual debiasing.
2. The study confirms that some non-English languages suffer from bias more than English, even when controlling for cultural shifts.
3. Significant cross-lingual differences in bias behavior were observed for all except the most accurate models.

### Analysis and Critique:

The paper provides a well-structured and coherent summary of the MBBQ dataset and its potential applications. The authors' experiments with various LLMs highlight the importance of controlling for cultural differences and task accuracy when measuring model bias. However, the paper does not discuss potential limitations, unanswered questions, or conflicting evidence that may have arisen during the research. Additionally, the paper does not address the methodological issues or areas that require further research or clarification.

Overall, the paper presents a valuable contribution to the field of bias in multilingual settings and encourages further research in this area. However, a more comprehensive analysis of the study's limitations and potential areas for improvement would have strengthened the paper's impact.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-23       |
| Abstract | [https://arxiv.org/abs/2406.07243v1](https://arxiv.org/abs/2406.07243v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.07243v1](https://browse.arxiv.org/html/2406.07243v1)       |
| Truncated       | False       |
| Word Count       | 10630       |