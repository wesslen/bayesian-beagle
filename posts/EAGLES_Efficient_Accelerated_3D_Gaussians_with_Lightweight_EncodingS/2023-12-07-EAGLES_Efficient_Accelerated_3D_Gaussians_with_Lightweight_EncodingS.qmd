
---
title: "EAGLES: Efficient Accelerated 3D Gaussians with Lightweight EncodingS"
id: "2312.04564v1"
description: "3D-GS accelerates scene synthesis, uses few Gaussians with quantized representations, reduces memory, and speeds up training and rendering."
author: ['Sharath Girish', 'Kamal Gupta', 'Abhinav Shrivastava']
date: "2023-12-07"
image: "https://browse.arxiv.org/html/2312.04564v1/x1.png"
categories: ['production']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2312.04564v1/x1.png)

### Major Findings 

1. **EAGLES** presents a technique utilizing quantized embeddings to significantly reduce memory storage requirements and a coarse-to-fine training strategy for a faster and more stable optimization of the Gaussian point clouds.
2. The approach results in scene representations with fewer Gaussians and quantized representations, leading to faster training times and rendering speeds for real-time rendering of high resolution scenes.
3. The authors validate the effectiveness of their approach on a variety of datasets and scenes, preserving the visual quality while consuming 10-20 times less memory and achieving faster training and inference speeds.

### Introduction
Neural Radiance Fields have been widely used for 3D scene representations but come with high training and rendering costs. **3D Gaussian splatting (3D-GS)** overcomes these issues with rapid and differentiable rasterization, achieving state-of-the-art reconstruction quality and real-time rendering speeds at 1080p scene resolutions.

### Method
- **Attribute Quantization**: The authors propose quantizing per-point attributes to significantly reduce storage memory. This includes compressing the color and rotation attributes via a latent quantization framework and also quantizing the opacity coefficients.
- **Progressive Training**: A coarse-to-fine training strategy is introduced, gradually increasing the size of the rendered image views over the training iterations until reaching the full resolution.
- **Controlled Densification**: By controlling the frequency of densification of the Gaussians, the authors reduce the number of Gaussians while still maintaining reconstruction performance.

### Related Work
The paper discusses works in neural network compression techniques and neural field compression approaches before focusing on 3D Gaussian point cloud representations.

### Background
The authors provide in-depth background information on 3D Gaussian splatting, including the representation of Gaussian attributes, the rendering process, and the optimization of Gaussians.

### Experiments
The authors implemented their method and evaluated it on a variety of datasets, comparing it with SOTA approaches like MiP-NeRF360, 3D-GS, and other fast NeRF methods. The paper presents benchmark comparisons and ablations to analyze the efficacy of their approach.

### Conclusion
The authors conclude that their approach achieves significant reductions in storage requirements, training cost, faster inference time, and maintains on-par reconstruction quality. They emphasize the potential of their method for 3D reconstruction and novel view synthesis, citing extensive quantitative and qualitative analyses to support their findings.

### Critique
The paper could benefit from a more detailed discussion of potential limitations and challenges in implementing their approach. Additionally, the evaluation metrics could be expanded to include more diverse measures of reconstruction quality and efficiency.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-26       |
| Abstract | [http://arxiv.org/abs/2312.04564v1](http://arxiv.org/abs/2312.04564v1)        |
| HTML     | [https://browse.arxiv.org/html/2312.04564v1](https://browse.arxiv.org/html/2312.04564v1)       |
| Truncated       | False       |
| Word Count       | 8103       |