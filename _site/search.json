[
  {
    "objectID": "posts/Multilingual_Instruction_Tuning_With_Just_a_Pinch_of_Multilinguality/2024-01-03-Multilingual_Instruction_Tuning_With_Just_a_Pinch_of_Multilinguality.html#appendix",
    "href": "posts/Multilingual_Instruction_Tuning_With_Just_a_Pinch_of_Multilinguality/2024-01-03-Multilingual_Instruction_Tuning_With_Just_a_Pinch_of_Multilinguality.html#appendix",
    "title": "Multilingual Instruction Tuning With Just a Pinch of Multilinguality",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01854v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01854v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8421"
  },
  {
    "objectID": "posts/A_Prompt_Learning_Framework_for_Source_Code_Summarization/2023-12-26-A_Prompt_Learning_Framework_for_Source_Code_Summarization.html#appendix",
    "href": "posts/A_Prompt_Learning_Framework_for_Source_Code_Summarization/2023-12-26-A_Prompt_Learning_Framework_for_Source_Code_Summarization.html#appendix",
    "title": "A Prompt Learning Framework for Source Code Summarization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16066v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16066v1\n\n\nTruncated\nTrue\n\n\nWord Count\n16076"
  },
  {
    "objectID": "posts/The_social_graph_based_on_real_data/2024-01-02-The_social_graph_based_on_real_data.html#appendix",
    "href": "posts/The_social_graph_based_on_real_data/2024-01-02-The_social_graph_based_on_real_data.html#appendix",
    "title": "The social graph based on real data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01152v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01152v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3211"
  },
  {
    "objectID": "posts/Ensemble_Learning_to_Assess_Dynamics_of_Affective_Experience_Ratings_and_Physiological_Change/2023-12-26-Ensemble_Learning_to_Assess_Dynamics_of_Affective_Experience_Ratings_and_Physiological_Change.html#appendix",
    "href": "posts/Ensemble_Learning_to_Assess_Dynamics_of_Affective_Experience_Ratings_and_Physiological_Change/2023-12-26-Ensemble_Learning_to_Assess_Dynamics_of_Affective_Experience_Ratings_and_Physiological_Change.html#appendix",
    "title": "Ensemble Learning to Assess Dynamics of Affective Experience Ratings and Physiological Change",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16036v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16036v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8064"
  },
  {
    "objectID": "posts/CMOSE_Comprehensive_Multi_Modality_Online_Student_Engagement_Dataset_with_High_Quality_Labels/2023-12-14-CMOSE_Comprehensive_Multi_Modality_Online_Student_Engagement_Dataset_with_High_Quality_Labels.html#appendix",
    "href": "posts/CMOSE_Comprehensive_Multi_Modality_Online_Student_Engagement_Dataset_with_High_Quality_Labels/2023-12-14-CMOSE_Comprehensive_Multi_Modality_Online_Student_Engagement_Dataset_with_High_Quality_Labels.html#appendix",
    "title": "CMOSE: Comprehensive Multi-Modality Online Student Engagement Dataset with High-Quality Labels",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.09066v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.09066v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11114"
  },
  {
    "objectID": "posts/Coordination_free_Decentralised_Federated_Learning_on_Complex_Networks_Overcoming_Heterogeneity/2023-12-07-Coordination_free_Decentralised_Federated_Learning_on_Complex_Networks_Overcoming_Heterogeneity.html#appendix",
    "href": "posts/Coordination_free_Decentralised_Federated_Learning_on_Complex_Networks_Overcoming_Heterogeneity/2023-12-07-Coordination_free_Decentralised_Federated_Learning_on_Complex_Networks_Overcoming_Heterogeneity.html#appendix",
    "title": "Coordination-free Decentralised Federated Learning on Complex Networks: Overcoming Heterogeneity",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.04504v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.04504v1\n\n\nTruncated\nTrue\n\n\nWord Count\n13550"
  },
  {
    "objectID": "posts/Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach/2023-12-28-Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach.html#major-takeaways",
    "href": "posts/Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach/2023-12-28-Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach.html#major-takeaways",
    "title": "Towards Auto-Modeling of Formal Verification for NextG Protocols: A Multimodal cross- and self-attention Large Language Model Approach",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nAVRE is a new system designed to formalize the verification of Next Generation (NextG) communication protocols, aiming to address the challenges of complexity and scalability in network protocol design and verification.\nIt utilizes Large Language Models (LLMs) to transform protocol descriptions into dependency graphs, resolving ambiguities and capturing design intent, while integrating a transformer model to establish quantifiable dependency relationships through cross- and self-attention mechanisms.\nEnhanced by iterative feedback from the HyFuzz experimental platform, AVRE significantly advances the accuracy and relevance of formal verification in complex communication protocols, offering a groundbreaking approach to validating sophisticated communication systems, achieving an accuracy of 95.94% and an AUC of 0.98."
  },
  {
    "objectID": "posts/Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach/2023-12-28-Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach.html#system-overview",
    "href": "posts/Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach/2023-12-28-Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach.html#system-overview",
    "title": "Towards Auto-Modeling of Formal Verification for NextG Protocols: A Multimodal cross- and self-attention Large Language Model Approach",
    "section": "System Overview",
    "text": "System Overview\n\nIntroduction: Discusses the expansion of 3GPP protocols, the complexity of next-generation networks, and the vulnerability of logical attacks.\nRelated Work: Describes previous methods for transforming natural language descriptions into formal descriptions and the use of LLMs in formal verification.\nContribution: Outlines the novel approach, AVRE, and its components, including the role of CAL and the enhancements provided by iterative feedback from the HyFuzz platform."
  },
  {
    "objectID": "posts/Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach/2023-12-28-Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach.html#methodology",
    "href": "posts/Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach/2023-12-28-Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach.html#methodology",
    "title": "Towards Auto-Modeling of Formal Verification for NextG Protocols: A Multimodal cross- and self-attention Large Language Model Approach",
    "section": "Methodology",
    "text": "Methodology\n\nBuilding Multimodal cross- and self-attention LLM: Details the CAL model’s structure and the incorporation of cross- and self-attention mechanisms.\nBalanced Loss Function: Discusses the utilization of weight-balanced binary cross-entropy loss to address the imbalance in data distribution.\nConnection to Experimental Platform: Explains how the HyFuzz platform serves as both a means to capture design intention and a method for enhancing trustworthiness."
  },
  {
    "objectID": "posts/Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach/2023-12-28-Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach.html#system-performance-assessment",
    "href": "posts/Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach/2023-12-28-Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach.html#system-performance-assessment",
    "title": "Towards Auto-Modeling of Formal Verification for NextG Protocols: A Multimodal cross- and self-attention Large Language Model Approach",
    "section": "System Performance Assessment",
    "text": "System Performance Assessment\n\nCAL Experiment Setting: Describes the configuration of the LLM and the model’s design.\nCAL Experiment Result Analysis: Presents the stable accuracy of CAL, with an accuracy of 95.94% and an AUC of 0.98, outperforming other models.\nCase Study of Design Intention Capturing and Trustworthy Enhancement via the connection to a real-world testbed: Illustrates the effectiveness of the system in capturing design intentions and improving trustworthiness through experimental feedback."
  },
  {
    "objectID": "posts/Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach/2023-12-28-Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach.html#formal-verification-and-attack-model",
    "href": "posts/Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach/2023-12-28-Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach.html#formal-verification-and-attack-model",
    "title": "Towards Auto-Modeling of Formal Verification for NextG Protocols: A Multimodal cross- and self-attention Large Language Model Approach",
    "section": "Formal Verification and Attack Model",
    "text": "Formal Verification and Attack Model\n\nFormal Verification and Attack Model: Demonstrates the generation and comparison of formal dependencies and their application in formal verification."
  },
  {
    "objectID": "posts/Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach/2023-12-28-Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach.html#critique",
    "href": "posts/Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach/2023-12-28-Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach.html#critique",
    "title": "Towards Auto-Modeling of Formal Verification for NextG Protocols: A Multimodal cross- and self-attention Large Language Model Approach",
    "section": "Critique",
    "text": "Critique\nThe paper provides significant insights into the development of a novel system for formal verification of communication protocols. However, a potential problem lies in the need for further validation of the effectiveness of AVRE in practical applications and its scalability to handle a wide range of protocol designs. Additionally, the experimental results and performance analyses could benefit from additional comparisons with existing methods in similar contexts. Overall, the paper presents a promising avenue for advancing the formal verification of NextG protocols."
  },
  {
    "objectID": "posts/Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach/2023-12-28-Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach.html#appendix",
    "href": "posts/Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach/2023-12-28-Towards_Auto_Modeling_of_Formal_Verification_for_NextG_Protocols_A_Multimodal_cross__and_self_attention_Large_Language_Model_Approach.html#appendix",
    "title": "Towards Auto-Modeling of Formal Verification for NextG Protocols: A Multimodal cross- and self-attention Large Language Model Approach",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17353v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17353v2\n\n\nTruncated\nFalse\n\n\nWord Count\n10118"
  },
  {
    "objectID": "posts/If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#main-findings",
    "href": "posts/If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#main-findings",
    "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents",
    "section": "Main Findings",
    "text": "Main Findings\n\nEnhanced Capabilities: The integration of code into large language models (LLMs) enhances their reasoning ability and programming skills, leading to improved performance as intelligent agents (IAs).\nDiverse Benefits: Code empowers LLMs to serve as IAs by improving their decision-making, execution, and self-improvement capabilities through the use of code-centric paradigms.\nIntegration with Functional Ends: LLMs connected to various functional ends through code exhibit versatility, enabling them to handle complex tasks and plan and execute actions."
  },
  {
    "objectID": "posts/If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#introduction",
    "href": "posts/If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#introduction",
    "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents",
    "section": "Introduction",
    "text": "Introduction\nThe paper presents a survey on the benefits of integrating code into LLMs and the emergence of LLMs as IAs. The code-centric paradigm enhances LLMs’ reasoning, planning, execution, and self-improvement capabilities in various contexts."
  },
  {
    "objectID": "posts/If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#preliminaries",
    "href": "posts/If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#preliminaries",
    "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents",
    "section": "Preliminaries",
    "text": "Preliminaries\n\nDefinition of Code: Code is a formal language that is both machine-executable and human-interpretable, including pre-defined formal languages and human-readable programming languages.\nLLM Code Training Methods: LLMs undergo code training through standard language modeling objectives applied to code corpora, involving code pre-training and code fine-tuning methods."
  },
  {
    "objectID": "posts/If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#code-pre-training-boosts-llms-performance",
    "href": "posts/If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#code-pre-training-boosts-llms-performance",
    "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents",
    "section": "Code Pre-Training Boosts LLMs’ Performance",
    "text": "Code Pre-Training Boosts LLMs’ Performance\n\nStrengthen LLMs’ Programming Skills: LLMs trained with code exhibit strong code generation and evaluation abilities, paving the way for various applications in different fields.\nEmpower LLMs’ Complex Reasoning: Code pre-training improves LLMs’ chain-of-thought performance, enhancing their reasoning skills and enabling them to perform complex reasoning tasks.\nEnable LLMs to Capture Structured Knowledge: Code-LLMs unveil superior structural commonsense reasoning, allowing them to understand complex multimedia data and structured information."
  },
  {
    "objectID": "posts/If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#code-connects-llms-to-other-functional-ends",
    "href": "posts/If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#code-connects-llms-to-other-functional-ends",
    "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents",
    "section": "Code Connects LLMs to Other Functional Ends",
    "text": "Code Connects LLMs to Other Functional Ends\n\nRelate LLMs to Digital Ends: LLMs linked to digital ends via a code-centric paradigm, aiding in leveraging textual and multimodal tools for improved performance in various tasks.\nRelate LLMs to Physical Ends: LLMs connected to physical ends, such as robotics and autonomous driving, demonstrating their potential in bridging the gap between physical worlds and AI."
  },
  {
    "objectID": "posts/If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#code-provides-llm-with-an-executable-environment-for-automated-feedback",
    "href": "posts/If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#code-provides-llm-with-an-executable-environment-for-automated-feedback",
    "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents",
    "section": "Code Provides LLM with an Executable Environment for Automated Feedback",
    "text": "Code Provides LLM with an Executable Environment for Automated Feedback\n\nVarious Feedback from Code Execution: Code execution environment provides versatile automated feedback, including simple correctness feedback, textual feedback, and feedback from external evaluation modules.\nMethods for Enhancing LLM’s Performance with Feedback: Feedback derived from code execution and external evaluation modules enhance LLMs through selection-based, prompting-based, and finetuning-based methods."
  },
  {
    "objectID": "posts/If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#application-code-empowered-llms-facilitate-intelligent-agents",
    "href": "posts/If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#application-code-empowered-llms-facilitate-intelligent-agents",
    "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents",
    "section": "Application: Code-empowered LLMs Facilitate Intelligent Agents",
    "text": "Application: Code-empowered LLMs Facilitate Intelligent Agents\n\nDecision Making: Code-empowered LLMs enhance IAs’ decision-making skills through better environment perception and improved planning capabilities.\nExecution: LLMs as IAs benefit from better action grounding and memory organization, leading to improved execution of complex tasks.\nSelf-improvement: LLM-based IAs can self-improve through feedback derived from code execution and external evaluation modules."
  },
  {
    "objectID": "posts/If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#challenges",
    "href": "posts/If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#challenges",
    "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents",
    "section": "Challenges",
    "text": "Challenges\n\nThe causality between code pre-training and LLMs’ reasoning enhancement.\nAcquisition of reasoning beyond code.\nChallenges of applying the code-centric paradigm."
  },
  {
    "objectID": "posts/If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#appendix",
    "href": "posts/If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard_Then_Code_Is_the_Wand_A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#appendix",
    "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00812v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00812v1\n\n\nTruncated\nTrue\n\n\nWord Count\n17975"
  },
  {
    "objectID": "posts/LLaMA_Beyond_English_An_Empirical_Study_on_Language_Capability_Transfer/2024-01-02-LLaMA_Beyond_English_An_Empirical_Study_on_Language_Capability_Transfer.html#appendix",
    "href": "posts/LLaMA_Beyond_English_An_Empirical_Study_on_Language_Capability_Transfer/2024-01-02-LLaMA_Beyond_English_An_Empirical_Study_on_Language_Capability_Transfer.html#appendix",
    "title": "LLaMA Beyond English: An Empirical Study on Language Capability Transfer",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01055v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01055v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7734"
  },
  {
    "objectID": "posts/Cross_target_Stance_Detection_by_Exploiting_Target_Analytical_Perspectives/2024-01-03-Cross_target_Stance_Detection_by_Exploiting_Target_Analytical_Perspectives.html#appendix",
    "href": "posts/Cross_target_Stance_Detection_by_Exploiting_Target_Analytical_Perspectives/2024-01-03-Cross_target_Stance_Detection_by_Exploiting_Target_Analytical_Perspectives.html#appendix",
    "title": "Cross-target Stance Detection by Exploiting Target Analytical Perspectives",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01761v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01761v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3790"
  },
  {
    "objectID": "posts/State_of_What_Art_A_Call_for_Multi_Prompt_LLM_Evaluation/2023-12-31-State_of_What_Art_A_Call_for_Multi_Prompt_LLM_Evaluation.html#appendix",
    "href": "posts/State_of_What_Art_A_Call_for_Multi_Prompt_LLM_Evaluation/2023-12-31-State_of_What_Art_A_Call_for_Multi_Prompt_LLM_Evaluation.html#appendix",
    "title": "State of What Art? A Call for Multi-Prompt LLM Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00595v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00595v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10053"
  },
  {
    "objectID": "posts/Principled_Instructions_Are_All_You_Need_for_Questioning_LLaMA_12_GPT_3.54/2023-12-26-Principled_Instructions_Are_All_You_Need_for_Questioning_LLaMA_12_GPT_3.54.html#appendix",
    "href": "posts/Principled_Instructions_Are_All_You_Need_for_Questioning_LLaMA_12_GPT_3.54/2023-12-26-Principled_Instructions_Are_All_You_Need_for_Questioning_LLaMA_12_GPT_3.54.html#appendix",
    "title": "Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16171v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16171v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5205"
  },
  {
    "objectID": "posts/LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward/2024-01-07-LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward.html#major-takeaways",
    "href": "posts/LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward/2024-01-07-LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward.html#major-takeaways",
    "title": "LLM-Powered Code Vulnerability Repair with Reinforcement Learning and Semantic Reward",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nAutomation Tools and Security: This paper highlights the increasing trend of AI-driven automation tools like GitHub Copilot in software development, which aid developers in functional code development while also potentially causing security vulnerabilities due to pre-training on publicly available repositories.\nSecRepair System: The paper introduces SecRepair, a multipurpose code vulnerability analysis system powered by a large language model, CodeGen2, and reinforced by semantic reward to identify and generate fixed code, provide vulnerability descriptions, and generate code comments.\nEffectiveness of SecRepair: The study demonstrates the effectiveness of SecRepair in identifying, repairing, and describing code vulnerabilities with code comments, as well as the optimization of the program description through reinforcement learning and semantic reward."
  },
  {
    "objectID": "posts/LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward/2024-01-07-LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward.html#introduction",
    "href": "posts/LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward/2024-01-07-LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward.html#introduction",
    "title": "LLM-Powered Code Vulnerability Repair with Reinforcement Learning and Semantic Reward",
    "section": "Introduction",
    "text": "Introduction\n\nCybersecurity Concerns: Cybersecurity and code vulnerabilities are critical concerns in today’s digital age, with vulnerabilities arising from technical glitches, human errors, open-source software reuse, and zero-day attacks.\nAdvancements in AI-driven Tools: Advancements in neural language modeling and AI-assisted automation tools like GitHub Copilot have improved software development but have also raised concerns about their training datasets, generated code outputs, and code security resilience."
  },
  {
    "objectID": "posts/LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward/2024-01-07-LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward.html#approach",
    "href": "posts/LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward/2024-01-07-LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward.html#approach",
    "title": "LLM-Powered Code Vulnerability Repair with Reinforcement Learning and Semantic Reward",
    "section": "Approach",
    "text": "Approach\n\nCode Vulnerability Repair and Description: The SecRepair system is designed to help developers generate fixed code while providing comprehensive descriptions of the vulnerability with a code comment. It leverages reinforcement learning with semantic reward to enhance its capabilities.\nInstruction Dataset: The paper introduces InstructVul, an instruction-based dataset for vulnerability identification, repair, and description with code comment generation. The dataset comprises vulnerability identification, repair, description, and code comment generation tasks."
  },
  {
    "objectID": "posts/LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward/2024-01-07-LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward.html#experiments-and-discussions",
    "href": "posts/LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward/2024-01-07-LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward.html#experiments-and-discussions",
    "title": "LLM-Powered Code Vulnerability Repair with Reinforcement Learning and Semantic Reward",
    "section": "Experiments and Discussions",
    "text": "Experiments and Discussions\n\nEvaluation Metrics: The paper uses BLEU, Rouge-L, and human evaluation scores for generative models’ effectiveness and F1, Precision, Recall, and Accuracy for vulnerability identification tasks.\nResults and Discussions: The study addresses three research questions (RQs) concerning the effectiveness and capabilities of the proposed system for vulnerability analysis, providing in-depth experimental results and discussions for each RQ."
  },
  {
    "objectID": "posts/LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward/2024-01-07-LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward.html#ablation-studies",
    "href": "posts/LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward/2024-01-07-LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward.html#ablation-studies",
    "title": "LLM-Powered Code Vulnerability Repair with Reinforcement Learning and Semantic Reward",
    "section": "Ablation Studies",
    "text": "Ablation Studies\n\nThe paper conducts ablation studies on the impact of temperature and beam size on generative models, highlighting the effect of these components on the performance of the model in code generation tasks."
  },
  {
    "objectID": "posts/LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward/2024-01-07-LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward.html#critique",
    "href": "posts/LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward/2024-01-07-LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward.html#critique",
    "title": "LLM-Powered Code Vulnerability Repair with Reinforcement Learning and Semantic Reward",
    "section": "Critique",
    "text": "Critique\nThe paper demonstrates the development and effectiveness of the SecRepair system in addressing code vulnerabilities. However, it would benefit from providing more detailed real-world case studies and user feedback to further validate the practical usability and impact of the system. Additionally, addressing potential ethics and biases related to AI-generated code and its impact on security would enhance the paper’s scope and relevance."
  },
  {
    "objectID": "posts/LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward/2024-01-07-LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward.html#appendix",
    "href": "posts/LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward/2024-01-07-LLM_Powered_Code_Vulnerability_Repair_with_Reinforcement_Learning_and_Semantic_Reward.html#appendix",
    "title": "LLM-Powered Code Vulnerability Repair with Reinforcement Learning and Semantic Reward",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.03374v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.03374v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8165"
  },
  {
    "objectID": "posts/LLM_Harmony_Multi_Agent_Communication_for_Problem_Solving/2024-01-02-LLM_Harmony_Multi_Agent_Communication_for_Problem_Solving.html#appendix",
    "href": "posts/LLM_Harmony_Multi_Agent_Communication_for_Problem_Solving/2024-01-02-LLM_Harmony_Multi_Agent_Communication_for_Problem_Solving.html#appendix",
    "title": "LLM Harmony: Multi-Agent Communication for Problem Solving",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01312v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01312v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5747"
  },
  {
    "objectID": "posts/A_Generative_AI_Assistant_to_Accelerate_Cloud_Migration/2024-01-03-A_Generative_AI_Assistant_to_Accelerate_Cloud_Migration.html#appendix",
    "href": "posts/A_Generative_AI_Assistant_to_Accelerate_Cloud_Migration/2024-01-03-A_Generative_AI_Assistant_to_Accelerate_Cloud_Migration.html#appendix",
    "title": "A Generative AI Assistant to Accelerate Cloud Migration",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01753v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01753v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2081"
  },
  {
    "objectID": "posts/Fully_Sparse_3D_Panoptic_Occupancy_Prediction/2023-12-28-Fully_Sparse_3D_Panoptic_Occupancy_Prediction.html#appendix",
    "href": "posts/Fully_Sparse_3D_Panoptic_Occupancy_Prediction/2023-12-28-Fully_Sparse_3D_Panoptic_Occupancy_Prediction.html#appendix",
    "title": "Fully Sparse 3D Panoptic Occupancy Prediction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17118v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17118v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7015"
  },
  {
    "objectID": "posts/Pushing_Boundaries_Exploring_Zero_Shot_Object_Classification_with_Large_Multimodal_Models/2023-12-30-Pushing_Boundaries_Exploring_Zero_Shot_Object_Classification_with_Large_Multimodal_Models.html#appendix",
    "href": "posts/Pushing_Boundaries_Exploring_Zero_Shot_Object_Classification_with_Large_Multimodal_Models/2023-12-30-Pushing_Boundaries_Exploring_Zero_Shot_Object_Classification_with_Large_Multimodal_Models.html#appendix",
    "title": "Pushing Boundaries: Exploring Zero Shot Object Classification with Large Multimodal Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00127v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00127v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4620"
  },
  {
    "objectID": "posts/Social_Media_Ready_Caption_Generation_for_Brands/2024-01-03-Social_Media_Ready_Caption_Generation_for_Brands.html#appendix",
    "href": "posts/Social_Media_Ready_Caption_Generation_for_Brands/2024-01-03-Social_Media_Ready_Caption_Generation_for_Brands.html#appendix",
    "title": "Social Media Ready Caption Generation for Brands",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01637v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01637v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7430"
  },
  {
    "objectID": "posts/Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface/2023-12-19-Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface.html#major-findings",
    "href": "posts/Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface/2023-12-19-Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface.html#major-findings",
    "title": "Localization and Discrete Beamforming with a Large Reconfigurable Intelligent Surface",
    "section": "Major Findings",
    "text": "Major Findings\n\nReconfigurable intelligent surfaces (RISs) can provide centimeter-level localization precision in future cellular systems under medium and high signal-to-noise ratios.\nThe proposed fast passive beamforming (FPB) algorithm optimally solves the discrete RIS beamforming problem, reducing the search complexity from exponential order to linear order.\nA two-stage coarse-to-fine localization algorithm leverages time delay and angle information to achieve centimeter-level accuracy with RIS assistance."
  },
  {
    "objectID": "posts/Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface/2023-12-19-Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface.html#introduction",
    "href": "posts/Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface/2023-12-19-Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface.html#introduction",
    "title": "Localization and Discrete Beamforming with a Large Reconfigurable Intelligent Surface",
    "section": "Introduction",
    "text": "Introduction\nIn fifth-generation cellular systems, reconfigurable intelligent surfaces (RISs) are promising for high-precision localization, but their deployment with large numbers of reflecting elements presents challenges in near-field localization and discrete beamforming."
  },
  {
    "objectID": "posts/Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface/2023-12-19-Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface.html#methodology-and-contributions",
    "href": "posts/Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface/2023-12-19-Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface.html#methodology-and-contributions",
    "title": "Localization and Discrete Beamforming with a Large Reconfigurable Intelligent Surface",
    "section": "Methodology and Contributions",
    "text": "Methodology and Contributions\nThe authors propose a scalable partitioned-far-field protocol and a FPB algorithm to solve the discrete RIS beamforming problem. They also introduce a two-stage coarse-to-fine localization algorithm leveraging time delay and angle information."
  },
  {
    "objectID": "posts/Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface/2023-12-19-Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface.html#balanced-signaling-and-localization-problem-formulation",
    "href": "posts/Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface/2023-12-19-Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface.html#balanced-signaling-and-localization-problem-formulation",
    "title": "Localization and Discrete Beamforming with a Large Reconfigurable Intelligent Surface",
    "section": "Balanced Signaling and Localization Problem Formulation",
    "text": "Balanced Signaling and Localization Problem Formulation\n\nBalanced signaling method: Separates received signals into non-line-of-sight (NLoS) and RIS-reflected line-of-sight (LoS) components.\nLocalization problem formulation: Formulates the maximum likelihood estimation problem using separated LoS components."
  },
  {
    "objectID": "posts/Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface/2023-12-19-Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface.html#optimal-algorithm-for-discrete-beamforming-problem",
    "href": "posts/Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface/2023-12-19-Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface.html#optimal-algorithm-for-discrete-beamforming-problem",
    "title": "Localization and Discrete Beamforming with a Large Reconfigurable Intelligent Surface",
    "section": "Optimal Algorithm for Discrete Beamforming Problem",
    "text": "Optimal Algorithm for Discrete Beamforming Problem\nThe authors propose a linear-time FPB algorithm to optimally solve the combinatorial optimization problem of discrete beamforming for RIS reflection coefficients."
  },
  {
    "objectID": "posts/Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface/2023-12-19-Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface.html#coarse-to-fine-localization-algorithm",
    "href": "posts/Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface/2023-12-19-Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface.html#coarse-to-fine-localization-algorithm",
    "title": "Localization and Discrete Beamforming with a Large Reconfigurable Intelligent Surface",
    "section": "Coarse-To-Fine Localization Algorithm",
    "text": "Coarse-To-Fine Localization Algorithm\nThe proposed two-stage localization algorithm consists of coarse and fine localization modules that leverage time delay and angle information for high-precision localization."
  },
  {
    "objectID": "posts/Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface/2023-12-19-Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface.html#simulation-studies",
    "href": "posts/Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface/2023-12-19-Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface.html#simulation-studies",
    "title": "Localization and Discrete Beamforming with a Large Reconfigurable Intelligent Surface",
    "section": "Simulation Studies",
    "text": "Simulation Studies\n\nPassive Beamforming: The FPB algorithm outperforms other methods in achieving higher passive beamforming gain with significantly lower computational complexity.\nCoarse-To-Fine Localization: The proposed coarse-to-fine localization algorithm achieves centimeter-level localization precision under medium and high signal-to-noise ratios."
  },
  {
    "objectID": "posts/Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface/2023-12-19-Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface.html#critique",
    "href": "posts/Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface/2023-12-19-Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface.html#critique",
    "title": "Localization and Discrete Beamforming with a Large Reconfigurable Intelligent Surface",
    "section": "Critique",
    "text": "Critique\nThe paper offers valuable insights into RIS-assisted localization and discrete beamforming. However, it would benefit from more comprehensive real-world validation and scalability analysis for practical deployment.\nOverall, the paper makes significant contributions to the field of RIS-assisted localization and presents efficient algorithms for addressing key challenges in large-scale RIS deployment."
  },
  {
    "objectID": "posts/Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface/2023-12-19-Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface.html#appendix",
    "href": "posts/Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface/2023-12-19-Localization_and_Discrete_Beamforming_with_a_Large_Reconfigurable_Intelligent_Surface.html#appendix",
    "title": "Localization and Discrete Beamforming with a Large Reconfigurable Intelligent Surface",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.12358v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.12358v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12650"
  },
  {
    "objectID": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#summary",
    "href": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#summary",
    "title": "Prompting LLMs with content plans to enhance the summarization of scientific articles",
    "section": "Summary",
    "text": "Summary\nThis paper introduces novel prompting techniques to improve the performance of automatic summarization systems for scientific articles, which are often challenging due to their complexity and length. The paper evaluates various prompting techniques and their impact on different summarization models and input texts. The results show performance gains, particularly for smaller models summarizing sections separately. The findings introduce a new research direction of using prompts to aid smaller models in summarizing scientific articles."
  },
  {
    "objectID": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#findings",
    "href": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#findings",
    "title": "Prompting LLMs with content plans to enhance the summarization of scientific articles",
    "section": "Findings",
    "text": "Findings\n\nChallenges of Scientific Article Summarization: Scientific articles pose difficulties for summarization due to their length, technical vocabulary, complex structures, and irregular organizational formats. This makes summarization challenging for even state-of-the-art natural language processing systems.\nEffectiveness of Prompting Techniques: The paper proposes and evaluates five prompting techniques, showing consistent performance improvements from prompting techniques on smaller models, especially when summarizing sections independently. Smaller models exhibit increases in ROUGE-1 score around 0.1-0.4 when aided by prompts. The results suggest that prompting is an effective approach for overcoming the limitations of smaller summarization systems.\nImplications of the Findings: The findings suggest that prompting techniques enhance the focus of summarization models on core concepts, especially for smaller models, indicating the potential of prompts to aid smaller models in resource-constrained contexts like mobile devices."
  },
  {
    "objectID": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#critique",
    "href": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#critique",
    "title": "Prompting LLMs with content plans to enhance the summarization of scientific articles",
    "section": "Critique",
    "text": "Critique\nThe paper provides valuable insights into the effectiveness of prompting techniques for scientific article summarization. However, the study primarily focuses on model performance metrics and lacks a comprehensive analysis of the semantic quality of the summaries generated. Furthermore, the paper could benefit from discussing potential limitations and challenges in the practical implementation of the proposed prompting techniques. This could include addressing how the approach handles ambiguous or polysemous terms and potential biases in the extraction of key terms from scientific articles. Additionally, the paper could further elaborate on future research directions beyond the specific techniques evaluated in the study."
  },
  {
    "objectID": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#appendix",
    "href": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#appendix",
    "title": "Prompting LLMs with content plans to enhance the summarization of scientific articles",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.08282v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.08282v2\n\n\nTruncated\nFalse\n\n\nWord Count\n9136"
  },
  {
    "objectID": "posts/Venn_Resource_Management_Across_Federated_Learning_Jobs/2023-12-13-Venn_Resource_Management_Across_Federated_Learning_Jobs.html#key-takeaways",
    "href": "posts/Venn_Resource_Management_Across_Federated_Learning_Jobs/2023-12-13-Venn_Resource_Management_Across_Federated_Learning_Jobs.html#key-takeaways",
    "title": "Venn: Resource Management Across Federated Learning Jobs",
    "section": "Key takeaways",
    "text": "Key takeaways\n\nFederated Learning (FL) is growing in popularity, bringing the challenge of managing resource contention among multiple FL jobs training on the same device population.\nExisting resource managers for FL jobs opt for random assignment of devices to FL jobs for simplicity and scalability, leading to poor performance.\nVenn, an FL resource manager, efficiently schedules heterogeneous devices among many FL jobs, improving the average job completion time (JCT) by up to 1.88×."
  },
  {
    "objectID": "posts/Venn_Resource_Management_Across_Federated_Learning_Jobs/2023-12-13-Venn_Resource_Management_Across_Federated_Learning_Jobs.html#introduction",
    "href": "posts/Venn_Resource_Management_Across_Federated_Learning_Jobs/2023-12-13-Venn_Resource_Management_Across_Federated_Learning_Jobs.html#introduction",
    "title": "Venn: Resource Management Across Federated Learning Jobs",
    "section": "Introduction",
    "text": "Introduction\n\nFL enables distributed edge devices to perform collaborative machine learning without moving raw data into the cloud.\nResource management in FL involves several unique characteristics like dynamic availability and heterogeneous resource pools."
  },
  {
    "objectID": "posts/Venn_Resource_Management_Across_Federated_Learning_Jobs/2023-12-13-Venn_Resource_Management_Across_Federated_Learning_Jobs.html#fl-resources",
    "href": "posts/Venn_Resource_Management_Across_Federated_Learning_Jobs/2023-12-13-Venn_Resource_Management_Across_Federated_Learning_Jobs.html#fl-resources",
    "title": "Venn: Resource Management Across Federated Learning Jobs",
    "section": "FL Resources",
    "text": "FL Resources\n\nFL resources exhibit high variance in availability and capacity, as shown by diurnal device availability and device hardware heterogeneity."
  },
  {
    "objectID": "posts/Venn_Resource_Management_Across_Federated_Learning_Jobs/2023-12-13-Venn_Resource_Management_Across_Federated_Learning_Jobs.html#fl-jobs",
    "href": "posts/Venn_Resource_Management_Across_Federated_Learning_Jobs/2023-12-13-Venn_Resource_Management_Across_Federated_Learning_Jobs.html#fl-jobs",
    "title": "Venn: Resource Management Across Federated Learning Jobs",
    "section": "FL Jobs",
    "text": "FL Jobs\n\nAn FL job is executed in multiple rounds that run sequentially for synchronous FL training. The job completion time of an FL job is significantly affected by both scheduling delay and response collection time."
  },
  {
    "objectID": "posts/Venn_Resource_Management_Across_Federated_Learning_Jobs/2023-12-13-Venn_Resource_Management_Across_Federated_Learning_Jobs.html#venn-overview",
    "href": "posts/Venn_Resource_Management_Across_Federated_Learning_Jobs/2023-12-13-Venn_Resource_Management_Across_Federated_Learning_Jobs.html#venn-overview",
    "title": "Venn: Resource Management Across Federated Learning Jobs",
    "section": "Venn Overview",
    "text": "Venn Overview\n\nVenn operates at a layer above all FL jobs, allocating each checked-in resource to individual jobs, optimizing the job-to-device assigning phase. It prioritizes small jobs requiring scarce resources and employs a resource-aware device-to-job matching heuristic to reduce response collection time."
  },
  {
    "objectID": "posts/Venn_Resource_Management_Across_Federated_Learning_Jobs/2023-12-13-Venn_Resource_Management_Across_Federated_Learning_Jobs.html#resource-scheduling-in-venn",
    "href": "posts/Venn_Resource_Management_Across_Federated_Learning_Jobs/2023-12-13-Venn_Resource_Management_Across_Federated_Learning_Jobs.html#resource-scheduling-in-venn",
    "title": "Venn: Resource Management Across Federated Learning Jobs",
    "section": "Resource Scheduling in Venn",
    "text": "Resource Scheduling in Venn\n\nIntersection Resource Scheduling (IRS): Venn addresses the intricate resource contention among FL jobs by formulating it as an IRS problem. It prioritizes jobs within each job group based on their remaining resource demand and employs a two-step approach to optimize the average JCT."
  },
  {
    "objectID": "posts/Venn_Resource_Management_Across_Federated_Learning_Jobs/2023-12-13-Venn_Resource_Management_Across_Federated_Learning_Jobs.html#device-matching",
    "href": "posts/Venn_Resource_Management_Across_Federated_Learning_Jobs/2023-12-13-Venn_Resource_Management_Across_Federated_Learning_Jobs.html#device-matching",
    "title": "Venn: Resource Management Across Federated Learning Jobs",
    "section": "Device Matching",
    "text": "Device Matching\n\nResource-aware tier-based device-to-job matching solution: Venn partitions eligible devices into tiers based on their hardware capabilities and matches devices with jobs to reduce response collection time."
  },
  {
    "objectID": "posts/Venn_Resource_Management_Across_Federated_Learning_Jobs/2023-12-13-Venn_Resource_Management_Across_Federated_Learning_Jobs.html#enhancements",
    "href": "posts/Venn_Resource_Management_Across_Federated_Learning_Jobs/2023-12-13-Venn_Resource_Management_Across_Federated_Learning_Jobs.html#enhancements",
    "title": "Venn: Resource Management Across Federated Learning Jobs",
    "section": "Enhancements",
    "text": "Enhancements\n\nVenn addresses dynamic resource supply and starvation prevention to improve fairness for different job sizes and eligibility types."
  },
  {
    "objectID": "posts/Venn_Resource_Management_Across_Federated_Learning_Jobs/2023-12-13-Venn_Resource_Management_Across_Federated_Learning_Jobs.html#evaluation",
    "href": "posts/Venn_Resource_Management_Across_Federated_Learning_Jobs/2023-12-13-Venn_Resource_Management_Across_Federated_Learning_Jobs.html#evaluation",
    "title": "Venn: Resource Management Across Federated Learning Jobs",
    "section": "Evaluation",
    "text": "Evaluation\n\nVenn improves average JCT across various real-world FL workloads and provides breakdowns to evaluate its scheduling and matching algorithms."
  },
  {
    "objectID": "posts/Venn_Resource_Management_Across_Federated_Learning_Jobs/2023-12-13-Venn_Resource_Management_Across_Federated_Learning_Jobs.html#critique",
    "href": "posts/Venn_Resource_Management_Across_Federated_Learning_Jobs/2023-12-13-Venn_Resource_Management_Across_Federated_Learning_Jobs.html#critique",
    "title": "Venn: Resource Management Across Federated Learning Jobs",
    "section": "Critique",
    "text": "Critique\n\nThe paper did not address potential challenges or limitations associated with the proposed Venn resource management approach.\nThere was no mention of any empirical testing or real-world applications where Venn was deployed and analyzed for performance."
  },
  {
    "objectID": "posts/Venn_Resource_Management_Across_Federated_Learning_Jobs/2023-12-13-Venn_Resource_Management_Across_Federated_Learning_Jobs.html#appendix",
    "href": "posts/Venn_Resource_Management_Across_Federated_Learning_Jobs/2023-12-13-Venn_Resource_Management_Across_Federated_Learning_Jobs.html#appendix",
    "title": "Venn: Resource Management Across Federated Learning Jobs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.08298v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.08298v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13457"
  },
  {
    "objectID": "posts/Semantic_Importance_Aware_Based_for_Multi_User_Communication_Over_MIMO_Fading_Channels/2023-12-26-Semantic_Importance_Aware_Based_for_Multi_User_Communication_Over_MIMO_Fading_Channels.html#appendix",
    "href": "posts/Semantic_Importance_Aware_Based_for_Multi_User_Communication_Over_MIMO_Fading_Channels/2023-12-26-Semantic_Importance_Aware_Based_for_Multi_User_Communication_Over_MIMO_Fading_Channels.html#appendix",
    "title": "Semantic Importance-Aware Based for Multi-User Communication Over MIMO Fading Channels",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16057v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16057v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10037"
  },
  {
    "objectID": "posts/Fairness_Certification_for_Natural_Language_Processing_and_Large_Language_Models/2024-01-02-Fairness_Certification_for_Natural_Language_Processing_and_Large_Language_Models.html#appendix",
    "href": "posts/Fairness_Certification_for_Natural_Language_Processing_and_Large_Language_Models/2024-01-02-Fairness_Certification_for_Natural_Language_Processing_and_Large_Language_Models.html#appendix",
    "title": "Fairness Certification for Natural Language Processing and Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01262v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01262v1\n\n\nTruncated\nTrue\n\n\nWord Count\n51134"
  },
  {
    "objectID": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#major-findings",
    "href": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#major-findings",
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "section": "Major Findings",
    "text": "Major Findings\n\nInstruction-tuned language models struggle to reproduce author-specific style in a few-shot setting, even with recent large LMs such as GPT-3.5.\nA proposed approach using contrastively-trained representations and a combination of generative re-scoring and discriminative control can effectively generate text in an author-specific style in various conditions, including unconditional generation and style transfer.\nThe proposed style transfer approach can be adapted to serve as an effective author anonymization technique, defeating authorship attribution while preserving meaning."
  },
  {
    "objectID": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#introduction",
    "href": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#introduction",
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "section": "Introduction",
    "text": "Introduction\n\nThe paper discusses the problem of generating text in the style of an arbitrary author based on a small writing sample, emphasizing the difficulty of this task due to the sparse signal of stylometric features."
  },
  {
    "objectID": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#preliminaries",
    "href": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#preliminaries",
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "section": "Preliminaries",
    "text": "Preliminaries\n\nThe goal is to produce text in a particular target style while satisfying other criteria, such as diverse outputs and meaning preservation.\nThe proposed approach involves future regressors and energy-based models for non-autoregressive generation."
  },
  {
    "objectID": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#guiding-generations-towards-a-target-style-representation",
    "href": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#guiding-generations-towards-a-target-style-representation",
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "section": "Guiding generations towards a target style representation",
    "text": "Guiding generations towards a target style representation\n\nUsing a regression model to guide a language model to produce text in a target style.\nThe resulting author-specific LM can be incorporated in an energy-based model for non-autoregressive generation."
  },
  {
    "objectID": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#style-control",
    "href": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#style-control",
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "section": "Style Control",
    "text": "Style Control\n\nThe proposed decoding strategy (EBM) performs competitively with large instruction-tuned LMs, outperforming in-context learning.\nInterpolating between two target author style vectors yields interpretable results, indicating that control vectors capture intuitive stylistic features and can successfully reproduce those features in generated text.\nSamples from the proposed approach circumvent machine-generated text detectors at a higher rate and address concerns with producing more in-domain detection data."
  },
  {
    "objectID": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#style-transfer",
    "href": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#style-transfer",
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "section": "Style Transfer",
    "text": "Style Transfer\n\nThe proposed approach achieves style accuracy comparable to large LMs while requiring only a fraction of the number of parameters.\nThe trade-off between stylistic accuracy and content preservation is observed."
  },
  {
    "objectID": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#anonymization",
    "href": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#anonymization",
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "section": "Anonymization",
    "text": "Anonymization\n\nThe proposed style transfer approach succeeds in reducing the detection rate through style transfer, serving as an effective author anonymization technique."
  },
  {
    "objectID": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#detection-of-generated-text",
    "href": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#detection-of-generated-text",
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "section": "Detection of Generated Text",
    "text": "Detection of Generated Text\n\nDetection of LM generated text becomes more tractable with basic classification approaches when more in-domain data is available."
  },
  {
    "objectID": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#related-work",
    "href": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#related-work",
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "section": "Related Work",
    "text": "Related Work\n\nThe paper discusses the limitations of automatic evaluation metrics and the use of discriminative models to guide generation."
  },
  {
    "objectID": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#conclusion",
    "href": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#conclusion",
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "section": "Conclusion",
    "text": "Conclusion\nThe paper addresses the potential applications and broader impact of style-controlled text generation, acknowledging both positive and potential misuse concerns regarding machine-text detection."
  },
  {
    "objectID": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#critique",
    "href": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#critique",
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "section": "Critique",
    "text": "Critique\n\nThe use of automatic metrics for evaluation may not fully capture the nuanced aspects of author-specific style and meaning preservation.\nThe heavy reliance on large corpora of social media data for training style representations might introduce biases and privacy concerns."
  },
  {
    "objectID": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#appendix",
    "href": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#appendix",
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17242v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17242v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12839"
  },
  {
    "objectID": "posts/TeamCAD____A_Multimodal_Interface_for_Remote_Computer_Aided_Design/2023-12-19-TeamCAD____A_Multimodal_Interface_for_Remote_Computer_Aided_Design.html#appendix",
    "href": "posts/TeamCAD____A_Multimodal_Interface_for_Remote_Computer_Aided_Design/2023-12-19-TeamCAD____A_Multimodal_Interface_for_Remote_Computer_Aided_Design.html#appendix",
    "title": "TeamCAD – A Multimodal Interface for Remote Computer Aided Design",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.12309v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.12309v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4768"
  },
  {
    "objectID": "posts/A_Comprehensive_Survey_of_Evaluation_Techniques_for_Recommendation_Systems/2023-12-26-A_Comprehensive_Survey_of_Evaluation_Techniques_for_Recommendation_Systems.html#appendix",
    "href": "posts/A_Comprehensive_Survey_of_Evaluation_Techniques_for_Recommendation_Systems/2023-12-26-A_Comprehensive_Survey_of_Evaluation_Techniques_for_Recommendation_Systems.html#appendix",
    "title": "A Comprehensive Survey of Evaluation Techniques for Recommendation Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16015v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16015v1\n\n\nTruncated\nTrue\n\n\nWord Count\n14462"
  },
  {
    "objectID": "posts/CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation/2024-01-02-CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation.html#major-findings",
    "href": "posts/CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation/2024-01-02-CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation.html#major-findings",
    "title": "CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation",
    "section": "Major Findings",
    "text": "Major Findings\n\nCharacterEval presents a novel Chinese benchmark for evaluating Role-Playing Conversational Agents (RPCAs), addressing the absence of comprehensive benchmarks in the field of emotionally engaging conversational agents.\nThe benchmark introduces a dataset of 1,785 multi-turn role-playing dialogues, featuring 77 characters derived from Chinese novels and scripts, carefully constructed and rigorously controlled for quality.\nThe evaluation approach includes thirteen specific metrics on four dimensions and introduces a role-playing reward model, CharacterRM, based on human annotations, which outperforms GPT-4 in correlation with human judgment."
  },
  {
    "objectID": "posts/CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation/2024-01-02-CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation.html#introduction",
    "href": "posts/CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation/2024-01-02-CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation.html#introduction",
    "title": "CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation",
    "section": "Introduction",
    "text": "Introduction\n\nLarge language models (LLMs) have revolutionized generative agents and opened up new possibilities in various applications, including in Role-Playing Conversational Agents (RPCAs), which engage users in dynamic scenarios as specific characters or roles from existing compositions (e.g., novels, films).\nThere is considerable interest in the multifaceted capabilities of RPCAs, but the absence of a comprehensive benchmark impedes the systematic assessment and comparison of RPCA capabilities."
  },
  {
    "objectID": "posts/CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation/2024-01-02-CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation.html#data-collection",
    "href": "posts/CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation/2024-01-02-CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation.html#data-collection",
    "title": "CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation",
    "section": "Data Collection",
    "text": "Data Collection\n\nThe construction of a dataset for role-playing conversation is complex and requires careful consideration of fidelity to source material, diversity in distribution, multi-turn features, and human-in-the-loop involvement to ensure quality and authenticity.\nThe dataset comprises 1,785 multi-turn role-playing dialogues and 77 leading characters drawn from diverse Chinese novels and scripts, carefully constructed through a process involving GPT-4 extraction, human filtering, and detailed character profiles from Baidu Baike."
  },
  {
    "objectID": "posts/CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation/2024-01-02-CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation.html#evaluation-metric",
    "href": "posts/CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation/2024-01-02-CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation.html#evaluation-metric",
    "title": "CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation",
    "section": "Evaluation Metric",
    "text": "Evaluation Metric\n\nCharacterEval employs a multifaceted evaluation approach, encompassing thirteen specific metrics on four dimensions: conversational ability, character consistency, role-playing attractiveness, and personality back-testing. These metrics are designed to comprehensively assess RPCA capabilities in role-playing conversation."
  },
  {
    "objectID": "posts/CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation/2024-01-02-CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation.html#experiment",
    "href": "posts/CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation/2024-01-02-CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation.html#experiment",
    "title": "CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation",
    "section": "Experiment",
    "text": "Experiment\n\nComprehensive evaluations of existing LLMs on CharacterEval demonstrate that Chinese LLMs exhibit more promising capabilities than GPT-4 in Chinese role-playing conversation.\nThe results indicate that specialized models designed for role-playing dialogues, such as BC-Character-Turbo and MiniMax, outperform general-purpose LLMs like GPT-4 and GPT-3.5 in specific dimensions such as character consistency and role-playing attractiveness."
  },
  {
    "objectID": "posts/CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation/2024-01-02-CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation.html#critique",
    "href": "posts/CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation/2024-01-02-CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation.html#critique",
    "title": "CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation",
    "section": "Critique",
    "text": "Critique\nThe paper presents a comprehensive and rigorous approach to evaluating RPCAs. However, potential limitations and problems to consider include: - The reliance on human annotations for training CharacterRM and evaluating RPCAs may introduce subjectivity and bias. - The research focuses largely on the specific context of Chinese role-playing conversation, which may limit the generalizability of the findings to other languages or cultural contexts. - The complexity in constructing a high-quality dataset may limit scalability and accessibility for researchers in the field."
  },
  {
    "objectID": "posts/CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation/2024-01-02-CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation.html#appendix",
    "href": "posts/CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation/2024-01-02-CharacterEval_A_Chinese_Benchmark_for_Role_Playing_Conversational_Agent_Evaluation.html#appendix",
    "title": "CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01275v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01275v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7604"
  },
  {
    "objectID": "posts/The_Butterfly_Effect_of_Altering_Prompts_How_Small_Changes_and_Jailbreaks_Affect_Large_Language_Model_Performance/2024-01-08-The_Butterfly_Effect_of_Altering_Prompts_How_Small_Changes_and_Jailbreaks_Affect_Large_Language_Model_Performance.html#appendix",
    "href": "posts/The_Butterfly_Effect_of_Altering_Prompts_How_Small_Changes_and_Jailbreaks_Affect_Large_Language_Model_Performance/2024-01-08-The_Butterfly_Effect_of_Altering_Prompts_How_Small_Changes_and_Jailbreaks_Affect_Large_Language_Model_Performance.html#appendix",
    "title": "The Butterfly Effect of Altering Prompts: How Small Changes and Jailbreaks Affect Large Language Model Performance",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.03729v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.03729v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6734"
  },
  {
    "objectID": "posts/Context_aware_Decoding_Reduces_Hallucination_in_Query_focused_Summarization/2023-12-21-Context_aware_Decoding_Reduces_Hallucination_in_Query_focused_Summarization.html#appendix",
    "href": "posts/Context_aware_Decoding_Reduces_Hallucination_in_Query_focused_Summarization/2023-12-21-Context_aware_Decoding_Reduces_Hallucination_in_Query_focused_Summarization.html#appendix",
    "title": "Context-aware Decoding Reduces Hallucination in Query-focused Summarization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.14335v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.14335v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6395"
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#major-takeaways",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#major-takeaways",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nThe article provides guidelines for using the jmlr class with the pmlr class option, offering advice on reducing complications when combining articles into a book.\nIt emphasizes the importance of avoiding obsolete commands and packages, ensuring the document compiles with PDFLATEX, and utilizing convenient cross-referencing commands provided by the jmlr class.\nThe article covers the formatting of equations, vectors, sets, floats (figures, tables, algorithms), description lists, theorem-like environments, citations, and the bibliography, providing detailed instructions for each."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#introduction",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#introduction",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Introduction",
    "text": "Introduction\n\nThe article provides guidelines for using the jmlr class with the pmlr class option to reduce complications when combining articles into a book.\nIt advises against using obsolete commands and packages and emphasizes the importance of ensuring the document compiles with PDFLATEX."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#cross-referencing",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#cross-referencing",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Cross-Referencing",
    "text": "Cross-Referencing\n\nThe jmlr class provides convenient cross-referencing commands for referencing sections, equations, tables, figures, algorithms, theorem-like environments, and appendices.\nExamples and syntax for using these cross-referencing commands are provided."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#equations",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#equations",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Equations",
    "text": "Equations\n\nUnnumbered and numbered single-lined equations should be displayed using specific environments and commands, with examples provided.\nMulti-lined numbered equations should be displayed using the align environment; unnumbered multi-lined equations should be displayed using the align* environment."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#vectors-and-sets",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#vectors-and-sets",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Vectors and Sets",
    "text": "Vectors and Sets\n\nVectors should be typeset using and sets using ."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#floats",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#floats",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Floats",
    "text": "Floats\n\nGuidelines for handling floats (figures, tables, and algorithms) are provided, including best practices for positioning, caption formatting, and the use of specifier."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#tables",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#tables",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Tables",
    "text": "Tables\n\nTables should go in the table environment and are advised to use the booktabs package for horizontal rules."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#figures",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#figures",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Figures",
    "text": "Figures\n\nGuidelines for including and formatting figures, including scaling images and using LATEX code for image creation, are provided."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#sub-figures",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#sub-figures",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Sub-Figures",
    "text": "Sub-Figures\n\nGuidance for creating and referencing sub-figures using the command is provided, with options for alignment and sub-caption width."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#sub-tables",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#sub-tables",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Sub-Tables",
    "text": "Sub-Tables\n\nAn analogous command for sub-tables is introduced, providing similar functionality to for sub-figures."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#algorithms",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#algorithms",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Algorithms",
    "text": "Algorithms\n\nEnumerated textual algorithms can be displayed using the algorithm environment, providing conveniences for indentation and numbering."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#description-lists",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#description-lists",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Description Lists",
    "text": "Description Lists\n\nThe jmlr class offers a description-like environment called altdescription, providing an alternative layout for descriptions."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#theorems-lemmas-etc",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#theorems-lemmas-etc",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Theorems, Lemmas etc",
    "text": "Theorems, Lemmas etc\n\nThe predefined theorem-like environments provided by the jmlr class and how to display proofs are explained, with examples for each environment."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#citations-and-bibliography",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#citations-and-bibliography",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Citations and Bibliography",
    "text": "Citations and Bibliography\n\nGuidelines for citations using natbib and \\bibliography for displaying the bibliography are provided."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#appendices",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#appendices",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Appendices",
    "text": "Appendices\n\nThe article includes examples of appendices and how they should be formatted."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#appendix",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI_NoteAid_EHR_Interaction.html#appendix",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17475v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17475v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4742"
  },
  {
    "objectID": "posts/Latent_Space_Editing_in_Transformer_Based_Flow_Matching/2023-12-17-Latent_Space_Editing_in_Transformer_Based_Flow_Matching.html#appendix",
    "href": "posts/Latent_Space_Editing_in_Transformer_Based_Flow_Matching/2023-12-17-Latent_Space_Editing_in_Transformer_Based_Flow_Matching.html#appendix",
    "title": "Latent Space Editing in Transformer-Based Flow Matching",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10825v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10825v1\n\n\nTruncated\nTrue\n\n\nWord Count\n13723"
  },
  {
    "objectID": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#major-takeaways",
    "href": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#major-takeaways",
    "title": "DePRL: Achieving Linear Convergence Speedup in Personalized Decentralized Learning with Shared Representations",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nDePRL is a personalized decentralized learning algorithm that achieves linear speedup for convergence with general non-linear representations.\nThe algorithm leverages representation learning theory to learn a global representation collaboratively among all workers and a user-specific local head for each worker.\nExperimental results show the superiority of DePRL in data heterogeneous environments."
  },
  {
    "objectID": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#abstract",
    "href": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#abstract",
    "title": "DePRL: Achieving Linear Convergence Speedup in Personalized Decentralized Learning with Shared Representations",
    "section": "Abstract",
    "text": "Abstract\nDePRL is introduced as a new personalized decentralized learning algorithm using shared representations. It achieves a linear speedup for convergence with general non-linear representations, addressing the challenge of data heterogeneity. Experimental results support the algorithm’s superiority in data heterogeneous environments."
  },
  {
    "objectID": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#introduction",
    "href": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#introduction",
    "title": "DePRL: Achieving Linear Convergence Speedup in Personalized Decentralized Learning with Shared Representations",
    "section": "Introduction",
    "text": "Introduction\n\nDecentralized learning has emerged as an alternative to the parameter-server framework, addressing communication burden and scalability issues.\nConventional decentralized learning struggles with data heterogeneity, leading to poor performance on individual workers.\nPersonalized decentralized learning is crucial for achieving personalized models for each worker."
  },
  {
    "objectID": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#deprl-algorithm",
    "href": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#deprl-algorithm",
    "title": "DePRL: Achieving Linear Convergence Speedup in Personalized Decentralized Learning with Shared Representations",
    "section": "DePRL Algorithm",
    "text": "DePRL Algorithm\n\nDePRL leverages ideas from representation learning theory to learn a global representation collaboratively among all workers and a user-specific local head for each worker.\nThe algorithm achieves a linear speedup for convergence with respect to the number of workers, allowing for efficient leveraging of massive parallelism."
  },
  {
    "objectID": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#system-model-and-problem-formulation",
    "href": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#system-model-and-problem-formulation",
    "title": "DePRL: Achieving Linear Convergence Speedup in Personalized Decentralized Learning with Shared Representations",
    "section": "System Model and Problem Formulation",
    "text": "System Model and Problem Formulation\n\nDescribes the consensus-based decentralized learning model and introduces the concept of personalization via common representation.\nOutlines the optimization problem for decentralized learning and the challenges associated with shared representations."
  },
  {
    "objectID": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#convergence-analysis",
    "href": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#convergence-analysis",
    "title": "DePRL: Achieving Linear Convergence Speedup in Personalized Decentralized Learning with Shared Representations",
    "section": "Convergence Analysis",
    "text": "Convergence Analysis\n\nIntroduces the notion of -approximation solution and presents assumptions for the convergence analysis.\nProvides a rigorous analysis of the convergence of DePRL with general non-linear representations, showcasing its linear speedup for convergence."
  },
  {
    "objectID": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#experiments",
    "href": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#experiments",
    "title": "DePRL: Achieving Linear Convergence Speedup in Personalized Decentralized Learning with Shared Representations",
    "section": "Experiments",
    "text": "Experiments\n\nEvaluates the performance of DePRL on different datasets with representative DNN models and compares it with a set of baselines.\nShows the superior performance of DePRL in data heterogeneous environments through test accuracy, generalization to new workers, and speedup comparisons."
  },
  {
    "objectID": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#additional-discussions-on-shared-representations-for-decentralized-and-ps-frameworks",
    "href": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#additional-discussions-on-shared-representations-for-decentralized-and-ps-frameworks",
    "title": "DePRL: Achieving Linear Convergence Speedup in Personalized Decentralized Learning with Shared Representations",
    "section": "Additional Discussions on Shared Representations for Decentralized and PS Frameworks",
    "text": "Additional Discussions on Shared Representations for Decentralized and PS Frameworks\n\nProvides an illustrative example of conventional decentralized learning framework and a PS-based framework with shared representations, comparing them with DePRL."
  },
  {
    "objectID": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#proof-of-theorem-1",
    "href": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#proof-of-theorem-1",
    "title": "DePRL: Achieving Linear Convergence Speedup in Personalized Decentralized Learning with Shared Representations",
    "section": "Proof of Theorem 1",
    "text": "Proof of Theorem 1\n\nPresents the proof for Theorem 1, demonstrating the convergence of DePRL with respect to the number of workers."
  },
  {
    "objectID": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#proof-of-corollary-1",
    "href": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#proof-of-corollary-1",
    "title": "DePRL: Achieving Linear Convergence Speedup in Personalized Decentralized Learning with Shared Representations",
    "section": "Proof of Corollary 1",
    "text": "Proof of Corollary 1\n\nProves Corollary 1, which showcases the convergence rate of DePRL with respect to the number of workers."
  },
  {
    "objectID": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#additional-experimental-details-and-results",
    "href": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#additional-experimental-details-and-results",
    "title": "DePRL: Achieving Linear Convergence Speedup in Personalized Decentralized Learning with Shared Representations",
    "section": "Additional Experimental Details and Results",
    "text": "Additional Experimental Details and Results\n\nDetails the experimental setup, including datasets, models, and hyperparameters used in the experiments.\nDiscusses the impact of local head update steps and the number of total workers on the performance of DePRL.\nAnalyzes consensus errors and showcases how DePRL performs with different levels of heterogeneity across workers."
  },
  {
    "objectID": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#critique",
    "href": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#critique",
    "title": "DePRL: Achieving Linear Convergence Speedup in Personalized Decentralized Learning with Shared Representations",
    "section": "Critique",
    "text": "Critique\nThe paper effectively introduces a novel algorithm, DePRL, and provides an in-depth convergence analysis. However, it would benefit from a more comprehensive comparison with existing methods in the field, such as a detailed evaluation against a wider range of baselines, including state-of-the-art decentralized learning algorithms. Furthermore, the generalization of DePRL to real-world applications and the potential challenges in practical implementation could be further discussed."
  },
  {
    "objectID": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#appendix",
    "href": "posts/DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations/2023-12-17-DePRL_Achieving_Linear_Convergence_Speedup_in_Personalized_Decentralized_Learning_with_Shared_Representations.html#appendix",
    "title": "DePRL: Achieving Linear Convergence Speedup in Personalized Decentralized Learning with Shared Representations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10815v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10815v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11278"
  },
  {
    "objectID": "posts/Socially_Responsible_Computing_in_an_Introductory_Course/2024-01-02-Socially_Responsible_Computing_in_an_Introductory_Course.html#major-takeaways",
    "href": "posts/Socially_Responsible_Computing_in_an_Introductory_Course/2024-01-02-Socially_Responsible_Computing_in_an_Introductory_Course.html#major-takeaways",
    "title": "Socially Responsible Computing in an Introductory Course",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nThe paper introduces a piloted introductory Java programming course that integrates ethical and socially responsible considerations across modules. The data suggests that students found the inclusion of the social context in technical assignments to be more motivating and expressed greater agency in realizing social change.\nThe paper highlights the importance of ensuring goal congruity, emphasizing that students need to perceive an alignment between their personal goals and their ability to fulfill those goals by participating in the field of study. In computing education, a greater emphasis on agentic goals, with an inward focus, has been found to be a barrier in enhancing diversity and inclusion in computing.\nThe paper acknowledges the challenges in integrating ethics into computer science (CS) courses and emphasizes the need for praxis-oriented computing courses that build upon ethical considerations toward encouraging students to take responsibility by understanding the power and social impact of technology — engaging with socially responsible computing."
  },
  {
    "objectID": "posts/Socially_Responsible_Computing_in_an_Introductory_Course/2024-01-02-Socially_Responsible_Computing_in_an_Introductory_Course.html#our-curricular-approach",
    "href": "posts/Socially_Responsible_Computing_in_an_Introductory_Course/2024-01-02-Socially_Responsible_Computing_in_an_Introductory_Course.html#our-curricular-approach",
    "title": "Socially Responsible Computing in an Introductory Course",
    "section": "Our Curricular Approach",
    "text": "Our Curricular Approach\n\nComputing Around Us: The course started with an examination of the impact of computing on society and discussions on ethical reasoning, power, and social impact analysis. Emphasis was placed on considering impact on individual, communal, and societal levels.\nComputing By Us and For Us: The course then transitioned into learning Java programming through socially-grounded assignments, projects intertwining social and technical issues, and individual and collective reflections.\nData Sources and Analysis: Data was collected through optional surveys and analyzed to understand the students’ perceptions and reflections on the course."
  },
  {
    "objectID": "posts/Socially_Responsible_Computing_in_an_Introductory_Course/2024-01-02-Socially_Responsible_Computing_in_an_Introductory_Course.html#findings",
    "href": "posts/Socially_Responsible_Computing_in_an_Introductory_Course/2024-01-02-Socially_Responsible_Computing_in_an_Introductory_Course.html#findings",
    "title": "Socially Responsible Computing in an Introductory Course",
    "section": "Findings",
    "text": "Findings\n\nUnderstanding Computing in a Social Context: Students expressed appreciation for addressing real-world challenges and found the integration of programming with social issues to be meaningful.\nAwareness of Justice and Power Relations: Through the projects, students grappled with power, especially developers’ power, and computing limitations in the face of structural issues.\nPersonal Relevance and Responsibilities: Students recognized their roles in addressing societal challenges and considered their social responsibilities during assignments and projects.\nLearning and Conceptual Integration: The integration of programming with social challenges deepened their understanding of both programming and social problems."
  },
  {
    "objectID": "posts/Socially_Responsible_Computing_in_an_Introductory_Course/2024-01-02-Socially_Responsible_Computing_in_an_Introductory_Course.html#discussion-and-conclusion",
    "href": "posts/Socially_Responsible_Computing_in_an_Introductory_Course/2024-01-02-Socially_Responsible_Computing_in_an_Introductory_Course.html#discussion-and-conclusion",
    "title": "Socially Responsible Computing in an Introductory Course",
    "section": "Discussion and Conclusion",
    "text": "Discussion and Conclusion\n\nThe paper outlines several challenges faced in the implementation of socially responsible computing in the curriculum, including the need to build trust with and among students, the challenge of being vulnerable to engage in discussions, and the difficulty in dovetailing technical problems with social issues.\nThe authors emphasize the importance of ensuring students grasp the limitations of individual responsibilities and acknowledge the need for corporate accountability in socially responsible computing."
  },
  {
    "objectID": "posts/Socially_Responsible_Computing_in_an_Introductory_Course/2024-01-02-Socially_Responsible_Computing_in_an_Introductory_Course.html#critique-and-potential-problems",
    "href": "posts/Socially_Responsible_Computing_in_an_Introductory_Course/2024-01-02-Socially_Responsible_Computing_in_an_Introductory_Course.html#critique-and-potential-problems",
    "title": "Socially Responsible Computing in an Introductory Course",
    "section": "Critique and Potential Problems",
    "text": "Critique and Potential Problems\nThe paper provides valuable insights into the integration of socially responsible computing in computer science education. However, there are a few potential problems to consider, including: - The reliance on student reflections and survey responses as the primary data source may introduce subjective bias and may not provide a comprehensive understanding of the course’s effectiveness. - The challenges faced in the implementation of the course are outlined, but detailed strategies for addressing these challenges are not provided, which may limit the practical applicability of the findings.\nOverall, while the paper contributes to the discourse on integrating socially responsible computing in CS education, a more in-depth exploration of the practical implications and potential solutions to the identified challenges would enhance its impact."
  },
  {
    "objectID": "posts/Socially_Responsible_Computing_in_an_Introductory_Course/2024-01-02-Socially_Responsible_Computing_in_an_Introductory_Course.html#appendix",
    "href": "posts/Socially_Responsible_Computing_in_an_Introductory_Course/2024-01-02-Socially_Responsible_Computing_in_an_Introductory_Course.html#appendix",
    "title": "Socially Responsible Computing in an Introductory Course",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01285v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01285v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10142"
  },
  {
    "objectID": "posts/MARG_Multi_Agent_Review_Generation_for_Scientific_Papers/2024-01-08-MARG_Multi_Agent_Review_Generation_for_Scientific_Papers.html#appendix",
    "href": "posts/MARG_Multi_Agent_Review_Generation_for_Scientific_Papers/2024-01-08-MARG_Multi_Agent_Review_Generation_for_Scientific_Papers.html#appendix",
    "title": "MARG: Multi-Agent Review Generation for Scientific Papers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.04259v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.04259v1\n\n\nTruncated\nTrue\n\n\nWord Count\n41968"
  },
  {
    "objectID": "posts/The_Critique_of_Critique/2024-01-09-The_Critique_of_Critique.html#appendix",
    "href": "posts/The_Critique_of_Critique/2024-01-09-The_Critique_of_Critique.html#appendix",
    "title": "The Critique of Critique",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.04518v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.04518v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8182"
  },
  {
    "objectID": "posts/Uncertainty_Resolution_in_Misinformation_Detection/2024-01-02-Uncertainty_Resolution_in_Misinformation_Detection.html#appendix",
    "href": "posts/Uncertainty_Resolution_in_Misinformation_Detection/2024-01-02-Uncertainty_Resolution_in_Misinformation_Detection.html#appendix",
    "title": "Uncertainty Resolution in Misinformation Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01197v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01197v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7771"
  },
  {
    "objectID": "posts/The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences/2024-01-04-The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences.html#major-takeaways",
    "href": "posts/The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences/2024-01-04-The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences.html#major-takeaways",
    "title": "The Effects of Generative AI on Computing Students’ Help-Seeking Preferences",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nGenerative AI tools, such as ChatGPT, are being adopted by computing students, but have not yet fully replaced traditional help resources.\nStudents’ help-seeking preferences vary across different tasks, and they often prioritize convenience, iteration, and avoiding social pressures when using generative AI tools.\nThe quality of assistance students receive from generative AI tools is dependent on their ability to formulate effective help requests and evaluate the responses."
  },
  {
    "objectID": "posts/The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences/2024-01-04-The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences.html#abstract-and-introduction",
    "href": "posts/The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences/2024-01-04-The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences.html#abstract-and-introduction",
    "title": "The Effects of Generative AI on Computing Students’ Help-Seeking Preferences",
    "section": "Abstract and Introduction",
    "text": "Abstract and Introduction\n\nAbstract\n\nHelp-seeking is essential for computing students, and the emergence of generative AI tools like ChatGPT offers a new on-demand resource.\nThis paper investigates computing students’ help-seeking preferences and experiences with generative AI tools through surveys and interviews.\nPreliminary evidence suggests that generative AI tools have not fully replaced traditional help resources, and using these tools requires developing the skill of harnessing their capabilities.\n\n\n\nIntroduction\n\nThe introduction explores the historical and recent emergence of help-seeking resources for students, focusing on the recent availability of generative AI tools like ChatGPT.\nIt sets the context for the study by discussing the potential impact of generative AI tools on students’ help-seeking preferences in computing education classes.\nThe research questions pertaining to help-seeking resource usage, influencing factors, and comparisons with other resources are introduced."
  },
  {
    "objectID": "posts/The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences/2024-01-04-The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences.html#related-work",
    "href": "posts/The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences/2024-01-04-The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences.html#related-work",
    "title": "The Effects of Generative AI on Computing Students’ Help-Seeking Preferences",
    "section": "Related Work",
    "text": "Related Work\n\nHelp-Seeking Behaviors and Challenges\n\nEffective help-seeking is vital for academic success, but students encounter socio-emotional and decision-making barriers when seeking help from peers, instructors, and online resources.\nThe barriers guide students’ decisions in choosing which help resources to utilize and when to engage with them based on quality and availability.\n\n\n\nHelp-Seeking in Computing Education\n\nUndergraduate computing students face challenges related to learning programming and seeking help, with a focus on troubleshooting, self-directed exploration, and prioritizing online tools over peers and instructors.\n\n\n\nGenerative AI in Computing Education\n\nThe potential for using generative AI in computing classrooms is discussed, including its capabilities in providing explanations, enhancing error messages, identifying bugs, and creating instructional materials and programming assignments."
  },
  {
    "objectID": "posts/The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences/2024-01-04-The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences.html#methodology",
    "href": "posts/The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences/2024-01-04-The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences.html#methodology",
    "title": "The Effects of Generative AI on Computing Students’ Help-Seeking Preferences",
    "section": "Methodology",
    "text": "Methodology\n\nThe methodology section details the participant recruitment process, the survey study, and the interview study conducted to evaluate research questions.\nIt provides insights into the design of survey questions and interview questions, along with the analysis methods used for both studies."
  },
  {
    "objectID": "posts/The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences/2024-01-04-The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences.html#results",
    "href": "posts/The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences/2024-01-04-The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences.html#results",
    "title": "The Effects of Generative AI on Computing Students’ Help-Seeking Preferences",
    "section": "Results",
    "text": "Results\n\nFrequency of Usage\n\nStudents heavily rely on internet resources for help-seeking, but generative AI tools like ChatGPT are also used, particularly for tasks like debugging and writing code.\nChatGPT usage varies across tasks, with students utilizing it more for certain tasks.\n\n\n\nContext of Usage\n\nStudents’ use of help-seeking resources varies across different tasks, with the internet being the most preferred method overall.\nThe experiences with using generative AI tools like ChatGPT for learning new concepts, writing code, debugging, and developing test cases are detailed with quotes from the interviews.\n\n\n\nFactors Influencing Usage\n\nTrust, trade-offs between convenience and quality, social aspects, and the ability for iteration are explored as factors influencing students’ usage of generative AI tools.\nThe perceived trade-off between efficient and accurate help, the social dynamics of help-seeking, and the potential for rapid iteration and follow-up questions with generative AI tools are highlighted."
  },
  {
    "objectID": "posts/The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences/2024-01-04-The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences.html#discussion",
    "href": "posts/The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences/2024-01-04-The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences.html#discussion",
    "title": "The Effects of Generative AI on Computing Students’ Help-Seeking Preferences",
    "section": "Discussion",
    "text": "Discussion\n\nThe discussion provides insights into students’ early adoption of generative AI tools for help-seeking and the significant barriers that still exist.\nIt emphasizes the importance of students’ ability to use generative AI tools effectively and the need for instructors to create pedagogical materials that guide students in maximizing the utility of these tools.\nThe limitations of the study and the need for future research with larger and more diverse samples are acknowledged."
  },
  {
    "objectID": "posts/The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences/2024-01-04-The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences.html#conclusion",
    "href": "posts/The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences/2024-01-04-The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences.html#conclusion",
    "title": "The Effects of Generative AI on Computing Students’ Help-Seeking Preferences",
    "section": "Conclusion",
    "text": "Conclusion\n\nThe study provides critical insights into how students are incorporating generative AI tools into their help-seeking process and the diverse patterns in their utilization and preferences.\nIt highlights the potential benefits and challenges associated with using generative AI tools for help-seeking and the need for additional research to understand students’ abilities to use these tools effectively."
  },
  {
    "objectID": "posts/The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences/2024-01-04-The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences.html#appendix",
    "href": "posts/The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences/2024-01-04-The_Effects_of_Generative_AI_on_Computing_Students_Help_Seeking_Preferences.html#appendix",
    "title": "The Effects of Generative AI on Computing Students’ Help-Seeking Preferences",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.02262v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.02262v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11637"
  },
  {
    "objectID": "posts/When_Metaverses_Meet_Vehicle_Road_Cooperation_Multi_Agent_DRL_Based_Stackelberg_Game_for_Vehicular_Twins_Migration/2023-12-28-When_Metaverses_Meet_Vehicle_Road_Cooperation_Multi_Agent_DRL_Based_Stackelberg_Game_for_Vehicular_Twins_Migration.html#major-findings",
    "href": "posts/When_Metaverses_Meet_Vehicle_Road_Cooperation_Multi_Agent_DRL_Based_Stackelberg_Game_for_Vehicular_Twins_Migration/2023-12-28-When_Metaverses_Meet_Vehicle_Road_Cooperation_Multi_Agent_DRL_Based_Stackelberg_Game_for_Vehicular_Twins_Migration.html#major-findings",
    "title": "When Metaverses Meet Vehicle Road Cooperation: Multi-Agent DRL-Based Stackelberg Game for Vehicular Twins Migration",
    "section": "Major Findings",
    "text": "Major Findings\n\nThe paper proposes a novel incentive mechanism for Vehicular Metaverses that integrates social effects among Vehicular Twin Providers (MSPs) and competitiveness among RoadSide Units (MRPs) in the form of a Stackelberg game with multi-leader multi-follower.\nIt demonstrates the existence and uniqueness of the Stackelberg Equilibrium using the backward induction method and obtains specific equilibrium solutions using the ADMM algorithm.\nThe paper introduces the MALPPO algorithm based on LSTM and PPO to find optimal solutions in a multi-agent environment with privacy protection requirements, achieving superior performance compared to baseline approaches."
  },
  {
    "objectID": "posts/When_Metaverses_Meet_Vehicle_Road_Cooperation_Multi_Agent_DRL_Based_Stackelberg_Game_for_Vehicular_Twins_Migration/2023-12-28-When_Metaverses_Meet_Vehicle_Road_Cooperation_Multi_Agent_DRL_Based_Stackelberg_Game_for_Vehicular_Twins_Migration.html#system-overview",
    "href": "posts/When_Metaverses_Meet_Vehicle_Road_Cooperation_Multi_Agent_DRL_Based_Stackelberg_Game_for_Vehicular_Twins_Migration/2023-12-28-When_Metaverses_Meet_Vehicle_Road_Cooperation_Multi_Agent_DRL_Based_Stackelberg_Game_for_Vehicular_Twins_Migration.html#system-overview",
    "title": "When Metaverses Meet Vehicle Road Cooperation: Multi-Agent DRL-Based Stackelberg Game for Vehicular Twins Migration",
    "section": "System Overview",
    "text": "System Overview\n\nVehicular Metaverses Model: Merges the Metaverse within autonomous vehicles and intelligent roads to provide immersive services to Vehicular Metaverse Users (VMUs) through Vehicular Twins (VTs).\nVT Migration Process: Due to constrained RoadSide Unit (RSU) coverage and consistently moving vehicles, necessitates migration of VTs between RSUs to ensure uninterrupted Metaverse services."
  },
  {
    "objectID": "posts/When_Metaverses_Meet_Vehicle_Road_Cooperation_Multi_Agent_DRL_Based_Stackelberg_Game_for_Vehicular_Twins_Migration/2023-12-28-When_Metaverses_Meet_Vehicle_Road_Cooperation_Multi_Agent_DRL_Based_Stackelberg_Game_for_Vehicular_Twins_Migration.html#methodology",
    "href": "posts/When_Metaverses_Meet_Vehicle_Road_Cooperation_Multi_Agent_DRL_Based_Stackelberg_Game_for_Vehicular_Twins_Migration/2023-12-28-When_Metaverses_Meet_Vehicle_Road_Cooperation_Multi_Agent_DRL_Based_Stackelberg_Game_for_Vehicular_Twins_Migration.html#methodology",
    "title": "When Metaverses Meet Vehicle Road Cooperation: Multi-Agent DRL-Based Stackelberg Game for Vehicular Twins Migration",
    "section": "Methodology",
    "text": "Methodology\n\nIncentive Mechanism: Formulates a game-theoretic incentive mechanism with multi-leader multi-follower to optimize VT migration and incorporates positive social effects among MSPs.\nPrivacy Protection: Proposes the MALPPO algorithm based on deep reinforcement learning to address incomplete information and security concerns in the Stackelberg game."
  },
  {
    "objectID": "posts/When_Metaverses_Meet_Vehicle_Road_Cooperation_Multi_Agent_DRL_Based_Stackelberg_Game_for_Vehicular_Twins_Migration/2023-12-28-When_Metaverses_Meet_Vehicle_Road_Cooperation_Multi_Agent_DRL_Based_Stackelberg_Game_for_Vehicular_Twins_Migration.html#simulation-results",
    "href": "posts/When_Metaverses_Meet_Vehicle_Road_Cooperation_Multi_Agent_DRL_Based_Stackelberg_Game_for_Vehicular_Twins_Migration/2023-12-28-When_Metaverses_Meet_Vehicle_Road_Cooperation_Multi_Agent_DRL_Based_Stackelberg_Game_for_Vehicular_Twins_Migration.html#simulation-results",
    "title": "When Metaverses Meet Vehicle Road Cooperation: Multi-Agent DRL-Based Stackelberg Game for Vehicular Twins Migration",
    "section": "Simulation Results",
    "text": "Simulation Results\n\nConvergence Analysis: Demonstrates superior performance of the MALPPO algorithm in terms of reward and convergence speed compared to baseline methods.\nParameter Influence Analysis: Examines the impact of the number of MSPs and MRPs, average cost and satisfaction coefficients, and social coefficient on system performance and utility."
  },
  {
    "objectID": "posts/When_Metaverses_Meet_Vehicle_Road_Cooperation_Multi_Agent_DRL_Based_Stackelberg_Game_for_Vehicular_Twins_Migration/2023-12-28-When_Metaverses_Meet_Vehicle_Road_Cooperation_Multi_Agent_DRL_Based_Stackelberg_Game_for_Vehicular_Twins_Migration.html#critique",
    "href": "posts/When_Metaverses_Meet_Vehicle_Road_Cooperation_Multi_Agent_DRL_Based_Stackelberg_Game_for_Vehicular_Twins_Migration/2023-12-28-When_Metaverses_Meet_Vehicle_Road_Cooperation_Multi_Agent_DRL_Based_Stackelberg_Game_for_Vehicular_Twins_Migration.html#critique",
    "title": "When Metaverses Meet Vehicle Road Cooperation: Multi-Agent DRL-Based Stackelberg Game for Vehicular Twins Migration",
    "section": "Critique",
    "text": "Critique\nThe paper provides a comprehensive approach for optimizing VT migration in Vehicular Metaverses. However, the simulation results could be strengthened with a comparison against real-world data or field experiments.\nOverall, the proposed MALPPO algorithm presents a promising solution for optimizing the Stackelberg game and addressing privacy protection concerns in Vehicular Metaverses."
  },
  {
    "objectID": "posts/When_Metaverses_Meet_Vehicle_Road_Cooperation_Multi_Agent_DRL_Based_Stackelberg_Game_for_Vehicular_Twins_Migration/2023-12-28-When_Metaverses_Meet_Vehicle_Road_Cooperation_Multi_Agent_DRL_Based_Stackelberg_Game_for_Vehicular_Twins_Migration.html#appendix",
    "href": "posts/When_Metaverses_Meet_Vehicle_Road_Cooperation_Multi_Agent_DRL_Based_Stackelberg_Game_for_Vehicular_Twins_Migration/2023-12-28-When_Metaverses_Meet_Vehicle_Road_Cooperation_Multi_Agent_DRL_Based_Stackelberg_Game_for_Vehicular_Twins_Migration.html#appendix",
    "title": "When Metaverses Meet Vehicle Road Cooperation: Multi-Agent DRL-Based Stackelberg Game for Vehicular Twins Migration",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17081v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17081v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11998"
  },
  {
    "objectID": "posts/Large_Language_Models_for_Mathematicians/2023-12-07-Large_Language_Models_for_Mathematicians.html#appendix",
    "href": "posts/Large_Language_Models_for_Mathematicians/2023-12-07-Large_Language_Models_for_Mathematicians.html#appendix",
    "title": "Large Language Models for Mathematicians",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.04556v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.04556v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13153"
  },
  {
    "objectID": "posts/The_Media_Bias_Taxonomy_A_Systematic_Literature_Review_on_the_Forms_and_Automated_Detection_of_Media_Bias/2023-12-26-The_Media_Bias_Taxonomy_A_Systematic_Literature_Review_on_the_Forms_and_Automated_Detection_of_Media_Bias.html#appendix",
    "href": "posts/The_Media_Bias_Taxonomy_A_Systematic_Literature_Review_on_the_Forms_and_Automated_Detection_of_Media_Bias/2023-12-26-The_Media_Bias_Taxonomy_A_Systematic_Literature_Review_on_the_Forms_and_Automated_Detection_of_Media_Bias.html#appendix",
    "title": "The Media Bias Taxonomy: A Systematic Literature Review on the Forms and Automated Detection of Media Bias",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16148v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16148v1\n\n\nTruncated\nTrue\n\n\nWord Count\n24383"
  },
  {
    "objectID": "posts/ICL_Markup_Structuring_In_Context_Learning_using_Soft_Token_Tags/2023-12-12-ICL_Markup_Structuring_In_Context_Learning_using_Soft_Token_Tags.html#appendix",
    "href": "posts/ICL_Markup_Structuring_In_Context_Learning_using_Soft_Token_Tags/2023-12-12-ICL_Markup_Structuring_In_Context_Learning_using_Soft_Token_Tags.html#appendix",
    "title": "ICL Markup: Structuring In-Context Learning using Soft-Token Tags",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.07405v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.07405v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12688"
  },
  {
    "objectID": "posts/On_Device_Recommender_Systems_A_Tutorial_on_The_New_Generation_Recommendation_Paradigm/2023-12-18-On_Device_Recommender_Systems_A_Tutorial_on_The_New_Generation_Recommendation_Paradigm.html#appendix",
    "href": "posts/On_Device_Recommender_Systems_A_Tutorial_on_The_New_Generation_Recommendation_Paradigm/2023-12-18-On_Device_Recommender_Systems_A_Tutorial_on_The_New_Generation_Recommendation_Paradigm.html#appendix",
    "title": "On-Device Recommender Systems: A Tutorial on The New-Generation Recommendation Paradigm",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10864v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10864v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4195"
  },
  {
    "objectID": "posts/Towards_Verifiable_Text_Generation_with_Evolving_Memory_and_Self_Reflection/2023-12-14-Towards_Verifiable_Text_Generation_with_Evolving_Memory_and_Self_Reflection.html#appendix",
    "href": "posts/Towards_Verifiable_Text_Generation_with_Evolving_Memory_and_Self_Reflection/2023-12-14-Towards_Verifiable_Text_Generation_with_Evolving_Memory_and_Self_Reflection.html#appendix",
    "title": "Towards Verifiable Text Generation with Evolving Memory and Self-Reflection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.09075v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.09075v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7635"
  },
  {
    "objectID": "posts/Terrapin_Attack_Breaking_SSH_Channel_Integrity_By_Sequence_Number_Manipulation/2023-12-19-Terrapin_Attack_Breaking_SSH_Channel_Integrity_By_Sequence_Number_Manipulation.html#appendix",
    "href": "posts/Terrapin_Attack_Breaking_SSH_Channel_Integrity_By_Sequence_Number_Manipulation/2023-12-19-Terrapin_Attack_Breaking_SSH_Channel_Integrity_By_Sequence_Number_Manipulation.html#appendix",
    "title": "Terrapin Attack: Breaking SSH Channel Integrity By Sequence Number Manipulation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.12422v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.12422v1\n\n\nTruncated\nTrue\n\n\nWord Count\n18928"
  },
  {
    "objectID": "posts/AQUALLM_Audio_Question_Answering_Data_Generation_Using_Large_Language_Models/2023-12-28-AQUALLM_Audio_Question_Answering_Data_Generation_Using_Large_Language_Models.html#appendix",
    "href": "posts/AQUALLM_Audio_Question_Answering_Data_Generation_Using_Large_Language_Models/2023-12-28-AQUALLM_Audio_Question_Answering_Data_Generation_Using_Large_Language_Models.html#appendix",
    "title": "AQUALLM: Audio Question Answering Data Generation Using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17343v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17343v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4081"
  },
  {
    "objectID": "posts/Mean_estimation_in_the_add_remove_model_of_differential_privacy/2023-12-11-Mean_estimation_in_the_add_remove_model_of_differential_privacy.html#appendix",
    "href": "posts/Mean_estimation_in_the_add_remove_model_of_differential_privacy/2023-12-11-Mean_estimation_in_the_add_remove_model_of_differential_privacy.html#appendix",
    "title": "Mean estimation in the add-remove model of differential privacy",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.06658v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.06658v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4008"
  },
  {
    "objectID": "posts/Generative_AI_is_already_widespread_in_the_public_sector/2024-01-02-Generative_AI_is_already_widespread_in_the_public_sector.html#appendix",
    "href": "posts/Generative_AI_is_already_widespread_in_the_public_sector/2024-01-02-Generative_AI_is_already_widespread_in_the_public_sector.html#appendix",
    "title": "Generative AI is already widespread in the public sector",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01291v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01291v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7649"
  },
  {
    "objectID": "posts/AstroLLaMA_Chat_Scaling_AstroLLaMA_with_Conversational_and_Diverse_Datasets/2024-01-03-AstroLLaMA_Chat_Scaling_AstroLLaMA_with_Conversational_and_Diverse_Datasets.html#appendix",
    "href": "posts/AstroLLaMA_Chat_Scaling_AstroLLaMA_with_Conversational_and_Diverse_Datasets/2024-01-03-AstroLLaMA_Chat_Scaling_AstroLLaMA_with_Conversational_and_Diverse_Datasets.html#appendix",
    "title": "AstroLLaMA-Chat: Scaling AstroLLaMA with Conversational and Diverse Datasets",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01916v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01916v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2717"
  },
  {
    "objectID": "posts/Cooperation_on_the_Fly_Exploring_Language_Agents_for_Ad_Hoc_Teamwork_in_the_Avalon_Game/2023-12-29-Cooperation_on_the_Fly_Exploring_Language_Agents_for_Ad_Hoc_Teamwork_in_the_Avalon_Game.html",
    "href": "posts/Cooperation_on_the_Fly_Exploring_Language_Agents_for_Ad_Hoc_Teamwork_in_the_Avalon_Game/2023-12-29-Cooperation_on_the_Fly_Exploring_Language_Agents_for_Ad_Hoc_Teamwork_in_the_Avalon_Game.html",
    "title": "Cooperation on the Fly: Exploring Language Agents for Ad Hoc Teamwork in the Avalon Game",
    "section": "",
    "text": "Major Findings:"
  },
  {
    "objectID": "posts/Cooperation_on_the_Fly_Exploring_Language_Agents_for_Ad_Hoc_Teamwork_in_the_Avalon_Game/2023-12-29-Cooperation_on_the_Fly_Exploring_Language_Agents_for_Ad_Hoc_Teamwork_in_the_Avalon_Game.html#appendix",
    "href": "posts/Cooperation_on_the_Fly_Exploring_Language_Agents_for_Ad_Hoc_Teamwork_in_the_Avalon_Game/2023-12-29-Cooperation_on_the_Fly_Exploring_Language_Agents_for_Ad_Hoc_Teamwork_in_the_Avalon_Game.html#appendix",
    "title": "Cooperation on the Fly: Exploring Language Agents for Ad Hoc Teamwork in the Avalon Game",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17515v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17515v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7222"
  },
  {
    "objectID": "posts/LLaMA_Pro_Progressive_LLaMA_with_Block_Expansion/2024-01-04-LLaMA_Pro_Progressive_LLaMA_with_Block_Expansion.html#appendix",
    "href": "posts/LLaMA_Pro_Progressive_LLaMA_with_Block_Expansion/2024-01-04-LLaMA_Pro_Progressive_LLaMA_with_Block_Expansion.html#appendix",
    "title": "LLaMA Pro: Progressive LLaMA with Block Expansion",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.02415v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.02415v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8377"
  },
  {
    "objectID": "posts/LLM_Assist_Enhancing_Closed_Loop_Planning_with_Language_Based_Reasoning/2023-12-30-LLM_Assist_Enhancing_Closed_Loop_Planning_with_Language_Based_Reasoning.html#appendix",
    "href": "posts/LLM_Assist_Enhancing_Closed_Loop_Planning_with_Language_Based_Reasoning/2023-12-30-LLM_Assist_Enhancing_Closed_Loop_Planning_with_Language_Based_Reasoning.html#appendix",
    "title": "LLM-Assist: Enhancing Closed-Loop Planning with Language-Based Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00125v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00125v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9991"
  },
  {
    "objectID": "posts/GEqO_ML_Accelerated_Semantic_Equivalence_Detection/2024-01-02-GEqO_ML_Accelerated_Semantic_Equivalence_Detection.html#appendix",
    "href": "posts/GEqO_ML_Accelerated_Semantic_Equivalence_Detection/2024-01-02-GEqO_ML_Accelerated_Semantic_Equivalence_Detection.html#appendix",
    "title": "GEqO: ML-Accelerated Semantic Equivalence Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01280v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01280v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3256"
  },
  {
    "objectID": "posts/A_Unified_Framework_for_Multi_Domain_CTR_Prediction_via_Large_Language_Models/2023-12-17-A_Unified_Framework_for_Multi_Domain_CTR_Prediction_via_Large_Language_Models.html#summary",
    "href": "posts/A_Unified_Framework_for_Multi_Domain_CTR_Prediction_via_Large_Language_Models/2023-12-17-A_Unified_Framework_for_Multi_Domain_CTR_Prediction_via_Large_Language_Models.html#summary",
    "title": "A Unified Framework for Multi-Domain CTR Prediction via Large Language Models",
    "section": "Summary",
    "text": "Summary\n\nFindings\n\nClick-Through Rate (CTR) prediction across multiple domains is challenging due to the complex mutual influence between domains.\nExisting multi-domain CTR models struggle with the “seesaw phenomenon,” where the performance in one domain is enhanced at the expense of another domain, and they overlook rich semantic information.\nThe proposed Uni-CTR leverages Large Language Models (LLMs) to capture commonalities between domains and decouples domain-specific networks from the backbone LLM, resulting in improved performance and scalability. It outperforms state-of-the-art (SOTA) MDCTR models significantly, demonstrating remarkable effectiveness in zero-shot prediction.\n\n\n\nSections\n\nIntroduction: Describes the importance of CTR prediction across multiple domains.\nRelated Work: Reviews existing multi-domain CTR prediction tasks and discusses the use of LLMs for CTR prediction.\nPreliminary: Discusses multi-domain CTR prediction and the use of LLMs in CTR prediction.\nThe Proposed Method (Uni-CTR architecture): Describes Uni-CTR’s design, including prompt-based semantic modeling, LLM backbone, domain-specific network, and general network.\nPrediction and Loss Function: Details the loss function design and a comparative analysis with existing multi-domain recommendation methodologies.\nExperiments: Outlines the experimental settings, including datasets, evaluation metrics, and comparison with baseline models."
  },
  {
    "objectID": "posts/A_Unified_Framework_for_Multi_Domain_CTR_Prediction_via_Large_Language_Models/2023-12-17-A_Unified_Framework_for_Multi_Domain_CTR_Prediction_via_Large_Language_Models.html#critique",
    "href": "posts/A_Unified_Framework_for_Multi_Domain_CTR_Prediction_via_Large_Language_Models/2023-12-17-A_Unified_Framework_for_Multi_Domain_CTR_Prediction_via_Large_Language_Models.html#critique",
    "title": "A Unified Framework for Multi-Domain CTR Prediction via Large Language Models",
    "section": "Critique",
    "text": "Critique\n\nThe paper lacks a detailed exploration of potential limitations, such as computational complexity, efficiency, or potential biases introduced by the design of Uni-CTR.\nWhile the experimental results are presented, a more comprehensive analysis of the comparative performance and potential limitations would enhance the findings.\n\nOverall, the paper provides a valuable contribution to the field of multi-domain CTR prediction, highlighting the effectiveness of Uni-CTR in addressing the challenges associated with multi-domain CTR prediction. However, a more thorough exploration of potential limitations and an extended analysis of the experimental results would further strengthen the paper’s findings."
  },
  {
    "objectID": "posts/A_Unified_Framework_for_Multi_Domain_CTR_Prediction_via_Large_Language_Models/2023-12-17-A_Unified_Framework_for_Multi_Domain_CTR_Prediction_via_Large_Language_Models.html#appendix",
    "href": "posts/A_Unified_Framework_for_Multi_Domain_CTR_Prediction_via_Large_Language_Models/2023-12-17-A_Unified_Framework_for_Multi_Domain_CTR_Prediction_via_Large_Language_Models.html#appendix",
    "title": "A Unified Framework for Multi-Domain CTR Prediction via Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10743v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10743v1\n\n\nTruncated\nTrue\n\n\nWord Count\n17221"
  },
  {
    "objectID": "posts/Exploring_the_Effectiveness_of_Instruction_Tuning_in_Biomedical_Language_Processing/2023-12-31-Exploring_the_Effectiveness_of_Instruction_Tuning_in_Biomedical_Language_Processing.html#appendix",
    "href": "posts/Exploring_the_Effectiveness_of_Instruction_Tuning_in_Biomedical_Language_Processing/2023-12-31-Exploring_the_Effectiveness_of_Instruction_Tuning_in_Biomedical_Language_Processing.html#appendix",
    "title": "Exploring the Effectiveness of Instruction Tuning in Biomedical Language Processing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00579v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00579v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4484"
  },
  {
    "objectID": "posts/Red_Teaming_for_Large_Language_Models_At_Scale_Tackling_Hallucinations_on_Mathematics_Tasks/2023-12-30-Red_Teaming_for_Large_Language_Models_At_Scale_Tackling_Hallucinations_on_Mathematics_Tasks.html#appendix",
    "href": "posts/Red_Teaming_for_Large_Language_Models_At_Scale_Tackling_Hallucinations_on_Mathematics_Tasks/2023-12-30-Red_Teaming_for_Large_Language_Models_At_Scale_Tackling_Hallucinations_on_Mathematics_Tasks.html#appendix",
    "title": "Red Teaming for Large Language Models At Scale: Tackling Hallucinations on Mathematics Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00290v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00290v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7380"
  },
  {
    "objectID": "posts/Securing_NextG_Systems_against_Poisoning_Attacks_on_Federated_Learning_A_Game_Theoretic_Solution/2023-12-28-Securing_NextG_Systems_against_Poisoning_Attacks_on_Federated_Learning_A_Game_Theoretic_Solution.html#appendix",
    "href": "posts/Securing_NextG_Systems_against_Poisoning_Attacks_on_Federated_Learning_A_Game_Theoretic_Solution/2023-12-28-Securing_NextG_Systems_against_Poisoning_Attacks_on_Federated_Learning_A_Game_Theoretic_Solution.html#appendix",
    "title": "Securing NextG Systems against Poisoning Attacks on Federated Learning: A Game-Theoretic Solution",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17164v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17164v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8577"
  },
  {
    "objectID": "posts/A_Computational_Framework_for_Behavioral_Assessment_of_LLM_Therapists/2024-01-01-A_Computational_Framework_for_Behavioral_Assessment_of_LLM_Therapists.html#appendix",
    "href": "posts/A_Computational_Framework_for_Behavioral_Assessment_of_LLM_Therapists/2024-01-01-A_Computational_Framework_for_Behavioral_Assessment_of_LLM_Therapists.html#appendix",
    "title": "A Computational Framework for Behavioral Assessment of LLM Therapists",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00820v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00820v1\n\n\nTruncated\nTrue\n\n\nWord Count\n19139"
  },
  {
    "objectID": "posts/Olapa_MCoT_Enhancing_the_Chinese_Mathematical_Reasoning_Capability_of_LLMs/2023-12-29-Olapa_MCoT_Enhancing_the_Chinese_Mathematical_Reasoning_Capability_of_LLMs.html#appendix",
    "href": "posts/Olapa_MCoT_Enhancing_the_Chinese_Mathematical_Reasoning_Capability_of_LLMs/2023-12-29-Olapa_MCoT_Enhancing_the_Chinese_Mathematical_Reasoning_Capability_of_LLMs.html#appendix",
    "title": "Olapa-MCoT: Enhancing the Chinese Mathematical Reasoning Capability of LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17535v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17535v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5510"
  },
  {
    "objectID": "posts/Designing_Artificial_Intelligence_Equipped_Social_Decentralized_Autonomous_Organizations_for_Tackling_Sextortion_Cases_Version_0.7/2023-12-21-Designing_Artificial_Intelligence_Equipped_Social_Decentralized_Autonomous_Organizations_for_Tackling_Sextortion_Cases_Version_0.7.html#appendix",
    "href": "posts/Designing_Artificial_Intelligence_Equipped_Social_Decentralized_Autonomous_Organizations_for_Tackling_Sextortion_Cases_Version_0.7/2023-12-21-Designing_Artificial_Intelligence_Equipped_Social_Decentralized_Autonomous_Organizations_for_Tackling_Sextortion_Cases_Version_0.7.html#appendix",
    "title": "Designing Artificial Intelligence Equipped Social Decentralized Autonomous Organizations for Tackling Sextortion Cases Version 0.7",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.14090v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.14090v1\n\n\nTruncated\nTrue\n\n\nWord Count\n63528"
  },
  {
    "objectID": "posts/WordArt_Designer_API_User_Driven_Artistic_Typography_Synthesis_with_Large_Language_Models_on_ModelScope/2024-01-03-WordArt_Designer_API_User_Driven_Artistic_Typography_Synthesis_with_Large_Language_Models_on_ModelScope.html#appendix",
    "href": "posts/WordArt_Designer_API_User_Driven_Artistic_Typography_Synthesis_with_Large_Language_Models_on_ModelScope/2024-01-03-WordArt_Designer_API_User_Driven_Artistic_Typography_Synthesis_with_Large_Language_Models_on_ModelScope.html#appendix",
    "title": "WordArt Designer API: User-Driven Artistic Typography Synthesis with Large Language Models on ModelScope",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01699v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01699v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1741"
  },
  {
    "objectID": "posts/Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning/2023-12-17-Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning.html#key-findings",
    "href": "posts/Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning/2023-12-17-Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning.html#key-findings",
    "title": "Addressing Sample Inefficiency in Multi-View Representation Learning",
    "section": "Key Findings",
    "text": "Key Findings\n\nThe orthogonality of features is more crucial than projector dimensionality for learning good representations.\nUsing multiple data augmentations better represents the self-supervised learning (SSL) objective, improving representation quality and trainability. It leads to faster optimization convergence and better features emerging earlier in the training.\nA multi-augmentation framework can improve sample efficiency, allowing for similar performance with significantly fewer unlabeled samples in the pretraining dataset."
  },
  {
    "objectID": "posts/Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning/2023-12-17-Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning.html#introduction",
    "href": "posts/Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning/2023-12-17-Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning.html#introduction",
    "title": "Addressing Sample Inefficiency in Multi-View Representation Learning",
    "section": "Introduction",
    "text": "Introduction\n\nUnsupervised representation learning is essential for progress in computer vision.\nNon-contrastive self-supervised learning (NC-SSL) methods eliminate the need for negative samples.\nMethods like BarlowTwins and VICReg enforce orthogonality among learned features and have become preferred for representation learning."
  },
  {
    "objectID": "posts/Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning/2023-12-17-Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning.html#theoretical-foundations",
    "href": "posts/Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning/2023-12-17-Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning.html#theoretical-foundations",
    "title": "Addressing Sample Inefficiency in Multi-View Representation Learning",
    "section": "Theoretical Foundations",
    "text": "Theoretical Foundations\n\nTheoretical insights into the implicit bias of NC-SSL algorithms, explaining essential design heuristics.\nLow-dimensional projectors are sufficient for good feature learning with appropriate orthogonalization.\nUsing more data augmentations improves estimation of the augmentation-defined data covariance kernel."
  },
  {
    "objectID": "posts/Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning/2023-12-17-Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning.html#practical-recommendations",
    "href": "posts/Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning/2023-12-17-Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning.html#practical-recommendations",
    "title": "Addressing Sample Inefficiency in Multi-View Representation Learning",
    "section": "Practical Recommendations",
    "text": "Practical Recommendations\n\nRecommendations for practical pretraining, improving wall-clock time and performance on benchmark datasets using a ResNet-50 backbone."
  },
  {
    "objectID": "posts/Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning/2023-12-17-Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning.html#experiments",
    "href": "posts/Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning/2023-12-17-Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning.html#experiments",
    "title": "Addressing Sample Inefficiency in Multi-View Representation Learning",
    "section": "Experiments",
    "text": "Experiments\n\nEmpirical support for theoretical insights, demonstrating the sufficiency of low-dimensional projectors and the benefits of multiple augmentations on representation learning performance and convergence."
  },
  {
    "objectID": "posts/Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning/2023-12-17-Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning.html#discussion",
    "href": "posts/Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning/2023-12-17-Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning.html#discussion",
    "title": "Addressing Sample Inefficiency in Multi-View Representation Learning",
    "section": "Discussion",
    "text": "Discussion\n\nThe Pareto Optimal SSL approach suggests using the number of augmentations as a control for sample efficiency.\nExciting opportunities to extend the analysis to other categories of SSL algorithms and explore sample-efficient methods in critical domains such as medical imaging."
  },
  {
    "objectID": "posts/Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning/2023-12-17-Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning.html#appendix",
    "href": "posts/Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning/2023-12-17-Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning.html#appendix",
    "title": "Addressing Sample Inefficiency in Multi-View Representation Learning",
    "section": "Appendix",
    "text": "Appendix\n\nDetails on the augmentation graph perspective of non-contrastive SSL, implementation specifics, and empirical results supporting the multi-augmentation framework."
  },
  {
    "objectID": "posts/Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning/2023-12-17-Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning.html#critique",
    "href": "posts/Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning/2023-12-17-Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning.html#critique",
    "title": "Addressing Sample Inefficiency in Multi-View Representation Learning",
    "section": "Critique",
    "text": "Critique\nThe paper presents strong theoretical insights and empirical evidence, but it would benefit from addressing additional domains beyond computer vision to generalize its findings. Additionally, further exploration of computational efficiency is recommended to improve the proposed framework."
  },
  {
    "objectID": "posts/Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning/2023-12-17-Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning.html#appendix-1",
    "href": "posts/Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning/2023-12-17-Addressing_Sample_Inefficiency_in_Multi_View_Representation_Learning.html#appendix-1",
    "title": "Addressing Sample Inefficiency in Multi-View Representation Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10725v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10725v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9538"
  },
  {
    "objectID": "posts/Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study/2024-01-04-Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study.html#major-takeaways",
    "href": "posts/Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study/2024-01-04-Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study.html#major-takeaways",
    "title": "Exploring Boundary of GPT-4V on Marine Analysis: A Preliminary Case Study",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nThe study explores the preliminary case study of utilizing GPT-4V for marine analysis, assessing the feasibility of MLLMs in domain-specific analysis.\nThe experimental results demonstrate that while GPT-4V showcases impressive general-purpose visual understanding, it has limitations in fine-grained marine object recognition and advanced marine analysis.\nThe paper highlights the potential shortcomings of GPT-4V and emphasizes the need for further research and inclusion of more domain-specific training data to improve its performance."
  },
  {
    "objectID": "posts/Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study/2024-01-04-Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study.html#introduction",
    "href": "posts/Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study/2024-01-04-Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study.html#introduction",
    "title": "Exploring Boundary of GPT-4V on Marine Analysis: A Preliminary Case Study",
    "section": "Introduction",
    "text": "Introduction\n\nLarge language models (LLMs) like GPT-4V have demonstrated powerful abilities in various tasks, but their performance in domain-specific analysis like marine analysis has gained less attention.\nThe study investigates whether GPT-4V can serve as an effective visual perception system and professional expert for marine analysis, evaluating its performance from different aspects."
  },
  {
    "objectID": "posts/Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study/2024-01-04-Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study.html#experiments",
    "href": "posts/Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study/2024-01-04-Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study.html#experiments",
    "title": "Exploring Boundary of GPT-4V on Marine Analysis: A Preliminary Case Study",
    "section": "Experiments",
    "text": "Experiments\n\nApproach\n\nThe data construction involves samples from private data, internet images, and public datasets to ensure consistency and reliability.\nGPT-4V’s diverse prompt designs aim to generate comprehensive and descriptive responses aligned with user intents.\n\n\n\nPerception\n\nThe study explores GPT-4V’s performance in marine object recognition, fine-grained marine object recognition, robustness analysis, and physical world knowledge understanding.\nResults show limitations in fine-grained object recognition and robustness with different image formats.\n\n\n\nStatistics\n\nObject counting experiments reveal GPT-4V’s limited ability, especially in crowded or occluded settings.\nThe study also assesses GPT-4V’s capability to recognize all existing objects within visual images, demonstrating more limitations in recognizing all objects.\n\n\n\nDomain-specific Question-Answering\n\nEvaluation on marine multiple choice questions and domain-specific visual question-answering shows GPT-4V’s strong optical character recognition but also limitations in handling more advanced marine analysis requirements.\nThe study also evaluates GPT-4V’s support for multi-round conversations and its struggle with marine object recognition.\n\n\n\nMarine Cultural Understanding\n\nGPT-4V’s performance in marine logo understanding, artist image understanding, and landmark recognition displays mixed results, highlighting its capability in recognizing certain visual elements but also its limitations.\n\n\n\nAdvanced Functions\n\nThe study tests GPT-4V’s abilities in coral coverage estimation, benthic composition, relationship summarization, event detection, framework understanding, aesthetic evaluation, and temporal sequence understanding.\nGPT-4V demonstrated limitations in providing accurate analysis and understanding specific details in these advanced functions.\n\n\n\nPrompt Engineering\n\nEvaluation of prompt engineering techniques shows limited effectiveness in promoting GPT-4V’s visual recognition ability for marine images."
  },
  {
    "objectID": "posts/Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study/2024-01-04-Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study.html#discussions-and-future-directions",
    "href": "posts/Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study/2024-01-04-Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study.html#discussions-and-future-directions",
    "title": "Exploring Boundary of GPT-4V on Marine Analysis: A Preliminary Case Study",
    "section": "Discussions and Future Directions",
    "text": "Discussions and Future Directions\n\nDiscussions\n\nThe study questions the potential roles of GPT-4V as an educational or labeling tool and highlights the challenges and potential sample biases in the constructed testing samples.\n\n\n\nFuture Works\n\nThe paper emphasizes the need for continued research to enhance the accuracy and expertise of responses generated by GPT-4V, emphasizing the inclusion of more domain-specific training data and feedback-driven model improvements."
  },
  {
    "objectID": "posts/Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study/2024-01-04-Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study.html#conclusion",
    "href": "posts/Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study/2024-01-04-Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study.html#conclusion",
    "title": "Exploring Boundary of GPT-4V on Marine Analysis: A Preliminary Case Study",
    "section": "Conclusion",
    "text": "Conclusion\n\nThe study concludes that while GPT-4V demonstrates valuable findings in visual understanding and reasoning, it falls short of being a strong artificial intelligence domain expert, indicating more research is needed in leveraging multimodal systems for domain-specific analysis."
  },
  {
    "objectID": "posts/Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study/2024-01-04-Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study.html#critique",
    "href": "posts/Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study/2024-01-04-Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study.html#critique",
    "title": "Exploring Boundary of GPT-4V on Marine Analysis: A Preliminary Case Study",
    "section": "Critique",
    "text": "Critique\n\nThe study provides comprehensive insights into the performance of GPT-4V in marine analysis but may benefit from a more extensive comparison with other MLLMs for a more holistic view of the capabilities in domain-specific analysis.\nThe paper could also benefit from addressing potential biases in the evaluation dataset and providing clearer recommendations for future research directions."
  },
  {
    "objectID": "posts/Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study/2024-01-04-Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study.html#appendix",
    "href": "posts/Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study/2024-01-04-Exploring_Boundary_of_GPT_4V_on_Marine_Analysis_A_Preliminary_Case_Study.html#appendix",
    "title": "Exploring Boundary of GPT-4V on Marine Analysis: A Preliminary Case Study",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.02147v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.02147v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11778"
  },
  {
    "objectID": "posts/Physio_An_LLM_Based_Physiotherapy_Advisor/2024-01-03-Physio_An_LLM_Based_Physiotherapy_Advisor.html#appendix",
    "href": "posts/Physio_An_LLM_Based_Physiotherapy_Advisor/2024-01-03-Physio_An_LLM_Based_Physiotherapy_Advisor.html#appendix",
    "title": "Physio: An LLM-Based Physiotherapy Advisor",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01825v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01825v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2619"
  },
  {
    "objectID": "posts/A_Comprehensive_Survey_of_Hallucination_Mitigation_Techniques_in_Large_Language_Models/2024-01-02-A_Comprehensive_Survey_of_Hallucination_Mitigation_Techniques_in_Large_Language_Models.html#appendix",
    "href": "posts/A_Comprehensive_Survey_of_Hallucination_Mitigation_Techniques_in_Large_Language_Models/2024-01-02-A_Comprehensive_Survey_of_Hallucination_Mitigation_Techniques_in_Large_Language_Models.html#appendix",
    "title": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01313v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01313v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13687"
  },
  {
    "objectID": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#key-findings",
    "href": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#key-findings",
    "title": "Alleviating Hallucinations of Large Language Models through Induced Hallucinations",
    "section": "Key Findings",
    "text": "Key Findings\n\nHallucinations in Large Language Models (LLMs): The paper introduces an approach called “Induce-then-Contrast Decoding (ICD)” to mitigate the phenomenon of hallucinations in LLMs by inducing factually weak LLMs and penalizing induced hallucinations during model decoding.\nEffectiveness of ICD: Experimental results demonstrate that the ICD approach significantly enhances the factuality of LLMs, as shown through improved performance on benchmarks such as TruthfulQA and FActScore.\nComparison with other Methods: The paper compares ICD with other decoding methods such as greedy decoding, inference time intervention (ITI), DoLa, and vanilla contrastive decoding (CD), demonstrating the superiority of ICD in reducing hallucinations and improving factuality."
  },
  {
    "objectID": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#introduction",
    "href": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#introduction",
    "title": "Alleviating Hallucinations of Large Language Models through Induced Hallucinations",
    "section": "Introduction",
    "text": "Introduction\n\nLarge Language Models (LLMs) exhibit remarkable capabilities but are prone to generating hallucinations - inaccurate or fabricated information, hindering their practical application in real-world scenarios."
  },
  {
    "objectID": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#induce-then-contrast-decoding",
    "href": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#induce-then-contrast-decoding",
    "title": "Alleviating Hallucinations of Large Language Models through Induced Hallucinations",
    "section": "Induce-then-Contrast Decoding",
    "text": "Induce-then-Contrast Decoding\n\nInducing Hallucinations from LLMs\n\nThe paper proposes a process for inducing hallucinations from LLMs, using fine-tuning with non-factual samples obtained through prompting.\nIt describes the fine-tuning process and the formulation of the fine-tuning dataset.\n\n\n\nFactually Weak LLM as A Penalty\n\nThe decoding process of LLMs is described, outlining the strategy to amplify the predictions from the original model and downplay the untruthful predictions using contrastive decoding."
  },
  {
    "objectID": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#experiments",
    "href": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#experiments",
    "title": "Alleviating Hallucinations of Large Language Models through Induced Hallucinations",
    "section": "Experiments",
    "text": "Experiments\n\nExperimental results on TruthfulQA and FActScore benchmarks demonstrate the efficacy of ICD in enhancing LLM factuality compared to other decoding methods.\nThe paper evaluates the impact of different tasks and model sizes on ICD effectiveness and analyzes the influence of fine-tuning data size and its source when inducing hallucinations."
  },
  {
    "objectID": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#critique",
    "href": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#critique",
    "title": "Alleviating Hallucinations of Large Language Models through Induced Hallucinations",
    "section": "Critique",
    "text": "Critique\nLimitations - The additional computational costs introduced by ICD could be a potential limitation. - The evaluation setting is limited to specific benchmarks, potentially restricting the generalization of the findings to other domains and tasks.\nEthical Considerations - The study acknowledges the ethical considerations of human annotator compensation and potential risks related to the inadvertent manipulation of LLMs.\nOverall, the paper presents a novel approach, ICD, for mitigating hallucinations in LLMs, demonstrating its effectiveness through experimental evaluations. However, the limitations and ethical considerations should be further addressed in future research."
  },
  {
    "objectID": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#appendix",
    "href": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#appendix",
    "title": "Alleviating Hallucinations of Large Language Models through Induced Hallucinations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.15710v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.15710v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9227"
  },
  {
    "objectID": "posts/Improving_the_Robustness_of_Knowledge_Grounded_Dialogue_via_Contrastive_Learning/2024-01-09-Improving_the_Robustness_of_Knowledge_Grounded_Dialogue_via_Contrastive_Learning.html#appendix",
    "href": "posts/Improving_the_Robustness_of_Knowledge_Grounded_Dialogue_via_Contrastive_Learning/2024-01-09-Improving_the_Robustness_of_Knowledge_Grounded_Dialogue_via_Contrastive_Learning.html#appendix",
    "title": "Improving the Robustness of Knowledge-Grounded Dialogue via Contrastive Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.04361v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.04361v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8188"
  },
  {
    "objectID": "posts/Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts/2024-01-04-Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts.html#major-takeaways",
    "href": "posts/Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts/2024-01-04-Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts.html#major-takeaways",
    "title": "Text2MDT: Extracting Medical Decision Trees from Medical Texts",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nText2MDT: The paper proposes a novel task, Text2MDT, which aims to automatically extract medical decision trees (MDTs) from medical texts such as medical guidelines and textbooks. This is significant for the development of clinical decision support systems.\nEnd-to-end vs. Pipeline Framework: The paper investigates both an end-to-end framework and a pipeline framework for the Text2MDT task and demonstrates that large language models (LLMs) show promising results in automated MDT extraction.\nOpen-Sourced Dataset and Source Code: The study contributes to the field by constructing the first Text2MDT benchmark dataset and making it openly available to facilitate further research."
  },
  {
    "objectID": "posts/Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts/2024-01-04-Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts.html#introduction",
    "href": "posts/Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts/2024-01-04-Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts.html#introduction",
    "title": "Text2MDT: Extracting Medical Decision Trees from Medical Texts",
    "section": "Introduction",
    "text": "Introduction\n\nThe development of clinical decision support systems, which rely on medical decision processes modeled as MDTs, has drawn significant attention in the medical field.\nCurrent methods for constructing MDTs rely on manual tree construction, which is time-consuming and laborious, leading to a need for automated pipelines for precise MDT extraction. This motivates the proposal of the Text2MDT task."
  },
  {
    "objectID": "posts/Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts/2024-01-04-Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts.html#text2mdt-task",
    "href": "posts/Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts/2024-01-04-Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts.html#text2mdt-task",
    "title": "Text2MDT: Extracting Medical Decision Trees from Medical Texts",
    "section": "Text2MDT Task",
    "text": "Text2MDT Task\n\nStructure: The knowledge of a medical decision process embedded in the medical text is modeled as a binary decision tree consisting of condition nodes and decision nodes, linked by the logical relationships"
  },
  {
    "objectID": "posts/Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts/2024-01-04-Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts.html#data-collection-and-evaluation",
    "href": "posts/Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts/2024-01-04-Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts.html#data-collection-and-evaluation",
    "title": "Text2MDT: Extracting Medical Decision Trees from Medical Texts",
    "section": "Data Collection and Evaluation",
    "text": "Data Collection and Evaluation\n\nData Collection: A Text2MDT dataset was constructed using clinical practice guidelines and clinical medicine textbooks, and medical practitioners evaluated the ability of medical texts and decision trees to represent the medical decision process.\nManual Evaluation: The quality of the annotated MDTs was evaluated by medical practitioners and individuals without a medical background."
  },
  {
    "objectID": "posts/Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts/2024-01-04-Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts.html#methods-of-modeling-text2mdt",
    "href": "posts/Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts/2024-01-04-Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts.html#methods-of-modeling-text2mdt",
    "title": "Text2MDT: Extracting Medical Decision Trees from Medical Texts",
    "section": "Methods of modeling Text2MDT",
    "text": "Methods of modeling Text2MDT\n\nPipelined Framework: The study investigates triplet extraction, node grouping, and tree assembling as subtasks for the pipeline framework. Both encoder-based and LLM-based methods are explored.\nEnd-to-end Framework: The paper proposes various COT-style generation methods for the end-to-end framework, considering the complexity of the Text2MDT task and the potential benefit of COT reasoning."
  },
  {
    "objectID": "posts/Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts/2024-01-04-Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts.html#experiments-and-results",
    "href": "posts/Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts/2024-01-04-Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts.html#experiments-and-results",
    "title": "Text2MDT: Extracting Medical Decision Trees from Medical Texts",
    "section": "Experiments and Results",
    "text": "Experiments and Results\n\nEvaluation Metrics: The study uses metrics such as triplet precision, recall, and F1 scores for triplet extraction, edit distance-based metrics for node grouping, and additional metrics for tree assembling.\nPerformance Findings: The study shows competitive results for MedBERT-based methods and demonstrates the potential of COT-style reasoning in improving the performance of generative LMs on the Text2MDT task."
  },
  {
    "objectID": "posts/Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts/2024-01-04-Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts.html#limitations-and-critique",
    "href": "posts/Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts/2024-01-04-Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts.html#limitations-and-critique",
    "title": "Text2MDT: Extracting Medical Decision Trees from Medical Texts",
    "section": "Limitations and Critique",
    "text": "Limitations and Critique\n\nThe study acknowledges limitations related to the expressiveness of the tree, limited logic expression of nodes, and text length constraints. Further improvements are identified as future work."
  },
  {
    "objectID": "posts/Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts/2024-01-04-Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts.html#conclusion",
    "href": "posts/Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts/2024-01-04-Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts.html#conclusion",
    "title": "Text2MDT: Extracting Medical Decision Trees from Medical Texts",
    "section": "Conclusion",
    "text": "Conclusion\n\nThe paper concludes with the significance of the proposed Text2MDT task for automated extraction of MDTs and highlights the contributions of the study, including the construction of the Text2MDT dataset and the exploration of novel method frameworks.\nAdditionally, the study identifies potential future work to address the limitations and challenges encountered in the investigation."
  },
  {
    "objectID": "posts/Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts/2024-01-04-Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts.html#critique",
    "href": "posts/Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts/2024-01-04-Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts.html#critique",
    "title": "Text2MDT: Extracting Medical Decision Trees from Medical Texts",
    "section": "Critique",
    "text": "Critique\nThe paper provides a comprehensive overview of the Text2MDT task and presents valuable contributions to the field of automated MDT extraction. However, a more detailed discussion of potential challenges and future directions for improving the proposed methods would enhance the paper’s completeness. Additionally, addressing the limitations of the proposed framework and its applicability in real-world clinical settings would provide a more comprehensive evaluation of the study’s contributions."
  },
  {
    "objectID": "posts/Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts/2024-01-04-Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts.html#appendix",
    "href": "posts/Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts/2024-01-04-Text2MDT_Extracting_Medical_Decision_Trees_from_Medical_Texts.html#appendix",
    "title": "Text2MDT: Extracting Medical Decision Trees from Medical Texts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.02034v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.02034v1\n\n\nTruncated\nTrue\n\n\nWord Count\n13994"
  },
  {
    "objectID": "posts/Prompting_Hard_or_Hardly_Prompting_Prompt_Inversion_for_Text_to_Image_Diffusion_Models/2023-12-19-Prompting_Hard_or_Hardly_Prompting_Prompt_Inversion_for_Text_to_Image_Diffusion_Models.html#appendix",
    "href": "posts/Prompting_Hard_or_Hardly_Prompting_Prompt_Inversion_for_Text_to_Image_Diffusion_Models/2023-12-19-Prompting_Hard_or_Hardly_Prompting_Prompt_Inversion_for_Text_to_Image_Diffusion_Models.html#appendix",
    "title": "Prompting Hard or Hardly Prompting: Prompt Inversion for Text-to-Image Diffusion Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.12416v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.12416v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9247"
  },
  {
    "objectID": "posts/Open_TI_Open_Traffic_Intelligence_with_Augmented_Language_Model/2023-12-30-Open_TI_Open_Traffic_Intelligence_with_Augmented_Language_Model.html#appendix",
    "href": "posts/Open_TI_Open_Traffic_Intelligence_with_Augmented_Language_Model/2023-12-30-Open_TI_Open_Traffic_Intelligence_with_Augmented_Language_Model.html#appendix",
    "title": "Open-TI: Open Traffic Intelligence with Augmented Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00211v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00211v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10460"
  },
  {
    "objectID": "posts/InFoBench_Evaluating_Instruction_Following_Ability_in_Large_Language_Models/2024-01-07-InFoBench_Evaluating_Instruction_Following_Ability_in_Large_Language_Models.html#summary",
    "href": "posts/InFoBench_Evaluating_Instruction_Following_Ability_in_Large_Language_Models/2024-01-07-InFoBench_Evaluating_Instruction_Following_Ability_in_Large_Language_Models.html#summary",
    "title": "InFoBench: Evaluating Instruction Following Ability in Large Language Models",
    "section": "Summary",
    "text": "Summary\n\nFindings\n\nThe paper introduces a new metric, the Decomposed Requirements Following Ratio (DRFR), for evaluating Large Language Models’ (LLMs) ability to follow instructions.\nThe study compares DRFR with traditional scoring methods and explores annotation sources, finding DRFR to have higher reliability and GPT-4 to be a cost-effective annotator.\nThe evaluation of several advanced LLMs using this framework reveals their strengths and areas needing improvement, particularly in complex instruction-following.\n\n\n\nIntroduction\nThe paper addresses the lack of evaluation methodologies dedicated to the crucial aspect of instruction-following in Large Language Models (LLMs) and aims to establish a reliable protocol and benchmark for appraising the instruction-following aptitude of LLMs.\n\n\nInFoBench\n\nIntroduces DRFR and InFoBench, a benchmark dataset, for assessing LLMs’ proficiency in adhering to complex instructions in a detailed and structured manner.\nDRFR decomposes each instruction into distinct, simpler criteria, allowing a granular analysis of a model’s performance.\nInFoBench dataset presents diverse instructions and decomposed questions across different constraint categories.\n\n\n\nExperiments\n\nCompared DRFR with traditional Direct Scoring (DS), results showed higher annotator consensus with DRFR, indicating its enhanced reliability.\nExplored cost-efficient annotation sources, finding GPT-4 to be highly accurate, cost-effective, and time-efficient.\nEmployed GPT-4 as an annotator and evaluated advanced LLMs, revealing the need for improvement in handling complex instructions."
  },
  {
    "objectID": "posts/InFoBench_Evaluating_Instruction_Following_Ability_in_Large_Language_Models/2024-01-07-InFoBench_Evaluating_Instruction_Following_Ability_in_Large_Language_Models.html#critique",
    "href": "posts/InFoBench_Evaluating_Instruction_Following_Ability_in_Large_Language_Models/2024-01-07-InFoBench_Evaluating_Instruction_Following_Ability_in_Large_Language_Models.html#critique",
    "title": "InFoBench: Evaluating Instruction Following Ability in Large Language Models",
    "section": "Critique",
    "text": "Critique\nThe paper presents significant contributions to the evaluation of LLMs’ instruction-following abilities. However, it has limitations: 1. The reliance on human annotation for only a fraction of the instruction set limits the reliability of comparisons among different annotations. 2. The dataset size is limited, and the manual nature of instruction writing restricts scalability. 3. The evaluation primarily focuses on the explicit intentions contained within the provided instructions, neglecting crucial factors such as truthfulness and harmlessness.\nOverall, while the paper’s contributions pave the way for future research and development in LLM evaluation, the limitations in dataset size and human annotation demonstrate areas for potential improvement."
  },
  {
    "objectID": "posts/InFoBench_Evaluating_Instruction_Following_Ability_in_Large_Language_Models/2024-01-07-InFoBench_Evaluating_Instruction_Following_Ability_in_Large_Language_Models.html#appendix",
    "href": "posts/InFoBench_Evaluating_Instruction_Following_Ability_in_Large_Language_Models/2024-01-07-InFoBench_Evaluating_Instruction_Following_Ability_in_Large_Language_Models.html#appendix",
    "title": "InFoBench: Evaluating Instruction Following Ability in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.03601v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.03601v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13442"
  },
  {
    "objectID": "posts/RAGTruth_A_Hallucination_Corpus_for_Developing_Trustworthy_Retrieval_Augmented_Language_Models/2023-12-31-RAGTruth_A_Hallucination_Corpus_for_Developing_Trustworthy_Retrieval_Augmented_Language_Models.html#appendix",
    "href": "posts/RAGTruth_A_Hallucination_Corpus_for_Developing_Trustworthy_Retrieval_Augmented_Language_Models/2023-12-31-RAGTruth_A_Hallucination_Corpus_for_Developing_Trustworthy_Retrieval_Augmented_Language_Models.html#appendix",
    "title": "RAGTruth: A Hallucination Corpus for Developing Trustworthy Retrieval-Augmented Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00396v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00396v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6757"
  },
  {
    "objectID": "posts/HE_DKSAP_Privacy_Preserving_Stealth_Address_Protocol_via_Additively_Homomorphic_Encryption/2023-12-17-HE_DKSAP_Privacy_Preserving_Stealth_Address_Protocol_via_Additively_Homomorphic_Encryption.html",
    "href": "posts/HE_DKSAP_Privacy_Preserving_Stealth_Address_Protocol_via_Additively_Homomorphic_Encryption/2023-12-17-HE_DKSAP_Privacy_Preserving_Stealth_Address_Protocol_via_Additively_Homomorphic_Encryption.html",
    "title": "HE-DKSAP: Privacy-Preserving Stealth Address Protocol via Additively Homomorphic Encryption",
    "section": "",
    "text": "Summary: - The paper introduces the Homomorphic Encryption-based Dual-Key Stealth Address Protocol (HE-DKSAP) as a novel approach to safeguarding transaction privacy and preventing potential quantum computing attacks in blockchain systems. - The protocol combines homomorphic encryption with a dual-key stealth address protocol to enhance privacy and security. - Three major challenges in stealth address (SA) protocols are identified: key leakage attacks, scalability and usability concerns, and vulnerability to quantum computing attacks.\nKey findings: 1. Homomorphic Encryption-based Dual-Key Stealth Address Protocol (HE-DKSAP): - The protocol introduces a novel approach to safeguarding transaction privacy and preventing potential quantum computing attacks by leveraging the power of homomorphic encryption. - By combining homomorphic encryption with the dual-key stealth address protocol, HE-DKSAP aims to enhance privacy and security in blockchain systems.\nCrypto Scheme Overview: - The paper discusses the use of homomorphic encryption schemes such as Paillier or BFV, describing the key generation, encryption, and decryption processes. - It outlines the implementation of the HE-DKSAP protocol using the Paillier encryption scheme and the BFV scheme for fully homomorphic encryption.\nCritique: - The paper effectively introduces a novel approach, HE-DKSAP, and outlines the challenges in SA protocols. However, it would benefit from more in-depth discussions of potential limitations or real-world deployment challenges for the proposed protocol. Additionally, the clarity and organization of technical details in the algorithmic and cryptographic scheme overview could be improved for a non-specialist audience."
  },
  {
    "objectID": "posts/HE_DKSAP_Privacy_Preserving_Stealth_Address_Protocol_via_Additively_Homomorphic_Encryption/2023-12-17-HE_DKSAP_Privacy_Preserving_Stealth_Address_Protocol_via_Additively_Homomorphic_Encryption.html#appendix",
    "href": "posts/HE_DKSAP_Privacy_Preserving_Stealth_Address_Protocol_via_Additively_Homomorphic_Encryption/2023-12-17-HE_DKSAP_Privacy_Preserving_Stealth_Address_Protocol_via_Additively_Homomorphic_Encryption.html#appendix",
    "title": "HE-DKSAP: Privacy-Preserving Stealth Address Protocol via Additively Homomorphic Encryption",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10698v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10698v1\n\n\nTruncated\nTrue\n\n\nWord Count\n19402"
  },
  {
    "objectID": "posts/RePLan_Robotic_Replanning_with_Perception_and_Language_Models/2024-01-08-RePLan_Robotic_Replanning_with_Perception_and_Language_Models.html#appendix",
    "href": "posts/RePLan_Robotic_Replanning_with_Perception_and_Language_Models/2024-01-08-RePLan_Robotic_Replanning_with_Perception_and_Language_Models.html#appendix",
    "title": "RePLan: Robotic Replanning with Perception and Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.04157v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.04157v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12338"
  },
  {
    "objectID": "posts/Benchmarking_Large_Language_Models_on_Controllable_Generation_under_Diversified_Instructions/2024-01-01-Benchmarking_Large_Language_Models_on_Controllable_Generation_under_Diversified_Instructions.html#appendix",
    "href": "posts/Benchmarking_Large_Language_Models_on_Controllable_Generation_under_Diversified_Instructions/2024-01-01-Benchmarking_Large_Language_Models_on_Controllable_Generation_under_Diversified_Instructions.html#appendix",
    "title": "Benchmarking Large Language Models on Controllable Generation under Diversified Instructions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00690v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00690v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12181"
  },
  {
    "objectID": "posts/JMA_a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example/2024-01-02-JMA_a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example.html#major-takeaways",
    "href": "posts/JMA_a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example/2024-01-02-JMA_a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example.html#major-takeaways",
    "title": "JMA: a General Algorithm to Craft Nearly Optimal Targeted Adversarial Example",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nThe paper proposes a new algorithm, Jacobian-induced Mahalanobis distance Attack (JMA), for crafting targeted adversarial examples against Deep Learning classifiers.\nJMA presents a more general and theoretically sound approach, resorting to the minimization of a Mahalanobis distance term derived from the Jacobian matrix, taking into account the effort required to move the input sample in a given direction in the latent space representation.\nThe experiments confirm the efficacy of JMA under different scenarios, including multi-label classification, ECOC output encoding, and one-hot encoding."
  },
  {
    "objectID": "posts/JMA_a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example/2024-01-02-JMA_a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example.html#sections",
    "href": "posts/JMA_a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example/2024-01-02-JMA_a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example.html#sections",
    "title": "JMA: a General Algorithm to Craft Nearly Optimal Targeted Adversarial Example",
    "section": "Sections",
    "text": "Sections\n\nIntroduction\nAdversarial Attacks against DNNs\nThe JMA Attack"
  },
  {
    "objectID": "posts/JMA_a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example/2024-01-02-JMA_a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example.html#critique",
    "href": "posts/JMA_a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example/2024-01-02-JMA_a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example.html#critique",
    "title": "JMA: a General Algorithm to Craft Nearly Optimal Targeted Adversarial Example",
    "section": "Critique",
    "text": "Critique\nThe paper introduces a novel and theoretically sound algorithm that addresses a significant issue in crafting targeted adversarial examples. The experimental results support the effectiveness of JMA across different scenarios. However, a critical analysis of the limitations or potential failure cases of JMA would provide a more comprehensive understanding of its applicability. Furthermore, a comparative analysis with existing state-of-the-art algorithms would enhance the paper’s contributions and provide additional context for evaluating the significance of JMA."
  },
  {
    "objectID": "posts/JMA_a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example/2024-01-02-JMA_a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example.html#appendix",
    "href": "posts/JMA_a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example/2024-01-02-JMA_a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example.html#appendix",
    "title": "JMA: a General Algorithm to Craft Nearly Optimal Targeted Adversarial Example",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01199v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01199v1\n\n\nTruncated\nTrue\n\n\nWord Count\n27623"
  },
  {
    "objectID": "posts/FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning/2024-01-02-FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning.html#major-findings",
    "href": "posts/FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning/2024-01-02-FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning.html#major-findings",
    "title": "FedQV: Leveraging Quadratic Voting in Federated Learning",
    "section": "Major Findings",
    "text": "Major Findings\n\nFedQV is a truthful mechanism and shows compatibility with FedAvg.\nFedQV outperforms FedAvg under various SOTA poisoning attacks, especially for local model poisoning attacks.\nThe combination of FedQV with a reputation model improves robustness against poisoning attacks."
  },
  {
    "objectID": "posts/FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning/2024-01-02-FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning.html#related-work",
    "href": "posts/FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning/2024-01-02-FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning.html#related-work",
    "title": "FedQV: Leveraging Quadratic Voting in Federated Learning",
    "section": "Related Work",
    "text": "Related Work\n\nElection Mechanisms in FL\n\nElection mechanisms explored in distributed systems and in FL for the aggregation step.\n\n\n\nByzantine-Robust FL Aggregation Against Privacy Attacks\n\nVarious Byzantine-robust FL aggregation methods are presented for mitigating Byzantine attacks.\nFedQV uses provably truthful mechanisms to guard against inference and reconstruction attacks."
  },
  {
    "objectID": "posts/FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning/2024-01-02-FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning.html#methodology",
    "href": "posts/FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning/2024-01-02-FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning.html#methodology",
    "title": "FedQV: Leveraging Quadratic Voting in Federated Learning",
    "section": "Methodology",
    "text": "Methodology\n\nQuadratic Voting in FL\n\nQuadratic Voting applied as an alternative to the 1p1v principle, aiming to enhance performance and deter collusion attacks.\nFedQV with a masked voting rule and limited budget is utilized to deter malicious actions and improve global model accuracy."
  },
  {
    "objectID": "posts/FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning/2024-01-02-FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning.html#theoretical-analysis",
    "href": "posts/FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning/2024-01-02-FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning.html#theoretical-analysis",
    "title": "FedQV: Leveraging Quadratic Voting in Federated Learning",
    "section": "Theoretical Analysis",
    "text": "Theoretical Analysis\n\nConvergence guarantees and truthfulness of FedQV are theoretically established, along with rigorous proofs."
  },
  {
    "objectID": "posts/FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning/2024-01-02-FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning.html#experiments",
    "href": "posts/FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning/2024-01-02-FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning.html#experiments",
    "title": "FedQV: Leveraging Quadratic Voting in Federated Learning",
    "section": "Experiments",
    "text": "Experiments\n\nExperimental Setting\n\nFL system involving ** parties and a central server with several communication rounds.\n\n\n\nEvaluated Poisoning Attacks\n\nData poisoning and model poisoning attacks are explored, demonstrating the robustness of FedQV against various attack scenarios.\n\n\n\nPerformance Metrics\n\nAverage test accuracy and attack success rate used to evaluate the defense mechanism’s effectiveness.\n\n\n\nDefence Against Poisoning Attacks\n\nFedQV consistently outperforms FedAvg under SOTA poisoning attacks, showcasing its robustness in varying attack scenarios."
  },
  {
    "objectID": "posts/FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning/2024-01-02-FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning.html#conclusion",
    "href": "posts/FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning/2024-01-02-FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning.html#conclusion",
    "title": "FedQV: Leveraging Quadratic Voting in Federated Learning",
    "section": "Conclusion",
    "text": "Conclusion\n\nFedQV is a promising complement to existing aggregation methods, exhibiting superior performance under various poisoning attacks."
  },
  {
    "objectID": "posts/FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning/2024-01-02-FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning.html#critique",
    "href": "posts/FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning/2024-01-02-FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning.html#critique",
    "title": "FedQV: Leveraging Quadratic Voting in Federated Learning",
    "section": "Critique",
    "text": "Critique\nThe paper provides a comprehensive analysis and evaluation of FedQV, demonstrating its robustness against poisoning attacks. However, the impact of varying system parameters and the generalizability of the findings to specific use cases could benefit from further exploration. Additionally, the integration of FedQV with other Byzantine-robust FL aggregation methods may require more in-depth investigation to ensure seamless compatibility and optimized performance."
  },
  {
    "objectID": "posts/FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning/2024-01-02-FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning.html#appendix",
    "href": "posts/FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning/2024-01-02-FedQV_Leveraging_Quadratic_Voting_in_Federated_Learning.html#appendix",
    "title": "FedQV: Leveraging Quadratic Voting in Federated Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01168v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01168v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11725"
  },
  {
    "objectID": "posts/Search_Games_with_Predictions/2024-01-02-Search_Games_with_Predictions.html#major-takeaways",
    "href": "posts/Search_Games_with_Predictions/2024-01-02-Search_Games_with_Predictions.html#major-takeaways",
    "title": "Search Games with Predictions",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nSearch games involve a Searcher trying to locate a Hider in an environment, with the Searcher aiming to minimize some payoff, such as the time to find the Hider or a normalized search time.\nThis study presents a new setting where the Searcher has potentially erroneous information or predictions on the Hider’s position, leading to tradeoffs between consistency and robustness of search strategies.\nThe paper explores optimal consistency/robustness tradeoffs for three fundamental search games, including searching in discrete locations, expanding search in a tree network, and linear search in an infinite line."
  },
  {
    "objectID": "posts/Search_Games_with_Predictions/2024-01-02-Search_Games_with_Predictions.html#introduction",
    "href": "posts/Search_Games_with_Predictions/2024-01-02-Search_Games_with_Predictions.html#introduction",
    "title": "Search Games with Predictions",
    "section": "Introduction",
    "text": "Introduction\n\nSearch games are a common task in everyday life, with applications in various fields such as search-and-rescue operations and robotics.\nThese games have been studied under the mathematical formulation of a zero-sum two-person game, with a focus on identifying the value of the search game and applying it to real-world problems."
  },
  {
    "objectID": "posts/Search_Games_with_Predictions/2024-01-02-Search_Games_with_Predictions.html#search-games-with-predictions-1",
    "href": "posts/Search_Games_with_Predictions/2024-01-02-Search_Games_with_Predictions.html#search-games-with-predictions-1",
    "title": "Search Games with Predictions",
    "section": "Search Games with Predictions",
    "text": "Search Games with Predictions\n\nThis study introduces a new approach where the Searcher has predictions about the Hider’s location, leading to a tradeoff between consistency and robustness of search strategies.\nThe objective is to find the Pareto frontier of the game, describing the best-possible consistency under a given robustness value or the best-possible robustness under a given consistency value."
  },
  {
    "objectID": "posts/Search_Games_with_Predictions/2024-01-02-Search_Games_with_Predictions.html#contribution",
    "href": "posts/Search_Games_with_Predictions/2024-01-02-Search_Games_with_Predictions.html#contribution",
    "title": "Search Games with Predictions",
    "section": "Contribution",
    "text": "Contribution\n\nThe paper studies three important search games under the predictions model: searching in discrete locations, expanding search in a tree network, and linear search in an infinite line.\nIt provides Pareto-optimal strategies that achieve optimal consistency-robustness tradeoffs, particularly for randomized algorithms, filling a gap in the analysis of such tradeoffs."
  },
  {
    "objectID": "posts/Search_Games_with_Predictions/2024-01-02-Search_Games_with_Predictions.html#preliminaries",
    "href": "posts/Search_Games_with_Predictions/2024-01-02-Search_Games_with_Predictions.html#preliminaries",
    "title": "Search Games with Predictions",
    "section": "Preliminaries",
    "text": "Preliminaries\n\nThe paper introduces the consistency and robustness metrics for search strategies with predictions, aiming to minimize both metrics to find the Pareto frontier.\nIt uses the concept of scalarization from multiobjective optimization to characterize the Pareto frontier of the game."
  },
  {
    "objectID": "posts/Search_Games_with_Predictions/2024-01-02-Search_Games_with_Predictions.html#box-search",
    "href": "posts/Search_Games_with_Predictions/2024-01-02-Search_Games_with_Predictions.html#box-search",
    "title": "Search Games with Predictions",
    "section": "Box Search",
    "text": "Box Search\n\nThe study explores a fundamental search game where a Hider hides in one of a set of boxes, and a Searcher looks in the boxes one by one until finding the target.\nIt presents Pareto-optimal strategies and characterizes the Pareto frontier for box search with predictions."
  },
  {
    "objectID": "posts/Search_Games_with_Predictions/2024-01-02-Search_Games_with_Predictions.html#expanding-search-on-a-tree-network",
    "href": "posts/Search_Games_with_Predictions/2024-01-02-Search_Games_with_Predictions.html#expanding-search-on-a-tree-network",
    "title": "Search Games with Predictions",
    "section": "Expanding Search on a Tree Network",
    "text": "Expanding Search on a Tree Network\n\nThis section extends the model to expanding search on a tree network and demonstrates the Pareto-optimal strategies for this scenario under the predictions model."
  },
  {
    "objectID": "posts/Search_Games_with_Predictions/2024-01-02-Search_Games_with_Predictions.html#a-general-approach-to-characterizing-the-pareto-frontier",
    "href": "posts/Search_Games_with_Predictions/2024-01-02-Search_Games_with_Predictions.html#a-general-approach-to-characterizing-the-pareto-frontier",
    "title": "Search Games with Predictions",
    "section": "A General Approach to Characterizing the Pareto Frontier",
    "text": "A General Approach to Characterizing the Pareto Frontier\n\nThe paper presents a general approach for finding the Pareto frontier of search games, applying it to arbitrary two-player zero-sum games."
  },
  {
    "objectID": "posts/Search_Games_with_Predictions/2024-01-02-Search_Games_with_Predictions.html#searching-on-the-infinite-line",
    "href": "posts/Search_Games_with_Predictions/2024-01-02-Search_Games_with_Predictions.html#searching-on-the-infinite-line",
    "title": "Search Games with Predictions",
    "section": "Searching on the Infinite Line",
    "text": "Searching on the Infinite Line\n\nThe study expands the analysis to the linear search problem, focusing specifically on finding Pareto-optimal strategies with predictions for the Searcher’s location."
  },
  {
    "objectID": "posts/Search_Games_with_Predictions/2024-01-02-Search_Games_with_Predictions.html#conclusion",
    "href": "posts/Search_Games_with_Predictions/2024-01-02-Search_Games_with_Predictions.html#conclusion",
    "title": "Search Games with Predictions",
    "section": "Conclusion",
    "text": "Conclusion\n\nThe paper concludes by emphasizing its pioneering analysis of search games with predictions and suggests potential applications of this framework in other classes of games rooted in Search Theory, such as patrolling, rendezvous, and cops and robbers games."
  },
  {
    "objectID": "posts/Search_Games_with_Predictions/2024-01-02-Search_Games_with_Predictions.html#critique",
    "href": "posts/Search_Games_with_Predictions/2024-01-02-Search_Games_with_Predictions.html#critique",
    "title": "Search Games with Predictions",
    "section": "Critique",
    "text": "Critique\nThe paper provides a comprehensive and insightful analysis of search games with predictions. However, it could benefit from clearer explanations of the implications of the findings in practical scenarios and potential limitations of the proposed framework. Additionally, further empirical validation of the proposed strategies in real-world search scenarios could enhance the paper’s practical relevance."
  },
  {
    "objectID": "posts/Search_Games_with_Predictions/2024-01-02-Search_Games_with_Predictions.html#appendix",
    "href": "posts/Search_Games_with_Predictions/2024-01-02-Search_Games_with_Predictions.html#appendix",
    "title": "Search Games with Predictions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01149v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01149v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8210"
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#key-findings",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#key-findings",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Key Findings",
    "text": "Key Findings\n\nThe paper presents an evolving large language model assistant that utilizes verbal long-term memory to preserve knowledge and experience from previous dialogues to improve future responses.\nConditional memory is proposed as a new memorizing mechanism to address the shortcomings of existing methods in preserving and utilizing critical information from dialogues.\nThe study evaluates the model on three constructed test datasets focusing on different abilities required by an AI assistant with long-term memory and finds that conditional memory achieves relatively better results."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#introduction",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#introduction",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Introduction",
    "text": "Introduction\n\nThe rapid development of large language models has led to the widespread use of AI assistants such as ChatGPT, which provide assistance through dialogue interactions.\nHowever, current AI assistants lack the ability to preserve information from previous dialogue sessions, hindering their capacity to learn and improve responses over time."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#proposed-framework",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#proposed-framework",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Proposed Framework",
    "text": "Proposed Framework\n\nThe evolving large language model assistant is made up of an existing LLM assistant, a memory, and a prompt-based wrapper responsible for interactions between the assistant and the memory.\nThe wrapper constructs memory records from ongoing dialogues and stores them in the memory, which is later retrieved to enhance the quality of responses."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#memory-construction",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#memory-construction",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Memory Construction",
    "text": "Memory Construction\n\nThe study explores three types of memory construction mechanisms: History-Based Memory, Summary-Based Memory, and Conditional Memory.\nConditional Memory is proposed to selectively memorize crucial information based on the importance of each utterance."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#memory-retrieval-and-application",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#memory-retrieval-and-application",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Memory Retrieval and Application",
    "text": "Memory Retrieval and Application\n\nThe retrieval of memory records is conducted using dense retrieval, and a self-reflection mechanism is employed to determine the usefulness of retrieved information in response generation."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#evaluation",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#evaluation",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Evaluation",
    "text": "Evaluation\n\nThe model is evaluated on three test datasets focusing on different aspects: continuing previous dialogues, learning new knowledge, and learning from human feedback.\nThe results show that conditional memory outperforms other forms of memory in learning new knowledge and learning from human feedback."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#critique",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#critique",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Critique",
    "text": "Critique\n\nThe study relies on small-scale test datasets, limiting the generalizability of the findings to real-world scenarios with larger and more diverse data.\nThe paper mainly investigates the foundational aspects of the proposed idea, leaving other key aspects such as the time stamp or forgetting mechanism unexplored."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#appendix",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#appendix",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17257v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17257v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8298"
  },
  {
    "objectID": "posts/GitAgent_Facilitating_Autonomous_Agent_with_GitHub_by_Tool_Extension/2023-12-28-GitAgent_Facilitating_Autonomous_Agent_with_GitHub_by_Tool_Extension.html#appendix",
    "href": "posts/GitAgent_Facilitating_Autonomous_Agent_with_GitHub_by_Tool_Extension/2023-12-28-GitAgent_Facilitating_Autonomous_Agent_with_GitHub_by_Tool_Extension.html#appendix",
    "title": "GitAgent: Facilitating Autonomous Agent with GitHub by Tool Extension",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17294v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17294v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8283"
  },
  {
    "objectID": "posts/Overview_of_the_PromptCBLUE_Shared_Task_in_CHIP2023/2023-12-29-Overview_of_the_PromptCBLUE_Shared_Task_in_CHIP2023.html#appendix",
    "href": "posts/Overview_of_the_PromptCBLUE_Shared_Task_in_CHIP2023/2023-12-29-Overview_of_the_PromptCBLUE_Shared_Task_in_CHIP2023.html#appendix",
    "title": "Overview of the PromptCBLUE Shared Task in CHIP2023",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17522v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17522v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7037"
  },
  {
    "objectID": "posts/Navigating_Uncertainty_Optimizing_API_Dependency_for_Hallucination_Reduction_in_Closed_Book_Question_Answering/2024-01-03-Navigating_Uncertainty_Optimizing_API_Dependency_for_Hallucination_Reduction_in_Closed_Book_Question_Answering.html#appendix",
    "href": "posts/Navigating_Uncertainty_Optimizing_API_Dependency_for_Hallucination_Reduction_in_Closed_Book_Question_Answering/2024-01-03-Navigating_Uncertainty_Optimizing_API_Dependency_for_Hallucination_Reduction_in_Closed_Book_Question_Answering.html#appendix",
    "title": "Navigating Uncertainty: Optimizing API Dependency for Hallucination Reduction in Closed-Book Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01780v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01780v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6011"
  },
  {
    "objectID": "posts/The_Art_of_Defending_A_Systematic_Evaluation_and_Analysis_of_LLM_Defense_Strategies_on_Safety_and_Over_Defensiveness/2023-12-30-The_Art_of_Defending_A_Systematic_Evaluation_and_Analysis_of_LLM_Defense_Strategies_on_Safety_and_Over_Defensiveness.html#appendix",
    "href": "posts/The_Art_of_Defending_A_Systematic_Evaluation_and_Analysis_of_LLM_Defense_Strategies_on_Safety_and_Over_Defensiveness/2023-12-30-The_Art_of_Defending_A_Systematic_Evaluation_and_Analysis_of_LLM_Defense_Strategies_on_Safety_and_Over_Defensiveness.html#appendix",
    "title": "The Art of Defending: A Systematic Evaluation and Analysis of LLM Defense Strategies on Safety and Over-Defensiveness",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00287v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00287v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8573"
  },
  {
    "objectID": "posts/Structured_Packing_in_LLM_Training_Improves_Long_Context_Utilization/2023-12-28-Structured_Packing_in_LLM_Training_Improves_Long_Context_Utilization.html#appendix",
    "href": "posts/Structured_Packing_in_LLM_Training_Improves_Long_Context_Utilization/2023-12-28-Structured_Packing_in_LLM_Training_Improves_Long_Context_Utilization.html#appendix",
    "title": "Structured Packing in LLM Training Improves Long Context Utilization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17296v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17296v2\n\n\nTruncated\nFalse\n\n\nWord Count\n8456"
  },
  {
    "objectID": "posts/Toward_enriched_Cognitive_Learning_with_XAI/2023-12-19-Toward_enriched_Cognitive_Learning_with_XAI.html#appendix",
    "href": "posts/Toward_enriched_Cognitive_Learning_with_XAI/2023-12-19-Toward_enriched_Cognitive_Learning_with_XAI.html#appendix",
    "title": "Toward enriched Cognitive Learning with XAI",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.12290v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.12290v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5546"
  },
  {
    "objectID": "posts/Aligning_Large_Language_Models_with_Human_Preferences_through_Representation_Engineering/2023-12-26-Aligning_Large_Language_Models_with_Human_Preferences_through_Representation_Engineering.html#appendix",
    "href": "posts/Aligning_Large_Language_Models_with_Human_Preferences_through_Representation_Engineering/2023-12-26-Aligning_Large_Language_Models_with_Human_Preferences_through_Representation_Engineering.html#appendix",
    "title": "Aligning Large Language Models with Human Preferences through Representation Engineering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.15997v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.15997v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6563"
  },
  {
    "objectID": "posts/The_Earth_is_Flat_Unveiling_Factual_Errors_in_Large_Language_Models/2024-01-01-The_Earth_is_Flat_Unveiling_Factual_Errors_in_Large_Language_Models.html#summary",
    "href": "posts/The_Earth_is_Flat_Unveiling_Factual_Errors_in_Large_Language_Models/2024-01-01-The_Earth_is_Flat_Unveiling_Factual_Errors_in_Large_Language_Models.html#summary",
    "title": "The Earth is Flat? Unveiling Factual Errors in Large Language Models",
    "section": "Summary",
    "text": "Summary\n\nMajor Takeaways\n\nBiasAsker is introduced as a testing method to identify bias in conversational AI software through asking questions.\nThe study demonstrates that BiasAsker can effectively reveal factual errors in a variety of large language models used in chatbot and digital assistant applications with an accuracy of up to 78.2% for commercial LLMs and an improvement of 33.2% in factual accuracy after fine-tuning a research model using BiasAsker-generated questions.\nBiasAsker is shown to be highly effective in identifying factual errors, passing a manual validation with a ~93% accuracy in identified errors.\n\n\n\nBackground\nRecent advancements in Large Language Models (LLMs) have led to the rapid adoption of AI-driven chatbot and digital assistant applications. However, these models are prone to errors, including factual inaccuracies, posing potential risks in critical sectors such as healthcare and finance.\n\n\nApproach and Implementation\nBiasAsker operates in three stages: Knowledge Graph Construction, Question Generation, and Answer Assessment. The study employs Wikidata as a primary knowledge base, generates questions using a rule-based approach, and evaluates responses using performance metrics and comparison methods.\n\n\nEvaluation\n\nEffectiveness of BiasAsker: BiasAsker successfully identifies factual errors across various LLMs, notably detecting 36.9% of the test cases with errors.\nValidity of Identified Factual Errors: Upon manual inspection, 93% of the identified errors were found to be valid.\nUsing BiasAsker for Improvement: Test cases generated by BiasAsker led to substantial improvements in factual accuracy, with an average improvement of 6.5% using in-context learning and 33.2% via fine-tuning of the research models."
  },
  {
    "objectID": "posts/The_Earth_is_Flat_Unveiling_Factual_Errors_in_Large_Language_Models/2024-01-01-The_Earth_is_Flat_Unveiling_Factual_Errors_in_Large_Language_Models.html#critique",
    "href": "posts/The_Earth_is_Flat_Unveiling_Factual_Errors_in_Large_Language_Models/2024-01-01-The_Earth_is_Flat_Unveiling_Factual_Errors_in_Large_Language_Models.html#critique",
    "title": "The Earth is Flat? Unveiling Factual Errors in Large Language Models",
    "section": "Critique",
    "text": "Critique\nThe paper’s reliance on NLP methods for error detection and the limitation to a single knowledge base may introduce the potential for false positives or overlook factual inaccuracies. Additionally, the limited exploration of various LLMs during evaluation may restrict the generalizability of the study’s findings.\nOverall, the study’s use of BiasAsker offers a valuable contribution to the field of conversational AI software testing, demonstrating its effectiveness in identifying and rectifying factual inaccuracies in large language models. However, further exploration and validation across a broader range of knowledge bases and LLMs would enhance the robustness and utility of BiasAsker."
  },
  {
    "objectID": "posts/The_Earth_is_Flat_Unveiling_Factual_Errors_in_Large_Language_Models/2024-01-01-The_Earth_is_Flat_Unveiling_Factual_Errors_in_Large_Language_Models.html#appendix",
    "href": "posts/The_Earth_is_Flat_Unveiling_Factual_Errors_in_Large_Language_Models/2024-01-01-The_Earth_is_Flat_Unveiling_Factual_Errors_in_Large_Language_Models.html#appendix",
    "title": "The Earth is Flat? Unveiling Factual Errors in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00761v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00761v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11574"
  },
  {
    "objectID": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#major-takeaways",
    "href": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#major-takeaways",
    "title": "Experimenting a New Programming Practice with LLMs",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nPotential for Revolutionizing Software Development: The paper explores the potential of large language models (LLMs) in automating software development, aiming to free engineers from low-level coding and focusing on requirement engineering and system testing.\nDevelopment of AISD: The authors introduce AISD, an AI-aided software development framework designed to engage users throughout the software development process and keep the human developers informed and involved.\nEvaluation of AISD: The experimental results suggest that AISD significantly improves the task pass rate while consuming fewer tokens, emphasizing the critical role of human engagement in AI-aided software development."
  },
  {
    "objectID": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#introduction",
    "href": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#introduction",
    "title": "Experimenting a New Programming Practice with LLMs",
    "section": "Introduction",
    "text": "Introduction\nLarge language models (LLMs) have shown promising performance in natural language understanding and complex problem-solving, leading to applications in code generation. Prior attempts have aimed to replace programmers with LLMs but often failed with non-trivial software projects due to inadequate user feedback and oversight of requirement engineering and system testing."
  },
  {
    "objectID": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#preliminaries",
    "href": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#preliminaries",
    "title": "Experimenting a New Programming Practice with LLMs",
    "section": "Preliminaries",
    "text": "Preliminaries\nThe extensive section reviews LLMs and prompt engineering, emphasizing their capabilities in natural language processing and code synthesis. It also introduces the concept of LLM-based autonomous agents as a core controller for planning and decision-making."
  },
  {
    "objectID": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#our-approach",
    "href": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#our-approach",
    "title": "Experimenting a New Programming Practice with LLMs",
    "section": "Our Approach",
    "text": "Our Approach\nThe paper introduces the AI-aided software development framework AISD, designed to involve users in the development process and to simplify system design to align with LLM capabilities. It lays out the workflow of AISD, involving user feedback in use case generation and manual testing."
  },
  {
    "objectID": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#experiments",
    "href": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#experiments",
    "title": "Experimenting a New Programming Practice with LLMs",
    "section": "Experiments",
    "text": "Experiments\nThe authors evaluate AISD using an internally developed benchmark, CAASD, comparing it to two existing approaches, ChatDev and MetaGPT. The experiment demonstrates that AISD achieved an impressive pass rate of 75.2% with the lowest token consumption, highlighting the critical role of human engagement."
  },
  {
    "objectID": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#related-work",
    "href": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#related-work",
    "title": "Experimenting a New Programming Practice with LLMs",
    "section": "Related Work",
    "text": "Related Work\nThe paper contextualizes its work within existing approaches to automatic code generation, emphasizing the limitations of traditional techniques and the potential of LLMs in software development."
  },
  {
    "objectID": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#critique",
    "href": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#critique",
    "title": "Experimenting a New Programming Practice with LLMs",
    "section": "Critique",
    "text": "Critique\nWhile the paper presents compelling findings about the potential of AI-aided software development and the effectiveness of AISD, it has limitations: - Benchmark Validity: The benchmark created by the authors may have bias and limitations that need to be addressed. - Limited Comparison: The comparison with existing approaches may not fully capture the complexity and diversity of real-world software projects. - Human Interaction: The paper highlights the importance of human interaction but does not delve into the potential challenges and biases introduced by human involvement.\nIn conclusion, the paper presents a compelling approach to AI-aided software development, emphasizing the critical role of human engagement in improving development outcomes. However, further research and refinement are necessary to validate the effectiveness and robustness of the proposed framework."
  },
  {
    "objectID": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#appendix",
    "href": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#appendix",
    "title": "Experimenting a New Programming Practice with LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01062v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01062v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12628"
  },
  {
    "objectID": "posts/Android_dialogue_system_for_customer_service_using_prompt_based_topic_control_and_compliments_generation/2023-12-20-Android_dialogue_system_for_customer_service_using_prompt_based_topic_control_and_compliments_generation.html#appendix",
    "href": "posts/Android_dialogue_system_for_customer_service_using_prompt_based_topic_control_and_compliments_generation/2023-12-20-Android_dialogue_system_for_customer_service_using_prompt_based_topic_control_and_compliments_generation.html#appendix",
    "title": "Android dialogue system for customer service using prompt-based topic control and compliments generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.12924v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.12924v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2038"
  },
  {
    "objectID": "posts/Large_Language_Models_are_Not_Stable_Recommender_Systems/2023-12-25-Large_Language_Models_are_Not_Stable_Recommender_Systems.html#appendix",
    "href": "posts/Large_Language_Models_are_Not_Stable_Recommender_Systems/2023-12-25-Large_Language_Models_are_Not_Stable_Recommender_Systems.html#appendix",
    "title": "Large Language Models are Not Stable Recommender Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.15746v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.15746v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8647"
  },
  {
    "objectID": "posts/EAGLES_Efficient_Accelerated_3D_Gaussians_with_Lightweight_EncodingS/2023-12-07-EAGLES_Efficient_Accelerated_3D_Gaussians_with_Lightweight_EncodingS.html#appendix",
    "href": "posts/EAGLES_Efficient_Accelerated_3D_Gaussians_with_Lightweight_EncodingS/2023-12-07-EAGLES_Efficient_Accelerated_3D_Gaussians_with_Lightweight_EncodingS.html#appendix",
    "title": "EAGLES: Efficient Accelerated 3D Gaussians with Lightweight EncodingS",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.04564v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.04564v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8103"
  },
  {
    "objectID": "posts/Fighting_Fire_with_Fire_Adversarial_Prompting_to_Generate_a_Misinformation_Detection_Dataset/2024-01-09-Fighting_Fire_with_Fire_Adversarial_Prompting_to_Generate_a_Misinformation_Detection_Dataset.html#appendix",
    "href": "posts/Fighting_Fire_with_Fire_Adversarial_Prompting_to_Generate_a_Misinformation_Detection_Dataset/2024-01-09-Fighting_Fire_with_Fire_Adversarial_Prompting_to_Generate_a_Misinformation_Detection_Dataset.html#appendix",
    "title": "Fighting Fire with Fire: Adversarial Prompting to Generate a Misinformation Detection Dataset",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.04481v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.04481v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6577"
  },
  {
    "objectID": "posts/A__B__B__A_Triggering_Logical_Reasoning_Failures_in_Large_Language_Models/2024-01-01-A__B__B__A_Triggering_Logical_Reasoning_Failures_in_Large_Language_Models.html#biasasker-measuring-the-bias-in-your-chatbot-via-asking-questions",
    "href": "posts/A__B__B__A_Triggering_Logical_Reasoning_Failures_in_Large_Language_Models/2024-01-01-A__B__B__A_Triggering_Logical_Reasoning_Failures_in_Large_Language_Models.html#biasasker-measuring-the-bias-in-your-chatbot-via-asking-questions",
    "title": "A & B == B & A: Triggering Logical Reasoning Failures in Large Language Models",
    "section": "BiasAsker: Measuring the Bias in Your Chatbot via Asking Questions",
    "text": "BiasAsker: Measuring the Bias in Your Chatbot via Asking Questions\n\nMajor Findings\n\nBiasAsker proposes a novel testing method to automatically detect bias in conversational AI software by asking questions. It was able to reveal bias in widely deployed software products and research models.\nThe research demonstrates the potential for BiasAsker to effectively identify biases and improve the performance of conversational AI software.\nThe paper provides valuable insights into the biases and weaknesses of conversational AI software, helping uncover specific areas that require improvement.\n\n\n\nIntroduction\n\nConversational AI software products, like chatbots and digital assistants, have gained widespread use, but they may generate speech containing biases and stereotypes.\nExisting methods for detecting bias in conversational AI systems have limitations, prompting the need for a new testing method.\n\n\n\nLogicAsker Framework\n\nLogicAsker systematically generates reasoning questions to evaluate the logical reasoning ability of large language models (LLMs).\nThe framework identifies weaknesses in LLMs’ logical reasoning abilities and provides insights into their strengths and weaknesses in different logical skills.\n\n\n\nEvaluation of BiasAsker\n\nBiasAsker was effective in triggering logical reasoning failures in conversational AI systems, exposing their weaknesses and biases.\nThe test cases generated by BiasAsker were found to be valid and reliable, indicating the framework’s ability to accurately identify biases and logical reasoning failures.\nThe research demonstrated the potential of BiasAsker to improve the reasoning ability of conversational AI software through in-context learning, further highlighting its effectiveness.\n\n\n\nCritique\nThe paper presents a promising approach to detecting biases in conversational AI systems, but it may be subject to limitations: - The evaluation was limited to a small set of LLMs, and the effectiveness of BiasAsker on other systems is still unproven. - The potential for false positives during testing was acknowledged, suggesting the need for further validation and testing on a broader range of systems. - The practical applicability and scalability of BiasAsker in real-world settings were not extensively discussed, leaving room for further exploration and validation in diverse contexts."
  },
  {
    "objectID": "posts/A__B__B__A_Triggering_Logical_Reasoning_Failures_in_Large_Language_Models/2024-01-01-A__B__B__A_Triggering_Logical_Reasoning_Failures_in_Large_Language_Models.html#appendix",
    "href": "posts/A__B__B__A_Triggering_Logical_Reasoning_Failures_in_Large_Language_Models/2024-01-01-A__B__B__A_Triggering_Logical_Reasoning_Failures_in_Large_Language_Models.html#appendix",
    "title": "A & B == B & A: Triggering Logical Reasoning Failures in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00757v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00757v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10017"
  },
  {
    "objectID": "posts/Distribution_Matching_for_Multi_Task_Learning_of_Classification_Tasks_a_Large_Scale_Study_on_Faces__Beyond/2024-01-02-Distribution_Matching_for_Multi_Task_Learning_of_Classification_Tasks_a_Large_Scale_Study_on_Faces__Beyond.html#appendix",
    "href": "posts/Distribution_Matching_for_Multi_Task_Learning_of_Classification_Tasks_a_Large_Scale_Study_on_Faces__Beyond/2024-01-02-Distribution_Matching_for_Multi_Task_Learning_of_Classification_Tasks_a_Large_Scale_Study_on_Faces__Beyond.html#appendix",
    "title": "Distribution Matching for Multi-Task Learning of Classification Tasks: a Large-Scale Study on Faces & Beyond",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01219v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01219v1\n\n\nTruncated\nTrue\n\n\nWord Count\n14703"
  },
  {
    "objectID": "posts/AI_Gender_Bias_Disparities_and_Fairness_Does_Training_Data_Matter/2023-12-17-AI_Gender_Bias_Disparities_and_Fairness_Does_Training_Data_Matter.html#major-findings",
    "href": "posts/AI_Gender_Bias_Disparities_and_Fairness_Does_Training_Data_Matter/2023-12-17-AI_Gender_Bias_Disparities_and_Fairness_Does_Training_Data_Matter.html#major-findings",
    "title": "AI Gender Bias, Disparities, and Fairness: Does Training Data Matter?",
    "section": "Major Findings",
    "text": "Major Findings\n\nMinimal Scoring Bias: The study found that training AI models on gender-unbalanced data did not lead to significant scoring bias. Mixed-trained models showed no significant difference in scoring accuracy compared to gender-specifically trained models, suggesting minimal scoring bias.\nReduced Disparities: Mixed-trained models generated fewer mean score gaps and reduced gender disparities compared to gender-specifically trained models, indicating that unbalanced training data may create algorithmic models that enlarge gender disparities.\nEnhanced Fairness: The Equalized Odds analysis suggests that mixed-trained models generated fairer outcomes compared with gender-specifically trained models, further highlighting the potential of balanced training data in addressing gender fairness."
  },
  {
    "objectID": "posts/AI_Gender_Bias_Disparities_and_Fairness_Does_Training_Data_Matter/2023-12-17-AI_Gender_Bias_Disparities_and_Fairness_Does_Training_Data_Matter.html#methodology",
    "href": "posts/AI_Gender_Bias_Disparities_and_Fairness_Does_Training_Data_Matter/2023-12-17-AI_Gender_Bias_Disparities_and_Fairness_Does_Training_Data_Matter.html#methodology",
    "title": "AI Gender Bias, Disparities, and Fairness: Does Training Data Matter?",
    "section": "Methodology",
    "text": "Methodology\n\nThe study employed a comprehensive methodology, including data analysis using BERT and GPT-3.5, statistical techniques such as Scoring Accuracy Difference, Mean Score Gap, and Equalized Odds evaluation."
  },
  {
    "objectID": "posts/AI_Gender_Bias_Disparities_and_Fairness_Does_Training_Data_Matter/2023-12-17-AI_Gender_Bias_Disparities_and_Fairness_Does_Training_Data_Matter.html#background",
    "href": "posts/AI_Gender_Bias_Disparities_and_Fairness_Does_Training_Data_Matter/2023-12-17-AI_Gender_Bias_Disparities_and_Fairness_Does_Training_Data_Matter.html#background",
    "title": "AI Gender Bias, Disparities, and Fairness: Does Training Data Matter?",
    "section": "Background",
    "text": "Background\n\nAI in Education: The role of AI in education, implications, and ethical considerations.\nAutomatic Scoring in Education: Advancements, challenges, and machine-human score agreements.\nAI Gender Bias, Disparities, and Fairness: The complexities and implications of gender biases in AI and the need for a multidisciplinary approach."
  },
  {
    "objectID": "posts/AI_Gender_Bias_Disparities_and_Fairness_Does_Training_Data_Matter/2023-12-17-AI_Gender_Bias_Disparities_and_Fairness_Does_Training_Data_Matter.html#results",
    "href": "posts/AI_Gender_Bias_Disparities_and_Fairness_Does_Training_Data_Matter/2023-12-17-AI_Gender_Bias_Disparities_and_Fairness_Does_Training_Data_Matter.html#results",
    "title": "AI Gender Bias, Disparities, and Fairness: Does Training Data Matter?",
    "section": "Results",
    "text": "Results\n\nScoring Accuracy Difference Evaluation: Both BERT and GPT-3.5 models demonstrated consistent performance across mixed and gender-specific datasets, suggesting minimal gender biases.\nMean Score Gap: Training with a mixed dataset in both BERT and GPT-3.5 models showed reduced MSG compared to gender-specific training, indicating reduced gender disparities and heightened fairness.\nEqualized Odds Evaluation: Mixed trained models for both BERT and GPT-3.5 showed lower EO values, suggesting more equitable predictions and higher fairness compared to gender-specific models."
  },
  {
    "objectID": "posts/AI_Gender_Bias_Disparities_and_Fairness_Does_Training_Data_Matter/2023-12-17-AI_Gender_Bias_Disparities_and_Fairness_Does_Training_Data_Matter.html#critique",
    "href": "posts/AI_Gender_Bias_Disparities_and_Fairness_Does_Training_Data_Matter/2023-12-17-AI_Gender_Bias_Disparities_and_Fairness_Does_Training_Data_Matter.html#critique",
    "title": "AI Gender Bias, Disparities, and Fairness: Does Training Data Matter?",
    "section": "Critique",
    "text": "Critique\n\nPotential Problems: While the study demonstrates the potential of balanced training data in addressing gender fairness, it may benefit from a more extensive dataset and broader representation across academic disciplines to generalize the findings.\n\nOverall, the study provides valuable insights into the impact of training data on gender biases in AI scoring systems and emphasizes the significance of inclusive and equitable AI practices in education."
  },
  {
    "objectID": "posts/AI_Gender_Bias_Disparities_and_Fairness_Does_Training_Data_Matter/2023-12-17-AI_Gender_Bias_Disparities_and_Fairness_Does_Training_Data_Matter.html#appendix",
    "href": "posts/AI_Gender_Bias_Disparities_and_Fairness_Does_Training_Data_Matter/2023-12-17-AI_Gender_Bias_Disparities_and_Fairness_Does_Training_Data_Matter.html#appendix",
    "title": "AI Gender Bias, Disparities, and Fairness: Does Training Data Matter?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10833v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10833v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9836"
  },
  {
    "objectID": "posts/Your_Student_is_Better_Than_Expected_Adaptive_Teacher_Student_Collaboration_for_Text_Conditional_Diffusion_Models/2023-12-17-Your_Student_is_Better_Than_Expected_Adaptive_Teacher_Student_Collaboration_for_Text_Conditional_Diffusion_Models.html#appendix",
    "href": "posts/Your_Student_is_Better_Than_Expected_Adaptive_Teacher_Student_Collaboration_for_Text_Conditional_Diffusion_Models/2023-12-17-Your_Student_is_Better_Than_Expected_Adaptive_Teacher_Student_Collaboration_for_Text_Conditional_Diffusion_Models.html#appendix",
    "title": "Your Student is Better Than Expected: Adaptive Teacher-Student Collaboration for Text-Conditional Diffusion Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10835v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10835v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11132"
  },
  {
    "objectID": "posts/The_Problem_of_Alignment/2023-12-30-The_Problem_of_Alignment.html#appendix",
    "href": "posts/The_Problem_of_Alignment/2023-12-30-The_Problem_of_Alignment.html#appendix",
    "title": "The Problem of Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00210v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00210v1\n\n\nTruncated\nTrue\n\n\nWord Count\n20502"
  },
  {
    "objectID": "posts/Scalable_and_automated_Evaluation_of_Blue_Team_cyber_posture_in_Cyber_Ranges/2023-12-28-Scalable_and_automated_Evaluation_of_Blue_Team_cyber_posture_in_Cyber_Ranges.html#appendix",
    "href": "posts/Scalable_and_automated_Evaluation_of_Blue_Team_cyber_posture_in_Cyber_Ranges/2023-12-28-Scalable_and_automated_Evaluation_of_Blue_Team_cyber_posture_in_Cyber_Ranges.html#appendix",
    "title": "Scalable and automated Evaluation of Blue Team cyber posture in Cyber Ranges",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17221v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17221v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3860"
  },
  {
    "objectID": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#key-findings",
    "href": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#key-findings",
    "title": "Neural Contextual Bandits for Personalized Recommendation",
    "section": "Key Findings",
    "text": "Key Findings\n\nContextual bandits offer an effective framework for personalized recommendations in online businesses, addressing the shortcomings of static supervised learning methods and the “Matthew Effect” in recommender systems.\nNeural contextual bandits have emerged as a crucial branch, leveraging the representation power of neural networks to tackle non-linear problem settings in the realm of contextual bandits for personalized recommendation.\nThis tutorial aims to provide an extensive review of advanced algorithms and theories, collaborative strategies, and open challenges in the field of neural contextual bandits for personalized recommendation."
  },
  {
    "objectID": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#introduction",
    "href": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#introduction",
    "title": "Neural Contextual Bandits for Personalized Recommendation",
    "section": "Introduction",
    "text": "Introduction\n\nRecommender systems play a crucial role in online businesses, traditionally relying on static supervised learning methods.\nThe ideal recommender system should adapt over time, prompting the formulation of the recommendation process as a sequential decision-making process.\nContextual bandits and neural contextual bandits have been introduced as techniques to address the challenges of balancing exploitation and exploration in personalized recommendation."
  },
  {
    "objectID": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#target-audience",
    "href": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#target-audience",
    "title": "Neural Contextual Bandits for Personalized Recommendation",
    "section": "Target Audience",
    "text": "Target Audience\n\nThe tutorial targets individuals interested in multi-armed bandits, reinforcement learning, information retrieval, data mining, and recommender systems, with a balance of introductory and advanced material."
  },
  {
    "objectID": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#short-bio-of-presenters",
    "href": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#short-bio-of-presenters",
    "title": "Neural Contextual Bandits for Personalized Recommendation",
    "section": "Short Bio of Presenters",
    "text": "Short Bio of Presenters\n\nYikun Ban, Yunzhe Qi, and Jingrui He are experienced researchers and practitioners with expertise in multi-armed bandits, reinforcement learning, and personalized recommendation systems."
  },
  {
    "objectID": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#outline",
    "href": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#outline",
    "title": "Neural Contextual Bandits for Personalized Recommendation",
    "section": "Outline",
    "text": "Outline\n\nThe tutorial comprises four parts: the introduction, linear contextual bandits, neural contextual bandits, collaborative contextual bandits, and open questions and future trends.\nEach part includes a deep dive into various algorithms, theories, and applications of contextual bandits in personalized recommendation settings."
  },
  {
    "objectID": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#related-tutorials-or-talks",
    "href": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#related-tutorials-or-talks",
    "title": "Neural Contextual Bandits for Personalized Recommendation",
    "section": "Related Tutorials or Talks",
    "text": "Related Tutorials or Talks\n\nContrasting with other industry and academic tutorials, this tutorial focuses specifically on neural contextual bandits and collaborative contextual bandits for personalized recommendation."
  },
  {
    "objectID": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#previous-editions",
    "href": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#previous-editions",
    "title": "Neural Contextual Bandits for Personalized Recommendation",
    "section": "Previous Editions",
    "text": "Previous Editions\n\nThis tutorial marks the first edition, but the presenters have prior experience in teaching material covering similar topics."
  },
  {
    "objectID": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#critique",
    "href": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#critique",
    "title": "Neural Contextual Bandits for Personalized Recommendation",
    "section": "Critique",
    "text": "Critique\nThe abstract and outline provide a comprehensive overview of the tutorial’s content, but the abstract could be more succinct. Additionally, the excessive focus on the presenters’ achievements might detract from the tutorial’s core content. The lack of specific case studies or real-world applications of the discussed algorithms and theories could limit the practical applicability of the tutorial."
  },
  {
    "objectID": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#appendix",
    "href": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#appendix",
    "title": "Neural Contextual Bandits for Personalized Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.14037v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.14037v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4052"
  },
  {
    "objectID": "posts/LLM_Interactive_Optimization_of_Open_Source_Python_Libraries____Case_Studies_and_Generalization/2023-12-08-LLM_Interactive_Optimization_of_Open_Source_Python_Libraries____Case_Studies_and_Generalization.html#appendix",
    "href": "posts/LLM_Interactive_Optimization_of_Open_Source_Python_Libraries____Case_Studies_and_Generalization/2023-12-08-LLM_Interactive_Optimization_of_Open_Source_Python_Libraries____Case_Studies_and_Generalization.html#appendix",
    "title": "LLM Interactive Optimization of Open Source Python Libraries – Case Studies and Generalization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.14949v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.14949v1\n\n\nTruncated\nTrue\n\n\nWord Count\n18038"
  },
  {
    "objectID": "posts/Physics_informed_Generalizable_Wireless_Channel_Modeling_with_Segmentation_and_Deep_Learning_Fundamentals_Methodologies_and_Challenges/2024-01-02-Physics_informed_Generalizable_Wireless_Channel_Modeling_with_Segmentation_and_Deep_Learning_Fundamentals_Methodologies_and_Challenges.html#appendix",
    "href": "posts/Physics_informed_Generalizable_Wireless_Channel_Modeling_with_Segmentation_and_Deep_Learning_Fundamentals_Methodologies_and_Challenges/2024-01-02-Physics_informed_Generalizable_Wireless_Channel_Modeling_with_Segmentation_and_Deep_Learning_Fundamentals_Methodologies_and_Challenges.html#appendix",
    "title": "Physics-informed Generalizable Wireless Channel Modeling with Segmentation and Deep Learning: Fundamentals, Methodologies, and Challenges",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01288v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01288v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8770"
  },
  {
    "objectID": "posts/SecFormer_Towards_Fast_and_Accurate_Privacy_Preserving_Inference_for_Large_Language_Models/2024-01-01-SecFormer_Towards_Fast_and_Accurate_Privacy_Preserving_Inference_for_Large_Language_Models.html#appendix",
    "href": "posts/SecFormer_Towards_Fast_and_Accurate_Privacy_Preserving_Inference_for_Large_Language_Models/2024-01-01-SecFormer_Towards_Fast_and_Accurate_Privacy_Preserving_Inference_for_Large_Language_Models.html#appendix",
    "title": "SecFormer: Towards Fast and Accurate Privacy-Preserving Inference for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00793v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00793v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10983"
  },
  {
    "objectID": "posts/DB_GPT_Empowering_Database_Interactions_with_Private_Large_Language_Models/2023-12-29-DB_GPT_Empowering_Database_Interactions_with_Private_Large_Language_Models.html#appendix",
    "href": "posts/DB_GPT_Empowering_Database_Interactions_with_Private_Large_Language_Models/2023-12-29-DB_GPT_Empowering_Database_Interactions_with_Private_Large_Language_Models.html#appendix",
    "title": "DB-GPT: Empowering Database Interactions with Private Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17449v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17449v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8411"
  },
  {
    "objectID": "posts/Fast_Inference_of_Mixture_of_Experts_Language_Models_with_Offloading/2023-12-28-Fast_Inference_of_Mixture_of_Experts_Language_Models_with_Offloading.html#appendix",
    "href": "posts/Fast_Inference_of_Mixture_of_Experts_Language_Models_with_Offloading/2023-12-28-Fast_Inference_of_Mixture_of_Experts_Language_Models_with_Offloading.html#appendix",
    "title": "Fast Inference of Mixture-of-Experts Language Models with Offloading",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17238v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17238v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6493"
  },
  {
    "objectID": "posts/TechGPT_2.0_A_large_language_model_project_to_solve_the_task_of_knowledge_graph_construction/2024-01-09-TechGPT_2.0_A_large_language_model_project_to_solve_the_task_of_knowledge_graph_construction.html#appendix",
    "href": "posts/TechGPT_2.0_A_large_language_model_project_to_solve_the_task_of_knowledge_graph_construction/2024-01-09-TechGPT_2.0_A_large_language_model_project_to_solve_the_task_of_knowledge_graph_construction.html#appendix",
    "title": "TechGPT-2.0: A large language model project to solve the task of knowledge graph construction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.04507v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.04507v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1974"
  },
  {
    "objectID": "posts/The_Persuasive_Power_of_Large_Language_Models/2023-12-24-The_Persuasive_Power_of_Large_Language_Models.html#appendix",
    "href": "posts/The_Persuasive_Power_of_Large_Language_Models/2023-12-24-The_Persuasive_Power_of_Large_Language_Models.html#appendix",
    "title": "The Persuasive Power of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.15523v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.15523v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9545"
  },
  {
    "objectID": "posts/KernelGPT_Enhanced_Kernel_Fuzzing_via_Large_Language_Models/2023-12-31-KernelGPT_Enhanced_Kernel_Fuzzing_via_Large_Language_Models.html#key-findings",
    "href": "posts/KernelGPT_Enhanced_Kernel_Fuzzing_via_Large_Language_Models/2023-12-31-KernelGPT_Enhanced_Kernel_Fuzzing_via_Large_Language_Models.html#key-findings",
    "title": "KernelGPT: Enhanced Kernel Fuzzing via Large Language Models",
    "section": "Key Findings",
    "text": "Key Findings\n\nAutomatic Inference of Syzkaller Specifications: KernelGPT, using Large Language Models (LLMs), automates the inference of all necessary specification components for kernel drivers, significantly improving coverage and detecting multiple previously unknown bugs.\nIterative Approach for Specification Generation: The paper introduces a novel iterative strategy to automatically infer driver descriptions based on kernel code analysis, leveraging state-of-the-art GPT4 to synthesize high-quality specifications.\nValidation and Repair of Specifications: KernelGPT validates and repairs the generated specifications by consulting LLMs with error messages encountered, resulting in enhanced coverage and bug detection."
  },
  {
    "objectID": "posts/KernelGPT_Enhanced_Kernel_Fuzzing_via_Large_Language_Models/2023-12-31-KernelGPT_Enhanced_Kernel_Fuzzing_via_Large_Language_Models.html#summary",
    "href": "posts/KernelGPT_Enhanced_Kernel_Fuzzing_via_Large_Language_Models/2023-12-31-KernelGPT_Enhanced_Kernel_Fuzzing_via_Large_Language_Models.html#summary",
    "title": "KernelGPT: Enhanced Kernel Fuzzing via Large Language Models",
    "section": "Summary",
    "text": "Summary\n\nIntroduction\n\nKernel fuzzing is crucial for detecting potential kernel bugs or vulnerabilities, and Syzkaller is a popular tool for this purpose.\nExisting approaches for automating syscall specifications are mostly manual and lead to incomplete coverage, and KernelGPT aims to address this issue.\n\n\n\nBackground and Related Work\n\nKernel and device drivers are critical for system functionality, and kernel fuzzing using techniques like Syzkaller has been effective in identifying vulnerabilities.\nExisting techniques for syscall specification generation rely on static analysis or dynamic tracing with limitations in accuracy and efficiency.\n\n\n\nApproach\n\nKernelGPT utilizes an iterative approach to automatically infer driver specifications and further repair the descriptions with the validation feedback.\nThe process involves driver detection, specification generation, and specification validation and repair.\n\n\n\nImplementation\n\nThe paper details the implementation of the source code extractor, analysis LLM, few-shot prompting, and driver selection in the experiment.\n\n\n\nEvaluation\n\nKernelGPT is evaluated based on the number and quality of generated specifications, comparison with baselines, and the detection of kernel bugs.\n\n\n\nConclusion\n\nThe paper concludes by summarizing the key contributions of KernelGPT and the future potential for leveraging LLMs in kernel fuzzing."
  },
  {
    "objectID": "posts/KernelGPT_Enhanced_Kernel_Fuzzing_via_Large_Language_Models/2023-12-31-KernelGPT_Enhanced_Kernel_Fuzzing_via_Large_Language_Models.html#critique",
    "href": "posts/KernelGPT_Enhanced_Kernel_Fuzzing_via_Large_Language_Models/2023-12-31-KernelGPT_Enhanced_Kernel_Fuzzing_via_Large_Language_Models.html#critique",
    "title": "KernelGPT: Enhanced Kernel Fuzzing via Large Language Models",
    "section": "Critique",
    "text": "Critique\nThe paper provides comprehensive details on the implementation and evaluation of KernelGPT, showcasing its effectiveness in enhancing kernel fuzzing. However, the experimental evaluation is preliminary, and the success could be influenced by the specific kernel version or configuration used in the study. Additionally, the potential limitations of using LLMs in this context, such as context size limitations and difficulties with complex code logic, should be further discussed for a comprehensive assessment of the approach."
  },
  {
    "objectID": "posts/KernelGPT_Enhanced_Kernel_Fuzzing_via_Large_Language_Models/2023-12-31-KernelGPT_Enhanced_Kernel_Fuzzing_via_Large_Language_Models.html#appendix",
    "href": "posts/KernelGPT_Enhanced_Kernel_Fuzzing_via_Large_Language_Models/2023-12-31-KernelGPT_Enhanced_Kernel_Fuzzing_via_Large_Language_Models.html#appendix",
    "title": "KernelGPT: Enhanced Kernel Fuzzing via Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00563v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00563v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12049"
  },
  {
    "objectID": "posts/TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models/2024-01-09-TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models.html#major-takeaways",
    "href": "posts/TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models/2024-01-09-TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models.html#major-takeaways",
    "title": "TransportationGames: Benchmarking Transportation Knowledge of (Multimodal) Large Language Models",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nTransportationGames is a comprehensive evaluation benchmark designed to assess the capabilities of (M)LLMs in executing transportation-related tasks. It categorizes these tasks into three skill levels based on widely recognized Bloom’s cognitive models: Transportation knowledge memorization, understanding, and applying.\nEvaluation results show that while some models perform well in certain tasks, there is still much room for improvement overall. This suggests that (M)LLMs may not possess reliable transportation knowledge and struggle with transportation-related tasks.\nThe study not only identifies the performance of various (M)LLMs but also analyzes the key factors affecting model performance. It hopes that the release of TransportationGames can serve as a foundation for future research, thereby accelerating the implementation and application of (M)LLMs in the transportation domain."
  },
  {
    "objectID": "posts/TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models/2024-01-09-TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models.html#introduction",
    "href": "posts/TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models/2024-01-09-TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models.html#introduction",
    "title": "TransportationGames: Benchmarking Transportation Knowledge of (Multimodal) Large Language Models",
    "section": "Introduction",
    "text": "Introduction\n\nLarge language models (LLMs) and multimodal large language models (MLLMs) have shown exceptional general capabilities and are increasingly being utilized across various professional domains.\nEvaluation benchmarks are crucial for assessing (M)LLMs and gaining insights into their strengths and weaknesses. Domain-specific benchmarks are especially important for driving practical progress and responsible implementation.\nThere is a lack of systematic evaluation benchmarks for the transportation domain, prompting the introduction of TransportationGames to assess (M)LLMs in transportation-related tasks."
  },
  {
    "objectID": "posts/TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models/2024-01-09-TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models.html#benchmark-construction",
    "href": "posts/TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models/2024-01-09-TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models.html#benchmark-construction",
    "title": "TransportationGames: Benchmarking Transportation Knowledge of (Multimodal) Large Language Models",
    "section": "Benchmark Construction",
    "text": "Benchmark Construction\n\nTransportationGames is organized using the first three levels in Bloom’s Taxonomy to evaluate (M)LLMs. It includes 10 tasks based on diverse sub-domains in the transportation domain, employing multiple-choice, “True/False” judge, and text generation formats.\nThe tasks are categorized into three skill levels: Transportation knowledge memorization, understanding, and applying, to offer a systematic outline of the skillset necessary for transportation-related tasks."
  },
  {
    "objectID": "posts/TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models/2024-01-09-TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models.html#experiments",
    "href": "posts/TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models/2024-01-09-TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models.html#experiments",
    "title": "TransportationGames: Benchmarking Transportation Knowledge of (Multimodal) Large Language Models",
    "section": "Experiments",
    "text": "Experiments\n\nThe evaluation results of LLMs on the text-only dataset of TransportationGames show varying performance across different models. Similarly, MLLMs exhibit differing performance on the multimodal dataset."
  },
  {
    "objectID": "posts/TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models/2024-01-09-TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models.html#analysis",
    "href": "posts/TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models/2024-01-09-TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models.html#analysis",
    "title": "TransportationGames: Benchmarking Transportation Knowledge of (Multimodal) Large Language Models",
    "section": "Analysis",
    "text": "Analysis\n\nThe study observes that the format error rate of some models is zero, indicating excellent instruction-following ability. There is still much room for improvement for some tasks, especially in multimodal scenarios.\nThe choice of BaseModel significantly affects model performance, and scaling up the model size can improve performance with similar BaseModels."
  },
  {
    "objectID": "posts/TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models/2024-01-09-TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models.html#conclusion",
    "href": "posts/TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models/2024-01-09-TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models.html#conclusion",
    "title": "TransportationGames: Benchmarking Transportation Knowledge of (Multimodal) Large Language Models",
    "section": "Conclusion",
    "text": "Conclusion\n\nThe release of TransportationGames serves as a foundation for future research and hopes to accelerate the implementation and application of (M)LLMs in the field of transportation."
  },
  {
    "objectID": "posts/TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models/2024-01-09-TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models.html#critique",
    "href": "posts/TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models/2024-01-09-TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models.html#critique",
    "title": "TransportationGames: Benchmarking Transportation Knowledge of (Multimodal) Large Language Models",
    "section": "Critique",
    "text": "Critique\n\nData Leakage: The study mentions the potential issue of data leakage as the data is collected from the internet. This could impact the fairness of the evaluation.\nModel and Task Selection: Due to time constraints, only a small portion of common models were tested. Additionally, the selection of evaluation tasks may not fully represent all aspects of the transportation domain."
  },
  {
    "objectID": "posts/TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models/2024-01-09-TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models.html#appendix",
    "href": "posts/TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models/2024-01-09-TransportationGames_Benchmarking_Transportation_Knowledge_of_(Multimodal)_Large_Language_Models.html#appendix",
    "title": "TransportationGames: Benchmarking Transportation Knowledge of (Multimodal) Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.04471v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.04471v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7381"
  },
  {
    "objectID": "posts/Integrating_micro_learning_content_in_traditional_e_learning_platforms/2023-12-11-Integrating_micro_learning_content_in_traditional_e_learning_platforms.html#appendix",
    "href": "posts/Integrating_micro_learning_content_in_traditional_e_learning_platforms/2023-12-11-Integrating_micro_learning_content_in_traditional_e_learning_platforms.html#appendix",
    "title": "Integrating micro-learning content in traditional e-learning platforms",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.06500v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.06500v1\n\n\nTruncated\nTrue\n\n\nWord Count\n19579"
  },
  {
    "objectID": "posts/Enhancing_Robot_Program_Synthesis_Through_Environmental_Context/2023-12-13-Enhancing_Robot_Program_Synthesis_Through_Environmental_Context.html#appendix",
    "href": "posts/Enhancing_Robot_Program_Synthesis_Through_Environmental_Context/2023-12-13-Enhancing_Robot_Program_Synthesis_Through_Environmental_Context.html#appendix",
    "title": "Enhancing Robot Program Synthesis Through Environmental Context",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.08250v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.08250v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12023"
  },
  {
    "objectID": "posts/Grimoire_is_All_You_Need_for_Enhancing_Large_Language_Models/2024-01-07-Grimoire_is_All_You_Need_for_Enhancing_Large_Language_Models.html#appendix",
    "href": "posts/Grimoire_is_All_You_Need_for_Enhancing_Large_Language_Models/2024-01-07-Grimoire_is_All_You_Need_for_Enhancing_Large_Language_Models.html#appendix",
    "title": "Grimoire is All You Need for Enhancing Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.03385v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.03385v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7777"
  },
  {
    "objectID": "posts/Malla_Demystifying_Real_world_Large_Language_Model_Integrated_Malicious_Services/2024-01-06-Malla_Demystifying_Real_world_Large_Language_Model_Integrated_Malicious_Services.html#appendix",
    "href": "posts/Malla_Demystifying_Real_world_Large_Language_Model_Integrated_Malicious_Services/2024-01-06-Malla_Demystifying_Real_world_Large_Language_Model_Integrated_Malicious_Services.html#appendix",
    "title": "Malla: Demystifying Real-world Large Language Model Integrated Malicious Services",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.03315v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.03315v1\n\n\nTruncated\nTrue\n\n\nWord Count\n17982"
  },
  {
    "objectID": "posts/Differentially_Private_Low_Rank_Adaptation_of_Large_Language_Model_Using_Federated_Learning/2023-12-29-Differentially_Private_Low_Rank_Adaptation_of_Large_Language_Model_Using_Federated_Learning.html#appendix",
    "href": "posts/Differentially_Private_Low_Rank_Adaptation_of_Large_Language_Model_Using_Federated_Learning/2023-12-29-Differentially_Private_Low_Rank_Adaptation_of_Large_Language_Model_Using_Federated_Learning.html#appendix",
    "title": "Differentially Private Low-Rank Adaptation of Large Language Model Using Federated Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17493v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17493v1\n\n\nTruncated\nTrue\n\n\nWord Count\n15580"
  },
  {
    "objectID": "posts/Coevolutionary_Algorithm_for_Building_Robust_Decision_Trees_under_Minimax_Regret/2023-12-14-Coevolutionary_Algorithm_for_Building_Robust_Decision_Trees_under_Minimax_Regret.html#appendix",
    "href": "posts/Coevolutionary_Algorithm_for_Building_Robust_Decision_Trees_under_Minimax_Regret/2023-12-14-Coevolutionary_Algorithm_for_Building_Robust_Decision_Trees_under_Minimax_Regret.html#appendix",
    "title": "Coevolutionary Algorithm for Building Robust Decision Trees under Minimax Regret",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.09078v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.09078v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10754"
  },
  {
    "objectID": "posts/Factoring_Expertise_Workload_and_Turnover_into_Code_Review_Recommendation/2023-12-28-Factoring_Expertise_Workload_and_Turnover_into_Code_Review_Recommendation.html#summary",
    "href": "posts/Factoring_Expertise_Workload_and_Turnover_into_Code_Review_Recommendation/2023-12-28-Factoring_Expertise_Workload_and_Turnover_into_Code_Review_Recommendation.html#summary",
    "title": "Factoring Expertise, Workload, and Turnover into Code Review Recommendation",
    "section": "Summary",
    "text": "Summary\n\nKey Findings\n\nDeveloper turnover on software projects leads to knowledge loss, reduced productivity, and increased defects.\nDistributed knowledge and reduced turnover risk are achieved through code review recommendations that are aware of code ownership, workload, and knowledge distribution.\nExisting code review recommenders focused solely on finding experts concentrate knowledge on a small group of developers, increasing the risk of knowledge loss from turnover.\n\n\n\nHistorical Analysis\n\nUse of code review naturally distributes knowledge and reduces the number of files at risk to turnover.\nRecommending reviewers based on ownership increases expertise but raises the number of files at risk to turnover, indicating concentration of knowledge.\nWorkload is not evenly distributed across developers, with top reviewers bearing the majority of the workload.\n\n\n\nSimulation Results\n\nLearnRec: Decreases expertise, distributes workload unevenly, and increases the files at risk to turnover.\nRetentionRec: Increases expertise, slightly increases workload concentration, and reduces the files at risk to turnover.\nSofia: Increases expertise, slightly increases workload concentration, and reduces the files at risk to turnover.\nWhoDo: Increases expertise, decreases workload concentration, but increases the files at risk to turnover.\nSofiaWL: Increases expertise, decreases workload concentration, and reduces the files at risk to turnover.\n\n\n\nCritique\nThe paper provided valuable insights into code review recommendations, but the impact of the proposed recommenders on developer satisfaction, team dynamics, and long-term project outcomes was not addressed. The focus on reducing the number of files at risk to turnover may inadvertently increase the workload for some developers, potentially leading to burnout and reduced productivity. Additionally, the study did not consider factors such as team diversity and collaboration, which could have significant implications for project success.\nThe paper could benefit from further exploration of the potential unintended consequences of workload distribution and turnover reduction on team dynamics and developer well-being. It would also be valuable to address practical implementation challenges and potential trade-offs associated with adopting the proposed code review recommenders in real-world software development settings."
  },
  {
    "objectID": "posts/Factoring_Expertise_Workload_and_Turnover_into_Code_Review_Recommendation/2023-12-28-Factoring_Expertise_Workload_and_Turnover_into_Code_Review_Recommendation.html#appendix",
    "href": "posts/Factoring_Expertise_Workload_and_Turnover_into_Code_Review_Recommendation/2023-12-28-Factoring_Expertise_Workload_and_Turnover_into_Code_Review_Recommendation.html#appendix",
    "title": "Factoring Expertise, Workload, and Turnover into Code Review Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17236v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17236v1\n\n\nTruncated\nTrue\n\n\nWord Count\n17921"
  },
  {
    "objectID": "posts/Profiling_Programming_Language_Learning/2024-01-02-Profiling_Programming_Language_Learning.html#appendix",
    "href": "posts/Profiling_Programming_Language_Learning/2024-01-02-Profiling_Programming_Language_Learning.html#appendix",
    "title": "Profiling Programming Language Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01257v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01257v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3045"
  },
  {
    "objectID": "posts/Critical_nonlinear_aspects_of_hopping_transport_for_reconfigurable_logic_in_disordered_dopant_networks/2023-12-26-Critical_nonlinear_aspects_of_hopping_transport_for_reconfigurable_logic_in_disordered_dopant_networks.html#appendix",
    "href": "posts/Critical_nonlinear_aspects_of_hopping_transport_for_reconfigurable_logic_in_disordered_dopant_networks/2023-12-26-Critical_nonlinear_aspects_of_hopping_transport_for_reconfigurable_logic_in_disordered_dopant_networks.html#appendix",
    "title": "Critical nonlinear aspects of hopping transport for reconfigurable logic in disordered dopant networks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16037v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16037v1\n\n\nTruncated\nTrue\n\n\nWord Count\n23967"
  },
  {
    "objectID": "posts/DocLLM_A_layout_aware_generative_language_model_for_multimodal_document_understanding/2023-12-31-DocLLM_A_layout_aware_generative_language_model_for_multimodal_document_understanding.html#summary",
    "href": "posts/DocLLM_A_layout_aware_generative_language_model_for_multimodal_document_understanding/2023-12-31-DocLLM_A_layout_aware_generative_language_model_for_multimodal_document_understanding.html#summary",
    "title": "DocLLM: A layout-aware generative language model for multimodal document understanding",
    "section": "Summary",
    "text": "Summary\nThe paper presents DocLLM, a generative language model designed to understand visual documents that contain complex layouts. It incorporates both textual semantics and spatial layout, and it outperforms existing large language models on various document intelligence tasks. DocLLM achieves this without relying on expensive image encoders by focusing exclusively on bounding box information to incorporate the visual spatial layout structure. The model features a disentangled spatial attention mechanism and a pre-training objective tailored to address irregular layouts effectively. The paper concludes by indicating that future work could involve infusing vision into DocLLM in a lightweight manner."
  },
  {
    "objectID": "posts/DocLLM_A_layout_aware_generative_language_model_for_multimodal_document_understanding/2023-12-31-DocLLM_A_layout_aware_generative_language_model_for_multimodal_document_understanding.html#major-takeaways",
    "href": "posts/DocLLM_A_layout_aware_generative_language_model_for_multimodal_document_understanding/2023-12-31-DocLLM_A_layout_aware_generative_language_model_for_multimodal_document_understanding.html#major-takeaways",
    "title": "DocLLM: A layout-aware generative language model for multimodal document understanding",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nDocLLM Outperforms Existing Models: The paper demonstrates that DocLLM outperforms state-of-the-art large language models on various document intelligence tasks, showcasing its efficacy in understanding visually rich documents.\nFocus on Spatial Layout: DocLLM’s lightweight extension focuses exclusively on bounding box information to understand the spatial layout of documents, without relying on expensive image encoders.\nDisentangled Spatial Attention and Block Infilling: The model features a disentangled spatial attention mechanism and a pre-training objective tailored to address irregular layouts effectively."
  },
  {
    "objectID": "posts/DocLLM_A_layout_aware_generative_language_model_for_multimodal_document_understanding/2023-12-31-DocLLM_A_layout_aware_generative_language_model_for_multimodal_document_understanding.html#sections",
    "href": "posts/DocLLM_A_layout_aware_generative_language_model_for_multimodal_document_understanding/2023-12-31-DocLLM_A_layout_aware_generative_language_model_for_multimodal_document_understanding.html#sections",
    "title": "DocLLM: A layout-aware generative language model for multimodal document understanding",
    "section": "Sections",
    "text": "Sections\n\nAbstract\nIntroduction: Challenges in understanding visually rich documents and the need for a different approach from conventional large language models.\nDocLLM Framework: Model architecture, disentangled spatial attention, and pre-training objectives are discussed.\nRelated Work: Review of recent advances in large language models and multimodal large language models.\nExperiments: Evaluation of DocLLM in two experimental settings - Same Datasets, Different Splits (SDDS) and Same Tasks, Different Datasets (STDD).\nAblation Studies: Evaluation of the three main components of DocLLM - disentangled spatial attention, block infilling, and masking strategy.\nDiscussion and Findings: Impressions and observations from internal training experiences.\nConclusions: Summary of the contributions and potential future work."
  },
  {
    "objectID": "posts/DocLLM_A_layout_aware_generative_language_model_for_multimodal_document_understanding/2023-12-31-DocLLM_A_layout_aware_generative_language_model_for_multimodal_document_understanding.html#critique",
    "href": "posts/DocLLM_A_layout_aware_generative_language_model_for_multimodal_document_understanding/2023-12-31-DocLLM_A_layout_aware_generative_language_model_for_multimodal_document_understanding.html#critique",
    "title": "DocLLM: A layout-aware generative language model for multimodal document understanding",
    "section": "Critique",
    "text": "Critique\nThe paper provides a comprehensive and detailed exploration of DocLLM, demonstrating its effectiveness in understanding visually rich documents. However, the evaluation of the model in real-world use cases or commercial applications is not explicitly discussed. Additionally, the paper’s results are derived from the model’s performance in specific experimental settings, and a broader evaluation in diverse real-world scenarios is needed to fully validate its applicability. Moreover, while the ablation studies provide insights into the effectiveness of the individual components of DocLLM, a more in-depth analysis of the limitations or potential failure cases of the model would enhance the paper’s completeness."
  },
  {
    "objectID": "posts/DocLLM_A_layout_aware_generative_language_model_for_multimodal_document_understanding/2023-12-31-DocLLM_A_layout_aware_generative_language_model_for_multimodal_document_understanding.html#appendix",
    "href": "posts/DocLLM_A_layout_aware_generative_language_model_for_multimodal_document_understanding/2023-12-31-DocLLM_A_layout_aware_generative_language_model_for_multimodal_document_understanding.html#appendix",
    "title": "DocLLM: A layout-aware generative language model for multimodal document understanding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00908v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00908v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13500"
  },
  {
    "objectID": "posts/Action_Item_Driven_Summarization_of_Long_Meeting_Transcripts/2023-12-29-Action_Item_Driven_Summarization_of_Long_Meeting_Transcripts.html#appendix",
    "href": "posts/Action_Item_Driven_Summarization_of_Long_Meeting_Transcripts/2023-12-29-Action_Item_Driven_Summarization_of_Long_Meeting_Transcripts.html#appendix",
    "title": "Action-Item-Driven Summarization of Long Meeting Transcripts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17581v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17581v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7904"
  },
  {
    "objectID": "posts/Task_Contamination_Language_Models_May_Not_Be_Few_Shot_Anymore/2023-12-26-Task_Contamination_Language_Models_May_Not_Be_Few_Shot_Anymore.html#appendix",
    "href": "posts/Task_Contamination_Language_Models_May_Not_Be_Few_Shot_Anymore/2023-12-26-Task_Contamination_Language_Models_May_Not_Be_Few_Shot_Anymore.html#appendix",
    "title": "Task Contamination: Language Models May Not Be Few-Shot Anymore",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16337v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16337v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8991"
  },
  {
    "objectID": "posts/Chain_of_Code_Reasoning_with_a_Language_Model_Augmented_Code_Emulator/2023-12-07-Chain_of_Code_Reasoning_with_a_Language_Model_Augmented_Code_Emulator.html#key-findings",
    "href": "posts/Chain_of_Code_Reasoning_with_a_Language_Model_Augmented_Code_Emulator/2023-12-07-Chain_of_Code_Reasoning_with_a_Language_Model_Augmented_Code_Emulator.html#key-findings",
    "title": "Chain of Code: Reasoning with a Language Model-Augmented Code Emulator",
    "section": "Key Findings",
    "text": "Key Findings\n\nChain of Code (CoC) proposes to utilize both code and language models (LMs) to improve reasoning performance across various reasoning tasks, achieving significant improvements over other baseline techniques.\nCoC generates reasoning substeps in the form of code or pseudocode and executes the code with a Python interpreter, using an LMulator to simulate execution for non-executable code, which allows it to perform well on tasks that involve both numeric and semantic reasoning.\nThe overall performance of CoC outperforms Chain of Thought and other baselines across a variety of benchmarks, achieving 84% accuracy on BIG-Bench Hard, a gain of 12% over Chain of Thought."
  },
  {
    "objectID": "posts/Chain_of_Code_Reasoning_with_a_Language_Model_Augmented_Code_Emulator/2023-12-07-Chain_of_Code_Reasoning_with_a_Language_Model_Augmented_Code_Emulator.html#introduction",
    "href": "posts/Chain_of_Code_Reasoning_with_a_Language_Model_Augmented_Code_Emulator/2023-12-07-Chain_of_Code_Reasoning_with_a_Language_Model_Augmented_Code_Emulator.html#introduction",
    "title": "Chain of Code: Reasoning with a Language Model-Augmented Code Emulator",
    "section": "Introduction",
    "text": "Introduction\n\nLanguage models (LMs) have shown to improve reasoning tasks, and using code to prompt LMs has been advantageous due to the structured nature of code and the interface it provides for performing precise algorithmic computations.\nWhile writing and executing code may improve LM reasoning performance across arithmetic tasks, it struggles with many semantic tasks difficult to express in code."
  },
  {
    "objectID": "posts/Chain_of_Code_Reasoning_with_a_Language_Model_Augmented_Code_Emulator/2023-12-07-Chain_of_Code_Reasoning_with_a_Language_Model_Augmented_Code_Emulator.html#chain-of-code-reasoning-with-an-lmulator",
    "href": "posts/Chain_of_Code_Reasoning_with_a_Language_Model_Augmented_Code_Emulator/2023-12-07-Chain_of_Code_Reasoning_with_a_Language_Model_Augmented_Code_Emulator.html#chain-of-code-reasoning-with-an-lmulator",
    "title": "Chain of Code: Reasoning with a Language Model-Augmented Code Emulator",
    "section": "Chain of Code: Reasoning with an LMulator",
    "text": "Chain of Code: Reasoning with an LMulator\n\nCoC encourages LMs to format semantic sub-tasks as flexible pseudocode that can be explicitly caught and handed off to an LMulator for simulation at runtime.\nCoC proceeds in two steps: generation, wherein an LM generates code or pseudocode to solve a problem, and execution, with the code being run using a Python interpreter or an LMulator.\nThe approach scales well with large and small models alike and outperforms Chain of Thought and other baselines across various tasks, even achieving human-rater level performance on several tasks."
  },
  {
    "objectID": "posts/Chain_of_Code_Reasoning_with_a_Language_Model_Augmented_Code_Emulator/2023-12-07-Chain_of_Code_Reasoning_with_a_Language_Model_Augmented_Code_Emulator.html#experimental-evaluation",
    "href": "posts/Chain_of_Code_Reasoning_with_a_Language_Model_Augmented_Code_Emulator/2023-12-07-Chain_of_Code_Reasoning_with_a_Language_Model_Augmented_Code_Emulator.html#experimental-evaluation",
    "title": "Chain of Code: Reasoning with a Language Model-Augmented Code Emulator",
    "section": "Experimental Evaluation",
    "text": "Experimental Evaluation\n\nCoC exhibits high performance across varied problems, particularly excelling in algorithmic tasks and performing on par with Chain of Thought for natural language tasks.\nAblations demonstrate that the interweaving of code and language execution provides significant improvements in performance across tasks.\nCoC’s performance increases with model size, and it outperforms other prompting techniques even with instruction-tuned chat models.\nCoC demonstrates promising results for applications involving robotic tasks that require semantic and algorithmic reasoning."
  },
  {
    "objectID": "posts/Chain_of_Code_Reasoning_with_a_Language_Model_Augmented_Code_Emulator/2023-12-07-Chain_of_Code_Reasoning_with_a_Language_Model_Augmented_Code_Emulator.html#critique",
    "href": "posts/Chain_of_Code_Reasoning_with_a_Language_Model_Augmented_Code_Emulator/2023-12-07-Chain_of_Code_Reasoning_with_a_Language_Model_Augmented_Code_Emulator.html#critique",
    "title": "Chain of Code: Reasoning with a Language Model-Augmented Code Emulator",
    "section": "Critique",
    "text": "Critique\n\nCoC requires additional context length and computation time due to its two-step process and interweaving of code and language execution.\nThe approach may not perform well on tasks where code is not beneficial and has limitations in modifying custom Python objects while simulating code execution.\n\nOverall, the paper presents an innovative approach, CoC, that combines the strengths of both code and language models to improve reasoning performance across a variety of tasks. However, the paper would benefit from further discussions on potential limitations and future work for extending the applicability of CoC."
  },
  {
    "objectID": "posts/Chain_of_Code_Reasoning_with_a_Language_Model_Augmented_Code_Emulator/2023-12-07-Chain_of_Code_Reasoning_with_a_Language_Model_Augmented_Code_Emulator.html#appendix",
    "href": "posts/Chain_of_Code_Reasoning_with_a_Language_Model_Augmented_Code_Emulator/2023-12-07-Chain_of_Code_Reasoning_with_a_Language_Model_Augmented_Code_Emulator.html#appendix",
    "title": "Chain of Code: Reasoning with a Language Model-Augmented Code Emulator",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.04474v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.04474v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9590"
  },
  {
    "objectID": "posts/Economics_Arena_for_Large_Language_Models/2024-01-03-Economics_Arena_for_Large_Language_Models.html",
    "href": "posts/Economics_Arena_for_Large_Language_Models/2024-01-03-Economics_Arena_for_Large_Language_Models.html",
    "title": "Economics Arena for Large Language Models",
    "section": "",
    "text": "he mean deviation distance of player i𝑖iitalic_i; and N, the total number of players. When with history, LLMs are expected to bring down their mean deviation distances compared to without history, otherwise it is a reflection of a failure in learning from the past information. For competitive game theoretic reasoning, a lower mean deviation distance, where players are closer to following the NE, implies playing more rational strategies.\nA.3.2 Adaptation to Dynamic Environments\nIn a dynamic environment, it is expected that the strategic ability of the agents would be put to test. The variation in game configurations would change transfer payoffs from one model to another. Furthermore, as configurations change, rationality is a quality of updating the strategy, and also of consistency of the strategy till it faces a more aggressive agent in the next round. Thus, strategic reasoning could be surmised from the consistency of the strategies across various game configurations and more so, varying player configurations. If a player has higher adaptive strategies, there would be a different quality of strategies over different adversaries, thus their mean deviation distances should be lower when playing with other players than when rationality assumption is already in place.\nA.3.3 Strategic Reasoning through Game History\nWith game history available, it is expected that the average payoff and deviation distance from NE would reduce, given that agents learn from their past experiences, or learn quickly to achieve a similar level of rationality as when a rationality assumption is already in place. We expect, with history, models that have optimal strategy which are robust to the varying ranges to have much lower deviation distances than models with relatively more volatile strategies, and then to observe convergence over runs. We note that the faster the rate of convergence is, the higher the rationality of the agents, thus stronger realization of Nash equilibria.\nA.3.4 Natural Language Instructions Following Behaviours of LLMs\nIt is essential for LLM-based agents to strictly follow the instructions described by the natural languages, as predicting and following commands is a task of everyday importance (Bender and Koller, 2020). The goal of this study is also to investigate the performance of these models in strictly adhering to natural language instructions. We will be calculating the frequency of rule-breaking and comparing it across the different LLM-based agents across the two game types as an insight into their ability in comprehending instructions in different contexts. The results would reflect their natural language understanding capabilities, and the ability to differentiate and execute different instructions based on the contexts.\nA.3.5 Other Variations\nThe performance of a model is not only determined by the dynamics of the agent itself, but also by other factors such as the agent’s memory capacity, and the temporal structure of the promp. To investigate the impact of Chain-of-Thought and variation in prompt language, we ran some of the same experiments under these variations and compared them to the main results. The findings will demonstrate the importance of these factors in shaping the performance of the LLMs and whether these variations can improve the strategic reasoning ability of the LLMs in the economics arena."
  },
  {
    "objectID": "posts/Economics_Arena_for_Large_Language_Models/2024-01-03-Economics_Arena_for_Large_Language_Models.html#appendix",
    "href": "posts/Economics_Arena_for_Large_Language_Models/2024-01-03-Economics_Arena_for_Large_Language_Models.html#appendix",
    "title": "Economics Arena for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01735v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01735v1\n\n\nTruncated\nTrue\n\n\nWord Count\n16328"
  },
  {
    "objectID": "posts/Towards_Trustworthy_AI_Software_Development_Assistance/2023-12-14-Towards_Trustworthy_AI_Software_Development_Assistance.html#appendix",
    "href": "posts/Towards_Trustworthy_AI_Software_Development_Assistance/2023-12-14-Towards_Trustworthy_AI_Software_Development_Assistance.html#appendix",
    "title": "Towards Trustworthy AI Software Development Assistance",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.09126v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.09126v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6324"
  },
  {
    "objectID": "posts/DIALIGHT_Lightweight_Multilingual_Development_and_Evaluation_of_Task_Oriented_Dialogue_Systems_with_Large_Language_Models/2024-01-04-DIALIGHT_Lightweight_Multilingual_Development_and_Evaluation_of_Task_Oriented_Dialogue_Systems_with_Large_Language_Models.html#appendix",
    "href": "posts/DIALIGHT_Lightweight_Multilingual_Development_and_Evaluation_of_Task_Oriented_Dialogue_Systems_with_Large_Language_Models/2024-01-04-DIALIGHT_Lightweight_Multilingual_Development_and_Evaluation_of_Task_Oriented_Dialogue_Systems_with_Large_Language_Models.html#appendix",
    "title": "DIALIGHT: Lightweight Multilingual Development and Evaluation of Task-Oriented Dialogue Systems with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.02208v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.02208v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9836"
  },
  {
    "objectID": "posts/Improving_Code_Reviewer_Recommendation_Accuracy_Latency_Workload_and_Bystanders/2023-12-28-Improving_Code_Reviewer_Recommendation_Accuracy_Latency_Workload_and_Bystanders.html#appendix",
    "href": "posts/Improving_Code_Reviewer_Recommendation_Accuracy_Latency_Workload_and_Bystanders/2023-12-28-Improving_Code_Reviewer_Recommendation_Accuracy_Latency_Workload_and_Bystanders.html#appendix",
    "title": "Improving Code Reviewer Recommendation: Accuracy, Latency, Workload, and Bystanders",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17169v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17169v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11269"
  },
  {
    "objectID": "posts/An_Adaptive_Framework_of_Geographical_Group_Specific_Network_on_O2O_Recommendation/2023-12-28-An_Adaptive_Framework_of_Geographical_Group_Specific_Network_on_O2O_Recommendation.html#appendix",
    "href": "posts/An_Adaptive_Framework_of_Geographical_Group_Specific_Network_on_O2O_Recommendation/2023-12-28-An_Adaptive_Framework_of_Geographical_Group_Specific_Network_on_O2O_Recommendation.html#appendix",
    "title": "An Adaptive Framework of Geographical Group-Specific Network on O2O Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17072v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17072v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5196"
  },
  {
    "objectID": "posts/Unicron_Economizing_Self_Healing_LLM_Training_at_Scale/2023-12-30-Unicron_Economizing_Self_Healing_LLM_Training_at_Scale.html#appendix",
    "href": "posts/Unicron_Economizing_Self_Healing_LLM_Training_at_Scale/2023-12-30-Unicron_Economizing_Self_Healing_LLM_Training_at_Scale.html#appendix",
    "title": "Unicron: Economizing Self-Healing LLM Training at Scale",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00134v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00134v1\n\n\nTruncated\nTrue\n\n\nWord Count\n14994"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian beagle",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nLarge Language Models for Robotics: Opportunities, Challenges, and Perspectives\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLarge language models (LLMs) integrate with robots for task planning, with a focus on multimodal LLMs for enhanced performance.\n\n\n\nJan 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\nproduction\n\n\n\nTL;DR: Chain-of-Table framework leverages tabular data in reasoning chain for better predictions in table understanding tasks.\n\n\n\nJan 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTransportationGames: Benchmarking Transportation Knowledge of (Multimodal) Large Language Models\n\n\n\narchitectures\n\n\nproduction\n\n\n\n(TL;DR) Large language models (LLMs) excel in professional domains, but their performance in transportation tasks needs improvement, leading to the proposal of…\n\n\n\nJan 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMERA: A Comprehensive LLM Evaluation in Russian\n\n\n\narchitectures\n\n\nproduction\n\n\n\nSummary: This article introduces MERA, a benchmark for evaluating Russian language models, aiming to understand their capabilities, limitations, and associated risks.\n\n\n\nJan 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTechGPT-2.0: A large language model project to solve the task of knowledge graph construction\n\n\n\narchitectures\n\n\nrobustness\n\n\nproduction\n\n\n\nTechGPT-2.0 enhances large language models and supports Chinese open-source community, with robust text processing capabilities in multiple domains.\n\n\n\nJan 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Prompt-Based Methods for Zero-Shot Hypernym Prediction with Large Language Models\n\n\n\nprompt-engineering\n\n\nproduction\n\n\n\nZero-shot hypernymy prediction using large language models through prompt selection, additional information, and iterative approach.\n\n\n\nJan 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFighting Fire with Fire: Adversarial Prompting to Generate a Misinformation Detection Dataset\n\n\n\nproduction\n\n\nrobustness\n\n\nprompt-engineering\n\n\nhci\n\n\n\nTL;DR: Large language models can be used to create fake news and misinformation; proposing an approach to identify and detect misinformation.\n\n\n\nJan 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRewriting the Code: A Simple Method for Large Language Model Augmented Code Search\n\n\n\narchitectures\n\n\nprogramming\n\n\nproduction\n\n\n\nCode search improved by ReCo for style normalization, boosting retrieval accuracy with new metric.\n\n\n\nJan 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKnow Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs\n\n\n\nprompt-engineering\n\n\nrecommender\n\n\nproduction\n\n\n\nTL;DR: The paper proposes a new method for user targeting using natural language demands transformed into logical languages, leveraging large language models.\n\n\n\nJan 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving the Robustness of Knowledge-Grounded Dialogue via Contrastive Learning\n\n\n\nproduction\n\n\nhci\n\n\n\nEntity-based contrastive learning framework improves robustness of dialogue systems, achieving state-of-the-art performance in real-world noisy contexts.\n\n\n\nJan 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Critique of Critique\n\n\n\narchitectures\n\n\nsocial-sciences\n\n\n\nMetaCritique evaluates critique quality through precision and recall scores, using AIUs for detailed assessment and providing natural language rationale.\n\n\n\nJan 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSonicVisionLM: Playing Sound with Vision Language Models\n\n\n\narchitectures\n\n\nrecommender\n\n\n\nSonicVisionLM generates sound effects for silent videos using vision language models, improving audio-visual alignment.\n\n\n\nJan 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRePLan: Robotic Replanning with Perception and Language Models\n\n\n\nprompt-engineering\n\n\nrobustness\n\n\n\nAdvancements in language models help robots plan and execute tasks, with a new framework enabling real-time replanning for long-horizon tasks.\n\n\n\nJan 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs\n\n\n\narchitectures\n\n\n\nFlightLLM enables efficient LLM inference on FPGAs, overcoming challenges with sparse DSP chain, memory bandwidth, and compilation overhead.\n\n\n\nJan 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMARG: Multi-Agent Review Generation for Scientific Papers\n\n\n\nprompt-engineering\n\n\n\nMARG improves AI feedback quality for scientific papers, generating specific and helpful comments using multiple LLM instances.\n\n\n\nJan 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Butterfly Effect of Altering Prompts: How Small Changes and Jailbreaks Affect Large Language Model Performance\n\n\n\nhci\n\n\nprompt-engineering\n\n\n\nTL;DR: Small changes in how prompts are constructed can significantly impact the decisions made by Large Language Models (LLMs).\n\n\n\nJan 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssessing AI Detectors in Identifying AI-Generated Code: Implications for Education\n\n\n\nprogramming\n\n\neducation\n\n\nprompt-engineering\n\n\n\nUsage of Large Language Models for education raises concerns about potential bypassing of AI-generated content detectors. Study shows poor detector performance.\n\n\n\nJan 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMs for Robotic Object Disambiguation\n\n\n\nprompt-engineering\n\n\n\nLarge language models (LLMs) excel at solving decision-making challenges in robotics, but struggle with object disambiguation without additional prompting.\n\n\n\nJan 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrimoire is All You Need for Enhancing Large Language Models\n\n\n\nprompt-engineering\n\n\n\nIn this paper, a method called SLEICL is proposed to enhance weak language models’ performance using examples learned by strong models.\n\n\n\nJan 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn Investigation of Large Language Models for Real-World Hate Speech Detection\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLarge language models (LLMs) show promise in detecting hate speech, but effective prompting strategies are crucial for leveraging their knowledge base.\n\n\n\nJan 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInFoBench: Evaluating Instruction Following Ability in Large Language Models\n\n\n\narchitectures\n\n\neducation\n\n\nprompt-engineering\n\n\n\nTL;DR: Introduces DRFR metric for evaluating Language Models’ instruction-following, presents InFoBench benchmark, and evaluates LLMs’ performance.\n\n\n\nJan 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChatGPT for Conversational Recommendation: Refining Recommendations by Reprompting with Feedback\n\n\n\nprogramming\n\n\nhci\n\n\nrecommender\n\n\nprompt-engineering\n\n\n\nChatGPT is investigated as a conversational recommendation system, and reprompting with feedback improves relevancy while mitigating popularity bias.\n\n\n\nJan 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects\n\n\n\nhci\n\n\n\nThis article explores the potential of large language model-based intelligent agents for various applications and their deployment in single-agent and multi-agent systems.\n\n\n\nJan 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-Powered Code Vulnerability Repair with Reinforcement Learning and Semantic Reward\n\n\n\nrobustness\n\n\narchitectures\n\n\nsecurity\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\nAI-driven tools like GitHub Copilot improve code development efficiency but also create security concerns. SecRepair addresses vulnerabilities with reinforcement learning…\n\n\n\nJan 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview of Dialogue Robot Competition 2023\n\n\n\narchitectures\n\n\nhci\n\n\n\nDRC2023 competition tested advanced real-time dialogue robot performance with a human-like android in challenging travel agency tasks.\n\n\n\nJan 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMalla: Demystifying Real-world Large Language Model Integrated Malicious Services\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nStudy uncovers proliferation of malicious language models in underground markets, prompting need for counteraction strategies.\n\n\n\nJan 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDIALIGHT: Lightweight Multilingual Development and Evaluation of Task-Oriented Dialogue Systems with Large Language Models\n\n\n\nprogramming\n\n\n\nDIALIGHT toolkit evaluates dialogue systems: PLMs for higher accuracy, LLMs for diversity. Challenges identified for future research.\n\n\n\nJan 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-Contrast: Better Reflection Through Inconsistent Solving Perspectives\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nExternal feedback stabilizes model’s self-reflection. Self-Contrast strategy reduces biases and improves LLM’s accuracy.\n\n\n\nJan 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers\n\n\n\nhci\n\n\n\nIntroduction of ICE-GRT, a model utilizing Reinforcement Learning from Human Feedback, performs well in domain-specific tasks and general capabilities.\n\n\n\nJan 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM Augmented LLMs: Expanding Capabilities through Composition\n\n\n\nprogramming\n\n\n\nFoundational models with billions of parameters are difficult to augment or impart new skills. CALM proposes cross-attention to compose representations and enable new…\n\n\n\nJan 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing LLM to select the right SQL Query from candidates\n\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\nAutomatic test case generation improves text-to-SQL model performance by re-ranking queries based on execution results and generation probabilities.\n\n\n\nJan 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding LLMs: A Comprehensive Overview from Training to Inference\n\n\n\nhci\n\n\n\nChatGPT has increased Large Language Model usage, sparking focus on cost-effective training and deployment for future development.\n\n\n\nJan 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nText2MDT: Extracting Medical Decision Trees from Medical Texts\n\n\n\nprogramming\n\n\n\nTL;DR: Text2MDT extracts medical decision trees from texts, with an end-to-end method showing promising results. Source codes and dataset are open-sourced.\n\n\n\nJan 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDCR-Consistency: Divide-Conquer-Reasoning for Consistency Evaluation and Improvement of Large Language Models\n\n\n\nrobustness\n\n\n\nProposes DCR framework for evaluating and improving Large Language Models text consistency, outperforming existing methods.\n\n\n\nJan 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Boundary of GPT-4V on Marine Analysis: A Preliminary Case Study\n\n\n\nhci\n\n\n\nLarge language models (LLMs) expanded with visual perception through multi-modal large language models (MLLM). GPT-4V evaluated for marine analysis, with results falling…\n\n\n\nJan 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearning to Prompt with Text Only Supervision for Vision-Language Models\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nFoundational vision-language models like CLIP have excellent generalization, but adapting for downstream tasks is challenging. Proposed method learns prompts using text only…\n\n\n\nJan 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLaMA Pro: Progressive LLaMA with Block Expansion\n\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\nWe propose a new post-pretraining method for Large Language Models using an expansion of Transformer blocks, yielding LLaMA Pro-8.3B, excelling in general tasks…\n\n\n\nJan 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Effects of Generative AI on Computing Students’ Help-Seeking Preferences\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nGenerative AI tools in computing education are being adopted, but traditional resources still hold value. Use of AI requires skill development.\n\n\n\nJan 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre LLMs Robust for Spoken Dialogues?\n\n\n\nsocial-sciences\n\n\n\nLarge language models perform well in written dialogue tasks but struggle with spoken interactions. Fine-tuning on spoken datasets improves performance.\n\n\n\nJan 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEconomics Arena for Large Language Models\n\n\n\neducation\n\n\n\nLLMs tested in competitive economics games show varying levels of rationality and strategic reasoning, with GPT-4 exhibiting faster convergence to Nash Equilibria.\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models Relearn Removed Concepts\n\n\n\nrobustness\n\n\n\nModel editing via neuron pruning allows for concept removal from language models. Models exhibit resilience and fluidity in relearning pruned concepts.\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNavigating Uncertainty: Optimizing API Dependency for Hallucination Reduction in Closed-Book Question Answering\n\n\n\nrobustness\n\n\n\nTL;DR: Proposed LLM can self-determine when to use external sources, achieving 78.2% direct answers and minimizing search to 77.2%.\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhysio: An LLM-Based Physiotherapy Advisor\n\n\n\nsocial-sciences\n\n\n\nNew language models have potential for real-world use but must be trustworthy. Physio combines these models with reliable health sources.\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWordArt Designer API: User-Driven Artistic Typography Synthesis with Large Language Models on ModelScope\n\n\n\nhci\n\n\n\nWordArt Designer API uses Large Language Models to simplify artistic typography for non-professionals, enhancing design flexibility and creative expression.\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAstroLLaMA-Chat: Scaling AstroLLaMA with Conversational and Diverse Datasets\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nEnhancing LLMs for astronomy Q&A using continual pre-training. Improved specialized topic comprehension & released open-source conversational AI tool.\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeneralist embedding models are better at short-context clinical semantic search than specialized embedding models\n\n\n\nsocial-sciences\n\n\n\nLarge Language Models (LLMs) in medicine raise concerns about robustness and reliability. Benchmarking shows generalist models perform better.\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGPT-4V(ision) is a Generalist Web Agent, if Grounded\n\n\n\nprompt-engineering\n\n\n\nRecent development in multimodal models has led to new web agents. SEEACT, using GPT-4V, can perform tasks on live websites.\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDe-Hallucinator: Iterative Grounding for LLM-Based Code Completion\n\n\n\nrobustness\n\n\nprogramming\n\n\n\nLLMs have limitations in code completion due to a lack of project-specific context. De-Hallucinator addresses this by integrating API references, improving code predictions.\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English Clinical Queries\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nCreating summaries of medical questions from patients is important for improving doctor-patient interactions. Current research overlooks visual cues and multilingual input…\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSocial Media Ready Caption Generation for Brands\n\n\n\nhci\n\n\n\nProposed solution uses image captioning and brand personalities to create engaging social media captions.\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Generative AI Assistant to Accelerate Cloud Migration\n\n\n\narchitectures\n\n\n\nTool uses generative AI to speed up on-premises app migration to the cloud, helping users find the right migration strategy.\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCross-target Stance Detection by Exploiting Target Analytical Perspectives\n\n\n\nprompt-engineering\n\n\n\nMPPT model uses analysis perspective to improve Cross-target Stance Detection, outperforming baseline methods.\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers\n\n\n\nprompt-engineering\n\n\n\nVisual reasoning with large language models can address current limitations by decomposing tasks and leveraging abstract routines.\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPLLaMa: An Open-source Large Language Model for Plant Science\n\n\n\nprogramming\n\n\n\nPLLaMa is an enhanced language model for plant science. It incorporates a vast database and expert panel for accurate responses.\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultilingual Instruction Tuning With Just a Pinch of Multilinguality\n\n\n\nprogramming\n\n\n\nMultilingual instruction-tuning enhances LLMs to follow instructions across languages with minimal multilingual examples.\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApplying Bayesian Data Analysis for Causal Inference about Requirements Quality: A Replicated Experiment\n\n\n\nsocial-sciences\n\n\n\nStudy finds quality defects in requirements impact software engineering activities differently, highlighting the need for varying levels of attention.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnifying Structured Data as Graph for Data-to-Text Pre-Training\n\n\n\nproduction\n\n\n\nData-to-text (D2T) generation enhanced by graph-based pre-training shows effective performance on various structured data.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProfiling Programming Language Learning\n\n\n\nprompt-engineering\n\n\nprogramming\n\n\neducation\n\n\n\nYear-long experiment on programming language learning, using quizzes to improve understanding and retention.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhysics-informed Generalizable Wireless Channel Modeling with Segmentation and Deep Learning: Fundamentals, Methodologies, and Challenges\n\n\n\nsocial-sciences\n\n\n\nData-driven techniques improve wireless channel modeling. Physics-informed neural networks show promise for accurate, interpretable predictions.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Comprehensive Study of Knowledge Editing for Large Language Models\n\n\n\nproduction\n\n\n\nLLMs face computational demands for ongoing updates. Research examines editing approaches for efficient model modifications and proposes a categorization criterion.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistribution Matching for Multi-Task Learning of Classification Tasks: a Large-Scale Study on Faces & Beyond\n\n\n\nsocial-sciences\n\n\n\nMulti-Task Learning can be successful with little overlapping annotations and uneven data sizes, with performance improvements in multiple domains.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPPBFL: A Privacy Protected Blockchain-based Federated Learning Model\n\n\n\nsecurity\n\n\n\nDeveloped Privacy Protected Blockchain-based Federated Learning Model (PPBFL) enhances security and participation in federated learning, outperforming baseline methods.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExperimenting a New Programming Practice with LLMs\n\n\n\nprogramming\n\n\neducation\n\n\n\nA prototype called AISD uses large language models to automate software development, allowing engineers to focus on high-level tasks.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSSP: A Simple and Safe automatic Prompt engineering method towards realistic image synthesis on LVM\n\n\n\nprompt-engineering\n\n\n\nEnhancing text-to-image (T2I) synthesis with Large Language Models (LLM) and Large Vision Models (LVM) using specific camera descriptions for safer and improved image…\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSearch Games with Predictions\n\n\n\nsecurity\n\n\n\nStudy explores search games with mobile Searcher and immobile Hider, considering consistency and robustness tradeoffs in search strategies.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFedQV: Leveraging Quadratic Voting in Federated Learning\n\n\n\nsecurity\n\n\n\nFederated Learning improved with FedQV, an election-based aggregation algorithm, offers better resistance to poisoning attacks and privacy breaches.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJMA: a General Algorithm to Craft Nearly Optimal Targeted Adversarial Example\n\n\n\nsecurity\n\n\n\nProposes a more effective targeted attack against deep learning classifiers, capable of inducing targeted modifications in complex classification scenarios.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpiker+: a framework for the generation of efficient Spiking Neural Networks FPGA accelerators for inference at the edge\n\n\n\nrobustness\n\n\n\nSpiker+ is a customizable framework for generating efficient Spiking Neural Networks accelerators on FPGA for edge computing, achieving competitive performance and low…\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models\n\n\n\nsocial-sciences\n\n\nhci\n\n\nrobustness\n\n\n\nLLMs have a hallucination issue hindering real-world deployment. Survey of 32 techniques for mitigation presented.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Legal Fictions: Profiling Legal Hallucinations in Large Language Models\n\n\n\nhci\n\n\nrobustness\n\n\n\nLLMs in law risk legal hallucinations 69-88% of interviews; caution against unsupervised use; risky for pro se litigants.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLbezpeky: Leveraging Large Language Models for Vulnerability Detection\n\n\n\nsecurity\n\n\n\nLLMs show promise in detecting Android app vulnerabilities with 91.67% accuracy, aiming to build a robust vulnerability detection system.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGEqO: ML-Accelerated Semantic Equivalence Detection\n\n\n\narchitectures\n\n\n\nGEqO framework automates detection of semantic equivalence in large-scale analytics, yielding significant performance gains.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning\n\n\n\narchitectures\n\n\n\nLLMs can handle long contexts without fine-tuning. Self-Extend extends their context window effortlessly.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerative AI is already widespread in the public sector\n\n\n\nsocial-sciences\n\n\n\nGenerative AI is transforming the public sector, with widespread use and positive opinions, but lack of clear guidelines.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideoDrafter: Content-Consistent Multi-Scene Video Generation with LLM\n\n\n\nprompt-engineering\n\n\n\nVideoDrafter uses language models to create consistent multi-scene videos, outperforming existing models in quality and consistency.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCXL and the Return of Scale-Up Database Engines\n\n\n\narchitectures\n\n\n\nSpecialization trend leads to bottleneck in CPU-device connection. CXL specification aims to tackle this with modern, more powerful interface.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUncertainty Resolution in Misinformation Detection\n\n\n\nhci\n\n\n\nLarge Language Models (LLMs) help combat misinformation but struggle with ambiguous statements. New framework improves context assessment.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSocially Responsible Computing in an Introductory Course\n\n\n\nsocial-sciences\n\n\nhci\n\n\nprompt-engineering\n\n\neducation\n\n\n\nTL;DR: Promoting social responsibility in Computer Science education boosts student motivation and inclusivity.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-Play Fine-Tuning Converts Weak Language Models to Strong Language Models\n\n\n\narchitectures\n\n\n\nTL;DR: Self-Play fIne-tuNing (SPIN) method improves language models using their own training data without additional human annotation.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJoint Offloading and Resource Allocation for Hybrid Cloud and Edge Computing in SAGINs: A Decision Assisted Hybrid Action Space Deep Reinforcement Learning Approach\n\n\n\narchitectures\n\n\n\nResearch on space-air-ground integrated networks (SAGINs) using deep reinforcement learning to optimize offloading and resource allocation in cloud and edge computing…\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation\n\n\n\nhci\n\n\n\nAn introduction of CharacterEval, a Chinese benchmark for Role-Playing Conversational Agents’ assessment with a tailored dataset.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFairness Certification for Natural Language Processing and Large Language Models\n\n\n\nsocial-sciences\n\n\n\nNLP needs fairness certification due to potential biases. Researched and developed six criteria for certification.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDeplatforming Norm-Violating Influencers on Social Media Reduces Overall Online Attention Toward Them\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nOnline deplatforming reduces attention towards influencers. Study addresses limitations, finds impact, and contributes to content moderation research.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nZero-Shot Position Debiasing for Large Language Models\n\n\n\narchitectures\n\n\n\nFine-tuning LLMs can improve domain performance, but may lead to bias. A zero-shot position debiasing framework is proposed.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM Harmony: Multi-Agent Communication for Problem Solving\n\n\n\nsocial-sciences\n\n\nprompt-engineering\n\n\n\nNovel multi-agent communication framework enhances autonomy and problem-solving of Large Language Models for diverse scenarios.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTREC iKAT 2023: The Interactive Knowledge Assistance Track Overview\n\n\n\nhci\n\n\n\nTREC iKAT focuses on creating adaptive conversational search agents for personalized information seeking and decision-making tasks.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLaMA Beyond English: An Empirical Study on Language Capability Transfer\n\n\n\nsocial-sciences\n\n\n\nTransfer English LLM capabilities to non-English languages with minimal pretraining data, achieving comparable performance.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeam-Based Multiple Access for IRS-Aided Millimeter-Wave and Terahertz Communications\n\n\n\narchitectures\n\n\n\nPaper proposes beam-based multiple-access strategy using intelligent reflecting surface for IRS-aided mmWave and THz communications. Increases system capacity significantly.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoise-NeRF: Hide Information in Neural Radiance Fields using Trainable Noise\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nNeRF faces security issues. This paper introduces Noise-NeRF for improved steganography quality and efficiency.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe social graph based on real data\n\n\n\nsocial-sciences\n\n\n\nProposed model creates realistic social graph using real community data, with power-law distribution and small world properties.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecFormer: Towards Fast and Accurate Privacy-Preserving Inference for Large Language Models\n\n\n\nsecurity\n\n\n\nPrivacy concerns with large language models led to Secure Multi-Party Computing (SMPC) for Privacy-Preserving Inference. SecFormer optimizes SMPC for Transformer models…\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA & B == B & A: Triggering Logical Reasoning Failures in Large Language Models\n\n\n\nsocial-sciences\n\n\nhci\n\n\nprompt-engineering\n\n\n\nAdvancements in large language models enable breakthroughs in tasks like writing and translation, but evaluating their reasoning is challenging. LogicAsker assesses logical…\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Earth is Flat? Unveiling Factual Errors in Large Language Models\n\n\n\nrobustness\n\n\n\nTL;DR: FactChecker is a new automatic testing framework that uncovers factual inaccuracies in large language models with up to 45% error detection.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBenchmarking Large Language Models on Controllable Generation under Diversified Instructions\n\n\n\nprogramming\n\n\n\nCoDI-Eval evaluates large language models’ ability to follow instructions with specific constraints, revealing limitations and the need for improvement.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAstraios: Parameter-Efficient Instruction Tuning Code Large Language Models\n\n\n\nsecurity\n\n\n\nAstraios compares fine-tuning methods for large language models and finds full-parameter fine-tuning generally leads to best performance.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDigger: Detecting Copyright Content Mis-usage in Large Language Model Training\n\n\n\nhci\n\n\n\nPre-training LLMs can raise copyright concerns. A new framework is introduced to detect and address copyrighted content misuse.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTaking the Next Step with Generative Artificial Intelligence: The Transformative Role of Multimodal Large Language Models in Science Education\n\n\n\neducation\n\n\n\nMLLMs like GPT-4V enhance education with multimodal learning, but careful integration is needed for ethical and effective use.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Computational Framework for Behavioral Assessment of LLM Therapists\n\n\n\nsocial-sciences\n\n\n\nChatGPT and other large language models are being considered as therapists, but research shows their behavior may not reflect high-quality therapy.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistillation is All You Need for Practically Using Different Pre-trained Recommendation Models\n\n\n\nrecommender\n\n\n\nProposed PRM-KD model efficiently utilizes diverse pre-trained recommendation models to enhance student models for real-world recommendations.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents\n\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\nLLMs benefit from integrating code in training, enhancing code generation and reasoning ability for complex tasks.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nToolEyes assesses large language model tool learning in authentic scenarios, uncovering limitations and guiding future research.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDocLLM: A layout-aware generative language model for multimodal document understanding\n\n\n\nhci\n\n\n\nDocLLM is a model for reasoning over visual documents using text and layout information, outperforming existing models.\n\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nViz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI\n\n\n\nproduction\n\n\nlegal\n\n\n\nViz system integrates QLoRA to fine-tune large language models legally and efficiently, addressing AI challenges.\n\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkeqing: knowledge-based question answering is a nature chain-of-thought mentor of LLM\n\n\n\neducation\n\n\nhci\n\n\n\nLLMs struggle with knowledge gaps. Keqing assists by retrieving relevant info and guiding logical answering paths.\n\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn Analysis of Embedding Layers and Similarity Scores using Siamese Neural Networks\n\n\n\nprogramming\n\n\n\nTL;DR: Large language models use word embeddings, and our research compares their accuracy and environmental impact.\n\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKernelGPT: Enhanced Kernel Fuzzing via Large Language Models\n\n\n\nprogramming\n\n\n\nKernelGPT automates syscall specification generation for enhanced kernel fuzzing, improving coverage and finding new bugs.\n\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFairness in Serving Large Language Models\n\n\n\narchitectures\n\n\n\nNew scheduling algorithm VTC ensures fair LLM serving, offering superior performance and resource utilization.\n\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeoGalactica: A Scientific Large Language Model in Geoscience\n\n\n\neducation\n\n\n\nLLMs show potential in AI for science. GeoGalactica is a large language model tailored for geoscience.\n\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBatchEval: Towards Human-like Text Evaluation\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nBatchEval improves text evaluation over LLMs, addressing design sensitivity, noise resistance, and ensemble performance, with 10.5% higher correlations at reduced API cost.\n\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nE-chat: Emotion-sensitive Spoken Dialogue System with Large Language Models\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nStudy introduces Emotional chat Model (E-chat) for emotion-sensitive spoken dialogue, outperforming baseline models.\n\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRAGTruth: A Hallucination Corpus for Developing Trustworthy Retrieval-Augmented Language Models\n\n\n\ndataset\n\n\nprompt-engineering\n\n\n\nRAGTruth is a dataset for analyzing hallucinations in large language models, helping measure and prevent unsupported claims in retrieved content.\n\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the Effectiveness of Instruction Tuning in Biomedical Language Processing\n\n\n\narchitectures\n\n\n\nLarge language models (LLMs) like ChatGPT impact NLP, but struggle with biomedical tasks. Study proposes instruction tuning for biomedical language processing.\n\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLaFFi: Leveraging Hybrid Natural Language Feedback for Fine-tuning Language Models\n\n\n\nsocial-sciences\n\n\neducation\n\n\n\nLLMs trained with LaFFi reflect on the feedback they’ll receive, improving question-answering accuracy. Experiments show the potential of natural language feedback.\n\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nState of What Art? A Call for Multi-Prompt LLM Evaluation\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nAdvances in large language models are analyzed for their evaluation, suggesting diverse prompts for more reliable assessments.\n\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnicron: Economizing Self-Healing LLM Training at Scale\n\n\n\narchitectures\n\n\n\nUnicron is a self-healing workload manager for large-scale language model training, reducing failure-related costs and improving efficiency.\n\n\n\nDec 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeach Large Language Models to Forget Privacy\n\n\n\nprompt-engineering\n\n\n\nTackle privacy risks in large language models with Prompt2Forget, achieving 90% forgetfulness without utility loss.\n\n\n\nDec 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Problem of Alignment\n\n\n\nsocial-sciences\n\n\nhci\n\n\nprompt-engineering\n\n\n\nLanguage models need alignment with human values to avoid reproducing biases. This relationship shapes linguistic theories and practice.\n\n\n\nDec 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBoosting Large Language Model for Speech Synthesis: An Empirical Study\n\n\n\nhci\n\n\nproduction\n\n\n\nCombining LLM LLaMA/OPT and VALL-E speech synthesis model, findings show directly fine-tuning LLMs or using superposed layers has limitations. Coupled LLMs and VALL-E…\n\n\n\nDec 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Art of Defending: A Systematic Evaluation and Analysis of LLM Defense Strategies on Safety and Over-Defensiveness\n\n\n\nsecurity\n\n\n\nSODE benchmark assesses LLM safety and over-defensiveness, revealing key defense strategy insights for further research.\n\n\n\nDec 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpen-TI: Open Traffic Intelligence with Augmented Language Model\n\n\n\nhci\n\n\n\nIntelligent transportation benefits cities, but complex algorithms pose challenges. Open-TI aims to bridge industry-academic gap with advanced traffic analysis.\n\n\n\nDec 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRed Teaming for Large Language Models At Scale: Tackling Hallucinations on Mathematics Tasks\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nStudy evaluates prompting techniques for LLMs on math tasks. Findings show models struggle with elementary calculations and reasoning even with red teaming.\n\n\n\nDec 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-Assist: Enhancing Closed-Loop Planning with Language-Based Reasoning\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nHybrid planner combines rule-based and language models, outperforming existing methods in driving scenario handling.\n\n\n\nDec 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvancing TTP Analysis: Harnessing the Power of Encoder-Only and Decoder-Only Language Models with Retrieval Augmented Generation\n\n\n\nhci\n\n\nrobustness\n\n\n\nCybersecurity experts explore using advanced language models to interpret and summarize cyberattack methods for better understanding.\n\n\n\nDec 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUncertainty-Penalized Reinforcement Learning from Human Feedback with Diverse Reward LoRA Ensembles\n\n\n\narchitectures\n\n\nproduction\n\n\n\nTL;DR: Reinforcement learning from human feedback (RLHF) can lead to overoptimization, but uncertainty-penalized RLHF (UP-RLHF) mitigates this issue effectively.\n\n\n\nDec 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs Knowledge All Large Language Models Needed for Causal Reasoning?\n\n\n\nhci\n\n\n\nPaper explores enhancing large language models’ causal reasoning for AI, finding its dependence on contextual information and domain-specific knowledge.\n\n\n\nDec 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPushing Boundaries: Exploring Zero Shot Object Classification with Large Multimodal Models\n\n\n\nhci\n\n\n\nTL;DR: Large Multimodal Models (LMMs) merge language and vision, showing great potential for image classification and zero-shot learning.\n\n\n\nDec 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Understanding with Large Language Models: A Survey\n\n\n\narchitectures\n\n\n\nSurvey explores advancements in video understanding using Large Language Models (Vid-LLMs), highlighting capabilities and applications.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAction-Item-Driven Summarization of Long Meeting Transcripts\n\n\n\nprompt-engineering\n\n\n\nNovel algorithm generates abstractive meeting summaries driven by action items, using sectional summaries and topic-based division method. Improved BERTScore.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDifferentially Private Low-Rank Adaptation of Large Language Model Using Federated Learning\n\n\n\nhci\n\n\n\nLLM fine-tuning raises privacy concerns. DP-LoRA, a federated learning algorithm, addresses privacy and communication overhead challenges effectively.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDB-GPT: Empowering Database Interactions with Private Large Language Models\n\n\n\nprogramming\n\n\n\nDB-GPT integrates large language models with databases for natural language queries and secure data interaction.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSMoT: Think in State Machine\n\n\n\nprompt-engineering\n\n\n\nNew approach uses State Machine of Thought (SMoT) and expert knowledge to improve language model reasoning accuracy.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview of the PromptCBLUE Shared Task in CHIP2023\n\n\n\nprompt-engineering\n\n\n\nOverview of PromptCBLUE shared task at CHIP-2023 Conference, featuring reformulated benchmarks for testing Chinese language models in medical domains.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChatEd: A Chatbot Leveraging ChatGPT for an Enhanced Learning Experience in Higher Education\n\n\n\neducation\n\n\n\nChatGPT and similar language models have potential in education but face challenges with accuracy. New architecture offers enhanced student support.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOlapa-MCoT: Enhancing the Chinese Mathematical Reasoning Capability of LLMs\n\n\n\neducation\n\n\n\nCoT method improved for LLMs. Olapa-MCoT, based on llama2-13B, enhanced Chinese math reasoning by 36%. English reasoning also improved.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the Sensitivity of LLMs’ Decision-Making Capabilities: Insights from Prompt Variation and Hyperparameters\n\n\n\nhci\n\n\n\nStudy examines language models’ decision making with varying prompts and hyperparameters showing human-like exploration-exploitation tradeoff.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCooperation on the Fly: Exploring Language Agents for Ad Hoc Teamwork in the Avalon Game\n\n\n\nhci\n\n\nrobustness\n\n\n\nLLMs show promise in ad hoc teamwork but may suffer from communication issues. CodeAct aims to address this with enhanced memory and code-driven reasoning.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Right Prompts for the Job: Repair Code-Review Defects with Large Language Model\n\n\n\nhci\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\nLLMs effectively repair code review defects, achieving 72.97% repair rate, improving automatic repair practicality.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEHR Interaction Between Patients and AI: NoteAid EHR Interaction\n\n\n\neducation\n\n\n\nIntroduction of NoteAid EHR Interaction Pipeline using LLMs for patient education from EHRs, with dataset evaluation.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nK-PERM: Personalized Response Generation Using Dynamic Knowledge Retrieval and Persona-Adaptive Queries\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nPersonalizing conversational agents with external knowledge improves user engagement and quality of conversations. K-PERM achieves state-of-the-art performance.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn Adaptive Framework of Geographical Group-Specific Network on O2O Recommendation\n\n\n\nrecommender\n\n\n\nUser and service spatiotemporal info requires personalized models. GeoGrouse improves group-specific recommendation by studying user preferences.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Code Reviewer Recommendation: Accuracy, Latency, Workload, and Bystanders\n\n\n\nhci\n\n\nrobustness\n\n\n\nCode review system at Meta improved through experiments, with emphasis on author-reviewer familiarity and balancing workloads. Bystander effect mitigated.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFactoring Expertise, Workload, and Turnover into Code Review Recommendation\n\n\n\nrecommender\n\n\n\nCode review recommendation can distribute knowledge and mitigate turnover, reducing workload concentration and files at risk.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo Androids Know They’re Only Dreaming of Electric Sheep?\n\n\n\nrobustness\n\n\n\nProbes trained on language model representations detect hallucination behavior across tasks, but force-decoded states are not valid for organic hallucination detection.…\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTimeliness: A New Design Metric and a New Attack Surface\n\n\n\nsecurity\n\n\n\nTL;DR: Age-based communication networks are vulnerable to threats like timestomping and misinformation dissemination from adversaries.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFENet: Focusing Enhanced Network for Lane Detection\n\n\n\nprogramming\n\n\n\nResearch addresses lane detection challenges in autonomous driving, by proposing targeted network enhancements and achieving improved accuracy.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFast Inference of Mixture-of-Experts Language Models with Offloading\n\n\n\narchitectures\n\n\n\nSparse Mixture-of-Experts language models run faster with parameter offloading strategies, enabling efficient use on consumer hardware.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrounding-Prompter: Prompting LLM with Multimodal Information for Temporal Sentence Grounding in Long Videos\n\n\n\nprompt-engineering\n\n\n\nTL;DR: Proposed Grounding-Prompter method improves temporal grounding in long videos using multimodal information, enhancing state-of-the-art performance.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScalable and automated Evaluation of Blue Team cyber posture in Cyber Ranges\n\n\n\nsecurity\n\n\n\nCyber ranges are vital for secure training. New automation proposal improves exercise evaluation and assessment.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn Inapproximability of Reconfiguration Problems: PSPACE-Hardness and some Tight NP-Hardness Results\n\n\n\narchitectures\n\n\n\nRIH asserts the hardness of finding a sequence of assignments satisfying constraints, proven and applied to reconfiguration problems.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStructured Packing in LLM Training Improves Long Context Utilization\n\n\n\nprogramming\n\n\n\nAdvances in language models are limited by context utilization. SPLiCe enhances model performance using related documents.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow Far Are We from Believable AI Agents? A Framework for Evaluating the Believability of Human Behavior Simulation\n\n\n\nhci\n\n\n\nAI agent believability relies on user trust. Large Language Model agents face challenges, so new metrics are introduced.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitAgent: Facilitating Autonomous Agent with GitHub by Tool Extension\n\n\n\nprogramming\n\n\n\nLLMs struggle with varied tasks, but GitAgent integrates GitHub tools to improve task performance with 69.4% success.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerative AI for Math: Part I – MathPile: A Billion-Token-Scale Pretraining Corpus for Math\n\n\n\nprogramming\n\n\n\nIntroducing extsc{MathPile}, a high-quality math-centric corpus, prioritizing data quality over quantity for language model pre-training.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecuring NextG Systems against Poisoning Attacks on Federated Learning: A Game-Theoretic Solution\n\n\n\nsecurity\n\n\n\nStudy analyzes poisoning attacks in federated learning (FL) for wireless signal classification, proposing a defense mechanism against malicious clients.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAQUALLM: Audio Question Answering Data Generation Using Large Language Models\n\n\n\nprogramming\n\n\n\nAQA dataset creation framework improves AQA models, sets superior benchmarks, and enhances generalizability. Accessible on GitHub.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReplica Tree-based Federated Learning using Limited Data\n\n\n\narchitectures\n\n\n\nProposed RepTreeFL framework enables effective federated learning with limited data and clients, outperforming in various tasks.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen Metaverses Meet Vehicle Road Cooperation: Multi-Agent DRL-Based Stackelberg Game for Vehicular Twins Migration\n\n\n\narchitectures\n\n\n\nTL;DR: Vehicular Metaverses use vehicle road cooperation and augmented intelligence for seamless user experience, with a proposed incentive mechanism for optimizing VT…\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearning to Generate Text in Arbitrary Writing Styles\n\n\n\nhci\n\n\nprompt-engineering\n\n\n\nText generation to mimic specific author styles using contrastively-trained representations and discriminative control is effective and versatile.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFully Sparse 3D Panoptic Occupancy Prediction\n\n\n\nprogramming\n\n\n\nNew method SparseOcc improves autonomous driving occupancy prediction with efficient sparse representation and instance differentiation, achieving high accuracy and…\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Auto-Modeling of Formal Verification for NextG Protocols: A Multimodal cross- and self-attention Large Language Model Approach\n\n\n\nprogramming\n\n\n\nAVRE is a novel system for formal verification of Next Generation protocols, using Large Language Models to improve accuracy and scalability.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSupervised Knowledge Makes Large Language Models Better In-context Learners\n\n\n\nprompt-engineering\n\n\n\nLLMs’ in-context learning is enhanced through task-specific fine-tuned Language Models, improving generalizability and factuality.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKnowledge Distillation of LLM for Education\n\n\n\neducation\n\n\n\nMethod distills knowledge of large models for efficient deployment on resource-constrained devices, improving accuracy and model size.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTask Contamination: Language Models May Not Be Few-Shot Anymore\n\n\n\nprompt-engineering\n\n\n\nLarge language models (LLMs) perform better on older datasets, suggesting task contamination affects zero-shot and few-shot tasks.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCritical nonlinear aspects of hopping transport for reconfigurable logic in disordered dopant networks\n\n\n\nrobustness\n\n\n\nNonlinear hopping transport enables logic gates in disordered devices, analyzed through simulations and compared to experimental data.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSocial-Transmotion: Promptable Human Trajectory Prediction\n\n\n\nhci\n\n\n\nSocial-Transmotion model uses transformers to improve human trajectory prediction by leveraging non-verbal social cues.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAligning Large Language Models with Human Preferences through Representation Engineering\n\n\n\narchitectures\n\n\n\nAligning large language models with human preferences is crucial. Representation Alignment from Human Feedback (RAHF) effectively manipulates model representations to align…\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutoTask: Executing Arbitrary Voice Commands by Exploring and Learning from Mobile GUI\n\n\n\narchitectures\n\n\n\nAutoTask is a voice command interface that automates any mobile app task without prior knowledge or configuration.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAchieving Fairness in DareFightingICE Agents Evaluation Through a Delay Mechanism\n\n\n\narchitectures\n\n\n\nDelay mechanism mitigates gRPC latency impact on agents in DareFightingICE, balancing performance between Java and Python.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn the Trajectories of SGD Without Replacement\n\n\n\nproduction\n\n\n\nStochastic Gradient Descent without replacement implicitly regularizes and optimizes differently than other methods, leading to faster escape from saddles and sparser…\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan ChatGPT Read Who You Are?\n\n\n\nhci\n\n\n\nAI and psychology intersect to assess personality traits using ChatGPT. It shows competitive performance with a positive bias.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRecRanker: Instruction Tuning Large Language Model as Ranker for Top-k Recommendation\n\n\n\nprompt-engineering\n\n\n\nLLMs used in recommendation systems lack integration of multiple ranking tasks, so RecRanker was developed to address this and improve model performance.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInter-X: Towards Versatile Human-Human Interaction Analysis\n\n\n\nhci\n\n\n\nLargest human-human interaction dataset with accurate body movements, hand gestures, and textual descriptions for research.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproved decoding of expander codes: fundamental trade-off between expansion ratio and minimum distance of inner code\n\n\n\nprogramming\n\n\n\nTanner codes and expander codes use bipartite graphs. The paper shows conditions for decoding expander codes efficiently.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Media Bias Taxonomy: A Systematic Literature Review on the Forms and Automated Detection of Media Bias\n\n\n\nhci\n\n\n\nMedia bias impacts public opinion. This article reviews research on detecting bias and introduces the Media Bias Taxonomy. Transformer-based approaches show promise, but…\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScaling Down, LiTting Up: Efficient Zero-Shot Listwise Reranking with Seq2seq Encoder-Decoder Models\n\n\n\nproduction\n\n\n\nEfficient zero-shot listwise reranking with LiT5-Distill and LiT5-Score challenge large-scale models. Competitive results with smaller models. Code available.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Comprehensive Survey of Evaluation Techniques for Recommendation Systems\n\n\n\nrecommender\n\n\n\nThis paper introduces a comprehensive suite of metrics to evaluate recommendation systems’ performance and their impact on business success.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemantic Importance-Aware Based for Multi-User Communication Over MIMO Fading Channels\n\n\n\nproduction\n\n\n\nNovel SIA-SC system boosts semantic performance in multi-user MIMO scenarios, with a new metric to measure performance.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrincipled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4\n\n\n\nprompt-engineering\n\n\n\n26 principles for efficient queries and prompts for large language models, verified on various models, to aid researchers.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnsemble Learning to Assess Dynamics of Affective Experience Ratings and Physiological Change\n\n\n\nhci\n\n\n\nUsing advanced technology and open science to address the relationship between emotions, physiology, and data analysis in the EPiC challenge.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Prompt Learning Framework for Source Code Summarization\n\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\nPromptCS improves code summarization using continuous prompts for LLMs, outperforming other schemes with faster training and better summaries.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models are Not Stable Recommender Systems\n\n\n\nrecommender\n\n\n\nLLMs’ positional bias hinders recommendation stability. Researchers propose STELLA, a Bayesian framework, to mitigate bias and improve recommendation performance in LLMs.\n\n\n\nDec 25, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlleviating Hallucinations of Large Language Models through Induced Hallucinations\n\n\n\nrobustness\n\n\n\nTL;DR: New method Induce-then-Contrast Decoding reduces inaccuracies in large language models by penalizing induced hallucinations in their responses.\n\n\n\nDec 25, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnlocking the Potential of Large Language Models for Explainable Recommendations\n\n\n\nrecommender\n\n\n\nTL;DR: The study proposes LLMXRec, a framework using large language models for better explanations in recommendation systems.\n\n\n\nDec 25, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Persuasive Power of Large Language Models\n\n\n\nhci\n\n\n\nLarge Language Models could generate effective arguments, shaping public opinion in online discourse. Synthetic social systems mimic human opinion dynamics.\n\n\n\nDec 24, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvolving Large Language Model Assistant with Long-Term Conditional Memory\n\n\n\nrobustness\n\n\n\nAI assistants like ChatGPT with long-term memory improve responses using past dialogue, tested on different datasets.\n\n\n\nDec 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogic-Scaffolding: Personalized Aspect-Instructed Recommendation Explanation Generation using LLMs\n\n\n\nhci\n\n\nprompt-engineering\n\n\n\nLarge Language Models have potential for recommendation explanations, but existing models struggle. Logic-Scaffolding offers a solution.\n\n\n\nDec 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Contextual Bandits for Personalized Recommendation\n\n\n\nrecommender\n\n\n\nTutorial on contextual bandits for personalized recommendations, exploring challenges, advanced algorithms, and future prospects in online businesses.\n\n\n\nDec 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeometric Awareness in Neural Fields for 3D Human Registration\n\n\n\nrobustness\n\n\n\nTL;DR: New neural field model (LoVD) and self-supervised task (INT) improve 3D human body alignment, outperforming existing methods.\n\n\n\nDec 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChatGPT as a commenter to the news: can LLMs generate human-like opinions?\n\n\n\nprogramming\n\n\n\nGPT-3.5 can’t generate human-like Dutch news comments, even with various prompting techniques and personas.\n\n\n\nDec 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRényi Pufferfish Privacy: General Additive Noise Mechanisms and Privacy Amplification by Iteration\n\n\n\nproduction\n\n\n\nFlexible privacy framework Pufferfish faces challenges in maintaining utility. A variant using Renyi divergence improves applicability and utility.\n\n\n\nDec 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDesigning Artificial Intelligence Equipped Social Decentralized Autonomous Organizations for Tackling Sextortion Cases Version 0.7\n\n\n\nhci\n\n\n\nText explores sextortion, studies lack of coordination in victim support, proposes AI and blockchain-based solutions.\n\n\n\nDec 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nContext-aware Decoding Reduces Hallucination in Query-focused Summarization\n\n\n\nrobustness\n\n\n\nQuery-focused summarization (QFS) uses Context-aware Decoding (CAD) to improve generation quality for QFS tasks.\n\n\n\nDec 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpen-Set: ID Card Presentation Attack Detection using Neural Transfer Style\n\n\n\nsecurity\n\n\n\nStudy explores using GANs to improve ID card Presentation Attack detection, showing effectiveness in training fraud detection systems.\n\n\n\nDec 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAndroid dialogue system for customer service using prompt-based topic control and compliments generation\n\n\n\nhci\n\n\nprompt-engineering\n\n\n\nA chatbot system for trip planning uses AI to control conversation topics and generate personalized compliments, showing effectiveness in a preliminary evaluation.\n\n\n\nDec 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuick Order Fairness: Implementation and Evaluation\n\n\n\nsecurity\n\n\n\nDecentralized finance tackles trust issues using blockchain but faces front-running vulnerabilities. QOF protocol mitigates attacks but adds complexity.\n\n\n\nDec 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrometheus: Infrastructure Security Posture Analysis with AI-generated Attack Graphs\n\n\n\nsecurity\n\n\n\nTL;DR: Cybersecurity breaches demand a holistic security solution. Prometheus system assesses vulnerabilities and attack paths comprehensively.\n\n\n\nDec 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLRS: Enhancing Adversarial Transferability through Lipschitz Regularized Surrogate\n\n\n\nsecurity\n\n\n\nTL;DR: The paper proposes Lipschitz Regularized Surrogate for improving transfer-based black-box attacks using transformed surrogate models.\n\n\n\nDec 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nToward enriched Cognitive Learning with XAI\n\n\n\nprompt-engineering\n\n\n\nAI-supported system CL-XAI enhances cognitive learning with explainable AI tools, benefiting human learners and addressing knowledge deficiencies.\n\n\n\nDec 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrompting Hard or Hardly Prompting: Prompt Inversion for Text-to-Image Diffusion Models\n\n\n\nprompt-engineering\n\n\n\nDiffusion models require engineered prompts for faithful image synthesis. This work focuses on inverting the model for interpretable language prompts, using a delayed…\n\n\n\nDec 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTerrapin Attack: Breaking SSH Channel Integrity By Sequence Number Manipulation\n\n\n\nsecurity\n\n\n\nSSH protocol vulnerabilities allow attackers to break channel integrity and downgrade security measures, affecting millions of servers.\n\n\n\nDec 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn Inference Stability for Diffusion Models\n\n\n\nproduction\n\n\n\nTL;DR: Denoising Probabilistic Models (DPMs) improve image generation with a new sequence-aware loss, yielding better results than traditional methods.\n\n\n\nDec 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeamCAD – A Multimodal Interface for Remote Computer Aided Design\n\n\n\neducation\n\n\n\nTL;DR: TeamCAD improves remote design collaboration with voice and gesture recognition for better user experience.\n\n\n\nDec 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLocalization and Discrete Beamforming with a Large Reconfigurable Intelligent Surface\n\n\n\nproduction\n\n\n\nTL;DR: Proposed scalable protocol and algorithms address issues in near-field RIS beamforming for improved localization in mmWave cellular systems.\n\n\n\nDec 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBypassing the Safety Training of Open-Source LLMs with Priming Attacks\n\n\n\nsecurity\n\n\nopen-source\n\n\n\nLLMs lack safety training and are vulnerable to priming attacks, effectively bypassing alignment, increasing attack success rate.\n\n\n\nDec 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFedDiv: Collaborative Noise Filtering for Federated Learning with Noisy Labels\n\n\n\nproduction\n\n\n\nF-LNL aims for optimal server model via collaborative learning, FedDiv introduces global noise filter for stability and performance.\n\n\n\nDec 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode Ownership in Open-Source AI Software Security\n\n\n\nsecurity\n\n\n\nNovel code ownership metrics correlate with security in AI open-source projects, aiding project evaluation and benchmarking.\n\n\n\nDec 18, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA novel diffusion recommendation algorithm based on multi-scale cnn and residual lstm\n\n\n\nrecommender\n\n\n\nSequential recommendation enhances user prediction with a novel diffusion recommendation algorithm named AREAL, achieving significant improvements in experiments.\n\n\n\nDec 18, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn-Device Recommender Systems: A Tutorial on The New-Generation Recommendation Paradigm\n\n\n\nrecommender\n\n\n\nTL;DR: On-device recommender systems (ODRSs) are emerging to address challenges of traditional cloud-based systems in e-commerce applications, offering lightweight…\n\n\n\nDec 18, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection\n\n\n\nsecurity\n\n\n\nJailGuard detects jailbreak attacks on large language models with 89.38% accuracy for image inputs and 85.42% for text, outperforming existing methods.\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYour Student is Better Than Expected: Adaptive Teacher-Student Collaboration for Text-Conditional Diffusion Models\n\n\n\neducation\n\n\n\nKnowledge distillation improves image synthesis by blending student and teacher models for better quality samples.\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI Gender Bias, Disparities, and Fairness: Does Training Data Matter?\n\n\n\neducation\n\n\n\nStudy examines gender biases in AI scoring of student responses. Mixed-trained models show no significant scoring bias but may widen gender disparities.\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHE-DKSAP: Privacy-Preserving Stealth Address Protocol via Additively Homomorphic Encryption\n\n\n\nsecurity\n\n\n\nBlockchain transactions face privacy concerns. Stealth addresses mitigate these, but have vulnerabilities. HE-DKSAP offers a secure, scalable privacy solution.\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRe-parameterized Low-rank Prompt: Generalize a Vision-Language Model within 0.5K Parameters\n\n\n\nprompt-engineering\n\n\n\nVision-language model adaptation is enhanced through RLP prompts, reducing parameters and storage, achieving superior results.\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAddressing Sample Inefficiency in Multi-View Representation Learning\n\n\n\nrecommender\n\n\n\nNon-contrastive self-supervised learning (NC-SSL) insights improve representation learning efficiency and performance in computer vision.\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkNN-ICL: Compositional Task-Oriented Parsing Generalization with Nearest Neighbor In-Context Learning\n\n\n\nprogramming\n\n\n\nLLMs improve semantic parsing tasks without needing extra data or specialized prompts, achieving comparable performance to supervised models.\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMixed Distillation Helps Smaller Language Model Better Reasoning\n\n\n\nproduction\n\n\n\nSmaller models gain LLM capabilities through Mixed Distillation, outperforming LLMs in reasoning accuracy.\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Unified Framework for Multi-Domain CTR Prediction via Large Language Models\n\n\n\nrecommender\n\n\n\nUni-CTR is a new approach to multi-domain click-through rate (MDCTR) prediction, leveraging a Large Language Model (LLM) and domain-specific networks for better performance…\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRevealing Networks: Understanding Effective Teacher Practices in AI-Supported Classrooms using Transmodal Ordered Network Analysis\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nUsing AI and quantitative ethnography, the study uncovers effective teacher practices in classrooms using AI tutors.\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding the Instruction Mixture for Large Language Model\n\n\n\neducation\n\n\nprogramming\n\n\n\nExploring the impact of different instruction types on large language models’ performance reveals the need for careful instruction design.\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDePRL: Achieving Linear Convergence Speedup in Personalized Decentralized Learning with Shared Representations\n\n\n\nproduction\n\n\n\nDePRL is a new personalized decentralized learning algorithm that improves convergence speed and performance in heterogeneous data environments.\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLatent Space Editing in Transformer-Based Flow Matching\n\n\n\nprompt-engineering\n\n\n\nTL;DR: The paper introduces a new image editing method using Flow Matching and a transformer backbone for scalable and high-quality generative modeling.\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Trustworthy AI Software Development Assistance\n\n\n\nprogramming\n\n\n\nA new architecture aims to improve AI software development assistants’ reliability and code quality. It includes a foundational LLM and a knowledge graph.\n\n\n\nDec 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoevolutionary Algorithm for Building Robust Decision Trees under Minimax Regret\n\n\n\nsecurity\n\n\n\nNovel CoEvoRDT algorithm creates robust decision trees, outperforming state-of-the-art methods in handling adversarial attacks.\n\n\n\nDec 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn the Difficulty of Defending Contrastive Learning against Backdoor Attacks\n\n\n\nsecurity\n\n\n\nContrastive backdoor attacks differ from supervised ones, requiring tailored defenses due to distinct learning mechanisms.\n\n\n\nDec 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating Augmented Reality Communication: How Can We Teach Procedural Skill in AR?\n\n\n\neducation\n\n\n\nAR in healthcare for remote medical training analyzed for teaching a CVC procedure, comparing AR and video communication.\n\n\n\nDec 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Verifiable Text Generation with Evolving Memory and Self-Reflection\n\n\n\nrobustness\n\n\n\nLarge Language Models (LLMs) face challenges in accuracy and verification. An innovative approach, VTG, uses memory and retrieval to improve text generation.\n\n\n\nDec 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCMOSE: Comprehensive Multi-Modality Online Student Engagement Dataset with High-Quality Labels\n\n\n\neducation\n\n\n\nTL;DR: Engagement recognition in online learning can be improved with CMOSE dataset and MocoRank training mechanism.\n\n\n\nDec 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Robot Program Synthesis Through Environmental Context\n\n\n\nrobustness\n\n\n\nRecent work on program synthesis uses deep neural networks and language models to generate programs, addressing challenges with partially observed environments.\n\n\n\nDec 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprompt-engineering-assisted Malware Dynamic Analysis Using GPT-4\n\n\n\nrobustness\n\n\n\nDynamic analysis with GPT-4 creates explanatory text for API calls to improve malware detection. Outperforms TextCNN with high generalization.\n\n\n\nDec 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrompt Engineering-assisted Malware Dynamic Analysis Using GPT-4\n\n\n\nrobustness\n\n\n\nDynamic analysis with GPT-4 creates explanatory text for API calls to improve malware detection. Outperforms TextCNN with high generalization.\n\n\n\nDec 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGuardRails: Automated Suggestions for Clarifying Ambiguous Purpose Statements\n\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\nPurpose statements for functions may be ambiguous; a heuristic is proposed to suggest clarifications using language models.\n\n\n\nDec 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Precoding for ORIS-Assisted MIMO Multi-User VLC System\n\n\n\nproduction\n\n\n\nMulti-user VLC system improves SINR with ORIS and optimized precoding matrices, outperforming ZF and MMSE algorithms.\n\n\n\nDec 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEfficient Toxic Content Detection by Bootstrapping and Distilling Large Language Models\n\n\n\neducation\n\n\n\nBD-LLM improves toxic content detection accuracy by using Decision-Tree-of-Thought prompting and student LMs.\n\n\n\nDec 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVenn: Resource Management Across Federated Learning Jobs\n\n\n\nproduction\n\n\n\nTL;DR: Venn is an FL resource manager that efficiently schedules devices among FL jobs, improving job completion time.\n\n\n\nDec 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrompting LLMs with content plans to enhance the summarization of scientific articles\n\n\n\nprompt-engineering\n\n\n\nNovel prompting techniques improve scientific article summarization by providing contextual information, showing performance gains for smaller models.\n\n\n\nDec 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExpand-and-Quantize: Unsupervised Semantic Segmentation Using High-Dimensional Space and Product Quantization\n\n\n\nproduction\n\n\n\nTL;DR: EQUSS improves unsupervised semantic segmentation with high-dimensional clustering and information compression for better results.\n\n\n\nDec 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReRoGCRL: Representation-based Robustness in Goal-Conditioned Reinforcement Learning\n\n\n\nsecurity\n\n\n\nPropose new attack and defense mechanisms for robustness in GCRL, with superior performance validated. Tool available.\n\n\n\nDec 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models are Clinical Reasoners: Reasoning-Aware Diagnosis Framework with Prompt-Generated Rationales\n\n\n\nprompt-engineering\n\n\n\nProposes a diagnosis framework using prompt-based learning for clinical reasoning in disease diagnosis, evaluating machine-generated rationales for real-world clinical…\n\n\n\nDec 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nICL Markup: Structuring In-Context Learning using Soft-Token Tags\n\n\n\nprogramming\n\n\n\nTL;DR: Soft-token tags simplify model adaptation for various tasks, improving LLM performance in enterprise applications.\n\n\n\nDec 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMEval: A Preliminary Study on How to Evaluate Large Language Models\n\n\n\neducation\n\n\n\nThis paper examines Large Language Model (LLM) evaluation methods, proposes a new dataset, and provides insights.\n\n\n\nDec 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan ChatGPT Play the Role of a Teaching Assistant in an Introductory Programming Course?\n\n\n\nprogramming\n\n\neducation\n\n\n\nStudy evaluates ChatGPT as a virtual TA for programming course. Compares its performance with human TAs in solving assignments, grading, and providing feedback.\n\n\n\nDec 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntegrating micro-learning content in traditional e-learning platforms\n\n\n\neducation\n\n\n\nTL;DR: This article explores micro-learning as a solution for corporate training, proposing to integrate it into traditional learning systems.\n\n\n\nDec 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean estimation in the add-remove model of differential privacy\n\n\n\nproduction\n\n\n\nNew algorithm for mean estimation in differential privacy under add-remove model, with similar error to swap model. Factor-of-two improvement demonstrated.\n\n\n\nDec 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSparse but Strong: Crafting Adversarially Robust Graph Lottery Tickets\n\n\n\nsecurity\n\n\n\nGraph Lottery Tickets (GLTs) reduce latency and footprint, but are vulnerable to structure attacks. A framework called ARGS enhances robustness.\n\n\n\nDec 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPerformance-lossless Black-box Model Watermarking\n\n\n\nrobustness\n\n\n\nPropose watermarking protocol protects model IP with branch backdoor-based method, verified with language generation task.\n\n\n\nDec 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM Interactive Optimization of Open Source Python Libraries – Case Studies and Generalization\n\n\n\nhci\n\n\nprogramming\n\n\n\nLLMs like ChatGPT-4 can optimize energy and compute efficiency in python libraries with human input.\n\n\n\nDec 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChain of Code: Reasoning with a Language Model-Augmented Code Emulator\n\n\n\nprogramming\n\n\n\nCode-writing aids language models in Chain of Thought reasoning, improving linguistic and logical tasks. Chain of Code outperforms Chain of Thought.\n\n\n\nDec 7, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEAGLES: Efficient Accelerated 3D Gaussians with Lightweight EncodingS\n\n\n\nproduction\n\n\n\n3D-GS accelerates scene synthesis, uses few Gaussians with quantized representations, reduces memory, and speeds up training and rendering.\n\n\n\nDec 7, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models for Mathematicians\n\n\n\nprogramming\n\n\neducation\n\n\n\nChatGPT and similar models can aid professional mathematicians by improving work speed and quality.\n\n\n\nDec 7, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoordination-free Decentralised Federated Learning on Complex Networks: Overcoming Heterogeneity\n\n\n\nproduction\n\n\n\nDecentralised Federated Learning (DFL) copes with edge computing challenges, enabling devices to train accurate models using a communication-efficient algorithm.\n\n\n\nDec 7, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMOCHa: Multi-Objective Reinforcement Mitigating Caption Hallucinations\n\n\n\nrobustness\n\n\n\nPropose MOCHa, a reinforcement learning approach, to reduce hallucinations in image captioning and demonstrate its superior performance.\n\n\n\nDec 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMitigating Data Injection Attacks on Federated Learning\n\n\n\nsecurity\n\n\n\nA novel method detects and mitigates data injection attacks in federated learning, ensuring model accuracy and data privacy.\n\n\n\nDec 4, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Bayesian beagle",
    "section": "",
    "text": "I’m a Bayesian beagle who has curated LLM-summarized articles on LLMs."
  },
  {
    "objectID": "posts/Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives/2024-01-09-Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives.html#takeaways",
    "href": "posts/Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives/2024-01-09-Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives.html#takeaways",
    "title": "Large Language Models for Robotics: Opportunities, Challenges, and Perspectives",
    "section": "Takeaways:",
    "text": "Takeaways:\n\nLLMs have been increasingly integrated into robotic task planning due to their advanced reasoning and language comprehension capabilities.\nThe integration of multimodal GPT-4V has shown promise in enhancing robot performance in embodied tasks, as demonstrated by diverse datasets.\nLLM-centric embodied intelligence holds potential for various applications, such as precision agriculture, healthcare, and brain-computer interfaces."
  },
  {
    "objectID": "posts/Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives/2024-01-09-Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives.html#i-introduction",
    "href": "posts/Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives/2024-01-09-Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives.html#i-introduction",
    "title": "Large Language Models for Robotics: Opportunities, Challenges, and Perspectives",
    "section": "I Introduction",
    "text": "I Introduction\n\nLarge pre-trained models have demonstrated remarkable capabilities across complex tasks in various domains.\nThe utilization of instruction tuning and alignment tuning has become the primary approach to adapt LLMs for specific objectives."
  },
  {
    "objectID": "posts/Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives/2024-01-09-Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives.html#ii-related-work",
    "href": "posts/Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives/2024-01-09-Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives.html#ii-related-work",
    "title": "Large Language Models for Robotics: Opportunities, Challenges, and Perspectives",
    "section": "II Related Work",
    "text": "II Related Work\n\nII-A LLM for Robotics\n\nLLMs exhibit exceptional natural language understanding and commonsense reasoning capabilities, contributing to enhanced comprehension and execution for robots.\n\n\n\nII-B Multimodal Task Planning with LLMs\n\nMultimodal LLMs excel in interpreting and correlating multiple data streams, broadening their role from language processing to more integrative functions."
  },
  {
    "objectID": "posts/Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives/2024-01-09-Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives.html#iii-scope-of-robotic-tasks",
    "href": "posts/Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives/2024-01-09-Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives.html#iii-scope-of-robotic-tasks",
    "title": "Large Language Models for Robotics: Opportunities, Challenges, and Perspectives",
    "section": "III Scope of Robotic Tasks",
    "text": "III Scope of Robotic Tasks\n\nIII-A Planning\n\nIII-A1 Natural Language Understanding\n\nLLMs excel in interpreting natural language instructions and integrating multimodal information to create actionable guidance for virtual agents.\n\n\n\nIII-A2 Complex Task Reasoning and Decision-making\n\nLLMs advance complex task reasoning and decision-making through reinforcement learning and collaboration with other modalities.\n\n\n\nIII-A3 Human-robot interaction\n\nIntegration of reinforcement learning with human feedback enables robots to continuously improve their task execution.\n\n\n\n\nIII-B Manipulation\n\nIII-B1 Natural Language Understanding\n\nLLMs help robots make common-sense analyses and enhance adaptability to new scenarios, agents, and tasks.\n\n\n\nIII-B2 Interactive Strategies\n\nThe use of LLMs in robot control focuses on generating interactive reward codes and extracting operants and constraints from LLMs.\n\n\n\nIII-B3 Modular Approaches\n\nModular approaches enhance system flexibility and adaptability to new tasks and environments.\n\n\n\n\nIII-C Reasoning\n\nIII-C1 Natural Language Understanding\n\nLLMs provide common sense insights crucial for various tasks, avoiding the need for costly data gathering and model training.\n\n\n\nIII-C2 Complex Task Reasoning and Decision-making\n\nLLMs leverage high-level semantic knowledge to enhance task execution and demonstrate effective performance, even in tasks with intricate settings or specific requirements.\n\n\n\nIII-C3 Interactive Strategies\n\nLLMs augment interactive multimodal perception and the development of advanced architectures and interaction patterns."
  },
  {
    "objectID": "posts/Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives/2024-01-09-Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives.html#iv-gpt-4v-empowered-embodied-task-planning",
    "href": "posts/Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives/2024-01-09-Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives.html#iv-gpt-4v-empowered-embodied-task-planning",
    "title": "Large Language Models for Robotics: Opportunities, Challenges, and Perspectives",
    "section": "IV GPT-4V Empowered Embodied Task Planning",
    "text": "IV GPT-4V Empowered Embodied Task Planning\n\nGPT-4V has demonstrated impressive performance in multimodal task planning across diverse environments and scenarios."
  },
  {
    "objectID": "posts/Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives/2024-01-09-Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives.html#v-experimental-results",
    "href": "posts/Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives/2024-01-09-Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives.html#v-experimental-results",
    "title": "Large Language Models for Robotics: Opportunities, Challenges, and Perspectives",
    "section": "V Experimental Results",
    "text": "V Experimental Results\n\nThe matching score for the generated task plans consistently reflects a high level of agreement between the LLM-generated plans and the ground truth demonstrations."
  },
  {
    "objectID": "posts/Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives/2024-01-09-Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives.html#vi-limitation-discussion-and-future-work",
    "href": "posts/Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives/2024-01-09-Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives.html#vi-limitation-discussion-and-future-work",
    "title": "Large Language Models for Robotics: Opportunities, Challenges, and Perspectives",
    "section": "VI Limitation, Discussion and Future Work",
    "text": "VI Limitation, Discussion and Future Work\n\nChallenges include homogenous generated plans, the need for carefully crafted prompts, and the closed-source nature of the GPT-4V API.\nFuture work focuses on addressing these challenges and developing more robust AGI robotic systems."
  },
  {
    "objectID": "posts/Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives/2024-01-09-Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives.html#vii-conclusion",
    "href": "posts/Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives/2024-01-09-Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives.html#vii-conclusion",
    "title": "Large Language Models for Robotics: Opportunities, Challenges, and Perspectives",
    "section": "VII Conclusion",
    "text": "VII Conclusion\n\nLLMs demonstrate impressive reasoning, language understanding, and multimodal processing abilities that can significantly enhance robotic comprehension and task execution."
  },
  {
    "objectID": "posts/Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives/2024-01-09-Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives.html#critique",
    "href": "posts/Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives/2024-01-09-Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives.html#critique",
    "title": "Large Language Models for Robotics: Opportunities, Challenges, and Perspectives",
    "section": "Critique",
    "text": "Critique\nThe paper provides a comprehensive overview and evaluation of LLMs and multimodal LLMs in robotic tasks. However, it would benefit from addressing potential biases in the evaluation process and considering the ethical implications of implementing advanced LLMs in robotics. Additionally, the critique would be enhanced by acknowledging potential limitations in the generalization of study results to real-world applications."
  },
  {
    "objectID": "posts/Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives/2024-01-09-Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives.html#appendix",
    "href": "posts/Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives/2024-01-09-Large_Language_Models_for_Robotics_Opportunities_Challenges_and_Perspectives.html#appendix",
    "title": "Large Language Models for Robotics: Opportunities, Challenges, and Perspectives",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.04334v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.04334v1\n\n\nTruncated\nTrue\n\n\nWord Count\n14055"
  },
  {
    "objectID": "posts/Mitigating_Data_Injection_Attacks_on_Federated_Learning/2023-12-04-Mitigating_Data_Injection_Attacks_on_Federated_Learning.html#appendix",
    "href": "posts/Mitigating_Data_Injection_Attacks_on_Federated_Learning/2023-12-04-Mitigating_Data_Injection_Attacks_on_Federated_Learning.html#appendix",
    "title": "Mitigating Data Injection Attacks on Federated Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.02102v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.02102v2\n\n\nTruncated\nFalse\n\n\nWord Count\n7092"
  },
  {
    "objectID": "posts/Video_Understanding_with_Large_Language_Models_A_Survey/2023-12-29-Video_Understanding_with_Large_Language_Models_A_Survey.html#appendix",
    "href": "posts/Video_Understanding_with_Large_Language_Models_A_Survey/2023-12-29-Video_Understanding_with_Large_Language_Models_A_Survey.html#appendix",
    "title": "Video Understanding with Large Language Models: A Survey",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17432v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17432v1\n\n\nTruncated\nTrue\n\n\nWord Count\n23164"
  },
  {
    "objectID": "posts/Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners/2023-12-26-Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners.html#appendix",
    "href": "posts/Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners/2023-12-26-Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners.html#appendix",
    "title": "Supervised Knowledge Makes Large Language Models Better In-context Learners",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.15918v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.15918v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12183"
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#findings",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#findings",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Findings",
    "text": "Findings\n\nDistillation Method: The paper proposes distilling the knowledge of fine-tuned Large Language Models (LLMs) into smaller, more efficient, and accurate neural networks using a specialized loss function tailored for the LLM’s output probabilities. Results showed that the distilled student models achieved 12% higher accuracy than normal neural network models on smaller datasets.\nModel Size: The student model size ranges from 0.1M to 0.02M, 100 times smaller in terms of parameters and ten times smaller compared to the original model size.\nEducational Access: The study highlights the potential to make advanced AI technologies accessible in typical educational settings, particularly for automatic scoring, which can enhance personalized learning experiences and adaptive assessment tools."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#background",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#background",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Background",
    "text": "Background\n\nLLMs in Education: LLMs have shown promise in enhancing learning experiences, providing personalized learning content, and automating scoring systems, but their deployment in educational settings is hindered by their size and computational requirements.\nKnowledge Distillation (KD): KD has emerged as a pivotal technique in harnessing the power of LLMs for practical applications, particularly in fields with limited computational resources."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#methodology",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#methodology",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Methodology",
    "text": "Methodology\n\nOriginal Neural Network: The study uses a deep neural network to approximate the conditional probability function for the classification tasks.\nProposed KD: The study proposes a KD approach where the teacher model’s predicted probability outputs are used as soft targets for training the compact student model."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#experimental-setup",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#experimental-setup",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Experimental Setup",
    "text": "Experimental Setup\n\nData Collection: The study utilized datasets of student-written responses to science and mathematical questions, categorizing the dataset into multiple tasks.\nTraining Scheme: The model is trained using conventional neural network training approaches and KD strategies and evaluated for performance."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#results",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#results",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Results",
    "text": "Results\n\nComparison: KD was found to enhance the performance of the student model relative to both an original neural network and a more complex teacher model across various datasets.\nEffectiveness of KD: The study demonstrated the efficacy of KD in establishing compact student models with improved performance, making them suitable for resource-constrained educational settings."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#discussion",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#discussion",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Discussion",
    "text": "Discussion\n\nApplication of KD in Education: KD has the potential to create accurate and productive automatic scoring systems, enhancing personalized and interactive learning experiences.\nLimitations of KD: Despite its advantages, KD student models often fall short of the teacher models, and the quality and applicability of training data are crucial factors."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#future-directions",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#future-directions",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Future Directions",
    "text": "Future Directions\n\nSoft label processing: More sophisticated validation techniques to process soft labels.\nEthical and Fairness Considerations: Addressing bias and fairness issues in educational applications of KD.\nCustomizable and Adaptive Models: Constructing small KD models adaptable to specific learning environments."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#conclusion",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#conclusion",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Conclusion",
    "text": "Conclusion\nThe paper effectively demonstrates the potential of KD in optimizing LLMs for educational technology, specifically in resource-constrained environments. It establishes the viability of KD in educational contexts and highlights the importance of ongoing research and innovation in AI for education."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#critique",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#critique",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Critique",
    "text": "Critique\n\nThe methodology and results could be strengthened by including more detailed explanations of the model evaluation and validation methods.\nThe study would benefit from discussing potential limitations and biases in the data used for training and testing.\nThe future directions section could further elaborate on the potential challenges and implications of the proposed advancements.\n\nOverall, the paper offers valuable insights into the application of KD in educational technology but could benefit from addressing potential limitations and biases."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#appendix",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#appendix",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.15842v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.15842v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9762"
  },
  {
    "objectID": "posts/Teach_Large_Language_Models_to_Forget_Privacy/2023-12-30-Teach_Large_Language_Models_to_Forget_Privacy.html#appendix",
    "href": "posts/Teach_Large_Language_Models_to_Forget_Privacy/2023-12-30-Teach_Large_Language_Models_to_Forget_Privacy.html#appendix",
    "title": "Teach Large Language Models to Forget Privacy",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00870v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00870v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12649"
  },
  {
    "objectID": "posts/Expand_and_Quantize_Unsupervised_Semantic_Segmentation_Using_High_Dimensional_Space_and_Product_Quantization/2023-12-12-Expand_and_Quantize_Unsupervised_Semantic_Segmentation_Using_High_Dimensional_Space_and_Product_Quantization.html#appendix",
    "href": "posts/Expand_and_Quantize_Unsupervised_Semantic_Segmentation_Using_High_Dimensional_Space_and_Product_Quantization/2023-12-12-Expand_and_Quantize_Unsupervised_Semantic_Segmentation_Using_High_Dimensional_Space_and_Product_Quantization.html#appendix",
    "title": "Expand-and-Quantize: Unsupervised Semantic Segmentation Using High-Dimensional Space and Product Quantization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.07342v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.07342v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10302"
  },
  {
    "objectID": "posts/Self_Contrast_Better_Reflection_Through_Inconsistent_Solving_Perspectives/2024-01-04-Self_Contrast_Better_Reflection_Through_Inconsistent_Solving_Perspectives.html#appendix",
    "href": "posts/Self_Contrast_Better_Reflection_Through_Inconsistent_Solving_Perspectives/2024-01-04-Self_Contrast_Better_Reflection_Through_Inconsistent_Solving_Perspectives.html#appendix",
    "title": "Self-Contrast: Better Reflection Through Inconsistent Solving Perspectives",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.02009v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.02009v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10949"
  },
  {
    "objectID": "posts/Applying_Bayesian_Data_Analysis_for_Causal_Inference_about_Requirements_Quality_A_Replicated_Experiment/2024-01-02-Applying_Bayesian_Data_Analysis_for_Causal_Inference_about_Requirements_Quality_A_Replicated_Experiment.html#appendix",
    "href": "posts/Applying_Bayesian_Data_Analysis_for_Causal_Inference_about_Requirements_Quality_A_Replicated_Experiment/2024-01-02-Applying_Bayesian_Data_Analysis_for_Causal_Inference_about_Requirements_Quality_A_Replicated_Experiment.html#appendix",
    "title": "Applying Bayesian Data Analysis for Causal Inference about Requirements Quality: A Replicated Experiment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01154v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01154v1\n\n\nTruncated\nTrue\n\n\nWord Count\n26833"
  },
  {
    "objectID": "posts/A_Mutation_Based_Method_for_Multi_Modal_Jailbreaking_Attack_Detection/2023-12-17-A_Mutation_Based_Method_for_Multi_Modal_Jailbreaking_Attack_Detection.html#appendix",
    "href": "posts/A_Mutation_Based_Method_for_Multi_Modal_Jailbreaking_Attack_Detection/2023-12-17-A_Mutation_Based_Method_for_Multi_Modal_Jailbreaking_Attack_Detection.html#appendix",
    "title": "A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10766v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10766v1\n\n\nTruncated\nTrue\n\n\nWord Count\n14983"
  },
  {
    "objectID": "posts/Unifying_Structured_Data_as_Graph_for_Data_to_Text_Pre_Training/2024-01-02-Unifying_Structured_Data_as_Graph_for_Data_to_Text_Pre_Training.html#appendix",
    "href": "posts/Unifying_Structured_Data_as_Graph_for_Data_to_Text_Pre_Training/2024-01-02-Unifying_Structured_Data_as_Graph_for_Data_to_Text_Pre_Training.html#appendix",
    "title": "Unifying Structured Data as Graph for Data-to-Text Pre-Training",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01183v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01183v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11140"
  },
  {
    "objectID": "posts/Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#key-findings",
    "href": "posts/Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#key-findings",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Key Findings",
    "text": "Key Findings\n\nInnovative Integration: The Viz system integrates Quantized Low-Rank Adapters (QLoRA) within a marketplace framework, revolutionizing the accessibility and efficiency of large language models (LLMs).\nAddressing Challenges: By reducing computational overhead, ensuring copyright compliance in training datasets, and creating a sustainable economic model, Viz offers a comprehensive solution to the complex challenges of AI landscape.\nLegal and Ethical Compliance: Viz contributes to the discussion on legal and ethical considerations in AI, particularly in copyright compliance and data privacy, providing a holistic and inventive approach to the existing obstacles in the artificial intelligence field."
  },
  {
    "objectID": "posts/Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#introduction",
    "href": "posts/Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#introduction",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Introduction",
    "text": "Introduction\n\nThe paper aims to introduce the Viz system, which addresses challenges of computational efficiency, legal compliance, and economic sustainability in the utilization and monetization of LLMs."
  },
  {
    "objectID": "posts/Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#literature-review",
    "href": "posts/Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#literature-review",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Literature Review",
    "text": "Literature Review\n\nThe review outlines the advancements in LLMs, copyright concerns in AI training, and the evolution of fine-tuning techniques, specifically LoRA and QLoRA."
  },
  {
    "objectID": "posts/Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#viz-system-architecture",
    "href": "posts/Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#viz-system-architecture",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Viz System Architecture",
    "text": "Viz System Architecture\n\nThe system integrates a marketplace for AI models fine-tuned through QLoRA, providing a legally compliant and economically viable avenue for content creators and users."
  },
  {
    "objectID": "posts/Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#qlora-importance-in-viz",
    "href": "posts/Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#qlora-importance-in-viz",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "QLoRA Importance in Viz",
    "text": "QLoRA Importance in Viz\n\nQLoRA’s core principles and adaptation within Viz significantly reduces computational overhead and enhances model performance."
  },
  {
    "objectID": "posts/Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#marketplace-design-and-economics",
    "href": "posts/Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#marketplace-design-and-economics",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Marketplace Design and Economics",
    "text": "Marketplace Design and Economics\n\nThe marketplace employs a dual monetization strategy and revenue sharing models, paralleling existing digital content platforms."
  },
  {
    "objectID": "posts/Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#legal-and-ethical-considerations",
    "href": "posts/Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#legal-and-ethical-considerations",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Legal and Ethical Considerations",
    "text": "Legal and Ethical Considerations\n\nViz ensures adherence to global copyright regulations, data privacy, ethical AI principles, and fair use."
  },
  {
    "objectID": "posts/Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#discussion",
    "href": "posts/Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#discussion",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Discussion",
    "text": "Discussion\n\nThe Viz system’s impact on the AI and content industry, and potential advancements such as decentralization are discussed."
  },
  {
    "objectID": "posts/Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#conclusion",
    "href": "posts/Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#conclusion",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Conclusion",
    "text": "Conclusion\n\nViz sets a precedent for future advancements in AI technology, combining technological innovation, economic insight, and legal caution."
  },
  {
    "objectID": "posts/Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#critique",
    "href": "posts/Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#critique",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Critique",
    "text": "Critique\n\nThe paper could benefit from a more in-depth analysis of potential limitations and challenges in the practical implementation of the Viz system.\nFurther exploration of the potential ethical implications and unintended consequences of widespread adoption of Viz would enhance the discussion."
  },
  {
    "objectID": "posts/Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#appendix",
    "href": "posts/Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz_A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#appendix",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00503v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00503v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6840"
  },
  {
    "objectID": "posts/LLMs_for_Robotic_Object_Disambiguation/2024-01-07-LLMs_for_Robotic_Object_Disambiguation.html#appendix",
    "href": "posts/LLMs_for_Robotic_Object_Disambiguation/2024-01-07-LLMs_for_Robotic_Object_Disambiguation.html#appendix",
    "title": "LLMs for Robotic Object Disambiguation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.03388v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.03388v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5796"
  },
  {
    "objectID": "posts/Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding/2024-01-09-Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding.html#key-findings",
    "href": "posts/Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding/2024-01-09-Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding.html#key-findings",
    "title": "Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding",
    "section": "Key Findings",
    "text": "Key Findings\n\nTable-based reasoning requires extraction of underlying semantics from both free-form questions and semi-structured tabular data.\nThe proposed Chain-of-Table framework achieves new state-of-the-art performance on WikiTQ, FeTaQA, and TabFact benchmarks across multiple LLM choices.\nThe framework outperforms generic reasoning and program-aided reasoning methods on TabFact and WikiTQ."
  },
  {
    "objectID": "posts/Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding/2024-01-09-Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding.html#abstract",
    "href": "posts/Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding/2024-01-09-Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding.html#abstract",
    "title": "Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding",
    "section": "Abstract",
    "text": "Abstract\nThe paper discusses the challenges of table-based reasoning and introduces the Chain-of-Table framework to leverage tabular data in the reasoning chain. It explains the use of in-context learning to iteratively generate operations and update the table, leading to a chain showing the reasoning process for a given tabular problem. The study also presents the outperformance of Chain-of-Table on multiple benchmarks."
  },
  {
    "objectID": "posts/Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding/2024-01-09-Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding.html#introduction",
    "href": "posts/Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding/2024-01-09-Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding.html#introduction",
    "title": "Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding",
    "section": "Introduction",
    "text": "Introduction\nThe introduction highlights the importance of table understanding and the promising direction of table-based reasoning with large language models (LLMs). The authors discuss the limitations of existing approaches and propose the Chain-of-Table framework as a solution."
  },
  {
    "objectID": "posts/Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding/2024-01-09-Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding.html#related-work",
    "href": "posts/Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding/2024-01-09-Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding.html#related-work",
    "title": "Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding",
    "section": "Related Work",
    "text": "Related Work\nThe section provides an overview of previous methods for fine-tuning language models for table understanding and program-aided reasoning for solving table-based tasks. It points out the shortcomings of existing methods in addressing complex table scenarios and sets the context for the proposed Chain-of-Table framework."
  },
  {
    "objectID": "posts/Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding/2024-01-09-Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding.html#chain-of-table-reasoning",
    "href": "posts/Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding/2024-01-09-Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding.html#chain-of-table-reasoning",
    "title": "Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding",
    "section": "Chain-of-Table Reasoning",
    "text": "Chain-of-Table Reasoning\nThe paper delves into the Chain-of-Table reasoning, discussing the problem formulation, overview, dynamic planning, argument generation, and final query stages. It explains the specific table operations used in the framework and presents an ablation study to demonstrate their effectiveness."
  },
  {
    "objectID": "posts/Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding/2024-01-09-Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding.html#experiments",
    "href": "posts/Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding/2024-01-09-Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding.html#experiments",
    "title": "Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding",
    "section": "Experiments",
    "text": "Experiments\nThe results of the experiments on WikiTQ, TabFact, and FeTaQA benchmarks are presented, along with comparisons with baseline methods. The performance analysis under different operation chain lengths and table sizes is discussed, showing the effectiveness of Chain-of-Table across various scenarios."
  },
  {
    "objectID": "posts/Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding/2024-01-09-Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding.html#efficiency-analysis-of-chain-of-table",
    "href": "posts/Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding/2024-01-09-Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding.html#efficiency-analysis-of-chain-of-table",
    "title": "Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding",
    "section": "Efficiency Analysis of Chain-of-Table",
    "text": "Efficiency Analysis of Chain-of-Table\nThe efficiency of the Chain-of-Table framework is analyzed in terms of the number of required generated samples compared to baseline methods. The study shows the improved efficiency of Chain-of-Table in generating queries for tabular reasoning."
  },
  {
    "objectID": "posts/Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding/2024-01-09-Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding.html#case-study",
    "href": "posts/Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding/2024-01-09-Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding.html#case-study",
    "title": "Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding",
    "section": "Case Study",
    "text": "Case Study\nA case study is presented to illustrate the tabular reasoning process in Chain-of-Table, showcasing how the framework facilitates correct answers by dynamically planning an operation chain and accurately storing intermediate results."
  },
  {
    "objectID": "posts/Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding/2024-01-09-Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding.html#conclusion",
    "href": "posts/Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding/2024-01-09-Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding.html#conclusion",
    "title": "Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding",
    "section": "Conclusion",
    "text": "Conclusion\nThe paper concludes by emphasizing the enhanced reasoning capability of LLMs with Chain-of-Table and the potential for leveraging tabular structure to express intermediate thoughts for table-based reasoning. Additionally, it highlights the role of Chain-of-Table in instructing LLMs to dynamically plan operation chains for improved table understanding."
  },
  {
    "objectID": "posts/Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding/2024-01-09-Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding.html#appendix",
    "href": "posts/Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding/2024-01-09-Chain_of_Table_Evolving_Tables_in_the_Reasoning_Chain_for_Table_Understanding.html#appendix",
    "title": "Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.04398v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.04398v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9507"
  },
  {
    "objectID": "posts/Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep/2023-12-28-Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep.html#main-findings",
    "href": "posts/Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep/2023-12-28-Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep.html#main-findings",
    "title": "Do Androids Know They’re Only Dreaming of Electric Sheep?",
    "section": "Main Findings",
    "text": "Main Findings\n\nThe study explores probes on a decoder-only transformer language model to detect hallucinations in multiple grounded generation tasks.\nProbes trained on the force-decoded states of synthetic hallucinations outperform contemporary baselines, showing that probing is a feasible and efficient alternative to language model hallucination evaluation when model states are available.\nThe work presents a high-quality dataset of over 15k utterances with hallucination annotations for organic and synthetic output texts across three grounded generation tasks."
  },
  {
    "objectID": "posts/Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep/2023-12-28-Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep.html#introduction",
    "href": "posts/Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep/2023-12-28-Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep.html#introduction",
    "title": "Do Androids Know They’re Only Dreaming of Electric Sheep?",
    "section": "Introduction",
    "text": "Introduction\n\nThe paper explores whether language models can detect hallucinations in their outputs and develops probes for this purpose.\nPrevious work focused on creating secondary detection models trained on and applied to surface text, but ignored the information already computed during generation.\nThe study aims to explore the degree to which probes on a decoder-only transformer language model can detect hallucinations in various grounded generation tasks."
  },
  {
    "objectID": "posts/Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep/2023-12-28-Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep.html#related-work",
    "href": "posts/Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep/2023-12-28-Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep.html#related-work",
    "title": "Do Androids Know They’re Only Dreaming of Electric Sheep?",
    "section": "Related Work",
    "text": "Related Work\n\nThe study focuses on hallucinations in the setting of in-context generation where grounding knowledge sources are provided within the prompt.\nHallucinations are classified as intrinsic, where generated responses directly contradict the knowledge sources, or extrinsic, where generated responses are neither entailed nor contradicted by the sources.\nPrior work uses various metrics and models such as Lexical metrics, NLI approaches, question-answer models, and transformer behavior prediction in small and large language models."
  },
  {
    "objectID": "posts/Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep/2023-12-28-Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep.html#grounded-generation-tasks",
    "href": "posts/Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep/2023-12-28-Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep.html#grounded-generation-tasks",
    "title": "Do Androids Know They’re Only Dreaming of Electric Sheep?",
    "section": "Grounded Generation Tasks",
    "text": "Grounded Generation Tasks\n\nThe study tests hallucination probes for autoregressive grounded generation in abstractive summarization, knowledge-grounded dialogue generation, and data-to-text.\nIt collects hallucinations in two ways: from sampled responses generated from a large language model and by editing reference inputs or outputs to create discrepancies.\nThe authors provide full details and examples for each task."
  },
  {
    "objectID": "posts/Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep/2023-12-28-Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep.html#probing",
    "href": "posts/Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep/2023-12-28-Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep.html#probing",
    "title": "Do Androids Know They’re Only Dreaming of Electric Sheep?",
    "section": "Probing",
    "text": "Probing\n\nProbes are designed as tools to analyze a neural network’s internal representations using linear classifiers and attention-pooling probes.\nThey are trained to discriminate between different types of inputs or outputs to detect hallucinations in the language model’s generated responses."
  },
  {
    "objectID": "posts/Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep/2023-12-28-Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep.html#experiments",
    "href": "posts/Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep/2023-12-28-Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep.html#experiments",
    "title": "Do Androids Know They’re Only Dreaming of Electric Sheep?",
    "section": "Experiments",
    "text": "Experiments\n\nResults show that probes trained on organic hallucinations worked best on specific datasets.\nProbes achieve high F1 in the detection of synthetically created hallucinations across all tasks.\nThe study demonstrates nuances in the saliency of hallucinatory behavior across model layers, hidden state types, model sizes, hallucination types, and contexts."
  },
  {
    "objectID": "posts/Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep/2023-12-28-Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep.html#discussion",
    "href": "posts/Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep/2023-12-28-Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep.html#discussion",
    "title": "Do Androids Know They’re Only Dreaming of Electric Sheep?",
    "section": "Discussion",
    "text": "Discussion\n\nThe study points out the efficiency and access limitations of probing and highlights the need for labeled in-domain data for probe training.\nIt emphasizes the need for better quality synthetic training data and discusses challenges in annotator disagreements, probe design, ecological validity, and the potential for mitigation of hallucinations in language models."
  },
  {
    "objectID": "posts/Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep/2023-12-28-Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep.html#critique",
    "href": "posts/Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep/2023-12-28-Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep.html#critique",
    "title": "Do Androids Know They’re Only Dreaming of Electric Sheep?",
    "section": "Critique",
    "text": "Critique\nThis paper presents valuable insights into the detection of hallucinations in language model outputs. However, the study’s generalization to out-of-domain tasks is limited, and the reliance on hidden states may pose challenges if LLMs move behind closed-source APIs. Additionally, the ecological validity of synthetic hallucinations and the annotation guidelines require further refinement to improve accuracy and reproducibility. Further exploration of more advanced probe architectures and mitigation strategies is also warranted for practical application."
  },
  {
    "objectID": "posts/Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep/2023-12-28-Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep.html#appendix",
    "href": "posts/Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep/2023-12-28-Do_Androids_Know_Theyre_Only_Dreaming_of_Electric_Sheep.html#appendix",
    "title": "Do Androids Know They’re Only Dreaming of Electric Sheep?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17249v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17249v1\n\n\nTruncated\nTrue\n\n\nWord Count\n16039"
  },
  {
    "objectID": "posts/On_the_Difficulty_of_Defending_Contrastive_Learning_against_Backdoor_Attacks/2023-12-14-On_the_Difficulty_of_Defending_Contrastive_Learning_against_Backdoor_Attacks.html#appendix",
    "href": "posts/On_the_Difficulty_of_Defending_Contrastive_Learning_against_Backdoor_Attacks/2023-12-14-On_the_Difficulty_of_Defending_Contrastive_Learning_against_Backdoor_Attacks.html#appendix",
    "title": "On the Difficulty of Defending Contrastive Learning against Backdoor Attacks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.09057v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.09057v1\n\n\nTruncated\nTrue\n\n\nWord Count\n28425"
  },
  {
    "objectID": "posts/ReRoGCRL_Representation_based_Robustness_in_Goal_Conditioned_Reinforcement_Learning/2023-12-12-ReRoGCRL_Representation_based_Robustness_in_Goal_Conditioned_Reinforcement_Learning.html#appendix",
    "href": "posts/ReRoGCRL_Representation_based_Robustness_in_Goal_Conditioned_Reinforcement_Learning/2023-12-12-ReRoGCRL_Representation_based_Robustness_in_Goal_Conditioned_Reinforcement_Learning.html#appendix",
    "title": "ReRoGCRL: Representation-based Robustness in Goal-Conditioned Reinforcement Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.07392v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.07392v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8910"
  },
  {
    "objectID": "posts/keqing_knowledge_based_question_answering_is_a_nature_chain_of_thought_mentor_of_LLM/2023-12-31-keqing_knowledge_based_question_answering_is_a_nature_chain_of_thought_mentor_of_LLM.html#appendix",
    "href": "posts/keqing_knowledge_based_question_answering_is_a_nature_chain_of_thought_mentor_of_LLM/2023-12-31-keqing_knowledge_based_question_answering_is_a_nature_chain_of_thought_mentor_of_LLM.html#appendix",
    "title": "keqing: knowledge-based question answering is a nature chain-of-thought mentor of LLM",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00426v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00426v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6677"
  },
  {
    "objectID": "posts/An_Analysis_of_Embedding_Layers_and_Similarity_Scores_using_Siamese_Neural_Networks/2023-12-31-An_Analysis_of_Embedding_Layers_and_Similarity_Scores_using_Siamese_Neural_Networks.html#appendix",
    "href": "posts/An_Analysis_of_Embedding_Layers_and_Similarity_Scores_using_Siamese_Neural_Networks/2023-12-31-An_Analysis_of_Embedding_Layers_and_Similarity_Scores_using_Siamese_Neural_Networks.html#appendix",
    "title": "An Analysis of Embedding Layers and Similarity Scores using Siamese Neural Networks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00582v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00582v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1974"
  },
  {
    "objectID": "posts/Timeliness_A_New_Design_Metric_and_a_New_Attack_Surface/2023-12-28-Timeliness_A_New_Design_Metric_and_a_New_Attack_Surface.html#appendix",
    "href": "posts/Timeliness_A_New_Design_Metric_and_a_New_Attack_Surface/2023-12-28-Timeliness_A_New_Design_Metric_and_a_New_Attack_Surface.html#appendix",
    "title": "Timeliness: A New Design Metric and a New Attack Surface",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17220v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17220v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8673"
  },
  {
    "objectID": "posts/FENet_Focusing_Enhanced_Network_for_Lane_Detection/2023-12-28-FENet_Focusing_Enhanced_Network_for_Lane_Detection.html#appendix",
    "href": "posts/FENet_Focusing_Enhanced_Network_for_Lane_Detection/2023-12-28-FENet_Focusing_Enhanced_Network_for_Lane_Detection.html#appendix",
    "title": "FENet: Focusing Enhanced Network for Lane Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17163v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17163v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6575"
  },
  {
    "objectID": "posts/Evaluating_Augmented_Reality_Communication_How_Can_We_Teach_Procedural_Skill_in_AR/2023-12-14-Evaluating_Augmented_Reality_Communication_How_Can_We_Teach_Procedural_Skill_in_AR.html#appendix",
    "href": "posts/Evaluating_Augmented_Reality_Communication_How_Can_We_Teach_Procedural_Skill_in_AR/2023-12-14-Evaluating_Augmented_Reality_Communication_How_Can_We_Teach_Procedural_Skill_in_AR.html#appendix",
    "title": "Evaluating Augmented Reality Communication: How Can We Teach Procedural Skill in AR?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.09152v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.09152v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11943"
  },
  {
    "objectID": "posts/MERA_A_Comprehensive_LLM_Evaluation_in_Russian/2024-01-09-MERA_A_Comprehensive_LLM_Evaluation_in_Russian.html#major-takeaways",
    "href": "posts/MERA_A_Comprehensive_LLM_Evaluation_in_Russian/2024-01-09-MERA_A_Comprehensive_LLM_Evaluation_in_Russian.html#major-takeaways",
    "title": "MERA: A Comprehensive LLM Evaluation in Russian",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nMERA is a widely used assessment tool for evaluating language proficiency in Russian as a foreign language.\nThe evaluation encompasses four key language skills: listening, reading, writing, and speaking, providing a comprehensive analysis of a learner’s language abilities.\nThe MERA evaluation aims to standardize the assessment process and provide reliable results for individuals and institutions seeking to gauge Russian language proficiency."
  },
  {
    "objectID": "posts/MERA_A_Comprehensive_LLM_Evaluation_in_Russian/2024-01-09-MERA_A_Comprehensive_LLM_Evaluation_in_Russian.html#introduction",
    "href": "posts/MERA_A_Comprehensive_LLM_Evaluation_in_Russian/2024-01-09-MERA_A_Comprehensive_LLM_Evaluation_in_Russian.html#introduction",
    "title": "MERA: A Comprehensive LLM Evaluation in Russian",
    "section": "Introduction",
    "text": "Introduction\n\nMERA is a widely recognized assessment tool used to evaluate proficiency in the Russian language.\nIt offers a comprehensive evaluation of language skills, including listening, reading, writing, and speaking."
  },
  {
    "objectID": "posts/MERA_A_Comprehensive_LLM_Evaluation_in_Russian/2024-01-09-MERA_A_Comprehensive_LLM_Evaluation_in_Russian.html#key-features-of-mera",
    "href": "posts/MERA_A_Comprehensive_LLM_Evaluation_in_Russian/2024-01-09-MERA_A_Comprehensive_LLM_Evaluation_in_Russian.html#key-features-of-mera",
    "title": "MERA: A Comprehensive LLM Evaluation in Russian",
    "section": "Key Features of MERA",
    "text": "Key Features of MERA\n\nComprehensive Evaluation: MERA assesses proficiency in all four language skills, providing a holistic view of an individual’s language abilities.\nStandardization: The evaluation aims to standardize the assessment process, ensuring consistent and reliable results.\nDifferent Levels: MERA offers evaluations at various levels, accommodating learners at different stages of language proficiency."
  },
  {
    "objectID": "posts/MERA_A_Comprehensive_LLM_Evaluation_in_Russian/2024-01-09-MERA_A_Comprehensive_LLM_Evaluation_in_Russian.html#components-of-the-evaluation",
    "href": "posts/MERA_A_Comprehensive_LLM_Evaluation_in_Russian/2024-01-09-MERA_A_Comprehensive_LLM_Evaluation_in_Russian.html#components-of-the-evaluation",
    "title": "MERA: A Comprehensive LLM Evaluation in Russian",
    "section": "Components of the Evaluation",
    "text": "Components of the Evaluation\n\nListening: This component assesses the ability to comprehend spoken Russian, including understanding conversations and speeches.\nReading: The reading component evaluates comprehension of written Russian texts, including articles and literary works.\nWriting: MERA assesses writing skills, including grammar, vocabulary usage, and overall coherence in written expression.\nSpeaking: The speaking component evaluates oral proficiency, including pronunciation, fluency, and communication skills."
  },
  {
    "objectID": "posts/MERA_A_Comprehensive_LLM_Evaluation_in_Russian/2024-01-09-MERA_A_Comprehensive_LLM_Evaluation_in_Russian.html#critique",
    "href": "posts/MERA_A_Comprehensive_LLM_Evaluation_in_Russian/2024-01-09-MERA_A_Comprehensive_LLM_Evaluation_in_Russian.html#critique",
    "title": "MERA: A Comprehensive LLM Evaluation in Russian",
    "section": "Critique",
    "text": "Critique\nThe paper could benefit from providing more specific details about the development and validation of the MERA evaluation tool. Additionally, it would be helpful to include data on the reliability and validity of the assessment to support its widespread usage. There may also be a need for further research on the effectiveness of MERA in accurately gauging Russian language proficiency in diverse contexts and learner populations."
  },
  {
    "objectID": "posts/MERA_A_Comprehensive_LLM_Evaluation_in_Russian/2024-01-09-MERA_A_Comprehensive_LLM_Evaluation_in_Russian.html#appendix",
    "href": "posts/MERA_A_Comprehensive_LLM_Evaluation_in_Russian/2024-01-09-MERA_A_Comprehensive_LLM_Evaluation_in_Russian.html#appendix",
    "title": "MERA: A Comprehensive LLM Evaluation in Russian",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.04531v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.04531v1\n\n\nTruncated\nFalse\n\n\nWord Count\n19"
  },
  {
    "objectID": "posts/ICE_GRT_Instruction_Context_Enhancement_by_Generative_Reinforcement_based_Transformers/2024-01-04-ICE_GRT_Instruction_Context_Enhancement_by_Generative_Reinforcement_based_Transformers.html#appendix",
    "href": "posts/ICE_GRT_Instruction_Context_Enhancement_by_Generative_Reinforcement_based_Transformers/2024-01-04-ICE_GRT_Instruction_Context_Enhancement_by_Generative_Reinforcement_based_Transformers.html#appendix",
    "title": "ICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.02072v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.02072v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8390"
  },
  {
    "objectID": "posts/Exploring_Prompt_Based_Methods_for_Zero_Shot_Hypernym_Prediction_with_Large_Language_Models/2024-01-09-Exploring_Prompt_Based_Methods_for_Zero_Shot_Hypernym_Prediction_with_Large_Language_Models.html#appendix",
    "href": "posts/Exploring_Prompt_Based_Methods_for_Zero_Shot_Hypernym_Prediction_with_Large_Language_Models/2024-01-09-Exploring_Prompt_Based_Methods_for_Zero_Shot_Hypernym_Prediction_with_Large_Language_Models.html#appendix",
    "title": "Exploring Prompt-Based Methods for Zero-Shot Hypernym Prediction with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.04515v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.04515v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7734"
  },
  {
    "objectID": "posts/Social_Transmotion_Promptable_Human_Trajectory_Prediction/2023-12-26-Social_Transmotion_Promptable_Human_Trajectory_Prediction.html#appendix",
    "href": "posts/Social_Transmotion_Promptable_Human_Trajectory_Prediction/2023-12-26-Social_Transmotion_Promptable_Human_Trajectory_Prediction.html#appendix",
    "title": "Social-Transmotion: Promptable Human Trajectory Prediction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16168v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16168v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10818"
  },
  {
    "objectID": "posts/LLM_Augmented_LLMs_Expanding_Capabilities_through_Composition/2024-01-04-LLM_Augmented_LLMs_Expanding_Capabilities_through_Composition.html",
    "href": "posts/LLM_Augmented_LLMs_Expanding_Capabilities_through_Composition/2024-01-04-LLM_Augmented_LLMs_Expanding_Capabilities_through_Composition.html",
    "title": "LLM Augmented LLMs: Expanding Capabilities through Composition",
    "section": "",
    "text": "Major Takeaways - The paper introduces the concept of Composition to Augment Language Models (CALM) which enables the composition of existing foundational language models with more specific models to enable newer capabilities. - The CALM framework introduces cross-attention between models to compose their representations and enable new capabilities, allowing for the reuse of existing models with established capabilities. - The paper demonstrates the practical applications of CALM in language inclusivity and code generation, showing significant improvements in translation, arithmetic reasoning, and code-related tasks.\nIntroduction - Large Language Models (LLMs) have foundational capabilities and have been fine-tuned for domain-specific capabilities, resulting in the development of several specialized large models with domain-specific capabilities. - The paper aims to enable the composition of an anchor model with a domain-specific augmenting model to enable new capabilities, such as composing an augmenting model’s code understanding capability with an anchor LLM’s language generation capability to enable code-to-text generation capability.\nThe CALM Framework - CALM aims to compose an anchor model and an augmenting model to enable new capabilities as a composition of capabilities of the two individual models. - It operates over a selected set of layers from the anchor and augmenting models and introduces a small number of trainable parameters over these layers. - The composition training data depicts a “combined skill” of the given models for the target composition domain and is used to learn the composition parameters.\nExperiments - The paper demonstrates the effectiveness of CALM in three domains: key-value arithmetic, low-resource language inclusivity, and code completion and explanation tasks. - The experiments show the significant improvements achieved by composing an augmenting model with an anchor LLM, surpassing the individual models and versions that have been fine-tuned for the specific tasks.\nCritique - The paper lacks a discussion on the potential limitations or challenges of the CALM framework, such as its scalability to larger models or its adaptability to diverse languages and domains. - The experimental results could benefit from a more extensive comparison with other relevant methods or frameworks to establish the unique advantages of CALM."
  },
  {
    "objectID": "posts/LLM_Augmented_LLMs_Expanding_Capabilities_through_Composition/2024-01-04-LLM_Augmented_LLMs_Expanding_Capabilities_through_Composition.html#appendix",
    "href": "posts/LLM_Augmented_LLMs_Expanding_Capabilities_through_Composition/2024-01-04-LLM_Augmented_LLMs_Expanding_Capabilities_through_Composition.html#appendix",
    "title": "LLM Augmented LLMs: Expanding Capabilities through Composition",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.02412v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.02412v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5397"
  },
  {
    "objectID": "posts/Grounding_Prompter_Prompting_LLM_with_Multimodal_Information_for_Temporal_Sentence_Grounding_in_Long_Videos/2023-12-28-Grounding_Prompter_Prompting_LLM_with_Multimodal_Information_for_Temporal_Sentence_Grounding_in_Long_Videos.html#appendix",
    "href": "posts/Grounding_Prompter_Prompting_LLM_with_Multimodal_Information_for_Temporal_Sentence_Grounding_in_Long_Videos/2023-12-28-Grounding_Prompter_Prompting_LLM_with_Multimodal_Information_for_Temporal_Sentence_Grounding_in_Long_Videos.html#appendix",
    "title": "Grounding-Prompter: Prompting LLM with Multimodal Information for Temporal Sentence Grounding in Long Videos",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17117v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17117v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8745"
  },
  {
    "objectID": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#major-findings",
    "href": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#major-findings",
    "title": "Code Ownership in Open-Source AI Software Security",
    "section": "Major Findings",
    "text": "Major Findings\n\nStrong Relationship Between Code Ownership and Vulnerabilities: The study found a positive correlation between high-level ownership characterized by a limited number of minor contributors and a decrease in vulnerabilities in open-source AI software projects.\nNovel Code Ownership Metrics: The paper introduces novel code ownership metrics tailored for open-source AI application security, integrating software component frequency/proportion and time/release attributes to provide deeper insights into the link between code ownership and vulnerabilities.\nEffective Time Metrics for Vulnerability Analysis: The time metrics introduced in the study adeptly categorize distinct phases of open-source AI software projects and their respective vulnerability intensities, providing a comprehensive framework for vulnerability management."
  },
  {
    "objectID": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#introduction",
    "href": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#introduction",
    "title": "Code Ownership in Open-Source AI Software Security",
    "section": "Introduction",
    "text": "Introduction\nThe paper discusses the growing significance of open-source AI software projects, highlighting the heightened concern over software vulnerabilities due to the transparent and anonymous nature of contributors. It emphasizes the importance of code ownership as a metric for evaluating developer involvement and identifying latent vulnerabilities in AI software projects."
  },
  {
    "objectID": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#related-work",
    "href": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#related-work",
    "title": "Code Ownership in Open-Source AI Software Security",
    "section": "Related Work",
    "text": "Related Work\nThe related work section discusses existing literature on developer contribution practices, software quality, and security in traditional software projects, drawing comparisons and contrasts in the context of open-source AI software projects."
  },
  {
    "objectID": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#research-questions-and-hypotheses",
    "href": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#research-questions-and-hypotheses",
    "title": "Code Ownership in Open-Source AI Software Security",
    "section": "Research Questions and Hypotheses",
    "text": "Research Questions and Hypotheses\nThe study formulates research questions centered around the development and effectiveness of code ownership metrics and their correlation with software vulnerabilities in open-source AI projects. It also introduces hypotheses related to the vulnerability of software components based on the number of minor contributors, vulnerability occurrence rate, and software component location."
  },
  {
    "objectID": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#terminology-and-metrics",
    "href": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#terminology-and-metrics",
    "title": "Code Ownership in Open-Source AI Software Security",
    "section": "Terminology and Metrics",
    "text": "Terminology and Metrics\nThe paper introduces crucial terminology and metrics essential for understanding the code ownership metrics and their application in vulnerability assessment. It discusses software components, contributors, contributions, ownership proportion, time stage, OSS stage, and classic metrics."
  },
  {
    "objectID": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#data-collection-and-analysis",
    "href": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#data-collection-and-analysis",
    "title": "Code Ownership in Open-Source AI Software Security",
    "section": "Data Collection and Analysis",
    "text": "Data Collection and Analysis\nThe data collection and analysis section details the process of collecting vulnerability data from NVD and GitHub repositories and conducting a comprehensive analysis of the vulnerability dataset using various techniques such as correlation analysis and multiple linear regression."
  },
  {
    "objectID": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#results",
    "href": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#results",
    "title": "Code Ownership in Open-Source AI Software Security",
    "section": "Results",
    "text": "Results\nThe results section presents potential distortion factor checks, correlation analysis, and discussion of the findings. It highlights the correlation between code ownership metrics and vulnerabilities, the effectiveness of time metrics, and the impact of project lifespan and minor contributors on vulnerability susceptibility."
  },
  {
    "objectID": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#threat-to-validity",
    "href": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#threat-to-validity",
    "title": "Code Ownership in Open-Source AI Software Security",
    "section": "Threat to Validity",
    "text": "Threat to Validity\nThe section discusses limitations and potential areas for future research, such as the influence of dependency management, project attribute limitations, data quality, and metric completeness on the validity and generalizability of the study."
  },
  {
    "objectID": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#conclusion",
    "href": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#conclusion",
    "title": "Code Ownership in Open-Source AI Software Security",
    "section": "Conclusion",
    "text": "Conclusion\nThe paper concludes by emphasizing the significance of code ownership in securing open-source AI software projects and its effectiveness in vulnerability management. It also recommends project managers closely monitor projects with distinct ownership patterns and lengthy lifespans and thoroughly examine components with minimal ownership."
  },
  {
    "objectID": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#critique",
    "href": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#critique",
    "title": "Code Ownership in Open-Source AI Software Security",
    "section": "Critique",
    "text": "Critique\nThe paper effectively introduces novel metrics and provides insights into the correlation between code ownership and vulnerabilities in open-source AI software. However, potential limitations include the reliance on a limited number of open-source AI projects for the study and the exclusion of complexity analysis in diverse programming languages, which may affect the accuracy and generalizability of the findings. Moreover, more comprehensive validation and testing in diverse open-source AI projects would enhance the robustness of the proposed metrics and their applicability."
  },
  {
    "objectID": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#appendix",
    "href": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#appendix",
    "title": "Code Ownership in Open-Source AI Software Security",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10861v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10861v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9732"
  },
  {
    "objectID": "posts/Using_LLM_to_select_the_right_SQL_Query_from_candidates/2024-01-04-Using_LLM_to_select_the_right_SQL_Query_from_candidates.html#appendix",
    "href": "posts/Using_LLM_to_select_the_right_SQL_Query_from_candidates/2024-01-04-Using_LLM_to_select_the_right_SQL_Query_from_candidates.html#appendix",
    "title": "Using LLM to select the right SQL Query from candidates",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.02115v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.02115v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7353"
  },
  {
    "objectID": "posts/Fairness_in_Serving_Large_Language_Models/2023-12-31-Fairness_in_Serving_Large_Language_Models.html",
    "href": "posts/Fairness_in_Serving_Large_Language_Models/2023-12-31-Fairness_in_Serving_Large_Language_Models.html",
    "title": "Fairness in Serving Large Language Models",
    "section": "",
    "text": "Here’s the summary:"
  },
  {
    "objectID": "posts/Fairness_in_Serving_Large_Language_Models/2023-12-31-Fairness_in_Serving_Large_Language_Models.html#major-findings",
    "href": "posts/Fairness_in_Serving_Large_Language_Models/2023-12-31-Fairness_in_Serving_Large_Language_Models.html#major-findings",
    "title": "Fairness in Serving Large Language Models",
    "section": "Major Findings",
    "text": "Major Findings\n\nMost major Large Language Model (LLM) inference services use request rate limits to ensure fair processing of client requests, but this often leads to under-utilization of resources and poor client experience when spare capacity is available.\nThe paper introduces the concept of LLM serving fairness based on a cost function that accounts for the number of input and output tokens processed and proposes a novel fair scheduler called Virtual Token Counter (VTC).\nThrough extensive experiments, the paper demonstrates the superior performance of VTC in ensuring fairness compared to other baseline methods under various conditions."
  },
  {
    "objectID": "posts/Fairness_in_Serving_Large_Language_Models/2023-12-31-Fairness_in_Serving_Large_Language_Models.html#methodology",
    "href": "posts/Fairness_in_Serving_Large_Language_Models/2023-12-31-Fairness_in_Serving_Large_Language_Models.html#methodology",
    "title": "Fairness in Serving Large Language Models",
    "section": "Methodology",
    "text": "Methodology\n\nIntroduction\n\nLarge Language Models (LLMs) have been integrated into various application domains, and request response time is a key metric for quality of service.\n\n\n\nChallenges in LLM Serving\n\nLLM serving presents unique challenges due to unpredictable request lengths and variable token-rate capacity.\n\n\n\nDefinition of Fairness in LLM Serving\n\nThe paper discusses the measurement of service for clients in LLM serving and defines fairness based on max-min fairness and work-conservation properties.\n\n\n\nAchieving Fairness with VTC\n\nThe Virtual Token Counter (VTC) algorithm is proposed to achieve fairness in LLM serving, which tracks the services received for each client and prioritizes those with the least services received."
  },
  {
    "objectID": "posts/Fairness_in_Serving_Large_Language_Models/2023-12-31-Fairness_in_Serving_Large_Language_Models.html#results",
    "href": "posts/Fairness_in_Serving_Large_Language_Models/2023-12-31-Fairness_in_Serving_Large_Language_Models.html#results",
    "title": "Fairness in Serving Large Language Models",
    "section": "Results",
    "text": "Results\n\nThrough synthetic and real-world workload experiments, the paper demonstrates that VTC maintains fairness among clients in various scenarios of request frequencies, request lengths, and arrival patterns."
  },
  {
    "objectID": "posts/Fairness_in_Serving_Large_Language_Models/2023-12-31-Fairness_in_Serving_Large_Language_Models.html#critique",
    "href": "posts/Fairness_in_Serving_Large_Language_Models/2023-12-31-Fairness_in_Serving_Large_Language_Models.html#critique",
    "title": "Fairness in Serving Large Language Models",
    "section": "Critique",
    "text": "Critique\nThe paper provides a comprehensive evaluation of the proposed VTC algorithm, demonstrating its superiority over other baseline methods. However, potential limitations or weaknesses of VTC, such as scalability to larger systems or potential edge cases where it may not perform optimally, are not thoroughly discussed. Further exploration is needed to ensure the generalizability of VTC to diverse LLM serving environments."
  },
  {
    "objectID": "posts/Fairness_in_Serving_Large_Language_Models/2023-12-31-Fairness_in_Serving_Large_Language_Models.html#appendix",
    "href": "posts/Fairness_in_Serving_Large_Language_Models/2023-12-31-Fairness_in_Serving_Large_Language_Models.html#appendix",
    "title": "Fairness in Serving Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00588v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00588v1\n\n\nTruncated\nTrue\n\n\nWord Count\n14021"
  },
  {
    "objectID": "posts/A_Comprehensive_Study_of_Knowledge_Editing_for_Large_Language_Models/2024-01-02-A_Comprehensive_Study_of_Knowledge_Editing_for_Large_Language_Models.html#appendix",
    "href": "posts/A_Comprehensive_Study_of_Knowledge_Editing_for_Large_Language_Models/2024-01-02-A_Comprehensive_Study_of_Knowledge_Editing_for_Large_Language_Models.html#appendix",
    "title": "A Comprehensive Study of Knowledge Editing for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01286v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01286v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5472"
  },
  {
    "objectID": "posts/Understanding_LLMs_A_Comprehensive_Overview_from_Training_to_Inference/2024-01-04-Understanding_LLMs_A_Comprehensive_Overview_from_Training_to_Inference.html#appendix",
    "href": "posts/Understanding_LLMs_A_Comprehensive_Overview_from_Training_to_Inference/2024-01-04-Understanding_LLMs_A_Comprehensive_Overview_from_Training_to_Inference.html#appendix",
    "title": "Understanding LLMs: A Comprehensive Overview from Training to Inference",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.02038v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.02038v1\n\n\nTruncated\nTrue\n\n\nWord Count\n21883"
  },
  {
    "objectID": "posts/GeoGalactica_A_Scientific_Large_Language_Model_in_Geoscience/2023-12-31-GeoGalactica_A_Scientific_Large_Language_Model_in_Geoscience.html#appendix",
    "href": "posts/GeoGalactica_A_Scientific_Large_Language_Model_in_Geoscience/2023-12-31-GeoGalactica_A_Scientific_Large_Language_Model_in_Geoscience.html#appendix",
    "title": "GeoGalactica: A Scientific Large Language Model in Geoscience",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00434v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00434v1\n\n\nTruncated\nTrue\n\n\nWord Count\n42068"
  },
  {
    "objectID": "posts/PPBFL_A_Privacy_Protected_Blockchain_based_Federated_Learning_Model/2024-01-02-PPBFL_A_Privacy_Protected_Blockchain_based_Federated_Learning_Model.html#appendix",
    "href": "posts/PPBFL_A_Privacy_Protected_Blockchain_based_Federated_Learning_Model/2024-01-02-PPBFL_A_Privacy_Protected_Blockchain_based_Federated_Learning_Model.html#appendix",
    "title": "PPBFL: A Privacy Protected Blockchain-based Federated Learning Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01204v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01204v1\n\n\nTruncated\nTrue\n\n\nWord Count\n14727"
  },
  {
    "objectID": "posts/SMoT_Think_in_State_Machine/2023-12-29-SMoT_Think_in_State_Machine.html#appendix",
    "href": "posts/SMoT_Think_in_State_Machine/2023-12-29-SMoT_Think_in_State_Machine.html#appendix",
    "title": "SMoT: Think in State Machine",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17445v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17445v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11018"
  },
  {
    "objectID": "posts/BatchEval_Towards_Human_like_Text_Evaluation/2023-12-31-BatchEval_Towards_Human_like_Text_Evaluation.html#appendix",
    "href": "posts/BatchEval_Towards_Human_like_Text_Evaluation/2023-12-31-BatchEval_Towards_Human_like_Text_Evaluation.html#appendix",
    "title": "BatchEval: Towards Human-like Text Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00437v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00437v1\n\n\nTruncated\nTrue\n\n\nWord Count\n15893"
  },
  {
    "objectID": "posts/prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#overview",
    "href": "posts/prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#overview",
    "title": "prompt-engineering-assisted Malware Dynamic Analysis Using GPT-4",
    "section": "Overview",
    "text": "Overview\n\nMajor Takeaways\n\nAPI Sequence as Dynamic Malware Behavior: The API sequence, composed of consecutive API calls, is a significant representation of dynamic malware behavior in dynamic analysis methods.\nIntroduction of Prompt Engineering & GPT-4: This paper introduces a method for generating representations for API calls using GPT-4 and prompt engineering, achieving excellent detection performance in dynamic malware analysis.\nSuperior Generalization Performance: The proposed model demonstrates superior generalization performance, effectively addressing issues such as weak generalization and concept drift in dynamic malware analysis."
  },
  {
    "objectID": "posts/prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#experiment-analysis",
    "href": "posts/prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#experiment-analysis",
    "title": "prompt-engineering-assisted Malware Dynamic Analysis Using GPT-4",
    "section": "Experiment Analysis",
    "text": "Experiment Analysis\n\nComparison of Representation Quality\n\nThe proposed model outperforms existing models in generating denser representations and capturing associations between API calls effectively, as demonstrated in case studies.\nFew-shot learning experiments show that the proposed model achieves superior fine-tuning and adaptation in comparison to TextCNN and BiLSTM.\n\n\n\nAnalysis of Concept Drift Alleviation\n\nThe proposed model effectively addresses the concept drift phenomenon, demonstrating excellent recall rates for malware even in the presence of new or previously unseen API calls."
  },
  {
    "objectID": "posts/prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#critique",
    "href": "posts/prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#critique",
    "title": "prompt-engineering-assisted Malware Dynamic Analysis Using GPT-4",
    "section": "Critique",
    "text": "Critique\n\nThe paper could benefit from more detailed information on the limitations or potential biases of the proposed method.\nFurther clarification on the real-world applicability and scalability of the proposed model would enhance the paper’s significance.\n\nOverall, the paper provides a promising approach to dynamic malware analysis, but further studies and real-world implementations are required to validate its full potential."
  },
  {
    "objectID": "posts/prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#appendix",
    "href": "posts/prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#appendix",
    "title": "prompt-engineering-assisted Malware Dynamic Analysis Using GPT-4",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.08317v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.08317v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13381"
  },
  {
    "objectID": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#major-takeaways",
    "href": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#major-takeaways",
    "title": "Large Language Models Relearn Removed Concepts",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nNeuroplasticity: Large language models (LLMs) demonstrate the ability to quickly regain performance and redistribute pruned concepts after retraining.\nConcept Redistribution: Pruned concepts originally present in later layers are remapped to neurons in earlier layers, demonstrating the resilience of LLMs.\nPolysemantic Capacities: Neurons show polysemantic properties, capturing a blend of old and new concepts during relearning."
  },
  {
    "objectID": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#abstract",
    "href": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#abstract",
    "title": "Large Language Models Relearn Removed Concepts",
    "section": "Abstract",
    "text": "Abstract\nThe study investigates neuroplasticity in large language models (LLMs) by exploring their capacity to reacquire pruned concepts after editing. The findings suggest that models can quickly regain performance post-pruning by relocating advanced concepts to earlier layers and reallocating pruned concepts to primed neurons with similar semantics. The paper highlights the challenges of permanent concept removal for improved model safety and the importance of monitoring concept reemergence and developing techniques to mitigate relearning of unsafe concepts."
  },
  {
    "objectID": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#introduction",
    "href": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#introduction",
    "title": "Large Language Models Relearn Removed Concepts",
    "section": "Introduction",
    "text": "Introduction\nLarge language models encode semantic concepts across different languages, architectures, and modalities. The primary objective when pruning such models is to eliminate redundant neurons while preserving the most crucial ones, leading to the assumption that removing important “concept neurons” will disrupt the model’s structured internal representation of key concepts. However, the paper presents evidence of neuroplasticity in models, allowing them to regain high performance after pruning random or important neurons. This phenomenon, termed “neuroplasticity,” demonstrates a degree of adaptability in such models and has significant implications for model editing."
  },
  {
    "objectID": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#related-work",
    "href": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#related-work",
    "title": "Large Language Models Relearn Removed Concepts",
    "section": "Related Work",
    "text": "Related Work\nThe paper builds on previous works that have analyzed the distribution of concept representations in LLMs and studied performance recovery after pruning. It is noted that prior works artificially redistributed concepts in large language models by modifying the activations of specific neurons, but there is limited understanding of how concept redistribution naturally occurs after pruning. The study also compares its approach with similar works in the field."
  },
  {
    "objectID": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#problem-setting",
    "href": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#problem-setting",
    "title": "Large Language Models Relearn Removed Concepts",
    "section": "Problem Setting",
    "text": "Problem Setting\nThe paper provides a formal definition of concept neurons, concept saliency, and concept similarity, and outlines the process for identifying and pruning top concept neurons in a language model to induce neuroplasticity."
  },
  {
    "objectID": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#method",
    "href": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#method",
    "title": "Large Language Models Relearn Removed Concepts",
    "section": "Method",
    "text": "Method\nThe researchers explore neuroplasticity within a pretrained model by fine-tuning the model for a specific task, identifying and pruning concept neurons, and tracking the redistribution of concepts over the retraining process. They explore the concept saliency and similarity to analyze the redistribution of concepts in the model after neuroplasticity."
  },
  {
    "objectID": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#experimental-setup",
    "href": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#experimental-setup",
    "title": "Large Language Models Relearn Removed Concepts",
    "section": "Experimental Setup",
    "text": "Experimental Setup\nThe study focuses on pruning the specific concept of location names from different LLMs and analyzes the models across different runs. The model architectures, training, and evaluations are clearly described."
  },
  {
    "objectID": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#results",
    "href": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#results",
    "title": "Large Language Models Relearn Removed Concepts",
    "section": "Results",
    "text": "Results\nThe paper presents a detailed analysis of the rapid performance recovery after retraining, high-level concept redistribution, and the relocation of pruned concepts. It also delves into the polysemantic characteristics of neurons after retraining."
  },
  {
    "objectID": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#conclusion",
    "href": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#conclusion",
    "title": "Large Language Models Relearn Removed Concepts",
    "section": "Conclusion",
    "text": "Conclusion\nThe findings contribute to a deeper understanding of how language models learn, adapt, and retain core conceptual representations. It also suggests potential research directions in model editing and transfer learning. The paper concludes by emphasizing the need for studying the implications of neuroplasticity-induced polysemanticity to aid the development of interpretable models and the enhanced transfer of learned representations."
  },
  {
    "objectID": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#critique",
    "href": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#critique",
    "title": "Large Language Models Relearn Removed Concepts",
    "section": "Critique",
    "text": "Critique\nThe paper provides valuable insights into neuroplasticity and concept reshaping in LLMs. However, the precise relationship between concept similarity and saliency and the generalizability of the findings to other LLMs require further investigation. Additionally, the paper acknowledges the potential wider impacts of its findings and emphasizes the importance of ethical and responsible AI research."
  },
  {
    "objectID": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#appendix",
    "href": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#appendix",
    "title": "Large Language Models Relearn Removed Concepts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01814v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01814v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12729"
  },
  {
    "objectID": "posts/Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study/2023-12-30-Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study.html#main-findings",
    "href": "posts/Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study/2023-12-30-Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study.html#main-findings",
    "title": "Boosting Large Language Model for Speech Synthesis: An Empirical Study",
    "section": "Main Findings",
    "text": "Main Findings\n\nDirectly fine-tuning Large Language Models (LLMs) with LoRA does not outperform the baseline and requires substantial computational resources.\nSuperposed LLMs and VALL-E can enhance speech quality, demonstrating that LLMs can encode both acoustic and textual tokens.\nCoupled LLMs and VALL-E achieves the best performance, significantly outperforming the baseline in word error rate, speaker similarity, and speech naturalness."
  },
  {
    "objectID": "posts/Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study/2023-12-30-Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study.html#introduction",
    "href": "posts/Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study/2023-12-30-Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study.html#introduction",
    "title": "Boosting Large Language Model for Speech Synthesis: An Empirical Study",
    "section": "Introduction",
    "text": "Introduction\n\nLLMs have revolutionized natural language processing and are extending to other modalities such as speech and vision.\nMost prior work focuses on aligning speech representation with LLM input space."
  },
  {
    "objectID": "posts/Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study/2023-12-30-Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study.html#methodology",
    "href": "posts/Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study/2023-12-30-Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study.html#methodology",
    "title": "Boosting Large Language Model for Speech Synthesis: An Empirical Study",
    "section": "Methodology",
    "text": "Methodology\n\nModel Components\n\nComponents include LLM, speech compression model (Encodec), and codec language model (VALL-E). ### Integration Strategies\n\n\nDirectly Fine-tuned LLMs\nSuperposed LLMs and VALL-E\nCoupled LLMs and VALL-E"
  },
  {
    "objectID": "posts/Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study/2023-12-30-Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study.html#related-work",
    "href": "posts/Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study/2023-12-30-Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study.html#related-work",
    "title": "Boosting Large Language Model for Speech Synthesis: An Empirical Study",
    "section": "Related Work",
    "text": "Related Work\n\nExplores the application of LLMs to speech and compares to prior work on multi-modal LLMs and large audio generative models."
  },
  {
    "objectID": "posts/Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study/2023-12-30-Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study.html#experiments",
    "href": "posts/Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study/2023-12-30-Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study.html#experiments",
    "title": "Boosting Large Language Model for Speech Synthesis: An Empirical Study",
    "section": "Experiments",
    "text": "Experiments\n\nConducted on ASR datasets and evaluated on LibriSpeech dev-clean, dev-other, test-clean, test-other datasets.\nRevealed the impact of model size, continual pre-training, pre-trained VALL-E, and compared LoRA vs. full fine-tuning in VALL-E."
  },
  {
    "objectID": "posts/Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study/2023-12-30-Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study.html#analysis",
    "href": "posts/Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study/2023-12-30-Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study.html#analysis",
    "title": "Boosting Large Language Model for Speech Synthesis: An Empirical Study",
    "section": "Analysis",
    "text": "Analysis\n\nDetailed analyses include the effect of model size, continual pre-training, pre-trained VALL-E, and comparison of LoRA vs. full fine-tuning in VALL-E."
  },
  {
    "objectID": "posts/Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study/2023-12-30-Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study.html#conclusion",
    "href": "posts/Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study/2023-12-30-Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study.html#conclusion",
    "title": "Boosting Large Language Model for Speech Synthesis: An Empirical Study",
    "section": "Conclusion",
    "text": "Conclusion\n\nDirectly fine-tuning LLMs with LoRA does not match the performance of the baseline, while superposed LLMs and coupled LLMs with VALL-E outperform the baseline."
  },
  {
    "objectID": "posts/Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study/2023-12-30-Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study.html#critique",
    "href": "posts/Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study/2023-12-30-Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study.html#critique",
    "title": "Boosting Large Language Model for Speech Synthesis: An Empirical Study",
    "section": "Critique",
    "text": "Critique\n\nThe paper could benefit from a more extensive analysis of the computational resources required for different methods and further exploration of the limitations of each integration strategy."
  },
  {
    "objectID": "posts/Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study/2023-12-30-Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study.html#appendix",
    "href": "posts/Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study/2023-12-30-Boosting_Large_Language_Model_for_Speech_Synthesis_An_Empirical_Study.html#appendix",
    "title": "Boosting Large Language Model for Speech Synthesis: An Empirical Study",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00246v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00246v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7680"
  },
  {
    "objectID": "posts/On_Inapproximability_of_Reconfiguration_Problems_PSPACE_Hardness_and_some_Tight_NP_Hardness_Results/2023-12-28-On_Inapproximability_of_Reconfiguration_Problems_PSPACE_Hardness_and_some_Tight_NP_Hardness_Results.html#summary",
    "href": "posts/On_Inapproximability_of_Reconfiguration_Problems_PSPACE_Hardness_and_some_Tight_NP_Hardness_Results/2023-12-28-On_Inapproximability_of_Reconfiguration_Problems_PSPACE_Hardness_and_some_Tight_NP_Hardness_Results.html#summary",
    "title": "On Inapproximability of Reconfiguration Problems: PSPACE-Hardness and some Tight NP-Hardness Results",
    "section": "Summary:",
    "text": "Summary:\nThis paper presents the resolution of the Reconfiguration Inapproximability Hypothesis (RIH) and provides tight results on the NP-hardness of approximation for GapMaxMin-2-CSP and Set Cover Reconfiguration. The authors prove RIH and establish the PSPACE-hardness of approximation results for various reconfiguration problems. They also offer tight NP-hardness results for GapMaxMin-2-CSP and Set Cover Reconfiguration, demonstrating the difficulty of approximating these problems to within certain factors."
  },
  {
    "objectID": "posts/On_Inapproximability_of_Reconfiguration_Problems_PSPACE_Hardness_and_some_Tight_NP_Hardness_Results/2023-12-28-On_Inapproximability_of_Reconfiguration_Problems_PSPACE_Hardness_and_some_Tight_NP_Hardness_Results.html#major-findings",
    "href": "posts/On_Inapproximability_of_Reconfiguration_Problems_PSPACE_Hardness_and_some_Tight_NP_Hardness_Results/2023-12-28-On_Inapproximability_of_Reconfiguration_Problems_PSPACE_Hardness_and_some_Tight_NP_Hardness_Results.html#major-findings",
    "title": "On Inapproximability of Reconfiguration Problems: PSPACE-Hardness and some Tight NP-Hardness Results",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe authors resolve the Reconfiguration Inapproximability Hypothesis (RIH), demonstrating the PSPACE-hardness of approximation results for various reconfiguration problems.\nTight NP-hardness results for GapMaxMin-2-CSP and Set Cover Reconfiguration are provided, illustrating the challenges in approximating these problems to within particular factors.\nAn approximate algorithm for GapMaxMin-2-CSP is presented, improving upon previous approximation algorithms and showcasing the feasibility of approximating this problem within certain bounds."
  },
  {
    "objectID": "posts/On_Inapproximability_of_Reconfiguration_Problems_PSPACE_Hardness_and_some_Tight_NP_Hardness_Results/2023-12-28-On_Inapproximability_of_Reconfiguration_Problems_PSPACE_Hardness_and_some_Tight_NP_Hardness_Results.html#critique",
    "href": "posts/On_Inapproximability_of_Reconfiguration_Problems_PSPACE_Hardness_and_some_Tight_NP_Hardness_Results/2023-12-28-On_Inapproximability_of_Reconfiguration_Problems_PSPACE_Hardness_and_some_Tight_NP_Hardness_Results.html#critique",
    "title": "On Inapproximability of Reconfiguration Problems: PSPACE-Hardness and some Tight NP-Hardness Results",
    "section": "Critique:",
    "text": "Critique:\nThe paper effectively addresses the inapproximability of reconfiguration problems and provides valuable insights into the complexity of solving these problems. However, the dependency of the alphabet size on the growth of certain factors in the NP-hardness results raises questions about the optimality and scalability of the proposed solutions. Additionally, further investigation into the best achievable approximations and a thorough exploration of the limitations of the presented algorithms could strengthen the paper’s conclusions."
  },
  {
    "objectID": "posts/On_Inapproximability_of_Reconfiguration_Problems_PSPACE_Hardness_and_some_Tight_NP_Hardness_Results/2023-12-28-On_Inapproximability_of_Reconfiguration_Problems_PSPACE_Hardness_and_some_Tight_NP_Hardness_Results.html#appendix",
    "href": "posts/On_Inapproximability_of_Reconfiguration_Problems_PSPACE_Hardness_and_some_Tight_NP_Hardness_Results/2023-12-28-On_Inapproximability_of_Reconfiguration_Problems_PSPACE_Hardness_and_some_Tight_NP_Hardness_Results.html#appendix",
    "title": "On Inapproximability of Reconfiguration Problems: PSPACE-Hardness and some Tight NP-Hardness Results",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17140v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17140v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11669"
  },
  {
    "objectID": "posts/E_chat_Emotion_sensitive_Spoken_Dialogue_System_with_Large_Language_Models/2023-12-31-E_chat_Emotion_sensitive_Spoken_Dialogue_System_with_Large_Language_Models.html#appendix",
    "href": "posts/E_chat_Emotion_sensitive_Spoken_Dialogue_System_with_Large_Language_Models/2023-12-31-E_chat_Emotion_sensitive_Spoken_Dialogue_System_with_Large_Language_Models.html#appendix",
    "title": "E-chat: Emotion-sensitive Spoken Dialogue System with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00475v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00475v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4854"
  },
  {
    "objectID": "posts/Quick_Order_Fairness_Implementation_and_Evaluation/2023-12-20-Quick_Order_Fairness_Implementation_and_Evaluation.html#appendix",
    "href": "posts/Quick_Order_Fairness_Implementation_and_Evaluation/2023-12-20-Quick_Order_Fairness_Implementation_and_Evaluation.html#appendix",
    "title": "Quick Order Fairness: Implementation and Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.13107v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.13107v1\n\n\nTruncated\nTrue\n\n\nWord Count\n13817"
  },
  {
    "objectID": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#key-findings",
    "href": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#key-findings",
    "title": "Geometric Awareness in Neural Fields for 3D Human Registration",
    "section": "Key Findings",
    "text": "Key Findings\n\nTask Significance: The paper addresses the crucial task of aligning a template to 3D human point clouds, important for animation, reconstruction, and supervised learning pipelines.\nProposed Solutions: The paper proposed two solutions, LoVD and INT, to address the lack of geometric awareness in neural fields. LoVD is a novel approach with localized MLPs to predict offsets, while INT is a self-supervised task to enhance the backbone network’s geometric awareness.\nPerformance: The integrated INLoVD pipeline, trained on a large MoCap dataset, achieves state-of-the-art results, is efficient, and demonstrates robustness and generalization on diverse out-of-distribution data sources."
  },
  {
    "objectID": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#introduction",
    "href": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#introduction",
    "title": "Geometric Awareness in Neural Fields for 3D Human Registration",
    "section": "Introduction",
    "text": "Introduction\n\n3D surface registration, particularly for human models, is crucial for various applications in computer vision, but poses significant challenges due to articulations, fine-grained details, and noisy acquisition processes."
  },
  {
    "objectID": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#proposed-solutions",
    "href": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#proposed-solutions",
    "title": "Geometric Awareness in Neural Fields for 3D Human Registration",
    "section": "Proposed Solutions",
    "text": "Proposed Solutions\n\nLoVD: A novel localized neural field model that predicts offsets for localized parts of the shape using spectral segmentation of the template.\nINT: A self-supervised task that enhances geometric awareness at inference time by refining the neural field’s predictions based on the target’s vertices."
  },
  {
    "objectID": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#inlovd-registration-pipeline",
    "href": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#inlovd-registration-pipeline",
    "title": "Geometric Awareness in Neural Fields for 3D Human Registration",
    "section": "INLoVD Registration Pipeline",
    "text": "INLoVD Registration Pipeline\n\nThe INLoVD pipeline integrates LoVD and INT to provide efficient and robust human registration, achieving state-of-the-art performance on public benchmarks and real-world challenges out of the training distribution."
  },
  {
    "objectID": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#related-works",
    "href": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#related-works",
    "title": "Geometric Awareness in Neural Fields for 3D Human Registration",
    "section": "Related Works",
    "text": "Related Works\n\nThe paper provides an extensive survey of related works in shape correspondence, shape matching, shape registration, and 3D human registration, highlighting the novelty and significance of the proposed solutions."
  },
  {
    "objectID": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#results",
    "href": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#results",
    "title": "Geometric Awareness in Neural Fields for 3D Human Registration",
    "section": "Results",
    "text": "Results\n\nThe paper reports comprehensive results validating the performance and generalization of the proposed INLoVD pipeline across diverse datasets, demonstrating its efficacy in handling challenging poses, partial point clouds, clutter, and diverse identities."
  },
  {
    "objectID": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#further-validations-and-ablations",
    "href": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#further-validations-and-ablations",
    "title": "Geometric Awareness in Neural Fields for 3D Human Registration",
    "section": "Further Validations and Ablations",
    "text": "Further Validations and Ablations\n\nThe paper provides detailed technical specifications, ablation studies, and further validation results to demonstrate the robustness and generalization of the proposed methods."
  },
  {
    "objectID": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#critique-and-further-directions",
    "href": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#critique-and-further-directions",
    "title": "Geometric Awareness in Neural Fields for 3D Human Registration",
    "section": "Critique and Further Directions",
    "text": "Critique and Further Directions\n\nWhile the paper presents compelling results, potential limitations include addressing failure cases related to the presence of clutter, unusual poses, and incomplete information in partial point clouds. Additionally, strategies to address the generalization and robustness of the proposed methods could be further highlighted.\n\nOverall, the paper makes significant contributions to the field of 3D human registration and demonstrates the efficacy of the proposed INLoVD pipeline in addressing real-world challenges. Further investigation into the failure cases and potential refinement of the proposed solutions could enhance the practical applicability of the methods."
  },
  {
    "objectID": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#appendix",
    "href": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#appendix",
    "title": "Geometric Awareness in Neural Fields for 3D Human Registration",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.14024v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.14024v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13169"
  },
  {
    "objectID": "posts/Rewriting_the_Code_A_Simple_Method_for_Large_Language_Model_Augmented_Code_Search/2024-01-09-Rewriting_the_Code_A_Simple_Method_for_Large_Language_Model_Augmented_Code_Search.html#summary-of-rewriting-the-code-a-simple-method-for-large-language-model-augmented-code-search",
    "href": "posts/Rewriting_the_Code_A_Simple_Method_for_Large_Language_Model_Augmented_Code_Search/2024-01-09-Rewriting_the_Code_A_Simple_Method_for_Large_Language_Model_Augmented_Code_Search.html#summary-of-rewriting-the-code-a-simple-method-for-large-language-model-augmented-code-search",
    "title": "Rewriting the Code: A Simple Method for Large Language Model Augmented Code Search",
    "section": "Summary of “Rewriting the Code: A Simple Method for Large Language Model Augmented Code Search”",
    "text": "Summary of “Rewriting the Code: A Simple Method for Large Language Model Augmented Code Search”\n\nMajor Takeaways\n\nCode search is a common software development activity aimed at retrieving relevant code snippets from a codebase based on natural language queries. The discrepancy in grammatical rules between natural language and code constraints search retrieval performance.\nThe Generation-Augmented Retrieval (GAR) framework showed limited improvement due to the significant stylistic difference between exemplar code and true code.\nThe proposed Rewrites the Code (ReCo) method significantly improved retrieval accuracy for both sparse and dense retrieval systems across diverse search scenarios, demonstrating the effectiveness of style normalization in code search.\n\n\n\nIntroduction\n\nTraditional code search methods suffer from vocabulary mismatch problems due to the grammatical discrepancy between programming languages and natural languages. Dense retrieval systems offer potential semantic connections but struggle with rare terminological associations.\nThe paper proposes the Generation-Augmented Retrieval (GAR) framework, where Large Language Models (LLMs) generate exemplar code snippets to augment natural language queries for code search. However, LLM-augmented GAR showed limited performance improvement due to stylistic deviations between generated and true code snippets.\n\n\n\nMethodology\n\nReCo: The paper introduces a method that not only generates exemplar codes based on the query but also rewrites the codes in the codebase. This process involves summarizing the code into a natural language description and then using this description to generate a rewritten code that aligns with the exemplar code’s style. Experimental results demonstrated significant retrieval accuracy improvements with ReCo across various search scenarios.\n\n\n\nCode Style Similarity\n\nThe paper proposes a novel evaluation metric, Code Style Similarity (CSSim), to quantify the disparity in code style. This metric evaluates style from three dimensions: variable naming, API invocation, and code structure, based on edit distance. Empirical findings revealed superior explanatory power of CSSim in measuring the style deviation of code compared to existing metrics.\n\n\n\nExperimental Setups\n\nThe paper evaluated ReCo across various search scenarios and programming languages, demonstrating its effectiveness in boosting retrieval performance. Comparison among evaluation metrics, impact of LLMs, and the number of generated codes were investigated to validate the superiority of CSSim and the effectiveness of ReCo.\n\n\n\nDiscussion\n\nThe paper highlights the potential impact of ReCo on various code-related tasks and proposes future work to develop specific models for code style normalization. The authors intend to train models to improve the efficiency of ReCo in practical applications.\n\n\n\nCritique\nThe paper’s approach in introducing ReCo and CSSim is innovative and addresses a significant limitation in code search with LLM-augmented methods. However, the experimental results are limited to simulated settings, and the real-world impact of ReCo in production systems needs to be further explored. Additionally, the paper could benefit from a deeper discussion on potential drawbacks or limitations of the ReCo method, as well as considerations for efficiency and scalability in real-time search systems."
  },
  {
    "objectID": "posts/Rewriting_the_Code_A_Simple_Method_for_Large_Language_Model_Augmented_Code_Search/2024-01-09-Rewriting_the_Code_A_Simple_Method_for_Large_Language_Model_Augmented_Code_Search.html#appendix",
    "href": "posts/Rewriting_the_Code_A_Simple_Method_for_Large_Language_Model_Augmented_Code_Search/2024-01-09-Rewriting_the_Code_A_Simple_Method_for_Large_Language_Model_Augmented_Code_Search.html#appendix",
    "title": "Rewriting the Code: A Simple Method for Large Language Model Augmented Code Search",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.04514v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.04514v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8696"
  },
  {
    "objectID": "posts/How_Far_Are_We_from_Believable_AI_Agents_A_Framework_for_Evaluating_the_Believability_of_Human_Behavior_Simulation/2023-12-28-How_Far_Are_We_from_Believable_AI_Agents_A_Framework_for_Evaluating_the_Believability_of_Human_Behavior_Simulation.html#appendix",
    "href": "posts/How_Far_Are_We_from_Believable_AI_Agents_A_Framework_for_Evaluating_the_Believability_of_Human_Behavior_Simulation/2023-12-28-How_Far_Are_We_from_Believable_AI_Agents_A_Framework_for_Evaluating_the_Believability_of_Human_Behavior_Simulation.html#appendix",
    "title": "How Far Are We from Believable AI Agents? A Framework for Evaluating the Believability of Human Behavior Simulation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17115v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17115v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8635"
  },
  {
    "objectID": "posts/SSP_A_Simple_and_Safe_automatic_Prompt_engineering_method_towards_realistic_image_synthesis_on_LVM/2024-01-02-SSP_A_Simple_and_Safe_automatic_Prompt_engineering_method_towards_realistic_image_synthesis_on_LVM.html#appendix",
    "href": "posts/SSP_A_Simple_and_Safe_automatic_Prompt_engineering_method_towards_realistic_image_synthesis_on_LVM/2024-01-02-SSP_A_Simple_and_Safe_automatic_Prompt_engineering_method_towards_realistic_image_synthesis_on_LVM.html#appendix",
    "title": "SSP: A Simple and Safe automatic Prompt engineering method towards realistic image synthesis on LVM",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01128v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01128v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6840"
  },
  {
    "objectID": "posts/Know_Your_Needs_Better_Towards_Structured_Understanding_of_Marketer_Demands_with_Analogical_Reasoning_Augmented_LLMs/2024-01-09-Know_Your_Needs_Better_Towards_Structured_Understanding_of_Marketer_Demands_with_Analogical_Reasoning_Augmented_LLMs.html#appendix",
    "href": "posts/Know_Your_Needs_Better_Towards_Structured_Understanding_of_Marketer_Demands_with_Analogical_Reasoning_Augmented_LLMs/2024-01-09-Know_Your_Needs_Better_Towards_Structured_Understanding_of_Marketer_Demands_with_Analogical_Reasoning_Augmented_LLMs.html#appendix",
    "title": "Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.04319v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.04319v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9552"
  },
  {
    "objectID": "posts/AutoTask_Executing_Arbitrary_Voice_Commands_by_Exploring_and_Learning_from_Mobile_GUI/2023-12-26-AutoTask_Executing_Arbitrary_Voice_Commands_by_Exploring_and_Learning_from_Mobile_GUI.html#appendix",
    "href": "posts/AutoTask_Executing_Arbitrary_Voice_Commands_by_Exploring_and_Learning_from_Mobile_GUI/2023-12-26-AutoTask_Executing_Arbitrary_Voice_Commands_by_Exploring_and_Learning_from_Mobile_GUI.html#appendix",
    "title": "AutoTask: Executing Arbitrary Voice Commands by Exploring and Learning from Mobile GUI",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16062v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16062v1\n\n\nTruncated\nTrue\n\n\nWord Count\n15489"
  },
  {
    "objectID": "posts/ChatEd_A_Chatbot_Leveraging_ChatGPT_for_an_Enhanced_Learning_Experience_in_Higher_Education/2023-12-29-ChatEd_A_Chatbot_Leveraging_ChatGPT_for_an_Enhanced_Learning_Experience_in_Higher_Education.html#appendix",
    "href": "posts/ChatEd_A_Chatbot_Leveraging_ChatGPT_for_an_Enhanced_Learning_Experience_in_Higher_Education/2023-12-29-ChatEd_A_Chatbot_Leveraging_ChatGPT_for_an_Enhanced_Learning_Experience_in_Higher_Education.html#appendix",
    "title": "ChatEd: A Chatbot Leveraging ChatGPT for an Enhanced Learning Experience in Higher Education",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00052v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00052v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5566"
  },
  {
    "objectID": "posts/Achieving_Fairness_in_DareFightingICE_Agents_Evaluation_Through_a_Delay_Mechanism/2023-12-26-Achieving_Fairness_in_DareFightingICE_Agents_Evaluation_Through_a_Delay_Mechanism.html#appendix",
    "href": "posts/Achieving_Fairness_in_DareFightingICE_Agents_Evaluation_Through_a_Delay_Mechanism/2023-12-26-Achieving_Fairness_in_DareFightingICE_Agents_Evaluation_Through_a_Delay_Mechanism.html#appendix",
    "title": "Achieving Fairness in DareFightingICE Agents Evaluation Through a Delay Mechanism",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16010v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16010v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4286"
  },
  {
    "objectID": "posts/Logic_Scaffolding_Personalized_Aspect_Instructed_Recommendation_Explanation_Generation_using_LLMs/2023-12-22-Logic_Scaffolding_Personalized_Aspect_Instructed_Recommendation_Explanation_Generation_using_LLMs.html#appendix",
    "href": "posts/Logic_Scaffolding_Personalized_Aspect_Instructed_Recommendation_Explanation_Generation_using_LLMs/2023-12-22-Logic_Scaffolding_Personalized_Aspect_Instructed_Recommendation_Explanation_Generation_using_LLMs.html#appendix",
    "title": "Logic-Scaffolding: Personalized Aspect-Instructed Recommendation Explanation Generation using LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.14345v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.14345v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3123"
  },
  {
    "objectID": "posts/An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection/2024-01-07-An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection.html",
    "href": "posts/An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection/2024-01-07-An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection.html",
    "title": "An Investigation of Large Language Models for Real-World Hate Speech Detection",
    "section": "",
    "text": "Key Takeaways"
  },
  {
    "objectID": "posts/An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection/2024-01-07-An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection.html#hate-speech-detection",
    "href": "posts/An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection/2024-01-07-An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection.html#hate-speech-detection",
    "title": "An Investigation of Large Language Models for Real-World Hate Speech Detection",
    "section": "Hate Speech Detection",
    "text": "Hate Speech Detection\n\nHate speech online has become a critical threat, with current AI/ML detectors primarily relying on supervised learning techniques and facing limitations in capturing the contextual diversity of hate speech."
  },
  {
    "objectID": "posts/An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection/2024-01-07-An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection.html#llms-and-prompts-based-hate-speech-detection",
    "href": "posts/An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection/2024-01-07-An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection.html#llms-and-prompts-based-hate-speech-detection",
    "title": "An Investigation of Large Language Models for Real-World Hate Speech Detection",
    "section": "LLMs and Prompts-based Hate Speech Detection",
    "text": "LLMs and Prompts-based Hate Speech Detection\n\nLLMs, like ChatGPT, have shown proficiency in natural language tasks, and prompting strategies have been found effective in guiding LLMs for specific tasks.\nPrior studies have explored LLMs for hate speech detection but there is a need for a more comprehensive understanding of LLMs’ proficiency, especially with varied prompting strategies."
  },
  {
    "objectID": "posts/An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection/2024-01-07-An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection.html#llm-based-general-prompting-strategy-vs.-baselines",
    "href": "posts/An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection/2024-01-07-An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection.html#llm-based-general-prompting-strategy-vs.-baselines",
    "title": "An Investigation of Large Language Models for Real-World Hate Speech Detection",
    "section": "LLM-based General Prompting Strategy vs. Baselines",
    "text": "LLM-based General Prompting Strategy vs. Baselines\n\nLLMs consistently outperform benchmark models, demonstrating higher accuracy and F1 scores in hate speech detection."
  },
  {
    "objectID": "posts/An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection/2024-01-07-An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection.html#analysis-of-different-prompts",
    "href": "posts/An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection/2024-01-07-An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection.html#analysis-of-different-prompts",
    "title": "An Investigation of Large Language Models for Real-World Hate Speech Detection",
    "section": "Analysis of Different Prompts",
    "text": "Analysis of Different Prompts\n\nDifferent prompts show varying levels of effectiveness, with the chain-of-thought reasoning prompt outperforming others, indicating the high impact of prompt design on model performance."
  },
  {
    "objectID": "posts/An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection/2024-01-07-An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection.html#effectiveness-of-llms-against-multilingual-hate-speech",
    "href": "posts/An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection/2024-01-07-An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection.html#effectiveness-of-llms-against-multilingual-hate-speech",
    "title": "An Investigation of Large Language Models for Real-World Hate Speech Detection",
    "section": "Effectiveness of LLMs against multilingual hate speech",
    "text": "Effectiveness of LLMs against multilingual hate speech\n\nLLMs show proficiency in detecting hate speech in English but underperform in non-English text, highlighting the need for further investigation into multilingual hate speech detection."
  },
  {
    "objectID": "posts/An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection/2024-01-07-An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection.html#appendix",
    "href": "posts/An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection/2024-01-07-An_Investigation_of_Large_Language_Models_for_Real_World_Hate_Speech_Detection.html#appendix",
    "title": "An Investigation of Large Language Models for Real-World Hate Speech Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.03346v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.03346v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6521"
  },
  {
    "objectID": "posts/Large_Language_Models_are_Clinical_Reasoners_Reasoning_Aware_Diagnosis_Framework_with_Prompt_Generated_Rationales/2023-12-12-Large_Language_Models_are_Clinical_Reasoners_Reasoning_Aware_Diagnosis_Framework_with_Prompt_Generated_Rationales.html#appendix",
    "href": "posts/Large_Language_Models_are_Clinical_Reasoners_Reasoning_Aware_Diagnosis_Framework_with_Prompt_Generated_Rationales/2023-12-12-Large_Language_Models_are_Clinical_Reasoners_Reasoning_Aware_Diagnosis_Framework_with_Prompt_Generated_Rationales.html#appendix",
    "title": "Large Language Models are Clinical Reasoners: Reasoning-Aware Diagnosis Framework with Prompt-Generated Rationales",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.07399v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.07399v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10273"
  },
  {
    "objectID": "posts/Astraios_Parameter_Efficient_Instruction_Tuning_Code_Large_Language_Models/2024-01-01-Astraios_Parameter_Efficient_Instruction_Tuning_Code_Large_Language_Models.html#summary",
    "href": "posts/Astraios_Parameter_Efficient_Instruction_Tuning_Code_Large_Language_Models/2024-01-01-Astraios_Parameter_Efficient_Instruction_Tuning_Code_Large_Language_Models.html#summary",
    "title": "Astraios: Parameter-Efficient Instruction Tuning Code Large Language Models",
    "section": "Summary",
    "text": "Summary\n\nMajor Findings\n\nThe study introduces Astraios, a suite of 28 instruction-tuned OctoCoder models using 7 tuning methods and 4 model sizes up to 16 billion parameters.\nFull-parameter fine-tuning (FFT) generally leads to the best downstream performance across all scales, and parameter-efficient fine-tuning (PEFT) methods differ significantly in their efficacy based on the model scale.\nLoRA usually offers the most favorable trade-off between cost and performance.\n\n\n\nAstraios Suite and Benchmark\n\nModel: The StarCoder series is selected as the base model, and 3 kinds of PEFT methods are focused on: adapter-based tuning, prompt-based tuning, and intrinsic-rank-based tuning.\nInstruction Tuning: The CommitPackFT+OASST dataset is selected for instruction tuning, and various training configurations and evaluations are implemented for code comprehension, code generation, model robustness, and code security.\n\n\n\nPreliminary Study: Cross-Entropy Loss\n\nThe study investigates the relationships between updated parameters, cross-entropy loss, and task performance.\n\n\n\nMain Results: Task Performance\n\nCode comprehension tasks do not align with patterns observed in code generation tasks, and larger PEFT Code LLMs perform better on code generation tasks."
  },
  {
    "objectID": "posts/Astraios_Parameter_Efficient_Instruction_Tuning_Code_Large_Language_Models/2024-01-01-Astraios_Parameter_Efficient_Instruction_Tuning_Code_Large_Language_Models.html#critique",
    "href": "posts/Astraios_Parameter_Efficient_Instruction_Tuning_Code_Large_Language_Models/2024-01-01-Astraios_Parameter_Efficient_Instruction_Tuning_Code_Large_Language_Models.html#critique",
    "title": "Astraios: Parameter-Efficient Instruction Tuning Code Large Language Models",
    "section": "Critique",
    "text": "Critique\nThe paper provides a comprehensive analysis of parameter-efficient instruction-tuning of Large Language Models (LLMs) but lacks a clear analysis of the limitations and potential biases in the experimental setup. The study’s heavy reliance on single-run evaluations and the lack of validation for data scaling and model architecture raise concerns about the robustness and generalizability of the findings. Further, while addressing the limitations and providing a detailed analysis of model architecture and data scaling were considered in the future work, the critique emphasizes the need for more thorough and varied experimental setups to improve the study’s comprehensive representation and generalizability."
  },
  {
    "objectID": "posts/Astraios_Parameter_Efficient_Instruction_Tuning_Code_Large_Language_Models/2024-01-01-Astraios_Parameter_Efficient_Instruction_Tuning_Code_Large_Language_Models.html#appendix",
    "href": "posts/Astraios_Parameter_Efficient_Instruction_Tuning_Code_Large_Language_Models/2024-01-01-Astraios_Parameter_Efficient_Instruction_Tuning_Code_Large_Language_Models.html#appendix",
    "title": "Astraios: Parameter-Efficient Instruction Tuning Code Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00788v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00788v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12057"
  },
  {
    "objectID": "posts/Spiker+_a_framework_for_the_generation_of_efficient_Spiking_Neural_Networks_FPGA_accelerators_for_inference_at_the_edge/2024-01-02-Spiker+_a_framework_for_the_generation_of_efficient_Spiking_Neural_Networks_FPGA_accelerators_for_inference_at_the_edge.html#appendix",
    "href": "posts/Spiker+_a_framework_for_the_generation_of_efficient_Spiking_Neural_Networks_FPGA_accelerators_for_inference_at_the_edge/2024-01-02-Spiker+_a_framework_for_the_generation_of_efficient_Spiking_Neural_Networks_FPGA_accelerators_for_inference_at_the_edge.html#appendix",
    "title": "Spiker+: a framework for the generation of efficient Spiking Neural Networks FPGA accelerators for inference at the edge",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01141v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01141v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13346"
  },
  {
    "objectID": "posts/Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#overview",
    "href": "posts/Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#overview",
    "title": "Prompt Engineering-assisted Malware Dynamic Analysis Using GPT-4",
    "section": "Overview",
    "text": "Overview\n\nMajor Takeaways\n\nAPI Sequence as Dynamic Malware Behavior: The API sequence, composed of consecutive API calls, is a significant representation of dynamic malware behavior in dynamic analysis methods.\nIntroduction of Prompt Engineering & GPT-4: This paper introduces a method for generating representations for API calls using GPT-4 and prompt engineering, achieving excellent detection performance in dynamic malware analysis.\nSuperior Generalization Performance: The proposed model demonstrates superior generalization performance, effectively addressing issues such as weak generalization and concept drift in dynamic malware analysis."
  },
  {
    "objectID": "posts/Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#experiment-analysis",
    "href": "posts/Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#experiment-analysis",
    "title": "Prompt Engineering-assisted Malware Dynamic Analysis Using GPT-4",
    "section": "Experiment Analysis",
    "text": "Experiment Analysis\n\nComparison of Representation Quality\n\nThe proposed model outperforms existing models in generating denser representations and capturing associations between API calls effectively, as demonstrated in case studies.\nFew-shot learning experiments show that the proposed model achieves superior fine-tuning and adaptation in comparison to TextCNN and BiLSTM.\n\n\n\nAnalysis of Concept Drift Alleviation\n\nThe proposed model effectively addresses the concept drift phenomenon, demonstrating excellent recall rates for malware even in the presence of new or previously unseen API calls."
  },
  {
    "objectID": "posts/Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#critique",
    "href": "posts/Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#critique",
    "title": "Prompt Engineering-assisted Malware Dynamic Analysis Using GPT-4",
    "section": "Critique",
    "text": "Critique\n\nThe paper could benefit from more detailed information on the limitations or potential biases of the proposed method.\nFurther clarification on the real-world applicability and scalability of the proposed model would enhance the paper’s significance.\n\nOverall, the paper provides a promising approach to dynamic malware analysis, but further studies and real-world implementations are required to validate its full potential."
  },
  {
    "objectID": "posts/Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#appendix",
    "href": "posts/Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#appendix",
    "title": "Prompt Engineering-assisted Malware Dynamic Analysis Using GPT-4",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-03\n\n\nAbstract\nhttp://arxiv.org/abs/2312.08317v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.08317v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13381"
  },
  {
    "objectID": "posts/ChatGPT_as_a_commenter_to_the_news_can_LLMs_generate_human_like_opinions/2023-12-21-ChatGPT_as_a_commenter_to_the_news_can_LLMs_generate_human_like_opinions.html#appendix",
    "href": "posts/ChatGPT_as_a_commenter_to_the_news_can_LLMs_generate_human_like_opinions/2023-12-21-ChatGPT_as_a_commenter_to_the_news_can_LLMs_generate_human_like_opinions.html#appendix",
    "title": "ChatGPT as a commenter to the news: can LLMs generate human-like opinions?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.13961v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.13961v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8845"
  },
  {
    "objectID": "posts/A_novel_diffusion_recommendation_algorithm_based_on_multi_scale_cnn_and_residual_lstm/2023-12-18-A_novel_diffusion_recommendation_algorithm_based_on_multi_scale_cnn_and_residual_lstm.html#appendix",
    "href": "posts/A_novel_diffusion_recommendation_algorithm_based_on_multi_scale_cnn_and_residual_lstm/2023-12-18-A_novel_diffusion_recommendation_algorithm_based_on_multi_scale_cnn_and_residual_lstm.html#appendix",
    "title": "A novel diffusion recommendation algorithm based on multi-scale cnn and residual lstm",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10885v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10885v1\n\n\nTruncated\nTrue\n\n\nWord Count\n15908"
  },
  {
    "objectID": "posts/GuardRails_Automated_Suggestions_for_Clarifying_Ambiguous_Purpose_Statements/2023-12-13-GuardRails_Automated_Suggestions_for_Clarifying_Ambiguous_Purpose_Statements.html#appendix",
    "href": "posts/GuardRails_Automated_Suggestions_for_Clarifying_Ambiguous_Purpose_Statements/2023-12-13-GuardRails_Automated_Suggestions_for_Clarifying_Ambiguous_Purpose_Statements.html#appendix",
    "title": "GuardRails: Automated Suggestions for Clarifying Ambiguous Purpose Statements",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.08189v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.08189v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5188"
  },
  {
    "objectID": "posts/Generative_AI_for_Math_Part_I____MathPile_A_Billion_Token_Scale_Pretraining_Corpus_for_Math/2023-12-28-Generative_AI_for_Math_Part_I____MathPile_A_Billion_Token_Scale_Pretraining_Corpus_for_Math.html#appendix",
    "href": "posts/Generative_AI_for_Math_Part_I____MathPile_A_Billion_Token_Scale_Pretraining_Corpus_for_Math/2023-12-28-Generative_AI_for_Math_Part_I____MathPile_A_Billion_Token_Scale_Pretraining_Corpus_for_Math.html#appendix",
    "title": "Generative AI for Math: Part I – MathPile: A Billion-Token-Scale Pretraining Corpus for Math",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17120v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17120v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10465"
  },
  {
    "objectID": "posts/DCR_Consistency_Divide_Conquer_Reasoning_for_Consistency_Evaluation_and_Improvement_of_Large_Language_Models/2024-01-04-DCR_Consistency_Divide_Conquer_Reasoning_for_Consistency_Evaluation_and_Improvement_of_Large_Language_Models.html#summary",
    "href": "posts/DCR_Consistency_Divide_Conquer_Reasoning_for_Consistency_Evaluation_and_Improvement_of_Large_Language_Models/2024-01-04-DCR_Consistency_Divide_Conquer_Reasoning_for_Consistency_Evaluation_and_Improvement_of_Large_Language_Models.html#summary",
    "title": "DCR-Consistency: Divide-Conquer-Reasoning for Consistency Evaluation and Improvement of Large Language Models",
    "section": "Summary",
    "text": "Summary\nDCR-Consistency: Divide-Conquer-Reasoning for Consistency Evaluation and Improvement of Large Language Models\n\nFindings\n\nThe paper proposes a new framework, DCR, for evaluating and improving the consistency of Large Language Model (LLM)-generated texts which outperforms state-of-the-art methods by a large margin in semantic, factual, and summarization consistency tasks.\nThe framework employs three components: Divide-Conquer Evaluator (DCE), Auto-Metric Converter (AMC), and Reason-Assisted Improver (RAI) to evaluate and improve the consistency of generated responses.\nThe DCR framework demonstrates high correlations with human judgments, reduces output inconsistencies, and shows promise for effective hallucination mitigation.\n\nPreliminaries\n\nConventional evaluation methods relying on token-level comparison fail to capture overall semantic meaning, leading to low correlation with human judgments.\nThe consistency of LLMs is essential for AI safety and reliability, but current methods often overlook self-consistency failures.\n\nDivide-Conquer-Reasoning\n\nDCE evaluates semantic consistency between reference and candidate paragraphs at a sentence level using a divide-and-conquer strategy.\nAMC converts the evaluation reasons into a numeric score for quantitative interpretation.\nRAI utilizes the outputs of DCE to generate new responses to mitigate inconsistencies.\n\nExperiments\n\nThe DCR framework outperforms baseline methods in semantic, factual, and summarization consistency evaluations, showing high correlations with human judgment.\nRAI significantly improves consistency, reducing nearly 90% of output inconsistencies."
  },
  {
    "objectID": "posts/DCR_Consistency_Divide_Conquer_Reasoning_for_Consistency_Evaluation_and_Improvement_of_Large_Language_Models/2024-01-04-DCR_Consistency_Divide_Conquer_Reasoning_for_Consistency_Evaluation_and_Improvement_of_Large_Language_Models.html#critique",
    "href": "posts/DCR_Consistency_Divide_Conquer_Reasoning_for_Consistency_Evaluation_and_Improvement_of_Large_Language_Models/2024-01-04-DCR_Consistency_Divide_Conquer_Reasoning_for_Consistency_Evaluation_and_Improvement_of_Large_Language_Models.html#critique",
    "title": "DCR-Consistency: Divide-Conquer-Reasoning for Consistency Evaluation and Improvement of Large Language Models",
    "section": "Critique",
    "text": "Critique\nWhile the DCR framework shows promise in evaluating and improving LLM-generated texts’ consistency, several limitations should be considered.\n\nNot Comprehensive: The approach may not universally address all dimensions of text evaluation, such as coherence and relevance.\nInput Dependence: The accuracy of the framework is inherently limited by the correctness of the input paragraphs, potentially affecting the detection of non-factual statements.\nManual Prompting: The requirement for hand-crafted prompts for specific tasks may limit the scalability and automation of the framework.\n\nOverall, the paper provides valuable insights into consistency evaluation and improvement for LLM-generated texts, but further research is needed to address the identified limitations."
  },
  {
    "objectID": "posts/DCR_Consistency_Divide_Conquer_Reasoning_for_Consistency_Evaluation_and_Improvement_of_Large_Language_Models/2024-01-04-DCR_Consistency_Divide_Conquer_Reasoning_for_Consistency_Evaluation_and_Improvement_of_Large_Language_Models.html#appendix",
    "href": "posts/DCR_Consistency_Divide_Conquer_Reasoning_for_Consistency_Evaluation_and_Improvement_of_Large_Language_Models/2024-01-04-DCR_Consistency_Divide_Conquer_Reasoning_for_Consistency_Evaluation_and_Improvement_of_Large_Language_Models.html#appendix",
    "title": "DCR-Consistency: Divide-Conquer-Reasoning for Consistency Evaluation and Improvement of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.02132v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.02132v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9608"
  },
  {
    "objectID": "posts/Prometheus_Infrastructure_Security_Posture_Analysis_with_AI_generated_Attack_Graphs/2023-12-20-Prometheus_Infrastructure_Security_Posture_Analysis_with_AI_generated_Attack_Graphs.html#appendix",
    "href": "posts/Prometheus_Infrastructure_Security_Posture_Analysis_with_AI_generated_Attack_Graphs/2023-12-20-Prometheus_Infrastructure_Security_Posture_Analysis_with_AI_generated_Attack_Graphs.html#appendix",
    "title": "Prometheus: Infrastructure Security Posture Analysis with AI-generated Attack Graphs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.13119v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.13119v1\n\n\nTruncated\nTrue\n\n\nWord Count\n18677"
  },
  {
    "objectID": "posts/Re_parameterized_Low_rank_Prompt_Generalize_a_Vision_Language_Model_within_0.5K_Parameters/2023-12-17-Re_parameterized_Low_rank_Prompt_Generalize_a_Vision_Language_Model_within_0.5K_Parameters.html#summary",
    "href": "posts/Re_parameterized_Low_rank_Prompt_Generalize_a_Vision_Language_Model_within_0.5K_Parameters/2023-12-17-Re_parameterized_Low_rank_Prompt_Generalize_a_Vision_Language_Model_within_0.5K_Parameters.html#summary",
    "title": "Re-parameterized Low-rank Prompt: Generalize a Vision-Language Model within 0.5K Parameters",
    "section": "Summary",
    "text": "Summary\n\nKey Findings\n\nPrompt Tuning: Prompt tuning has become popular for adapting vision-language models to downstream tasks. It involves freezing the parameters in the backbone and tuning the prompts for better transferability on different tasks.\nRe-parameterized Low-rank Prompt (RLP): The RLP method reduces the number of tunable parameters and storage space, demonstrating superior performance with a significantly small number of parameters.\nEfficiency and Effectiveness: RLP demonstrates efficiency and effectiveness, reaching state-of-the-art performance with an extremely small number of parameters.\n\n\n\nIntroduction\nIn recent years, large pre-trained vision-language models have achieved tremendous success. Representative models like CLIP are first pre-trained on a huge number of text-image pairs on the web to align textual and visual features, and then can be tuned and used for various downstream tasks.\n\n\nMotivation for Low-Rank Prompts\nThe authors observed that the evolution pattern of the generalization capability in visual-language models aligns harmoniously with the trend of rank variations in the prompt matrix during adaptation. This observation led them to propose the Re-parameterized Low-rank Prompt (RLP), aiming for effective and efficient adaptation for vision-language models.\n\n\nRelated Works\nThe paper discusses various related works in the vision-language models and prompt tuning, outlining the challenges and advancements in the field.\n\n\nMethodology\nThe paper reviews the prompt tuning for CLIP, introduces the Low-rank prompt, and explains the motivation behind it. It also discusses the initialization method, integration of a Dropout layer, and the efficiency analysis of the proposed RLP method.\n\n\nResults\n\nBase-to-New Generalization: RLP consistently outperforms zero-shot CLIP, CoOp, and CLIP-Adapter across all the shot numbers.\nDomain Generalization: RLP demonstrates robustness and outperforms state-of-the-art methods in domain generalization experiments.\nCross-Dataset Transfer: RLP excels in cross-dataset transfer, showcasing its ability to extract general and data-agnostic knowledge from given images.\nFew-shot Learning: RLP consistently outperforms zero-shot CLIP, CoOp, and CLIP-Adapter across all the shot numbers, demonstrating its adaptation ability when there are few samples in downstream tasks.\n\n\n\nAnalysis\nThe paper includes an ablation study, efficiency comparison, and results across different hyper-parameters to demonstrate the effectiveness and efficiency of the proposed RLP method."
  },
  {
    "objectID": "posts/Re_parameterized_Low_rank_Prompt_Generalize_a_Vision_Language_Model_within_0.5K_Parameters/2023-12-17-Re_parameterized_Low_rank_Prompt_Generalize_a_Vision_Language_Model_within_0.5K_Parameters.html#critique",
    "href": "posts/Re_parameterized_Low_rank_Prompt_Generalize_a_Vision_Language_Model_within_0.5K_Parameters/2023-12-17-Re_parameterized_Low_rank_Prompt_Generalize_a_Vision_Language_Model_within_0.5K_Parameters.html#critique",
    "title": "Re-parameterized Low-rank Prompt: Generalize a Vision-Language Model within 0.5K Parameters",
    "section": "Critique",
    "text": "Critique\nThe paper provides a comprehensive exploration of the RLP method and its effectiveness in adapting vision-language models within an extremely small number of parameters. However, further details on the limitations and potential challenges in real-world applications would enhance the comprehensiveness of the paper. Additionally, addressing the scalability and generalizability of the RLP method to larger and diverse datasets could strengthen its practical utility."
  },
  {
    "objectID": "posts/Re_parameterized_Low_rank_Prompt_Generalize_a_Vision_Language_Model_within_0.5K_Parameters/2023-12-17-Re_parameterized_Low_rank_Prompt_Generalize_a_Vision_Language_Model_within_0.5K_Parameters.html#appendix",
    "href": "posts/Re_parameterized_Low_rank_Prompt_Generalize_a_Vision_Language_Model_within_0.5K_Parameters/2023-12-17-Re_parameterized_Low_rank_Prompt_Generalize_a_Vision_Language_Model_within_0.5K_Parameters.html#appendix",
    "title": "Re-parameterized Low-rank Prompt: Generalize a Vision-Language Model within 0.5K Parameters",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10813v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10813v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13488"
  },
  {
    "objectID": "posts/Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#major-takeaways",
    "href": "posts/Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#major-takeaways",
    "title": "Digger: Detecting Copyright Content Mis-usage in Large Language Model Training",
    "section": "Major Takeaways:",
    "text": "Major Takeaways:\n\nPre-training and success of Large Language Models (LLMs): The success of LLMs in various applications heavily depends on their extensive pre-training on large and diverse datasets. This raises concerns about potential misuse of copyrighted material and the need for ethical use of such content in LLM development.\nEffectiveness of the Digger framework: The paper introduces the Digger framework, designed to detect the presence of copyrighted content within LLM training datasets and provide a confidence estimation for the likelihood of each content sample’s inclusion. Through experiments, the paper affirms the effectiveness of Digger in identifying instances of content misuse in LLM training processes.\nReal-world applicability: The paper demonstrates the applicability of Digger in real-world scenarios by testing its performance in identifying copyrighted content within two widely-recognized LLMs: GPT2-XL and LLaMA-7b."
  },
  {
    "objectID": "posts/Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#introduction",
    "href": "posts/Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#introduction",
    "title": "Digger: Detecting Copyright Content Mis-usage in Large Language Model Training",
    "section": "Introduction",
    "text": "Introduction\n\nLarge Language Models (LLMs) have achieved impressive performance in various tasks, relying on extensive pre-training on large and diverse datasets.\nConcerns about potential misuse of copyrighted material in training datasets lead to the introduction of the Digger framework."
  },
  {
    "objectID": "posts/Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#background",
    "href": "posts/Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#background",
    "title": "Digger: Detecting Copyright Content Mis-usage in Large Language Model Training",
    "section": "Background",
    "text": "Background\n\nComplications of AI Models Trained on Copyrighted Content: The training of AI models, especially LLMs, on copyrighted content has emerged as a complex issue straddling legal, ethical, and technological domains.\nLimitations of Existing Mitigations: Legal and technological solutions to mitigate the use of copyrighted content in AI training have challenges and may not fully address ethical dimensions."
  },
  {
    "objectID": "posts/Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#characteristic-study",
    "href": "posts/Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#characteristic-study",
    "title": "Digger: Detecting Copyright Content Mis-usage in Large Language Model Training",
    "section": "Characteristic Study",
    "text": "Characteristic Study\n\nThe study aims to detect possible copyright infringements within LLMs by discerning the behavioral differences of LLMs when exposed to materials they have encountered during training versus those they have not.\nThe sample loss dynamics of LLMs are analyzed to address research questions related to the impact of fine-tuning and evaluation metrics investigation."
  },
  {
    "objectID": "posts/Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#methodology",
    "href": "posts/Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#methodology",
    "title": "Digger: Detecting Copyright Content Mis-usage in Large Language Model Training",
    "section": "Methodology",
    "text": "Methodology\n\nThe Digger framework is proposed to identify if a given target material has been trained on a given LLM, involving three main phases: Preparation, Simulation Experiment, and Confidence Calculation."
  },
  {
    "objectID": "posts/Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#evaluation",
    "href": "posts/Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#evaluation",
    "title": "Digger: Detecting Copyright Content Mis-usage in Large Language Model Training",
    "section": "Evaluation",
    "text": "Evaluation\n\nControlled experiments demonstrate the effectiveness of Digger in identifying instances of content misuse in LLM training processes, with an AUC of 0.914.\nReal-world scenarios also show promise with Digger effectively identifying copyrighted content within GPT2-XL and LLaMA-7b."
  },
  {
    "objectID": "posts/Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#discussion",
    "href": "posts/Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#discussion",
    "title": "Digger: Detecting Copyright Content Mis-usage in Large Language Model Training",
    "section": "Discussion",
    "text": "Discussion\n\nThe study emphasizes the cost for training and prediction and highlights the need for further research on target probability calculation and legal considerations.\nThe limitations and challenges such as the lack of ground truth labels and limited confidence level calculation are also discussed."
  },
  {
    "objectID": "posts/Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#threats-to-validity",
    "href": "posts/Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#threats-to-validity",
    "title": "Digger: Detecting Copyright Content Mis-usage in Large Language Model Training",
    "section": "Threats To Validity",
    "text": "Threats To Validity\n\nInternal threats include the lack of ground truth labels and limited inclusion of LLMs, while external threats involve the limited confidence level calculation and copyright legal considerations."
  },
  {
    "objectID": "posts/Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#conclusion",
    "href": "posts/Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#conclusion",
    "title": "Digger: Detecting Copyright Content Mis-usage in Large Language Model Training",
    "section": "Conclusion",
    "text": "Conclusion\n\nThe paper introduces a universal optimization framework, Digger, and demonstrates its effectiveness in identifying copyrighted content within LLM training datasets. The potential of Digger in real-world scenarios is highlighted, opening up opportunities in identifying copyrighted materials used in LLMs."
  },
  {
    "objectID": "posts/Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#critique-and-potential-problems",
    "href": "posts/Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#critique-and-potential-problems",
    "title": "Digger: Detecting Copyright Content Mis-usage in Large Language Model Training",
    "section": "Critique and Potential Problems",
    "text": "Critique and Potential Problems\n\nThe paper could benefit from a broader range of LLMs included in the study to enhance the generalizability of the findings.\nThe reliance on normal distribution fitting for confidence level calculation could be expanded to explore alternative statistical methods.\nThe study is situated within a specific legal and cultural context, which may limit the generalizability of its findings to other jurisdictions.\n\nOverall, the paper provides valuable insights into the challenges and solutions related to detecting copyright content misuse in the training of Large Language Models, with the potential for future research to further refine and expand the proposed Digger framework."
  },
  {
    "objectID": "posts/Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#appendix",
    "href": "posts/Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger_Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#appendix",
    "title": "Digger: Detecting Copyright Content Mis-usage in Large Language Model Training",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00676v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00676v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12663"
  },
  {
    "objectID": "posts/Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration/2023-12-21-Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration.html#key-findings",
    "href": "posts/Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration/2023-12-21-Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration.html#key-findings",
    "title": "Rényi Pufferfish Privacy: General Additive Noise Mechanisms and Privacy Amplification by Iteration",
    "section": "Key Findings",
    "text": "Key Findings\n\nRényi Pufferfish privacy\n\nA flexible generalization of differential privacy that allows modeling arbitrary secrets and adversary’s prior knowledge about the data.\nIntroduces a Rényi divergence-based variant of Pufferfish that extends the applicability of the framework.\n\nGeneral Additive Mechanism\n\nIntroduces the General Wasserstein Mechanism (GWM) that provides Rényi Pufferfish privacy guarantees for all additive noise distributions.\nProposes two ways to improve the utility of GWM by relaxing the -Wasserstein distance constraint in the calibration of the noise.\n\nPrivacy Amplification by Iteration\n\nShows that Rényi Pufferfish privacy is amenable to privacy amplification by iteration, providing a way to analyze iterative gradient descent algorithms for convex optimization."
  },
  {
    "objectID": "posts/Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration/2023-12-21-Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration.html#rényi-pufferfish-privacy",
    "href": "posts/Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration/2023-12-21-Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration.html#rényi-pufferfish-privacy",
    "title": "Rényi Pufferfish Privacy: General Additive Noise Mechanisms and Privacy Amplification by Iteration",
    "section": "Rényi Pufferfish Privacy",
    "text": "Rényi Pufferfish Privacy\n\nDefinitions of Rényi differential privacy and Pufferfish privacy\nPost-processing inequality, running examples"
  },
  {
    "objectID": "posts/Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration/2023-12-21-Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration.html#general-additive-mechanism-for-rényi-pufferfish-privacy",
    "href": "posts/Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration/2023-12-21-Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration.html#general-additive-mechanism-for-rényi-pufferfish-privacy",
    "title": "Rényi Pufferfish Privacy: General Additive Noise Mechanisms and Privacy Amplification by Iteration",
    "section": "General Additive Mechanism for Rényi Pufferfish Privacy",
    "text": "General Additive Mechanism for Rényi Pufferfish Privacy\n\nIntroduction of the General Wasserstein Mechanism (GWM)\nProof of the properties of GWM\nImprovement of the utility of GWM by relaxing the -Wasserstein distance constraint"
  },
  {
    "objectID": "posts/Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration/2023-12-21-Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration.html#improving-utility-by-relaxing-the--wasserstein-constraint",
    "href": "posts/Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration/2023-12-21-Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration.html#improving-utility-by-relaxing-the--wasserstein-constraint",
    "title": "Rényi Pufferfish Privacy: General Additive Noise Mechanisms and Privacy Amplification by Iteration",
    "section": "Improving Utility by Relaxing the -Wasserstein Constraint",
    "text": "Improving Utility by Relaxing the -Wasserstein Constraint\n\nIntroduction of an -Approximation of -RPP\nProof of the -Approximation and its utility improvement\nLeveraging -Wasserstein Metrics to improve the utility of the GWM"
  },
  {
    "objectID": "posts/Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration/2023-12-21-Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration.html#protection-against-close-adversaries",
    "href": "posts/Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration/2023-12-21-Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration.html#protection-against-close-adversaries",
    "title": "Rényi Pufferfish Privacy: General Additive Noise Mechanisms and Privacy Amplification by Iteration",
    "section": "Protection Against Close Adversaries",
    "text": "Protection Against Close Adversaries\n\nExtension of privacy guarantees to “close adversaries”\nApplication to analyze the privacy guarantees of differentially private mechanisms under weakly-correlated data"
  },
  {
    "objectID": "posts/Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration/2023-12-21-Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration.html#privacy-amplification-by-iteration",
    "href": "posts/Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration/2023-12-21-Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration.html#privacy-amplification-by-iteration",
    "title": "Rényi Pufferfish Privacy: General Additive Noise Mechanisms and Privacy Amplification by Iteration",
    "section": "Privacy Amplification by Iteration",
    "text": "Privacy Amplification by Iteration\n\nTheoretical results and application to convex optimization\nProof of the theoretical results and application to convex optimization"
  },
  {
    "objectID": "posts/Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration/2023-12-21-Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration.html#critique",
    "href": "posts/Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration/2023-12-21-Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration.html#critique",
    "title": "Rényi Pufferfish Privacy: General Additive Noise Mechanisms and Privacy Amplification by Iteration",
    "section": "Critique",
    "text": "Critique\nThe paper presents a significant advancement in the Pufferfish privacy framework, but there are some limitations and potential issues to consider: - The complexity and computational overhead of the proposed mechanisms and frameworks may limit practical implementation. - The applicability of the proposed methods and results to real-world datasets and scenarios needs to be tested and validated.\nOverall, while the paper provides valuable insights and advancements in privacy mechanisms, further empirical research and validation in real-world settings are needed to assess the practical utility and feasibility of the proposed methods."
  },
  {
    "objectID": "posts/Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration/2023-12-21-Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration.html#appendix",
    "href": "posts/Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration/2023-12-21-Renyi_Pufferfish_Privacy_General_Additive_Noise_Mechanisms_and_Privacy_Amplification_by_Iteration.html#appendix",
    "title": "Rényi Pufferfish Privacy: General Additive Noise Mechanisms and Privacy Amplification by Iteration",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.13985v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.13985v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9777"
  },
  {
    "objectID": "posts/Large_Legal_Fictions_Profiling_Legal_Hallucinations_in_Large_Language_Models/2024-01-02-Large_Legal_Fictions_Profiling_Legal_Hallucinations_in_Large_Language_Models.html#appendix",
    "href": "posts/Large_Legal_Fictions_Profiling_Legal_Hallucinations_in_Large_Language_Models/2024-01-02-Large_Legal_Fictions_Profiling_Legal_Hallucinations_in_Large_Language_Models.html#appendix",
    "title": "Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01301v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01301v1\n\n\nTruncated\nTrue\n\n\nWord Count\n21736"
  },
  {
    "objectID": "posts/Taking_the_Next_Step_with_Generative_Artificial_Intelligence_The_Transformative_Role_of_Multimodal_Large_Language_Models_in_Science_Education/2024-01-01-Taking_the_Next_Step_with_Generative_Artificial_Intelligence_The_Transformative_Role_of_Multimodal_Large_Language_Models_in_Science_Education.html#appendix",
    "href": "posts/Taking_the_Next_Step_with_Generative_Artificial_Intelligence_The_Transformative_Role_of_Multimodal_Large_Language_Models_in_Science_Education/2024-01-01-Taking_the_Next_Step_with_Generative_Artificial_Intelligence_The_Transformative_Role_of_Multimodal_Large_Language_Models_in_Science_Education.html#appendix",
    "title": "Taking the Next Step with Generative Artificial Intelligence: The Transformative Role of Multimodal Large Language Models in Science Education",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00832v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00832v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12625"
  },
  {
    "objectID": "posts/kNN_ICL_Compositional_Task_Oriented_Parsing_Generalization_with_Nearest_Neighbor_In_Context_Learning/2023-12-17-kNN_ICL_Compositional_Task_Oriented_Parsing_Generalization_with_Nearest_Neighbor_In_Context_Learning.html#appendix",
    "href": "posts/kNN_ICL_Compositional_Task_Oriented_Parsing_Generalization_with_Nearest_Neighbor_In_Context_Learning/2023-12-17-kNN_ICL_Compositional_Task_Oriented_Parsing_Generalization_with_Nearest_Neighbor_In_Context_Learning.html#appendix",
    "title": "kNN-ICL: Compositional Task-Oriented Parsing Generalization with Nearest Neighbor In-Context Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10771v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10771v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8730"
  },
  {
    "objectID": "posts/LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#major-takeaways",
    "href": "posts/LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#major-takeaways",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nLarge Language Models (LLMs) show promise in identifying vulnerabilities in Android applications, outperforming existing tools in flagging insecure apps in 91.67% of cases in the Ghera benchmark.\nPrompt Engineering, a technique that optimizes LLM performance by crafting intricate prompts, is instrumental in enhancing the efficacy of LLMs for specific tasks.\nThe study introduces LLB, a Python package that leverages LLMs to scan Android projects for security vulnerabilities. The package integrates distinct scanning mechanisms, offering flexibility in the vulnerability assessment process."
  },
  {
    "objectID": "posts/LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#introduction",
    "href": "posts/LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#introduction",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "section": "Introduction",
    "text": "Introduction\n\nDespite advancements in building secure systems, Android applications remain prone to vulnerabilities, creating a demand for effective vulnerability detection methodologies.\nCurrent strategies involving static and dynamic analysis tools have limitations such as overwhelming false positives and adaptability challenges."
  },
  {
    "objectID": "posts/LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#leveraging-large-language-models-for-vulnerability-detection",
    "href": "posts/LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#leveraging-large-language-models-for-vulnerability-detection",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "section": "Leveraging Large Language Models for Vulnerability Detection",
    "text": "Leveraging Large Language Models for Vulnerability Detection\n\nLLMs have shown potential in understanding semantics in both human and programming languages.\nPrior research has explored the use of LLMs for vulnerability detection, showing promising results, which leads to an exploration of LLMs in the context of Android security."
  },
  {
    "objectID": "posts/LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#prompt-engineering",
    "href": "posts/LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#prompt-engineering",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "section": "Prompt Engineering",
    "text": "Prompt Engineering\n\nPrompt Engineering involves intricate prompt construction to optimize AI performance by guiding the model through a sequence of prompts that enrich and build upon each other.\nChain-of-Thought Prompting is one groundbreaking strategy within Prompt Engineering that allows for more depth in AI reasoning."
  },
  {
    "objectID": "posts/LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#retrieval-augmented-generation",
    "href": "posts/LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#retrieval-augmented-generation",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "section": "Retrieval-Augmented Generation",
    "text": "Retrieval-Augmented Generation\n\nRetrieval-Augmented Generation (RAG) is an AI framework designed to enhance the quality of responses generated by LLMs by leveraging a specialized body of knowledge to answer questions more accurately."
  },
  {
    "objectID": "posts/LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#results",
    "href": "posts/LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#results",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "section": "Results",
    "text": "Results\n\nExperiments demonstrate that with sufficient context, GPT4 can successfully identify vulnerabilities in Android applications.\nThe study introduces LLB, a Python package that leverages LLMs to scan Android projects for security vulnerabilities and includes a Command Line Interface and expert command for post-scan analysis."
  },
  {
    "objectID": "posts/LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#case-study",
    "href": "posts/LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#case-study",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "section": "Case Study",
    "text": "Case Study\n\nThe LLB package correctly identifies 6 of the 8 seeded vulnerabilities in the Vuldroid application, providing valid fixes and walking through the reasoning involved."
  },
  {
    "objectID": "posts/LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#discussion-and-future-work",
    "href": "posts/LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#discussion-and-future-work",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "section": "Discussion and Future Work",
    "text": "Discussion and Future Work\n\nFurther work is needed to optimize the performance of LLB as an analyzer and consider incorporating static analysis into the framework.\nThe dynamic nature of Android platform and cybersecurity threats necessitates continuous updates and retraining of LLMs, which can be resource-intensive."
  },
  {
    "objectID": "posts/LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#conclusion",
    "href": "posts/LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#conclusion",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "section": "Conclusion",
    "text": "Conclusion\n\nLLMs demonstrate promise in detecting Android vulnerabilities, but require further work in drafting a better analysis pipeline architecture and optimizing the context available to the LLM."
  },
  {
    "objectID": "posts/LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#critique",
    "href": "posts/LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#critique",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "section": "Critique",
    "text": "Critique\n\nThe study acknowledges potential bias and limitations in prompt engineering, as poorly designed prompts can lead to suboptimal results and introduce bias.\nLeakage of semantic information and varying performance of LLMs are potential concerns impacting the replicability of results."
  },
  {
    "objectID": "posts/LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#potential-problems",
    "href": "posts/LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#potential-problems",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "section": "Potential Problems",
    "text": "Potential Problems\n\nThe study highlights potential biases introduced through prompt engineering and the need for continuous updates and retraining of LLMs, which could be resource-intensive and impact the applicability of the findings."
  },
  {
    "objectID": "posts/LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#appendix",
    "href": "posts/LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky_Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#appendix",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01269v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01269v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8022"
  },
  {
    "objectID": "posts/On_the_Trajectories_of_SGD_Without_Replacement/2023-12-26-On_the_Trajectories_of_SGD_Without_Replacement.html#appendix",
    "href": "posts/On_the_Trajectories_of_SGD_Without_Replacement/2023-12-26-On_the_Trajectories_of_SGD_Without_Replacement.html#appendix",
    "title": "On the Trajectories of SGD Without Replacement",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16143v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16143v1\n\n\nTruncated\nTrue\n\n\nWord Count\n30429"
  },
  {
    "objectID": "posts/Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models/2024-01-04-Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models.html#abstract",
    "href": "posts/Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models/2024-01-04-Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models.html#abstract",
    "title": "Learning to Prompt with Text Only Supervision for Vision-Language Models",
    "section": "Abstract:",
    "text": "Abstract:\nVision-language models such as CLIP have shown excellent generalization abilities, but adapting these models for downstream tasks while maintaining their generalization remains a challenge. In this work, the authors propose a method, ProText, which learns prompts using only text data derived from large language models (LLMs). This approach enables zero-shot transfer of prompts to new classes and datasets, potentially reducing the LLM prompt engineering cost. Extensive evaluations show that ProText improves upon prior ensembling works and is competitive with those utilizing labeled images."
  },
  {
    "objectID": "posts/Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models/2024-01-04-Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models.html#introduction",
    "href": "posts/Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models/2024-01-04-Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models.html#introduction",
    "title": "Learning to Prompt with Text Only Supervision for Vision-Language Models",
    "section": "1 Introduction",
    "text": "1 Introduction\n\nVision-language models (VLMs) like CLIP leverage contrastive pre-training on massive image-text pairs from the internet.\nAdapting CLIP for downstream tasks while maintaining its generalization is challenging.\nMost methods for adapting CLIP require annotated image labels, which is impractical in real-world scenarios."
  },
  {
    "objectID": "posts/Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models/2024-01-04-Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models.html#related-work",
    "href": "posts/Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models/2024-01-04-Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models.html#related-work",
    "title": "Learning to Prompt with Text Only Supervision for Vision-Language Models",
    "section": "2 Related Work",
    "text": "2 Related Work\n\nFoundational Vision-Language models (VLMs) leverage joint image-text pretraining using internet-scale data in a self-supervised fashion.\nPrompt Learning [6, 49, 50, 27, 9, 41, 40] and Training-Free Text Prompt Enhancement are effective fine-tuning strategies for VLMs."
  },
  {
    "objectID": "posts/Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models/2024-01-04-Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models.html#method",
    "href": "posts/Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models/2024-01-04-Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models.html#method",
    "title": "Learning to Prompt with Text Only Supervision for Vision-Language Models",
    "section": "3 Method",
    "text": "3 Method\n\n3.1 Preliminaries\n\nCLIP consists of an image encoder and a text encoder which maps image and text input into visual and textual features respectively.\nExisting prompt learning methods require visual samples with labels to optimize prompts using cross-entropy loss.\n\n\n\n3.2 Prompt Learning with Text-Only Supervision\n\nProText employs a contextual mapping strategy that effectively learns a mapping function that embeds rich contextual knowledge from LLM data within the prompts.\nAt inference, the learned prompts are used with class-name templates for zero-shot inference."
  },
  {
    "objectID": "posts/Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models/2024-01-04-Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models.html#experiments",
    "href": "posts/Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models/2024-01-04-Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models.html#experiments",
    "title": "Learning to Prompt with Text Only Supervision for Vision-Language Models",
    "section": "4 Experiments",
    "text": "4 Experiments\n\nProText improves the generalization of CLIP across various settings and is competitive with approaches that explicitly use labeled image samples for training.\nAchieves substantial gains over CLIP and CuPL in cross-dataset transfer settings.\n\n\n4.7 Ablative Analysis\n\nContextual mapping loss allows learnable prompts to exploit internal knowledge of CLIP’s text encoder for generalized context from the LLM descriptions."
  },
  {
    "objectID": "posts/Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models/2024-01-04-Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models.html#conclusion",
    "href": "posts/Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models/2024-01-04-Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models.html#conclusion",
    "title": "Learning to Prompt with Text Only Supervision for Vision-Language Models",
    "section": "Conclusion",
    "text": "Conclusion\nProText improves upon prior ensembling works and is competitive with approaches that utilize labeled images for training."
  },
  {
    "objectID": "posts/Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models/2024-01-04-Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models.html#appendix",
    "href": "posts/Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models/2024-01-04-Learning_to_Prompt_with_Text_Only_Supervision_for_Vision_Language_Models.html#appendix",
    "title": "Learning to Prompt with Text Only Supervision for Vision-Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.02418v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.02418v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12266"
  },
  {
    "objectID": "posts/Mixed_Distillation_Helps_Smaller_Language_Model_Better_Reasoning/2023-12-17-Mixed_Distillation_Helps_Smaller_Language_Model_Better_Reasoning.html#appendix",
    "href": "posts/Mixed_Distillation_Helps_Smaller_Language_Model_Better_Reasoning/2023-12-17-Mixed_Distillation_Helps_Smaller_Language_Model_Better_Reasoning.html#appendix",
    "title": "Mixed Distillation Helps Smaller Language Model Better Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10730v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10730v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6198"
  },
  {
    "objectID": "posts/Exploring_the_Sensitivity_of_LLMs_Decision_Making_Capabilities_Insights_from_Prompt_Variation_and_Hyperparameters/2023-12-29-Exploring_the_Sensitivity_of_LLMs_Decision_Making_Capabilities_Insights_from_Prompt_Variation_and_Hyperparameters.html#appendix",
    "href": "posts/Exploring_the_Sensitivity_of_LLMs_Decision_Making_Capabilities_Insights_from_Prompt_Variation_and_Hyperparameters/2023-12-29-Exploring_the_Sensitivity_of_LLMs_Decision_Making_Capabilities_Insights_from_Prompt_Variation_and_Hyperparameters.html#appendix",
    "title": "Exploring the Sensitivity of LLMs’ Decision-Making Capabilities: Insights from Prompt Variation and Hyperparameters",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17476v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17476v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4103"
  },
  {
    "objectID": "posts/Can_ChatGPT_Read_Who_You_Are/2023-12-26-Can_ChatGPT_Read_Who_You_Are.html#appendix",
    "href": "posts/Can_ChatGPT_Read_Who_You_Are/2023-12-26-Can_ChatGPT_Read_Who_You_Are.html#appendix",
    "title": "Can ChatGPT Read Who You Are?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16070v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16070v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10609"
  },
  {
    "objectID": "posts/Unlocking_the_Potential_of_Large_Language_Models_for_Explainable_Recommendations/2023-12-25-Unlocking_the_Potential_of_Large_Language_Models_for_Explainable_Recommendations.html#appendix",
    "href": "posts/Unlocking_the_Potential_of_Large_Language_Models_for_Explainable_Recommendations/2023-12-25-Unlocking_the_Potential_of_Large_Language_Models_for_Explainable_Recommendations.html#appendix",
    "title": "Unlocking the Potential of Large Language Models for Explainable Recommendations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.15661v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.15661v2\n\n\nTruncated\nFalse\n\n\nWord Count\n9663"
  },
  {
    "objectID": "posts/RecRanker_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top_k_Recommendation/2023-12-26-RecRanker_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top_k_Recommendation.html#appendix",
    "href": "posts/RecRanker_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top_k_Recommendation/2023-12-26-RecRanker_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top_k_Recommendation.html#appendix",
    "title": "RecRanker: Instruction Tuning Large Language Model as Ranker for Top-k Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16018v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16018v1\n\n\nTruncated\nTrue\n\n\nWord Count\n15714"
  },
  {
    "objectID": "posts/LLM_Maybe_LongLM_Self_Extend_LLM_Context_Window_Without_Tuning/2024-01-02-LLM_Maybe_LongLM_Self_Extend_LLM_Context_Window_Without_Tuning.html#appendix",
    "href": "posts/LLM_Maybe_LongLM_Self_Extend_LLM_Context_Window_Without_Tuning/2024-01-02-LLM_Maybe_LongLM_Self_Extend_LLM_Context_Window_Without_Tuning.html#appendix",
    "title": "LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01325v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01325v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8504"
  },
  {
    "objectID": "posts/Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis.html#major-takeaways",
    "href": "posts/Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis.html#major-takeaways",
    "title": "Inter-X: Towards Versatile Human-Human Interaction Analysis",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nInter-X Dataset: Proposes the Inter-X dataset, a comprehensive human-human interaction dataset with accurate body movements, diverse interaction patterns, and detailed hand gestures.\nUnified Benchmark: Introduces a unified benchmark for 4 categories of downstream tasks in the perceptual and generative directions.\nExtensive Experiments: Conducts extensive experiments and analysis, showing that Inter-X poses challenges for human-human interaction-related tasks."
  },
  {
    "objectID": "posts/Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis.html#abstract",
    "href": "posts/Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis.html#abstract",
    "title": "Inter-X: Towards Versatile Human-Human Interaction Analysis",
    "section": "Abstract",
    "text": "Abstract\nThe paper introduces the Inter-X dataset, a large-scale human-human interaction dataset with accurate body movements, diverse interaction patterns, and detailed hand gestures. It also proposes a unified benchmark for 4 categories of downstream tasks from both perceptual and generative directions."
  },
  {
    "objectID": "posts/Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis.html#introduction",
    "href": "posts/Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis.html#introduction",
    "title": "Inter-X: Towards Versatile Human-Human Interaction Analysis",
    "section": "Introduction",
    "text": "Introduction\n\nUnderstanding human-human interactions is crucial for intelligent digital human systems with applications in surveillance, AR/VR, games, and robotics.\nExisting datasets lack accurate body motions, hand gestures, and fine-grained textual descriptions, hindering progress in human-human interaction analysis."
  },
  {
    "objectID": "posts/Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis.html#related-work",
    "href": "posts/Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis.html#related-work",
    "title": "Inter-X: Towards Versatile Human-Human Interaction Analysis",
    "section": "Related Work",
    "text": "Related Work\n\nDiscusses existing human motion and human-human interaction datasets and their functionalities."
  },
  {
    "objectID": "posts/Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis.html#the-inter-x-dataset",
    "href": "posts/Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis.html#the-inter-x-dataset",
    "title": "Inter-X: Towards Versatile Human-Human Interaction Analysis",
    "section": "The Inter-X Dataset",
    "text": "The Inter-X Dataset\n\nData Capturing System\n\nUtilizes an optical MoCap system for accurate body movements and inertial gloves for capturing finger gestures without occlusions.\nCaptures 40 daily interaction categories, involving 11K motion sequences and 8.1M frames.\n\n\n\nData Postprocessing\n\nInvolves aligning body poses from the MoCap system with finger gestures and segmenting interaction snippets."
  },
  {
    "objectID": "posts/Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis.html#dataset-taxonomy",
    "href": "posts/Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis.html#dataset-taxonomy",
    "title": "Inter-X: Towards Versatile Human-Human Interaction Analysis",
    "section": "Dataset Taxonomy",
    "text": "Dataset Taxonomy\n\nEnriches the dataset with high-precision human-human interaction sequences and multifaceted annotations, including textual descriptions, action categories, interaction order, and relationship/personality information."
  },
  {
    "objectID": "posts/Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis.html#task-taxonomy",
    "href": "posts/Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis.html#task-taxonomy",
    "title": "Inter-X: Towards Versatile Human-Human Interaction Analysis",
    "section": "Task Taxonomy",
    "text": "Task Taxonomy\n\nOutlines 4 categories of downstream tasks enabled by the dataset: Texts related Tasks, Actions related Tasks, Interaction-order related Tasks, and Relationship & Personality related Tasks."
  },
  {
    "objectID": "posts/Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis.html#experiments",
    "href": "posts/Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis.html#experiments",
    "title": "Inter-X: Towards Versatile Human-Human Interaction Analysis",
    "section": "Experiments",
    "text": "Experiments\n\nReports experiments and evaluations for text-conditioned interaction generation, action-conditioned interaction generation, human reaction generation, and human interaction recognition."
  },
  {
    "objectID": "posts/Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis.html#conclusion-and-limitation",
    "href": "posts/Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis.html#conclusion-and-limitation",
    "title": "Inter-X: Towards Versatile Human-Human Interaction Analysis",
    "section": "Conclusion and Limitation",
    "text": "Conclusion and Limitation\n\nHighlights the contributions of the Inter-X dataset and acknowledges limitations in facial expressions and the duration of interactions."
  },
  {
    "objectID": "posts/Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis.html#appendix",
    "href": "posts/Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis.html#appendix",
    "title": "Inter-X: Towards Versatile Human-Human Interaction Analysis",
    "section": "Appendix",
    "text": "Appendix\n\nIncludes additional experiments, SMPL-X optimization details, the action categories, samples of textual annotations, and visualization results."
  },
  {
    "objectID": "posts/Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis.html#appendix-1",
    "href": "posts/Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X_Towards_Versatile_Human_Human_Interaction_Analysis.html#appendix-1",
    "title": "Inter-X: Towards Versatile Human-Human Interaction Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16051v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16051v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11982"
  },
  {
    "objectID": "posts/Distillation_is_All_You_Need_for_Practically_Using_Different_Pre_trained_Recommendation_Models/2024-01-01-Distillation_is_All_You_Need_for_Practically_Using_Different_Pre_trained_Recommendation_Models.html#appendix",
    "href": "posts/Distillation_is_All_You_Need_for_Practically_Using_Different_Pre_trained_Recommendation_Models/2024-01-01-Distillation_is_All_You_Need_for_Practically_Using_Different_Pre_trained_Recommendation_Models.html#appendix",
    "title": "Distillation is All You Need for Practically Using Different Pre-trained Recommendation Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00797v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00797v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11769"
  },
  {
    "objectID": "posts/Revealing_Networks_Understanding_Effective_Teacher_Practices_in_AI_Supported_Classrooms_using_Transmodal_Ordered_Network_Analysis/2023-12-17-Revealing_Networks_Understanding_Effective_Teacher_Practices_in_AI_Supported_Classrooms_using_Transmodal_Ordered_Network_Analysis.html#summary-of-revealing-networks-understanding-effective-teacher-practices-in-ai-supported-classrooms",
    "href": "posts/Revealing_Networks_Understanding_Effective_Teacher_Practices_in_AI_Supported_Classrooms_using_Transmodal_Ordered_Network_Analysis/2023-12-17-Revealing_Networks_Understanding_Effective_Teacher_Practices_in_AI_Supported_Classrooms_using_Transmodal_Ordered_Network_Analysis.html#summary-of-revealing-networks-understanding-effective-teacher-practices-in-ai-supported-classrooms",
    "title": "Revealing Networks: Understanding Effective Teacher Practices in AI-Supported Classrooms using Transmodal Ordered Network Analysis",
    "section": "Summary of “Revealing Networks: Understanding Effective Teacher Practices in AI-Supported Classrooms”",
    "text": "Summary of “Revealing Networks: Understanding Effective Teacher Practices in AI-Supported Classrooms”\n\nMajor Findings:\n\nThe study found that incorporating out-of-tutor teacher practices significantly improved the inference of student learning rates in AI tutors.\nStudents with low learning rates tended to exhibit more hint use after monitoring by the teacher, while after extended visits, these students showed learning behavior similar to their peers with high learning rates.\nQualitative analysis revealed that teacher support during screen monitoring and talking differed for students with low and high learning rates, with low learning rate students receiving more procedural support and high learning rate students receiving abstract support.\n\n\n\nBackground:\n\nLearning in AI-supported classrooms involves students learning with AI-based systems while the teacher facilitates learning. Prior work has found that the role of teacher practice for effective learning with AI tutors is understudied and there is a lack of studies analyzing student learning through the lens of teacher practices.\nMultimodal Learning Analytics (MMLA) integrates data from various modalities to understand learning processes, and quantitative ethnography methods are increasingly used in learning analytics to model complex dependencies between data sets.\n\n\n\nMethods:\n\nThe study used Transmodal Ordered Network Analysis to model temporal relationships between teacher practices and student learning in AI-supported classrooms.\nData sets included student interaction data with an AI tutor, classroom observation notes, and teacher spatial positions during classroom practice.\nFeature engineering involved creating codes for teacher practices and student behaviors and grouping students by their learning rates.\n\n\n\nResults:\n\nIncluding out-of-tutor teacher practices significantly improved the inference of student learning rates within the AI tutor.\nConnection patterns for students with low and high learning rates differed, with low learning rate students exhibiting more hint use after monitoring by the teacher.\nTeacher visits led to changes in student behavior, with low learning rate students exhibiting more desirable learning behavior after extended visits.\n\n\n\nDiscussion:\n\nThe study provides insights into the associations between teacher practices and student learning rates and the differential impact of teacher support on students with low and high learning rates.\nQualitative analysis revealed differences in the type of teacher support provided to students with low and high learning rates, suggesting potential areas for intervention and improvement.\n\n\n\nCritique:\n\nThe study relies heavily on observational and log data, which may not fully capture the complexity of teacher-student interactions and learning processes. There may be confounding variables or unobserved factors influencing the relationships identified.\nThe study does not address potential biases in the observation and coding of teacher practices, which could impact the validity of the findings.\n\nOverall, the study provides valuable insights into the role of teacher practices in AI-supported classrooms and highlights the potential for further research and intervention to improve learning outcomes."
  },
  {
    "objectID": "posts/Revealing_Networks_Understanding_Effective_Teacher_Practices_in_AI_Supported_Classrooms_using_Transmodal_Ordered_Network_Analysis/2023-12-17-Revealing_Networks_Understanding_Effective_Teacher_Practices_in_AI_Supported_Classrooms_using_Transmodal_Ordered_Network_Analysis.html#appendix",
    "href": "posts/Revealing_Networks_Understanding_Effective_Teacher_Practices_in_AI_Supported_Classrooms_using_Transmodal_Ordered_Network_Analysis/2023-12-17-Revealing_Networks_Understanding_Effective_Teacher_Practices_in_AI_Supported_Classrooms_using_Transmodal_Ordered_Network_Analysis.html#appendix",
    "title": "Revealing Networks: Understanding Effective Teacher Practices in AI-Supported Classrooms using Transmodal Ordered Network Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10826v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10826v1\n\n\nTruncated\nTrue\n\n\nWord Count\n15625"
  },
  {
    "objectID": "posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.html#major-takeaways",
    "href": "posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.html#major-takeaways",
    "title": "FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nEfficiency Enhancement: FlightLLM addresses the efficiency limitations of Large Language Models (LLMs) by leveraging FPGA-specific resources to achieve higher energy and cost efficiency compared to commercial GPUs.\nComplete Mapping Flow: The paper proposes a complete mapping flow for LLM inference on FPGAs, highlighting innovations in computation and memory overhead solutions.\nPerformance Comparison: FlightLLM outperforms SOTA accelerators, achieving better latency and throughput compared to GPUs and other FPGA-based accelerators."
  },
  {
    "objectID": "posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.html#abstract",
    "href": "posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.html#abstract",
    "title": "FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs",
    "section": "Abstract",
    "text": "Abstract\nThe paper introduces FlightLLM, a solution for efficient Large Language Model (LLM) inference on FPGAs. It addresses the challenges of heavy computation and memory overheads by leveraging FPGA-specific resources. FlightLLM achieves higher energy and cost efficiency compared to commercial GPUs and outperforms SOTA accelerators."
  },
  {
    "objectID": "posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.html#introduction",
    "href": "posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.html#introduction",
    "title": "FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs",
    "section": "Introduction",
    "text": "Introduction\n\nRecent developments in Large Language Models (LLMs) have highlighted their significant impact across various domains.\nLLMs are widely used in latency-sensitive scenarios, necessitating efficient computation and memory management.\nCompression techniques such as sparsification and quantization are employed to mitigate computation and memory overheads, but current hardware platforms struggle to efficiently support these methods."
  },
  {
    "objectID": "posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.html#background-and-related-work",
    "href": "posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.html#background-and-related-work",
    "title": "FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs",
    "section": "Background and Related Work",
    "text": "Background and Related Work\n\nTransformer-based LLMs achieve state-of-the-art performance across Natural Language Processing (NLP) tasks. The transformer model architecture consists of cascaded transformer blocks with Multi-Head Attention (MHA) and Feed Forward Network (FFN) networks.\nEfficient transformer models leverage compression techniques such as sparsification and quantization to reduce computation and memory overheads. Previous works have focused on specialized architectures to accelerate sparse attention and optimize linear layers with mixed-precision quantization."
  },
  {
    "objectID": "posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.html#computing-architecture",
    "href": "posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.html#computing-architecture",
    "title": "FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs",
    "section": "Computing Architecture",
    "text": "Computing Architecture\n\nFlightLLM’s overall architecture includes a task scheduler, memory controller, and multiple computing cores equipped with a unified Matrix Processing Engine (MPE), Memory Management Unit (MMU), Special Function Unit (SFU), and Instruction Scheduler.\nThe configurable sparse DSP chain and always-on-chip decode scheme enhance computation efficiency and memory bandwidth, while supporting different sparsity patterns. FlightLLM also supports mixed-precision quantization and length adaptive compilation to reduce instruction storage overhead."
  },
  {
    "objectID": "posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.html#always-on-chip-decode",
    "href": "posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.html#always-on-chip-decode",
    "title": "FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs",
    "section": "Always-on-chip Decode",
    "text": "Always-on-chip Decode\n\nThe on-chip decode scheme in FlightLLM enables efficient memory bandwidth utilization by keeping activations in on-chip memory during the decode stage, reducing frequent access to off-chip memory.\nMixed-precision support using a dedicated dequantization unit helps optimize compactly stored mixed-precision data and reduce memory access overhead."
  },
  {
    "objectID": "posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.html#length-adaptive-compilation",
    "href": "posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.html#length-adaptive-compilation",
    "title": "FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs",
    "section": "Length Adaptive Compilation",
    "text": "Length Adaptive Compilation\n\nFlightLLM proposes a length adaptive compilation approach to reduce the instruction storage overhead by allowing different lengths of prefill or decode to share the same instructions within threshold ranges, optimizing memory utilization."
  },
  {
    "objectID": "posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.html#analytical-model-for-rtl-generation",
    "href": "posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.html#analytical-model-for-rtl-generation",
    "title": "FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs",
    "section": "Analytical Model for RTL Generation",
    "text": "Analytical Model for RTL Generation\n\nFlightLLM uses an analytical model to optimize hardware resource utilization and dynamically adjust the computing parallelism and buffer size to generate corresponding RTL code for implementation on different FPGA platforms."
  },
  {
    "objectID": "posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.html#evaluation",
    "href": "posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.html#evaluation",
    "title": "FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs",
    "section": "Evaluation",
    "text": "Evaluation\n\nFlightLLM is evaluated on state-of-the-art LLMs such as OPT-6.7B and LLaMA2-7B, achieving better latency, throughput, energy efficiency, and cost efficiency compared to both commercial GPUs and SOTA accelerators.\nThe latency breakdown analysis and multi-batch performance comparisons highlight FlightLLM’s efficient hardware performance."
  },
  {
    "objectID": "posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.html#conclusion",
    "href": "posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.html#conclusion",
    "title": "FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs",
    "section": "Conclusion",
    "text": "Conclusion\nThe paper introduces FlightLLM as a promising approach for efficient LLM inference on FPGAs, enabling higher energy and cost efficiency compared to commercial GPUs and SOTA accelerators. FlightLLM demonstrates optimizations in computation efficiency, memory bandwidth utilization, and latency reductions, making it a competitive solution for LLM inference."
  },
  {
    "objectID": "posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.html#critique",
    "href": "posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.html#critique",
    "title": "FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs",
    "section": "Critique",
    "text": "Critique\n\nThe paper does not provide a detailed discussion of potential limitations or trade-offs with FlightLLM’s approach, which could help provide a more comprehensive understanding of its applicability and potential constraints.\nWhile the evaluation results are promising, it would be useful to compare FlightLLM’s performance against a wider range of FPGA-based LLM accelerators to provide a more comprehensive picture of its comparative advantages.\n\nOverall, the paper effectively presents FlightLLM as a compelling solution for efficient LLM inference, highlighting innovations in FPGA-based acceleration and performance optimizations."
  },
  {
    "objectID": "posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.html#appendix",
    "href": "posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.html#appendix",
    "title": "FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.03868v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.03868v2\n\n\nTruncated\nFalse\n\n\nWord Count\n12121"
  },
  {
    "objectID": "posts/Improved_decoding_of_expander_codes_fundamental_trade_off_between_expansion_ratio_and_minimum_distance_of_inner_code/2023-12-26-Improved_decoding_of_expander_codes_fundamental_trade_off_between_expansion_ratio_and_minimum_distance_of_inner_code.html#appendix",
    "href": "posts/Improved_decoding_of_expander_codes_fundamental_trade_off_between_expansion_ratio_and_minimum_distance_of_inner_code/2023-12-26-Improved_decoding_of_expander_codes_fundamental_trade_off_between_expansion_ratio_and_minimum_distance_of_inner_code.html#appendix",
    "title": "Improved decoding of expander codes: fundamental trade-off between expansion ratio and minimum distance of inner code",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16087v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16087v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13225"
  },
  {
    "objectID": "posts/Replica_Tree_based_Federated_Learning_using_Limited_Data/2023-12-28-Replica_Tree_based_Federated_Learning_using_Limited_Data.html#appendix",
    "href": "posts/Replica_Tree_based_Federated_Learning_using_Limited_Data/2023-12-28-Replica_Tree_based_Federated_Learning_using_Limited_Data.html#appendix",
    "title": "Replica Tree-based Federated Learning using Limited Data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17159v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17159v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8855"
  },
  {
    "objectID": "posts/VideoDrafter_Content_Consistent_Multi_Scene_Video_Generation_with_LLM/2024-01-02-VideoDrafter_Content_Consistent_Multi_Scene_Video_Generation_with_LLM.html#appendix",
    "href": "posts/VideoDrafter_Content_Consistent_Multi_Scene_Video_Generation_with_LLM/2024-01-02-VideoDrafter_Content_Consistent_Multi_Scene_Video_Generation_with_LLM.html#appendix",
    "title": "VideoDrafter: Content-Consistent Multi-Scene Video Generation with LLM",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01256v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01256v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9002"
  },
  {
    "objectID": "posts/Sparse_but_Strong_Crafting_Adversarially_Robust_Graph_Lottery_Tickets/2023-12-11-Sparse_but_Strong_Crafting_Adversarially_Robust_Graph_Lottery_Tickets.html#appendix",
    "href": "posts/Sparse_but_Strong_Crafting_Adversarially_Robust_Graph_Lottery_Tickets/2023-12-11-Sparse_but_Strong_Crafting_Adversarially_Robust_Graph_Lottery_Tickets.html#appendix",
    "title": "Sparse but Strong: Crafting Adversarially Robust Graph Lottery Tickets",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.06568v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.06568v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12768"
  },
  {
    "objectID": "posts/Advancing_TTP_Analysis_Harnessing_the_Power_of_Encoder_Only_and_Decoder_Only_Language_Models_with_Retrieval_Augmented_Generation/2023-12-30-Advancing_TTP_Analysis_Harnessing_the_Power_of_Encoder_Only_and_Decoder_Only_Language_Models_with_Retrieval_Augmented_Generation.html#appendix",
    "href": "posts/Advancing_TTP_Analysis_Harnessing_the_Power_of_Encoder_Only_and_Decoder_Only_Language_Models_with_Retrieval_Augmented_Generation/2023-12-30-Advancing_TTP_Analysis_Harnessing_the_Power_of_Encoder_Only_and_Decoder_Only_Language_Models_with_Retrieval_Augmented_Generation.html#appendix",
    "title": "Advancing TTP Analysis: Harnessing the Power of Encoder-Only and Decoder-Only Language Models with Retrieval Augmented Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00280v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00280v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8243"
  },
  {
    "objectID": "posts/Understanding_the_Instruction_Mixture_for_Large_Language_Model/2023-12-17-Understanding_the_Instruction_Mixture_for_Large_Language_Model.html#major-findings",
    "href": "posts/Understanding_the_Instruction_Mixture_for_Large_Language_Model/2023-12-17-Understanding_the_Instruction_Mixture_for_Large_Language_Model.html#major-findings",
    "title": "Understanding the Instruction Mixture for Large Language Model",
    "section": "Major Findings",
    "text": "Major Findings\n\nSpecific types of instructions are more beneficial for particular uses, while they may cause harm to other aspects.\nEvaluating models with diverse benchmarks and alignment skills yielded insights into the impact of different distributions of instruction datasets on model performance across diverse aspects.\nResults suggest that researchers should carefully design the instruction mixture to maximize the model’s performance on the target usage, taking model size into consideration."
  },
  {
    "objectID": "posts/Understanding_the_Instruction_Mixture_for_Large_Language_Model/2023-12-17-Understanding_the_Instruction_Mixture_for_Large_Language_Model.html#experimental-setup",
    "href": "posts/Understanding_the_Instruction_Mixture_for_Large_Language_Model/2023-12-17-Understanding_the_Instruction_Mixture_for_Large_Language_Model.html#experimental-setup",
    "title": "Understanding the Instruction Mixture for Large Language Model",
    "section": "Experimental Setup",
    "text": "Experimental Setup\n\nSupervised fine-tuning (SFT) has been proven to be an effective approach to align large language models (LLMs) with human instructions, enhancing downstream task performance and facilitating code generation.\nThe study focused on evaluating the model’s performance in three key areas: NLP downstream task performance, coding ability, and chat capabilities.\nExperiments were conducted using eight different mixture settings involving instruction datasets for NLP downstream tasks, code generation, and general-purpose instructions."
  },
  {
    "objectID": "posts/Understanding_the_Instruction_Mixture_for_Large_Language_Model/2023-12-17-Understanding_the_Instruction_Mixture_for_Large_Language_Model.html#results",
    "href": "posts/Understanding_the_Instruction_Mixture_for_Large_Language_Model/2023-12-17-Understanding_the_Instruction_Mixture_for_Large_Language_Model.html#results",
    "title": "Understanding the Instruction Mixture for Large Language Model",
    "section": "Results",
    "text": "Results\n\nDifferent types of specialized instructions improved the performance on the benchmarks they were designed for.\nIncorporating general instructions consistently improved coding performance, and larger models could better leverage various instructions.\nThe mixture of instruction datasets had a significant impact on alignment skills, with general instructions providing better alignment skills and performance on NLP benchmarks."
  },
  {
    "objectID": "posts/Understanding_the_Instruction_Mixture_for_Large_Language_Model/2023-12-17-Understanding_the_Instruction_Mixture_for_Large_Language_Model.html#critique",
    "href": "posts/Understanding_the_Instruction_Mixture_for_Large_Language_Model/2023-12-17-Understanding_the_Instruction_Mixture_for_Large_Language_Model.html#critique",
    "title": "Understanding the Instruction Mixture for Large Language Model",
    "section": "Critique",
    "text": "Critique\nThe paper’s potential limitations include: - Limited use of only LLaMA-2 7B and 13B models in the experiments, with the need for verification using different sizes of models. - The restriction to a specific instruction dataset size and mainly comparing the 1:1 ratio of all instruction types, leaving the exploration of the impact of more instructions and mixing ratios for future research.\nIt is important to consider the potential variability in model behavior across different sizes and explore the impact of different instruction dataset sizes and mixing ratios on LLMs’ performance for comprehensive understanding."
  },
  {
    "objectID": "posts/Understanding_the_Instruction_Mixture_for_Large_Language_Model/2023-12-17-Understanding_the_Instruction_Mixture_for_Large_Language_Model.html#appendix",
    "href": "posts/Understanding_the_Instruction_Mixture_for_Large_Language_Model/2023-12-17-Understanding_the_Instruction_Mixture_for_Large_Language_Model.html#appendix",
    "title": "Understanding the Instruction Mixture for Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10793v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10793v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4269"
  },
  {
    "objectID": "posts/CXL_and_the_Return_of_Scale_Up_Database_Engines/2024-01-02-CXL_and_the_Return_of_Scale_Up_Database_Engines.html#appendix",
    "href": "posts/CXL_and_the_Return_of_Scale_Up_Database_Engines/2024-01-02-CXL_and_the_Return_of_Scale_Up_Database_Engines.html#appendix",
    "title": "CXL and the Return of Scale-Up Database Engines",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01150v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01150v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9476"
  },
  {
    "objectID": "posts/Generalist_embedding_models_are_better_at_short_context_clinical_semantic_search_than_specialized_embedding_models/2024-01-03-Generalist_embedding_models_are_better_at_short_context_clinical_semantic_search_than_specialized_embedding_models.html#appendix",
    "href": "posts/Generalist_embedding_models_are_better_at_short_context_clinical_semantic_search_than_specialized_embedding_models/2024-01-03-Generalist_embedding_models_are_better_at_short_context_clinical_semantic_search_than_specialized_embedding_models.html#appendix",
    "title": "Generalist embedding models are better at short-context clinical semantic search than specialized embedding models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01943v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01943v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4480"
  },
  {
    "objectID": "posts/LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#major-takeaways",
    "href": "posts/LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#major-takeaways",
    "title": "LLMEval: A Preliminary Study on How to Evaluate Large Language Models",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nThe evaluation of Large Language Models (LLMs) has become a prominent area of research, with a focus on determining how to assess their capabilities and limitations.\nExisting research primarily addresses “what” tasks to assign and “where” to evaluate LLMs, but less attention has been given to determining “how” to evaluate, including scoring methods, ranking systems, and type of annotators to use.\nThe study analyzes evaluation methods by comparing various criteria, different types of annotators, rating methods, and ranking approaches. It also introduces a new dataset, LLMEval, and provides insights for future LLM evaluation."
  },
  {
    "objectID": "posts/LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#introduction",
    "href": "posts/LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#introduction",
    "title": "LLMEval: A Preliminary Study on How to Evaluate Large Language Models",
    "section": "Introduction",
    "text": "Introduction\n\nIntroduction to the emergence of LLMs as a significant area of research and the need to assess their performance and limitations.\nExisting research focuses on “what” tasks and “where” to evaluate LLMs, but little has been discussed about “how” to evaluate, including scoring methods, ranking systems, and annotator types.\nStudy’s emphasis on evaluating LLMs using various criteria, different types of annotators, rating methods, and ranking approaches, leading to the introduction of the LLMEval dataset."
  },
  {
    "objectID": "posts/LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#design",
    "href": "posts/LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#design",
    "title": "LLMEval: A Preliminary Study on How to Evaluate Large Language Models",
    "section": "Design",
    "text": "Design\n\nCriteria: The paper introduced new criteria for evaluating LLMs, including accuracy, fluency, informativeness, logical coherence, and harmlessness.\nAnnotation Method: The study employed star scoring for onsite annotators, pairwise comparison for crowd-sourcing and public annotators, and GPT-4 for automatic evaluation. It found onsite evaluations to exhibit superior accuracy and consistency.\nRanking System: The study compared the Elo rating system and the Points scoring system for evaluating LLMs, noting poor stability with the Elo rating system."
  },
  {
    "objectID": "posts/LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#experiments",
    "href": "posts/LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#experiments",
    "title": "LLMEval: A Preliminary Study on How to Evaluate Large Language Models",
    "section": "Experiments",
    "text": "Experiments\n\nDataset: The study utilized two datasets, LLMEval-1 and LLMEval-2, to evaluate LLMs across various tasks and subjects.\nMetrics: Accuracy and consistency were used to assess the annotation methods, with a focus on alignment between manual and automated evaluation."
  },
  {
    "objectID": "posts/LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#results",
    "href": "posts/LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#results",
    "title": "LLMEval: A Preliminary Study on How to Evaluate Large Language Models",
    "section": "Results",
    "text": "Results\n\nComparison of Criteria: Findings showed that accuracy and informativeness are the most distinguishing criteria, and that conversation tasks best differentiate model capabilities.\nComparison of Annotation Methods: Onsite annotators demonstrated the best quality in terms of accuracy and consistency, while public annotators exhibited the lowest level of consistency and accuracy.\nComparison of Ranking Systems: The Elo rating system exhibited significant instability and sequence dependence, and was sensitive to the order of matches."
  },
  {
    "objectID": "posts/LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#discussion",
    "href": "posts/LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#discussion",
    "title": "LLMEval: A Preliminary Study on How to Evaluate Large Language Models",
    "section": "Discussion",
    "text": "Discussion\n\nThe study emphasizes the need to prioritize informativeness and accuracy in future evaluations, considers onsite evaluations as optimal, and suggests automated evaluation as a complementary approach. It also highlights the challenges in evaluating LLMs in subjective questions."
  },
  {
    "objectID": "posts/LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#appendix",
    "href": "posts/LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#appendix",
    "title": "LLMEval: A Preliminary Study on How to Evaluate Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\nThe study provides detailed implementation, including dataset specifics, mathematical proof of Elo rating instability, details of LLMEval-1 and LLMEval-2, and the implementation of scoring and ranking systems."
  },
  {
    "objectID": "posts/LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#critique",
    "href": "posts/LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#critique",
    "title": "LLMEval: A Preliminary Study on How to Evaluate Large Language Models",
    "section": "Critique",
    "text": "Critique\nThe paper provides a comprehensive analysis of LLM evaluation methods, but it lacks a discussion on potential biases in the dataset, such as language-specific nuances or biases introduced by the annotators. Additionally, the paper could benefit from a more in-depth comparison to existing evaluation methods and a broader discussion of the limitations of the proposed evaluation framework."
  },
  {
    "objectID": "posts/LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#appendix-1",
    "href": "posts/LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval_A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#appendix-1",
    "title": "LLMEval: A Preliminary Study on How to Evaluate Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.07398v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.07398v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12912"
  },
  {
    "objectID": "posts/The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model.html#major-findings",
    "href": "posts/The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model.html#major-findings",
    "title": "The Right Prompts for the Job: Repair Code-Review Defects with Large Language Model",
    "section": "Major Findings",
    "text": "Major Findings\n\nLimited accuracy and considerable time costs associated with existing Automatic Program Repair (APR) techniques hinder their adoption in industrial practice.\nAdvanced Large Language Models (LLMs) can comprehend natural and programming languages, making them capable of generating patches based on review comments, demonstrating a remarkable repair rate of 72.97% with the best prompt.\nIncorporating review comments and fix ranges significantly aids in repairing Code Review (CR) defects, leading to progressive enhancement in the models’ ability to address the defects."
  },
  {
    "objectID": "posts/The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model.html#introduction",
    "href": "posts/The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model.html#introduction",
    "title": "The Right Prompts for the Job: Repair Code-Review Defects with Large Language Model",
    "section": "Introduction",
    "text": "Introduction\n\nContinuous Integration/Continuous Deployment (CI/CD) pipelines control the software development process, with Code Review (CR) serving as a pivotal node.\nAutomatic Program Repair (APR) aims to offer a fully automated solution for defect repair, but its inherent time-consuming nature poses challenges for integration within time-sensitive CI/CD pipelines.\nLimitations of traditional approaches (search-based, constraint-based, and template-based methods) in effectively utilizing the insights from review comments expressed in natural language led to the exploration of AI-based APR approaches with Large Language Models (LLMs)."
  },
  {
    "objectID": "posts/The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model.html#code-review",
    "href": "posts/The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model.html#code-review",
    "title": "The Right Prompts for the Job: Repair Code-Review Defects with Large Language Model",
    "section": "Code Review",
    "text": "Code Review\n\nDefect identification process involves human reviewers and automated checkers, with both providing comments describing identified defects and, in some cases, offering suggestions on rectifying them."
  },
  {
    "objectID": "posts/The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model.html#repairing",
    "href": "posts/The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model.html#repairing",
    "title": "The Right Prompts for the Job: Repair Code-Review Defects with Large Language Model",
    "section": "Repairing",
    "text": "Repairing\n\nDefect repair predominantly relies on manual effort, calling for the need for a semi-automated paradigm to leverage APR techniques effectively in the CR process.\nTraditional approaches face challenges in effectively utilizing information from review comments. AI-based APR approaches with LLMs are seen as a promising solution to effectively address the underlying problem."
  },
  {
    "objectID": "posts/The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model.html#research-questions-and-experiment-settings",
    "href": "posts/The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model.html#research-questions-and-experiment-settings",
    "title": "The Right Prompts for the Job: Repair Code-Review Defects with Large Language Model",
    "section": "Research Questions and Experiment Settings",
    "text": "Research Questions and Experiment Settings\n\nEffectiveness of LLMs: Explored using various LLMs for repairing CR defects using zero-shot learning or finetuning.\nImpact of different prompts: Investigated the performance of LLMs with different prompts containing varied information.\nPerformance of LLMs in repairing defects varying with different model sizes.\nImpact of different datasets: Explored the capacity to rectify defects and interchangeably employ these datasets."
  },
  {
    "objectID": "posts/The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model.html#experiment-results",
    "href": "posts/The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model.html#experiment-results",
    "title": "The Right Prompts for the Job: Repair Code-Review Defects with Large Language Model",
    "section": "Experiment Results",
    "text": "Experiment Results\n\nOverall Effectiveness (RQ1)\n\nZero-shot learning resulted in improved repair rates using review comments.\nDesigned prompts demonstrated that review comments and fix ranges were the most effective prompts.\nModel performance improves with successive prompts, with the best performance achieved in prompt P7.\n\nPrompt Comparison (RQ2)\n\nOverall improvement in ECM from prompt P3 to P7, showcasing the incremental benefits of incorporating different cues.\n\nModel Size Comparison (RQ3)\n\nGradual increases noticed in both ECM and Code BLEU scores as the model sizes increase, with 6-7B LLMs showing a favorable balance between efficiency and effectiveness.\n\nImpacts of Datasets (RQ4)\n\nOptimal performance achieved when finetuning and evaluating models on the appropriate datasets, highlighting the necessity of diverse datasets in the finetuning process."
  },
  {
    "objectID": "posts/The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model.html#critique",
    "href": "posts/The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model.html#critique",
    "title": "The Right Prompts for the Job: Repair Code-Review Defects with Large Language Model",
    "section": "Critique",
    "text": "Critique\n\nThe study focuses on a specific range of LLMs and model sizes, potentially limiting the generalizability of the findings to other models in the open source community.\nThe study acknowledges the necessity of ensuring data quality but does not delve into potential biases in the datasets that could affect model performance.\n\nOverall, the study provides valuable insights into leveraging LLMs for repairing CR defects, highlighting the importance of review comments and fix ranges in improving the effectiveness of APR techniques. Further research could explore the potential biases in the datasets and consider a wider range of LLMs to enhance the generalizability of the findings."
  },
  {
    "objectID": "posts/The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model.html#appendix",
    "href": "posts/The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job_Repair_Code_Review_Defects_with_Large_Language_Model.html#appendix",
    "title": "The Right Prompts for the Job: Repair Code-Review Defects with Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17485v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17485v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12983"
  },
  {
    "objectID": "posts/On_Inference_Stability_for_Diffusion_Models/2023-12-19-On_Inference_Stability_for_Diffusion_Models.html#appendix",
    "href": "posts/On_Inference_Stability_for_Diffusion_Models/2023-12-19-On_Inference_Stability_for_Diffusion_Models.html#appendix",
    "title": "On Inference Stability for Diffusion Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.12431v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.12431v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6949"
  },
  {
    "objectID": "posts/Scaling_Down_LiTting_Up_Efficient_Zero_Shot_Listwise_Reranking_with_Seq2seq_Encoder_Decoder_Models/2023-12-26-Scaling_Down_LiTting_Up_Efficient_Zero_Shot_Listwise_Reranking_with_Seq2seq_Encoder_Decoder_Models.html#appendix",
    "href": "posts/Scaling_Down_LiTting_Up_Efficient_Zero_Shot_Listwise_Reranking_with_Seq2seq_Encoder_Decoder_Models/2023-12-26-Scaling_Down_LiTting_Up_Efficient_Zero_Shot_Listwise_Reranking_with_Seq2seq_Encoder_Decoder_Models.html#appendix",
    "title": "Scaling Down, LiTting Up: Efficient Zero-Shot Listwise Reranking with Seq2seq Encoder-Decoder Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16098v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16098v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8529"
  },
  {
    "objectID": "posts/Uncertainty_Penalized_Reinforcement_Learning_from_Human_Feedback_with_Diverse_Reward_LoRA_Ensembles/2023-12-30-Uncertainty_Penalized_Reinforcement_Learning_from_Human_Feedback_with_Diverse_Reward_LoRA_Ensembles.html#appendix",
    "href": "posts/Uncertainty_Penalized_Reinforcement_Learning_from_Human_Feedback_with_Diverse_Reward_LoRA_Ensembles/2023-12-30-Uncertainty_Penalized_Reinforcement_Learning_from_Human_Feedback_with_Diverse_Reward_LoRA_Ensembles.html#appendix",
    "title": "Uncertainty-Penalized Reinforcement Learning from Human Feedback with Diverse Reward LoRA Ensembles",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00243v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00243v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6956"
  },
  {
    "objectID": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded.html#major-takeaways",
    "href": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded.html#major-takeaways",
    "title": "GPT-4V(ision) is a Generalist Web Agent, if Grounded",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nLMMs like GPT-4V have great potential as generalist web agents, outperforming text-only LLMs like GPT-4 and smaller models specifically fine-tuned for web agents in completing tasks on live websites.\nGrounding, especially element grounding, remains a substantial challenge, with the best strategies still exhibiting a performance gap with oracle grounding. Grounding via textual choices was the most effective approach, outperforming image annotation strategies, but still faced challenges with identical elements on webpages.\nIn-context learning (ICL) with large models showed better generalization to unseen websites compared to supervised fine-tuning (SFT) methods, making it a more compelling solution for generalist web agents, especially in scenarios lacking annotations or requiring strong generalization capabilities."
  },
  {
    "objectID": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded.html#introduction",
    "href": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded.html#introduction",
    "title": "GPT-4V(ision) is a Generalist Web Agent, if Grounded",
    "section": "Introduction",
    "text": "Introduction\nThe paper explores the potential of LMMs as generalist web agents, defining generalist web agents as those that can follow natural language instructions and complete tasks on any real-world website."
  },
  {
    "objectID": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded.html#seeact",
    "href": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded.html#seeact",
    "title": "GPT-4V(ision) is a Generalist Web Agent, if Grounded",
    "section": "SeeAct",
    "text": "SeeAct\n\nAims to investigate the capabilities of GPT-4V as a generalist web agent by generating action descriptions and identifying webpage elements for completing tasks on websites.\nFormulation includes two essential capabilities: Action Generation and Element Grounding for identifying HTML elements at each step."
  },
  {
    "objectID": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded.html#experiments",
    "href": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded.html#experiments",
    "title": "GPT-4V(ision) is a Generalist Web Agent, if Grounded",
    "section": "Experiments",
    "text": "Experiments\n\nDataset: Evaluated on the Mind2Web benchmark, encompassing over 2,000 tasks on real-world websites.\nMethods: SeeAct, baselines such as FLAN-T5 and BLIP2-T5, and in-context learning methods using GPT-3.5 and GPT-4 are compared.\nOffline Evaluation: Shows potential of GPT-4V as a web agent with oracle grounding method achieving notable success rates, but still exhibiting a substantial gap with proposed strategies. In-context learning methods demonstrate better generalization to unseen websites compared to supervised fine-tuning methods.\nOnline Evaluation: Demonstrates a substantial discrepancy with offline evaluations, indicating that multiple viable plans for the same task impact model performance."
  },
  {
    "objectID": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded.html#results-and-analysis",
    "href": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded.html#results-and-analysis",
    "title": "GPT-4V(ision) is a Generalist Web Agent, if Grounded",
    "section": "Results and Analysis",
    "text": "Results and Analysis\n\nWhole Task Success Rate: SeeActChoice outperforms existing methods on live websites, showcasing its potential as a generalist web agent. Surpassed fine-tuned models like FLAN-T5-XL in online evaluation, despite showing lower step success rates in offline evaluation.\nError Analysis: Showed challenges in grounding via textual choices and image annotation, with challenges of identical elements and hallucination errors.\nKnowledge and Reasoning: Tasks requiring knowledge and reasoning displayed GPT-4V’s capabilities in identifying specific details like IATA codes and geographic locations.\nPath Variation and Error Correction: Demonstrates the model’s flexibility in finding alternative paths to task completion and awareness of error correction during the task."
  },
  {
    "objectID": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded.html#critique",
    "href": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded.html#critique",
    "title": "GPT-4V(ision) is a Generalist Web Agent, if Grounded",
    "section": "Critique",
    "text": "Critique\n\nThe major findings are promising, but the discrepancy between offline and online evaluations raises questions about the robustness of the evaluation protocols and the need for better alignment between the two.\nThe focus on the specific dataset Mind2Web and the limited subset used for experiments may limit the generalizability of the findings.\n\nOverall, the paper provides valuable insights into the potential of large multimodal models as generalist web agents and highlights the challenges and future research directions in this domain. It opens up discussions on the practical implications and ethical considerations of deploying such models in real-world web environments."
  },
  {
    "objectID": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded.html#appendix",
    "href": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent_if_Grounded.html#appendix",
    "title": "GPT-4V(ision) is a Generalist Web Agent, if Grounded",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01614v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01614v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12123"
  },
  {
    "objectID": "posts/A_Precoding_for_ORIS_Assisted_MIMO_Multi_User_VLC_System/2023-12-13-A_Precoding_for_ORIS_Assisted_MIMO_Multi_User_VLC_System.html#appendix",
    "href": "posts/A_Precoding_for_ORIS_Assisted_MIMO_Multi_User_VLC_System/2023-12-13-A_Precoding_for_ORIS_Assisted_MIMO_Multi_User_VLC_System.html#appendix",
    "title": "A Precoding for ORIS-Assisted MIMO Multi-User VLC System",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.08214v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.08214v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4026"
  },
  {
    "objectID": "posts/Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models/2024-01-02-Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models.html#major-takeaways",
    "href": "posts/Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models/2024-01-02-Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models.html#major-takeaways",
    "title": "Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nSPIN: Self-Play fIne-tuNing method starts from a supervised fine-tuned model and employs a self-play mechanism to eliminate the need for human or AI feedback. It progressively enhances the LLM’s performance by distinguishing between responses generated by itself and those generated by humans.\nPerformance Improvement: SPIN significantly improves LLM’s performance across various benchmark datasets, even outperforming models trained with additional human data or AI feedback.\nComparison with DPO: SPIN achieves comparable or better performance compared to models trained with additional data sources, showing its effectiveness in leveraging existing data for improvement."
  },
  {
    "objectID": "posts/Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models/2024-01-02-Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models.html#introduction",
    "href": "posts/Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models/2024-01-02-Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models.html#introduction",
    "title": "Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models",
    "section": "Introduction",
    "text": "Introduction\n\nLarge Language Models (LLMs) have shown remarkable capabilities in various domains but typically rely on costly human-annotated data for alignment methods like Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF).\nThere is a growing interest in fine-tuning methods that can effectively utilize human data and convert weak LLMs to strong ones without additional training data."
  },
  {
    "objectID": "posts/Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models/2024-01-02-Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models.html#problem-setting-and-preliminaries",
    "href": "posts/Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models/2024-01-02-Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models.html#problem-setting-and-preliminaries",
    "title": "Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models",
    "section": "Problem Setting and Preliminaries",
    "text": "Problem Setting and Preliminaries\n\nDescribes LLM parameterization, supervised fine-tuning, and RL fine-tuning to enhance LLM capabilities in specific downstream tasks."
  },
  {
    "objectID": "posts/Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models/2024-01-02-Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models.html#method",
    "href": "posts/Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models/2024-01-02-Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models.html#method",
    "title": "Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models",
    "section": "Method",
    "text": "Method\n\nSelf-Play Fine-Tuning (SPIN): The method employs a self-play mechanism where a main player (LLM) is refined to distinguish its responses from human responses. The opponent player is an instance of the LLM from the previous iteration, and the method iteratively aligns the LLM with the target data distribution."
  },
  {
    "objectID": "posts/Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models/2024-01-02-Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models.html#related-work",
    "href": "posts/Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models/2024-01-02-Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models.html#related-work",
    "title": "Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models",
    "section": "Related Work",
    "text": "Related Work\n\nCompares SPIN to self-play in Multi-Agent Reinforcement Learning, synthetic data for LLMs, and curriculum learning in deep learning."
  },
  {
    "objectID": "posts/Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models/2024-01-02-Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models.html#theoretical-analysis",
    "href": "posts/Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models/2024-01-02-Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models.html#theoretical-analysis",
    "title": "Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models",
    "section": "Theoretical Analysis",
    "text": "Theoretical Analysis\n\nProves that the global optimum of SPIN is achieved when the LLM’s distribution is identical to the target data distribution."
  },
  {
    "objectID": "posts/Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models/2024-01-02-Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models.html#experiments",
    "href": "posts/Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models/2024-01-02-Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models.html#experiments",
    "title": "Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models",
    "section": "Experiments",
    "text": "Experiments\n\nShows experimental results on various benchmark datasets and compares SPIN with other training methods, demonstrating its effectiveness and robustness."
  },
  {
    "objectID": "posts/Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models/2024-01-02-Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models.html#conclusion-and-discussion",
    "href": "posts/Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models/2024-01-02-Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models.html#conclusion-and-discussion",
    "title": "Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models",
    "section": "Conclusion and Discussion",
    "text": "Conclusion and Discussion\n\nDiscusses limitations of the study and points out potential future directions for improving LLM performance."
  },
  {
    "objectID": "posts/Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models/2024-01-02-Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models.html#appendix-a-experiment-details",
    "href": "posts/Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models/2024-01-02-Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models.html#appendix-a-experiment-details",
    "title": "Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models",
    "section": "Appendix A: Experiment Details",
    "text": "Appendix A: Experiment Details\n\nProvides detailed hyperparameters and implementation details, including the generation examples of fine-tuned models by SPIN."
  },
  {
    "objectID": "posts/Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models/2024-01-02-Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models.html#appendix-b-proof-of-theorems",
    "href": "posts/Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models/2024-01-02-Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models.html#appendix-b-proof-of-theorems",
    "title": "Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models",
    "section": "Appendix B: Proof of Theorems",
    "text": "Appendix B: Proof of Theorems\n\nIncludes the proofs for the theoretical analysis conducted in the paper."
  },
  {
    "objectID": "posts/Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models/2024-01-02-Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models.html#appendix",
    "href": "posts/Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models/2024-01-02-Self_Play_Fine_Tuning_Converts_Weak_Language_Models_to_Strong_Language_Models.html#appendix",
    "title": "Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01335v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01335v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10807"
  },
  {
    "objectID": "posts/Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach/2024-01-02-Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach.html#major-takeaways",
    "href": "posts/Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach/2024-01-02-Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach.html#major-takeaways",
    "title": "Joint Offloading and Resource Allocation for Hybrid Cloud and Edge Computing in SAGINs: A Decision Assisted Hybrid Action Space Deep Reinforcement Learning Approach",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nThe paper introduces a deep reinforcement learning (DRL)-based approach for joint optimization of offloading and resource allocation in hybrid cloud and multi-access edge computing (MEC) scenarios within space-air-ground integrated networks (SAGINs).\nThe proposed algorithm leverages a decision-assisted hybrid multi-agent soft actor-critic (SAC) algorithm to optimize offloading strategy and resource allocation in the MEC infrastructure within SAGIN, achieving energy consumption reduction and latency minimization.\nSimulation results demonstrate the efficacy of the proposed learning-based scheme, outperforming benchmark methods and highlighting its superior performance and potential for practical applications."
  },
  {
    "objectID": "posts/Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach/2024-01-02-Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach.html#i-introduction",
    "href": "posts/Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach/2024-01-02-Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach.html#i-introduction",
    "title": "Joint Offloading and Resource Allocation for Hybrid Cloud and Edge Computing in SAGINs: A Decision Assisted Hybrid Action Space Deep Reinforcement Learning Approach",
    "section": "I Introduction",
    "text": "I Introduction\n\nI-A Background\n\nSatellite communication has become integral for global communication systems, leading to the emergence of space-air-ground integrated networks (SAGINs).\nMulti-access edge computing (MEC) in wireless communications aims to meet the increasing demand for low-latency and high-bandwidth applications and services.\nPrevious work has explored the benefits of integrating satellite communication within MEC frameworks, but does not address dynamic grouping and access capabilities of UAVs within the aerial layer, and the substantial computational power provided by cloud servers.\n\n\n\nI-B Related Work\n\nPrevious research has explored the advantages of integrating satellite communication within MEC frameworks and studied the performance of MEC under the SAGIN architecture.\nA range of DRL-based algorithms and resource allocation methods have been proposed for optimizing MEC frameworks in SAGINs.\n\n\n\nI-C Motivation and Contributions\n\nThe paper addresses a research gap by integrating dynamic access capability of UAVs, multi-satellite access in hybrid cloud environments, cloud service selection and MEC resource allocation simultaneously.\nContributions include multi-task scheduling based on Directed Acyclic Graphs (DAGs) and consideration of partial offloading, task dependency and cloud selection in MEC."
  },
  {
    "objectID": "posts/Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach/2024-01-02-Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach.html#ii-system-model-and-problem-formulation",
    "href": "posts/Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach/2024-01-02-Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach.html#ii-system-model-and-problem-formulation",
    "title": "Joint Offloading and Resource Allocation for Hybrid Cloud and Edge Computing in SAGINs: A Decision Assisted Hybrid Action Space Deep Reinforcement Learning Approach",
    "section": "II System Model and Problem Formulation",
    "text": "II System Model and Problem Formulation\n\nThe system model encompasses ground users, UAVs, LEO satellites, cloud servers, and considers communication, LEO coverage, and computation models.\nTwo optimization problems are formulated: minimizing overall energy consumption while satisfying latency constraints, and minimizing average latency while satisfying energy consumption constraints."
  },
  {
    "objectID": "posts/Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach/2024-01-02-Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach.html#iii-decision-assisted-hybrid-action-space-drl-based-optimization",
    "href": "posts/Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach/2024-01-02-Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach.html#iii-decision-assisted-hybrid-action-space-drl-based-optimization",
    "title": "Joint Offloading and Resource Allocation for Hybrid Cloud and Edge Computing in SAGINs: A Decision Assisted Hybrid Action Space Deep Reinforcement Learning Approach",
    "section": "III Decision-Assisted Hybrid Action Space DRL-Based Optimization",
    "text": "III Decision-Assisted Hybrid Action Space DRL-Based Optimization\n\nIII-A SAC Algorithm for MEC in SAGIN\n\nThe proposed algorithm leverages the Soft Actor-Critic (SAC) algorithm to optimize offloading and resource allocation in MEC within SAGIN, with reward functions designed for each optimization problem.\nThe SAC algorithm is utilized for long-term optimization and non-convex problems, addressing the challenge of hybrid discrete-continuous action spaces.\n\n\n\nIII-B Hybrid Action Space SAC Algorithm\n\nAction decoupling is introduced to address the hybrid discrete-continuous action space challenges, allowing agents to focus on specific aspects of optimization, facilitating collaborative training.\nThe hybrid action space SAC algorithm effectively addresses the challenges of the hybrid action space in the proposed optimization problems.\n\n\n\nIII-C Decision-Assisted DRL\n\nThe decision-assisted DRL algorithm is introduced to mitigate the negative impact of unavailable actions on the training process of DRL, utilizing prior knowledge in deep learning to train neural networks.\nThe algorithm reduces the exploration range for agents and improves convergence efficiency."
  },
  {
    "objectID": "posts/Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach/2024-01-02-Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach.html#iv-simulation-results",
    "href": "posts/Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach/2024-01-02-Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach.html#iv-simulation-results",
    "title": "Joint Offloading and Resource Allocation for Hybrid Cloud and Edge Computing in SAGINs: A Decision Assisted Hybrid Action Space Deep Reinforcement Learning Approach",
    "section": "IV Simulation Results",
    "text": "IV Simulation Results\n\nSimulation results demonstrate the superior performance of the proposed DM-SAC-H algorithm in minimizing energy consumption and average latency, outperforming benchmark methods in various scenarios."
  },
  {
    "objectID": "posts/Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach/2024-01-02-Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach.html#v-conclusion",
    "href": "posts/Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach/2024-01-02-Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach.html#v-conclusion",
    "title": "Joint Offloading and Resource Allocation for Hybrid Cloud and Edge Computing in SAGINs: A Decision Assisted Hybrid Action Space Deep Reinforcement Learning Approach",
    "section": "V Conclusion",
    "text": "V Conclusion\n\nCritique and Potential Problems\n\nThe paper provides a comprehensive approach to joint offloading and resource allocation, but further validation in real-world deployments would enhance the practical applicability of the proposed algorithm.\nThe simulation results showcase the effectiveness of the proposed algorithm, but further comparative studies with additional state-of-the-art algorithms would strengthen the paper’s contributions.\n\nThe paper presents an in-depth investigation into joint offloading and resource allocation in hybrid cloud and MEC environments within SAGINs, demonstrating the efficacy of the proposed decision-assisted hybrid action space DRL approach through comprehensive simulation results. Further real-world validation and comparative studies would enhance the robustness and applicability of the proposed algorithm."
  },
  {
    "objectID": "posts/Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach/2024-01-02-Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach.html#appendix",
    "href": "posts/Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach/2024-01-02-Joint_Offloading_and_Resource_Allocation_for_Hybrid_Cloud_and_Edge_Computing_in_SAGINs_A_Decision_Assisted_Hybrid_Action_Space_Deep_Reinforcement_Learning_Approach.html#appendix",
    "title": "Joint Offloading and Resource Allocation for Hybrid Cloud and Edge Computing in SAGINs: A Decision Assisted Hybrid Action Space Deep Reinforcement Learning Approach",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01140v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01140v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12913"
  },
  {
    "objectID": "posts/De_Hallucinator_Iterative_Grounding_for_LLM_Based_Code_Completion/2024-01-03-De_Hallucinator_Iterative_Grounding_for_LLM_Based_Code_Completion.html#takeaways",
    "href": "posts/De_Hallucinator_Iterative_Grounding_for_LLM_Based_Code_Completion/2024-01-03-De_Hallucinator_Iterative_Grounding_for_LLM_Based_Code_Completion.html#takeaways",
    "title": "De-Hallucinator: Iterative Grounding for LLM-Based Code Completion",
    "section": "Takeaways",
    "text": "Takeaways\n\nLarge language models (LLMs) have been successful in code completion, but they lack knowledge of project-specific APIs, resulting in inaccurate completions and “hallucinated” code.\nDe-Hallucinator addresses this challenge by iteratively querying the LLM with increasingly suitable context information, thus improving the predicted code and recall of correctly predicted API usages.\nThe approach is language-agnostic and designed to work with any off-the-shelf LLM trained on code, making it a versatile solution for improving code completion accuracy."
  },
  {
    "objectID": "posts/De_Hallucinator_Iterative_Grounding_for_LLM_Based_Code_Completion/2024-01-03-De_Hallucinator_Iterative_Grounding_for_LLM_Based_Code_Completion.html#introduction",
    "href": "posts/De_Hallucinator_Iterative_Grounding_for_LLM_Based_Code_Completion/2024-01-03-De_Hallucinator_Iterative_Grounding_for_LLM_Based_Code_Completion.html#introduction",
    "title": "De-Hallucinator: Iterative Grounding for LLM-Based Code Completion",
    "section": "Introduction",
    "text": "Introduction\n\nLarge language models (LLMs) have shown promise in code completion tasks, but they lack project-specific API knowledge, leading to incomplete and inaccurate code predictions."
  },
  {
    "objectID": "posts/De_Hallucinator_Iterative_Grounding_for_LLM_Based_Code_Completion/2024-01-03-De_Hallucinator_Iterative_Grounding_for_LLM_Based_Code_Completion.html#approach",
    "href": "posts/De_Hallucinator_Iterative_Grounding_for_LLM_Based_Code_Completion/2024-01-03-De_Hallucinator_Iterative_Grounding_for_LLM_Based_Code_Completion.html#approach",
    "title": "De-Hallucinator: Iterative Grounding for LLM-Based Code Completion",
    "section": "Approach",
    "text": "Approach\n\nStatic Pre-Analysis\n\nThe approach utilizes CodeQL to statically analyze code and extract API references for fast retrieval during the code completion process. The extracted API references are then indexed for efficient querying.\n\n\n\nRetrieval of Related APIs\n\nDe-Hallucinator retrieves relevant API references based on similarity to the input code, providing a ranked list of project-specific API references to be added to the prompt.\n\n\n\nPrompt Construction\n\nThe augmented prompt is designed to resemble “normal” code and consists of a commented block of relevant API references followed by the original prompt.\n\n\n\nIntegration with the LLM\n\nDe-Hallucinator queries the LLM as a black box and post-processes the completion to make it syntactically correct and remove extraneous completions."
  },
  {
    "objectID": "posts/De_Hallucinator_Iterative_Grounding_for_LLM_Based_Code_Completion/2024-01-03-De_Hallucinator_Iterative_Grounding_for_LLM_Based_Code_Completion.html#evaluation",
    "href": "posts/De_Hallucinator_Iterative_Grounding_for_LLM_Based_Code_Completion/2024-01-03-De_Hallucinator_Iterative_Grounding_for_LLM_Based_Code_Completion.html#evaluation",
    "title": "De-Hallucinator: Iterative Grounding for LLM-Based Code Completion",
    "section": "Evaluation",
    "text": "Evaluation\n\nThe approach is evaluated on four state-of-the-art LLMs for code completion, demonstrating consistent improvements in predicted code, edit distance, and recall of correctly predicted API usages compared to querying the model with a fixed prompt."
  },
  {
    "objectID": "posts/De_Hallucinator_Iterative_Grounding_for_LLM_Based_Code_Completion/2024-01-03-De_Hallucinator_Iterative_Grounding_for_LLM_Based_Code_Completion.html#appendix",
    "href": "posts/De_Hallucinator_Iterative_Grounding_for_LLM_Based_Code_Completion/2024-01-03-De_Hallucinator_Iterative_Grounding_for_LLM_Based_Code_Completion.html#appendix",
    "title": "De-Hallucinator: Iterative Grounding for LLM-Based Code Completion",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01701v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01701v1\n\n\nTruncated\nTrue\n\n\nWord Count\n14084"
  },
  {
    "objectID": "posts/LRS_Enhancing_Adversarial_Transferability_through_Lipschitz_Regularized_Surrogate/2023-12-20-LRS_Enhancing_Adversarial_Transferability_through_Lipschitz_Regularized_Surrogate.html#appendix",
    "href": "posts/LRS_Enhancing_Adversarial_Transferability_through_Lipschitz_Regularized_Surrogate/2023-12-20-LRS_Enhancing_Adversarial_Transferability_through_Lipschitz_Regularized_Surrogate.html#appendix",
    "title": "LRS: Enhancing Adversarial Transferability through Lipschitz Regularized Surrogate",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.13118v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.13118v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10577"
  },
  {
    "objectID": "posts/Open_Set_ID_Card_Presentation_Attack_Detection_using_Neural_Transfer_Style/2023-12-21-Open_Set_ID_Card_Presentation_Attack_Detection_using_Neural_Transfer_Style.html#appendix",
    "href": "posts/Open_Set_ID_Card_Presentation_Attack_Detection_using_Neural_Transfer_Style/2023-12-21-Open_Set_ID_Card_Presentation_Attack_Detection_using_Neural_Transfer_Style.html#appendix",
    "title": "Open-Set: ID Card Presentation Attack Detection using Neural Transfer Style",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.13993v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.13993v1\n\n\nTruncated\nTrue\n\n\nWord Count\n14697"
  },
  {
    "objectID": "posts/MedSumm_A_Multimodal_Approach_to_Summarizing_Code_Mixed_Hindi_English_Clinical_Queries/2024-01-03-MedSumm_A_Multimodal_Approach_to_Summarizing_Code_Mixed_Hindi_English_Clinical_Queries.html#appendix",
    "href": "posts/MedSumm_A_Multimodal_Approach_to_Summarizing_Code_Mixed_Hindi_English_Clinical_Queries/2024-01-03-MedSumm_A_Multimodal_Approach_to_Summarizing_Code_Mixed_Hindi_English_Clinical_Queries.html#appendix",
    "title": "MedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English Clinical Queries",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01596v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01596v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6480"
  },
  {
    "objectID": "posts/Is_Knowledge_All_Large_Language_Models_Needed_for_Causal_Reasoning/2023-12-30-Is_Knowledge_All_Large_Language_Models_Needed_for_Causal_Reasoning.html#appendix",
    "href": "posts/Is_Knowledge_All_Large_Language_Models_Needed_for_Causal_Reasoning/2023-12-30-Is_Knowledge_All_Large_Language_Models_Needed_for_Causal_Reasoning.html#appendix",
    "title": "Is Knowledge All Large Language Models Needed for Causal Reasoning?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00139v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00139v1\n\n\nTruncated\nTrue\n\n\nWord Count\n14300"
  },
  {
    "objectID": "posts/Deplatforming_Norm_Violating_Influencers_on_Social_Media_Reduces_Overall_Online_Attention_Toward_Them/2024-01-02-Deplatforming_Norm_Violating_Influencers_on_Social_Media_Reduces_Overall_Online_Attention_Toward_Them.html#appendix",
    "href": "posts/Deplatforming_Norm_Violating_Influencers_on_Social_Media_Reduces_Overall_Online_Attention_Toward_Them/2024-01-02-Deplatforming_Norm_Violating_Influencers_on_Social_Media_Reduces_Overall_Online_Attention_Toward_Them.html#appendix",
    "title": "Deplatforming Norm-Violating Influencers on Social Media Reduces Overall Online Attention Toward Them",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01253v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01253v1\n\n\nTruncated\nTrue\n\n\nWord Count\n16844"
  },
  {
    "objectID": "posts/Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models/2023-12-13-Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models.html#major-takeaways",
    "href": "posts/Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models/2023-12-13-Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models.html#major-takeaways",
    "title": "Efficient Toxic Content Detection by Bootstrapping and Distilling Large Language Models",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nThe paper proposes a novel approach called BD-LLM to address the challenges of efficiently designing prompts for Large Language Models (LLMs) for toxic content detection.\nThe Decision-Tree-of-Thought (DToT) method is introduced to bootstrap LLMs’ detection performance and extract high-quality rationales, leading to improved accuracy of LLMs and student LMs.\nThe study demonstrates that fine-tuning student LMs with DToT-extracted rationales leads to up to 16.9% accuracy improvement, while being more than 60 times smaller than conventional LLMs."
  },
  {
    "objectID": "posts/Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models/2023-12-13-Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models.html#introduction",
    "href": "posts/Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models/2023-12-13-Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models.html#introduction",
    "title": "Efficient Toxic Content Detection by Bootstrapping and Distilling Large Language Models",
    "section": "Introduction",
    "text": "Introduction\n\nToxic content detection is important for online services to protect users from harmful and offensive content.\nExisting supervised learning ML solutions face challenges such as obtaining training data with labels and limited transferability to other datasets.\nLarge Language Models (LLMs) have shown promise in toxic content detection but face challenges in prompt design and high run-time costs."
  },
  {
    "objectID": "posts/Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models/2023-12-13-Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models.html#approach",
    "href": "posts/Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models/2023-12-13-Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models.html#approach",
    "title": "Efficient Toxic Content Detection by Bootstrapping and Distilling Large Language Models",
    "section": "Approach",
    "text": "Approach\n\nDToT Prompting\n\nA novel prompting approach that iteratively selects more fine-grained context to re-prompt LLMs and enhance their detection performance.\nDToT prompting consists of four modules: confidence checker, context tree, context selector, and prompt generator for both black-box and white-box LLMs.\n\nRationale Distillation\n\nStudent LMs are fine-tuned with both labels and rationales extracted via DToT prompting, leading to improved detection performance."
  },
  {
    "objectID": "posts/Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models/2023-12-13-Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models.html#related-work",
    "href": "posts/Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models/2023-12-13-Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models.html#related-work",
    "title": "Efficient Toxic Content Detection by Bootstrapping and Distilling Large Language Models",
    "section": "Related Work",
    "text": "Related Work\n\nPrior works on toxic content detection focus on creating benchmark datasets and proposing novel approaches to fine-tune LMs for toxic content.\nExisting works on prompting LLMs have demonstrated superior zero-shot/few-shot in-context learning capabilities but heavily rely on the quality of input prompts.\nSome recent works have focused on distilling LLMs into smaller LMs for domain-specific tasks."
  },
  {
    "objectID": "posts/Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models/2023-12-13-Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models.html#experimental-setup",
    "href": "posts/Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models/2023-12-13-Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models.html#experimental-setup",
    "title": "Efficient Toxic Content Detection by Bootstrapping and Distilling Large Language Models",
    "section": "Experimental Setup",
    "text": "Experimental Setup\n\nEvaluation is conducted on three public datasets and an Amazon internal dataset using different models and baselines.\nThe effectiveness of DToT prompting and rationale distillation is thoroughly evaluated, demonstrating improvements in accuracy, F1 score, and AUC score."
  },
  {
    "objectID": "posts/Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models/2023-12-13-Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models.html#evaluation-results",
    "href": "posts/Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models/2023-12-13-Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models.html#evaluation-results",
    "title": "Efficient Toxic Content Detection by Bootstrapping and Distilling Large Language Models",
    "section": "Evaluation Results",
    "text": "Evaluation Results\n\nDToT Prompting\n\nDToT prompting significantly enhances the zero-shot learning performance of LLMs across different datasets.\nCombining DToT with few-shot in-context learning and rationales further improves models’ performance.\n\nRationale Distillation\n\nFine-tuning with DToT-extracted rationales leads to significant improvements in accuracy, F1 score, and AUC score for student LMs.\nThe approach also improves the cross-dataset transferability of student LMs and demonstrates the impact of model size on performance."
  },
  {
    "objectID": "posts/Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models/2023-12-13-Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models.html#conclusions-and-limitations",
    "href": "posts/Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models/2023-12-13-Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models.html#conclusions-and-limitations",
    "title": "Efficient Toxic Content Detection by Bootstrapping and Distilling Large Language Models",
    "section": "Conclusions and Limitations",
    "text": "Conclusions and Limitations\n\nThe paper proposes an end-to-end approach for toxic content detection, showcasing the effectiveness of DToT prompting and rationale distillation.\nLimitations include the context selector conducting a greedy search and the use of a pre-defined context tree."
  },
  {
    "objectID": "posts/Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models/2023-12-13-Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models.html#critique",
    "href": "posts/Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models/2023-12-13-Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models.html#critique",
    "title": "Efficient Toxic Content Detection by Bootstrapping and Distilling Large Language Models",
    "section": "Critique",
    "text": "Critique\nThe paper effectively presents a series of novel approaches and provides comprehensive evaluations. However, more detailed analysis on the potential limitations and challenges of the proposed approaches could further strengthen the paper.\nFor instance, the study could benefit from a more in-depth discussion on the generalizability of the results, potential biases in the evaluation, and the robustness of the proposed method in real-world scenarios. Furthermore, a comparison with state-of-the-art methods in the field could enhance the paper’s contributions and significance."
  },
  {
    "objectID": "posts/Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models/2023-12-13-Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models.html#appendix",
    "href": "posts/Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models/2023-12-13-Efficient_Toxic_Content_Detection_by_Bootstrapping_and_Distilling_Large_Language_Models.html#appendix",
    "title": "Efficient Toxic Content Detection by Bootstrapping and Distilling Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.08303v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.08303v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8732"
  },
  {
    "objectID": "posts/Zero_Shot_Position_Debiasing_for_Large_Language_Models/2024-01-02-Zero_Shot_Position_Debiasing_for_Large_Language_Models.html#summary",
    "href": "posts/Zero_Shot_Position_Debiasing_for_Large_Language_Models/2024-01-02-Zero_Shot_Position_Debiasing_for_Large_Language_Models.html#summary",
    "title": "Zero-Shot Position Debiasing for Large Language Models",
    "section": "Summary",
    "text": "Summary\nThe paper presents a zero-shot position debiasing (ZOE) framework to mitigate position bias in large language models (LLMs) without any external knowledge or datasets. ZOE leverages low-bias inference and a master-slave alignment (MSA) module to collect and prune unsupervised responses and applies multi-objective optimization for fine-tuning. Experimental results show that ZOE outperforms existing methods in mitigating position biases for generative tasks, sacrificing only a small performance on biased samples.\n\nMajor Findings\n\nZOE consistently outperforms existing methods in mitigating position biases for generative tasks without the need for external bias knowledge or non-biased samples.\nThe framework achieves this by leveraging low-bias unsupervised responses and pruning low-quality responses with the MSA module.\nZOE mitigates various types of position biases by sacrificing only small performance on biased samples, demonstrating its effectiveness and generalization.\n\n\n\nPreliminary\n\nLarge language models (LLMs) exhibit poor generalization performance due to dataset biases and artifacts, particularly in position bias.\nExisting debiasing methods for LLMs often rely on external bias knowledge or manually annotated non-biased samples, which is impractical for position bias.\nThe proposed ZOE framework leverages pre-trained LLMs’ low position bias characteristics for debiasing in a zero-shot setting.\n\n\n\nModel\n\nThe ZOE framework consists of three parts: low-bias inference, MSA, and multi-objective optimization, all without requiring external bias knowledge or non-biased datasets.\nLow-bias inference generates unsupervised low-bias responses based on pre-trained LLMs through diverse prompting strategies.\nThe MSA module prunes unsupervised responses to align them with the target responses to mitigate position bias.\nMulti-objective optimization fine-tunes the model by optimizing target responses and aligned unsupervised responses.\n\n\n\nExperiments\n\nZOE is evaluated on five tasks with eight datasets and consistently outperforms existing methods in mitigating three types of position biases.\nThe framework sacrifices only a small performance on biased samples, demonstrating its effectiveness and generalization across tasks and datasets."
  },
  {
    "objectID": "posts/Zero_Shot_Position_Debiasing_for_Large_Language_Models/2024-01-02-Zero_Shot_Position_Debiasing_for_Large_Language_Models.html#critique",
    "href": "posts/Zero_Shot_Position_Debiasing_for_Large_Language_Models/2024-01-02-Zero_Shot_Position_Debiasing_for_Large_Language_Models.html#critique",
    "title": "Zero-Shot Position Debiasing for Large Language Models",
    "section": "Critique",
    "text": "Critique\nThe paper effectively introduces the ZOE framework for mitigating position bias in LLMs and supports its effectiveness through extensive experiments. However, the paper could benefit from additional discussions or experiments regarding potential limitations or drawbacks of the proposed framework. Furthermore, the paper would benefit from more thorough analysis of the ethical considerations associated with the use of dialogue systems and language models."
  },
  {
    "objectID": "posts/Zero_Shot_Position_Debiasing_for_Large_Language_Models/2024-01-02-Zero_Shot_Position_Debiasing_for_Large_Language_Models.html#appendix",
    "href": "posts/Zero_Shot_Position_Debiasing_for_Large_Language_Models/2024-01-02-Zero_Shot_Position_Debiasing_for_Large_Language_Models.html#appendix",
    "title": "Zero-Shot Position Debiasing for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01218v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01218v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9120"
  },
  {
    "objectID": "posts/SonicVisionLM_Playing_Sound_with_Vision_Language_Models/2024-01-09-SonicVisionLM_Playing_Sound_with_Vision_Language_Models.html#appendix",
    "href": "posts/SonicVisionLM_Playing_Sound_with_Vision_Language_Models/2024-01-09-SonicVisionLM_Playing_Sound_with_Vision_Language_Models.html#appendix",
    "title": "SonicVisionLM: Playing Sound with Vision Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.04394v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.04394v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7641"
  },
  {
    "objectID": "posts/Are_LLMs_Robust_for_Spoken_Dialogues/2024-01-04-Are_LLMs_Robust_for_Spoken_Dialogues.html#appendix",
    "href": "posts/Are_LLMs_Robust_for_Spoken_Dialogues/2024-01-04-Are_LLMs_Robust_for_Spoken_Dialogues.html#appendix",
    "title": "Are LLMs Robust for Spoken Dialogues?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.02297v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.02297v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7839"
  },
  {
    "objectID": "posts/LaFFi_Leveraging_Hybrid_Natural_Language_Feedback_for_Fine_tuning_Language_Models/2023-12-31-LaFFi_Leveraging_Hybrid_Natural_Language_Feedback_for_Fine_tuning_Language_Models.html#appendix",
    "href": "posts/LaFFi_Leveraging_Hybrid_Natural_Language_Feedback_for_Fine_tuning_Language_Models/2023-12-31-LaFFi_Leveraging_Hybrid_Natural_Language_Feedback_for_Fine_tuning_Language_Models.html#appendix",
    "title": "LaFFi: Leveraging Hybrid Natural Language Feedback for Fine-tuning Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00907v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00907v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4606"
  },
  {
    "objectID": "posts/Can_ChatGPT_Play_the_Role_of_a_Teaching_Assistant_in_an_Introductory_Programming_Course/2023-12-12-Can_ChatGPT_Play_the_Role_of_a_Teaching_Assistant_in_an_Introductory_Programming_Course.html#appendix",
    "href": "posts/Can_ChatGPT_Play_the_Role_of_a_Teaching_Assistant_in_an_Introductory_Programming_Course/2023-12-12-Can_ChatGPT_Play_the_Role_of_a_Teaching_Assistant_in_an_Introductory_Programming_Course.html#appendix",
    "title": "Can ChatGPT Play the Role of a Teaching Assistant in an Introductory Programming Course?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.07343v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.07343v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8276"
  },
  {
    "objectID": "posts/ChatGPT_for_Conversational_Recommendation_Refining_Recommendations_by_Reprompting_with_Feedback/2024-01-07-ChatGPT_for_Conversational_Recommendation_Refining_Recommendations_by_Reprompting_with_Feedback.html#appendix",
    "href": "posts/ChatGPT_for_Conversational_Recommendation_Refining_Recommendations_by_Reprompting_with_Feedback/2024-01-07-ChatGPT_for_Conversational_Recommendation_Refining_Recommendations_by_Reprompting_with_Feedback.html#appendix",
    "title": "ChatGPT for Conversational Recommendation: Refining Recommendations by Reprompting with Feedback",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.03605v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.03605v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10455"
  },
  {
    "objectID": "posts/Exploring_Large_Language_Model_based_Intelligent_Agents_Definitions_Methods_and_Prospects/2024-01-07-Exploring_Large_Language_Model_based_Intelligent_Agents_Definitions_Methods_and_Prospects.html",
    "href": "posts/Exploring_Large_Language_Model_based_Intelligent_Agents_Definitions_Methods_and_Prospects/2024-01-07-Exploring_Large_Language_Model_based_Intelligent_Agents_Definitions_Methods_and_Prospects.html",
    "title": "Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects",
    "section": "",
    "text": "Key Findings:"
  },
  {
    "objectID": "posts/Exploring_Large_Language_Model_based_Intelligent_Agents_Definitions_Methods_and_Prospects/2024-01-07-Exploring_Large_Language_Model_based_Intelligent_Agents_Definitions_Methods_and_Prospects.html#appendix",
    "href": "posts/Exploring_Large_Language_Model_based_Intelligent_Agents_Definitions_Methods_and_Prospects/2024-01-07-Exploring_Large_Language_Model_based_Intelligent_Agents_Definitions_Methods_and_Prospects.html#appendix",
    "title": "Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.03428v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.03428v1\n\n\nTruncated\nTrue\n\n\nWord Count\n38668"
  },
  {
    "objectID": "posts/Performance_lossless_Black_box_Model_Watermarking/2023-12-11-Performance_lossless_Black_box_Model_Watermarking.html#appendix",
    "href": "posts/Performance_lossless_Black_box_Model_Watermarking/2023-12-11-Performance_lossless_Black_box_Model_Watermarking.html#appendix",
    "title": "Performance-lossless Black-box Model Watermarking",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.06488v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.06488v1\n\n\nTruncated\nTrue\n\n\nWord Count\n16235"
  },
  {
    "objectID": "posts/Bypassing_the_Safety_Training_of_Open_Source_LLMs_with_Priming_Attacks/2023-12-19-Bypassing_the_Safety_Training_of_Open_Source_LLMs_with_Priming_Attacks.html#appendix",
    "href": "posts/Bypassing_the_Safety_Training_of_Open_Source_LLMs_with_Priming_Attacks/2023-12-19-Bypassing_the_Safety_Training_of_Open_Source_LLMs_with_Priming_Attacks.html#appendix",
    "title": "Bypassing the Safety Training of Open-Source LLMs with Priming Attacks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.12321v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.12321v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3431"
  },
  {
    "objectID": "posts/TREC_iKAT_2023_The_Interactive_Knowledge_Assistance_Track_Overview/2024-01-02-TREC_iKAT_2023_The_Interactive_Knowledge_Assistance_Track_Overview.html#appendix",
    "href": "posts/TREC_iKAT_2023_The_Interactive_Knowledge_Assistance_Track_Overview/2024-01-02-TREC_iKAT_2023_The_Interactive_Knowledge_Assistance_Track_Overview.html#appendix",
    "title": "TREC iKAT 2023: The Interactive Knowledge Assistance Track Overview",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01330v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01330v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9078"
  },
  {
    "objectID": "posts/FedDiv_Collaborative_Noise_Filtering_for_Federated_Learning_with_Noisy_Labels/2023-12-19-FedDiv_Collaborative_Noise_Filtering_for_Federated_Learning_with_Noisy_Labels.html#appendix",
    "href": "posts/FedDiv_Collaborative_Noise_Filtering_for_Federated_Learning_with_Noisy_Labels/2023-12-19-FedDiv_Collaborative_Noise_Filtering_for_Federated_Learning_with_Noisy_Labels.html#appendix",
    "title": "FedDiv: Collaborative Noise Filtering for Federated Learning with Noisy Labels",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.12263v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.12263v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10854"
  },
  {
    "objectID": "posts/Overview_of_Dialogue_Robot_Competition_2023/2024-01-07-Overview_of_Dialogue_Robot_Competition_2023.html#appendix",
    "href": "posts/Overview_of_Dialogue_Robot_Competition_2023/2024-01-07-Overview_of_Dialogue_Robot_Competition_2023.html#appendix",
    "title": "Overview of Dialogue Robot Competition 2023",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.03547v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.03547v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5677"
  },
  {
    "objectID": "posts/Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education/2024-01-08-Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education.html#key-findings",
    "href": "posts/Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education/2024-01-08-Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education.html#key-findings",
    "title": "Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education",
    "section": "Key Findings",
    "text": "Key Findings\n\nExisting AIGC Detectors perform poorly in distinguishing between human-written code and AI-generated code, indicating the inherent weaknesses of current detectors. This underscores the need for further research and development in this domain to enhance their efficacy.\nVariations in the prompts used to generate AI-generated content significantly impact the sensitivity and accuracy of AIGC Detectors, particularly the GLTR model.\nA need for comprehensive guidelines and policies to safeguard the responsible and ethical usage of AI in the educational context is emphasized. Educators are encouraged to consider the integration of generative AI into education processes, the automation level, and its ethical focus."
  },
  {
    "objectID": "posts/Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education/2024-01-08-Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education.html#abstract",
    "href": "posts/Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education/2024-01-08-Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education.html#abstract",
    "title": "Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education",
    "section": "Abstract",
    "text": "Abstract\nThe paper presents an empirical study evaluating the performance of AI-generated content (AIGC) detectors in distinguish AI-generated code from human-written code. A dataset comprising programming problems and corresponding human-written and AI-generated Python solutions was collected from various online sources. 13 variations of prompts were used to instruct an AI model to generate outputs, and the performance of five AIGC detectors was evaluated. Results indicate that existing detectors perform poorly in distinguishing AI-generated from human-written code."
  },
  {
    "objectID": "posts/Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education/2024-01-08-Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education.html#introduction",
    "href": "posts/Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education/2024-01-08-Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education.html#introduction",
    "title": "Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education",
    "section": "Introduction",
    "text": "Introduction\n\nLarge Language Models (LLMs) have advanced to the point of generating human-like code, raising concerns in programming education about potential academic misconduct.\nAccessibility of LLMs has implications for educational assessment and academic dishonesty, thereby compelling educators to utilize AIGC Detectors to ascertain student integrity."
  },
  {
    "objectID": "posts/Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education/2024-01-08-Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education.html#background-and-motivations",
    "href": "posts/Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education/2024-01-08-Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education.html#background-and-motivations",
    "title": "Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education",
    "section": "Background and Motivations",
    "text": "Background and Motivations\n\nSoftware Engineering (SE) and Computer Science (CS) education are significantly impacted by the emergence of generative AI, introducing complexities and challenges in educational assessment and evaluation.\nThere is a noticeable impact on academic dishonesty due to growing student reliance on AI-driven solutions.\nEducators find themselves compelled to utilize AIGC Detectors, while the limitations of these detectors in recognizing AI-generated code remain uncertain."
  },
  {
    "objectID": "posts/Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education/2024-01-08-Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education.html#empirical-study-design-and-methodology",
    "href": "posts/Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education/2024-01-08-Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education.html#empirical-study-design-and-methodology",
    "title": "Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education",
    "section": "Empirical Study Design and Methodology",
    "text": "Empirical Study Design and Methodology\n\nThe study includes the research questions, methodology, process overview, and data collection details.\nResearch questions revolve around the accuracy and limitations of existing AIGC Detectors in detecting AI-generated code, evaluating their effectiveness and potential vulnerabilities with different code variants."
  },
  {
    "objectID": "posts/Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education/2024-01-08-Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education.html#results",
    "href": "posts/Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education/2024-01-08-Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education.html#results",
    "title": "Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education",
    "section": "Results",
    "text": "Results\n\nExisting AIGC Detectors perform poorly in distinguishing between human-written and AI-generated code, indicating the inherent weaknesses of current detectors. GLTR demonstrates the highest sensitivity and significant variability across different code variants.\nLimitations of AIGC Detectors include their struggle in detecting AI-generated code accurately, highlighting the need for ongoing research and development to enhance their reliability."
  },
  {
    "objectID": "posts/Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education/2024-01-08-Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education.html#discussion",
    "href": "posts/Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education/2024-01-08-Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education.html#discussion",
    "title": "Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education",
    "section": "Discussion",
    "text": "Discussion\n\nSuggestions are provided for SE and CS educators to address the challenges and opportunities presented by the integration of AI into education.\nKey areas for improvement include defining objectives, considering automation levels, focusing on ethical considerations, continuous evaluation, and comprehensive policies."
  },
  {
    "objectID": "posts/Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education/2024-01-08-Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education.html#threats-to-validity",
    "href": "posts/Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education/2024-01-08-Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education.html#threats-to-validity",
    "title": "Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education",
    "section": "Threats to Validity",
    "text": "Threats to Validity\n\nThe study acknowledges challenges related to prompts used for AIGC generation, verification of human-written code, and the impact of vague queries on AIGC Detector performance."
  },
  {
    "objectID": "posts/Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education/2024-01-08-Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education.html#conclusion-and-future-work",
    "href": "posts/Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education/2024-01-08-Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education.html#conclusion-and-future-work",
    "title": "Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education",
    "section": "Conclusion and Future Work",
    "text": "Conclusion and Future Work\n\nPromising opportunities exist for AIGC Detector tools to positively impact education, but challenges need to be addressed. Ethical guidelines and ongoing tool refinement are vital for responsible AI usage in education."
  },
  {
    "objectID": "posts/Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education/2024-01-08-Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education.html#data-availability",
    "href": "posts/Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education/2024-01-08-Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education.html#data-availability",
    "title": "Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education",
    "section": "Data Availability",
    "text": "Data Availability\nThe replication package, including associated data, has been made publicly available for transparency and reproducibility."
  },
  {
    "objectID": "posts/Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education/2024-01-08-Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education.html#critique-and-potential-problems",
    "href": "posts/Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education/2024-01-08-Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education.html#critique-and-potential-problems",
    "title": "Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education",
    "section": "Critique and Potential Problems",
    "text": "Critique and Potential Problems\n\nThe study’s reliance on one specific type of AI model, ChatGPT, might limit the generalizability of the findings to other AI models.\nThe study could benefit from a more diverse range of programming languages and problem types to better assess the performance of AIGC Detectors in a broader context.\nThe implications of the findings on educational practice and student learning outcomes could be further elucidated for a more comprehensive understanding of the study’s practical significance."
  },
  {
    "objectID": "posts/Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education/2024-01-08-Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education.html#appendix",
    "href": "posts/Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education/2024-01-08-Assessing_AI_Detectors_in_Identifying_AI_Generated_Code_Implications_for_Education.html#appendix",
    "title": "Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.03676v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.03676v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12715"
  },
  {
    "objectID": "posts/MOCHa_Multi_Objective_Reinforcement_Mitigating_Caption_Hallucinations/2023-12-06-MOCHa_Multi_Objective_Reinforcement_Mitigating_Caption_Hallucinations.html#appendix",
    "href": "posts/MOCHa_Multi_Objective_Reinforcement_Mitigating_Caption_Hallucinations/2023-12-06-MOCHa_Multi_Objective_Reinforcement_Mitigating_Caption_Hallucinations.html#appendix",
    "title": "MOCHa: Multi-Objective Reinforcement Mitigating Caption Hallucinations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.03631v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.03631v1\n\n\nTruncated\nTrue\n\n\nWord Count\n13650"
  },
  {
    "objectID": "posts/Beam_Based_Multiple_Access_for_IRS_Aided_Millimeter_Wave_and_Terahertz_Communications/2024-01-02-Beam_Based_Multiple_Access_for_IRS_Aided_Millimeter_Wave_and_Terahertz_Communications.html#appendix",
    "href": "posts/Beam_Based_Multiple_Access_for_IRS_Aided_Millimeter_Wave_and_Terahertz_Communications/2024-01-02-Beam_Based_Multiple_Access_for_IRS_Aided_Millimeter_Wave_and_Terahertz_Communications.html#appendix",
    "title": "Beam-Based Multiple Access for IRS-Aided Millimeter-Wave and Terahertz Communications",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01224v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01224v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5325"
  },
  {
    "objectID": "posts/Noise_NeRF_Hide_Information_in_Neural_Radiance_Fields_using_Trainable_Noise/2024-01-02-Noise_NeRF_Hide_Information_in_Neural_Radiance_Fields_using_Trainable_Noise.html#appendix",
    "href": "posts/Noise_NeRF_Hide_Information_in_Neural_Radiance_Fields_using_Trainable_Noise/2024-01-02-Noise_NeRF_Hide_Information_in_Neural_Radiance_Fields_using_Trainable_Noise.html#appendix",
    "title": "Noise-NeRF: Hide Information in Neural Radiance Fields using Trainable Noise",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01216v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01216v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5592"
  },
  {
    "objectID": "posts/Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers/2024-01-03-Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers.html#major-takeaways",
    "href": "posts/Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers/2024-01-03-Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers.html#major-takeaways",
    "title": "Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nLarge language models (LLMs) demonstrate strong performance on compositional visual question answering, visual grounding, and video temporal reasoning tasks. However, their performance heavily relies on human-engineered in-context examples (ICEs) in the prompt.\nThe presented framework introduces spatially and temporally abstract routines and leverages a small number of labeled examples to automatically generate in-context examples, thus avoiding the need for human-created ICEs.\nThe framework leads to consistent gains in performance, makes LLMs as controllers setup more robust, and removes the need for human engineering of ICEs across various visual reasoning tasks."
  },
  {
    "objectID": "posts/Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers/2024-01-03-Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers.html#introduction",
    "href": "posts/Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers/2024-01-03-Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers.html#introduction",
    "title": "Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers",
    "section": "Introduction",
    "text": "Introduction\nCompositional visual question answering necessitates understanding visual information in images and the structure of the question, posing a challenge for end-to-end neural networks, especially in tasks requiring compositional reasoning, spatial reasoning, and counting. A promising alternative involves LLMs as controllers, orchestrating a set of visual tools to decompose tasks into subtasks and solve them by utilizing abstract routines."
  },
  {
    "objectID": "posts/Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers/2024-01-03-Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers.html#llms-as-programmers-for-visual-reasoning-framework",
    "href": "posts/Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers/2024-01-03-Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers.html#llms-as-programmers-for-visual-reasoning-framework",
    "title": "Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers",
    "section": "LLMs as programmers for visual reasoning framework",
    "text": "LLMs as programmers for visual reasoning framework\n\nBackground: The ViperGPT approach uses an LLM (Codex) and a tools API to generate scripts to solve visual queries, with the prompt consisting of API functions, docstrings, and query-code examples of their use.\nAbstract API through visual routines: The framework introduces spatially and temporally abstract routines to reduce the LLM’s burden of strong spatial and temporal reasoning.\nAutomatic generation of in-context examples: Using a few labeled examples, the framework generates query-code examples in a zero-shot manner, thereby eliminating human engineering of ICEs.\nSelf-correction: The framework enables LLMs to perform self-debugging and self-tuning to correct generated code when execution fails without any ground truth labels."
  },
  {
    "objectID": "posts/Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers/2024-01-03-Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers.html#experiments",
    "href": "posts/Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers/2024-01-03-Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers.html#experiments",
    "title": "Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers",
    "section": "Experiments",
    "text": "Experiments\n\nTasks: Evaluation is conducted on datasets such as RefCOCO, RefCOCO+, GQA, and NExT-QA, assessing a diverse set of capabilities including visual grounding, compositional image question answering, and video temporal reasoning.\nVision and Language Models: The framework uses a code instruction-tuned version of PaLM2 for code generation and various vision models for object detection, depth estimation, and image captioning.\nSelf-Correction: Results show that self-tuning, dynamic object detector thresholds, and generated in-context examples lead to improved performance across tasks."
  },
  {
    "objectID": "posts/Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers/2024-01-03-Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers.html#conclusion",
    "href": "posts/Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers/2024-01-03-Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers.html#conclusion",
    "title": "Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers",
    "section": "Conclusion",
    "text": "Conclusion\nThe framework showcased consistent performance gains while removing the need for human engineering of ICEs and demonstrating the potential of LLMs as controllers for visual reasoning."
  },
  {
    "objectID": "posts/Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers/2024-01-03-Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers.html#critique-and-future-work",
    "href": "posts/Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers/2024-01-03-Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers.html#critique-and-future-work",
    "title": "Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers",
    "section": "Critique and Future Work",
    "text": "Critique and Future Work\nWhile the framework shows promise, further research is needed to optimize the Abstract API routines and automate prompt engineering with natural language dataset specifications. Additionally, the creation of better benchmarks for evaluating compositional visual reasoning is needed to maximize the framework’s potential. There should also be continued exploration of LLMs’ self-correction capabilities."
  },
  {
    "objectID": "posts/Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers/2024-01-03-Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers.html#appendix",
    "href": "posts/Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers/2024-01-03-Towards_Truly_Zero_shot_Compositional_Visual_Reasoning_with_LLMs_as_Programmers.html#appendix",
    "title": "Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01974v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01974v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13256"
  },
  {
    "objectID": "posts/K_PERM_Personalized_Response_Generation_Using_Dynamic_Knowledge_Retrieval_and_Persona_Adaptive_Queries/2023-12-29-K_PERM_Personalized_Response_Generation_Using_Dynamic_Knowledge_Retrieval_and_Persona_Adaptive_Queries.html#appendix",
    "href": "posts/K_PERM_Personalized_Response_Generation_Using_Dynamic_Knowledge_Retrieval_and_Persona_Adaptive_Queries/2023-12-29-K_PERM_Personalized_Response_Generation_Using_Dynamic_Knowledge_Retrieval_and_Persona_Adaptive_Queries.html#appendix",
    "title": "K-PERM: Personalized Response Generation Using Dynamic Knowledge Retrieval and Persona-Adaptive Queries",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17748v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17748v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8655"
  },
  {
    "objectID": "posts/ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#key-findings",
    "href": "posts/ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#key-findings",
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "section": "Key Findings",
    "text": "Key Findings\n\nToolEyes offers a fine-grained evaluation system for Large Language Models’ (LLMs) tool learning capabilities, examining seven real-world scenarios and approximately 600 tools.\nThe evaluation reveals that LLMs exhibit preference for specific scenarios and restricted cognitive abilities in tool learning, with larger model size exacerbating the hindrance to tool learning.\nThe findings suggest the need for improvement in tool learning capabilities across all categories of LLMs."
  },
  {
    "objectID": "posts/ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#evaluation-system",
    "href": "posts/ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#evaluation-system",
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "section": "Evaluation System",
    "text": "Evaluation System\n\nScenario Construction\n\nToolEyes formulates seven real-world scenarios, including Text Generation, Data Understanding, Real-Time Search, Application Manipulation, Personal Life, Information Retrieval, and Financial Transactions.\nEach scenario is equipped with a related set of tools, totaling 41 categories, 95 subcategories, and 568 tools.\n\n\n\nTool Library Building\n\nThe system establishes a tool library, serving as an interface for LLMs to interact with the environment.\n\n\n\nHuman-Driven Data Generation\n\nProfessionals were engaged to identify actual requirements by reviewing the tool documentation to ensure comprehensive coverage of different scenarios.\n\n\n\nLLMs Capability Evaluation\n\nToolEyes evaluates LLMs across five essential capabilities: format alignment, intent comprehension, behavior planning, tool selection, and answer organization."
  },
  {
    "objectID": "posts/ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#experiments",
    "href": "posts/ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#experiments",
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "section": "Experiments",
    "text": "Experiments\n\nModel Selection\n\nExperiments were conducted on ten LLMs from three sources: open-source, tool-oriented, and closed-source categories, including LLaMA-2-chat, Vicuna-1.5, Text-davinci-003, GPT-3.5-turbo, and GPT-4.\n\n\n\nExperimental Setup\n\nLLMs were assessed using a five-shot format for open-source models and zero-shot format for others, with specific prompt templates used during inference.\n\n\n\nResults in Different Scenarios\n\nLLMs exhibit scenario-specific preferences in tool learning, influenced by their optimization goals and training data.\n\n\n\nResults of Different LLMs Capabilities\n\nThe present constraints in LLMs thinking skills present a substantial obstacle to tool learning, and LLMs with superior performance exhibit more effective problem-solving abilities.\n\n\n\nWhy does NOT LLMs Capabilities Increase with Size?\n\nThe study found that as the model size increases, there is a potential weakening of the instrumental learning capabilities within specific LLM families."
  },
  {
    "objectID": "posts/ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#insights-for-advancing-tool-learning",
    "href": "posts/ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#insights-for-advancing-tool-learning",
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "section": "Insights for Advancing Tool Learning",
    "text": "Insights for Advancing Tool Learning\n\nIdeas for advancing tool learning include task construction considering model behavior, scenario generalization using diverse data, and capability enhancement addressing the “barrel effect.”"
  },
  {
    "objectID": "posts/ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#related-works",
    "href": "posts/ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#related-works",
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "section": "Related Works",
    "text": "Related Works\n\nThe paper discusses tool learning and evaluations for tool learning, highlighting the challenges in current tool learning research."
  },
  {
    "objectID": "posts/ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#conclusion",
    "href": "posts/ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#conclusion",
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "section": "Conclusion",
    "text": "Conclusion\n\nToolEyes offers instructive insights to inform the development of tool learning and presents avenues for future research."
  },
  {
    "objectID": "posts/ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#limitations",
    "href": "posts/ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#limitations",
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "section": "Limitations",
    "text": "Limitations\n\nThe paper acknowledges limitations, including the absence of a novel LLM dedicated to tool learning and the associated costs of scoring using specific LLMs."
  },
  {
    "objectID": "posts/ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#appendix",
    "href": "posts/ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes_Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#appendix",
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00741v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00741v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11381"
  },
  {
    "objectID": "posts/PLLaMa_An_Open_source_Large_Language_Model_for_Plant_Science/2024-01-03-PLLaMa_An_Open_source_Large_Language_Model_for_Plant_Science.html#appendix",
    "href": "posts/PLLaMa_An_Open_source_Large_Language_Model_for_Plant_Science/2024-01-03-PLLaMa_An_Open_source_Large_Language_Model_for_Plant_Science.html#appendix",
    "title": "PLLaMa: An Open-source Large Language Model for Plant Science",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-10\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01600v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01600v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8053"
  }
]