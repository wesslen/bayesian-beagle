
---
title: "AssertionBench: A Benchmark to Evaluate Large-Language Models for Assertion Generation"
id: "2406.18627v1"
description: "LLMs evaluated for hardware assertion generation;  benchmark used for quantitative comparison."
author: Vaishnavi Pulavarthi, Deeksha Nandal, Soham Dan, Debjit Pal
date: "2024-06-26"
image: "https://browse.arxiv.org/html/2406.18627v1/extracted/5693363/pic/design_details_1.png"
categories: ['prompt-engineering', 'security', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.18627v1/extracted/5693363/pic/design_details_1.png)

### Summary:

The paper presents a novel benchmark, , to evaluate the effectiveness of Large-Language Models (LLMs) for assertion generation. The benchmark consists of 100 curated Verilog hardware designs from OpenCores and formally verified assertions for each design generated from GoldMine and HARM. The authors use this benchmark to compare state-of-the-art LLMs, such as GPT-3.5, GPT-4o, CodeLLaMa 2, and LLaMa3-70B, to assess their effectiveness in inferring functionally correct assertions for hardware designs. The experiments demonstrate the relative performance of LLMs, the benefits of using more in-context exemplars, and the significant room for improvement for LLM-based assertion generators.

### Major Findings:

1. The benchmark, , is a valuable resource for evaluating the effectiveness of LLMs for assertion generation in hardware designs.
2. The experiments demonstrate that LLMs can generate functionally correct assertions for hardware designs, but there is significant room for improvement.
3. Using more in-context exemplars can improve the performance of LLMs in generating functionally correct assertions.

### Analysis and Critique:

1. The paper provides a comprehensive evaluation of LLMs for assertion generation, but it does not discuss the limitations of the benchmark or the potential biases in the evaluation process.
2. The paper does not provide a detailed comparison of the performance of different LLMs, which could be useful for understanding the strengths and weaknesses of each model.
3. The paper does not discuss the potential applications of LLMs for assertion generation in other domains, such as software engineering or cybersecurity.
4. The paper does not discuss the potential impact of LLMs on the hardware design and verification process, which could be an interesting area for future research.
5. The paper does not discuss the potential ethical implications of using LLMs for assertion generation, such as the risk of generating incorrect or misleading assertions.

Overall, the paper provides a valuable contribution to the field of hardware design and verification by introducing a novel benchmark for evaluating LLMs for assertion generation. However, there are several areas for improvement, such as a more detailed comparison of LLMs, a discussion of the limitations and bi

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-07       |
| Abstract | [https://arxiv.org/abs/2406.18627v1](https://arxiv.org/abs/2406.18627v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.18627v1](https://browse.arxiv.org/html/2406.18627v1)       |
| Truncated       | False       |
| Word Count       | 6426       |