
---
title: "Towards Multimodal Emotional Support Conversation Systems"
id: "2408.03650v1"
description: "TL;DR: New dataset & framework improve AI's empathetic emotional support in mental health care."
author: Yuqi Chu, Lizi Liao, Zhiyuan Zhou, Chong-Wah Ngo, Richang Hong
date: "2024-08-07"
image: "https://browse.arxiv.org/html/2408.03650v1/x1.png"
categories: ['social-sciences', 'hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.03650v1/x1.png)

### Summary:

The integration of conversational AI into mental health care has the potential to revolutionize the therapeutic landscape by offering more nuanced, empathetic interactions. However, current AI systems are limited by their reliance on single-modal data, which constrains their ability to empathize and provide effective emotional support. To address this gap, the authors introduce the Multimodal Emotional Support Conversation (MESC) dataset, a first-of-its-kind resource enriched with comprehensive annotations across text, audio, and video modalities. The MESC dataset captures the intricate interplay of user emotions, system strategies, system emotion, and system responses. Leveraging the MESC dataset, the authors propose a general Sequential Multimodal Emotional Support framework (SMES) grounded in Therapeutic Skills Theory. The SMES framework is tailored for multimodal dialogue systems and incorporates an LLM-based reasoning model that sequentially generates user emotion recognition, system strategy prediction, system emotion prediction, and response generation. The authors' rigorous evaluations demonstrate that this framework significantly enhances the capability of AI systems to mimic therapist behaviors with heightened empathy and strategic responsiveness.

### Major Findings:

1. The introduction of the MESC dataset, a comprehensive multimodal conversation dataset for mental health care, addresses the critical gap in resources that encapsulate the multimodal nature of human communication essential for therapeutic counseling.
2. The development of the SMES framework, a general approach designed to enhance AI-driven conversation systems in mental health care, leverages the strengths of multimodal foundation models to extract emotional cues from video and audio.
3. The SMES framework significantly boosts the empathetic and strategic capabilities of AI, setting a new benchmark for conversational AI in mental health support.

### Analysis and Critique:

The authors' work pushes the boundaries of AI's role in mental health care and establishes a foundation for developing conversational agents that can provide more empathetic and effective emotional support. However, several potential limitations and areas for further research should be considered:

1. The MESC dataset is derived from a single source (the TV show In Treatment), which may limit its generalizability

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-13       |
| Abstract | [https://arxiv.org/abs/2408.03650v1](https://arxiv.org/abs/2408.03650v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.03650v1](https://browse.arxiv.org/html/2408.03650v1)       |
| Truncated       | False       |
| Word Count       | 7737       |