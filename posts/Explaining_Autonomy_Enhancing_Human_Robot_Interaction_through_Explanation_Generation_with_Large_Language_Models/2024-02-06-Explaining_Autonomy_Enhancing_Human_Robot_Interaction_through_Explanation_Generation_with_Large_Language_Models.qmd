
---
title: "Explaining Autonomy: Enhancing Human-Robot Interaction through Explanation Generation with Large Language Models"
id: "2402.04206v1"
description: "System generates explanations for autonomous robot actions using Large Language Models (LLMs). Evaluated in navigation test."
author: David Sobrín-Hidalgo, Miguel A. González-Santamarta, Ángel M. Guerrero-Higueras, Francisco J. Rodríguez-Lera, Vicente Matellán-Olivera
date: "2024-02-06"
image: "../../img/2402.04206v1/image_1.png"
categories: ['production']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.04206v1/image_1.png)

### Summary:
This paper introduces a system designed to generate explanations for the actions performed by an autonomous robot in Human-Robot Interaction (HRI). The work described in this paper aims to take advantage of the capabilities of Large Language Models (LLMs) in performing natural language processing tasks. The study focuses on the possibility of generating explanations using such models in combination with a Retrieval Augmented Generation (RAG) method to interpret data gathered from the logs of autonomous systems. The system is evaluated through a navigation test from the European Robotics League (ERL), a Europe-wide social robotics competition. The results obtained during the experiment highlight the potential utility of LLMs in achieving explanatory capabilities in robots.

### Major Findings:
1. The system successfully generated explanations for the actions performed by an autonomous robot in a navigation test from the European Robotics League (ERL).
2. The study demonstrated the potential utility of Large Language Models (LLMs) in achieving explanatory capabilities in robots.
3. The system was able to interpret data gathered from the logs of autonomous systems and generate explanations using a Retrieval Augmented Generation (RAG) method.

### Analysis and Critique:
- The study successfully demonstrated the potential of Large Language Models (LLMs) in generating explanations for autonomous robots. However, the system's real-time processing capabilities need improvement.
- The explanations generated by the system were generally consistent with the robot's behavior, but there were instances where the explanations lacked clarity and conciseness.
- The study focused on a specific navigation test, and further research is needed to evaluate the system's performance in other scenarios and tasks.
- The questionnaire results provided valuable feedback on the quality and clarity of the explanations, highlighting areas for improvement in future iterations of the system.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.04206v1](https://arxiv.org/abs/2402.04206v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.04206v1](https://browse.arxiv.org/html/2402.04206v1)       |
| Truncated       | False       |
| Word Count       | 15714       |