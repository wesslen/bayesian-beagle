
---
title: "Sonnet or Not, Bot? Poetry Evaluation for Large Models and Datasets"
id: "2406.18906v1"
description: "LLMs can recognize poetic form, but challenges remain in evaluating their poetic capabilities and creating NLP benchmarks for poetry."
author: Melanie Walsh, Anna Preus, Maria Antoniak
date: "2024-06-27"
image: "https://browse.arxiv.org/html/2406.18906v1/x1.png"
categories: ['education', 'social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.18906v1/x1.png)

### Summary:

The article "Sonnet or Not, Bot?" explores the poetic capabilities of large language models (LLMs) and their ability to recognize and generate poetry. The authors develop a task to evaluate how well LLMs can identify more than 20 poetic forms and formal elements in the English language. They find that LLMs, particularly GPT-4 and GPT-4o, can successfully identify both common and uncommon fixed poetic forms, such as sonnets, sestinas, and pantoums, at surprisingly high accuracy levels when compared to annotations by human experts. However, performance varies widely by poetic form and feature; the models struggle to identify unfixed poetic forms, especially ones based on topic or visual features.

### Major Findings:

1. LLMs, particularly GPT-4 and GPT-4o, can successfully identify both common and uncommon fixed poetic forms, such as sonnets, sestinas, and pantoums, at high accuracy levels when compared to annotations by human experts.
2. Performance varies widely by poetic form and feature; the models struggle to identify unfixed poetic forms, especially ones based on topic or visual features.
3. While the LLMs have most success with the poetic forms most commonly found in popular pretraining datasets, the authors do not see major differences when they compare model performance on poems from major online poetry institutions, popular pretraining datasets, or print books with little to no digital presence.

### Analysis and Critique:

The article provides a comprehensive evaluation of LLMs' ability to recognize poetic forms, which is a significant contribution to the field of NLP. However, the study has some limitations. The authors acknowledge that the circulation of poetry is different from other literary texts, which may result in unmeasured differences in pretraining datasets. Additionally, the study focuses on English-language poetry, which may not be representative of poetry in other languages. The authors also note that identifying poetic form is a "difficult" task, even for expert human annotators, which may limit the accuracy of the LLMs' evaluations. Finally, the study does not address the potential biases in the pretraining datasets, which could impact the models' performance.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-07       |
| Abstract | [https://arxiv.org/abs/2406.18906v1](https://arxiv.org/abs/2406.18906v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.18906v1](https://browse.arxiv.org/html/2406.18906v1)       |
| Truncated       | False       |
| Word Count       | 3809       |