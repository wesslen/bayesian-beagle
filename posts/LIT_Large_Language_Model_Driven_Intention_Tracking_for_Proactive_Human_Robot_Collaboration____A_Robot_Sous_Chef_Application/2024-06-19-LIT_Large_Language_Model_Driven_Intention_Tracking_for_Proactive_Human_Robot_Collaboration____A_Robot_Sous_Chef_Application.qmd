
---
title: "LIT: Large Language Model Driven Intention Tracking for Proactive Human-Robot Collaboration -- A Robot Sous-Chef Application"
id: "2406.13787v1"
description: "LIT predicts human intentions for proactive robot collaboration, reducing excessive prompting in long-horizon tasks."
author: Zhe Huang, John Pohovey, Ananya Yammanuru, Katherine Driggs-Campbell
date: "2024-06-19"
image: "https://browse.arxiv.org/html/2406.13787v1/extracted/5679315/figures/lit-framework-v3.png"
categories: ['prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.13787v1/extracted/5679315/figures/lit-framework-v3.png)

### Summary:

The paper introduces Language-driven Intention Tracking (LIT), a framework that leverages Large Language Models (LLMs) and Vision Language Models (VLMs) to model the long-term behavior of human users and predict their next intentions. This approach aims to address the challenge of excessive prompting in long-horizon collaborative tasks between humans and robots. LIT extends intention tracking by applying an LLM to model measurement likelihood and transition probabilities in the probabilistic graphical model of human intentions. The framework is demonstrated in a scenario where a collaborative robot acts as a sous-chef to assist a human user in cooking.

### Major Findings:

1. LIT enables robots to understand and predict human intentions in long-horizon collaborative tasks, reducing the need for excessive prompting.
2. The framework uses LLMs and VLMs to model measurement likelihood and transition probabilities in the probabilistic graphical model of human intentions.
3. LIT is demonstrated to be effective in a scenario where a collaborative robot acts as a sous-chef to assist a human user in cooking.

### Analysis and Critique:

1. The paper does not provide a comprehensive evaluation of the LIT framework, relying mainly on a single demonstration in a cooking scenario. More diverse and complex scenarios should be tested to validate the framework's generalizability.
2. The paper does not discuss potential limitations or challenges in implementing LIT, such as the computational resources required for LLMs and VLMs, or the potential for misinterpretation of human intentions.
3. The paper does not explore the potential for integrating other types of models or data, such as motion tracking or sensor data, to improve the accuracy of intention tracking.
4. The paper does not discuss the ethical implications of using LLMs and VLMs to model human behavior, such as the potential for bias or privacy concerns.
5. The paper does not provide a clear roadmap for future research, beyond mentioning the need for more comprehensive evaluations and testing in different daily tasks.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-23       |
| Abstract | [https://arxiv.org/abs/2406.13787v1](https://arxiv.org/abs/2406.13787v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.13787v1](https://browse.arxiv.org/html/2406.13787v1)       |
| Truncated       | False       |
| Word Count       | 3696       |