
---
title: "Investigating the Efficacy of Large Language Models for Code Clone Detection"
id: "2401.13802v1"
description: "Large Language Models (LLMs) succeed in prompt-based code tasks. Preliminary study shows LLMs' applicability in non-generative tasks like Code Clone Detection."
author: ['Mohamad Khajezade', 'Jie Wu', 'Fatemeh Hendijani Fard', 'Gema Rodríguez-Pérez', 'Mohamed Sami Shehata']
date: "2024-01-24"
image: "https://browse.arxiv.org/html/2401.13802v1/extracted/5367349/Figs/motivation3.png"
categories: ['robustness', 'hci', 'social-sciences', 'prompt-engineering', 'programming']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.13802v1/extracted/5367349/Figs/motivation3.png)

**Summary of the Article:**
The article investigates the efficacy of Large Language Models (LLMs), particularly ChatGPT, for Code Clone Detection (CCD). The study explores the performance of ChatGPT in detecting Type-4 code clones in Java-Java and Java-Ruby pairs, as well as its comparison with fully fine-tuned models. The researchers found that ChatGPT surpasses baselines in cross-language CCD and achieves comparable performance for mono-lingual CCD. The use of different prompts and the difficulty level of the problems were identified as significant factors affecting ChatGPT's performance. Additionally, the study compares its results with existing works and discusses the applicability of LLMs for code clones, focusing on Type-4 clones.

### Major Findings:
1. ChatGPT surpasses baselines in cross-language CCD, achieving an F1-score of 0.877, and achieves comparable performance to fully fine-tuned models for mono-lingual CCD, with an F1-score of 0.878.
2. The prompt and the difficulty level of the problems have a notable impact on the performance of ChatGPT for code clone detection. Different prompts showed varying effectiveness, and the complexity of the code pairs influenced ChatGPT's performance.
3. While existing studies have explored LLMs for various code-related tasks, limited works have focused on using LLMs for code clones, specifically mono- and cross-language CCD. This study highlights the importance of investigating the complexity and difficulty level of problems for CCD using LLMs.

### Analysis and Critique:
The article provides valuable insights into the potential of using LLMs, particularly ChatGPT, for code clone detection, emphasizing the importance of different prompts and problem difficulty. However, the study primarily focuses on the effectiveness of ChatGPT without delving into the underlying reasons for its performance in CCD. Additionally, the research acknowledges the vulnerability of ChatGPT to specific types of problems but does not provide a comprehensive understanding of these limitations. Further investigation is required to explore the generalizability of the model's performance to other programming languages. Moreover, the article could benefit from a more detailed discussion on the practical implications of using LLMs for CCD and the potential challenges associated with their deployment in real-world software engineering contexts.

Overall, while the study presents compelling findings regarding the use of LLMs for CCD, it would benefit from a deeper examination of the underlying mechanisms driving the model's performance and a more comprehensive exploration of potential limitations and practical considerations.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-29       |
| Abstract | [http://arxiv.org/abs/2401.13802v1](http://arxiv.org/abs/2401.13802v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.13802v1](https://browse.arxiv.org/html/2401.13802v1)       |
| Truncated       | False       |
| Word Count       | 5349       |