
---
title: "AMONGAGENTS: Evaluating Large Language Models in the Interactive Text-Based Social Deduction Game"
id: "2407.16521v2"
description: "LLMs can grasp game rules and make decisions in AmongAgents, a text-based game mirroring Among Us, for studying simulated human behavior."
author: Yizhou Chi, Lingjun Mao, Zineng Tang
date: "2024-07-24"
image: "https://browse.arxiv.org/html/2407.16521v2/x2.png"
categories: ['hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2407.16521v2/x2.png)

### Summary:

The paper introduces a text-based game environment, AmongAgents, which simulates the dynamics of the popular game Among Us. The study aims to analyze the behavior of simulated language agents in this environment. The experiments involve various game sequences with different configurations of Crewmates and Impostor personality archetypes. The results demonstrate that state-of-the-art large language models (LLMs) can understand game rules and make decisions based on context. The paper encourages further exploration of LLMs in goal-oriented games with incomplete information and complex action spaces.

### Major Findings:

1. LLMs can effectively grasp the game rules and make decisions based on the current context in the AmongAgents environment.
2. The study introduces a text-based game environment, AmongAgents, that mirrors the dynamics of Among Us, providing a valuable tool for studying simulated human behavior.
3. The experiments involve diverse game sequences featuring different configurations of Crewmates and Impostor personality archetypes, offering insights into the behavior of simulated language agents.

### Analysis and Critique:

1. The paper focuses on the potential of LLMs in understanding and making decisions in complex, goal-oriented games but does not address the ethical implications of using such models in simulated environments.
2. The study does not provide a comprehensive comparison of the performance of different LLMs in the AmongAgents environment, which could be a valuable addition to the research.
3. The paper does not discuss the potential for using the AmongAgents environment to train LLMs for improved performance in real-world scenarios, which could be an interesting direction for future research.
4. The paper does not address the potential for bias in the behavior of LLMs in the AmongAgents environment, which could be influenced by the data used to train the models.
5. The study does not explore the potential for using the AmongAgents environment to study the behavior of human players, which could provide valuable insights into human decision-making in complex, goal-oriented games.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-30       |
| Abstract | [https://arxiv.org/abs/2407.16521v2](https://arxiv.org/abs/2407.16521v2)        |
| HTML     | [https://browse.arxiv.org/html/2407.16521v2](https://browse.arxiv.org/html/2407.16521v2)       |
| Truncated       | False       |
| Word Count       | 8569       |