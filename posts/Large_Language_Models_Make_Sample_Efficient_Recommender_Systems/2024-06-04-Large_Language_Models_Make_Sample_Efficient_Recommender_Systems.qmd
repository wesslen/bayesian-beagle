
---
title: "Large Language Models Make Sample-Efficient Recommender Systems"
id: "2406.02368v1"
description: "LLMs improve sample efficiency in recommender systems, requiring less training data to match or surpass conventional models."
author: Jianghao Lin, Xinyi Dai, Rong Shan, Bo Chen, Ruiming Tang, Yong Yu, Weinan Zhang
date: "2024-06-04"
image: "https://browse.arxiv.org/html/2406.02368v1/x1.png"
categories: ['recommender']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.02368v1/x1.png)

### Summary:

The paper explores the application of large language models (LLMs) in recommender systems, focusing on their sample efficiency. The authors propose a framework called Laser, which validates the viewpoint that LLMs can make recommender systems more sample-efficient. The framework consists of two paradigms: (1) using LLMs as the recommender itself, and (2) using LLMs for feature engineering and encoding to assist conventional recommendation models (CRMs). The authors argue that LLMs can infer user preferences and factual knowledge about items under few-shot or even zero-shot settings, which can help alleviate sample inefficiency issues caused by feature and interaction sparsity.

### Major Findings:

1. **LLMs as Sample-Efficient Recommenders:** The paper demonstrates that LLMs can be used as sample-efficient recommenders, as they possess extensive open-world knowledge and powerful logical reasoning capabilities. This enables them to infer user preferences and factual knowledge about items under few-shot or even zero-shot settings.
2. **LLMs Enhancing Sample Efficiency of CRMs:** The authors show that LLMs can also enhance the sample efficiency of CRMs. They propose a framework called LaserLLM+CRM, which uses LLMs as feature generators and encoders to assist CRMs. This approach allows for the LLM processing to be conducted offline, satisfying the strict online inference latency constraints of industrial applications.
3. **Superior Sample Efficiency of Laser:** The authors conduct experiments on two real-world public datasets and show that both Laser and LaserLLM+CRM can match or even surpass CRMs that are trained on the entire training set, using only a small fraction of training samples. This demonstrates the superior sample efficiency of LLMs in recommender systems.

### Analysis and Critique:

While the paper presents an interesting approach to improving the sample efficiency of recommender systems using LLMs, there are a few potential limitations and areas for further research.

1. **Inference Latency:** The inference latency of Laser is high and unavoidable for practical recommender systems, as it directly uses LLMs to perform per-sample CTR estimation tasks. This could be a significant drawback in real-world applications where low latency is

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2406.02368v1](https://arxiv.org/abs/2406.02368v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.02368v1](https://browse.arxiv.org/html/2406.02368v1)       |
| Truncated       | False       |
| Word Count       | 3649       |