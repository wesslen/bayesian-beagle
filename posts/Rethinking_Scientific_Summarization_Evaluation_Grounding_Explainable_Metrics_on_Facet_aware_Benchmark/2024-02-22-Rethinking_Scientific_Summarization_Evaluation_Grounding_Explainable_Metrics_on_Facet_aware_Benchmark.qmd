
---
title: "Rethinking Scientific Summarization Evaluation: Grounding Explainable Metrics on Facet-aware Benchmark"
id: "2402.14359v1"
description: "Pretrained language models are effective for scientific summarization, but traditional evaluation methods are inadequate. New facet-aware metric proposed."
author: Xiuying Chen, Tairan Wang, Qingqing Zhu, Taicheng Guo, Shen Gao, Zhiyong Lu, Xin Gao, Xiangliang Zhang
date: "2024-02-22"
image: "https://browse.arxiv.org/html/2402.14359v1/x1.png"
categories: ['education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.14359v1/x1.png)

### Summary:
- The paper presents an analysis of scientific summarization, highlighting the inadequacies of traditional evaluation methods in providing explanations, grasping scientific concepts, or identifying key content.
- The authors introduce a Facet-aware Metric (FM) employing Large Language Models (LLMs) for advanced semantic matching to evaluate summaries based on different aspects.
- They curate a Facet-based scientific summarization Dataset (FD) with facet-level annotations and find that FM offers a more logical approach to evaluating scientific summaries.

### Major Findings:
1. Traditional evaluation metrics like ROUGE and BERTScore focus on word-level comparisons and lack interpretable reasoning, while QA-based and verification methods have limitations in conducting a thorough assessment.
2. The authors propose a novel Facet-aware Metric (FM) that decomposes the abstract into distinct sections and performs continuous semantic matching, providing a more thorough evaluation of scientific summaries.
3. LLMs like GPT-3.5 and Llama2 consistently achieve higher evaluation scores, demonstrating their robustness and adaptability in different scholarly domains.

### Analysis and Critique:
- The paper effectively addresses the limitations of traditional evaluation metrics and proposes a novel approach to evaluating scientific summaries. However, the reliance on reference summaries and the potential biases encoded within the LLMs raise ethical and methodological concerns.
- The study highlights the need for future research in reference-free summarization evaluation techniques and the development of more refined LLMs to address challenges such as hallucination.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.14359v1](https://arxiv.org/abs/2402.14359v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.14359v1](https://browse.arxiv.org/html/2402.14359v1)       |
| Truncated       | False       |
| Word Count       | 7022       |