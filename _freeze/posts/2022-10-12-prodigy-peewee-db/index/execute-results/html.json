{
  "hash": "bb5693848ecd394c2d2d19e52492e726",
  "result": {
    "markdown": "---\ntitle: \"Prodigy DB: ORM's, peewee and Python\"\nauthor: \"Ryan Wesslen\"\ndescription: \"ORM's, peewee, and how to access Prodigy's database with Python.\"\ndate: \"2022-10-12\"\ncategories: [prodigy, database, orm]\nexecute: \n  enabled: true\n---\n\nIn a [previous post](https://wesslen-blog.netlify.app/posts/2022-10-11-prodigy-db-intro), I described some Prodigy database recipes that enable you to manipulate annotations saved in the default SQLite database. However, you may find you want more database customization. In this post, I will dig into Prodigy's database core concepts. \n\nI'll also show how you can interact with [Prodigy's default database too from Python](#accessing-the-database-programmatically) to enable a more programmatic approach. This enables you to pull from the database using Python, not SQL.\n\nLast, I'll outline experimental database features to highlight possible changes to Prodigy's database system.\n\nIf you're new to Prodigy's database, I recommend starting with [Prodigy's Database documentation](https://prodi.gy/docs/api-database) before this post.\n\n## Under the hood: ORM and peewee\n\nAs of v1.11.8, Prodigy's database uses an ORM, or \"object-relational mapper\". The key idea of an ORM is to implement an object-oriented paradigm to managing databases.\n\nBy contrast, if you're from data analytics, you've likely used databases as SQL database management systems (DBMS) such as SQLite or MySQL. These systems are not object-oriented. They can only store and manipulate scalar values like strings and integers within tables.\n\nNow wait - you may know that [Prodigy implements by default SQLite](https://prodi.gy/docs/api-database). How can Prodigy use an ORM approach but still implement a DBMS like SQLite?\n\nThat's because Prodigy also includes [peewee](http://docs.peewee-orm.com/en/latest/), which is a common open-source ORM and operates as Prodigy's ORM. There are [many alternative ORMs](https://en.wikipedia.org/wiki/List_of_object%E2%80%93relational_mapping_software) and they vary by programming language.\n\nTODO: https://www.fullstackpython.com/object-relational-mappers-orms.html\n\nAn ORM provides a library to convert (\"map\") between objects in code and database tables (\"relations\"). With an ORM, you normally create a class that represents a table in a SQL database, each attribute of the class represents a column, with a name and a type. For example, a class named `Animals` can represent a SQL table `animals`. Each instance object of that class represents a row in the database.\n\nTODO: explain model and connect to second part\n\nSo why would we even use an ORM? \n\nORM's enable us to interact with our database using our language of choice instead of SQL. Because of Prodigy's ORM, this enables us to interface with our database using Python and not SQL.\n\n:::{.column-margin}\nFor a detailed look on ORM's, I recommend [Full Stack Python's post](https://www.fullstackpython.com/object-relational-mappers-orms.html)\n:::\n\nBut another advantage to ORMs is that they make it easier to switch between different relational databases. For example, a developer could use SQLite for local development and MySQL in production (although, not recommended in practice). Since Prodigy has [configurations for either SQLite, MySQL, or PostgreSQL](https://prodi.gy/docs/api-database), this makes it even easier.\n\n:::{.column-margin}\nTo globally modify your database, you can edit the `db` and `db_settings` in Prodigy's [configuration file](https://prodi.gy/docs/install#config), `prodigy.json`.\n:::\n\n## Accessing the database programmatically with Python \n\nProdigy’s database model is available from `prodigy.components.db` in Python.\n\n```python\nfrom prodigy.components.db import connect\n\ndb = connect(\"sqlite\", {\"name\": \"prodigy.db\"}) # default\nexamples = db.get_dataset(\"my_dataset\")\n```\n\nTODO: How to use\n\nTODO: Show data format for data.\n\n```python\nfrom prodigy.components.db import connect\n\nexamples = [{\"text\": \"hello world\", \"_task_hash\": 123, \"_input_hash\": 456}]\n\ndb = connect()                               # uses settings from prodigy.json\ndb.add_dataset(\"test_dataset\")               # add dataset\nassert \"test_dataset\" in db                  # check that dataset was added\ndb.add_examples(examples, [\"test_dataset\"])  # add examples to dataset\ndataset = db.get_dataset(\"test_dataset\")     # retrieve a dataset\nassert len(dataset) == 1                     # check that examples were added\n```\n\nAlternatively, you can view the datasets like: \n\n::: {.cell .column-margin execution_count=1}\n``` {.python .cell-code}\nfrom prodigy.components.db import connect\ndb = connect() \nprint(db.datasets)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['test_dataset']\n```\n:::\n:::\n\n\nTODO: give an interesting example\n\n## Down the road changes\n\nEarlier in 2022, the Prodigy team released a new [experimental branch in Prodigy Support](https://support.prodi.gy/t/duplicate-annotations-in-output/4961/53) that outlines experimental features in Prodigy's database system.\n\nThe new branch includes a new Feed system stores all examples that are to be shown to annotators in the Database. Currently, [Prodigy creates and maps three tables](https://prodi.gy/docs/api-database#setup-tables):\n\n| Table   | Description                                                                                                                                                   |\n|---------|---------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Dataset | The dataset / session IDs and meta information.                                                                                                               |\n| Example | The individual annotation examples. Each example is only added once, so if you add the same annotation to multiple datasets, it’ll only have one record here. |\n| Link    | Example IDs linked to datasets. This is how Prodigy knows which examples belong to which datasets and sessions.                                               |\n\nWhat is new is a fourth table, Feed, which serves as a buffer to handle the batch of data for multiple annotators. Ultimately, this new Feed will replace Prodigy's current generator-based streams and will aim to reduce issues with multi-user annotators.\n\nThis change requires schema changes so it also aligns with a switch to [SQLAlchemy](https://www.sqlalchemy.org/) from `peewee` for Prodigy's ORM. One advantage of this switch is that it can enable more database systems beyond SQLite, PostgreSQL, and MySQL.\n\nIf you're interested in learning more, see this [Prodigy Support issue](https://support.prodi.gy/t/duplicate-annotations-in-output/4961/53), or you can install it:\n\n```bash\npip install prodigy==1.11.8a4 --extra-index-url https://{YOUR_LICENSE_KEY}@download.prodi.gy\n```\n\nand modify `prodigy.json` such that:\n\n```{.json filename=\"prodigy.json\"}\n{\n    \"experimental_feed\": true\n}\n```\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}