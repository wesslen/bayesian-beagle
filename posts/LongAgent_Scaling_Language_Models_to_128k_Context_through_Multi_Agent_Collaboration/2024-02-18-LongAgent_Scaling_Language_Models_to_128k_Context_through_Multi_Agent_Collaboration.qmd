
---
title: "LongAgent: Scaling Language Models to 128k Context through Multi-Agent Collaboration"
id: "2402.11550v1"
description: "LLMs struggle with long context, but LongAgent improves long-text processing."
author: Jun Zhao, Can Zu, Hao Xu, Yi Lu, Wei He, Yiwen Ding, Tao Gui, Qi Zhang, Xuanjing Huang
date: "2024-02-18"
image: "../../img/2402.11550v1/image_1.png"
categories: ['robustness', 'programming']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.11550v1/image_1.png)

### Summary:
- The article introduces LONGAGENT, a method based on multi-agent collaboration, which scales large language models (LLMs) to a context of 128K and demonstrates potential superiority in long-text processing compared to GPT-4. 
- It discusses the performance of LONGAGENT, comparing it with other models and addressing the issue of model hallucination. 
- The section also describes the construction process of the test data for single-document and multi-document QA, providing insights into the dataset used and the process of creating test samples for evaluation. 
- Additionally, it discusses the process of task determination based on the responses of team members, emphasizing the importance of considering all responses to determine the task's solvability.

### Major Findings:
1. LONGAGENT, instantiated with LLaMA-7B, exhibits potential superiority over GPT-4 in handling long texts, indicating its significance in the broader context of the paper.
2. The findings underscore the promising alternative that LONGAGENT offers for long-text processing, addressing the challenges of model hallucination and demonstrating an efficiency advantage over other models.
3. The methodology for constructing test data for single-document and multi-document QA provides crucial insights into the experimental setup and the validity of the results obtained from the QA tasks.

### Analysis and Critique:
- The article presents a promising method in LONGAGENT for addressing the challenges of long-text processing, but further research is needed to validate its performance in diverse contexts and applications.
- The construction process of the test data for QA tasks is well-documented, but potential biases or limitations in the dataset creation process should be critically evaluated.
- The collaborative nature of the task determination process is highlighted, but potential methodological issues or biases in the leader's decision-making process should be considered for a more comprehensive evaluation.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.11550v1](https://arxiv.org/abs/2402.11550v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.11550v1](https://browse.arxiv.org/html/2402.11550v1)       |
| Truncated       | True       |
| Word Count       | 17134       |