
---
title: "Exploring Mathematical Extrapolation of Large Language Models with Synthetic Data"
id: "2406.02100v1"
description: "LLMs improve multi-step reasoning via fine-tuning on synthetic data, showing generalization on out-of-domain tasks."
author: Haolong Li, Yu Ma, Yinqi Zhang, Chen Ye, Jie Chen
date: "2024-06-04"
image: "https://browse.arxiv.org/html/2406.02100v1/extracted/5642379/dn.png"
categories: ['programming']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.02100v1/extracted/5642379/dn.png)

### Summary:

The paper explores the mathematical extrapolation capabilities of Large Language Models (LLMs) using a novel arithmetical puzzle problem. The authors propose a challenging puzzle that requires multi-step calculations to generate a correct solution. They develop a data synthesis pipeline to automatically generate high-quality data for supervised fine-tuning (SFT) and fine-tune a series of LLMs based on open-llama-3B on this synthetic dataset.

To demonstrate the reasoning abilities in extrapolation, the authors design two out-of-domain benchmarks: one by extending the numerical range and the other by changing the composing components of the arithmetical puzzle problem. The models are restricted to greedy sampling in a zero-shot setting, and a corresponding verifier is provided for fair evaluation.

The authors' experiments show that increasing the amount of high-quality synthetic data leads to performance enhancements across in-domain and out-of-domain datasets. The paper also includes a comprehensive case study.

### Major Findings:

1. The authors propose a novel arithmetical puzzle problem with a corresponding data synthesis pipeline and out-of-domain benchmarks to verify the multi-step reasoning and extrapolation capabilities of LLMs fine-tuned on synthetic data.
2. Experiments indicate that increasing the amount of high-quality synthetic data leads to performance enhancements across in-domain and out-of-domain datasets.
3. A comprehensive case study is performed to evaluate the model's performance on the proposed puzzle.

### Analysis and Critique:

The paper presents an interesting approach to exploring the mathematical extrapolation capabilities of LLMs using a novel arithmetical puzzle problem. The authors' use of a data synthesis pipeline to generate high-quality data for SFT and their design of out-of-domain benchmarks are noteworthy.

However, the paper does not discuss the limitations of the proposed approach or potential biases in the synthetic data. Additionally, the authors do not provide a comparison with other methods for fine-tuning LLMs on mathematical reasoning tasks.

Furthermore, the paper does not address the issue of overfitting to the synthetic data, which could limit the model's ability to generalize to real-world mathematical reasoning tasks. The authors could have

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2406.02100v1](https://arxiv.org/abs/2406.02100v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.02100v1](https://browse.arxiv.org/html/2406.02100v1)       |
| Truncated       | False       |
| Word Count       | 3993       |