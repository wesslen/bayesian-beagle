
---
title: "Response Generation for Cognitive Behavioral Therapy with Large Language Models: Comparative Study with Socratic Questioning"
id: "2401.15966v1"
description: "Dialogue systems using LLMs like GPT-4 improve mental health app outcomes. Ethical concerns remain."
author: Kenta Izumi, Hiroki Tanaka, Kazuhiro Shidara, Hiroyoshi Adachi, Daisuke Kanayama, Takashi Kudo, Satoshi Nakamura
date: "2024-01-29"
image: "../../../bayesian-beagle.png"
categories: ['social-sciences', 'hci', 'education', 'production']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### **Summary:**
The study explores the use of large language models (LLMs) in cognitive behavioral therapy (CBT) dialogue systems, focusing on the impact of LLM-generated responses on subjective evaluations such as mood change, cognitive change, and dialogue quality. The researchers compared the use of a Transformer-based dialogue model trained with a social media empathetic counseling dataset (OsakaED) and GPT-4, an LLM created by OpenAI. The results indicate that GPT-4 significantly improves mood change, empathy, and other dialogue qualities, suggesting a high counseling ability. However, the study also found that even when using a dialogue model trained with a human counseling dataset, it does not necessarily yield better outcomes compared to scenario-based dialogues. The authors raise ethical concerns about directly using LLM-generated responses in real-life mental health care services, suggesting that human professionals could produce example responses or response templates using LLMs in advance in systems that use rules, scenarios, or example responses.

### Major Findings:
1. GPT-4 significantly improves mood change, empathy, and other dialogue qualities.
2. Even when using a dialogue model trained with a human counseling dataset, it does not necessarily yield better outcomes compared to scenario-based dialogues.
3. Ethical concerns are raised about directly using LLM-generated responses in real-life mental health care services.

### Analysis and Critique:
The study provides valuable insights into the potential of LLMs in CBT dialogue systems, particularly the significant improvements observed with GPT-4. However, the ethical concerns raised about directly using LLM-generated responses in real-life mental health care services are important to consider. The limitations of the study include the focus on subjective evaluations and the need for further research to explore the long-term impact of LLM-generated responses on mental health outcomes. Additionally, the study does not address potential biases in the LLM-generated responses and the challenges of ensuring responsible and ethical use of LLMs in mental health care settings. Further research is needed to address these limitations and provide a comprehensive understanding of the implications of using LLMs in CBT dialogue systems.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2401.15966v1](https://arxiv.org/abs/2401.15966v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.15966v1](https://browse.arxiv.org/html/2401.15966v1)       |
| Truncated       | False       |
| Word Count       | 1859       |