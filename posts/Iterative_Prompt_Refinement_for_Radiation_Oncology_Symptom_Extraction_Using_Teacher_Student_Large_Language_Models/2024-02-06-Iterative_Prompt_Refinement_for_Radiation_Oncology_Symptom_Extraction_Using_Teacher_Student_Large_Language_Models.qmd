
---
title: "Iterative Prompt Refinement for Radiation Oncology Symptom Extraction Using Teacher-Student Large Language Models"
id: "2402.04075v1"
description: "Novel teacher-student model improves prostate cancer symptom extraction from clinical notes using Large Language Models."
author: Reza Khanmohammadi, Ahmed I Ghanem, Kyle Verdecchia, Ryan Hall, Mohamed Elshaikh, Benjamin Movsas, Hassan Bagher-Ebadian, Indrin Chetty, Mohammad M. Ghassemi, Kundan Thind
date: "2024-02-06"
image: "../../img/2402.04075v1/image_1.png"
categories: ['production', 'prompt-engineering', 'education']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.04075v1/image_1.png)

### Summary:
- The study introduces a novel teacher-student architecture using Large Language Models (LLMs) to improve prostate cancer radiotherapy symptom extraction from clinical notes.
- The iterative prompt refinement process involved 294 single symptom clinical notes across 12 symptoms, with up to 16 rounds of refinement per epoch.
- Results showed significant improvements in extracting symptoms from both single and multi-symptom notes.

### Major Findings:
1. The teacher-student architecture using Large Language Models (LLMs) significantly improved the extraction of symptoms from both single and multi-symptom clinical notes.
2. The iterative prompt refinement process led to substantial increases in accuracy, precision, recall, and F1 scores for both single and multi-symptom notes.
3. The study demonstrated the effectiveness of advanced prompt engineering in LLMs for radiation oncology use.

### Analysis and Critique:
- The study's findings are promising, but potential limitations include the small sample size of single symptom notes used for optimization, which may have led to overfitting.
- Hyperparameter selection for both student and teacher models could have a significant impact on the overall optimization process and should be further explored.
- The study's approach presents a pathway for self-optimized local LLM agents that can extract key concepts in medical notes with a zero-shot learning approach, addressing data privacy concerns in healthcare. However, further research and experimentation are needed to enhance robustness and performance.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.04075v1](https://arxiv.org/abs/2402.04075v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.04075v1](https://browse.arxiv.org/html/2402.04075v1)       |
| Truncated       | False       |
| Word Count       | 5555       |