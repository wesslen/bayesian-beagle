
---
title: "An Empirical Design Justice Approach to Identifying Ethical Considerations in the Intersection of Large Language Models and Social Robotics"
id: "2406.06400v1"
description: "LLMs in social robotics offer benefits but raise ethical concerns like misinformation, biased responses, and emotional disruption, exacerbated by physical embodiment."
author: Alva Markelius
date: "2024-06-10"
image: "../../../bayesian-beagle.png"
categories: ['hci', 'social-sciences']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

**Summary:**

The integration of Large Language Models (LLMs) in social robotics presents a unique set of ethical challenges and social impacts. This research aims to identify ethical considerations that arise in the design and development of these two technologies in combination. Using LLMs for social robotics may provide benefits, such as enabling natural language open-domain dialogues. However, the intersection of these two technologies also gives rise to ethical concerns related to misinformation, non-verbal cues, emotional disruption, and biases. The robotâ€™s physical social embodiment adds complexity, as ethical hazards associated with LLM-based Social AI, such as hallucinations and misinformation, can be exacerbated due to the effects of physical embodiment on social perception and communication. To address these challenges, this study employs an empirical design justice-based methodology, focusing on identifying socio-technical ethical considerations through a qualitative co-design and interaction study. The purpose of the study is to identify ethical considerations relevant to the process of co-design of, and interaction with a humanoid social robot as the interface of a LLM, and to evaluate how a design justice methodology can be used in the context of designing LLMs-based social robotics.

**Major Findings:**

1. The study reveals a mapping of ethical considerations arising in four conceptual dimensions: interaction, co-design, terms of service, and relationship.
2. The ethical considerations identified in the study are affected or introduced by the design of the combination of LLMs and social robotics.
3. The social ethical hazards of LLMs, such as biases, emotional disruption, and misinformation, are perpetuated or escalated with the effects of physical embodiment on social perception and communication when implemented in social robots.
4. Combining LLMs and social robotics gives rise to ethical considerations as a result of the social effects of physical embodiment on interaction, design, social perception, and relationships.

**Analysis and Critique:**

The study presents a novel methodological approach based on previous work on design justice in AI and HRI. The approach enables the identification and validation of ethical concerns through empirical design justice-based data from diverse participants. However, the study also highlights limitations, such as the inability to confidently determine ethical considerations in

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-12       |
| Abstract | [https://arxiv.org/abs/2406.06400v1](https://arxiv.org/abs/2406.06400v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.06400v1](https://browse.arxiv.org/html/2406.06400v1)       |
| Truncated       | False       |
| Word Count       | 14471       |