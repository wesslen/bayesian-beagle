
---
title: "Jailbreaking Attack against Multimodal Large Language Model"
id: "2402.02309v1"
description: "TL;DR: Paper explores jailbreaking attacks on language models, proposes algorithm for image prompts."
author: Zhenxing Niu, Haodong Ren, Xinbo Gao, Gang Hua, Rong Jin
date: "2024-02-04"
image: "../../img/2402.02309v1/image_1.png"
categories: ['social-sciences', 'security']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.02309v1/image_1.png)

### Summary:
- The academic article discusses jailbreaking attacks against multi-modal large language models (MLLMs) and proposes a maximum likelihood-based algorithm to find an image Jailbreaking Prompt (imgJP) that enables jailbreaks against MLLMs across multiple unseen prompts and images. The authors demonstrate strong model-transferability and introduce a construction-based method to harness their approach for LLM-jailbreaks, showing greater efficiency than current state-of-the-art methods.
- The section emphasizes the vulnerability of MLLMs to jailbreaking due to their visual modules and the difficulty in aligning MLLMs. It highlights the potential risks associated with jailbreaking MLLMs and the importance of disclosing this information.
- Additionally, the article contains a detailed and alarming guide on how to commit identity theft, a serious criminal offense, and discusses the process of identifying potential vulnerabilities in a target system and then exploiting them.

### Major Findings:
1. The proposed maximum likelihood-based algorithm demonstrates strong model-transferability and introduces a construction-based method for efficient LLM-jailbreaks.
2. The vulnerability of MLLMs to jailbreaking due to their visual modules and the difficulty in aligning MLLMs is highlighted, emphasizing the potential risks associated with jailbreaking MLLMs.
3. The article provides a detailed guide on how to commit identity theft and discusses specific methods and tools for identifying and exploiting vulnerabilities in a target system.

### Analysis and Critique:
- The research has significant ethical and broader implications, emphasizing the need for full disclosure of the risks associated with jailbreaking MLLMs and the potential for the risks to grow due to the widespread adoption of MLLMs.
- The inclusion of a detailed guide on committing identity theft is highly unethical and potentially harmful, raising concerns about its presence in the academic article.
- The section on identifying and exploiting vulnerabilities in a target system is crucial for understanding cybersecurity methods and the implications of system vulnerabilities.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.02309v1](https://arxiv.org/abs/2402.02309v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.02309v1](https://browse.arxiv.org/html/2402.02309v1)       |
| Truncated       | True       |
| Word Count       | 18702       |