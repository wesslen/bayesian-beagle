
---
title: "Prompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models"
id: "2406.16333v1"
description: "New framework improves text-to-image model reliability, reducing inconsistencies between visual output and textual input."
author: Yichen Sun, Zhixuan Chu, Zhan Qin, Kui Ren
date: "2024-06-24"
image: "https://browse.arxiv.org/html/2406.16333v1/extracted/5622461/figure1.png"
categories: ['robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.16333v1/extracted/5622461/figure1.png)

**Summary:**

The paper introduces a novel diffusion-based framework called Prompt-Consistency Image Generation (PCIG) to address the inconsistency between visual output and textual input in Text-to-Image (T2I) generative models. The framework leverages a state-of-the-art large language module to extract objects and construct a knowledge graph to predict the locations of these objects in potentially generated images. It then integrates a controllable image generation model with a visual text generation module to generate an image that is consistent with the original prompt, guided by the predicted object locations.

**Major Findings:**

1. PCIG significantly enhances the alignment of generated images with their corresponding descriptions, addressing the inconsistency between visual output and textual input.
2. The framework leverages state-of-the-art techniques in natural language processing and computer vision, including large language models (LLMs) and controllable diffusion models.
3. PCIG addresses three key aspects of consistency: (1) general objects, ensuring accurate depiction of object attributes and placement; (2) text within the image, generating legible and correct text; and (3) objects that refer to proper nouns existing in the real world, which cannot be directly generated by the model.
4. Through extensive experiments on an advanced multimodal hallucination benchmark, PCIG demonstrates superior performance in terms of object hallucination accuracy, textual hallucination accuracy, and factual hallucination accuracy.

**Analysis and Critique:**

While PCIG shows promising results in generating images that align with the original prompt, there are some potential limitations and areas for improvement. For instance, the use of GPT4-turbo as the LLM for prompt analysis may introduce additional costs. Additionally, the framework may struggle with generating images with complex relationships and interactions between objects or with small text. Future work could explore the use of more powerful basic diffusion models to address these challenges.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-07       |
| Abstract | [https://arxiv.org/abs/2406.16333v1](https://arxiv.org/abs/2406.16333v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.16333v1](https://browse.arxiv.org/html/2406.16333v1)       |
| Truncated       | False       |
| Word Count       | 5668       |