
---
title: "Language Models Represent Beliefs of Self and Others"
id: "2402.18496v1"
description: "LLMs show ToM abilities through neural activations, impacting social reasoning and diverse tasks."
author: Wentao Zhu, Zhining Zhang, Yizhou Wang
date: "2024-02-28"
image: "https://browse.arxiv.org/html/2402.18496v1/x1.png"
categories: ['social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.18496v1/x1.png)

### **Summary:**
- Large Language Models (LLMs) possess Theory of Mind (ToM) capabilities, but the mechanisms underlying these capabilities are not well understood.
- It is possible to linearly decode belief status from the perspectives of various agents through neural activations of language models, indicating the existence of internal representations of self and others' beliefs.
- Manipulating these representations can dramatically change the models' ToM performance, underscoring their pivotal role in the social reasoning process.

### Major Findings:
1. LLMs can distinguish between different belief states of multiple perspectives through their intermediate activation with simple linear models.
2. Manipulating these representations significantly affects the model's social reasoning performances.
3. The internal belief representations in LLMs generalize across diverse social reasoning task scenarios.

### Analysis and Critique:
- The study provides valuable insights into the ToM capabilities of LLMs, but it is limited to certain types of LLMs and specific social reasoning tasks, which may not capture the full spectrum of ToM capabilities.
- Future work should aim to address these gaps, broadening the understanding of ToM in AI systems across various models and more complex contexts.
- Ethical considerations are crucial to prevent misuse and bias propagation, ensuring AI's societal impact is positive. Responsible development and transparent deployment are imperative to safeguard against unintended consequences and maintain trust in AI advancements.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.18496v1](https://arxiv.org/abs/2402.18496v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.18496v1](https://browse.arxiv.org/html/2402.18496v1)       |
| Truncated       | False       |
| Word Count       | 6809       |