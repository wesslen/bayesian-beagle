
---
title: "Mutation-based Consistency Testing for Evaluating the Code Understanding Capability of LLMs"
id: "2401.05940v1"
description: "LLMs' code understanding performance is assessed using code mutations, showing variation in capability across different types and programming languages."
author: ['Ziyu Li', 'Donghwan Shin']
date: "2024-01-11"
image: "https://browse.arxiv.org/html/2401.05940v1/x1.png"
categories: ['production', 'programming', 'architectures']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.05940v1/x1.png)

# Summary of "Mutation-based Consistency Testing for Evaluating the Code Understanding Capability of LLMs"

## Overall Findings
- The study proposed a novel method called *Mutation-based Consistency Testing (MCT)* to evaluate the code understanding performance of Large Language Models (LLMs) by introducing code *mutations* to create mismatches between code and its natural language descriptions.
- The study conducted a case study on popular LLMs, GPT-3.5 and GPT-4, using the HumanEval-X benchmark and found significant variation in their code understanding performance, with the models showing different strengths and weaknesses depending on the mutation type and programming language.
- The results demonstrated the importance of prompt engineering, with one-shot prompts significantly improving the performance of LLMs in identifying subtle inconsistencies between code and its descriptions.

## 1. Introduction

- Large Language Models (LLMs) have gained attention in software engineering, yet existing benchmarks do not thoroughly assess the code understanding performance of LLMs, especially for subtle inconsistencies between code and its natural language descriptions.

## 2. Background
- Large Language Models (LLMs) are advanced Deep Learning systems that comprehend natural and programming languages. They have been used in various software engineering applications.
- Existing benchmarks such as HumanEval-X assess the code generation ability of LLMs, but do not focus on code understanding, syntax, and semantics.

## 3. Approach
- The study proposed *Mutation-based Consistency Testing (MCT)* to assess the code understanding capability of LLMs using code mutations to create inconsistencies between code and its descriptions.
- Details on prompt engineering and mutant generation were provided.

## 4. Case Study Design
- The case study aimed to evaluate the ability of different LLMs to detect inconsistencies between code and its descriptions, assess their performance across different programming languages, and investigate the impact of one-shot prompt engineering on their performance.

## 5. Case Study Results
- Findings included the impact of mutation operators and programming languages on LLM performance, the explanation of test results, and the impact of prompt engineering.

## 5.5. Threats to Validity
- Potential threats to validity included implementation bugs and the impact of input understanding on model performance.

## 6. Data Availability
- The replication package, including the MCT method implementation and execution results, is available for public access.

## 7. Related Work
- The study highlighted the existing literature on LLM testing, focusing on code generation and code understanding.

## 8. Conclusion
- The study concluded that MCT can effectively assess the code understanding capability of LLMs and offered suggestions for future research in this area.

### Critique
- The paper provides a comprehensive exploration of MCT for evaluating LLMs, but potential limitations include the small scale of the case study and reliance on GPT-3.5 and GPT-4, which may not fully represent all LLMs.

The paper provides valuable insights into evaluating LLMs' code understanding capability and introduces a novel method, MCT, to assess LLM performance in identifying subtle code inconsistencies. The findings have implications for future research and development of LLM-based software engineering, with potential for further exploration and refinement of the MCT approach.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-02       |
| Abstract | [http://arxiv.org/abs/2401.05940v1](http://arxiv.org/abs/2401.05940v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.05940v1](https://browse.arxiv.org/html/2401.05940v1)       |
| Truncated       | False       |
| Word Count       | 11106       |