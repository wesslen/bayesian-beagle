
---
title: "COMCAT: Leveraging Human Judgment to Improve Automatic Documentation and Summarization"
id: "2407.13648v1"
description: "ComCat automates comment generation for code, improving comprehension by up to 12% and offering accurate, readable comments preferred over ChatGPT-generated ones."
author: Skyler Grandel, Scott Thomas Andersen, Yu Huang, Kevin Leach
date: "2024-07-18"
image: "https://browse.arxiv.org/html/2407.13648v1/extracted/5727629/fig/summary_bar_graph.png"
categories: ['programming']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2407.13648v1/extracted/5727629/fig/summary_bar_graph.png)

### Summary:

The ComCat pipeline is a novel approach to automate comment generation in software documentation. It leverages human judgment to target the annotation of source code with comments that improve comprehension. The pipeline identifies suitable locations for comments, predicts the most helpful type of comment for each location, and generates a comment based on the selected location and comment type. In a human subject evaluation, ComCat-generated comments significantly improved developer code comprehension across three indicative software engineering tasks by up to 12% for 87% of participants. Additionally, ComCat-generated comments were at least as accurate and readable as human-generated comments and were preferred over standard ChatGPT-generated comments for up to 92% of snippets of code.

### Major Findings:

1. ComCat-generated comments significantly improve developer code comprehension across three indicative software engineering tasks by up to 12% for 87% of participants.
2. ComCat-generated comments are at least as accurate and readable as human-generated comments.
3. ComCat-generated comments are preferred over standard ChatGPT-generated comments for up to 92% of snippets of code.

### Analysis and Critique:

While ComCat demonstrates promising results in improving code comprehension and generating accurate and readable comments, there are potential limitations and areas for further research. The dataset used for training and evaluation may have biases inherent in the code and comments scraped from GitHub projects. Additionally, the evaluation of ChatGPT is reliant on prompt quality, which may introduce variability in the results. Future research could explore the application of ComCat to other programming languages and investigate the impact of different prompt engineering techniques on the quality of generated comments.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-30       |
| Abstract | [https://arxiv.org/abs/2407.13648v1](https://arxiv.org/abs/2407.13648v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.13648v1](https://browse.arxiv.org/html/2407.13648v1)       |
| Truncated       | False       |
| Word Count       | 11075       |