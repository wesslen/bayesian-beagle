
---
title: "ConceptMath: A Bilingual Concept-wise Benchmark for Measuring Mathematical Reasoning of Large Language Models"
id: "2402.14660v1"
description: "ConceptMath evaluates LLMs' mathematical reasoning at different granularities, revealing performance variations and offering fine-tuning strategies."
author: Yanan Wu, Jie Liu, Xingyuan Bu, Jiaheng Liu, Zhanhui Zhou, Yuanxing Zhang, Chenchen Zhang, Zhiqi Bai, Haibin Chen, Tiezheng Ge, Wanli Ouyang, Wenbo Su, Bo Zheng
date: "2024-02-22"
image: "https://browse.arxiv.org/html/2402.14660v1/x1.png"
categories: ['architectures']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.14660v1/x1.png)

### **Summary:**
- ConceptMath is a bilingual benchmark that evaluates concept-wise mathematical reasoning of Large Language Models (LLMs).
- It organizes math problems under a hierarchy of math concepts to evaluate mathematical reasoning at different granularity.
- Existing LLMs exhibit significant performance variations across different math concepts and may fail on basic ones.

### Major Findings:
1. ConceptMath systematically organizes math problems under a hierarchy of math concepts to evaluate mathematical reasoning at different granularity.
2. Existing LLMs exhibit significant performance variations across different math concepts and may fail catastrophically on basic ones.
3. An efficient fine-tuning strategy is introduced to enhance the weaknesses of existing LLMs.

### Analysis and Critique:
- The paper introduces a comprehensive benchmark for evaluating mathematical reasoning of LLMs, but it requires human efforts to design the hierarchical systems of mathematical concepts.
- The contamination rates of ConceptMath are low, indicating its effectiveness in evaluating existing LLMs.
- The paper provides a simple and efficient fine-tuning strategy to enhance the weaknesses of existing LLMs, but it may require further validation and testing.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.14660v1](https://arxiv.org/abs/2402.14660v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.14660v1](https://browse.arxiv.org/html/2402.14660v1)       |
| Truncated       | False       |
| Word Count       | 6235       |