
---
title: "Chain of Targeted Verification Questions to Improve the Reliability of Code Generated by LLMs"
id: "2405.13932v1"
description: "Self-refinement method improves LLM-generated code reliability, reducing bugs by up to 62% without human intervention or test cases."
author: Sylvain Kouemo Ngassom, Arghavan Moradi Dakhel, Florian Tambon, Foutse Khomh
date: "2024-05-22"
image: "../../../bayesian-beagle.png"
categories: ['programming']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### Summary:

The study proposes a self-refinement method aimed at improving the reliability of code generated by LLMs by minimizing the number of bugs before execution, without human intervention, and in the absence of test cases. The approach is based on targeted Verification Questions (VQs) to identify potential bugs within the initial code, which target various nodes within the Abstract Syntax Tree (AST) of the initial code. These nodes have the potential to trigger specific types of bug patterns commonly found in LLM-generated code. The method then attempts to repair these potential bugs by re-prompting the LLM with the targeted VQs and the initial code. The evaluation, based on programming tasks in the CoderEval dataset, demonstrates that the proposed method outperforms state-of-the-art methods by decreasing the number of targeted errors in the code between 21% to 62% and improving the number of executable code instances to 13%.

### Major Findings:

1. The proposed self-refinement method, which uses targeted VQs, improves the reliability of code generated by LLMs by minimizing the number of bugs before execution, without human intervention, and in the absence of test cases.
2. The method targets various nodes within the AST of the initial code, which have the potential to trigger specific types of bug patterns commonly found in LLM-generated code.
3. The evaluation, based on programming tasks in the CoderEval dataset, demonstrates that the proposed method outperforms state-of-the-art methods by decreasing the number of targeted errors in the code between 21% to 62% and improving the number of executable code instances to 13%.

### Analysis and Critique:

The proposed method is a promising approach to improving the reliability of code generated by LLMs. However, there are some potential limitations and areas for further research.

1. The method relies on the ability of the LLM to accurately identify and repair potential bugs in the code. The performance of the method may be affected by the quality and accuracy of the LLM.
2. The method targets specific types of bug patterns commonly found in LLM-generated code. However, there may be other types of bugs that are not addressed by the method. Further research is needed to identify

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2405.13932v1](https://arxiv.org/abs/2405.13932v1)        |
| HTML     | [https://browse.arxiv.org/html/2405.13932v1](https://browse.arxiv.org/html/2405.13932v1)       |
| Truncated       | False       |
| Word Count       | 10246       |