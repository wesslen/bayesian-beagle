
---
title: "GenSco: Can Question Decomposition based Passage Alignment improve Question Answering?"
id: "2407.10245v1"
description: "TL;DR: GenSco selects passages for multi-hop QA, improving LLM answer generation and efficiency."
author: Barah Fazili, Koustava Goswami, Natwar Modani, Inderjeet Nair
date: "2024-07-14"
image: "https://browse.arxiv.org/html/2407.10245v1/extracted/5730511/tnr-1.png"
categories: ['education', 'robustness', 'prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2407.10245v1/extracted/5730511/tnr-1.png)

### Summary:

The paper introduces a novel approach called "GenSco" for selecting a passage sequence for multi-hop question answering. GenSco leverages an open-source LLM as a scorer to guide the Generator LLM for passage sequence selection before answer generation. The proposed approach starts with an empty context and generates a sub-question from the question, the context collected up to now, and the sub-questions generated up to now. The generated sub-question is then used to rank all the candidate passages based on negative log-likelihood using the scorer LLM. The passage with the best score is added to the context, and the generator LLM is asked to generate the next sub-question. The process continues until the stopping criteria are met, and the context is then passed to the generator LLM for final answer generation.

### Major Findings:

1. GenSco achieves an absolute gain of  and  points in Exact Match score with respect to the best performing baselines over MuSiQue and 2WikiMultiHop datasets, respectively.
2. GenSco effectively mitigates hallucination in the LLM responses by achieving high precision on the passage retrieval task.
3. GenSco is an inference-only approach, making it data-efficient and cost-effective.

### Analysis and Critique:

1. The proposed approach assumes that the generator LLM is a black box, which may not always be the case.
2. The approach relies on the scorer LLM to guide the generator LLM, which may introduce bias or errors if the scorer LLM is not accurate.
3. The approach requires specifying an upper limit on the number of levels that can be explored, which may limit the exploration of the search space.
4. The approach does not address the issue of handling ambiguous or underspecified questions, which may require additional context or clarification.
5. The approach does not consider the possibility of multiple valid answers to a question, which may require a more nuanced evaluation metric.
6. The approach does not address the issue of handling out-of-domain questions, which may require additional training data or domain-specific knowledge.
7. The approach does not consider the computational cost of generating sub-questions and ranking passages, which may be a

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-16       |
| Abstract | [https://arxiv.org/abs/2407.10245v1](https://arxiv.org/abs/2407.10245v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.10245v1](https://browse.arxiv.org/html/2407.10245v1)       |
| Truncated       | False       |
| Word Count       | 7220       |