
---
title: "Towards Verifiable Text Generation with Evolving Memory and Self-Reflection"
id: "2312.09075v1"
description: "Large Language Models (LLMs) face challenges in accuracy and verification. An innovative approach, VTG, uses memory and retrieval to improve text generation."
author: ['Hao Sun', 'Hengyi Cai', 'Bo Wang', 'Yingyan Hou', 'Xiaochi Wei', 'Shuaiqiang Wang', 'Yan Zhang', 'Dawei Yin']
date: "2023-12-14"
image: "https://browse.arxiv.org/html/2312.09075v1/x1.png"
categories: ['robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2312.09075v1/x1.png)

### Major Takeaways:
1. Verifiable text generation (VTG) addresses the challenges faced by Large Language Models (LLMs), such as hallucination, by incorporating citations for accuracy verification in content generation.
2. VTG introduces an innovative approach with evolving memory and self-reflection to maintain the accuracy and credibility of the generated content.
3. Extensive experiments on diverse datasets reveal that VTG outperforms existing baselines in both citation quality and answering correctness.

### Method:
- **Evolving Memory System**: VTG features an evolving memory system with long-term memory and short-term memory to dynamically retain valuable and up-to-date documents for content generation.
- **Active Retrieval and Diverse Query Generation**: VTG utilizes active retrieval and diverse query generation to enhance both precision and scope of retrieved documents, improving the credibility and reliability of citations.
- **Two-tier Verifier and Evidence Finder**: The framework employs a two-tier verifier and an evidence finder to analyze and reflect on the relationship between claims and citations, ensuring thorough and accurate verification.

### Experiment:
- **Datasets and Baselines**: The experiment involves five datasets across three knowledge-intensive tasks, comparing VTG with four baseline methodologies, namely Vanilla, Summ, Snippet, and Rerank.
- **Performance**: VTG outperforms existing baselines across various datasets and metrics, significantly enhancing citation quality and answering correctness.

### Ablation Study:
- The study highlights the significance of each component in VTG, emphasizing the crucial role of the verifier, simplifier, and query generation in improving performance.

### Critique:
- The paper provides a comprehensive and innovative approach to verifiable text generation, addressing major challenges faced by LLMs. However, the study primarily focuses on the effectiveness of VTG without discussing potential limitations or trade-offs associated with the proposed framework. Additionally, further investigation into the scalability and generalizability of VTG to different domains and tasks could provide a more comprehensive evaluation of its practical applicability.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-29       |
| Abstract | [http://arxiv.org/abs/2312.09075v1](http://arxiv.org/abs/2312.09075v1)        |
| HTML     | [https://browse.arxiv.org/html/2312.09075v1](https://browse.arxiv.org/html/2312.09075v1)       |
| Truncated       | False       |
| Word Count       | 7635       |