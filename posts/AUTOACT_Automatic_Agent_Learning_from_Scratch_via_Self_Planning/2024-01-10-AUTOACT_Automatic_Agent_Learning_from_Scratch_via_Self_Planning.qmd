
---
title: "AUTOACT: Automatic Agent Learning from Scratch via Self-Planning"
id: "2401.05268v1"
description: "AutoAct is an automatic agent learning framework that eliminates reliance on large-scale annotated data and synthetic trajectories. It outperforms strong baselines with limited data and achieves performance comparable to GPT-3.5-Turbo. Code available on GitHub."
author: Shuofei Qiao, Ningyu Zhang, Runnan Fang, Yujie Luo, Wangchunshu Zhou, Yuchen Eleanor Jiang, Chengfei Lv, Huajun Chen
date: "2024-01-10"
image: "https://browse.arxiv.org/html/2401.05268v1/x1.png"
categories: ['architectures', 'production']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.05268v1/x1.png)

## Summary of "AutoAct: Automatic Agent Learning from Scratch via Self-Planning"

### Key Findings
1. **AutoAct** is an automatic agent learning framework that does not rely on large-scale annotated data and synthetic trajectories from closed-source models. It leverages a *division-of-labor strategy* to differentiate the Meta-Agent based on target task information and synthesized trajectories, producing a sub-agent group to complete the task. 
2. Experimentation with various large language models (LLMs) demonstrates that AutoAct yields better or parallel performance compared to various strong baselines, including achieving performance comparable to GPT-3.5-Turbo agent using the Llama-2-13b model.
3. The study suggests that a *proper division-of-labor strategy* and the quality of trajectories generated by AutoAct significantly outperforms that of other methods from multiple aspects.

### AutoAct Framework (Summary)
- **Overview**: AutoAct framework initiates with self-instruct to extend the task database from scratch and self-planning is applied to conduct automatic agent learning, including automatic tool selection, trajectories synthesis, self-differentiation and group planning.
- **Critical Components of AutoAct**: It includes the Meta-Agent, target task information, and a tool library.
- **Starting from Scratch via Self-Instruct**: Self-instruct is used to augment the task data based on the examples at hand.
- **Automatic Agent Learning via Self-Planning**: It includes automatic tool selection, trajectories synthesis, self-differentiation, and group planning.

### Experimental Setup
- **Tasks**: Evaluation was conducted on HotpotQA and ScienceQA question-answering tasks.
- **Baselines**: Open-source Llama-2 models were chosen as the backbones. Comparison was made with CoT, ReAct, Reflexion, Chameleon, FireAct, BOLAA, and GPT-3.5-Turbo.
- **Training Setups**: Models were fine-tuned with LoRA and FastChat using DeepSpeed. Different learning rates, sequence lengths, and optimizer types were used for different model scales.

### Critique
The paper's strength lies in proposing a novel automatic agent learning framework. However, the paper lacks a thorough comparison with existing related works, and the evaluation is limited to question-answering tasks only. Additionally, the results heavily focus on performance, without much insight into the interpretability or robustness of the AutoAct framework, leaving potential areas for further investigation.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-27       |
| Abstract | [http://arxiv.org/abs/2401.05268v1](http://arxiv.org/abs/2401.05268v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.05268v1](https://browse.arxiv.org/html/2401.05268v1)       |
| Truncated       | False       |
| Word Count       | 9023       |