
---
title: "Large Language Models are Not Stable Recommender Systems"
id: "2312.15746v1"
description: "LLMs' positional bias hinders recommendation stability. Researchers propose STELLA, a Bayesian framework, to mitigate bias and improve recommendation performance in LLMs."
author: Tianhui Ma, Yuan Cheng, Hengshu Zhu, Hui Xiong
date: "2023-12-25"
image: "https://browse.arxiv.org/html/2312.15746v1/x1.png"
categories: ['recommender']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2312.15746v1/x1.png)

### Main Findings

- Large language models (LLMs) used as recommender systems exhibit **instability due to inherent position bias** which leads to varying recommendation performance as the position of ground truth items changes.
- The paper presents a two-stage Bayesian probabilistic framework, STELLA, which identifies and addresses the positional bias, enhancing recommendation performance.

### Introduction
- Recommender systems are critical for various online services, and traditional models have limited capability in capturing user preferences in complex scenarios.
- LLMs have gained attention for recommendation systems, but their inherent position bias leads to instability.

### Position Bias in Large Language Models
- LLMs exhibit **consistent position bias** affecting recommendation performance across various scenarios.
- Analysis shows sensitivity to prompt designs, candidate set sizes, and context of candidate items.

### Calibrating the Position Bias
- **Probing Stage**: A probing set is used to identify patterns in a transition matrix, reflecting the position bias in LLMs.
- **Recommendation Stage**: Bayesian updating is used to adjust biased output based on the transition matrix, improving recommendation accuracy.

### Experiments
- Evaluation on four diverse datasets (movies, books, music, news) shows the effectiveness of STELLA in providing **stable and accurate recommendations**, outperforming the raw outputs and a baseline Bootstrapping strategy.

### Ablation Study
- The study demonstrates the importance of the transition matrix and the proper length of ensemble steps in the probing detection set for **improving recommendation accuracy**.

### Critique
- While the paper effectively presents the challenges of using LLMs as recommender systems and proposes an innovative solution, the evaluation is limited to a specific LLM (ChatGPT) and small-scale datasets. Further evaluation on larger-scale LLMs and real-world data is needed to validate the effectiveness of STELLA in diverse scenarios.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-05       |
| Abstract | [http://arxiv.org/abs/2312.15746v1](http://arxiv.org/abs/2312.15746v1)        |
| HTML     | [https://browse.arxiv.org/html/2312.15746v1](https://browse.arxiv.org/html/2312.15746v1)       |
| Truncated       | False       |
| Word Count       | 8647       |