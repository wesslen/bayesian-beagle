
---
title: "On the Scaling Laws of Geographical Representation in Language Models"
id: "2402.19406v1"
description: "Language Models Contain and Scale with Geographical Bias"
author: Nathan Godey, Éric de la Clergerie, Benoît Sagot
date: "2024-02-29"
image: "https://browse.arxiv.org/html/2402.19406v1/x1.png"
categories: ['social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.19406v1/x1.png)

### Summary:

- Recent studies have shown that language models implicitly embed geographical information in their hidden representations.
- This geographical knowledge can be observed even in tiny models and scales consistently as the model size increases.
- Larger language models cannot mitigate the geographical bias inherited from the training data.

### Major Findings:

1. **Geographical knowledge in language models:** Geographical knowledge is observable even in tiny models and scales consistently as the model size increases.
2. **Geographical bias in language models:** Larger language models cannot mitigate the geographical bias inherited from the training data.
3. **Correlation between model performance and training data frequency:** The performance of models in terms of geographical probing is correlated with the frequency of corresponding country names in the training data.

### Analysis and Critique:

- The study does not provide a clear definition of what constitutes a "tiny"

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x7b-instruct       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.19406v1](https://arxiv.org/abs/2402.19406v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.19406v1](https://browse.arxiv.org/html/2402.19406v1)       |
| Truncated       | False       |
| Word Count       | 3038       |