
---
title: "Self-assessment, Exhibition, and Recognition: a Review of Personality in Large Language Models"
id: "2406.17624v1"
description: "TL;DR: This paper reviews studies on personality in large language models, categorizing them into self-assessment, exhibition, and recognition, and discusses challenges and future directions."
author: Zhiyuan Wen, Yu Yang, Jiannong Cao, Haoming Sun, Ruosong Yang, Shuaiqi Liu
date: "2024-06-25"
image: "../../../bayesian-beagle.png"
categories: ['hci']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### Summary:

This paper presents a comprehensive review of the latest studies on personality in Large Language Models (LLMs). The authors propose a hierarchical taxonomy to organize the existing research into three research problems: self-assessment, exhibition, and recognition. The paper provides a thorough analysis of each problem, conducts in-depth investigations and comparisons of the corresponding methods, and consolidates findings and open challenges. The authors also collect publicly available resources, including personality inventories, code repositories, and datasets, to facilitate researchers and developers.

### Major Findings:

1. Self-assessment: Most studies rely on prompt engineering to instruct LLMs to complete questionnaires for personality assessment. However, there is no consensus on personality assessment results due to the diversity in assessment methods. Multiple studies agree that LLMs often exhibit darker traits than humans.
2. Exhibition: Editing and inducing methods are used to control LLMs to reflect specified personality traits in the generated text content. Editing methods modify the model parameters of LLMs, while inducing methods utilize prompt engineering to induce LLMs to exhibit specific personalities.
3. Recognition: LLMs can recognize personality traits from the given text content. LLMs can be used to enhance existing personality recognition models by augmenting the input data or providing additional features.

### Analysis and Critique:

The paper provides a comprehensive review of the latest studies on personality in LLMs. However, the authors acknowledge that most of the reviewed studies are from the perspective of computer science, which has led to their taxonomy being more based on a computer science viewpoint. The authors also highlight that some of the reviewed methods do not have a solid grounding in the social sciences. The authors hope that their survey can attract researchers from the social sciences to contribute more rational research methodologies from social science perspectives to Personality in LLMs.

The paper also acknowledges that the number of papers in this emerging domain has been increasing annually, indicating a growing interest in the field. However, the authors note that there is a relatively less increase of personality recognition in LLM compared to the two new research problems. This may be attributed to the fact that personality recognition, as a classical text classification problem, has been already widely studied with traditional methods. Nevertheless, personality recognition based on LLMs remains crucial in LLM-based interactions.

The

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-07       |
| Abstract | [https://arxiv.org/abs/2406.17624v1](https://arxiv.org/abs/2406.17624v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.17624v1](https://browse.arxiv.org/html/2406.17624v1)       |
| Truncated       | False       |
| Word Count       | 9841       |