
---
title: "Reasoning about concepts with LLMs: Inconsistencies abound"
id: "2405.20163v1"
description: "LLMs exhibit inconsistencies in conceptual knowledge; simple ontologies can reveal these, and KG-based prompting strategies can improve LLM performance."
author: Rosario Uceda-Sosa, Karthikeyan Natesan Ramamurthy, Maria Chang, Moninder Singh
date: "2024-05-30"
image: "https://browse.arxiv.org/html/2405.20163v1/x1.png"
categories: ['prompt-engineering', 'education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2405.20163v1/x1.png)

### Summary:

The paper discusses the inconsistencies in the knowledge displayed by large language models (LLMs) when questioned methodically. The authors propose strategies for domain experts to evaluate and improve the coverage of key domain concepts in LLMs. They demonstrate that using simple knowledge-graph (KG) based prompting strategies can significantly enhance the performance of LLMs with openly available weights.

The authors argue that the consistent use and reasoning about a concept hierarchy by LLMs is critical in several industrial applications. They propose a three-step process to test and correct inconsistencies in LLMs, which includes extracting a concept hierarchy to be tested from a knowledge base, creating various test cases to sieve inconsistencies via direct questioning, and testing the language model to identify inconsistencies and reduce them using additional context.

The authors also discuss the integration of KGs and LLMs, which holds the potential for creating more accurate and reliable AI systems, especially in applications requiring both precise information and sophisticated language capabilities.

### Major Findings:

1. LLMs often display and demonstrate significant inconsistencies in their knowledge when methodically questioned.
2. Simple ontologies can be used to reveal conceptual inconsistencies across several LLMs.
3. Using simple prompting approaches, the authors have been able to significantly enhance the performance of LLMs of various sizes with openly available weights.

### Analysis and Critique:

The paper provides a valuable contribution to the field by highlighting the inconsistencies in LLMs and proposing strategies to evaluate and improve their performance. However, the paper does not discuss the potential limitations of the proposed strategies or the potential biases that may be introduced by the use of KGs. Additionally, the paper does not provide a comprehensive evaluation of the proposed strategies or a comparison with other methods for improving the performance of LLMs.

Further research is needed to evaluate the effectiveness of the proposed strategies in different domains and to compare them with other methods for improving the performance of LLMs. Additionally, it would be useful to explore the potential limitations and biases of the proposed strategies and to develop methods for mitigating these issues.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2405.20163v1](https://arxiv.org/abs/2405.20163v1)        |
| HTML     | [https://browse.arxiv.org/html/2405.20163v1](https://browse.arxiv.org/html/2405.20163v1)       |
| Truncated       | False       |
| Word Count       | 7062       |