
---
title: "Consistency Matters: Explore LLMs Consistency From a Black-Box Perspective"
id: "2402.17411v1"
description: "LLM consistency is lacking in NLP research. We built a dataset and achieved best performance."
author: Fufangchen Zhao, Guoqiang Jin, Jiaheng Huang, Rui Zhao, Fei Tan
date: "2024-02-27"
image: "https://browse.arxiv.org/html/2402.17411v1/extracted/5434342/consistency_2.png"
categories: ['architectures']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.17411v1/extracted/5434342/consistency_2.png)

### **Summary:**
- The article addresses the lack of research on Large Language Model (LLM) consistency, which refers to the need for LLMs to ensure that their internal parameters and model capabilities remain unchanged across various scenarios and stages of research and application.
- The authors propose an LLM consistency task dataset and design several baselines, using models of diverse scales for the main experiments. They use traditional Nature Language Generation (NLG) metrics for model training and achieve the best performance with the LightGBM model.
- The authors also propose an automated evaluation tool that analyzes response pairs for end-to-end verification of model consistency and provide a new Chinese-English dataset specifically designed for model consistency checkout task.

### Major Findings:
1. The lack of research on LLM consistency is a significant issue in both industrial and academic sectors.
2. The LightGBM model outperformed GPT3.5 and other models in the main experiment, achieving the best performance in evaluating LLM consistency.
3. The introduction of the question feature optimizes the evaluation of both positive and negative cases in the LLM consistency task.

### Analysis and Critique:
- The article provides valuable insights into the importance of LLM consistency and proposes a practical solution for evaluating model consistency. However, the study's limitations include differences between the experimental environment and real-world application of LLMs, as well as the time cost required for constructing a sufficient number of test cases using a large number of LLMs or LLMs APIs. Additionally, the impact of the question on the evaluation results raises questions about the generalizability of the proposed evaluation tool. Further research is needed to address these limitations and validate the effectiveness of the proposed approach in real-world scenarios.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.17411v1](https://arxiv.org/abs/2402.17411v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.17411v1](https://browse.arxiv.org/html/2402.17411v1)       |
| Truncated       | False       |
| Word Count       | 6300       |