
---
title: "Hidding the Ghostwriters: An Adversarial Evaluation of AI-Generated Student Essay Detection"
id: "2402.00412v1"
description: "TL;DR: Large language models pose risks in education due to easy evasion of detection methods."
author: Xinlin Peng, Ying Zhou, Ben He, Le Sun, Yingfei Sun
date: "2024-02-01"
image: "../../../bayesian-beagle.png"
categories: ['robustness', 'security', 'education']
format:
  html:
    code-overflow: wrap
---

![](None)

### **Summary:**
- Large language models (LLMs) have remarkable capabilities in text generation tasks, but they carry inherent risks, including plagiarism and dissemination of fake news.
- AIG-ASAP, an AI-generated student essay dataset, was constructed to assess the performance of current AIGC detectors on AI-generated student essays.
- Existing detectors can be easily circumvented using straightforward automatic adversarial attacks, highlighting the need for more accurate and robust detection methods.

### Major Findings:
1. The utilization of large language models (LLMs) in educational exercises poses challenges related to ethical and practical implications.
2. AIG-ASAP dataset was constructed to assess the performance of current AIGC detectors on AI-generated student essays.
3. Existing detectors can be easily circumvented using straightforward automatic adversarial attacks, highlighting the need for more accurate and robust detection methods.

### Analysis and Critique:
- The study highlights the urgent need for more accurate and robust methods to detect AI-generated student essays in the education domain.
- The AIG-ASAP dataset provides valuable insights into the vulnerabilities of existing detection methods and the potential for circumvention through adversarial attacks.
- The study does not delve into the practical implementation and deployment of proposed detection methods, which could impact the real-world applicability of the research.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-02       |
| Abstract | [https://arxiv.org/abs/2402.00412v1](https://arxiv.org/abs/2402.00412v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.00412v1](https://browse.arxiv.org/html/2402.00412v1)       |
| Truncated       | False       |
| Word Count       | 14877       |