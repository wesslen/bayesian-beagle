
---
title: "Self-Distillation Bridges Distribution Gap in Language Model Fine-Tuning"
id: "2402.13669v1"
description: "TL;DR: Self-Distillation Fine-Tuning bridges distribution gap, improves LLM performance on specific tasks."
author: Zhaorui Yang, Qian Liu, Tianyu Pang, Han Wang, Haozhe Feng, Minfeng Zhu, Wei Chen
date: "2024-02-21"
image: "https://browse.arxiv.org/html/2402.13669v1/x1.png"
categories: ['architectures']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.13669v1/x1.png)

### Summary:
- The surge in Large Language Models (LLMs) has revolutionized natural language processing, but fine-tuning them for specific tasks often encounters challenges in balancing performance and preserving general instruction-following abilities.
- The distribution gap between task datasets and LLMs is identified as the primary underlying cause of these challenges.
- Self-Distillation Fine-Tuning (SDFT) is introduced as a novel approach to bridge the distribution gap by guiding fine-tuning with a distilled dataset generated by the model itself to match its original distribution.
- Experimental results demonstrate that SDFT effectively mitigates catastrophic forgetting while achieving comparable or superior performance on downstream tasks compared to vanilla fine-tuning.

### Major Findings:
1. SDFT effectively mitigates catastrophic forgetting while achieving comparable or superior performance on downstream tasks compared to vanilla fine-tuning.
2. The proposed method demonstrates the potential to maintain the helpfulness and safety alignment of LLMs.
3. Fine-tuning on various datasets leads to a significant decrease in both safety alignment and general helpfulness, but SDFT effectively mitigates this decline.

### Analysis and Critique:
- The study is limited by computational resources, and further investigations involving larger models and full parameter tuning are needed.
- The safety evaluations are limited to specific datasets and adversarial suffixes, leaving the robustness against other jailbreak strategies for future research.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.13669v1](https://arxiv.org/abs/2402.13669v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.13669v1](https://browse.arxiv.org/html/2402.13669v1)       |
| Truncated       | False       |
| Word Count       | 6203       |