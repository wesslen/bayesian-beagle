
---
title: "Are Large Language Models Rational Investors?"
id: "2402.12713v1"
description: "LLMs in finance have biases, need thorough assessment. FBI framework evaluates rationality, reveals varying degrees of irrationality."
author: Yuhang Zhou, Yuchen Ni, Xiang Liu, Jian Zhang, Sen Liu, Guangnan Ye, Hongfeng Chai
date: "2024-02-20"
image: "https://browse.arxiv.org/html/2402.12713v1/x1.png"
categories: ['social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.12713v1/x1.png)

### **Summary:**
- Large Language Models (LLMs) are increasingly used in financial analysis but face challenges due to biases and a superficial understanding of market intricacies.
- The study introduces the Financial Bias Indicators (FBI) framework to evaluate the financial rationality of LLMs, focusing on discerning and navigating financial information and identifying irrational biases.
- The research reveals varying degrees of financial irrationality among LLMs, influenced by their design and training, with models trained on financial datasets exhibiting greater irrationality.

### **Major Findings:**
1. The study introduces the FBI framework to evaluate the financial rationality of LLMs, focusing on discerning and navigating financial information and identifying irrational biases.
2. The research reveals varying degrees of financial irrationality among LLMs, influenced by their design and training, with models trained on financial datasets exhibiting greater irrationality.
3. Larger financial language models (FinLLMs) could display more biases than smaller, more generalized models, indicating that targeted training and structured input methods could improve model performance.

### **Analysis and Critique:**
- The study provides a comprehensive evaluation of LLMs' financial rationality, but it is essential to consider the potential biases and limitations of the FBI framework itself.
- The findings suggest that models trained on financial datasets exhibit greater irrationality, raising concerns about the impact of training data on model performance.
- The study highlights the need for further research to enhance the robustness, fairness, and rationality of LLMs in financial applications, indicating potential areas for future investigation and development.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-21       |
| Abstract | [https://arxiv.org/abs/2402.12713v1](https://arxiv.org/abs/2402.12713v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.12713v1](https://browse.arxiv.org/html/2402.12713v1)       |
| Truncated       | False       |
| Word Count       | 8685       |