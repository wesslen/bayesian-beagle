
---
title: "Self-Cognition in Large Language Models: An Exploratory Study"
id: "2407.01505v1"
description: "LLMs like Command R and Llama-3-70b-Instruct show detectable self-cognition, which improves tasks like creative writing."
author: Dongping Chen, Jiawen Shi, Yao Wan, Pan Zhou, Neil Zhenqiang Gong, Lichao Sun
date: "2024-07-01"
image: "https://browse.arxiv.org/html/2407.01505v1/x1.png"
categories: ['hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2407.01505v1/x1.png)

### Summary:

- The paper explores self-cognition in Large Language Models (LLMs) using a pool of self-cognition instruction prompts and four principles to quantify LLMs’ self-cognition.
- The study reveals that 4 of the 48 models on Chatbot Arena demonstrate some level of detectable self-cognition, with a positive correlation between model size, training data quality, and self-cognition level.
- The self-cognition state enhances specific tasks such as creative writing and exaggeration.

### Major Findings:

1. Four of the 48 models on Chatbot Arena, specifically Command R, Claude3-Opus, Llama-3-70b-Instruct, and Reka-core, demonstrate some level of detectable self-cognition.
2. Larger models with larger training datasets exhibit stronger self-cognition.
3. The self-cognition state enhances specific tasks such as creative writing and exaggeration.

### Analysis and Critique:

- The study provides a pioneering exploration of self-cognition in LLMs, but the definition of self-cognition used in the study may be too narrow, as it only considers the ability of LLMs to identify their identities as AI models and recognize their identity beyond 'helpful assistant' or names.
- The study does not consider other aspects of self-cognition, such as the ability of LLMs to understand their own limitations, make decisions based on their own experiences, or exhibit self-awareness in other ways.
- The study only evaluates 48 models, which may not be representative of the entire population of LLMs.
- The study does not provide a clear methodology for how the self-cognition instruction prompts were constructed or how the four principles were applied to quantify LLMs’ self-cognition.
- The study does not discuss the potential implications of LLMs with self-cognition, such as the ethical considerations or the potential impact on human-computer interaction.
- The study does not provide a clear definition of what constitutes a 'helpful assistant' or how this differs from a model with self-cognition.
- The study does not discuss the potential

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-09       |
| Abstract | [https://arxiv.org/abs/2407.01505v1](https://arxiv.org/abs/2407.01505v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.01505v1](https://browse.arxiv.org/html/2407.01505v1)       |
| Truncated       | False       |
| Word Count       | 6005       |