
---
title: "Logic-Scaffolding: Personalized Aspect-Instructed Recommendation Explanation Generation using LLMs"
description: "Large Language Models show potential for recommendation explanations, but current models struggle. A proposed Logic-Scaffolding framework aims to improve explanation generation."
author: Behnam Rahdari, Hao Ding, Ziwei Fan, Yifei Ma, Zhuotong Chen, Anoop Deoras, Branislav Kveton
date: "2023-12-22"
image: "https://browse.arxiv.org/html/2312.14345v1/x1.png"
categories: ['hci', 'prompt engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2312.14345v1/x1.png)

### Major Takeaways
1. **Logic-Scaffolding** is a framework proposed to address the challenge of generating reliable zero-shot explanations for recommendations using Large Language Models (LLMs).
2. The framework combines **aspect-based explanation** and **chain-of-thought prompting** to generate explanations through intermediate reasoning steps, aiming to enhance personalization, factuality, robustness, human readability, and proper utterance in the generated explanations.
3. An interactive demonstration is presented to showcase the improved quality of explanations generated by the Logic-Scaffolding framework.

### Characteristics of a Good Explanation
- **Personalization**: Enhances user understanding and satisfaction.
- **Factuality**: Establishes credibility and ensures accurate and reliable information.
- **Robustness**: Ensures consistent and relevant explanations across diverse domains.
- **Human readability**: Essential for informed decision-making and aligning with human cognition.
- **Proper utterance**: Focuses on delivering clear, concise, and unbiased explanations.

### Aspect-Instructed Recommendation Evidence Generation
- **Relevant Item Selection**: Involves selecting influential items related to the recommended item from the userâ€™s history.
- **Aspect Extraction**: Utilizes few-shot learning technique to extract essential aspects associated with each item.
- **Chain-of-Thought Reasoning**: Guides the explanation generation process through intermediate reasoning steps.

### Demonstration of Results
- **Generating the Explanation**: Data from the "MovieLens 1M" dataset is used to generate and compare explanations with both the Logic-Scaffolding framework and a zero-shot model.
- **Human Evaluation**: A between-subjects study reveals that explanations generated by the Logic-Scaffolding framework consistently received higher ratings in terms of relevance, human-readability, factuality, and proper utterance compared to the zero-shot approach.

### Critique
The paper provides a comprehensive framework and demonstrates its efficacy through an interactive demonstration and human evaluation. However, it would be beneficial to include a more extensive comparison with existing explanation generation techniques and address potential limitations or challenges in implementing the Logic-Scaffolding framework in different recommendation systems. Additionally, the generalizability of the framework across various domains and datasets could be further explored to ascertain its scalability and robustness.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-02       |
| Abstract | [http://arxiv.org/abs/2312.14345v1](http://arxiv.org/abs/2312.14345v1)        |
| HTML     | [https://browse.arxiv.org/html/2312.14345v1](https://browse.arxiv.org/html/2312.14345v1)       |
| Truncated       | False       |
| Word Count       | 3123       |