
---
title: "Assessing the Effectiveness of LLMs in Android Application Vulnerability Analysis"
id: "2406.18894v1"
description: "LLMs' strengths and weaknesses in detecting Android code vulnerabilities are analyzed, highlighting the potential of context augmentation with RAG for secure app development."
author: Vasileios Kouliaridis, Georgios Karopoulos, Georgios Kambourakis
date: "2024-06-27"
image: "../../../bayesian-beagle.png"
categories: ['security', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### Summary:

The study compares the ability of nine state-of-the-art large language models (LLMs) to detect Android code vulnerabilities listed in the OWASP Mobile Top 10. The models were evaluated against an open dataset of over 100 vulnerable code samples, including obfuscated ones. The analysis reveals the strengths and weaknesses of each LLM and provides insights into context augmentation with retrieval-augmented generation (RAG) for detecting Android code vulnerabilities. The reported findings show promise but also reveal significant discrepancies among the different LLMs.

### Major Findings:

1. GPT-4 and Code Llama emerged as the top performers among the nine LLMs tested, with GPT-4 showing promising results in both detection and code improvement, while Code Llama excelled in detection but failed to provide sufficient code improvements.
2. Specific LLMs performed exceptionally well for particular types of vulnerabilities, such as MistralOrca and Zephyr Beta for M9, and Zephyr Alpha for M10.
3. Open LLM models were the best performers in seven out of ten categories of vulnerabilities, i.e., M3, M4, M5, M7, M8, M9, M10.
4. The use of RAG in fine-tuning LLMs for vulnerability analysis significantly reinforced detection performance.
5. The detection of privacy-invasive actions varied among the LLMs, with Zephyr Alpha being the top performer, but MistralOrca's inability to identify any potential privacy-invasive actions underscores the need for increased model robustness in privacy analysis concerning mobile platforms.
6. LLMs seem more adept at identifying code vulnerabilities compared to well-respected static application security testing (SAST) tools.

### Analysis and Critique:

The study provides valuable insights into the current state of LLMs in Android vulnerability detection. However, there is ample room for improvement and targeted optimizations, particularly in addressing complex and subtle vulnerabilities. The variability in performance among the LLMs highlights the need for increased model robustness and sensitivity in privacy analysis concerning mobile platforms. More experiments with larger datasets are needed to obtain a more complete view of the capabilities of

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-07       |
| Abstract | [https://arxiv.org/abs/2406.18894v1](https://arxiv.org/abs/2406.18894v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.18894v1](https://browse.arxiv.org/html/2406.18894v1)       |
| Truncated       | False       |
| Word Count       | 7395       |