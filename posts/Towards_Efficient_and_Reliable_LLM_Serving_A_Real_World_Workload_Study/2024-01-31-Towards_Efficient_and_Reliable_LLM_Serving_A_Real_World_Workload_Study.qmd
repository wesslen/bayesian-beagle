
---
title: "Towards Efficient and Reliable LLM Serving: A Real-World Workload Study"
id: "2401.17644v1"
description: "TL;DR: Industry faces challenges with high costs and reliability of large language models, new dataset and benchmark suite developed."
author: Yuxin Wang, Yuhan Chen, Zeyu Li, Zhenheng Tang, Rui Guo, Xin Wang, Qiang Wang, Amelie Chi Zhou, Xiaowen Chu
date: "2024-01-31"
image: "../../../bayesian-beagle.png"
categories: ['architectures']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### **Summary:**
The article introduces BurstGPT, a real-world trace dataset of large language model (LLM) serving workloads, and analyzes the characteristics of these workloads. The study focuses on the impact of burstiness on LLM serving systems and aims to improve the reliability and performance of these systems. The authors also develop a benchmark suite based on BurstGPT to evaluate LLM serving systems.

### Major Findings:
1. The absence of reliable workload data for evaluating LLM serving systems impacts the quality of service (QoS) and reliability in industrial deployments.
2. BurstGPT provides insights into the characteristics of LLM serving workloads, including burstiness, request and response distributions, and the reliability of GPT services.
3. The evaluation uncovers a previously unrecognized vulnerability of LLM serving systems to short-term burstiness, particularly in common workload scenarios.

### Analysis and Critique:
The article provides a comprehensive analysis of real-world LLM serving workloads and introduces a benchmark suite based on BurstGPT to evaluate LLM serving systems. The study highlights the impact of burstiness on the reliability and performance of LLM serving systems, emphasizing the need for real-world workload data in optimizing and evaluating these systems. However, the article could benefit from a more detailed discussion of potential solutions or strategies to address the challenges identified in the study. Additionally, further research is needed to explore the practical implications of the findings and to develop effective strategies for optimizing LLM serving systems based on BurstGPT data.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2401.17644v1](https://arxiv.org/abs/2401.17644v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.17644v1](https://browse.arxiv.org/html/2401.17644v1)       |
| Truncated       | False       |
| Word Count       | 14587       |