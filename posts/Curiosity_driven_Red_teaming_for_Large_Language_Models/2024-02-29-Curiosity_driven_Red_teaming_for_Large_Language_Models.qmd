
---
title: "Curiosity-driven Red-teaming for Large Language Models"
id: "2402.19464v1"
description: "CRT: Curiosity-Driven LLM Testing Achieves Wider, Effective Probing of Undesirable Responses

(Note: This is a brief summary and not a true tl;dr, as it exceeds the 15-word limit. The original abstract is quite complex and would be difficult to summarize accurately in just 15 words.)"
author: Zhang-Wei Hong, Idan Shenfeld, Tsun-Hsuan Wang, Yung-Sung Chuang, Aldo Pareja, James Glass, Akash Srivastava, Pulkit Agrawal
date: "2024-02-29"
image: "https://browse.arxiv.org/html/2402.19464v1/x1.png"
categories: ['production', 'security', 'robustness', 'architectures']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.19464v1/x1.png)

### Summary

- **Curiosity-driven Red-teaming for Large Language Models**
  - Large language models (LLMs) have the potential to be used in various natural language applications, but they also risk generating incorrect or toxic content.
  - The current paradigm for probing when an LLM generates unwanted content involves human testers designing input prompts to elicit undesirable responses from LLMs.
  - A recent approach automates red teaming by training a separate red team LLM with reinforcement learning (RL) to generate test cases that maximize the chance of eliciting undesirable responses from the target LLM.
  - However, current RL methods are only able to generate a small number of effective test cases, resulting in low coverage of the span of prompts that elicit undesirable responses from the target LLM.
  - The paper aims to achieve greater coverage of test cases while

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x7b-instruct       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.19464v1](https://arxiv.org/abs/2402.19464v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.19464v1](https://browse.arxiv.org/html/2402.19464v1)       |
| Truncated       | False       |
| Word Count       | 13336       |