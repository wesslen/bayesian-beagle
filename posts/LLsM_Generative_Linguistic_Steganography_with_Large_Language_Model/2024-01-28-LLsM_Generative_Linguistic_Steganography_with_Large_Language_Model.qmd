
---
title: "LLsM: Generative Linguistic Steganography with Large Language Model"
id: "2401.15656v1"
description: "TL;DR: LLsM scheme uses Large Language Model for better steganographic text quality and anti-steganalysis."
author: Yihao Wang, Ruiqi Song, Ru Zhang, Jianyi Liu, Lingxiao Li
date: "2024-01-28"
image: "https://browse.arxiv.org/html/2401.15656v1/x1.png"
categories: ['prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.15656v1/x1.png)

### Summary:
The article introduces a novel scheme named LLsM, a generative Linguistic Steganography (LS) based on a Large Language Model (LLM). The scheme aims to generate steganographic texts with specific discourse characteristics in a controllable manner. The proposed LLsM utilizes fine-tuned LLM to generate texts with specific discourse and employs range encoding to ensure the stego imitates natural text distribution. Experiments demonstrate that LLsM outperforms prevalent baselines regarding text quality, statistical analysis, discourse matching, and anti-steganalysis.

### Major Findings:
1. LLsM performs superior to prevalent baselines regarding text quality, statistical analysis, discourse matching, and anti-steganalysis.
2. The proposed LLsM is the first effort on LS tasks with a larger-scale language model, fine-tuning the LLM with a large-scale constructed dataset encompassing rich discourse characteristics.
3. LLsM utilizes range coding for encoding the candidate pool, ensuring the stego imitates natural text distribution and exhibits specific discourse characteristics.

### Analysis and Critique:
The article presents a novel and promising approach to address the challenges of linguistic steganography. However, it is essential to consider potential limitations and unanswered questions. The article does not explicitly discuss the potential ethical implications of using linguistic steganography for covert communication. Additionally, the generalizability of the proposed LLsM scheme to different languages and text genres is not thoroughly explored. Further research is needed to validate the effectiveness of LLsM across diverse linguistic contexts and to address potential ethical concerns related to covert communication.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2401.15656v1](https://arxiv.org/abs/2401.15656v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.15656v1](https://browse.arxiv.org/html/2401.15656v1)       |
| Truncated       | False       |
| Word Count       | 4564       |