
---
title: "Large Language Model Distilling Medication Recommendation Model"
id: "2402.02803v1"
description: "LEADER: Transforming Medication Recommendations using LLMs, despite high computational costs, now efficient on MIMIC-III & IV datasets."
author: Qidong Liu, Xian Wu, Xiangyu Zhao, Yuanshao Zhu, Zijian Zhang, Feng Tian, Yefeng Zheng
date: "2024-02-05"
image: "../../img/2402.02803v1/image_1.png"
categories: ['prompt-engineering', 'recommender', 'social-sciences']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.02803v1/image_1.png)

### **Summary:**

- The article introduces LargE languAge moDel distilling mEdication Recommendation (LEADER), a novel approach that utilizes Large Language Models (LLMs) for medication recommendation in intelligent healthcare systems.
- LEADER enhances the semantic understanding capabilities of existing models by adapting LLMs with a new output layer and a refined tuning loss function.
- A feature-level knowledge distillation technique is developed to transfer the LLM's proficiency to a more compact model, improving efficiency.

### Major Findings:

1. LEADER leverages the powerful semantic comprehension and input-agnostic characteristics of LLMs to suggest medications effectively.
2. The authors address the out-of-corpus issue specific to drugs by adapting LLMs with a novel output layer and a refined tuning loss function.
3. The proposed feature-level knowledge distillation technique efficiently transfers the LLM's capabilities to a more compact model, ensuring effectiveness and efficiency.

### Analysis and Critique:

- The article could benefit from a more thorough discussion on the limitations of the approach, such as potential biases in the LLMs' understanding of medical data and the challenges of maintaining up-to-date medical knowledge within the models.
- The authors might also consider addressing the generalizability of their approach to various medical domains and languages, as LLMs may perform differently across different contexts.
- Further exploration of the ethical implications of using LLMs in healthcare, particularly regarding patient privacy and data security, would strengthen the article.
- The authors could provide more information on the evaluation metrics used to assess the performance of their model, ensuring transparency and reproducibility.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x7b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.02803v1](https://arxiv.org/abs/2402.02803v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.02803v1](https://browse.arxiv.org/html/2402.02803v1)       |
| Truncated       | False       |
| Word Count       | 16933       |