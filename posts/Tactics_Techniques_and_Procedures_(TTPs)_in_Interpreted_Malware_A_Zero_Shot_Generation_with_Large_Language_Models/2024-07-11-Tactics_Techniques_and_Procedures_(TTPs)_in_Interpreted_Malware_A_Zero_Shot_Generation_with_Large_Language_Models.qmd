
---
title: "Tactics, Techniques, and Procedures (TTPs) in Interpreted Malware: A Zero-Shot Generation with Large Language Models"
id: "2407.08532v1"
description: "GenTTP: AI-Powered Tool Extracts Tactics of Interpreted OSS Malware with High Accuracy."
author: Ying Zhang, Xiaoyan Zhou, Hui Wen, Wenjia Niu, Jiqiang Liu, Haining Wang, Qiang Li
date: "2024-07-11"
image: "https://browse.arxiv.org/html/2407.08532v1/x1.png"
categories: ['security', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2407.08532v1/x1.png)

### Summary:

The paper introduces Tactics, Techniques, and Procedures (TTPs) to characterize the various phases of an attack lifecycle in interpreted malware analysis. The authors propose GenTTP, a zero-shot approach to extracting a TTP of an interpreted malware package using large language models (LLMs). The input is a malicious package, and the output is a deceptive tactic and an execution tactic of attack vectors. The effectiveness of GenTTP is validated using two datasets: one with ground truth labels and a large dataset in the wild. Experimental results show that GenTTP can generate TTPs with high accuracy and efficiency. The authors also build an LLM-based Chatbot from 3,700+ PyPI malware's TTPs and conduct a quantitative analysis of malware's TTPs at a large scale. The main findings include: (1) many OSS malicious packages share a relatively stable TTP, (2) a TTP reflects characteristics of a malware-based attack, and (3) an attacker’s intent behind the malware is linked to a TTP.

### Major Findings:

1. Many OSS malicious packages share a relatively stable TTP, even with the increasing emergence of malware and attack campaigns.
2. A TTP reflects characteristics of a malware-based attack.
3. An attacker’s intent behind the malware is linked to a TTP.

### Analysis and Critique:

The paper presents an innovative approach to analyzing interpreted malware using TTPs and LLMs. The proposed GenTTP method effectively extracts TTPs from malware packages with high accuracy and efficiency. The use of LLMs in this context is a novel application and demonstrates the potential of these models in security research.

However, there are some limitations to the study. The reliance on LLMs as a black box may raise concerns about the unbiasedness and stability of the analysis results. Additionally, the study focuses on PyPI malware packages, and the approach may not be directly applicable to other ecosystems. The authors acknowledge this limitation and plan to extend their work to more ecosystems in the future.

Another potential issue is the lack of similarity in interpreted malware, which

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-16       |
| Abstract | [https://arxiv.org/abs/2407.08532v1](https://arxiv.org/abs/2407.08532v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.08532v1](https://browse.arxiv.org/html/2407.08532v1)       |
| Truncated       | False       |
| Word Count       | 14754       |