
---
title: "Towards a Personal Health Large Language Model"
id: "2406.06474v1"
description: "PH-LLM, a fine-tuned Gemini model, excels in personal health insights, outperforming experts in fitness and nearing their level in sleep, while accurately predicting sleep quality."
author: Justin Cosentino, Anastasiya Belyaeva, Xin Liu, Nicholas A. Furlotte, Zhun Yang, Chace Lee, Erik Schenck, Yojan Patel, Jian Cui, Logan Douglas Schneider, Robby Bryant, Ryan G. Gomes, Allen Jiang, Roy Lee, Yun Liu, Javier Perez, Jameson K. Rogers, Cathy Speed, Shyam Tailor, Megan Walker, Jeffrey Yu, Tim Althoff, Conor Heneghan, John Hernandez, Mark Malhotra, Leor Stern, Yossi Matias, Greg S. Corrado, Shwetak Patel, Shravya Shetty, Jiening Zhan, Shruthi Prabhakara, Daniel McDuff, Cory Y. McLean
date: "2024-06-10"
image: "https://browse.arxiv.org/html/2406.06474v1/x1.png"
categories: ['education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.06474v1/x1.png)

**Summary:**

The paper introduces Personal Health Large Language Model (PH-LLM), a version of Gemini fine-tuned for personal health and wellness. PH-LLM is evaluated on three aspects of personal health: generating personalized insights and recommendations for user goals in the domains of sleep and fitness, assessing levels of expert domain knowledge, and predicting patient-reported outcomes in sleep quality from detailed sensor information. The model is benchmarked against expert human responses and evaluated through comprehensive human and automatic evaluation of domain-specific rubrics. The results show that both Gemini Ultra 1.0 and PH-LLM are not statistically different from expert performance in fitness, while experts remain superior for sleep. However, fine-tuning PH-LLM provided significant improvements in using relevant domain knowledge and personalizing information for sleep insights. PH-LLM achieved 79% on sleep (N=629 questions) and 88% on fitness (N=99 questions) in multiple choice question examinations, both of which exceed average scores from a sample of human experts. The model also demonstrated the ability to predict self-reported assessments of sleep quality by training it to predict self-reported sleep disruption and sleep impairment outcomes from textual and multimodal encoding representations of wearable sensor data.

**Major Findings:**

1. PH-LLM, a fine-tuned version of Gemini, is capable of generating personalized insights and recommendations for user goals in the domains of sleep and fitness, assessing levels of expert domain knowledge, and predicting patient-reported outcomes in sleep quality from detailed sensor information.
2. Both Gemini Ultra 1.0 and PH-LLM are not statistically different from expert performance in fitness, while experts remain superior for sleep. However, fine-tuning PH-LLM provided significant improvements in using relevant domain knowledge and personalizing information for sleep insights.
3. PH-LLM achieved 79% on sleep (N=629 questions) and 88% on fitness (N=99 questions) in multiple choice question examinations, both of which exceed average scores from a sample of human experts.
4. PH-LLM demonstrated the ability to predict self-reported assessments of sleep quality by training it to predict self-report

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-23       |
| Abstract | [https://arxiv.org/abs/2406.06474v1](https://arxiv.org/abs/2406.06474v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.06474v1](https://browse.arxiv.org/html/2406.06474v1)       |
| Truncated       | False       |
| Word Count       | 17580       |