
---
title: "Whose LLM is it Anyway? Linguistic Comparison and LLM Attribution for GPT-3.5, GPT-4 and Bard"
id: "2402.14533v1"
description: "LLMs exhibit distinctive linguistic styles, enabling accurate classification with 88% accuracy."
author: Ariel Rosenfeld, Teddy Lazebnik
date: "2024-02-22"
image: "https://browse.arxiv.org/html/2402.14533v1/x1.png"
categories: ['hci', 'social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.14533v1/x1.png)

### Summary:
- The article compares the linguistic styles of three popular Large Language Models (LLMs): GPT-3.5, GPT-4, and Bard, to determine if they exhibit distinctive linguistic styles similar to human authors.
- The study analyzes vocabulary, Part-Of-Speech (POS) distribution, dependency distribution, and sentiment of texts generated by the LLMs and attributes a given text to its LLM origin with 88% accuracy using a simple off-the-shelf classification model.
- The results reveal significant linguistic variations among the LLMs, indicating that they are linguistically different and can be effectively distinguished based on their linguistic markers.

### Major Findings:
1. Linguistic Variations: The study finds significant linguistic variations among the LLMs, particularly in terms of vocabulary, POS, and dependencies.
2. LLM Attribution: The linguistic markers of the LLMs enable accurate attribution of a given text to its LLM origin with 88% accuracy using a simple classification model.
3. Theoretical and Practical Implications: The results affirm the potential of LLMs to reproduce the diversity inherent in human language expression, with implications for model comparison, evaluation, and LLM detection.

### Analysis and Critique:
- Limitations: The analysis focuses on a limited cohort of datasets, and the study only examines the English language, limiting the generalizability of the findings.
- Contextual Considerations: The study focuses on the zero-shot case, where the LLMs do not have any context, and future research should consider different datasets and contexts to provide a wider perspective.
- Potential Bias: The study does not address potential biases in the datasets used for analysis, which could impact the generalizability of the findings to real-world applications.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.14533v1](https://arxiv.org/abs/2402.14533v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.14533v1](https://browse.arxiv.org/html/2402.14533v1)       |
| Truncated       | False       |
| Word Count       | 4348       |