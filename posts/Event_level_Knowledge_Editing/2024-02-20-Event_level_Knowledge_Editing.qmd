
---
title: "Event-level Knowledge Editing"
id: "2402.13093v1"
description: "Knowledge editing updates large language models with new events for efficiency and completeness. ELKEN benchmark challenges existing methods."
author: Hao Peng, Xiaozhi Wang, Chunyang Li, Kaisheng Zeng, Jiangshan Duo, Yixin Cao, Lei Hou, Juanzi Li
date: "2024-02-20"
image: "https://browse.arxiv.org/html/2402.13093v1/x1.png"
categories: ['architectures', 'production']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.13093v1/x1.png)

### Summary:
The article introduces the concept of event-level knowledge editing, which aims to update large language models (LLMs) with new knowledge that emerges from real-world events. The authors propose a new task setting, event-level knowledge editing, and construct a high-quality benchmark called ELKEN to evaluate the performance of various knowledge editing methods and LLMs. The article systematically evaluates the performance of different methods and models on ELKEN and finds that existing methods struggle to address the challenges posed by event-level knowledge editing.

### Major Findings:
1. **Efficiency**: Event-level editing leads to updates in multiple entailed knowledge triplets, making it more efficient than conventional triplet-level editing.
2. **Completeness**: Event-level editing requires considering the event influences and updating LLMsâ€™ knowledge about future trends, addressing the limitations of triplet-level editing.
3. **Challenges to Existing Methods**: ELKEN poses significant challenges to existing knowledge editing approaches, highlighting the importance of future research.

### Analysis and Critique:
- **Limitations**: The article acknowledges that ELKEN only contains data in English and does not support other languages, which may limit its potential applications. Additionally, the evaluation only includes open-source LLMs with about 6 or 175 billion parameters, without assessing larger models such as TULU 2 with 70 billion parameters.
- **Ethical Considerations**: The authors discuss the intellectual property, data annotation, intended use, potential risk control, and AI assistance related to the work, ensuring ethical considerations are addressed.

The article provides a comprehensive overview of event-level knowledge editing, introduces a new benchmark, and evaluates the performance of various methods and models. However, it also highlights potential limitations and ethical considerations that need to be addressed in future research.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.13093v1](https://arxiv.org/abs/2402.13093v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.13093v1](https://browse.arxiv.org/html/2402.13093v1)       |
| Truncated       | False       |
| Word Count       | 8687       |