
---
title: "How Good (Or Bad) Are LLMs at Detecting Misleading Visualizations?"
id: "2407.17291v1"
description: "LLMs can detect misleading charts, aiding in data interpretation and combating misinformation."
author: Leo Yu-Ho Lo, Huamin Qu
date: "2024-07-24"
image: "https://browse.arxiv.org/html/2407.17291v1/x1.png"
categories: ['prompt-engineering', 'education', 'robustness', 'hci', 'social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2407.17291v1/x1.png)

### Summary:

This study explores the capabilities of multimodal Large Language Models (LLMs) in analyzing complex charts and assessing the impact of different prompting strategies on their analyses. The authors utilized a dataset of misleading charts collected from the internet and crafted nine distinct prompts, ranging from simple to complex, to test the ability of four different multimodal LLMs in detecting over 21 different chart issues. Through three experiments, the authors gained insights into how to effectively prompt LLMs to identify misleading charts and developed strategies to address scalability challenges. The findings reveal that multimodal LLMs possess a strong capability for chart comprehension and critical thinking in data interpretation, with significant potential in employing multimodal LLMs to counter misleading information by supporting critical thinking and enhancing visualization literacy.

### Major Findings:

1. Multimodal LLMs demonstrate exceptional ability in interpreting charts presented as bitmap images, recognizing different chart elements, exercising critical thinking in data interpretation, and detecting a wide range of issues in misleading charts.
2. LLMs consistently sought additional context for the charts, showcasing an innate caution that proved instrumental in uncovering issues like dubious data sources and concealed information.
3. LLMs proficiently detected charts with fabricated data, a challenge that goes beyond structural analysis to require a critical evaluation of the charts' textual content.

### Analysis and Critique:

1. The study's reliance on a limited dataset of misleading charts collected from the internet may not fully represent the diversity and complexity of misleading visualizations encountered in real-world scenarios.
2. The scalability challenges encountered as the number of issues for detection by LLMs increased may limit the practical application of these models in real-world settings.
3. The study does not address the potential biases or limitations of the LLMs themselves, which could impact their ability to accurately detect misleading visualizations.
4. The authors do not discuss the potential ethical implications of using LLMs to detect misleading visualizations, such as the risk of false positives or negatives and the potential for misuse.
5. The study does not provide a comprehensive comparison of the performance of the four different multimodal LLMs tested, making it difficult to determine which model is most

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-30       |
| Abstract | [https://arxiv.org/abs/2407.17291v1](https://arxiv.org/abs/2407.17291v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.17291v1](https://browse.arxiv.org/html/2407.17291v1)       |
| Truncated       | False       |
| Word Count       | 10270       |