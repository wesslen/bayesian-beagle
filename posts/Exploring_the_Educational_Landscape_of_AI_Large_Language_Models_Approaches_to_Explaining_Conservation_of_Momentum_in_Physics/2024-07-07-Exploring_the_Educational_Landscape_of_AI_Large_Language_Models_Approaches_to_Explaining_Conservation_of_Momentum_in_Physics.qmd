
---
title: "Exploring the Educational Landscape of AI: Large Language Models' Approaches to Explaining Conservation of Momentum in Physics"
id: "2407.05308v1"
description: "LLMs vary in explaining physics concepts; educator guidance crucial for effective use in teaching."
author: Keisuke Sato
date: "2024-07-07"
image: "../../../bayesian-beagle.png"
categories: ['education', 'prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### Summary:

This study explores the capabilities of six state-of-the-art Large Language Models (LLMs) in explaining the law of conservation of momentum, a fundamental principle in physics. The models evaluated include ChatGPT (versions 3.5 and 4.0), Cohere’s Command R+, and Google’s Gemini (versions 1.0 Pro, 1.5 Flash, and 1.5 Pro). The analysis, conducted in Japanese, focuses on text characteristics, response similarity, and keyword usage to assess the models’ explanatory approaches, depth of understanding, and adaptability to different educational levels.

The results reveal significant diversity in explanatory styles across models. ChatGPT4.0 and Coral provided more comprehensive and technically detailed explanations, while Gemini models tended toward more intuitive approaches. Key findings include variations in the treatment of critical concepts such as net force and differing emphases on mathematical rigor and real-world applications.

The study suggests that different AI models may be more suitable for various educational contexts, ranging from introductory to advanced levels. ChatGPT4.0 and Coral demonstrated potential for advanced discussions, while Gemini models appeared more appropriate for introductory explanations. Importantly, the study underscores the necessity of educator guidance in effectively leveraging these AI tools, as models varied in their ability to convey nuanced aspects of physical principles.

### Major Findings:

1. ChatGPT4.0 and Coral provided more comprehensive and technically detailed explanations, while Gemini models tended toward more intuitive approaches.
2. Key findings include variations in the treatment of critical concepts such as net force and differing emphases on mathematical rigor and real-world applications.
3. Different AI models may be more suitable for various educational contexts, ranging from introductory to advanced levels. ChatGPT4.0 and Coral demonstrated potential for advanced discussions, while Gemini models appeared more appropriate for introductory explanations.

### Analysis and Critique:

This research establishes a foundation for understanding the educational potential of LLMs in physics, providing insights for educators on integrating these tools into their teaching practices. However, the study has some limitations. It focuses on a single physics concept and does not test the models in real

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-09       |
| Abstract | [https://arxiv.org/abs/2407.05308v1](https://arxiv.org/abs/2407.05308v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.05308v1](https://browse.arxiv.org/html/2407.05308v1)       |
| Truncated       | False       |
| Word Count       | 4973       |