
---
title: "Context-aware Decoding Reduces Hallucination in Query-focused Summarization"
id: "2312.14335v1"
description: "Query-focused summarization (QFS) uses Context-aware Decoding (CAD) to improve generation quality for QFS tasks."
author: ['Zhichao Xu']
date: "2023-12-21"
image: "../../../bayesian-beagle.png"
categories: ['robustness']
format:
  html:
    code-overflow: wrap
---

![](None)

### Major Takeaways

- Query-focused summarization (QFS) has significant real-world applications such as abstractive snippet generation and retrieval augmented generation.
- Large language models (LLMs) used in QFS may suffer from hallucination, generating information that contradicts the source documents.
- Context-aware Decoding (CAD) has been proposed as a decoding method to reduce hallucination and improve generation quality in QFS.

### Introduction
- QFS aims to provide a summary of a single/multiple documents satisfying a given query, relevant for real-world applications.
- Large language models (LLMs) used in QFS may lead to hallucinations, contradicting the source documents.
- Different decoding methods have been explored to improve generation quality and reduce hallucination, with growing interest in CAD.

### Background
- Context-aware Decoding (CAD) leverages pointwise mutual information and introduces a product-of-experts enhancement to condition generation on input evidence.
- The use of PMI in CAD aims to measure the association of predicting specific tokens and the presence of input context.
- The computational cost in CAD is analyzed, and the additional complexity in terms of FLOPs is discussed.

### Experiments
- Experiments are conducted on QFS datasets and news summarization datasets using different language models, including pre-trained and instruction finetuned models.
- Prompting templates and experiment setup, including datasets, language models, evaluation metrics, and hyperparameters, are detailed.

### Results and Analysis
- CAD improves news summarization performance and reduces factuality errors, as evidenced by improved ROUGE scores and FactKB scores on multiple language models.
- Trade-offs between FactKB and ROUGE scores are observed with varying hyperparameter α, with optimal performance at α=0.3.
- CAD introduces additional inference-time FLOPs and reduces decoding speed, impacting performance on real-world datasets.

### Related Work
- Other works have focused on addressing hallucination in natural language generation and developing decoding methods to improve generation quality.

### Conclusion and Limitations
- The study provides insights into the effectiveness of CAD in QFS and news summarization, but is limited to language models no larger than 11B.

### Critique
- This paper provides a comprehensive study on the effectiveness of CAD in reducing hallucination and improving generation quality in QFS. However, the paper could benefit from a more in-depth analysis of trade-offs between different decoding methods and a thorough investigation of the impact of CAD on different types of documents beyond news and QFS datasets. More discussions on potential limitations and challenges in the deployment of CAD in real-world applications would also enhance the paper's practical implications.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-02       |
| Abstract | [http://arxiv.org/abs/2312.14335v1](http://arxiv.org/abs/2312.14335v1)        |
| HTML     | [https://browse.arxiv.org/html/2312.14335v1](https://browse.arxiv.org/html/2312.14335v1)       |
| Truncated       | False       |
| Word Count       | 6395       |