
---
title: "Benchmarking LLMs for Translating Classical Chinese Poetry:Evaluating Adequacy, Fluency, and Elegance"
id: "2408.09945v1"
description: "LLMs struggle with translating classical poetry; RAT method and GPT-4 metric proposed for improvement."
author: Andong Chen, Lianzhang Lou, Kehai Chen, Xuefeng Bai, Yang Xiang, Muyun Yang, Tiejun Zhao, Min Zhang
date: "2024-08-19"
image: "https://browse.arxiv.org/html/2408.09945v1/x1.png"
categories: ['social-sciences', 'production', 'architectures']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.09945v1/x1.png)

# Summary:

The study introduces a benchmark for evaluating large language models (LLMs) in translating classical Chinese poetry into English. The task requires not only adequacy in translating culturally and historically significant content but also strict adherence to linguistic fluency and poetic elegance. The authors reveal that existing LLMs fall short of this task. To address these issues, they propose RAT, a Retrieval-Augmented machine Translation method that enhances the translation process by incorporating knowledge related to classical poetry. Additionally, they propose an automatic evaluation metric based on GPT-4, which better assesses translation quality in terms of adequacy, fluency, and elegance, overcoming the limitations of traditional metrics.

## Major Findings:

1. Existing LLMs fall short in translating classical Chinese poetry into English, which requires adequacy, fluency, and elegance.
2. The authors propose RAT, a Retrieval-Augmented machine Translation method, to enhance the translation process by incorporating knowledge related to classical poetry.
3. An automatic evaluation metric based on GPT-4 is proposed, which better assesses translation quality in terms of adequacy, fluency, and elegance.

## Analysis and Critique:

The study provides a valuable contribution to the field of machine translation by introducing a benchmark for evaluating LLMs in translating classical Chinese poetry. The proposed RAT method and the GPT-4-based evaluation metric are promising approaches to improve translation quality. However, the study does not provide a comprehensive evaluation of the proposed methods, and it is unclear how they compare to other existing methods. Additionally, the study does not discuss potential limitations or biases in the proposed methods. Further research is needed to evaluate the effectiveness and generalizability of the proposed methods.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-20       |
| Abstract | [https://arxiv.org/abs/2408.09945v1](https://arxiv.org/abs/2408.09945v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.09945v1](https://browse.arxiv.org/html/2408.09945v1)       |
| Truncated       | False       |
| Word Count       | 7016       |