[
  {
    "objectID": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#key-findings",
    "href": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#key-findings",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Key Findings",
    "text": "Key Findings\n\nInnovative Integration: The Viz system integrates Quantized Low-Rank Adapters (QLoRA) within a marketplace framework, revolutionizing the accessibility and efficiency of large language models (LLMs).\nAddressing Challenges: By reducing computational overhead, ensuring copyright compliance in training datasets, and creating a sustainable economic model, Viz offers a comprehensive solution to the complex challenges of AI landscape.\nLegal and Ethical Compliance: Viz contributes to the discussion on legal and ethical considerations in AI, particularly in copyright compliance and data privacy, providing a holistic and inventive approach to the existing obstacles in the artificial intelligence field."
  },
  {
    "objectID": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#introduction",
    "href": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#introduction",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Introduction",
    "text": "Introduction\n\nThe paper aims to introduce the Viz system, which addresses challenges of computational efficiency, legal compliance, and economic sustainability in the utilization and monetization of LLMs."
  },
  {
    "objectID": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#literature-review",
    "href": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#literature-review",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Literature Review",
    "text": "Literature Review\n\nThe review outlines the advancements in LLMs, copyright concerns in AI training, and the evolution of fine-tuning techniques, specifically LoRA and QLoRA."
  },
  {
    "objectID": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#viz-system-architecture",
    "href": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#viz-system-architecture",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Viz System Architecture",
    "text": "Viz System Architecture\n\nThe system integrates a marketplace for AI models fine-tuned through QLoRA, providing a legally compliant and economically viable avenue for content creators and users."
  },
  {
    "objectID": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#qlora-importance-in-viz",
    "href": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#qlora-importance-in-viz",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "QLoRA Importance in Viz",
    "text": "QLoRA Importance in Viz\n\nQLoRA’s core principles and adaptation within Viz significantly reduces computational overhead and enhances model performance."
  },
  {
    "objectID": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#marketplace-design-and-economics",
    "href": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#marketplace-design-and-economics",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Marketplace Design and Economics",
    "text": "Marketplace Design and Economics\n\nThe marketplace employs a dual monetization strategy and revenue sharing models, paralleling existing digital content platforms."
  },
  {
    "objectID": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#legal-and-ethical-considerations",
    "href": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#legal-and-ethical-considerations",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Legal and Ethical Considerations",
    "text": "Legal and Ethical Considerations\n\nViz ensures adherence to global copyright regulations, data privacy, ethical AI principles, and fair use."
  },
  {
    "objectID": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#discussion",
    "href": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#discussion",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Discussion",
    "text": "Discussion\n\nThe Viz system’s impact on the AI and content industry, and potential advancements such as decentralization are discussed."
  },
  {
    "objectID": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#conclusion",
    "href": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#conclusion",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Conclusion",
    "text": "Conclusion\n\nViz sets a precedent for future advancements in AI technology, combining technological innovation, economic insight, and legal caution."
  },
  {
    "objectID": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#critique",
    "href": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#critique",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Critique",
    "text": "Critique\n\nThe paper could benefit from a more in-depth analysis of potential limitations and challenges in the practical implementation of the Viz system.\nFurther exploration of the potential ethical implications and unintended consequences of widespread adoption of Viz would enhance the discussion."
  },
  {
    "objectID": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#appendix",
    "href": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#appendix",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n6840"
  },
  {
    "objectID": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#key-findings",
    "href": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#key-findings",
    "title": "Prompting LLMs with content plans to enhance the summarization of scientific articles",
    "section": "Key Findings",
    "text": "Key Findings\n\nThe study introduces novel prompting techniques to improve the performance of automatic summarization systems for scientific articles, demonstrating consistent performance improvements from prompting techniques on smaller models\nResults show that smaller models obtain ROUGE-1 score increases around 0.1-0.4 when summarizing sections aided by prompts, indicating the effectiveness of prompting to overcome the limitations of smaller, less capable summarization systems\nThe study suggests that rather than large models, lightweight models supplemented with prompts may be preferable in resource-constrained contexts like mobile devices."
  },
  {
    "objectID": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#abstract",
    "href": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#abstract",
    "title": "Prompting LLMs with content plans to enhance the summarization of scientific articles",
    "section": "Abstract",
    "text": "Abstract\nThe paper presents novel prompting techniques to enhance automatic summarization systems for scientific articles, addressing the challenges posed by the length and complexity of these documents. The study tests the techniques with various summarization models and input texts, showing consistent performance gains, especially for smaller models summarizing sections separately."
  },
  {
    "objectID": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#introduction",
    "href": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#introduction",
    "title": "Prompting LLMs with content plans to enhance the summarization of scientific articles",
    "section": "Introduction",
    "text": "Introduction\n\nAutomatic text summarization aims to produce shortened versions of documents while retaining relevant information, with current systems based on abstractive summarization models, such as transformer architectures.\nSummarizing scientific articles is particularly challenging due to their length, linguistic complexity, and irregular organizational structures.\nThe study introduces novel prompting techniques to provide key term context and enhance scientific literature summarizers, aiming to address the limitations of less powerful systems."
  },
  {
    "objectID": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#related-work",
    "href": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#related-work",
    "title": "Prompting LLMs with content plans to enhance the summarization of scientific articles",
    "section": "Related Work",
    "text": "Related Work\n\nConventional approaches to automatic summarization heavily relied on extractive methods but current dominant paradigm has shifted toward abstractive methods using neural network architectures.\nThe study contextualizes the work by summarizing prior studies and techniques in automatic text summarization, particularly focusing on prompting and section-level summarization."
  },
  {
    "objectID": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#methods",
    "href": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#methods",
    "title": "Prompting LLMs with content plans to enhance the summarization of scientific articles",
    "section": "Methods",
    "text": "Methods\n\nThe study details three key evaluation dimensions: prompting technique dimension, model dimension, and input text dimension.\nDifferent approaches for generating prompts are compared, various state-of-the-art transformer models are evaluated, and three main text input conditions are studied."
  },
  {
    "objectID": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#results",
    "href": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#results",
    "title": "Prompting LLMs with content plans to enhance the summarization of scientific articles",
    "section": "Results",
    "text": "Results\n\nExperiment results demonstrate consistent performance improvements from prompting techniques on smaller summarization models. The study also highlights the benefits of prompting based on the attention mechanism and the input text dimension."
  },
  {
    "objectID": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#discussion",
    "href": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#discussion",
    "title": "Prompting LLMs with content plans to enhance the summarization of scientific articles",
    "section": "Discussion",
    "text": "Discussion\n\nThe findings reveal that smaller models demonstrate significant performance improvements when subjected to prompting techniques, particularly for section-level summarization.\nThe study discusses the implications of the results, highlighting the potential of prompting as a technique for enhancing small neural network summarizers and its practical applications."
  },
  {
    "objectID": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#future-work",
    "href": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#future-work",
    "title": "Prompting LLMs with content plans to enhance the summarization of scientific articles",
    "section": "Future Work",
    "text": "Future Work\n\nThe study outlines future research opportunities, including exploring new prompting techniques, investigating automated prompt generation, and adapting attention mechanisms.\nHigh-level directions for future work are suggested based on the observations and implications of the study."
  },
  {
    "objectID": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#conclusion",
    "href": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#conclusion",
    "title": "Prompting LLMs with content plans to enhance the summarization of scientific articles",
    "section": "Conclusion",
    "text": "Conclusion\n\nThe paper introduces and evaluates prompting techniques as an effective approach to enhancing scientific summarization systems, particularly for smaller models and section-level summarization.\nThe study provides valuable insights into the potential of prompting and suggests promising opportunities for future research. It also acknowledges the support received for the work."
  },
  {
    "objectID": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#appendix",
    "href": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#appendix",
    "title": "Prompting LLMs with content plans to enhance the summarization of scientific articles",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n9136"
  },
  {
    "objectID": "posts/RAGTruth__A_Hallucination_Corpus_for_Developing_Trustworthy_Retrieval_Augmented_Language_Models/2023-12-31-RAGTruth__A_Hallucination_Corpus_for_Developing_Trustworthy_Retrieval_Augmented_Language_Models.html#appendix",
    "href": "posts/RAGTruth__A_Hallucination_Corpus_for_Developing_Trustworthy_Retrieval_Augmented_Language_Models/2023-12-31-RAGTruth__A_Hallucination_Corpus_for_Developing_Trustworthy_Retrieval_Augmented_Language_Models.html#appendix",
    "title": "RAGTruth: A Hallucination Corpus for Developing Trustworthy Retrieval-Augmented Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n6757"
  },
  {
    "objectID": "posts/Logic_Scaffolding__Personalized_Aspect_Instructed_Recommendation_Explanation_Generation_using_LLMs/2023-12-22-Logic_Scaffolding__Personalized_Aspect_Instructed_Recommendation_Explanation_Generation_using_LLMs.html#appendix",
    "href": "posts/Logic_Scaffolding__Personalized_Aspect_Instructed_Recommendation_Explanation_Generation_using_LLMs/2023-12-22-Logic_Scaffolding__Personalized_Aspect_Instructed_Recommendation_Explanation_Generation_using_LLMs.html#appendix",
    "title": "Logic-Scaffolding: Personalized Aspect-Instructed Recommendation Explanation Generation using LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n3123"
  },
  {
    "objectID": "posts/Unlocking_the_Potential_of_Large_Language_Models_for_Explainable_Recommendations/2023-12-25-Unlocking_the_Potential_of_Large_Language_Models_for_Explainable_Recommendations.html#appendix",
    "href": "posts/Unlocking_the_Potential_of_Large_Language_Models_for_Explainable_Recommendations/2023-12-25-Unlocking_the_Potential_of_Large_Language_Models_for_Explainable_Recommendations.html#appendix",
    "title": "Unlocking the Potential of Large Language Models for Explainable Recommendations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n9663"
  },
  {
    "objectID": "posts/A_Computational_Framework_for_Behavioral_Assessment_of_LLM_Therapists/2024-01-01-A_Computational_Framework_for_Behavioral_Assessment_of_LLM_Therapists.html#appendix",
    "href": "posts/A_Computational_Framework_for_Behavioral_Assessment_of_LLM_Therapists/2024-01-01-A_Computational_Framework_for_Behavioral_Assessment_of_LLM_Therapists.html#appendix",
    "title": "A Computational Framework for Behavioral Assessment of LLM Therapists",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nTrue\n\n\nWord Count\n19139"
  },
  {
    "objectID": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#appendix",
    "href": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#appendix",
    "title": "Alleviating Hallucinations of Large Language Models through Induced Hallucinations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n9227"
  },
  {
    "objectID": "posts/ChatEd__A_Chatbot_Leveraging_ChatGPT_for_an_Enhanced_Learning_Experience_in_Higher_Education/2023-12-29-ChatEd__A_Chatbot_Leveraging_ChatGPT_for_an_Enhanced_Learning_Experience_in_Higher_Education.html#appendix",
    "href": "posts/ChatEd__A_Chatbot_Leveraging_ChatGPT_for_an_Enhanced_Learning_Experience_in_Higher_Education/2023-12-29-ChatEd__A_Chatbot_Leveraging_ChatGPT_for_an_Enhanced_Learning_Experience_in_Higher_Education.html#appendix",
    "title": "ChatEd: A Chatbot Leveraging ChatGPT for an Enhanced Learning Experience in Higher Education",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n5566"
  },
  {
    "objectID": "posts/Principled_Instructions_Are_All_You_Need_for_Questioning_LLaMA_1_2__GPT_3.5_4/2023-12-26-Principled_Instructions_Are_All_You_Need_for_Questioning_LLaMA_1_2__GPT_3.5_4.html#appendix",
    "href": "posts/Principled_Instructions_Are_All_You_Need_for_Questioning_LLaMA_1_2__GPT_3.5_4/2023-12-26-Principled_Instructions_Are_All_You_Need_for_Questioning_LLaMA_1_2__GPT_3.5_4.html#appendix",
    "title": "Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n5205"
  },
  {
    "objectID": "posts/SecFormer__Towards_Fast_and_Accurate_Privacy_Preserving_Inference_for_Large_Language_Models/2024-01-01-SecFormer__Towards_Fast_and_Accurate_Privacy_Preserving_Inference_for_Large_Language_Models.html#appendix",
    "href": "posts/SecFormer__Towards_Fast_and_Accurate_Privacy_Preserving_Inference_for_Large_Language_Models/2024-01-01-SecFormer__Towards_Fast_and_Accurate_Privacy_Preserving_Inference_for_Large_Language_Models.html#appendix",
    "title": "SecFormer: Towards Fast and Accurate Privacy-Preserving Inference for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n10983"
  },
  {
    "objectID": "posts/Large_Language_Models_are_Not_Stable_Recommender_Systems/2023-12-25-Large_Language_Models_are_Not_Stable_Recommender_Systems.html#appendix",
    "href": "posts/Large_Language_Models_are_Not_Stable_Recommender_Systems/2023-12-25-Large_Language_Models_are_Not_Stable_Recommender_Systems.html#appendix",
    "title": "Large Language Models are Not Stable Recommender Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n8647"
  },
  {
    "objectID": "posts/LLM_Assist__Enhancing_Closed_Loop_Planning_with_Language_Based_Reasoning/2023-12-30-LLM_Assist__Enhancing_Closed_Loop_Planning_with_Language_Based_Reasoning.html#appendix",
    "href": "posts/LLM_Assist__Enhancing_Closed_Loop_Planning_with_Language_Based_Reasoning/2023-12-30-LLM_Assist__Enhancing_Closed_Loop_Planning_with_Language_Based_Reasoning.html#appendix",
    "title": "LLM-Assist: Enhancing Closed-Loop Planning with Language-Based Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n9991"
  },
  {
    "objectID": "posts/Large_Language_Models_are_Clinical_Reasoners__Reasoning_Aware_Diagnosis_Framework_with_Prompt_Generated_Rationales/2023-12-12-Large_Language_Models_are_Clinical_Reasoners__Reasoning_Aware_Diagnosis_Framework_with_Prompt_Generated_Rationales.html#appendix",
    "href": "posts/Large_Language_Models_are_Clinical_Reasoners__Reasoning_Aware_Diagnosis_Framework_with_Prompt_Generated_Rationales/2023-12-12-Large_Language_Models_are_Clinical_Reasoners__Reasoning_Aware_Diagnosis_Framework_with_Prompt_Generated_Rationales.html#appendix",
    "title": "Large Language Models are Clinical Reasoners: Reasoning-Aware Diagnosis Framework with Prompt-Generated Rationales",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n10273"
  },
  {
    "objectID": "posts/Action_Item_Driven_Summarization_of_Long_Meeting_Transcripts/2023-12-29-Action_Item_Driven_Summarization_of_Long_Meeting_Transcripts.html#appendix",
    "href": "posts/Action_Item_Driven_Summarization_of_Long_Meeting_Transcripts/2023-12-29-Action_Item_Driven_Summarization_of_Long_Meeting_Transcripts.html#appendix",
    "title": "Action-Item-Driven Summarization of Long Meeting Transcripts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n7904"
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#key-findings",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#key-findings",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Key Findings",
    "text": "Key Findings\n\nKnowledge Distillation (KD) effectively optimizes Large Language Models (LLMs) for use in educational technology, especially on low-processor devices, achieving upto 90% accuracy with much smaller model parameters (0.02M) and processing requirements, compared to the original LLMs.\nThe effectiveness of KD in enhancing the performance of a smaller student model compared to original neural network models, particularly in scenarios where the original model may not fully capture the underlying patterns in the data, is demonstrated across various datasets.\nWhile KD does not achieve the same level of accuracy as the teacher models, it greatly reduces the performance gap, demonstrating its efficiency in establishing compact student models and making it suitable for practical educational settings."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#introduction",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#introduction",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Introduction",
    "text": "Introduction\n\nAI has significant impact on classroom assessment practices and adaptive learning systems, particularly with the integration of Large Language Models (LLMs) into various domains, such as education.\nHowever, the considerable size and computational requirements of LLMs pose a challenge for deployment in resource-constrained educational environments, prompting exploration of methods like KD."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#background",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#background",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Background",
    "text": "Background\n\nThe use of LLMs in education, specifically for automatic scoring, has gained significant attention, and studies have shown promise in handling diverse types of educational assessments.\nChallenges in deploying LLMs in practical educational settings have led to various approaches, including knowledge distillation techniques, to address these limitations."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#methodology",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#methodology",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Methodology",
    "text": "Methodology\n\nThe proposed KD approach leverages knowledge from a large pre-trained teacher model to guide the training of a more compact student model, effectively transferring its predictive and generalization capabilities.\nThe KD methodology is applied and evaluated across diverse datasets of student-written responses, with results showcasing the efficacy in enhancing the performance of compact student models relative to original neural network models."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#experimental-setup",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#experimental-setup",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Experimental Setup",
    "text": "Experimental Setup\n\nDatasets of student-written responses to science and mathematical questions were used to evaluate the performance of student models trained using the KD approach, with results showing improved performance using KD, particularly on datasets where the original neural network models did not fully capture the underlying patterns in the data."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#discussion",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#discussion",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Discussion",
    "text": "Discussion\n\nThe discussed study provides valuable insights into the potential applications of KD in educational technology, particularly in automated grading systems and personalized learning experiences. However, it’s important to recognize the limitations and future directions for further research and development in this field."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#conclusion",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#conclusion",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Conclusion",
    "text": "Conclusion\n\nThe study effectively illustrates the potential and viability of KD in educational contexts, underscoring the need for ongoing research and innovation in AI for education."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#critique",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#critique",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Critique",
    "text": "Critique\nThe article does not delve into the technical details of the KD process, making it challenging for readers to understand the specific methodologies and challenges involved in the knowledge distillation approach. Additionally, the limitations of the study, such as the potential biases in the teacher model and the representativeness of data used, could be elaborated further to provide a more comprehensive understanding of the implications of the study’s findings."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#appendix",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#appendix",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n9762"
  },
  {
    "objectID": "posts/Task_Contamination__Language_Models_May_Not_Be_Few_Shot_Anymore/2023-12-26-Task_Contamination__Language_Models_May_Not_Be_Few_Shot_Anymore.html#appendix",
    "href": "posts/Task_Contamination__Language_Models_May_Not_Be_Few_Shot_Anymore/2023-12-26-Task_Contamination__Language_Models_May_Not_Be_Few_Shot_Anymore.html#appendix",
    "title": "Task Contamination: Language Models May Not Be Few-Shot Anymore",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n8991"
  },
  {
    "objectID": "posts/Mitigating_Data_Injection_Attacks_on_Federated_Learning/2023-12-04-Mitigating_Data_Injection_Attacks_on_Federated_Learning.html#appendix",
    "href": "posts/Mitigating_Data_Injection_Attacks_on_Federated_Learning/2023-12-04-Mitigating_Data_Injection_Attacks_on_Federated_Learning.html#appendix",
    "title": "Mitigating Data Injection Attacks on Federated Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n7092"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Bayesian beagle",
    "section": "",
    "text": "I’m a Bayesian beagle who has curated LLM-summarized articles on LLMs."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ryan’s LLM Blog 🤖",
    "section": "",
    "text": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios\n\n\n\nrobustness\n\n\nprompt engineering\n\n\n\nToolEyes assesses large language model tool learning in authentic scenarios, uncovering limitations and guiding future research.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecFormer: Towards Fast and Accurate Privacy-Preserving Inference for Large Language Models\n\n\n\nsecurity\n\n\n\nPrivacy concerns with large language models led to Secure Multi-Party Computing (SMPC) for Privacy-Preserving Inference. SecFormer optimizes SMPC for Transformer models…\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Computational Framework for Behavioral Assessment of LLM Therapists\n\n\n\nsocial sciences\n\n\n\nChatGPT and other large language models are being considered as therapists, but research shows their behavior may not reflect high-quality therapy.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistillation is All You Need for Practically Using Different Pre-trained Recommendation Models\n\n\n\nrecommender\n\n\n\nProposed PRM-KD model efficiently utilizes diverse pre-trained recommendation models to enhance student models for real-world recommendations.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Earth is Flat? Unveiling Factual Errors in Large Language Models\n\n\n\nrobustness\n\n\n\nTL;DR: FactChecker is a new automatic testing framework that uncovers factual inaccuracies in large language models with up to 45% error detection.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nState of What Art? A Call for Multi-Prompt LLM Evaluation\n\n\n\nrobustness\n\n\nprompt engineering\n\n\n\nAdvances in large language models are analyzed for their evaluation, suggesting diverse prompts for more reliable assessments.\n\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBatchEval: Towards Human-like Text Evaluation\n\n\n\nrobustness\n\n\nprompt engineering\n\n\n\nBatchEval improves text evaluation over LLMs, addressing design sensitivity, noise resistance, and ensemble performance, with 10.5% higher correlations at reduced API cost.\n\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRAGTruth: A Hallucination Corpus for Developing Trustworthy Retrieval-Augmented Language Models\n\n\n\ndataset\n\n\nprompt engineering\n\n\n\nRAGTruth is a dataset for analyzing hallucinations in large language models, helping measure and prevent unsupported claims in retrieved content.\n\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nViz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI\n\n\n\nproduction\n\n\nlegal\n\n\n\nViz system integrates QLoRA to fine-tune large language models legally and efficiently, addressing AI challenges.\n\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-Assist: Enhancing Closed-Loop Planning with Language-Based Reasoning\n\n\n\nrobustness\n\n\nprompt engineering\n\n\n\nHybrid planner combines rule-based and language models, outperforming existing methods in driving scenario handling.\n\n\n\nDec 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Art of Defending: A Systematic Evaluation and Analysis of LLM Defense Strategies on Safety and Over-Defensiveness\n\n\n\nsecurity\n\n\n\nSODE benchmark assesses LLM safety and over-defensiveness, revealing key defense strategy insights for further research.\n\n\n\nDec 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRed Teaming for Large Language Models At Scale: Tackling Hallucinations on Mathematics Tasks\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nStudy evaluates prompting techniques for LLMs on math tasks. Findings show models struggle with elementary calculations and reasoning even with red teaming.\n\n\n\nDec 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAction-Item-Driven Summarization of Long Meeting Transcripts\n\n\n\nprompt engineering\n\n\n\nAutomated abstractive meeting summary algorithm for action items, achieving improved BERTScore on AMI corpus.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChatEd: A Chatbot Leveraging ChatGPT for an Enhanced Learning Experience in Higher Education\n\n\n\neducation\n\n\n\nChatGPT and similar language models have potential in education but face challenges with accuracy. New architecture offers enhanced student support.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTask Contamination: Language Models May Not Be Few-Shot Anymore\n\n\n\nprompt engineering\n\n\n\nLarge language models (LLMs) perform better in zero-shot and few-shot tasks on datasets released before their training data creation date, possibly due to task contamination.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSupervised Knowledge Makes Large Language Models Better In-context Learners\n\n\n\nprompt engineering\n\n\n\nTL;DR: A framework enhances Large Language Models’ reliability, generalizability, and factuality, using discriminative models during inference.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKnowledge Distillation of LLM for Education\n\n\n\neducation\n\n\n\nA method is proposed to create smaller, efficient neural networks from large language models, aiming to deploy them on resource-constrained devices and improve accessibility…\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRecRanker: Instruction Tuning Large Language Model as Ranker for Top-k Recommendation\n\n\n\nprompt engineering\n\n\n\nLLMs used in recommendation systems lack integration of multiple ranking tasks, so RecRanker was developed to address this and improve model performance.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrincipled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4\n\n\n\nprompt engineering\n\n\n\nThis paper presents 26 principles for querying large language models, validated through experiments on different models.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models are Not Stable Recommender Systems\n\n\n\nrecommender\n\n\n\nLLMs struggle as recommender systems due to position bias. STELLA framework mitigates bias, improving recommendation performance.\n\n\n\nDec 25, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlleviating Hallucinations of Large Language Models through Induced Hallucinations\n\n\n\nrobustness\n\n\n\nNew decoding strategy reduces misinformation in large language models, improving factuality across various models and benchmarks.\n\n\n\nDec 25, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnlocking the Potential of Large Language Models for Explainable Recommendations\n\n\n\nrecommender\n\n\n\nAdvances in language generation tech enhance trust and decision-making. LLMXRec proposes a two-stage recommendation framework emphasizing collaboration and fine-tuning to…\n\n\n\nDec 25, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Persuasive Power of Large Language Models\n\n\n\nhci\n\n\n\nLarge Language Models’ potential to influence public opinion and engage in persuasive dialogue was assessed through a study on climate change arguments.\n\n\n\nDec 24, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvolving Large Language Model Assistant with Long-Term Conditional Memory\n\n\n\nrobustness\n\n\n\nAI assistant ChatGPT with verbal long-term memory for improved responses using GPT-4.\n\n\n\nDec 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogic-Scaffolding: Personalized Aspect-Instructed Recommendation Explanation Generation using LLMs\n\n\n\nhci\n\n\nprompt engineering\n\n\n\nLarge Language Models show potential for recommendation explanations, but current models struggle. A proposed Logic-Scaffolding framework aims to improve explanation…\n\n\n\nDec 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nContext-aware Decoding Reduces Hallucination in Query-focused Summarization\n\n\n\nrobustness\n\n\n\nQuery-focused summarization (QFS) benefits from new decoding techniques, improving quality but with increased complexity and reduced speed.\n\n\n\nDec 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAndroid dialogue system for customer service using prompt-based topic control and compliments generation\n\n\n\nhci\n\n\nprompt engineering\n\n\n\nDialogue system for trip planning uses ChatGPT-API to control topics and generate compliments, evaluated positively in a travel agency.\n\n\n\nDec 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBypassing the Safety Training of Open-Source LLMs with Priming Attacks\n\n\n\nsecurity\n\n\nopen-source\n\n\n\nLLMs lack safety training and are vulnerable to priming attacks, effectively bypassing alignment, increasing attack success rate.\n\n\n\nDec 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGuardRails: Automated Suggestions for Clarifying Ambiguous Purpose Statements\n\n\n\nprompt engineering\n\n\nprogramming\n\n\n\nPurpose statements for functions may be ambiguous; a heuristic is proposed to suggest clarifications using language models.\n\n\n\nDec 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrompting LLMs with content plans to enhance the summarization of scientific articles\n\n\n\nprompt engineering\n\n\n\nNovel prompting techniques improve summarization systems for scientific articles, especially for smaller models summarizing sections separately.\n\n\n\nDec 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models are Clinical Reasoners: Reasoning-Aware Diagnosis Framework with Prompt-Generated Rationales\n\n\n\nprompt engineering\n\n\n\nProposing a time-efficient framework for clinical reasoning in disease diagnosis using prompt-based learning and machine-generated rationales.\n\n\n\nDec 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM Interactive Optimization of Open Source Python Libraries – Case Studies and Generalization\n\n\n\nhci\n\n\nprogramming\n\n\n\nGPT-4 effectively optimizes python libraries with human input, but further quantification is needed for broader application.\n\n\n\nDec 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMitigating Data Injection Attacks on Federated Learning\n\n\n\nsecurity\n\n\n\nFederated learning has privacy benefits, but false data attacks are a risk. A new method detects and mitigates these attacks.\n\n\n\nDec 4, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/State_of_What_Art__A_Call_for_Multi_Prompt_LLM_Evaluation/2023-12-31-State_of_What_Art__A_Call_for_Multi_Prompt_LLM_Evaluation.html#appendix",
    "href": "posts/State_of_What_Art__A_Call_for_Multi_Prompt_LLM_Evaluation/2023-12-31-State_of_What_Art__A_Call_for_Multi_Prompt_LLM_Evaluation.html#appendix",
    "title": "State of What Art? A Call for Multi-Prompt LLM Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n10053"
  },
  {
    "objectID": "posts/Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners/2023-12-26-Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners.html#key-findings",
    "href": "posts/Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners/2023-12-26-Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners.html#key-findings",
    "title": "Supervised Knowledge Makes Large Language Models Better In-context Learners",
    "section": "Key Findings",
    "text": "Key Findings\n\nLarge Language Models (LLMs) demonstrate emerging in-context learning abilities through prompt engineering and have garnered significant performance across diverse tasks.\nThe study introduces SuperContext, a framework that uses task-Specific fine-tuned Language Models (SLMs) to improve LLMs’ in-context learning during the inference stage.\nUsing SuperContext, enhanced versions of Llama 2 and ChatGPT surpass their original versions regarding generalizability and factuality."
  },
  {
    "objectID": "posts/Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners/2023-12-26-Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners.html#introduction",
    "href": "posts/Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners/2023-12-26-Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners.html#introduction",
    "title": "Supervised Knowledge Makes Large Language Models Better In-context Learners",
    "section": "Introduction",
    "text": "Introduction\n\nLarge language models (LLMs) have shown robust performance across various tasks, but face challenges such as substantial resources for training and deployment, slow inference times, and susceptibility to hallucinations."
  },
  {
    "objectID": "posts/Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners/2023-12-26-Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners.html#method",
    "href": "posts/Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners/2023-12-26-Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners.html#method",
    "title": "Supervised Knowledge Makes Large Language Models Better In-context Learners",
    "section": "Method",
    "text": "Method\n\nIn-context Learning Baseline: Traditional in-context learning involves using in-domain data for several Natural Language Understanding (NLU) tasks with 16-shot examples.\nSuperContext: A simple and general approach that incorporates the auxiliary knowledge from a small, discriminative model with LLMs when making predictions for new tasks."
  },
  {
    "objectID": "posts/Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners/2023-12-26-Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners.html#experiments",
    "href": "posts/Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners/2023-12-26-Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners.html#experiments",
    "title": "Supervised Knowledge Makes Large Language Models Better In-context Learners",
    "section": "Experiments",
    "text": "Experiments\n\nSetup: Tested on 8 NLU tasks and 1 generation task to validate SuperContext on GLUE-X benchmark and SQuAD 2.0.\nNLU Results: SuperContext outperformed both SLMs and LLMs across NLU tasks, surpassing the supervised task-specific model, ELECTRA-large, as well.\nQA Results: SuperContext significantly improved accuracy for open questions in the QA task."
  },
  {
    "objectID": "posts/Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners/2023-12-26-Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners.html#analysis-and-discussion",
    "href": "posts/Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners/2023-12-26-Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners.html#analysis-and-discussion",
    "title": "Supervised Knowledge Makes Large Language Models Better In-context Learners",
    "section": "Analysis and Discussion",
    "text": "Analysis and Discussion\n\nReversed Predictions: SuperContext lead to the correction of predictions made by LLMs in both NLU and QA tasks.\nInterpretation Analysis: LLMs demonstrated the ability to recall influential in-context examples and output rationales, with SuperContext resulting in higher performance and overlap with human rationale.\nThe Effect of SLM Confidence: There is a positive correlation between SLM confidence and LLM performance, emphasizing the importance of including both prediction and confidence in the prompt design."
  },
  {
    "objectID": "posts/Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners/2023-12-26-Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners.html#critique",
    "href": "posts/Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners/2023-12-26-Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners.html#critique",
    "title": "Supervised Knowledge Makes Large Language Models Better In-context Learners",
    "section": "Critique",
    "text": "Critique\n\nThe study lacked a comparison with other large-scale language models, potentially limiting the generalizability of the findings.\nThe effectiveness of SuperContext was not evaluated in real-world applications, limiting its practical implications.\n\nOverall, the study sheds light on the potential of incorporating supervised knowledge from SLMs to enhance the performance of LLMs in various NLU and QA tasks. The findings highlight the importance of leveraging discriminative models for improving the reliability and factuality of LLMs."
  },
  {
    "objectID": "posts/Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners/2023-12-26-Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners.html#appendix",
    "href": "posts/Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners/2023-12-26-Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners.html#appendix",
    "title": "Supervised Knowledge Makes Large Language Models Better In-context Learners",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n12183"
  },
  {
    "objectID": "posts/RecRanker__Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top_k_Recommendation/2023-12-26-RecRanker__Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top_k_Recommendation.html#appendix",
    "href": "posts/RecRanker__Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top_k_Recommendation/2023-12-26-RecRanker__Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top_k_Recommendation.html#appendix",
    "title": "RecRanker: Instruction Tuning Large Language Model as Ranker for Top-k Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nTrue\n\n\nWord Count\n15714"
  },
  {
    "objectID": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#key-findings",
    "href": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#key-findings",
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "section": "Key Findings",
    "text": "Key Findings\n\nToolEyes offers a fine-grained evaluation system for Large Language Models’ (LLMs) tool learning capabilities, examining seven real-world scenarios and approximately 600 tools.\nThe evaluation reveals that LLMs exhibit preference for specific scenarios and restricted cognitive abilities in tool learning, with larger model size exacerbating the hindrance to tool learning.\nThe findings suggest the need for improvement in tool learning capabilities across all categories of LLMs."
  },
  {
    "objectID": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#evaluation-system",
    "href": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#evaluation-system",
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "section": "Evaluation System",
    "text": "Evaluation System\n\nScenario Construction\n\nToolEyes formulates seven real-world scenarios, including Text Generation, Data Understanding, Real-Time Search, Application Manipulation, Personal Life, Information Retrieval, and Financial Transactions.\nEach scenario is equipped with a related set of tools, totaling 41 categories, 95 subcategories, and 568 tools.\n\n\n\nTool Library Building\n\nThe system establishes a tool library, serving as an interface for LLMs to interact with the environment.\n\n\n\nHuman-Driven Data Generation\n\nProfessionals were engaged to identify actual requirements by reviewing the tool documentation to ensure comprehensive coverage of different scenarios.\n\n\n\nLLMs Capability Evaluation\n\nToolEyes evaluates LLMs across five essential capabilities: format alignment, intent comprehension, behavior planning, tool selection, and answer organization."
  },
  {
    "objectID": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#experiments",
    "href": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#experiments",
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "section": "Experiments",
    "text": "Experiments\n\nModel Selection\n\nExperiments were conducted on ten LLMs from three sources: open-source, tool-oriented, and closed-source categories, including LLaMA-2-chat, Vicuna-1.5, Text-davinci-003, GPT-3.5-turbo, and GPT-4.\n\n\n\nExperimental Setup\n\nLLMs were assessed using a five-shot format for open-source models and zero-shot format for others, with specific prompt templates used during inference.\n\n\n\nResults in Different Scenarios\n\nLLMs exhibit scenario-specific preferences in tool learning, influenced by their optimization goals and training data.\n\n\n\nResults of Different LLMs Capabilities\n\nThe present constraints in LLMs thinking skills present a substantial obstacle to tool learning, and LLMs with superior performance exhibit more effective problem-solving abilities.\n\n\n\nWhy does NOT LLMs Capabilities Increase with Size?\n\nThe study found that as the model size increases, there is a potential weakening of the instrumental learning capabilities within specific LLM families."
  },
  {
    "objectID": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#insights-for-advancing-tool-learning",
    "href": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#insights-for-advancing-tool-learning",
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "section": "Insights for Advancing Tool Learning",
    "text": "Insights for Advancing Tool Learning\n\nIdeas for advancing tool learning include task construction considering model behavior, scenario generalization using diverse data, and capability enhancement addressing the “barrel effect.”"
  },
  {
    "objectID": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#related-works",
    "href": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#related-works",
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "section": "Related Works",
    "text": "Related Works\n\nThe paper discusses tool learning and evaluations for tool learning, highlighting the challenges in current tool learning research."
  },
  {
    "objectID": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#conclusion",
    "href": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#conclusion",
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "section": "Conclusion",
    "text": "Conclusion\n\nToolEyes offers instructive insights to inform the development of tool learning and presents avenues for future research."
  },
  {
    "objectID": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#limitations",
    "href": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#limitations",
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "section": "Limitations",
    "text": "Limitations\n\nThe paper acknowledges limitations, including the absence of a novel LLM dedicated to tool learning and the associated costs of scoring using specific LLMs."
  },
  {
    "objectID": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#appendix",
    "href": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#appendix",
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n11381"
  },
  {
    "objectID": "posts/The_Persuasive_Power_of_Large_Language_Models/2023-12-24-The_Persuasive_Power_of_Large_Language_Models.html#appendix",
    "href": "posts/The_Persuasive_Power_of_Large_Language_Models/2023-12-24-The_Persuasive_Power_of_Large_Language_Models.html#appendix",
    "title": "The Persuasive Power of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n9545"
  },
  {
    "objectID": "posts/LLM_Interactive_Optimization_of_Open_Source_Python_Libraries____Case_Studies_and_Generalization/2023-12-08-LLM_Interactive_Optimization_of_Open_Source_Python_Libraries____Case_Studies_and_Generalization.html",
    "href": "posts/LLM_Interactive_Optimization_of_Open_Source_Python_Libraries____Case_Studies_and_Generalization/2023-12-08-LLM_Interactive_Optimization_of_Open_Source_Python_Libraries____Case_Studies_and_Generalization.html",
    "title": "LLM Interactive Optimization of Open Source Python Libraries – Case Studies and Generalization",
    "section": "",
    "text": "Summary:\nMajor Takeaways: - The paper presents methodologically stringent case studies applied to well-known open source Python libraries pillow and numpy, using the LLM ChatGPT-4, to optimize source code for energy and compute efficiency in interactive collaboration with a human expert. - LLM ChatGPT-4 was successful in optimizing the source code, with improvements reported for the same expert across multiple case studies, where performance improvements ranged from 1.2 to 38 times. - The case studies demonstrate a strong potential for practical utility of LLMs in collaborative code optimization for open-source Python libraries."
  },
  {
    "objectID": "posts/LLM_Interactive_Optimization_of_Open_Source_Python_Libraries____Case_Studies_and_Generalization/2023-12-08-LLM_Interactive_Optimization_of_Open_Source_Python_Libraries____Case_Studies_and_Generalization.html#appendix",
    "href": "posts/LLM_Interactive_Optimization_of_Open_Source_Python_Libraries____Case_Studies_and_Generalization/2023-12-08-LLM_Interactive_Optimization_of_Open_Source_Python_Libraries____Case_Studies_and_Generalization.html#appendix",
    "title": "LLM Interactive Optimization of Open Source Python Libraries – Case Studies and Generalization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nTrue\n\n\nWord Count\n18038"
  },
  {
    "objectID": "posts/Android_dialogue_system_for_customer_service_using_prompt_based_topic_control_and_compliments_generation/2023-12-20-Android_dialogue_system_for_customer_service_using_prompt_based_topic_control_and_compliments_generation.html#appendix",
    "href": "posts/Android_dialogue_system_for_customer_service_using_prompt_based_topic_control_and_compliments_generation/2023-12-20-Android_dialogue_system_for_customer_service_using_prompt_based_topic_control_and_compliments_generation.html#appendix",
    "title": "Android dialogue system for customer service using prompt-based topic control and compliments generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n2038"
  },
  {
    "objectID": "posts/The_Art_of_Defending__A_Systematic_Evaluation_and_Analysis_of_LLM_Defense_Strategies_on_Safety_and_Over_Defensiveness/2023-12-30-The_Art_of_Defending__A_Systematic_Evaluation_and_Analysis_of_LLM_Defense_Strategies_on_Safety_and_Over_Defensiveness.html#appendix",
    "href": "posts/The_Art_of_Defending__A_Systematic_Evaluation_and_Analysis_of_LLM_Defense_Strategies_on_Safety_and_Over_Defensiveness/2023-12-30-The_Art_of_Defending__A_Systematic_Evaluation_and_Analysis_of_LLM_Defense_Strategies_on_Safety_and_Over_Defensiveness.html#appendix",
    "title": "The Art of Defending: A Systematic Evaluation and Analysis of LLM Defense Strategies on Safety and Over-Defensiveness",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n8573"
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#major-findings",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#major-findings",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Major Findings",
    "text": "Major Findings\n\nThe paper presents a new evolving large language model (LLM) assistant that uses long-term memory to preserve knowledge and experiences from past dialogues to improve future responses.\nThe model utilizes a memory-based framework with three main components: an existing LLM assistant, a memory, and a prompt-based interaction between the assistant and the memory.\nThe proposed conditional memory approach is the most effective for learning new knowledge and from human feedback, while a combination of conditional memory and summary-based memory improves performance for continuing previous dialogue."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#abstract",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#abstract",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Abstract",
    "text": "Abstract\nThe paper introduces an evolving large language model assistant that leverages long-term conditional memory to enhance the quality of responses in future dialogues. The model generates and stores records for each dialogue to be used in later interactions. The paper examines different mechanisms for constructing and utilizing memory and evaluates the assistant on three test datasets focusing on various abilities required by an AI assistant with long-term memory."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#introduction",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#introduction",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Introduction",
    "text": "Introduction\n\nLarge language models (LLMs), such as ChatGPT, have become popular in providing assistance and engaging in chit-chat with users.\nThe main problem is that current AI assistants do not retain information from previous dialogues, hindering their ability to learn from past interactions and improve future responses.\nThe evolving LLM assistant aims to address this by using a memory-based framework to store and retrieve dialogue history."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#related-work",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#related-work",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Related Work",
    "text": "Related Work\n\nExisting research in retrieval-based dialogue systems and conversational question answering has long focused on integrating retrieved dialogue and external knowledge into the generation process."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#method",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#method",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Method",
    "text": "Method\n\nMemory Construction\n\nThe paper explores three types of memory construction: history-based memory, summary-based memory, and conditional memory, with conditional memory demonstrating the most promising results. ### Memory Retrieval and Application\nThe memory retrieval process involves utilizing dense retrieval and a self-reflection mechanism to determine the usefulness of retrieved information."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#dataset",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#dataset",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Dataset",
    "text": "Dataset\n\nThe experiment involves constructing three test datasets focusing on different aspects: continuing previous dialogue, learning new knowledge, and learning from user feedback."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#experiment",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#experiment",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Experiment",
    "text": "Experiment\n\nThe study uses GPT-4 as the backbone for evaluation and employs various GPT-4 evaluations, including scoring, comparing, and multiple choice.\nResults indicate that conditional memory outperforms other forms of memory and that the combination of conditional memory and summary-based memory enhances performance.\nSelf-reflection retrieval is effective, especially for summary-based memory."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#appendix-a-method-details",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#appendix-a-method-details",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Appendix A: Method Details",
    "text": "Appendix A: Method Details\n\nIt provides detailed prompts for memory construction, self-reflection retrieval, and dataset construction."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#appendix-b-dataset-construction-details",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#appendix-b-dataset-construction-details",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Appendix B: Dataset Construction Details",
    "text": "Appendix B: Dataset Construction Details\n\nIt presents prompts for constructing test datasets focusing on continuing previous dialogue, learning new knowledge, and learning from human feedback."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#appendix-c-gpt-evaluation-details",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#appendix-c-gpt-evaluation-details",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Appendix C: GPT Evaluation Details",
    "text": "Appendix C: GPT Evaluation Details\n\nIt outlines prompts for GPT-4 evaluations, such as scoring, comparing, and multiple choice."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#critique",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#critique",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Critique",
    "text": "Critique\n\nThe study uses small-scale datasets for testing due to the high cost of GPT-4 usage, which may limit the generalizability of the findings.\nThe paper acknowledges that other key points, such as time stamp or forgetting mechanism, are yet to be explored, suggesting that the study is still in the foundational stage."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#appendix",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#appendix",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n8298"
  },
  {
    "objectID": "posts/Red_Teaming_for_Large_Language_Models_At_Scale__Tackling_Hallucinations_on_Mathematics_Tasks/2023-12-30-Red_Teaming_for_Large_Language_Models_At_Scale__Tackling_Hallucinations_on_Mathematics_Tasks.html#appendix",
    "href": "posts/Red_Teaming_for_Large_Language_Models_At_Scale__Tackling_Hallucinations_on_Mathematics_Tasks/2023-12-30-Red_Teaming_for_Large_Language_Models_At_Scale__Tackling_Hallucinations_on_Mathematics_Tasks.html#appendix",
    "title": "Red Teaming for Large Language Models At Scale: Tackling Hallucinations on Mathematics Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n7380"
  },
  {
    "objectID": "posts/GuardRails__Automated_Suggestions_for_Clarifying_Ambiguous_Purpose_Statements/2023-12-13-GuardRails__Automated_Suggestions_for_Clarifying_Ambiguous_Purpose_Statements.html#appendix",
    "href": "posts/GuardRails__Automated_Suggestions_for_Clarifying_Ambiguous_Purpose_Statements/2023-12-13-GuardRails__Automated_Suggestions_for_Clarifying_Ambiguous_Purpose_Statements.html#appendix",
    "title": "GuardRails: Automated Suggestions for Clarifying Ambiguous Purpose Statements",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n5188"
  },
  {
    "objectID": "posts/BatchEval__Towards_Human_like_Text_Evaluation/2023-12-31-BatchEval__Towards_Human_like_Text_Evaluation.html#appendix",
    "href": "posts/BatchEval__Towards_Human_like_Text_Evaluation/2023-12-31-BatchEval__Towards_Human_like_Text_Evaluation.html#appendix",
    "title": "BatchEval: Towards Human-like Text Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nTrue\n\n\nWord Count\n15893"
  },
  {
    "objectID": "posts/Distillation_is_All_You_Need_for_Practically_Using_Different_Pre_trained_Recommendation_Models/2024-01-01-Distillation_is_All_You_Need_for_Practically_Using_Different_Pre_trained_Recommendation_Models.html#appendix",
    "href": "posts/Distillation_is_All_You_Need_for_Practically_Using_Different_Pre_trained_Recommendation_Models/2024-01-01-Distillation_is_All_You_Need_for_Practically_Using_Different_Pre_trained_Recommendation_Models.html#appendix",
    "title": "Distillation is All You Need for Practically Using Different Pre-trained Recommendation Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n11769"
  },
  {
    "objectID": "posts/The_Earth_is_Flat__Unveiling_Factual_Errors_in_Large_Language_Models/2024-01-01-The_Earth_is_Flat__Unveiling_Factual_Errors_in_Large_Language_Models.html#summary",
    "href": "posts/The_Earth_is_Flat__Unveiling_Factual_Errors_in_Large_Language_Models/2024-01-01-The_Earth_is_Flat__Unveiling_Factual_Errors_in_Large_Language_Models.html#summary",
    "title": "The Earth is Flat? Unveiling Factual Errors in Large Language Models",
    "section": "Summary",
    "text": "Summary\n\nMajor Takeaways\n\nBiasAsker is introduced as a testing method to identify bias in conversational AI software through asking questions.\nThe study demonstrates that BiasAsker can effectively reveal factual errors in a variety of large language models used in chatbot and digital assistant applications with an accuracy of up to 78.2% for commercial LLMs and an improvement of 33.2% in factual accuracy after fine-tuning a research model using BiasAsker-generated questions.\nBiasAsker is shown to be highly effective in identifying factual errors, passing a manual validation with a ~93% accuracy in identified errors.\n\n\n\nBackground\nRecent advancements in Large Language Models (LLMs) have led to the rapid adoption of AI-driven chatbot and digital assistant applications. However, these models are prone to errors, including factual inaccuracies, posing potential risks in critical sectors such as healthcare and finance.\n\n\nApproach and Implementation\nBiasAsker operates in three stages: Knowledge Graph Construction, Question Generation, and Answer Assessment. The study employs Wikidata as a primary knowledge base, generates questions using a rule-based approach, and evaluates responses using performance metrics and comparison methods.\n\n\nEvaluation\n\nEffectiveness of BiasAsker: BiasAsker successfully identifies factual errors across various LLMs, notably detecting 36.9% of the test cases with errors.\nValidity of Identified Factual Errors: Upon manual inspection, 93% of the identified errors were found to be valid.\nUsing BiasAsker for Improvement: Test cases generated by BiasAsker led to substantial improvements in factual accuracy, with an average improvement of 6.5% using in-context learning and 33.2% via fine-tuning of the research models."
  },
  {
    "objectID": "posts/The_Earth_is_Flat__Unveiling_Factual_Errors_in_Large_Language_Models/2024-01-01-The_Earth_is_Flat__Unveiling_Factual_Errors_in_Large_Language_Models.html#critique",
    "href": "posts/The_Earth_is_Flat__Unveiling_Factual_Errors_in_Large_Language_Models/2024-01-01-The_Earth_is_Flat__Unveiling_Factual_Errors_in_Large_Language_Models.html#critique",
    "title": "The Earth is Flat? Unveiling Factual Errors in Large Language Models",
    "section": "Critique",
    "text": "Critique\nThe paper’s reliance on NLP methods for error detection and the limitation to a single knowledge base may introduce the potential for false positives or overlook factual inaccuracies. Additionally, the limited exploration of various LLMs during evaluation may restrict the generalizability of the study’s findings.\nOverall, the study’s use of BiasAsker offers a valuable contribution to the field of conversational AI software testing, demonstrating its effectiveness in identifying and rectifying factual inaccuracies in large language models. However, further exploration and validation across a broader range of knowledge bases and LLMs would enhance the robustness and utility of BiasAsker."
  },
  {
    "objectID": "posts/The_Earth_is_Flat__Unveiling_Factual_Errors_in_Large_Language_Models/2024-01-01-The_Earth_is_Flat__Unveiling_Factual_Errors_in_Large_Language_Models.html#appendix",
    "href": "posts/The_Earth_is_Flat__Unveiling_Factual_Errors_in_Large_Language_Models/2024-01-01-The_Earth_is_Flat__Unveiling_Factual_Errors_in_Large_Language_Models.html#appendix",
    "title": "The Earth is Flat? Unveiling Factual Errors in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n11574"
  },
  {
    "objectID": "posts/Context_aware_Decoding_Reduces_Hallucination_in_Query_focused_Summarization/2023-12-21-Context_aware_Decoding_Reduces_Hallucination_in_Query_focused_Summarization.html#appendix",
    "href": "posts/Context_aware_Decoding_Reduces_Hallucination_in_Query_focused_Summarization/2023-12-21-Context_aware_Decoding_Reduces_Hallucination_in_Query_focused_Summarization.html#appendix",
    "title": "Context-aware Decoding Reduces Hallucination in Query-focused Summarization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n6395"
  },
  {
    "objectID": "posts/Bypassing_the_Safety_Training_of_Open_Source_LLMs_with_Priming_Attacks/2023-12-19-Bypassing_the_Safety_Training_of_Open_Source_LLMs_with_Priming_Attacks.html#appendix",
    "href": "posts/Bypassing_the_Safety_Training_of_Open_Source_LLMs_with_Priming_Attacks/2023-12-19-Bypassing_the_Safety_Training_of_Open_Source_LLMs_with_Priming_Attacks.html#appendix",
    "title": "Bypassing the Safety Training of Open-Source LLMs with Priming Attacks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-02\n\n\nHTML\n\n\n\nTruncated\nFalse\n\n\nWord Count\n3431"
  }
]