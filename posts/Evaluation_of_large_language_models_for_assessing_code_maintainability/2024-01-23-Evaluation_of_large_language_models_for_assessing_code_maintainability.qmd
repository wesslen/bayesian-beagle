
---
title: "Evaluation of large language models for assessing code maintainability"
id: "2401.12714v1"
description: "Open-source software and LLMs can automate tasks, but cross-entropy alone may not predict maintainability accurately."
author: ['Marc Dillmann', 'Julien Siebert', 'Adam Trendowicz']
date: "2024-01-23"
image: "https://browse.arxiv.org/html/2401.12714v1/x1.png"
categories: ['production', 'programming', 'robustness', 'architectures']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.12714v1/x1.png)

### Summary of the Article:

The article explores the use of large language models (LLMs) to assess code maintainability at a class level. It investigates the relationship between the cross-entropy of code generated by different LLMs and quality aspects such as readability, understandability, complexity, modularization, and overall maintainability. The study revealed a predictive relationship between cross-entropy and maintainability, especially when controlling for the number of logical lines of code (LLOC). However, the association reversed when not controlling for LLOC. The complexity of LLMs was found to influence the range of cross-entropy but did not significantly impact the predictability of maintainability aspects.

### Major Findings:
1. Cross-entropy computed by LLMs is a predictor of maintainability on a class level, particularly when controlling for LLOC.
2. The association between cross-entropy and maintainability reversed when not controlling for LLOC, indicating a potential confounding effect.
3. The complexity of LLMs affects the range of cross-entropy but does not play a significant role in predicting maintainability aspects.

### Analysis and Critique:
The article presents valuable insights into the use of LLMs for code maintainability assessment, highlighting the influence of cross-entropy and LLOC. However, it is crucial to acknowledge limitations in the study, such as its focus on a limited number of pretrained models and maintainability aspects, potentially affecting the generalizability of the findings. Methodological concerns, including the choice of evaluation metrics and assumptions about the use of LLMs as oracles, necessitate further exploration and validation. Additionally, the potential impact of data quality, selection bias, and construct validity on the study's outcomes should be carefully considered in future research. Further investigations should address these limitations to enhance the robustness and applicability of the study's findings.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-29       |
| Abstract | [http://arxiv.org/abs/2401.12714v1](http://arxiv.org/abs/2401.12714v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.12714v1](https://browse.arxiv.org/html/2401.12714v1)       |
| Truncated       | False       |
| Word Count       | 6426       |