
---
title: "MathOdyssey: Benchmarking Mathematical Problem-Solving Skills in Large Language Models Using Odyssey Math Data"
id: "2406.18321v1"
description: "LLMs excel at basic math but struggle with complex problems, per the MathOdyssey dataset. Open-source models are closing the gap with closed-source models."
author: Meng Fang, Xiangpeng Wan, Fei Lu, Fei Xing, Kai Zou
date: "2024-06-26"
image: "https://browse.arxiv.org/html/2406.18321v1/x1.png"
categories: ['education', 'prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.18321v1/x1.png)

### Summary:

The paper introduces the MathOdyssey dataset, a new benchmark for evaluating the mathematical problem-solving capabilities of large language models (LLMs). The dataset includes diverse mathematical problems at high school and university levels, created by experts from notable institutions. The authors conduct benchmarking on open-source models, such as Llama-3 and DBRX-Instruct, and closed-source models from the GPT series and Gemini models. The results indicate that while LLMs perform well on routine and moderately difficult tasks, they face significant challenges with Olympiad-level problems and complex university-level questions. The study highlights the ongoing need for research to enhance the mathematical reasoning of LLMs.

### Major Findings:

1. LLMs perform well on routine and moderately difficult mathematical tasks but struggle with Olympiad-level problems and complex university-level questions.
2. There is a narrowing performance gap between open-source and closed-source models, yet substantial challenges remain, particularly with the most demanding problems.
3. The MathOdyssey dataset provides a new benchmark for evaluating the mathematical problem-solving capabilities of LLMs, covering a wider range of subject areas and difficulty levels.

### Analysis and Critique:

1. The paper provides a comprehensive evaluation of LLMs' mathematical problem-solving capabilities, highlighting their strengths and weaknesses.
2. The MathOdyssey dataset is a valuable resource for the AI community, contributing to the understanding and improvement of AI capabilities in complex mathematical problem-solving.
3. The study reveals that while LLMs have made significant progress in mathematical reasoning, there is still a considerable gap in their ability to solve the most challenging problems.
4. The paper does not discuss the potential limitations of the MathOdyssey dataset, such as the representativeness of the problems or the generalizability of the findings to other types of mathematical problems.
5. Future research could explore the potential of using the MathOdyssey dataset to develop new methods for improving the mathematical reasoning of LLMs.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-07       |
| Abstract | [https://arxiv.org/abs/2406.18321v1](https://arxiv.org/abs/2406.18321v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.18321v1](https://browse.arxiv.org/html/2406.18321v1)       |
| Truncated       | False       |
| Word Count       | 5533       |