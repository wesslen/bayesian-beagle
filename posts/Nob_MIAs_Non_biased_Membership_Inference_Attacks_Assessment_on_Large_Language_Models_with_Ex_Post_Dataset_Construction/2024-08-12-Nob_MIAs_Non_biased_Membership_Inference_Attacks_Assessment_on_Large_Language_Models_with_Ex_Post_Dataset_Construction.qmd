
---
title: "Nob-MIAs: Non-biased Membership Inference Attacks Assessment on Large Language Models with Ex-Post Dataset Construction"
id: "2408.05968v1"
description: "TL;DR: New methods create fairer datasets for evaluating MIAs on LLMs, showing biases hinder MIA effectiveness."
author: Cédric Eichler, Nathan Champeil, Nicolas Anciaux, Alexandra Bensamoun, Heber Hwang Arcolezi, José Maria De Fuentes
date: "2024-08-12"
image: "https://browse.arxiv.org/html/2408.05968v1/x1.png"
categories: ['production']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.05968v1/x1.png)

# Summary:

The paper addresses the problem of assessing Membership Inference Attacks (MIAs) on Large Language Models (LLMs) with partially inferable training sets. The authors propose and validate algorithms to create "non-biased" and "non-classifiable" datasets for fairer MIA assessment. The experiments using the Gutenberg dataset on OpenLamma and Pythia show that neutralizing known biases alone is insufficient. The proposed methods produce non-biased ex-post datasets with AUC-ROC scores comparable to those previously obtained on genuinely random datasets, validating the approach. However, MIAs yield results close to random, with only one being effective on both random and the proposed datasets, but its performance decreases when bias is removed.

# Major Findings:

1. The paper proposes and validates algorithms to create "non-biased" and "non-classifiable" datasets for fairer MIA assessment on LLMs with partially inferable training sets.
2. Neutralizing known biases alone is insufficient for accurate MIA assessment.
3. The proposed methods produce non-biased ex-post datasets with AUC-ROC scores comparable to those previously obtained on genuinely random datasets, validating the approach.
4. MIAs yield results close to random, with only one being effective on both random and the proposed datasets, but its performance decreases when bias is removed.

# Analysis and Critique:

1. The paper addresses an important issue in the field of LLMs and copyright infringement, providing a method for fairer MIA assessment.
2. The proposed algorithms and experiments provide a valuable contribution to the field, offering a way to create "non-biased" and "non-classifiable" datasets.
3. However, the paper does not discuss the potential limitations or biases of the proposed methods, which could be a topic for future research.
4. The paper also does not discuss the potential implications of the findings for the development and use of LLMs, which could be an important area for further research.
5. The paper could benefit from a more detailed discussion of the potential applications and implications of the proposed methods, as well as a more thorough analysis of the limitations and biases of the proposed methods.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-13       |
| Abstract | [https://arxiv.org/abs/2408.05968v1](https://arxiv.org/abs/2408.05968v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.05968v1](https://browse.arxiv.org/html/2408.05968v1)       |
| Truncated       | False       |
| Word Count       | 7404       |