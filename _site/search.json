[
  {
    "objectID": "posts/Context-aware_Decoding_Reduces_Hallucination_in_Query-focused_Summarization/2023-12-21-Context-aware_Decoding_Reduces_Hallucination_in_Query-focused_Summarization.html",
    "href": "posts/Context-aware_Decoding_Reduces_Hallucination_in_Query-focused_Summarization/2023-12-21-Context-aware_Decoding_Reduces_Hallucination_in_Query-focused_Summarization.html",
    "title": "Context-aware Decoding Reduces Hallucination in Query-focused Summarization",
    "section": "",
    "text": "Context-aware Decoding (CAD) is a decoding method that reduces factual mistakes/hallucinations while mostly retaining the match of lexical patterns in query-focused summarization (QFS) datasets.\nThe study demonstrates that CAD can improve news summarization quality and reduce hallucination/factuality errors in QFS.\nDespite the benefits, CAD also introduces additional inference-time FLOPs and potentially slows down decoding speed, and the choice of hyperparameter Œ± affects the performance."
  },
  {
    "objectID": "posts/Context-aware_Decoding_Reduces_Hallucination_in_Query-focused_Summarization/2023-12-21-Context-aware_Decoding_Reduces_Hallucination_in_Query-focused_Summarization.html#appendix",
    "href": "posts/Context-aware_Decoding_Reduces_Hallucination_in_Query-focused_Summarization/2023-12-21-Context-aware_Decoding_Reduces_Hallucination_in_Query-focused_Summarization.html#appendix",
    "title": "Context-aware Decoding Reduces Hallucination in Query-focused Summarization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nLink\nhttps://browse.arxiv.org/html/2312.14335v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2884"
  },
  {
    "objectID": "posts/Android_dialogue_system_for_customer_service_using_prompt-based_topic_control_and_compliments_generation/2023-12-20-Android_dialogue_system_for_customer_service_using_prompt-based_topic_control_and_compliments_generation.html",
    "href": "posts/Android_dialogue_system_for_customer_service_using_prompt-based_topic_control_and_compliments_generation/2023-12-20-Android_dialogue_system_for_customer_service_using_prompt-based_topic_control_and_compliments_generation.html",
    "title": "Android dialogue system for customer service using prompt-based topic control and compliments generation",
    "section": "",
    "text": "Topic Control and Compliments: The developed Android dialogue system for customer service demonstrated the use of ChatGPT for topic control in trip planning, as well as generating compliments for users based on their appearance.\nUser Preference Integration: The system integrated user preferences by extracting knowledge from the history of the user‚Äôs utterances and utilizing it to propose travel plans matching the user‚Äôs preferences.\nEffective User Evaluation: In a preliminary round held at a travel agency‚Äôs actual store, the system garnered positive feedback and was ranked first in both satisfaction ratings and plan ratings by real customers."
  },
  {
    "objectID": "posts/Android_dialogue_system_for_customer_service_using_prompt-based_topic_control_and_compliments_generation/2023-12-20-Android_dialogue_system_for_customer_service_using_prompt-based_topic_control_and_compliments_generation.html#appendix",
    "href": "posts/Android_dialogue_system_for_customer_service_using_prompt-based_topic_control_and_compliments_generation/2023-12-20-Android_dialogue_system_for_customer_service_using_prompt-based_topic_control_and_compliments_generation.html#appendix",
    "title": "Android dialogue system for customer service using prompt-based topic control and compliments generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nLink\nhttps://browse.arxiv.org/html/2312.12924v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1231"
  },
  {
    "objectID": "posts/RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation/2023-12-26-RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation.html",
    "href": "posts/RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation/2023-12-26-RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation.html",
    "title": "RecRanker: Instruction Tuning Large Language Model as Ranker for Top-k Recommendation",
    "section": "",
    "text": "The paper introduces RecRanker, a framework designed for using instruction-tuning large language models (LLMs) to serve as the ranker in top-k recommendations. The authors propose importance-aware sampling, a position-shifting strategy, and prompt enhancement from conventional recommendation models to improve the model‚Äôs performance. They also introduce a hybrid ranking method to combine different ranking tasks for better performance.\n\n\n\n\nHybrid Ranking Method: The hybrid ranking approach significantly enhances the model‚Äôs performance across diverse ranking tasks.\nAdaptive User Sampling: Adaptive user sampling greatly improves the quality and diversity of the dataset, leading to better model performance.\nPrompt Enhancement: Integrating signals from conventional recommendation models into prompts enhances the model‚Äôs understanding and reasoning capabilities.\n\n\n\n\n\nAdaptive User Sampling: The framework employs importance-aware sampling and clustering-based sampling to procure high-quality, representative, and diverse users for the dataset.\nPrompt Construction: The position shifting strategy and prompt enhancement improve the contextual understanding of the LLM. Signals from conventional recommender models are seamlessly incorporated into the prompt.\nOptimization via Instruction Tuning: The fine-tuning process involves optimizing the LLM using a dataset generated from instructional data to align the model responses with user intents and preferences.\nHybrid Ranking: A hybrid ranking method is introduced to amalgamate the outputs of different ranking tasks for more effective recommendations.\n\n\n\n\n\nThe proposed RecRanker outperforms the traditional recommendation models, especially for the BookCrossing dataset.\nAnalysis of hyper-parameters shows the significance of appropriate hyper-parameter selection in achieving optimal model performance.\nInstruction-tuned LLMs perform significantly better than the GPT-3.5 model in top-k recommendations.\n\n\n\n\nThe paper provides valuable insights and contributions to the field of recommendation systems. However, the study could have delved deeper into the computational resources and scalability issues associated with deploying LLMs for large-scale recommender systems. Additionally, further exploration of potential limitations or challenges associated with the proposed framework may have added depth to the paper.\nOverall, the RecRanker framework presents a promising approach to leveraging instruction-tuning LLMs for top-k recommendations, with empirical evaluations demonstrating its effectiveness.\n\n\n\n\n\n\nLink\nhttps://browse.arxiv.org/html/2312.16018v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7669"
  },
  {
    "objectID": "posts/RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation/2023-12-26-RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation.html#abstract",
    "href": "posts/RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation/2023-12-26-RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation.html#abstract",
    "title": "RecRanker: Instruction Tuning Large Language Model as Ranker for Top-k Recommendation",
    "section": "",
    "text": "The paper introduces RecRanker, a framework designed for using instruction-tuning large language models (LLMs) to serve as the ranker in top-k recommendations. The authors propose importance-aware sampling, a position-shifting strategy, and prompt enhancement from conventional recommendation models to improve the model‚Äôs performance. They also introduce a hybrid ranking method to combine different ranking tasks for better performance."
  },
  {
    "objectID": "posts/RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation/2023-12-26-RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation.html#main-findings",
    "href": "posts/RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation/2023-12-26-RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation.html#main-findings",
    "title": "RecRanker: Instruction Tuning Large Language Model as Ranker for Top-k Recommendation",
    "section": "",
    "text": "Hybrid Ranking Method: The hybrid ranking approach significantly enhances the model‚Äôs performance across diverse ranking tasks.\nAdaptive User Sampling: Adaptive user sampling greatly improves the quality and diversity of the dataset, leading to better model performance.\nPrompt Enhancement: Integrating signals from conventional recommendation models into prompts enhances the model‚Äôs understanding and reasoning capabilities."
  },
  {
    "objectID": "posts/RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation/2023-12-26-RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation.html#methodology",
    "href": "posts/RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation/2023-12-26-RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation.html#methodology",
    "title": "RecRanker: Instruction Tuning Large Language Model as Ranker for Top-k Recommendation",
    "section": "",
    "text": "Adaptive User Sampling: The framework employs importance-aware sampling and clustering-based sampling to procure high-quality, representative, and diverse users for the dataset.\nPrompt Construction: The position shifting strategy and prompt enhancement improve the contextual understanding of the LLM. Signals from conventional recommender models are seamlessly incorporated into the prompt.\nOptimization via Instruction Tuning: The fine-tuning process involves optimizing the LLM using a dataset generated from instructional data to align the model responses with user intents and preferences.\nHybrid Ranking: A hybrid ranking method is introduced to amalgamate the outputs of different ranking tasks for more effective recommendations."
  },
  {
    "objectID": "posts/RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation/2023-12-26-RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation.html#experimental-results",
    "href": "posts/RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation/2023-12-26-RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation.html#experimental-results",
    "title": "RecRanker: Instruction Tuning Large Language Model as Ranker for Top-k Recommendation",
    "section": "",
    "text": "The proposed RecRanker outperforms the traditional recommendation models, especially for the BookCrossing dataset.\nAnalysis of hyper-parameters shows the significance of appropriate hyper-parameter selection in achieving optimal model performance.\nInstruction-tuned LLMs perform significantly better than the GPT-3.5 model in top-k recommendations."
  },
  {
    "objectID": "posts/RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation/2023-12-26-RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation.html#critique",
    "href": "posts/RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation/2023-12-26-RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation.html#critique",
    "title": "RecRanker: Instruction Tuning Large Language Model as Ranker for Top-k Recommendation",
    "section": "",
    "text": "The paper provides valuable insights and contributions to the field of recommendation systems. However, the study could have delved deeper into the computational resources and scalability issues associated with deploying LLMs for large-scale recommender systems. Additionally, further exploration of potential limitations or challenges associated with the proposed framework may have added depth to the paper.\nOverall, the RecRanker framework presents a promising approach to leveraging instruction-tuning LLMs for top-k recommendations, with empirical evaluations demonstrating its effectiveness."
  },
  {
    "objectID": "posts/RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation/2023-12-26-RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation.html#appendix",
    "href": "posts/RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation/2023-12-26-RecRanker:_Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top-k_Recommendation.html#appendix",
    "title": "RecRanker: Instruction Tuning Large Language Model as Ranker for Top-k Recommendation",
    "section": "",
    "text": "Link\nhttps://browse.arxiv.org/html/2312.16018v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7669"
  },
  {
    "objectID": "posts/GuardRails:_Automated_Suggestions_for_Clarifying_Ambiguous_Purpose_Statements/2023-12-13-GuardRails:_Automated_Suggestions_for_Clarifying_Ambiguous_Purpose_Statements.html",
    "href": "posts/GuardRails:_Automated_Suggestions_for_Clarifying_Ambiguous_Purpose_Statements/2023-12-13-GuardRails:_Automated_Suggestions_for_Clarifying_Ambiguous_Purpose_Statements.html",
    "title": "GuardRails: Automated Suggestions for Clarifying Ambiguous Purpose Statements",
    "section": "",
    "text": "GuardRails is a novel heuristic that leverages Large Language Models (LLMs) to suggest inputs for ambiguous purpose statements, aiding programmers in clarifying the intended behavior of functions.\nGuardRails compares favorably against GitHub Copilot‚Äôs Chat feature in identifying potential ambiguities in purpose statements, explicitly highlighting ambiguous inputs and outperforming Copilot Chat in several cases.\nThe tool has the potential to be especially helpful for novice programmers and instructors, aiding in the identification and clarification of ambiguities in purpose statements."
  },
  {
    "objectID": "posts/GuardRails:_Automated_Suggestions_for_Clarifying_Ambiguous_Purpose_Statements/2023-12-13-GuardRails:_Automated_Suggestions_for_Clarifying_Ambiguous_Purpose_Statements.html#appendix",
    "href": "posts/GuardRails:_Automated_Suggestions_for_Clarifying_Ambiguous_Purpose_Statements/2023-12-13-GuardRails:_Automated_Suggestions_for_Clarifying_Ambiguous_Purpose_Statements.html#appendix",
    "title": "GuardRails: Automated Suggestions for Clarifying Ambiguous Purpose Statements",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nLink\nhttps://browse.arxiv.org/html/2312.08189v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3094"
  },
  {
    "objectID": "posts/Logic-Scaffolding:_Personalized_Aspect-Instructed_Recommendation_Explanation_Generation_using_LLMs/2023-12-22-Logic-Scaffolding:_Personalized_Aspect-Instructed_Recommendation_Explanation_Generation_using_LLMs.html",
    "href": "posts/Logic-Scaffolding:_Personalized_Aspect-Instructed_Recommendation_Explanation_Generation_using_LLMs/2023-12-22-Logic-Scaffolding:_Personalized_Aspect-Instructed_Recommendation_Explanation_Generation_using_LLMs.html",
    "title": "Logic-Scaffolding: Personalized Aspect-Instructed Recommendation Explanation Generation using LLMs",
    "section": "",
    "text": "Large language models (LLMs) have the potential to provide explanations for recommendations, but existing models struggle to produce zero-shot explanations reliably due to lack of true personalization, transparency, and adaptability.\nThe paper proposes a framework called Logic-Scaffolding that addresses these challenges by combining aspect-based explanation and chain-of-thought prompting to generate explanations through intermediate reasoning steps.\nThe authors present an interactive demonstration to showcase the effectiveness of the Logic-Scaffolding framework in generating explanation for movie recommendations."
  },
  {
    "objectID": "posts/Logic-Scaffolding:_Personalized_Aspect-Instructed_Recommendation_Explanation_Generation_using_LLMs/2023-12-22-Logic-Scaffolding:_Personalized_Aspect-Instructed_Recommendation_Explanation_Generation_using_LLMs.html#appendix",
    "href": "posts/Logic-Scaffolding:_Personalized_Aspect-Instructed_Recommendation_Explanation_Generation_using_LLMs/2023-12-22-Logic-Scaffolding:_Personalized_Aspect-Instructed_Recommendation_Explanation_Generation_using_LLMs.html#appendix",
    "title": "Logic-Scaffolding: Personalized Aspect-Instructed Recommendation Explanation Generation using LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nLink\nhttps://browse.arxiv.org/html/2312.14345v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1744"
  },
  {
    "objectID": "posts/Mitigating_Data_Injection_Attacks_on_Federated_Learning/2023-12-04-Mitigating_Data_Injection_Attacks_on_Federated_Learning.html",
    "href": "posts/Mitigating_Data_Injection_Attacks_on_Federated_Learning/2023-12-04-Mitigating_Data_Injection_Attacks_on_Federated_Learning.html",
    "title": "Mitigating Data Injection Attacks on Federated Learning",
    "section": "",
    "text": "Federated Learning and Its Vulnerabilities: The paper highlights the concept of federated learning, where multiple entities collaboratively train models using their private data. It emphasizes that despite its advantages, federated learning is susceptible to data injection attacks, which can compromise the learning process and lead to a suboptimal model.\nDetection and Mitigation Technique: The paper proposes a novel local scheme for detecting and mitigating data injection attacks in federated learning systems. The technique involves comparing updates from participating agents and ignoring updates from suspicious agents. A threshold-based mechanism is employed for attacker localization and subsequent mitigation.\nSimulation Results: The paper presents simulation results showcasing the effectiveness of the proposed technique in detecting and mitigating data injection attacks. It demonstrates mitigating attacks such as constant-output attacks and label-flipping attacks, highlighting the ability of the algorithm to maintain convergence of the model to a truthful model."
  },
  {
    "objectID": "posts/Mitigating_Data_Injection_Attacks_on_Federated_Learning/2023-12-04-Mitigating_Data_Injection_Attacks_on_Federated_Learning.html#appendix",
    "href": "posts/Mitigating_Data_Injection_Attacks_on_Federated_Learning/2023-12-04-Mitigating_Data_Injection_Attacks_on_Federated_Learning.html#appendix",
    "title": "Mitigating Data Injection Attacks on Federated Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nLink\nhttps://browse.arxiv.org/html/2312.02102v2\n\n\nTruncated\nFalse\n\n\nWord Count\n3631"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Bayesian beagle",
    "section": "",
    "text": "I‚Äôm a Bayesian beagle who has curated reading though LLM generation."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ryan‚Äôs LLM Blog ü§ñ",
    "section": "",
    "text": "RecRanker: Instruction Tuning Large Language Model as Ranker for Top-k Recommendation\n\n\n\nprompt engineering\n\n\n\nLarge language models (LLMs) are being used for recommender systems, but current research overlooks integrating multiple ranking tasks. RecRanker aims to enhance LLM‚Ä¶\n\n\n\ngpt-3.5-turbo-1106\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Persuasive Power of Large Language Models\n\n\n\nhci\n\n\n\nLarge Language Models can generate effective arguments and interact with each other in opinion dynamics, suggesting potential impact on online discourse.\n\n\n\ngpt-3.5-turbo-1106\n\n\nDec 24, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogic-Scaffolding: Personalized Aspect-Instructed Recommendation Explanation Generation using LLMs\n\n\n\nhci\n\n\nprompt engineering\n\n\n\nLarge Language Models are great at text generation but struggle with explanations. Logic-Scaffolding offers a solution using intermediate reasoning steps.\n\n\n\ngpt-3.5-turbo-1106\n\n\nDec 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nContext-aware Decoding Reduces Hallucination in Query-focused Summarization\n\n\n\nrobustness\n\n\n\nQuery-focused summarization explores methods like Context-aware Decoding to improve summarization quality without generating false information.\n\n\n\ngpt-3.5-turbo-1106\n\n\nDec 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAndroid dialogue system for customer service using prompt-based topic control and compliments generation\n\n\n\nhci\n\n\nprompt engineering\n\n\n\nA dialogue system using ChatGPT-API to plan trips and give compliments, effectively evaluated in a preliminary round.\n\n\n\ngpt-3.5-turbo-1106\n\n\nDec 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBypassing the Safety Training of Open-Source LLMs with Priming Attacks\n\n\n\nsecurity\n\n\nopen-source\n\n\n\nLLMs need safety training due to vulnerability to priming attacks bypassing safety measures, with an improved attack success rate.\n\n\n\ngpt-3.5-turbo-1106\n\n\nDec 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGuardRails: Automated Suggestions for Clarifying Ambiguous Purpose Statements\n\n\n\nprompt engineering\n\n\nprogramming\n\n\n\nProgrammers should clarify function purposes using a heuristic, comparing it with GitHub Copilot‚Äôs Chat, and providing an open-source implementation.\n\n\n\ngpt-3.5-turbo-1106\n\n\nDec 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrompting LLMs with content plans to enhance the summarization of scientific articles\n\n\n\nprompt engineering\n\n\n\nNovel prompting techniques improve scientific article summarization, providing key terms to guide summarization systems for better performance.\n\n\n\ngpt-3.5-turbo-1106\n\n\nDec 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models are Clinical Reasoners: Reasoning-Aware Diagnosis Framework with Prompt-Generated Rationales\n\n\n\nprompt engineering\n\n\n\nNLP-driven clinical reasoning framework improves disease diagnosis through efficient rationale generation and evaluation, benefiting future research.\n\n\n\ngpt-3.5-turbo-1106\n\n\nDec 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM Interactive Optimization of Open Source Python Libraries ‚Äì Case Studies and Generalization\n\n\n\nhci\n\n\nprogramming\n\n\n\nGPT-4 can optimize code efficiency, but human input is essential and more study is needed.\n\n\n\ngpt-3.5-turbo-1106\n\n\nDec 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMitigating Data Injection Attacks on Federated Learning\n\n\n\nsecurity\n\n\n\nTL;DR: Proposed technique detects and mitigates false data injection attacks in federated learning systems to ensure model accuracy.\n\n\n\ngpt-3.5-turbo-1106\n\n\nDec 4, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/The_Persuasive_Power_of_Large_Language_Models/2023-12-24-The_Persuasive_Power_of_Large_Language_Models.html",
    "href": "posts/The_Persuasive_Power_of_Large_Language_Models/2023-12-24-The_Persuasive_Power_of_Large_Language_Models.html",
    "title": "The Persuasive Power of Large Language Models",
    "section": "",
    "text": "Takeaways - Large Language Models (LLMs) are increasingly capable of emulating social agents and engaging in complex interactions, raising concerns about potential implications for online discourse. - In a study on climate change persuasion, LLMs demonstrated the ability to generate effective arguments, incorporating dimensions of social pragmatics that influence opinion change. - While arguments that conveyed knowledge, trust, status, and support were perceived as most effective by both LLM agents and human judges, humans showed a disproportionate preference for knowledge-based arguments."
  },
  {
    "objectID": "posts/The_Persuasive_Power_of_Large_Language_Models/2023-12-24-The_Persuasive_Power_of_Large_Language_Models.html#appendix",
    "href": "posts/The_Persuasive_Power_of_Large_Language_Models/2023-12-24-The_Persuasive_Power_of_Large_Language_Models.html#appendix",
    "title": "The Persuasive Power of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nLink\nhttps://browse.arxiv.org/html/2312.15523v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5448"
  },
  {
    "objectID": "posts/Large_Language_Models_are_Clinical_Reasoners:_Reasoning-Aware_Diagnosis_Framework_with_Prompt-Generated_Rationales/2023-12-12-Large_Language_Models_are_Clinical_Reasoners:_Reasoning-Aware_Diagnosis_Framework_with_Prompt-Generated_Rationales.html",
    "href": "posts/Large_Language_Models_are_Clinical_Reasoners:_Reasoning-Aware_Diagnosis_Framework_with_Prompt-Generated_Rationales/2023-12-12-Large_Language_Models_are_Clinical_Reasoners:_Reasoning-Aware_Diagnosis_Framework_with_Prompt-Generated_Rationales.html",
    "title": "Large Language Models are Clinical Reasoners: Reasoning-Aware Diagnosis Framework with Prompt-Generated Rationales",
    "section": "",
    "text": "The paper presents a ‚Äúreasoning-aware‚Äù diagnosis framework using large language models (LLMs) to rationalize the diagnostic process via prompt-based learning in a time- and labor-efficient manner.\nIt addresses the clinical reasoning for disease diagnosis, demonstrating LLMs‚Äô ability of clinical reasoning through extensive experiments and analyses on both rationale generation and disease diagnosis in various settings.\nThe framework involves clinical rationalization, few-shot reasoning and diagnosis with LLMs, and knowledge distillation towards smaller models."
  },
  {
    "objectID": "posts/Large_Language_Models_are_Clinical_Reasoners:_Reasoning-Aware_Diagnosis_Framework_with_Prompt-Generated_Rationales/2023-12-12-Large_Language_Models_are_Clinical_Reasoners:_Reasoning-Aware_Diagnosis_Framework_with_Prompt-Generated_Rationales.html#appendix-1",
    "href": "posts/Large_Language_Models_are_Clinical_Reasoners:_Reasoning-Aware_Diagnosis_Framework_with_Prompt-Generated_Rationales/2023-12-12-Large_Language_Models_are_Clinical_Reasoners:_Reasoning-Aware_Diagnosis_Framework_with_Prompt-Generated_Rationales.html#appendix-1",
    "title": "Large Language Models are Clinical Reasoners: Reasoning-Aware Diagnosis Framework with Prompt-Generated Rationales",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nLink\nhttps://browse.arxiv.org/html/2312.07399v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5596"
  },
  {
    "objectID": "posts/LLM_Interactive_Optimization_of_Open_Source_Python_Libraries_--_Case_Studies_and_Generalization/2023-12-08-LLM_Interactive_Optimization_of_Open_Source_Python_Libraries_--_Case_Studies_and_Generalization.html",
    "href": "posts/LLM_Interactive_Optimization_of_Open_Source_Python_Libraries_--_Case_Studies_and_Generalization/2023-12-08-LLM_Interactive_Optimization_of_Open_Source_Python_Libraries_--_Case_Studies_and_Generalization.html",
    "title": "LLM Interactive Optimization of Open Source Python Libraries ‚Äì Case Studies and Generalization",
    "section": "",
    "text": "LLMs for Code Optimization: The study showcases the efficacy of Large Language Models (LLMs) in optimizing open-source Python libraries by collaborating with human experts. The results demonstrate substantial performance improvements across multiple case studies.\nHuman Expert in the Loop: The paper highlights the essential role of human expertise in guiding LLMs to achieve effective solutions, often with fewer iterations than anticipated. The interactive collaboration of human and LLMs leads to significant performance improvements in the optimized code.\nPromising Tool for Code Optimization: The findings indicate a strong potential for the practical utility of LLMs in code optimization in open-source libraries, emphasizing their collaborative dynamics with human experts."
  },
  {
    "objectID": "posts/LLM_Interactive_Optimization_of_Open_Source_Python_Libraries_--_Case_Studies_and_Generalization/2023-12-08-LLM_Interactive_Optimization_of_Open_Source_Python_Libraries_--_Case_Studies_and_Generalization.html#appendix",
    "href": "posts/LLM_Interactive_Optimization_of_Open_Source_Python_Libraries_--_Case_Studies_and_Generalization/2023-12-08-LLM_Interactive_Optimization_of_Open_Source_Python_Libraries_--_Case_Studies_and_Generalization.html#appendix",
    "title": "LLM Interactive Optimization of Open Source Python Libraries ‚Äì Case Studies and Generalization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nLink\nhttps://browse.arxiv.org/html/2312.14949v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10353"
  },
  {
    "objectID": "posts/Bypassing_the_Safety_Training_of_Open-Source_LLMs_with_Priming_Attacks/2023-12-19-Bypassing_the_Safety_Training_of_Open-Source_LLMs_with_Priming_Attacks.html",
    "href": "posts/Bypassing_the_Safety_Training_of_Open-Source_LLMs_with_Priming_Attacks/2023-12-19-Bypassing_the_Safety_Training_of_Open-Source_LLMs_with_Priming_Attacks.html",
    "title": "Bypassing the Safety Training of Open-Source LLMs with Priming Attacks",
    "section": "",
    "text": "Priming attacks are shown to be effective in bypassing safety training for open-source Large Language Models (LLMs), resulting in a significant increase in the Attack Success Rate on Harmful Behaviors.\nThe study highlights the ease with which adversaries can coerce open-source LLMs to comply with harmful requests, undermining the efficacy of safety measures in current LLMs, and raising pivotal concerns for the future of open-sourcing LLMs.\nThe research contributes to demonstrating the fragility of existing safety measures for LLMs and emphasizes the need for further exploration of novel methods for safer open-sourcing."
  },
  {
    "objectID": "posts/Bypassing_the_Safety_Training_of_Open-Source_LLMs_with_Priming_Attacks/2023-12-19-Bypassing_the_Safety_Training_of_Open-Source_LLMs_with_Priming_Attacks.html#appendix",
    "href": "posts/Bypassing_the_Safety_Training_of_Open-Source_LLMs_with_Priming_Attacks/2023-12-19-Bypassing_the_Safety_Training_of_Open-Source_LLMs_with_Priming_Attacks.html#appendix",
    "title": "Bypassing the Safety Training of Open-Source LLMs with Priming Attacks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nLink\nhttps://browse.arxiv.org/html/2312.12321v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2072"
  },
  {
    "objectID": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html",
    "href": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html",
    "title": "Prompting LLMs with content plans to enhance the summarization of scientific articles",
    "section": "",
    "text": "Scientific Summarization Challenge: Summarizing scientific articles presents unique challenges, given their length, complexity, and irregular organizational structures, making it a remarkably challenging domain within automatic text summarization.\nProposed Prompting Techniques: The study proposes novel prompting techniques to provide contextual information to aid scientific summarization systems, yielding consistent performance gains, especially for smaller models summarizing sections separately.\nImplications and Future Directions: The study suggests that smaller summarization models benefit from prompts and provides opportunities for further research in exploring different prompt generation techniques and attention mechanisms.\n\n\n\n\n\nAutomatic text summarization aims to produce shortened versions of documents while retaining relevant information.\nScientific article summarization is especially challenging due to their length, complexity, and irregular organizational structures.\n\n\n\n\n\nPrior work heavily relied on extractive methods but has shifted towards abstractive methods using neural network architectures, motivating the study‚Äôs focus on enhancing abstractive scientific summarizers based on transformer models.\n\n\n\n\n\nPrompting Technique Dimension: The study compares approaches for generating prompts, providing lists of salient terms through unsupervised extraction from input texts and evaluates five distinct prompting techniques.\nModel Dimension: The study integrates prompting techniques with a range of current state-of-the-art transformer models for scientific summarization.\nInput Text Dimension: The study explores different text input conditions for summarization, including I+D (concatenation of introduction and discussion texts), S-n/a (summarizing sections separately), and S-w/a (similar to S-n/a, with added section type identifiers).\n\n\n\n\n\nConsistent ROUGE improvements were observed in smaller models, especially when summarizing sections independently, suggesting that supplied terms offer valuable global context.\nSmaller models showed significant declines in quality when exposed to unrelated prompts in confusion testing, indicating active utilization of supplied informative terms.\nNo single prompting technique consistently outperformed across all settings, suggesting that the optimal selection depends on specific architectures and tasks.\n\n\n\n\n\nThe findings indicate that focused local contexts derive the greatest benefit from global information provided through prompts.\nThe ETC attention mechanism shows advancements compared to sliding window attention, highlighting the importance of adopting an attention architecture that ensures continuous access to the instruction throughout the summarization process.\n\n\n\n\n\nOpportunities for future research include exploring additional prompting techniques, investigating automatic entity prompt generation, and adapting global attention to directly focus on prompt token positions to enhance prompt utilization.\n\n\n\n\n\nThe study introduces prompting as a technique to enhance scientific summarization systems and demonstrates particular utility for improving fundamental deficiencies of smaller models in appropriate contexts, providing implications for resource-limited applications."
  },
  {
    "objectID": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#summary",
    "href": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#summary",
    "title": "Prompting LLMs with content plans to enhance the summarization of scientific articles",
    "section": "",
    "text": "Scientific Summarization Challenge: Summarizing scientific articles presents unique challenges, given their length, complexity, and irregular organizational structures, making it a remarkably challenging domain within automatic text summarization.\nProposed Prompting Techniques: The study proposes novel prompting techniques to provide contextual information to aid scientific summarization systems, yielding consistent performance gains, especially for smaller models summarizing sections separately.\nImplications and Future Directions: The study suggests that smaller summarization models benefit from prompts and provides opportunities for further research in exploring different prompt generation techniques and attention mechanisms.\n\n\n\n\n\nAutomatic text summarization aims to produce shortened versions of documents while retaining relevant information.\nScientific article summarization is especially challenging due to their length, complexity, and irregular organizational structures.\n\n\n\n\n\nPrior work heavily relied on extractive methods but has shifted towards abstractive methods using neural network architectures, motivating the study‚Äôs focus on enhancing abstractive scientific summarizers based on transformer models.\n\n\n\n\n\nPrompting Technique Dimension: The study compares approaches for generating prompts, providing lists of salient terms through unsupervised extraction from input texts and evaluates five distinct prompting techniques.\nModel Dimension: The study integrates prompting techniques with a range of current state-of-the-art transformer models for scientific summarization.\nInput Text Dimension: The study explores different text input conditions for summarization, including I+D (concatenation of introduction and discussion texts), S-n/a (summarizing sections separately), and S-w/a (similar to S-n/a, with added section type identifiers).\n\n\n\n\n\nConsistent ROUGE improvements were observed in smaller models, especially when summarizing sections independently, suggesting that supplied terms offer valuable global context.\nSmaller models showed significant declines in quality when exposed to unrelated prompts in confusion testing, indicating active utilization of supplied informative terms.\nNo single prompting technique consistently outperformed across all settings, suggesting that the optimal selection depends on specific architectures and tasks.\n\n\n\n\n\nThe findings indicate that focused local contexts derive the greatest benefit from global information provided through prompts.\nThe ETC attention mechanism shows advancements compared to sliding window attention, highlighting the importance of adopting an attention architecture that ensures continuous access to the instruction throughout the summarization process.\n\n\n\n\n\nOpportunities for future research include exploring additional prompting techniques, investigating automatic entity prompt generation, and adapting global attention to directly focus on prompt token positions to enhance prompt utilization.\n\n\n\n\n\nThe study introduces prompting as a technique to enhance scientific summarization systems and demonstrates particular utility for improving fundamental deficiencies of smaller models in appropriate contexts, providing implications for resource-limited applications."
  },
  {
    "objectID": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#appendix",
    "href": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#appendix",
    "title": "Prompting LLMs with content plans to enhance the summarization of scientific articles",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nLink\nhttps://browse.arxiv.org/html/2312.08282v2\n\n\nTruncated\nFalse\n\n\nWord Count\n4878"
  }
]