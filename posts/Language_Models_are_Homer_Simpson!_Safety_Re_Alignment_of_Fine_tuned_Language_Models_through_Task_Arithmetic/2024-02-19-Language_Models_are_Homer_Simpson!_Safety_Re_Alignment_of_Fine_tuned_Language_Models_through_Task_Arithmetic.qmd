
---
title: "Language Models are Homer Simpson! Safety Re-Alignment of Fine-tuned Language Models through Task Arithmetic"
id: "2402.11746v1"
description: "RESTA method improves safety of language models through simple arithmetic addition."
author: Rishabh Bhardwaj, Do Duc Anh, Soujanya Poria
date: "2024-02-19"
image: "../../img/2402.11746v1/image_1.png"
categories: ['robustness', 'security']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.11746v1/image_1.png)

### Summary:
- The article proposes a method called RESTA to realign language models for safety after fine-tuning.
- RESTA involves adding a safety vector to the weights of the compromised model to restore safety.
- The authors demonstrate the effectiveness of RESTA in reducing harmfulness while maintaining most of the model's performance on the task.

### Major Findings:
1. RESTA significantly reduces the harmfulness of the compromised model from 18.6% to 5.1% in parameter-efficient fine-tuning and from 9.2% to 1.5% in full fine-tuning.
2. The safety vector obtained from unalignment is effective in reducing unsafety scores across different evaluation benchmarks.
3. RESTA is observed to be effective in reducing unsafety scores across different languages, as shown in the multilingual safety evaluation benchmarks.

### Analysis and Critique:
- The article provides a comprehensive and effective method for realigning language models for safety after fine-tuning.
- The study demonstrates the generalizability of the safety vectors and their effectiveness in reducing unsafety scores across different languages and evaluation benchmarks.
- The article could benefit from further investigation into the impact of RESTA on larger models and the transferability of safety vectors across different language models. Additionally, a more extensive evaluation of hyperparameters could provide valuable insights.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.11746v1](https://arxiv.org/abs/2402.11746v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.11746v1](https://browse.arxiv.org/html/2402.11746v1)       |
| Truncated       | False       |
| Word Count       | 13973       |