
---
title: "CodeS: Towards Building Open-source Language Models for Text-to-SQL"
id: "2402.16347v1"
description: "CodeS: Open-source language model for text-to-SQL, outperforms SOTA with smaller parameters."
author: Haoyang Li, Jing Zhang, Hanbing Liu, Ju Fan, Xiaokang Zhang, Jun Zhu, Renjie Wei, Hongyan Pan, Cuiping Li, Hong Chen
date: "2024-02-26"
image: "https://browse.arxiv.org/html/2402.16347v1/x1.png"
categories: ['programming', 'architectures']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.16347v1/x1.png)

### **Summary:**
The article introduces CodeS, a series of pre-trained language models designed for the text-to-SQL task. The models are incrementally pre-trained using a specially curated SQL-focused dataset and are evaluated on various text-to-SQL benchmarks. The study also proposes a comprehensive database prompt construction strategy and a novel bi-directional data augmentation method to enhance the adaptability of the models to new domains.

### **Major Findings:**
1. **Incremental Pre-Training:** The incremental pre-training of CodeS significantly improves its SQL generation capability, with smaller models showing more pronounced improvements.
2. **Supervised Fine-Tuning:** SFT CodeS-7B and SFT CodeS-15B achieve new SOTA accuracy and robustness on Spider and BIRD benchmarks, outperforming previous state-of-the-art methods.
3. **Robustness and Real-World Scenarios:** SFT CodeS-7B and SFT CodeS-15B exhibit exceptional performance on robustness benchmarks and real-world domain datasets, showcasing their generalization and adaptability.

### **Analysis and Critique:**
- The study provides valuable insights into the development and evaluation of pre-trained language models for text-to-SQL applications.
- The proposed strategies for database prompt construction and data augmentation demonstrate the model's adaptability to new domains and real-world scenarios.
- The study's comprehensive evaluations on various benchmarks highlight the effectiveness and efficiency of CodeS in SQL generation tasks.

Overall, the article presents a significant advancement in the field of text-to-SQL and offers valuable contributions to the research community. However, further research and real-world deployment of the models are necessary to fully assess their practical utility and impact. Additionally, the study could benefit from a more detailed discussion of potential limitations and future research directions.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.16347v1](https://arxiv.org/abs/2402.16347v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.16347v1](https://browse.arxiv.org/html/2402.16347v1)       |
| Truncated       | False       |
| Word Count       | 14375       |