
---
title: "MedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English Clinical Queries"
id: "2401.01596v1"
description: "Creating summaries of medical questions from patients is important for improving doctor-patient interactions. Current research overlooks visual cues and multilingual input, but this work introduces a dataset and framework for multimodal medical question summarization."
author: ['Akash Ghosh', 'Arkadeep Acharya', 'Prince Jha', 'Aniket Gaudgaul', 'Rajdeep Majumdar', 'Sriparna Saha', 'Aman Chadha', 'Raghav Jain', 'Setu Sinha', 'Shivani Agarwal']
date: "2024-01-03"
image: "https://browse.arxiv.org/html/2401.01596v1/x1.png"
categories: ['social-sciences', 'hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.01596v1/x1.png)

### Major Takeaways

1. The paper addresses the task of **multimodal medical question summarization** for codemixed input in a low-resource setting. It introduces the **Multimodal Medical Codemixed Question Summarization (MMCQS) dataset**, combining Hindi-English codemixed medical queries with visual aids to enrich the representation of a patientâ€™s medical condition.

2. The proposed **MedSumm framework** leverages both Large Language Models (LLMs) and Vision Language Models (VLMs) to integrate visual information from images, demonstrating the value of integrating visual information to improve the creation of medical summaries, with the potential to increase access to quality healthcare and promote health equity.

3. The paper introduces a **novel metric MMFCM** to quantify how well the model captures the multimodal information in the generated summary.

### Qualitative Analysis

- The study suggests that all models perform better in a multimodal setting, capturing important visual information conveyed through the images and predicting the exact disorder phrase. However, some models demonstrate a tendency of hallucination and generation of facts out of context.

### Critique and Potential Problems

- The paper acknowledges limitations such as confining the task to a limited set of symptoms conducive to image sharing, which may lead to potentially erroneous information in the summary when introducing an image outside this scope. It is prudent to engage a medical expert for ultimate verification, particularly in high-stakes scenarios.

- While the multimodal model shows promise, it is necessary to consider its role as a tool, not a substitute for medical professionals, particularly in scenarios involving high-stakes medical decisions.

- The paper's reliance on automatic evaluation metrics such as ROUGE, BLEU, and BERT score may not fully capture the nuanced quality of summaries in the medical domain, suggesting the need for human evaluation and verification by medical professionals to ensure accuracy and relevance.

Overall, the paper's focus on multimodal medical question summarization and the introduction of the MMCQS dataset and MedSumm framework offer valuable contributions to the field, but it is important to consider potential limitations and the need for further validation and ethical considerations in real-world medical applications.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-26       |
| Abstract | [http://arxiv.org/abs/2401.01596v1](http://arxiv.org/abs/2401.01596v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.01596v1](https://browse.arxiv.org/html/2401.01596v1)       |
| Truncated       | False       |
| Word Count       | 6480       |