
---
title: "Exploring Mathematical Extrapolation of Large Language Models with Synthetic Data"
id: "2406.02100v1"
description: "LLMs excel in various tasks but struggle with multi-step reasoning. Fine-tuning on synthetic data improves performance in complex arithmetic puzzles."
author: Haolong Li, Yu Ma, Yinqi Zhang, Chen Ye, Jie Chen
date: "2024-06-04"
image: "https://browse.arxiv.org/html/2406.02100v1/extracted/5642379/dn.png"
categories: ['programming']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.02100v1/extracted/5642379/dn.png)

### Summary:

- The paper explores the performance of Large Language Models (LLMs) in complex multi-step reasoning tasks, specifically mathematical reasoning.
- The authors propose a new arithmetical puzzle problem and demonstrate that LLMs can perform well on multi-step reasoning tasks when fine-tuned on high-quality synthetic data.
- The study uses the open-llama-3B model and shows that it can reach a zero-shot pass@1 of 0.44 on the in-domain dataset and demonstrates generalization capabilities on out-of-domain datasets.
- The authors design two out-of-domain datasets by extending the numerical range and the composing components of the arithmetical puzzle problem separately.
- The fine-tuned models show encouraging performance on these two more difficult tasks with a zero-shot pass@1 of 0.33 and 0.35, respectively.

### Major Findings:

1. LLMs can perform well on multi-step reasoning tasks when fine-tuned on high-quality synthetic data.
2. The open-llama-3B model can reach a zero-shot pass@1 of 0.44 on the in-domain dataset and demonstrates generalization capabilities on out-of-domain datasets.
3. The fine-tuned models show encouraging performance on two more difficult tasks with a zero-shot pass@1 of 0.33 and 0.35, respectively.

### Analysis and Critique:

- The study provides a novel approach to improving the performance of LLMs in complex multi-step reasoning tasks.
- The use of high-quality synthetic data for fine-tuning is a promising approach to improving the performance of LLMs in mathematical reasoning tasks.
- The study could be improved by exploring the performance of other LLMs on the proposed arithmetical puzzle problem.
- The study could also be improved by exploring the performance of LLMs on other complex multi-step reasoning tasks.
- The study could be further improved by exploring the impact of different types of synthetic data on the performance of LLMs in mathematical reasoning tasks.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-23       |
| Abstract | [https://arxiv.org/abs/2406.02100v1](https://arxiv.org/abs/2406.02100v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.02100v1](https://browse.arxiv.org/html/2406.02100v1)       |
| Truncated       | False       |
| Word Count       | 3993       |