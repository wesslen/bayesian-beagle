
---
title: "Solving Data-centric Tasks using Large Language Models"
id: "2402.11734v1"
description: "LLMs replacing help forums for non-professional programmers, cluster-then-select technique improves performance."
author: Shraddha Barke, Christian Poelitz, Carina Suzana Negreanu, Benjamin Zorn, Jos√© Cambronero, Andrew D. Gordon, Vu Le, Elnaz Nouri, Nadia Polikarpova, Advait Sarkar, Brian Slininger, Neil Toronto, Jack Williams
date: "2024-02-18"
image: "https://browse.arxiv.org/html/2402.11734v1/x1.png"
categories: ['prompt-engineering', 'programming']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.11734v1/x1.png)

### **Summary:**
- Large language models (LLMs) are being used to solve data-centric tasks, such as spreadsheet manipulation and data wrangling, by providing natural-language descriptions and input data to the model.
- The paper introduces a dataset of real-world NL-to-code tasks manipulating tabular data, mined from StackOverflow posts, and proposes a cluster-then-select prompting technique to add representative rows from the input data to the LLM prompt.
- Experiments show that LLM performance is sensitive to the amount of data passed in the prompt, and the cluster-then-select technique outperforms a random selection baseline for tasks with a lot of syntactic variation in the input table.

### **Major Findings:**
1. LLM performance is sensitive to the amount of data passed in the prompt.
2. The cluster-then-select prompting technique outperforms a random selection baseline for tasks with a lot of syntactic variation in the input table.
3. The dataset of real-world NL-to-code tasks for data-centric code generation is a valuable contribution to the research community.

### **Analysis and Critique:**
- The paper provides valuable insights into the use of LLMs for data-centric tasks and proposes a novel prompting technique. However, the limitations and potential biases of the dataset and models used for evaluation are not thoroughly addressed.
- The ethical considerations related to the use of language models for code generation and the potential impact on decision-making processes are briefly mentioned, but a more in-depth analysis of these ethical implications would enhance the paper's contribution.

Overall, the paper presents important findings regarding the use of LLMs for data-centric tasks and provides a valuable dataset for further research. However, a more comprehensive analysis of the limitations and ethical implications would strengthen the paper's impact.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.11734v1](https://arxiv.org/abs/2402.11734v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.11734v1](https://browse.arxiv.org/html/2402.11734v1)       |
| Truncated       | False       |
| Word Count       | 8522       |