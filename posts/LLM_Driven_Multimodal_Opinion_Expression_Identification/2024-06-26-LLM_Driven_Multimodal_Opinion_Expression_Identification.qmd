
---
title: "LLM-Driven Multimodal Opinion Expression Identification"
id: "2406.18088v1"
description: "This study enhances Opinion Expression Identification (OEI) with multimodal inputs, improving performance and achieving state-of-the-art results."
author: Bonian Jia, Huiyao Chen, Yueheng Sun, Meishan Zhang, Min Zhang
date: "2024-06-26"
image: "https://browse.arxiv.org/html/2406.18088v1/extracted/5690751/figures/intro.png"
categories: ['social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.18088v1/extracted/5690751/figures/intro.png)

### Summary:

The study introduces a novel multimodal Opinion Expression Identification (MOEI) task, integrating text and speech to mirror real-world scenarios. The authors utilize CMU MOSEI and IEMOCAP datasets to construct the CI-MOEI dataset and apply Text-to-Speech (TTS) technology to the MPQA dataset to obtain the CIM-OEI dataset. They propose an LLM-driven method STOEI, which combines speech and text modal to identify opinion expressions. The experiments demonstrate that MOEI significantly improves the performance while their method outperforms existing methods by 9.20% and obtains SOTA results.

### Major Findings:

1. The study introduces a novel multimodal Opinion Expression Identification (MOEI) task, which integrates text and speech to reflect real-world communication nuances.
2. The authors utilize open-source datasets CMU MOSEI and IEMOCAP to create the CI-MOEI dataset, addressing the alignment challenges between speech and text.
3. The study applies Text-to-Speech technology on the MPQA dataset to form CIM-OEI, assessing the effectiveness of multimodal data as training material.
4. The authors propose an LLM-driven approach that combines speech and text modalities to help identify opinion expressions, achieving state-of-the-art (SOTA) results.
5. The experiments demonstrate significant improvements in MOEI performance with this integrated approach, surpassing existing techniques by 9.20%.

### Analysis and Critique:

The study presents a novel approach to Opinion Expression Identification (OEI) by integrating text and speech modalities. The authors' use of open-source datasets and TTS technology to create the CI-MOEI and CIM-OEI datasets is commendable. The proposed LLM-driven method STOEI demonstrates significant improvements in MOEI performance, achieving SOTA results.

However, the study has some limitations. First, the experiments are only conducted on English datasets, limiting the generalizability of the findings to other languages. Second, the study compares a limited number of methods, which may

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-07       |
| Abstract | [https://arxiv.org/abs/2406.18088v1](https://arxiv.org/abs/2406.18088v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.18088v1](https://browse.arxiv.org/html/2406.18088v1)       |
| Truncated       | False       |
| Word Count       | 4217       |