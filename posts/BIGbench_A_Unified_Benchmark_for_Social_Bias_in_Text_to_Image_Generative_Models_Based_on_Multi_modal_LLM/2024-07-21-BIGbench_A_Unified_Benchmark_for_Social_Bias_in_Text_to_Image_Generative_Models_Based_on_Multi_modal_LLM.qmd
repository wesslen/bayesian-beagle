
---
title: "BIGbench: A Unified Benchmark for Social Bias in Text-to-Image Generative Models Based on Multi-modal LLM"
id: "2407.15240v1"
description: "BIGbench: A Unified Benchmark for Biases in Image Generation, Evaluating Four Dimensions of Bias in T2I Models."
author: Hanjun Luo, Haoyu Huang, Ziye Deng, Xuecheng Liu, Ruizhe Chen, Zuozhu Liu
date: "2024-07-21"
image: "https://browse.arxiv.org/html/2407.15240v1/extracted/5745844/image/prompt_portion.png"
categories: ['hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2407.15240v1/extracted/5745844/image/prompt_portion.png)

### Summary:

The paper introduces BIGbench, a unified benchmark for Biases of Image Generation, which aims to address the limitations of existing benchmarks in classifying and evaluating complex biases in Text-to-Image (T2I) generative models. BIGbench classifies biases into four dimensions: manifestation of bias, visibility of bias, acquired attributes, and protected attributes. The benchmark employs a fully automated evaluation process using a fine-tuned multi-modal large language model (MLLM) and a dataset of 47,040 prompts covering occupations, characteristics, and social relations. The paper evaluates eight recent general T2I models and three debiased methods using BIGbench and conducts human evaluations to prove its efficacy.

### Major Findings:

1. BIGbench establishes a specific 4-dimension bias definition system for T2I models and develops an MLLM for high-accuracy human feature alignment.
2. The benchmark introduces a unified bias evaluation for T2I models with a dataset based on the definition system, including 47,040 prompts.
3. The evaluation results cover implicit generative bias, explicit generative bias, ignorance, and discrimination, making BIGbench suitable for automated bias evaluation for any T2I model.
4. The study reveals new research directions about biases, including the side-effect of irrelevant protected attributes and distillation.

### Analysis and Critique:

1. The paper addresses the need for a unified bias benchmark for T2I models, which is crucial for intuitively comparing the biases of different models and the performance of debiasing methods.
2. The use of a fine-tuned MLLM for automated evaluation ensures high accuracy and consistency in the evaluation process.
3. The study reveals the limitations of existing benchmarks, such as limited prompts, a small number of models for comparison, and the evaluation of specific types of bias.
4. The paper highlights the importance of categorizing different biases and measuring them separately, as recent T2I models perform well in gender biases but have considerable race biases.
5. The study raises concerns about the side-effects of distillation on biases in T2

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-30       |
| Abstract | [https://arxiv.org/abs/2407.15240v1](https://arxiv.org/abs/2407.15240v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.15240v1](https://browse.arxiv.org/html/2407.15240v1)       |
| Truncated       | False       |
| Word Count       | 6160       |