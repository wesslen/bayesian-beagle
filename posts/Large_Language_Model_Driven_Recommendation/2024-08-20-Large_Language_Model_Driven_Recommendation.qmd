
---
title: "Large Language Model Driven Recommendation"
id: "2408.10946v1"
description: "LLMs enable personalized RSs via NL interactions, using item descriptions, user-system interactions, and profiles. Techniques include encoder-only and autoregressive LLM recommendation, multi-module architectures, and conversational recommender systems."
author: Anton Korikov, Scott Sanner, Yashar Deldjoo, Zhankui He, Julian McAuley, Arnau Ramisa, Rene Vidal, Mahesh Sathiamoorthy, Atoosa Kasrizadeh, Silvia Milano, Francesco Ricci
date: "2024-08-20"
image: "https://browse.arxiv.org/html/2408.10946v1/extracted/5803119/fig/ch4_text_data_types.png"
categories: ['recommender', 'hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.10946v1/extracted/5803119/fig/ch4_text_data_types.png)

**Summary:**

This chapter discusses the use of large language models (LLMs) in building highly personalized recommendation systems (RSs) that can effectively connect nuanced and diverse user preferences to items. The chapter presents a taxonomy of key data sources for language-driven recommendation, including item descriptions, user-system interactions, and user profiles. It then proceeds to fundamental techniques for LLM recommendation, reviewing the use of encoder-only and autoregressive LLM recommendation in both tuned and untuned settings. The chapter also covers multi-module recommendation architectures in which LLMs interact with components such as retrievers and RSs in multi-stage pipelines. Finally, the chapter discusses architectures for conversational recommender systems (CRSs), in which LLMs facilitate multi-turn dialogues where each turn presents an opportunity not only to make recommendations but also to engage with the user in interactive preference elicitation, critiquing, and question-answering.

**Major Findings:**

1. LLMs enable the use of natural language (NL) interactions for recommendation, unlocking the rich NL data sources within RSs such as item descriptions, reviews, and queries.
2. LLMs' abilities for general NL reasoning present novel opportunities to build highly personalized RSs that can accommodate diverse and nuanced user preferences through customized recommendations and interactions.
3. LLMs can be used in both encoder-only and autoregressive architectures for recommendation, with the latter also enabling the generation of explanations for recommendations.
4. LLMs can be integrated with other components such as retrievers and RSs in multi-stage pipelines to improve recommendation performance.
5. LLMs can facilitate multi-turn dialogues in CRSs, enabling interactive preference elicitation, critiquing, and question-answering.

**Analysis and Critique:**

While LLMs offer many opportunities for building highly personalized RSs, there are also potential limitations and challenges. For example, LLMs may hallucinate, generating outputs that are incorrect or misleading, which can create significant risks in settings where reliability is key. Additionally, our ability to control LLM behavior is limited, and prompt engineering and fine-tuning may not achieve total control. However, the chapter also discusses approaches to mitigate

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-27       |
| Abstract | [https://arxiv.org/abs/2408.10946v1](https://arxiv.org/abs/2408.10946v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.10946v1](https://browse.arxiv.org/html/2408.10946v1)       |
| Truncated       | False       |
| Word Count       | 8885       |