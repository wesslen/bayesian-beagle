
---
title: "What You Need is What You Get: Theory of Mind for an LLM-Based Code Understanding Assistant"
id: "2408.04477v1"
description: "TL;DR: Personalized LLM-based assistant aids novices in code understanding, tailored to user's mental state."
author: Jonan Richards, Mairieli Wessel
date: "2024-08-08"
image: "https://browse.arxiv.org/html/2408.04477v1/extracted/5781459/figures/client_screenshot_interaction_tagged.png"
categories: ['social-sciences', 'education', 'hci', 'programming', 'prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.04477v1/extracted/5781459/figures/client_screenshot_interaction_tagged.png)

### Summary:

- The study introduces ToMMY, an LLM-based conversational agent that provides personalized explanations about code by inferring and adapting to developers' needs, intents, knowledge, experience, and preferences.
- ToMMY is evaluated against a more basic agent in a within-subject study with 14 novices to capture their perceptions and preferences.
- The results reveal that novices exhibit distinct interaction styles based on whether they phrase some questions as hypotheses or not.
- Using ToMMY has distinct impacts on novices' code understanding depending on their interaction styles.

### Major Findings:

1. Novices who interacted with ToMMY less frequently stated their intent or asked follow-up questions and slightly more often provided instructions regarding the response format.
2. Using ToMMY had distinct impacts on novices' code understanding depending on their interaction styles.
3. No significant differences in TAM and TLX scores were found between the two approaches, but ToMMY reduced perceived effort compared to the control approach, although this effect greatly varied per participant.

### Analysis and Critique:

- The study's findings suggest that ToMMY was able to better recognize participants' intent and adapt responses to their background experience. However, ToMMY's responses often being formatted as a single paragraph may have introduced usability issues.
- The results imply that LLMs can personalize responses independently on some aspects, but may need guidance on others. This guidance could entail explicitly prompting the LLM for certain elements of mental state or providing explicit instructions.
- The study's limitations include the difficulty of prompt engineering and validation, the use of a sample composed of students, and the potential for categorization bias in the qualitative research methods used.
- More research is needed to understand how to structure ToMMY's content and to better adjust to users' needs, ensuring less cognitive load from users when interacting with the tool.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-13       |
| Abstract | [https://arxiv.org/abs/2408.04477v1](https://arxiv.org/abs/2408.04477v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.04477v1](https://browse.arxiv.org/html/2408.04477v1)       |
| Truncated       | False       |
| Word Count       | 4881       |