
---
title: "AI Gender Bias, Disparities, and Fairness: Does Training Data Matter?"
id: "2312.10833v1"
description: "Study examines gender biases in AI scoring of student responses. Mixed-trained models show no significant scoring bias but may widen gender disparities."
author: ['Ehsan Latif', 'Xiaoming Zhai', 'Lei Liu']
date: "2023-12-17"
image: "https://browse.arxiv.org/html/2312.10833v1/extracted/5301032/figures/BERT_MixModel_mean_std_plot.png"
categories: ['education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2312.10833v1/extracted/5301032/figures/BERT_MixModel_mean_std_plot.png)

# Summary: AI Gender Bias, Disparities, and Fairness in Training Data

## Major Findings
1. **Minimal Scoring Bias**: The study found that training AI models on gender-unbalanced data did not lead to significant scoring bias. Mixed-trained models showed no significant difference in scoring accuracy compared to gender-specifically trained models, suggesting minimal scoring bias.
2. **Reduced Disparities**: Mixed-trained models generated fewer mean score gaps and reduced gender disparities compared to gender-specifically trained models, indicating that unbalanced training data may create algorithmic models that enlarge gender disparities.
3. **Enhanced Fairness**: The Equalized Odds analysis suggests that mixed-trained models generated fairer outcomes compared with gender-specifically trained models, further highlighting the potential of balanced training data in addressing gender fairness.

## Methodology
- The study employed a comprehensive methodology, including data analysis using BERT and GPT-3.5, statistical techniques such as Scoring Accuracy Difference, Mean Score Gap, and Equalized Odds evaluation.

## Background
- AI in Education: The role of AI in education, implications, and ethical considerations.
- Automatic Scoring in Education: Advancements, challenges, and machine-human score agreements.
- AI Gender Bias, Disparities, and Fairness: The complexities and implications of gender biases in AI and the need for a multidisciplinary approach.

## Results
- Scoring Accuracy Difference Evaluation: Both BERT and GPT-3.5 models demonstrated consistent performance across mixed and gender-specific datasets, suggesting minimal gender biases.
- Mean Score Gap: Training with a mixed dataset in both BERT and GPT-3.5 models showed reduced MSG compared to gender-specific training, indicating reduced gender disparities and heightened fairness.
- Equalized Odds Evaluation: Mixed trained models for both BERT and GPT-3.5 showed lower EO values, suggesting more equitable predictions and higher fairness compared to gender-specific models.

## Critique
- Potential Problems: While the study demonstrates the potential of balanced training data in addressing gender fairness, it may benefit from a more extensive dataset and broader representation across academic disciplines to generalize the findings.

Overall, the study provides valuable insights into the impact of training data on gender biases in AI scoring systems and emphasizes the significance of inclusive and equitable AI practices in education.


## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-02       |
| Abstract | [http://arxiv.org/abs/2312.10833v1](http://arxiv.org/abs/2312.10833v1)        |
| HTML     | [https://browse.arxiv.org/html/2312.10833v1](https://browse.arxiv.org/html/2312.10833v1)       |
| Truncated       | False       |
| Word Count       | 9836       |