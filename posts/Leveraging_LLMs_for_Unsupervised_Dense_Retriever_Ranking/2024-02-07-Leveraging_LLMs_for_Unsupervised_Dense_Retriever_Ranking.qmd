
---
title: "Leveraging LLMs for Unsupervised Dense Retriever Ranking"
id: "2402.04853v1"
description: "Unsupervised method to select best dense retriever for a specific target corpus using large language models."
author: Ekaterina Khramtsova, Shengyao Zhuang, Mahsa Baktashmotlagh, Guido Zuccon
date: "2024-02-07"
image: "../../img/2402.04853v1/image_1.png"
categories: ['architectures']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.04853v1/image_1.png)

**Summary:**

- The paper introduces LARMOR, an unsupervised, query-free dense retriever selection method using Large Language Models (LLMs) to generate synthetic queries for a target corpus.
- LARMOR addresses the challenge of selecting an optimal pre-trained dense retriever for a specific target corpus, especially under domain shift scenarios where the target corpus differs from the original training set.
- The proposed method outperforms existing benchmarks in both dense retriever selection and ranking.

**Major Findings:**

1. LARMOR utilizes LLMs to create pseudo-relevant queries, labels, and reference lists by analyzing a subset of documents from the target corpus, allowing for the ranking of dense retrievers based on their performance with these pseudo-relevant signals.
2. This strategy is the first to depend exclusively on the target corpus data, removing the necessity for training data and test labels.
3. The paper demonstrates that LARMOR surpasses existing benchmarks in both the selection and ranking of dense retrievers.

**Analysis and Critique:**

- The paper focuses on the unsupervised selection of an optimally pre-trained dense retriever for a specific target corpus, particularly under conditions of domain shift. However, the paper could benefit from a more detailed discussion on the limitations of the proposed method, such as:
  - The potential impact of the quality and diversity of the documents in the target corpus on the performance of LARMOR.
  - The sensitivity of LARMOR to the choice of LLM and the specific prompt used for query generation.
  - The computational complexity of LARMOR compared to other methods, especially when dealing with large target corpora.
- The paper could also explore the application of LARMOR in other NLP tasks where dense retrievers are commonly used, such as question answering or text classification, to further demonstrate its generalizability.
- It would be interesting to see a comparison between LARMOR and other unsupervised or few-shot learning methods for dense retriever selection, to better understand the advantages and disadvantages of the proposed approach.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x7b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.04853v1](https://arxiv.org/abs/2402.04853v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.04853v1](https://browse.arxiv.org/html/2402.04853v1)       |
| Truncated       | False       |
| Word Count       | 21177       |