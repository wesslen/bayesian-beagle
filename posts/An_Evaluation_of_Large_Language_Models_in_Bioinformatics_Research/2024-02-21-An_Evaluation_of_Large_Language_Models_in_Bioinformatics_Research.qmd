
---
title: "An Evaluation of Large Language Models in Bioinformatics Research"
id: "2402.13714v1"
description: "LLMs like ChatGPT show potential in bioinformatics tasks, with some limitations. Motivates future research."
author: Hengchuang Yin, Zhonghui Gu, Fanhao Wang, Yiparemu Abuduhaibaier, Yanqiao Zhu, Xinming Tu, Xian-Sheng Hua, Xiao Luo, Yizhou Sun
date: "2024-02-21"
image: "https://browse.arxiv.org/html/2402.13714v1/x1.png"
categories: ['hci', 'architectures']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.13714v1/x1.png)

### **Summary:**
- Large language models (LLMs) such as ChatGPT have gained considerable interest across diverse research communities.
- In this work, the performance of LLMs on a wide spectrum of crucial bioinformatics tasks is studied.
- Findings indicate that, given appropriate prompts, LLMs like GPT variants can successfully handle most of these tasks.

### **Major Findings:**
1. LLMs like GPT variants can successfully handle most bioinformatics tasks with appropriate prompts.
2. The model has difficulties when faced with more complex tasks, such as generating non-existing gene name mentions for gene and protein named entity recognition.
3. Some prompts and model variants could lead to fluctuating performance, indicating the need for further investigation.

### **Analysis and Critique:**
- The GPT-4 model can successfully deliver the definitions of coding regions and open reading frames in DNA sequences.
- GPT-3.5 (Davinci-ft) outperforms the AMP-BERT model across a variety of metrics for identifying antimicrobial peptides.
- GPT-3.5 (Davinci-ft) achieves the best performance in terms of most matrices including MCC, AUC, and AUPRC for identifying anti-cancer peptides.
- GPT-4 can successfully generate valid SMILES in most cases for molecule optimization and has an advantage in improving synthetic accessibility and drug-likeness.
- GPT-3.5 and GPT-4 demonstrate an overall improvement compared to GPT-3.5 across various types of problems in educational bioinformatics problem solving.

- The GPT-3.5 model could miss gene mention entities in sentences and misunderstand the gene name, while GPT-4 achieves better performance than GPT-3.5 but still lower than other models for gene and protein named entity recognition.
- GPT-4 demonstrates an overall improvement compared to GPT-3.5 across various types of problems in educational bioinformatics problem solving.

- The performance of GPT-3.5 and GPT-4 is almost consistent across different topics, with GPT-4 demonstrating an overall improvement compared to GPT-3.5 across various types of problems in educational bioinformatics problem solving.
- GPT-3.5 exhibits excellent performance in handling relatively simple problems, while GPT-4 demonstrates a limited capacity in tackling complex problems in educational bioinformatics problem solving.

### **Limitations:**
- The authors cannot guarantee that the datasets used for evaluation are not included in the pretraining of the GPT models.
- Some of the models evaluated may become depreciated in the future, and the authors will need to update the results with more advanced models in the future.
- The study only evaluates six basic bioinformatics tasks, and a wide range of sub-regions in bioinformatics have not been considered.

Overall, the study provides valuable insights into the potential applications of LLMs in bioinformatics research and highlights the need for further investigation and development in this area.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-26       |
| Abstract | [https://arxiv.org/abs/2402.13714v1](https://arxiv.org/abs/2402.13714v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.13714v1](https://browse.arxiv.org/html/2402.13714v1)       |
| Truncated       | False       |
| Word Count       | 8713       |