
---
title: "Self and Cross-Model Distillation for LLMs: Effective Methods for Refusal Pattern Alignment"
id: "2406.11285v1"
description: "LLMs can be secured against toxic prompts via alignment techniques like SFT and RLHF. Distillation methods, especially cross-model, significantly improve refusal rates and reduce unsafe content."
author: Jie Li, Yi Liu, Chongyang Liu, Xiaoning Ren, Ling Shi, Weisong Sun, Yinxing Xue
date: "2024-06-17"
image: "https://browse.arxiv.org/html/2406.11285v1/x1.png"
categories: ['programming']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.11285v1/x1.png)

### Summary:

This paper investigates the security challenges posed by toxic prompts in Large Language Models (LLMs) and proposes effective methods to mitigate these risks. The authors conduct an empirical study to evaluate the refusal patterns of nine LLMs, highlighting the superior security of models with uniform refusal patterns, such as Claude3. Based on these insights, the authors introduce self-distilling and cross-model distilling techniques to enhance LLM security. The experimental results demonstrate significant improvements in refusal rates and a reduction in unsafe content, with cross-model distilling achieving refusal rates nearing Claude3’s 94.51%.

### Major Findings:

1. LLMs with uniform refusal patterns, such as Claude3, exhibit higher security.
2. Self-distilling and cross-model distilling techniques significantly improve refusal rates and reduce unsafe content.
3. Cross-model distilling achieves refusal rates close to Claude3’s 94.51%.

### Analysis and Critique:

The paper provides a comprehensive analysis of the security challenges posed by toxic prompts in LLMs and proposes effective methods to mitigate these risks. The authors' empirical study and experimental results demonstrate the effectiveness of their proposed techniques in enhancing LLM security. However, the paper has some limitations, such as the relatively small size of the toxic prompts dataset and the potential inaccuracy of automated evaluation methods. Additionally, the paper focuses mainly on English data, and the method may not be directly applicable to non-English languages. Future work should address these limitations and expand the research to multilingualism.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-23       |
| Abstract | [https://arxiv.org/abs/2406.11285v1](https://arxiv.org/abs/2406.11285v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.11285v1](https://browse.arxiv.org/html/2406.11285v1)       |
| Truncated       | False       |
| Word Count       | 6660       |