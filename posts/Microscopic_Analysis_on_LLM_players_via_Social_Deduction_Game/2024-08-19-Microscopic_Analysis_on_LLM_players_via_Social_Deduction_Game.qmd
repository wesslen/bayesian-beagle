
---
title: "Microscopic Analysis on LLM players via Social Deduction Game"
id: "2408.09946v1"
description: "LLMs evaluated in SpyGame with new metrics for better assessment of game-playing abilities."
author: Byungjun Kim, Dayeon Seo, Bugeun Kim
date: "2024-08-19"
image: "../../../bayesian-beagle.png"
categories: ['social-sciences', 'robustness', 'hci', 'architectures']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### Summary:

This study focuses on the evaluation of large language models (LLMs) in the context of social deduction games (SDGs), specifically SpyGame, a variant of SpyFall. The authors propose an approach that utilizes microscopic event-level metrics to analyze the performance of LLMs in SDGs, demonstrating that these metrics offer a more detailed assessment than conventional macroscopic metrics. The study also conducts a qualitative analysis to identify categories of abnormal reasoning patterns in LLMs, discovering four main categories and five subcategories, including exposure, role ambiguity, memory distortion, and dissociation. The authors validate their quantitative findings by correlating them with the results of the qualitative analysis.

### Major Findings:

1. The study demonstrates the effectiveness of using microscopic event-level metrics to analyze the performance of LLMs in SDGs, showing that these metrics are more effective than conventional macroscopic metrics in evaluating gameplay skills in SpyGame.
2. The qualitative analysis identifies four main categories and five subcategories of abnormal reasoning patterns in LLMs, providing insights into the limitations and potential biases of LLMs in SDGs.
3. The study validates the quantitative findings by correlating them with the results of the qualitative analysis, highlighting the importance of a multifaceted approach to evaluating LLMs in SDGs.

### Analysis and Critique:

The study provides a comprehensive evaluation of LLMs in SDGs, addressing the limitations of previous studies that relied on macroscopic quantitative evaluations and non-systematic qualitative analyses. The use of microscopic event-level metrics and thematic analysis offers a more detailed and nuanced understanding of LLMs' performance in SDGs. However, the study has some limitations, such as the use of a simplified version of SpyGame and the focus on text-based LLMs. Future research should extend this work to multi-modal LLMs and explore the differences between human and LLM players in SDGs. Overall, the study provides valuable insights into the behavior of LLM-based players in SDGs and highlights the importance of a multifaceted approach to evaluating LLMs in such games.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-20       |
| Abstract | [https://arxiv.org/abs/2408.09946v1](https://arxiv.org/abs/2408.09946v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.09946v1](https://browse.arxiv.org/html/2408.09946v1)       |
| Truncated       | False       |
| Word Count       | 10720       |