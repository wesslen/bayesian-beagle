
---
title: "InfinityBench: Extending Long Context Evaluation Beyond 100K Tokens"
id: "2402.13718v1"
description: "LLMs need improvement to effectively process 100K+ context, lacking standardized benchmark."
author: Xinrong Zhang, Yingfa Chen, Shengding Hu, Zihang Xu, Junhao Chen, Moo Khai Hao, Xu Han, Zhen Leng Thai, Shuo Wang, Zhiyuan Liu, Maosong Sun
date: "2024-02-21"
image: "https://browse.arxiv.org/html/2402.13718v1/x1.png"
categories: ['architectures']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.13718v1/x1.png)

### **Summary:**
- The article introduces Bench, the first benchmark tailored for long contexts exceeding 100K in average length. It evaluates the performance of large language models (LLMs) in processing long contexts.
- The benchmark includes tasks in different domains and languages, designed to require understanding of long dependencies in contexts.
- The results indicate that current state-of-the-art LLMs are not fully equipped to handle all tasks within Bench, highlighting the ongoing challenge of enabling LLMs to process long contexts effectively.

### **Major Findings:**
1. Processing and reasoning over long contexts is crucial for practical applications of LLMs, but current LLMs still require significant advancements to effectively process 100K+ context.
2. The benchmark, Bench, comprises synthetic and realistic tasks spanning diverse domains, presented in both English and Chinese, and is designed to require well understanding of long dependencies in contexts.
3. The performance of various LLMs on Bench indicates that they exhibit significant performance degradation when dealing with lengthy contexts, highlighting the need for advanced methodologies to improve LLMs’ efficiency in processing long context.

### **Analysis and Critique:**
- The article provides valuable insights into LLM performance, but the benchmark may not be sufficiently diverse or extensive to provide a comprehensive assessment of model capabilities.
- The reliance on exact match for scoring may necessitate tailored redesigns for new model evaluations.
- The article highlights the need for advanced methodologies to improve LLMs’ efficiency in processing long context, and suggests exploring LLMs’ capacity to handle up to a million tokens or more as a promising research avenue.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.13718v1](https://arxiv.org/abs/2402.13718v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.13718v1](https://browse.arxiv.org/html/2402.13718v1)       |
| Truncated       | False       |
| Word Count       | 7044       |