
---
title: "Revisiting Demonstration Selection Strategies in In-Context Learning"
id: "2401.12087v1"
description: "LLMs' in-context learning performance varies with demonstration choice. New method improves language tasks."
author: Keqin Peng, Liang Ding, Yancheng Yuan, Xuebo Liu, Min Zhang, Yuanxin Ouyang, Dacheng Tao
date: "2024-01-22"
image: "../../../bayesian-beagle.png"
categories: ['programming']
format:
  html:
    code-overflow: wrap
---

![](None)

The markdown summary of the academic article "Revisiting Demonstration Selection Strategies in In-Context Learning" is as follows:

### **Summary:**
Large language models (LLMs) have shown impressive abilities in in-context learning (ICL), where a few examples are used to describe a task to the model. The performance of ICL varies significantly with the choice of demonstrations, and it is still unclear why this happens or what factors will influence its choice. In this work, the authors revisit the factors contributing to this variance from both data and model aspects and propose a data- and model-dependent demonstration selection method, TopK + ConE, based on the conjecture that the performance of a demonstration positively correlates with its contribution to the modelâ€™s understanding of the test samples.

### Major Findings:
1. The choice of demonstration is both data- and model-dependent.
2. The proposed TopK + ConE method yields consistent improvements in both language understanding and generation tasks with different model scales.
3. The method provides a unified explanation for the effectiveness of previous methods.

### Analysis and Critique:
The article provides valuable insights into the factors influencing the choice of demonstrations in in-context learning. However, it is essential to note that the method's effectiveness may be limited by the maximum sentence length of the model, as observed in the experiments. Additionally, the study primarily focuses on language models and may not fully generalize to other types of models or tasks. Further research is needed to explore the broader applicability and potential limitations of the proposed method.

Overall, the article offers a significant contribution to understanding demonstration selection strategies in in-context learning, but further investigation is required to address potential methodological limitations and generalizability.

Please note that the summary is a concise representation of the article's content and findings. For a comprehensive understanding, it is recommended to refer to the original article.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-02       |
| Abstract | [https://arxiv.org/abs/2401.12087v1](https://arxiv.org/abs/2401.12087v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.12087v1](https://browse.arxiv.org/html/2401.12087v1)       |
| Truncated       | False       |
| Word Count       | 11709       |