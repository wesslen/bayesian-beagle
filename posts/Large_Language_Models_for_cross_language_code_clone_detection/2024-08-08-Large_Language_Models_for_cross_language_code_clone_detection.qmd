
---
title: "Large Language Models for cross-language code clone detection"
id: "2408.04430v1"
description: "LLMs struggle with complex code clones; embedding models outperform LLMs in cross-lingual code clone detection."
author: Micheline Bénédicte Moumoula, Abdoul Kader Kabore, Jacques Klein, Tegawendé Bissyande
date: "2024-08-08"
image: "https://browse.arxiv.org/html/2408.04430v1/x1.png"
categories: ['education', 'programming']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.04430v1/x1.png)

**Summary:**

This paper investigates the use of Large Language Models (LLMs) and Embedding Models (EMs) for cross-lingual code clone detection. The study focuses on four LLMs (Falcon-7B-Instruct, LLAMA2-Chat-7B, Starchat-, and GPT-3.5-Turbo) and one EM (Text-Embedding-Ada-002). The authors design various prompts for LLMs and evaluate their performance on two datasets, XLCoST and CodeNet. The results show that GPT-3.5-Turbo achieves the highest F1 score, while the "improved simple prompt" enables all LLMs to achieve their best performance. The EM outperforms all LLMs, even though LLMs yield satisfactory results when combined with CoT-based prompts.

**Major Findings:**

1. GPT-3.5-Turbo outperforms other LLMs in cross-lingual code clone detection, achieving an overall F1 score of 0.98 for XLCoST and 0.75 for CodeNet.
2. The "improved simple prompt" enables all LLMs to achieve their best performance in the task of code clone detection.
3. The EM outperforms all LLMs, with the SVM classifier using a polynomial kernel achieving F1-scores of 0.998 and 0.995 for XLCoST and CodeNet, respectively.

**Analysis and Critique:**

1. The study focuses on a limited number of LLMs and EMs, which may not be representative of the entire field.
2. The evaluation is based on two datasets, which may not cover all possible programming languages and code clone scenarios.
3. The study does not explore the potential of combining LLMs and EMs for improved performance.
4. The study does not discuss the computational cost and efficiency of using LLMs and EMs for cross-lingual code clone detection.
5. The study does not provide a comparison with other state-of-the-art methods for cross-lingual code clone detection.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-13       |
| Abstract | [https://arxiv.org/abs/2408.04430v1](https://arxiv.org/abs/2408.04430v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.04430v1](https://browse.arxiv.org/html/2408.04430v1)       |
| Truncated       | False       |
| Word Count       | 9785       |