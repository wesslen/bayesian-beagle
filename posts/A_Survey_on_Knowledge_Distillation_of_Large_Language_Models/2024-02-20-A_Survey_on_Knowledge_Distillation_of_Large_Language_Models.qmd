
---
title: "A Survey on Knowledge Distillation of Large Language Models"
id: "2402.13116v1"
description: "Survey explores knowledge distillation in Large Language Models, bridging gap between proprietary and open-source models."
author: Xiaohan Xu, Ming Li, Chongyang Tao, Tao Shen, Reynold Cheng, Jinyang Li, Can Xu, Dacheng Tao, Tianyi Zhou
date: "2024-02-20"
image: "https://browse.arxiv.org/html/2402.13116v1/x1.png"
categories: ['architectures', 'production']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.13116v1/x1.png)

### Summary:
- The article provides an overview of the evolving landscape of Large Language Models (LLMs), emphasizing the significance of knowledge distillation (KD) in transferring advanced capabilities from proprietary to open-source LLMs.
- The distillation pipeline of LLMs involves directing the teacher LLM towards a specific target skill or domain, feeding it with seed knowledge, generating distillation knowledge, and training the student model with a specific learning objective.
- Various methodologies for distilling knowledge from teacher LLMs into student models are discussed, including supervised fine-tuning, divergence and similarity-based methods, reinforcement learning, and ranking optimization.
- The development of LLMs with tool use proficiency and planning capabilities is crucial for their effectiveness in interactive environments and complex tasks, with various methods for distilling these capabilities into smaller models highlighted.
- The article also discusses the customization of LLMs for specific vertical domains, showcasing the significant role of knowledge distillation in enhancing domain-specific AI applications.
- SciGLM proposes to train a scientific LLM, prompting a teacher LLM to generate detailed answers for unlabelled scientific questions, and a self-reflective critic-and-revise to improve data quality, showcasing advancements in various scientific domains.
- The concept of self-alignment in aligning LLMs and the potential for the student model to autonomously improve and align its responses with desired behaviors is also discussed.

### Major Findings:
1. Knowledge distillation plays a crucial role in transferring advanced capabilities from proprietary to open-source Large Language Models (LLMs).
2. Various methodologies, such as supervised fine-tuning, divergence and similarity-based methods, reinforcement learning, and ranking optimization, are used for distilling knowledge from teacher LLMs into student models.
3. The development of LLMs with tool use proficiency and planning capabilities, as well as their customization for specific vertical domains, showcases the transformative potential of LLMs in various industries and scientific domains.

### Analysis and Critique:
- The article provides a comprehensive overview of knowledge distillation in the context of LLMs, showcasing its transformative potential and diverse applications.
- The methodologies discussed for distilling knowledge from teacher LLMs into student models highlight the importance of skill distillation in enhancing the capabilities of smaller language models.
- The customization of LLMs for specific vertical domains and the advancements in various scientific domains demonstrate the broad impact of LLMs and the significance of knowledge distillation in real-world applications.
- The concept of self-alignment in aligning LLMs offers potential avenues for continual self-improvement and alignment, contributing to the broader context of knowledge distillation in LLMs.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-21       |
| Abstract | [https://arxiv.org/abs/2402.13116v1](https://arxiv.org/abs/2402.13116v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.13116v1](https://browse.arxiv.org/html/2402.13116v1)       |
| Truncated       | True       |
| Word Count       | 38489       |