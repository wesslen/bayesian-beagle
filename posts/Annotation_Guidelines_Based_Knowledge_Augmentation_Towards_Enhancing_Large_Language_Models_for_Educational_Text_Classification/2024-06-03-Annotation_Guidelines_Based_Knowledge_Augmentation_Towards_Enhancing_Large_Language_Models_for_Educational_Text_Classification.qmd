
---
title: "Annotation Guidelines-Based Knowledge Augmentation: Towards Enhancing Large Language Models for Educational Text Classification"
id: "2406.00954v1"
description: "AGKA improves LLMs like GPT 4.0 and Llama 3 70B for learning engagement classification, but struggles with multi-class tasks and similar labels."
author: Shiqi Liu, Sannyuya Liu, Lele Sha, Zijie Zeng, Dragan Gasevic, Zhi Liu
date: "2024-06-03"
image: "https://browse.arxiv.org/html/2406.00954v1/x1.png"
categories: ['social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.00954v1/x1.png)

### Summary:

This study proposes the Annotation Guidelines-based Knowledge Augmentation (AGKA) approach to improve Large Language Models (LLMs) for Learning Engagement Classification (LEC) tasks. AGKA employs GPT 4.0 to retrieve label definition knowledge from annotation guidelines and applies the random under-sampler to select a few typical examples. The study evaluates the performance of LLMs on six LEC datasets, covering behavior, emotion, and cognition classification tasks. The results demonstrate that AGKA enhances non-fine-tuned LLMs, particularly GPT 4.0 and Llama 3 70B. GPT 4.0 with AGKA few-shot outperforms full-shot fine-tuned models such as BERT and RoBERTa on simple binary classification datasets. However, GPT 4.0 lags in multi-class tasks that require a deep understanding of complex semantic information. The study highlights the effectiveness of AGKA for LLMs in education and provides a valuable benchmark for evaluating LEC models.

### Major Findings:

1. AGKA improves the performance of non-fine-tuned LLMs, particularly GPT 4.0 and Llama 3 70B, for LEC tasks.
2. GPT 4.0 with AGKA few-shot outperforms full-shot fine-tuned models such as BERT and RoBERTa on simple binary classification datasets.
3. GPT 4.0 with AGKA lags in multi-class tasks that require a deep understanding of complex semantic information.
4. Llama 3 70B with AGKA is a promising combination based on open-source LLM, as its performance is on par with closed-source GPT 4.0 with AGKA.
5. LLMs struggle to distinguish between labels with similar names in multi-class classification.

### Analysis and Critique:

The study provides a valuable contribution to the field of LEC by proposing the AGKA approach to improve LLMs. The comprehensive evaluation of LLMs on six LEC datasets offers a valuable benchmark for evaluating LEC models. However, the study has

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2406.00954v1](https://arxiv.org/abs/2406.00954v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.00954v1](https://browse.arxiv.org/html/2406.00954v1)       |
| Truncated       | False       |
| Word Count       | 9686       |