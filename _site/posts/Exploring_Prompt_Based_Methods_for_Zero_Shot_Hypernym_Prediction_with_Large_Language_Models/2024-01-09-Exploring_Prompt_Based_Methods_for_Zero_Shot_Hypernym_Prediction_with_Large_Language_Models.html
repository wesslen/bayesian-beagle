<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Mikhail Tikhomirov">
<meta name="author" content="Natalia Loukachevitch">
<meta name="dcterms.date" content="2024-01-09">
<meta name="description" content="Zero-shot hypernymy prediction using large language models through prompt selection, additional information, and iterative approach.">

<title>Bayesian beagle - Exploring Prompt-Based Methods for Zero-Shot Hypernym Prediction with Large Language Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Bayesian beagle - Exploring Prompt-Based Methods for Zero-Shot Hypernym Prediction with Large Language Models">
<meta property="og:description" content="Zero-shot hypernymy prediction using large language models through prompt selection, additional information, and iterative approach.">
<meta property="og:image" content="https://browse.arxiv.org/html/2401.04515v1/extracted/5337813/scheme1.png">
<meta property="og:site-name" content="Bayesian beagle">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../icon.jpg" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Bayesian beagle</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">Bayesian beagle</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/wesslen/bayesian-beagle" rel="" target=""><i class="bi bi-github" role="img" aria-label="github">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Exploring Prompt-Based Methods for Zero-Shot Hypernym Prediction with Large Language Models</h1>
  <div class="quarto-categories">
    <div class="quarto-category">prompt-engineering</div>
    <div class="quarto-category">production</div>
  </div>
  </div>

<div>
  <div class="description">
    Zero-shot hypernymy prediction using large language models through prompt selection, additional information, and iterative approach.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Authors</div>
    <div class="quarto-title-meta-contents">
             <p>Mikhail Tikhomirov </p>
             <p>Natalia Loukachevitch </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 9, 2024</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p><img src="https://browse.arxiv.org/html/2401.04515v1/extracted/5337813/scheme1.png" class="img-fluid"></p>
<section id="main-takeaways" class="level3">
<h3 class="anchored" data-anchor-id="main-takeaways">Main Takeaways</h3>
<ol type="1">
<li>The study explores a <strong>zero-shot approach to hypernymy prediction</strong> using large language models (LLMs), demonstrating a strong correlation between the effectiveness of language model prompts and classic patterns.</li>
<li>The article investigates prompts for predicting <strong>co-hyponyms</strong> and improving hypernymy predictions by augmenting prompts with additional information through automatically identified co-hyponyms, leading to significant improvements in prediction quality.</li>
<li>The research also develops an <strong>iterative approach for predicting higher-level concepts</strong>, further improving the quality of hypernym chain prediction on the BLESS dataset.</li>
</ol>
</section>
<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<ul>
<li>Taxonomies play a crucial role in knowledge organization, and extracting taxonomic relationships from text data has been a focus of extensive research.</li>
<li><strong>Hypernym acquisition</strong> techniques include linear patterns, unsupervised and supervised vector-based techniques, and large language models based on neural transformer architectures, allowing for the study of novel methods for hypernym prediction.</li>
<li>The article investigates the research questions related to the consistency of language models on a set of prompts, the benefits of co-hyponym prompts for hypernym prediction, and the possibility of improving hypernym chain prediction using prompts.</li>
</ul>
</section>
<section id="related-works" class="level3">
<h3 class="anchored" data-anchor-id="related-works">Related Works</h3>
<section id="pattern-based-approaches" class="level4">
<h4 class="anchored" data-anchor-id="pattern-based-approaches">Pattern-based approaches</h4>
<ul>
<li><strong>Pattern-based approach</strong> involves exploiting certain lexico-syntactic patterns to detect hypernym relations in text, with efforts to increase recall and precision of extracted relationships.</li>
<li>Strategies to improve recall of patterns include using extended sets of patterns and applying Singular Value Decomposition to reduce the dimensionality of the matrix describing ppmi weights for words met in the patterns.</li>
<li><strong>Co-hyponym patterns</strong> are also used as an additional source of information for hypernym detection.</li>
</ul>
</section>
<section id="unsupervised-vector-based-approaches" class="level4">
<h4 class="anchored" data-anchor-id="unsupervised-vector-based-approaches">Unsupervised vector-based approaches</h4>
<ul>
<li>This approach is based on the methods of distributional semantics and focuses on the distributional inclusion hypothesis, distributional exclusivity hypothesis, and distributional informativeness hypothesis.</li>
</ul>
</section>
<section id="zero-shot-prompts-for-large-language-models" class="level4">
<h4 class="anchored" data-anchor-id="zero-shot-prompts-for-large-language-models">Zero-shot prompts for large language models</h4>
<ul>
<li>Large language models like BERT and GPT are utilized for predicting hypernyms based on classical lexico-syntactic patterns, with studies highlighting the importance of unambiguous prompts encoding hypernymy and the competitive nature of the most frequent prompts in pretraining corpora.</li>
</ul>
</section>
</section>
<section id="approach" class="level3">
<h3 class="anchored" data-anchor-id="approach">Approach</h3>
<ul>
<li>The study focuses on an approach to exploiting prompts and maps a pair of terms and a prompt type to a single sentence, estimating the probabilities of hypernyms using language models.</li>
<li>The primary idea is to experiment with prompts combinations, including <strong>combinations of hypernym prompts, combinations of hypernym and co-hyponym prompts, and iterative application of hypernym prompts</strong>.</li>
</ul>
</section>
<section id="datasets-and-models" class="level3">
<h3 class="anchored" data-anchor-id="datasets-and-models">Datasets and Models</h3>
<ul>
<li>The study experiments with datasets from the hypernymysuite benchmark and evaluates prompts and models in two different task settings of hypernym prediction.</li>
</ul>
</section>
<section id="single-prompts-experiments" class="level3">
<h3 class="anchored" data-anchor-id="single-prompts-experiments">Single prompts experiments</h3>
<section id="hypernym-prompts" class="level4">
<h4 class="anchored" data-anchor-id="hypernym-prompts">Hypernym prompts</h4>
<ul>
<li>The investigation of 76 prompts for hypernymy prediction highlighted that the performance varies significantly across different prompts and large language models, with <strong>selective variant of the hypernym probability estimation being superior to the full variant</strong>.</li>
</ul>
</section>
<section id="co-hyponym-prompts" class="level4">
<h4 class="anchored" data-anchor-id="co-hyponym-prompts">Co-hyponym prompts</h4>
<ul>
<li>The study considered four types of co-hyponym prompts based on enumeration patterns, and the evaluation results on 11 prompts demonstrated that the prompt “such as hypo, cohypo, and others of the same type” showed the best quality for both the full and selective approaches.</li>
</ul>
</section>
</section>
<section id="combinations" class="level3">
<h3 class="anchored" data-anchor-id="combinations">Combinations</h3>
<section id="combinations-of-hypernyms-prompts" class="level4">
<h4 class="anchored" data-anchor-id="combinations-of-hypernyms-prompts">Combinations of hypernyms prompts</h4>
<ul>
<li>The study investigated if combining different hypernym prompts could enhance hypernym prediction, but estaurs that this approach did not improve the ranking quality for most models.</li>
</ul>
</section>
<section id="co-hyponym-augmented-prompts" class="level4">
<h4 class="anchored" data-anchor-id="co-hyponym-augmented-prompts">Co-hyponym-augmented prompts</h4>
<ul>
<li>The concept of combining co-hyponyms with hypernyms prompts was analyzed, highlighting different variations with some significantly improving the quality of hypernymy predictions.</li>
</ul>
</section>
<section id="iterative-approach-to-ranking-a-list-of-hypernyms" class="level4">
<h4 class="anchored" data-anchor-id="iterative-approach-to-ranking-a-list-of-hypernyms">Iterative approach to ranking a list of hypernyms</h4>
<ul>
<li>An iterative approach was developed for hypernym predictions, demonstrating overall improvements in quality on the BLESS dataset.</li>
</ul>
</section>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<ul>
<li>The study recommends using the probability estimate of the entire sequence and answers the three research questions posed.</li>
<li>The best quality on the BLESS dataset (MAP 0.8 from 0.7 with straightforward approach) was achieved by using the full method, co-hyponym-augmented prompt “hypo, cohypo are an hyper that,” and the iterative approach.</li>
</ul>
</section>
<section id="critique" class="level3">
<h3 class="anchored" data-anchor-id="critique">Critique</h3>
<p>The article provides comprehensive insights into the zero-shot hypernym prediction approach using large language models. However, the evaluation method for these datasets is noted to be not entirely correct, and there are recommendations to improve the evaluation process. Additionally, the study could benefit from further discussion on the potential limitations and challenges associated with the proposed methods.</p>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>gpt-3.5-turbo-1106</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-02-26</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="http://arxiv.org/abs/2401.04515v1">http://arxiv.org/abs/2401.04515v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2401.04515v1">https://browse.arxiv.org/html/2401.04515v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>False</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>7734</td>
</tr>
</tbody>
</table>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="wesslen/bayesian-beagle" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/wesslen/bayesian-beagle/edit/main/posts/Exploring_Prompt_Based_Methods_for_Zero_Shot_Hypernym_Prediction_with_Large_Language_Models/2024-01-09-Exploring_Prompt_Based_Methods_for_Zero_Shot_Hypernym_Prediction_with_Large_Language_Models.qmd" class="toc-action">Edit this page</a></p></div></div></div></div></footer></body></html>