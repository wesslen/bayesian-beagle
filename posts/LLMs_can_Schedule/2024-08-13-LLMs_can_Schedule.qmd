
---
title: "LLMs can Schedule"
id: "2408.06993v1"
description: "TL;DR: LLMs can tackle job shop scheduling problems, performing comparably to other neural methods."
author: Henrik Abgaryan, Ararat Harutyunyan, Tristan Cazenave
date: "2024-08-13"
image: "https://browse.arxiv.org/html/2408.06993v1/extracted/5789627/imgs/losses.png"
categories: ['hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.06993v1/extracted/5789627/imgs/losses.png)

### Summary:

This paper explores the potential of Large Language Models (LLMs) in tackling the complexities of the job shop scheduling problem (JSSP). The authors introduce a novel supervised dataset specifically designed to train LLMs for JSSP, which is different from traditional matrix representation formats. The paper presents a comparative analysis that demonstrates the efficacy of LLM-based scheduling, showing that LLMs have the potential to effectively schedule tasks, demonstrating performance on par with some of the current neural network methods for JSSP. Furthermore, the authors propose a sampling method that enhances the effectiveness of LLMs in tackling this problem.

### Major Findings:

1. The authors introduce the very first supervised 120k dataset specifically designed for LLM training for JSSP, addressing the unique requirements of the problem domain and facilitating effective LLM training.
2. The paper explores the potential application of LLMs for job shop scheduling, offering a novel approach.
3. The authors present a comparative analysis demonstrating the effectiveness of end-to-end LLM-based scheduling compared to existing neural network approaches.
4. The analysis sheds light on the capabilities of LLMs in this domain, and the authors use a sampling method that improves LLM performance in JSSP.

### Analysis and Critique:

While the paper presents promising results, there are some limitations and potential areas for improvement. The computational overhead of fine-tuning LLMs remains resource-intensive, and the generalizability of the results across larger JSSP instances is uncertain due to lack of computational resources. The interpretability of LLM-generated schedules is also a challenge, due to their black-box nature. Additionally, while a sampling method is used to improve performance, exploring different sampling strategies could further enhance LLM-generated schedules. Future research should also explore integrating LLMs with other AI techniques, such as reinforcement learning and graph neural networks, to combine their strengths.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-20       |
| Abstract | [https://arxiv.org/abs/2408.06993v1](https://arxiv.org/abs/2408.06993v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.06993v1](https://browse.arxiv.org/html/2408.06993v1)       |
| Truncated       | False       |
| Word Count       | 5428       |