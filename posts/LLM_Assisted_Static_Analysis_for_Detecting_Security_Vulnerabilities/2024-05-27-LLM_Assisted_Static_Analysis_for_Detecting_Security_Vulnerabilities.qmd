
---
title: "LLM-Assisted Static Analysis for Detecting Security Vulnerabilities"
id: "2405.17238v1"
description: "IRIS, a new approach, combines LLMs with static analysis to detect security vulnerabilities, outperforming state-of-the-art tools."
author: Ziyang Li, Saikat Dutta, Mayur Naik
date: "2024-05-27"
image: "https://browse.arxiv.org/html/2405.17238v1/x1.png"
categories: ['programming']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2405.17238v1/x1.png)

### Summary:

The paper presents a novel approach, IRIS, that combines large language models (LLMs) with static analysis to perform whole-repository reasoning for detecting security vulnerabilities. The authors curate a new dataset, CWE-Bench-Java, comprising 120 manually validated security vulnerabilities in real-world Java projects. The results show that IRIS, using GPT-4, detects 69 vulnerabilities, while the state-of-the-art static analysis tool only detects 27. Additionally, IRIS significantly reduces the number of false alarms (by more than 80% in the best case).

### Major Findings:

1. IRIS, the proposed neuro-symbolic approach, combines the strengths of static analysis and LLMs without suffering from their limitations, enabling more precise whole-repository reasoning and minimizing human effort.
2. The CWE-Bench-Java dataset, curated by the authors, contains manually vetted and compilable Java projects with 120 vulnerabilities across four common vulnerability classes, making it a challenging benchmark for vulnerability detection.
3. Evaluation of IRIS on CWE-Bench-Java using eight diverse open- and closed-source LLMs shows that IRIS obtains the best results with GPT-4, detecting 69 vulnerabilities, which is 42 (35%) more than CodeQL. Among open-source LLMs, DeepSeekCoder 7B performs the best, detecting 67 vulnerabilities, followed by Llama 3 70B with 57 vulnerabilities.

### Analysis and Critique:

1. The paper presents a promising approach to combining LLMs with static analysis for vulnerability detection. However, the evaluation is limited to Java projects, and it remains to be seen how well the approach generalizes to other programming languages.
2. The authors curate a new dataset, CWE-Bench-Java, which is a valuable contribution to the field. However, the dataset is relatively small, with only 120 vulnerabilities, which may limit the generalizability of the results.
3. The paper does not discuss the potential limitations or biases of the LLMs used in the study, which could impact the results. For example

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2405.17238v1](https://arxiv.org/abs/2405.17238v1)        |
| HTML     | [https://browse.arxiv.org/html/2405.17238v1](https://browse.arxiv.org/html/2405.17238v1)       |
| Truncated       | False       |
| Word Count       | 10510       |