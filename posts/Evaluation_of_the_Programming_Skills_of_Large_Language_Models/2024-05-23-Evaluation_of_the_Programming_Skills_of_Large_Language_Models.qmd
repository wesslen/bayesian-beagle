
---
title: "Evaluation of the Programming Skills of Large Language Models"
id: "2405.14388v1"
description: "LLMs' code quality compared: OpenAI's ChatGPT vs Google's Gemini AI."
author: Luc Bryan Heitz, Joun Chamas, Christopher Scherb
date: "2024-05-23"
image: "https://browse.arxiv.org/html/2405.14388v1/extracted/2405.14388v1/figure/bardvsgpt.png"
categories: ['programming']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2405.14388v1/extracted/2405.14388v1/figure/bardvsgpt.png)

### Summary:

The paper evaluates the programming skills of two leading Large Language Models (LLMs), OpenAI's ChatGPT and Google's Gemini AI, by comparing the quality of code generated in their free versions. The study uses a real-world example and a systematic dataset to investigate the code quality produced by these LLMs. The research aims to shed light on the efficacy and reliability of LLMs in generating high-quality programming code, which has significant implications for the field of software development and beyond.

### Major Findings:

1. ChatGPT and Gemini AI demonstrate notable proficiency in generating programming code, making them compelling subjects for analysis.
2. The complexity of programming code often escalates to levels where its verification becomes a formidable task, underscoring the importance of this study.
3. The study employs standardized datasets and prompts to ensure an equitable and comprehensive assessment across a spectrum of programming challenges.

### Analysis and Critique:

1. The study focuses on the functional correctness, maintainability, and efficiency of the code generated by ChatGPT and Gemini AI.
2. The study does not investigate the intricate technical details of the chatbots' architecture, such as how they are trained, their use of reinforcement learning algorithms, or the structure of their neural networks.
3. The study recognizes that ChatGPT and Gemini AI are dynamic technologies, subject to ongoing updates and improvements, which may overcome some of the current limitations discussed.
4. The study does not address the potential for bias in the training data of these LLMs, which could impact the quality and fairness of the generated code.
5. The study does not discuss the potential for these LLMs to be used in malicious ways, such as generating code for cyber attacks.
6. The study does not consider the potential for these LLMs to be used in a way that violates software licensing agreements or intellectual property rights.
7. The study does not discuss the potential for these LLMs to be used to automate jobs, potentially leading to job displacement in the software development industry.
8. The study does not consider the potential for these LLMs to be used to generate code that is difficult for humans to understand or maintain, which could lead to long-term maintenance issues.
9. The study

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2405.14388v1](https://arxiv.org/abs/2405.14388v1)        |
| HTML     | [https://browse.arxiv.org/html/2405.14388v1](https://browse.arxiv.org/html/2405.14388v1)       |
| Truncated       | False       |
| Word Count       | 4508       |