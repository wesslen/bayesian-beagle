
---
title: "Is Cognition and Action Consistent or Not: Investigating Large Language Model's Personality"
id: "2402.14679v1"
description: "Study evaluates reliability of Large Language Models in emulating human-like personality traits."
author: Yiming Ai, Zhiwei He, Ziyin Zhang, Wenhong Zhu, Hongkun Hao, Kai Yu, Lingjun Chen, Rui Wang
date: "2024-02-22"
image: "https://browse.arxiv.org/html/2402.14679v1/x1.png"
categories: ['hci', 'social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.14679v1/x1.png)

### **Summary:**
- The study investigates the reliability of Large Language Models (LLMs) in professing human-like personality traits through responses to personality questionnaires.
- The study evaluates the consistency between LLMs’ professed personality inclinations and their actual "behavior", examining the extent to which these models can emulate human-like personality patterns.
- The study proposes hypotheses for the observed results based on psychological theories and metrics.

### Major Findings:
1. The study develops a methodology, including 2 metrics, for analyzing LLMs’ personality representation reliability.
2. The study gauges the cognition-action congruence of LLMs, indicating that LLMs significantly underperform humans in achieving consistency between cognition and action.
3. The study empirically tests various LLMs against established metrics, shedding light on the potential and limitations of LLMs in mimicking complex human psychological traits.

### Analysis and Critique:
- The study raises questions about LLMs’ ability to achieve cognition-action unity in practice.
- The study suggests that LLMs might be aligning their responses more closely with perceived societal expectations than with genuine personality inclinations.
- The study emphasizes the need for further investigation into the fundamental reasons behind the inconsistency observed in LLMs’ responses.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-26       |
| Abstract | [https://arxiv.org/abs/2402.14679v1](https://arxiv.org/abs/2402.14679v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.14679v1](https://browse.arxiv.org/html/2402.14679v1)       |
| Truncated       | False       |
| Word Count       | 7374       |