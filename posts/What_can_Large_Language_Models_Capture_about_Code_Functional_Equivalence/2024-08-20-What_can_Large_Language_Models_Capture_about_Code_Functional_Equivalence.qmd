
---
title: "What can Large Language Models Capture about Code Functional Equivalence?"
id: "2408.11081v1"
description: "Code-LLMs struggle to grasp code semantics, despite strong performance in code generation and classification."
author: Nickil Maveli, Antonio Vergari, Shay B. Cohen
date: "2024-08-20"
image: "../../img/2408.11081v1/image_1.png"
categories: ['programming']
format:
  html:
    code-overflow: wrap
---

![](../../img/2408.11081v1/image_1.png)

**Summary:**
The paper "What can Large Language Models Capture about Code Functional Equivalence?" by Nickil Maveli, Antonio Vergari, and Shay B. Cohen explores the ability of Code-LLMs (LLMs pre-trained on large code corpora) to understand code semantics and functional equivalence. The authors introduce SeqCoBench, a benchmark for evaluating Code-LLMs' ability to capture code functional equivalence. SeqCoBench contains over 20 code transformations that either preserve or alter the semantics of Python programs. The paper presents extensive evaluations of state-of-the-art (Code-)LLMs in different settings, including zero-shot and parameter-efficient finetuning methods. The results show that the performance gap between these LLMs and classical match-based retrieval scores is minimal, with both approaches showing a concerning lack of depth in understanding code semantics

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-27       |
| Abstract | [https://arxiv.org/abs/2408.11081v1](https://arxiv.org/abs/2408.11081v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.11081v1](https://browse.arxiv.org/html/2408.11081v1)       |
| Truncated       | True       |
| Word Count       | 33204       |