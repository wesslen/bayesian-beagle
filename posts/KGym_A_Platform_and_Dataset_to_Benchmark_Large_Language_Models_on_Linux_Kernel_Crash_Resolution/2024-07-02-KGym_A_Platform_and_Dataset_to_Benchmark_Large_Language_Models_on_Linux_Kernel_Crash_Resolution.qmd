
---
title: "KGym: A Platform and Dataset to Benchmark Large Language Models on Linux Kernel Crash Resolution"
id: "2407.02680v1"
description: "LLMs struggle with Linux kernel crashes, achieving 0.72%-5.38% success. Further research needed for SE tasks."
author: Alex Mathai, Chenxi Huang, Petros Maniatis, Aleksandr Nogikh, Franjo Ivancic, Junfeng Yang, Baishakhi Ray
date: "2024-07-02"
image: "https://browse.arxiv.org/html/2407.02680v1/x1.png"
categories: ['programming']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2407.02680v1/x1.png)

### Summary:

The paper introduces kGym, a platform for benchmarking large language models (LLMs) on Linux kernel crash resolution, and kBench, a dataset of real-world Linux kernel bugs. The authors argue that existing benchmarks for LLMs do not reflect the complexities of everyday software engineering tasks, and kBench aims to address this gap. The platform provides an environment for large-scale experiments on the Linux kernel, including compiling and running kernels, detecting operations and crashes, and querying and patching the codebase. The dataset consists of bug-resolution samples, each containing a crashing stack trace, a bug-reproducer file, a developer-written fix, and other associated data. The authors conduct baseline experiments using LLMs to resolve Linux kernel crashes, with the best-performing model achieving 0.72% and 5.38% in unassisted and assisted settings, respectively. The results highlight the need for further research to enhance model performance in software engineering tasks.

### Major Findings:

1. kGym is a platform for benchmarking LLMs on Linux kernel crash resolution, providing an environment for large-scale experiments on the Linux kernel.
2. kBench is a dataset of real-world Linux kernel bugs, consisting of bug-resolution samples with crashing stack traces, bug-reproducer files, developer-written fixes, and other associated data.
3. Baseline experiments using LLMs to resolve Linux kernel crashes reveal that the best-performing model achieves 0.72% and 5.38% in unassisted and assisted settings, respectively.

### Analysis and Critique:

The paper presents a valuable contribution to the field of software engineering by introducing a platform and dataset for benchmarking LLMs on Linux kernel crash resolution. The authors argue that existing benchmarks do not reflect the complexities of everyday software engineering tasks, and kBench aims to address this gap. However, the paper does not provide a detailed analysis of the limitations and potential biases of the dataset, which could impact the generalizability of the results. Additionally, the paper does not discuss the methodological issues or conflicting evidence that may arise from using LLMs for software engineering tasks. Further research is needed to evaluate the effectiveness of LLMs in

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-09       |
| Abstract | [https://arxiv.org/abs/2407.02680v1](https://arxiv.org/abs/2407.02680v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.02680v1](https://browse.arxiv.org/html/2407.02680v1)       |
| Truncated       | False       |
| Word Count       | 3950       |