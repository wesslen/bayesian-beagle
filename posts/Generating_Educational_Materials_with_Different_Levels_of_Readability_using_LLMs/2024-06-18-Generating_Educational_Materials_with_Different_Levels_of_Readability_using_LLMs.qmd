
---
title: "Generating Educational Materials with Different Levels of Readability using LLMs"
id: "2406.12787v1"
description: "TL;DR: Few-shot prompting improves AI's ability to simplify educational texts, but quality concerns remain."
author: Chieh-Yang Huang, Jing Wei, Ting-Hao 'Kenneth' Huang
date: "2024-06-18"
image: "https://browse.arxiv.org/html/2406.12787v1/extracted/5676358/figure/score_gpt3.5-zeroshot-output_subset.png"
categories: ['robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.12787v1/extracted/5676358/figure/score_gpt3.5-zeroshot-output_subset.png)

### Summary:
- The study introduces the leveled-text generation task, which aims to rewrite educational materials to specific readability levels while preserving meaning.
- The researchers assess the capability of GPT-3.5, LLaMA-2 70B, and Mixtral 8x7B to generate content at various readability levels through zero-shot and few-shot prompting.
- Evaluating 100 processed educational materials reveals that few-shot prompting significantly improves performance in readability manipulation and information preservation.
- LLaMA-2 70B performs better in achieving the desired difficulty range, while GPT-3.5 maintains original meaning.
- However, manual inspection highlights concerns such as misinformation introduction and inconsistent edit distribution.

### Major Findings:
1. Few-shot prompting significantly improves performance in readability manipulation and information preservation.
2. LLaMA-2 70B performs better in achieving the desired difficulty range, while GPT-3.5 maintains original meaning.
3. Manual inspection reveals concerns such as misinformation introduction and inconsistent edit distribution.

### Analysis and Critique:
- The study highlights the potential of large language models (LLMs) in generating educational content at specific readability levels.
- However, the findings also emphasize the need for further research to ensure the quality of generated educational content, as concerns such as misinformation introduction and inconsistent edit distribution were identified.
- The study also points out the limitations of current LLMs, such as the tendency to produce shorter texts than the originals and the uneven distribution of edits within articles.
- Future research should address these limitations and explore ways to integrate learning objectives and retain key information in the generated texts.
- The study also suggests the need for human involvement in determining appropriate learning objectives for students at different levels.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-23       |
| Abstract | [https://arxiv.org/abs/2406.12787v1](https://arxiv.org/abs/2406.12787v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.12787v1](https://browse.arxiv.org/html/2406.12787v1)       |
| Truncated       | False       |
| Word Count       | 5307       |