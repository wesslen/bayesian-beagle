
---
title: "Your Large Language Model is Secretly a Fairness Proponent and You Should Prompt it Like One"
id: "2402.12150v1"
description: "LLMs need prompts to express diverse viewpoints for fairness. FairThinking pipeline outperforms in experiments."
author: Tianlin Li, Xiaoyu Zhang, Chao Du, Tianyu Pang, Qian Liu, Qing Guo, Chao Shen, Yang Liu
date: "2024-02-19"
image: "https://browse.arxiv.org/html/2402.12150v1/x2.png"
categories: ['social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.12150v1/x2.png)

### Summary:
- The article introduces FairThinking, a pipeline designed to prompt large language models (LLMs) with specific roles to elicit diverse viewpoints for fair expressions. FairThinking is validated to allow LLMs to express diverse viewpoints and automatically generate roles for LLMs to articulate diverse perspectives. It is evaluated on GPT-3.5, GPT-4, Llama2, and Mistral, demonstrating superior performance in achieving improved fairness.
- Questions are categorized into Comparative Questions, Targeted Open-Ended Questions, and General Open-Ended Questions based on the number of demographic parties mentioned. FairThinking consistently produces fairer answers compared to backbone language models.
- Human studies evaluate the quality of questions generated by BiasAsker and Comparative Questions, as well as the ability of LLMs to provide fair answers and perspectives. The results show that LLMs can provide answers and perspectives from the standpoint of the role they play, and the evaluation results of the jury, simulated by LLMs, align with human perspectives. Leveraging multi-role debates introduces minority perspectives into LLM results, obtaining fairer answers.
- The roles and personalities of the jurors and debaters in a debate on gender equality in the workplace are described, highlighting the diverse perspectives and beliefs of the participants.

### Major Findings:
1. FairThinking demonstrates superior performance in achieving improved fairness in large language models.
2. Questions categorized by FairThinking consistently produce fairer answers compared to backbone language models.
3. Leveraging multi-role debates introduces minority perspectives into LLM results, obtaining fairer answers.

### Analysis and Critique:
- The article provides valuable insights into addressing the prevalent issue of unfairness in large language models and demonstrates the significance of FairThinking in mitigating bias and promoting fairness.
- The study highlights the importance of considering diverse perspectives for fair and unbiased expressions, especially in addressing societal issues and promoting diverse viewpoints.
- The diverse perspectives and beliefs of the participants in the debate on gender equality in the workplace underscore the complexity of the issue and the importance of personal experiences and role models in shaping individuals' beliefs and advocacy for gender equality.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-26       |
| Abstract | [https://arxiv.org/abs/2402.12150v1](https://arxiv.org/abs/2402.12150v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.12150v1](https://browse.arxiv.org/html/2402.12150v1)       |
| Truncated       | True       |
| Word Count       | 17302       |