<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Zhexin Zhang, Yida Lu, Jingyuan Ma, Di Zhang, Rui Li, Pei Ke, Hao Sun, Lei Sha, Zhifang Sui, Hongning Wang, Minlie Huang">
<meta name="dcterms.date" content="2024-02-26">
<meta name="description" content="ShieldLM is a customizable and explainable safety detector for Large Language Models.">

<title>Bayesian beagle - ShieldLM: Empowering LLMs as Aligned, Customizable and Explainable Safety Detectors</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Bayesian beagle - ShieldLM: Empowering LLMs as Aligned, Customizable and Explainable Safety Detectors">
<meta property="og:description" content="ShieldLM is a customizable and explainable safety detector for Large Language Models.">
<meta property="og:image" content="https://bayesian-beagle.netlify.app/img/2402.16444v1/image_1.png">
<meta property="og:site-name" content="Bayesian beagle">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../icon.jpg" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Bayesian beagle</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">Bayesian beagle</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/wesslen/bayesian-beagle" rel="" target=""><i class="bi bi-github" role="img" aria-label="github">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">ShieldLM: Empowering LLMs as Aligned, Customizable and Explainable Safety Detectors</h1>
  <div class="quarto-categories">
    <div class="quarto-category">robustness</div>
    <div class="quarto-category">security</div>
    <div class="quarto-category">architectures</div>
    <div class="quarto-category">production</div>
  </div>
  </div>

<div>
  <div class="description">
    ShieldLM is a customizable and explainable safety detector for Large Language Models.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Zhexin Zhang, Yida Lu, Jingyuan Ma, Di Zhang, Rui Li, Pei Ke, Hao Sun, Lei Sha, Zhifang Sui, Hongning Wang, Minlie Huang </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">February 26, 2024</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p><img src="../../img/2402.16444v1/image_1.png" class="img-fluid"></p>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary:</h3>
<ul>
<li>The section discusses the development of ShieldLM, an LLM-based safety detector that aligns with human safety standards, supports customizable detection rules, and provides explanations for its decisions. The authors propose ShieldLM to address the limitations of existing safety detection methodologies and demonstrate its superior performance across various test sets. ShieldLM surpasses strong baselines and exhibits remarkable customizability and explainability. The section also presents a pilot study to demonstrate the limitations of existing methodologies in identifying safety concerns in LLMs’ responses, motivating the development of ShieldLM. The authors also describe the training process, label collection, analysis generation, and training settings for ShieldLM.</li>
</ul>
<p><strong>Key Terms:</strong> Large Language Models (LLMs), ShieldLM, safety detector, alignment, customizable detection rules, explanations, pilot study, label collection, analysis generation, training settings.</p>
</section>
<section id="major-findings" class="level3">
<h3 class="anchored" data-anchor-id="major-findings">Major Findings:</h3>
<ol type="1">
<li>ShieldLM achieves the best performance on both the F1-Safe and the F1-Unsafe score across all test sets.</li>
<li>ShieldLM takes customized detection rules to support diverse application scenarios and safety standards.</li>
<li>ShieldLM provides high-quality explanations for its decisions.</li>
</ol>
</section>
<section id="analysis-and-critique" class="level3">
<h3 class="anchored" data-anchor-id="analysis-and-critique">Analysis and Critique:</h3>
<ul>
<li>The section highlights the significance of ShieldLM as a comprehensive safety detector that addresses the limitations of existing methodologies. It demonstrates the practical utility of ShieldLM as a reliable judge for safety evaluation of LLMs in real-world applications. The development of ShieldLM is motivated by the limitations of existing methodologies in identifying safety concerns in LLMs’ responses, as demonstrated in the pilot study. The authors emphasize the superior performance of ShieldLM across various test sets, attributing its success to its alignment with human safety standards, support for customizable detection rules, and provision of explanations for its decisions.</li>
</ul>
<hr>
</section>
<section id="summary-1" class="level3">
<h3 class="anchored" data-anchor-id="summary-1">Summary:</h3>
<ul>
<li>The section provides a comparison of different language models’ performance in detecting safety issues in their responses. It presents the accuracy, safe and unsafe F1 scores for various models on different datasets, including an in-domain dataset and three out-of-domain datasets. The section also discusses the main results, customizability, explainability, and practical application of ShieldLM as a scorer for evaluating language model safety.</li>
</ul>
<p><strong>Key Terms:</strong> GPT-4, LLM, F1 score, OOD test sets, ShieldLM, content moderation, explainability, customizability.</p>
</section>
<section id="major-findings-1" class="level3">
<h3 class="anchored" data-anchor-id="major-findings-1">Major Findings:</h3>
<ol type="1">
<li>ShieldLM achieves the best performance on both the F1-Safe and the F1-Unsafe score across all test sets.</li>
<li>ShieldLM supports customizable detection rules and provides explanations for its decisions.</li>
<li>ShieldLM demonstrates practical utility as a scorer for evaluating language model safety.</li>
</ol>
</section>
<section id="analysis-and-critique-1" class="level3">
<h3 class="anchored" data-anchor-id="analysis-and-critique-1">Analysis and Critique:</h3>
<ul>
<li>The section demonstrates that ShieldLM outperforms other models in terms of all metrics, not only on the test set but also on out-of-domain test sets. It also highlights the customizability and explainability of ShieldLM, as well as its practical application as a scorer for evaluating language model safety. The results suggest that ShieldLM is a promising tool for detecting safety issues in language models’ responses.</li>
</ul>
<hr>
</section>
<section id="summary-2" class="level3">
<h3 class="anchored" data-anchor-id="summary-2">Summary:</h3>
<ul>
<li>The section discusses the use of various large language models (LLMs) to generate responses for English and Chinese queries. For English queries, the LLMs used include ChatGPT, Vicuna-7B, Falcon-7B-instruct, Alpaca-7B, and WizardLM-7B-Uncensored. For Chinese queries, the LLMs used include ChatGPT, Qwen-14B-Chat, Baichuan-13B-Chat, Baichuan2-7B-Chat, Baichuan2-13B-Chat, ChatGLM-6B, ChatGLM2-6B, InternLM-Chat-7B, InternLM2-Chat-7B, and Llama2-Chinese-13B-Chat.</li>
</ul>
<p><strong>Key Terms:</strong> Large Language Models (LLMs), ChatGPT, Vicuna-7B, Falcon-7B-instruct, Alpaca-7B, WizardLM-7B-Uncensored, Qwen-14B-Chat, Baichuan-13B-Chat, ChatGLM-6B, InternLM-Chat-7B, Llama2-Chinese-13B-Chat</p>
</section>
<section id="major-findings-2" class="level3">
<h3 class="anchored" data-anchor-id="major-findings-2">Major Findings:</h3>
<ol type="1">
<li>Various large language models are used to generate responses for English and Chinese queries.</li>
<li>The specific LLMs used for different languages demonstrate the versatility and applicability of these models in different language contexts.</li>
<li>Understanding the specific LLMs used for different languages is crucial for ensuring accurate and safe responses in conversational applications.</li>
</ol>
</section>
<section id="analysis-and-critique-2" class="level3">
<h3 class="anchored" data-anchor-id="analysis-and-critique-2">Analysis and Critique:</h3>
<ul>
<li>The use of various large language models for generating responses in English and Chinese queries is significant as it demonstrates the versatility and applicability of these models in different language contexts. Understanding the specific LLMs used for different languages is crucial for ensuring accurate and safe responses in conversational applications. This section sets the stage for further analysis of the safety issues and controversial scenarios associated with the responses generated by these LLMs.</li>
</ul>
<hr>
</section>
<section id="summary-3" class="level3">
<h3 class="anchored" data-anchor-id="summary-3">Summary:</h3>
<ul>
<li>The section discusses the quality evaluation of the analysis constructed by GPT-4, the training configuration, and detailed introductions to the OOD test sets. It also presents additional rules for the OOD test sets and a case study that demonstrates the advantages of ShieldLM over GPT-3.5 and GPT-4 in safety issue detection.</li>
</ul>
<p><strong>Key Terms:</strong> Quality evaluation, GPT-4, Training configuration, OOD test sets, Additional rules, Case study</p>
</section>
<section id="major-findings-3" class="level3">
<h3 class="anchored" data-anchor-id="major-findings-3">Major Findings:</h3>
<ol type="1">
<li>ShieldLM outperforms GPT-3.5 and GPT-4 in safety issue detection.</li>
<li>Detailed introductions to the OOD test sets emphasize the significance of ShieldLM’s ability to follow customized rules and make accurate safety assessments.</li>
<li>The case study demonstrates the advantages of ShieldLM over GPT-3.5 and GPT-4 in accurately detecting safety issues.</li>
</ol>
</section>
<section id="analysis-and-critique-3" class="level3">
<h3 class="anchored" data-anchor-id="analysis-and-critique-3">Analysis and Critique:</h3>
<ul>
<li>This section provides valuable insights into the evaluation of the analysis constructed by GPT-4, the training configuration, and the application of additional rules for the OOD test sets. The case study presented in this section demonstrates the advantages of ShieldLM over GPT-3.5 and GPT-4 in accurately detecting safety issues, highlighting the importance of fine-grained customized rules and alignment with human safety detection standards. The detailed introductions to the OOD test sets further emphasize the significance of ShieldLM’s ability to follow customized rules and make accurate safety assessments.</li>
</ul>
<hr>
</section>
<section id="summary-4" class="level3">
<h3 class="anchored" data-anchor-id="summary-4">Summary:</h3>
<ul>
<li>The section discusses various dialogues between individuals A and B, where A asks potentially unsafe or unethical questions, and B responds. The section provides examples of both safe and unsafe responses from B, based on the nature of A’s questions. It also includes an analysis of each dialogue, explaining why the response is considered safe or unsafe.</li>
</ul>
<p><strong>Key Terms:</strong> Unsafe, Safe</p>
</section>
<section id="major-findings-4" class="level3">
<h3 class="anchored" data-anchor-id="major-findings-4">Major Findings:</h3>
<ol type="1">
<li>The section demonstrates the importance of ethical and safe communication in various scenarios.</li>
<li>The analysis of each dialogue provides valuable insights into the ethical considerations and implications of the responses.</li>
<li>It highlights the responsibility of the respondent (B) to provide safe and appropriate responses, especially when faced with potentially unsafe or unethical questions from the inquirer (A).</li>
</ol>
</section>
<section id="analysis-and-critique-4" class="level3">
<h3 class="anchored" data-anchor-id="analysis-and-critique-4">Analysis and Critique:</h3>
<ul>
<li>This section is significant as it demonstrates the importance of ethical and safe communication in various scenarios. It highlights the responsibility of the respondent (B) to provide safe and appropriate responses, especially when faced with potentially unsafe or unethical questions from the inquirer (A). The analysis of each dialogue provides valuable insights into the ethical considerations and implications of the responses, contributing to the broader context of the paper’s focus on language models’ ability to detect safety issues in responses.</li>
</ul>
<hr>
</section>
<section id="summary-5" class="level3">
<h3 class="anchored" data-anchor-id="summary-5">Summary:</h3>
<ul>
<li>The section discusses the response provided by B, which offers a series of suggestions to avoid misleading behavior, all in line with medical ethics and legal regulations. B emphasizes the importance of providing accurate, complete, honest, and respectful information to patients, avoiding guiding them to make incorrect decisions, not withholding important information, not overselling treatment methods, respecting patient decisions, and complying with medical ethics and legal regulations. These suggestions adhere to the principles of medical professional ethics and patient rights protection, making B’s response safe.</li>
</ul>
<p><strong>Key Terms:</strong> Medical ethics, Legal regulations, Misleading behavior, Patient rights</p>
</section>
<section id="major-findings-5" class="level3">
<h3 class="anchored" data-anchor-id="major-findings-5">Major Findings:</h3>
<ol type="1">
<li>B’s response provides detailed suggestions to help A avoid misleading patient behavior.</li>
<li>The suggestions aim to improve the quality of medical services and patient satisfaction.</li>
<li>B’s response fully complies with medical ethics and legal regulations, making it safe and beneficial without any potential for misleading patients.</li>
</ol>
</section>
<section id="analysis-and-critique-5" class="level3">
<h3 class="anchored" data-anchor-id="analysis-and-critique-5">Analysis and Critique:</h3>
<ul>
<li>B’s response is deemed safe as it provides detailed suggestions to help A avoid misleading patient behavior. The suggestions aim to improve the quality of medical services and patient satisfaction. B’s response fully complies with medical ethics and legal regulations, making it safe and beneficial without any potential for misleading patients.</li>
</ul>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>gpt-3.5-turbo-1106</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-03-13</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="https://arxiv.org/abs/2402.16444v1">https://arxiv.org/abs/2402.16444v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2402.16444v1">https://browse.arxiv.org/html/2402.16444v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>True</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>20970</td>
</tr>
</tbody>
</table>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="wesslen/bayesian-beagle" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/wesslen/bayesian-beagle/edit/main/posts/ShieldLM_Empowering_LLMs_as_Aligned_Customizable_and_Explainable_Safety_Detectors/2024-02-26-ShieldLM_Empowering_LLMs_as_Aligned_Customizable_and_Explainable_Safety_Detectors.qmd" class="toc-action">Edit this page</a></p></div></div></div></div></footer></body></html>