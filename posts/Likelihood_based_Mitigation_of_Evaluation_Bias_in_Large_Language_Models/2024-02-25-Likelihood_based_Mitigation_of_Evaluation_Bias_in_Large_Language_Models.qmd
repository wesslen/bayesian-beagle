
---
title: "Likelihood-based Mitigation of Evaluation Bias in Large Language Models"
id: "2402.15987v1"
description: "LLMs may have likelihood bias in evaluating natural language generation, but bias can be mitigated."
author: Masanari Ohi, Masahiro Kaneko, Ryuto Koike, Mengsay Loem, Naoaki Okazaki
date: "2024-02-25"
image: "https://browse.arxiv.org/html/2402.15987v1/extracted/5429840/bias_image_data2text_v2.png"
categories: ['programming', 'social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.15987v1/extracted/5429840/bias_image_data2text_v2.png)

### Summary:
- Large Language Models (LLMs) are used to evaluate natural language generation tasks as automated metrics.
- The likelihood, a measure of LLMâ€™s plausibility for a sentence, can vary due to superficial differences in sentences, such as word order and sentence structure.
- The paper investigates the presence and impact of likelihood bias in LLM-based evaluators and proposes a method to mitigate the likelihood bias.
- Experiments in evaluating the data-to-text and grammatical error correction tasks reveal that several LLMs display a likelihood bias, and the proposed method successfully mitigates this bias, improving evaluation performance significantly.

### Major Findings:
1. LLMs exhibit strong likelihood bias, overrating high-likelihood texts and underrating low-likelihood ones compared to human ratings.
2. The proposed method successfully mitigates likelihood bias and improves evaluation performance in data-to-text and grammatical error correction tasks.
3. Non-intrinsic criteria are much more prone to bias compared to intrinsic criteria, suggesting that the effect of likelihood on the evaluation does not necessarily cause a harmful bias on intrinsic criteria as much as on non-intrinsic ones.

### Analysis and Critique:
- The paper effectively identifies and addresses the issue of likelihood bias in LLM-based evaluators, providing a method to quantify and mitigate the bias.
- The limitations of the study, such as the use of in-context learning and the computational budget, are acknowledged and discussed, providing avenues for future research.
- The ethical implications of reducing likelihood bias in LLMs are briefly discussed, highlighting the potential impact on addressing social bias in evaluators.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.15987v1](https://arxiv.org/abs/2402.15987v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.15987v1](https://browse.arxiv.org/html/2402.15987v1)       |
| Truncated       | False       |
| Word Count       | 5223       |