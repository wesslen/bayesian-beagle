
---
title: "Harnessing Multimodal Large Language Models for Multimodal Sequential Recommendation"
id: "2408.09698v2"
description: "MLLM-MSR model proposed for multimodal sequential recommendation, capturing dynamic user preferences with image and text inputs."
author: Yuyang Ye, Zhi Zheng, Yishan Shen, Tianshu Wang, Hengruo Zhang, Peijun Zhu, Runlong Yu, Kai Zhang, Hui Xiong
date: "2024-08-20"
image: "https://browse.arxiv.org/html/2408.09698v2/extracted/5803222/figures/framework.png"
categories: ['recommender']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.09698v2/extracted/5803222/figures/framework.png)

### Summary:

The paper introduces the Multimodal Large Language Model-enhanced Multimodal Sequential Recommendation (MLLM-MSR) model, which aims to capture dynamic user preferences in a two-stage user preference summarization method. The model utilizes an MLLM-based item-summarizer to extract image features and convert them into text, followed by a recurrent user preference summarization generation paradigm to capture the changes in user preferences. The MLLM-based recommender is then fine-tuned using Supervised Fine-Tuning (SFT) techniques. The proposed model is evaluated across various datasets, demonstrating its effectiveness in capturing and adapting to evolving user preferences.

### Major Findings:

1. The MLLM-MSR model introduces a two-stage user preference summarization method to capture dynamic user preferences, utilizing an MLLM-based item-summarizer and a recurrent user preference summarization generation paradigm.
2. The MLLM-based recommender is fine-tuned using Supervised Fine-Tuning (SFT) techniques to enable the model for multi-modal recommendation tasks.
3. Extensive evaluations across various datasets validate the effectiveness of MLLM-MSR, showcasing its superior ability to capture and adapt to the evolving dynamics of user preferences.

### Analysis and Critique:

The paper presents an innovative approach to multimodal sequential recommendation by leveraging MLLMs. The proposed model, MLLM-MSR, demonstrates promising results in capturing and adapting to dynamic user preferences. However, the paper does not discuss potential limitations or challenges in implementing the model, such as computational complexity, scalability, or the need for large-scale training data. Additionally, the paper does not provide a comparison with other state-of-the-art multimodal sequential recommendation models, which could further validate the effectiveness of the proposed approach. Future research could address these limitations and explore the potential of MLLM-MSR in real-world applications.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-27       |
| Abstract | [https://arxiv.org/abs/2408.09698v2](https://arxiv.org/abs/2408.09698v2)        |
| HTML     | [https://browse.arxiv.org/html/2408.09698v2](https://browse.arxiv.org/html/2408.09698v2)       |
| Truncated       | False       |
| Word Count       | 6167       |