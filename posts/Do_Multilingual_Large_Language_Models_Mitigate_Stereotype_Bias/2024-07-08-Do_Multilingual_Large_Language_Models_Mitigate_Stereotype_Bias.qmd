
---
title: "Do Multilingual Large Language Models Mitigate Stereotype Bias?"
id: "2407.05740v1"
description: "Multilingual training in LLMs reduces bias and improves prediction accuracy compared to monolingual models."
author: Shangrui Nie, Michael Fromm, Charles Welch, Rebekka GÃ¶rge, Akbar Karimi, Joan Plepi, Nazia Afsan Mowmita, Nicolas Flores-Herr, Mehdi Ali, Lucie Flek
date: "2024-07-08"
image: "../../img/2407.05740v1/image_1.png"
categories: ['social-sciences']
format:
  html:
    code-overflow: wrap
---

![](../../img/2407.05740v1/image_1.png)

Summary:
This paper investigates the impact of multilingual training on bias mitigation in large language models (LLMs). The authors train six LLMs of identical size (2.6B parameters) and architecture, including five monolingual models (English, German, French, Italian, and Spanish) and one multilingual model. The models are evaluated on standard bias benchmarks, which are automatically translated and verified for both translation quality and bias preservation. The results show that multilingual training effectively mitigates bias, and multilingual models achieve not only lower bias but also superior prediction accuracy compared to monolingual models with the same amount of training data, model architecture, and size.

Major Findings:
1. Multilingual training effectively mitigates bias in LLMs.
2. Multilingual models achieve lower bias than monolingual models with the same amount of training data, model architecture, and size.
3. Multilingual models outperform monolingual models in prediction accuracy.

Analysis and Critique:
The paper presents a well-structured and coherent summary of the research, providing a clear overview of the methodology and findings. The use of a controlled setting and the evaluation of both bias and prediction accuracy are strengths of the study. However, the paper does not discuss potential limitations or shortcomings of the research, such as the generalizability of the findings to other languages or the impact of different translation methods on the results. Additionally, the paper does not address the potential for biases to be introduced during the translation process, which could affect the validity of the results. Further research is needed to explore these issues and to validate the findings in other contexts.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-09       |
| Abstract | [https://arxiv.org/abs/2407.05740v1](https://arxiv.org/abs/2407.05740v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.05740v1](https://browse.arxiv.org/html/2407.05740v1)       |
| Truncated       | False       |
| Word Count       | 21234       |