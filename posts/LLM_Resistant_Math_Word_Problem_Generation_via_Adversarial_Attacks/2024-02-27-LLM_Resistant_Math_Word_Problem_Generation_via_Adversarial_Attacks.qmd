
---
title: "LLM-Resistant Math Word Problem Generation via Adversarial Attacks"
id: "2402.17916v1"
description: "LLMs challenge fair assessment. Adversarial examples degrade math problem-solving ability. Shared vulnerabilities identified. Code available."
author: Roy Xie, Chengxuan Huang, Junlin Wang, Bhuwan Dhingra
date: "2024-02-27"
image: "https://browse.arxiv.org/html/2402.17916v1/extracted/5435783/images/Method_overview.drawio.png"
categories: ['education', 'security', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.17916v1/extracted/5435783/images/Method_overview.drawio.png)

### Summary:
Large language models (LLMs) have transformed education, posing challenges for fair evaluation of students' problem-solving abilities. This study explores generating adversarial examples for math word problems (MWPs) to degrade LLMs' problem-solving ability. The study leverages abstract syntax trees to systematically generate adversarial problems by editing numeric values in MWPs. Experiments demonstrate that the method significantly degrades LLMs' math problem-solving ability. The study identifies shared vulnerabilities among LLMs and proposes a cost-effective approach to attack high-cost models. Human evaluations confirm the coherence and difficulty level of the generated problems.

### Major Findings:
1. The study introduces a new paradigm for generating homework assignments that LLMs cannot solve by utilizing adversarial attacks.
2. Adversarial examples are generated by editing the numeric values in MWPs, significantly degrading LLMs' math problem-solving ability.
3. The study identifies shared vulnerabilities among LLMs and proposes a cost-effective approach to attack high-cost models.

### Analysis and Critique:
- The study does not empirically validate the correlation between the complexity of problems generated and the actual difficulty perceived by human students.
- Imperfect logical coherence in some cases may affect the educational context of the generated problems.
- The study does not address the alteration of words in questions, which may represent numeric values.
- The approach may exacerbate educational inequality by placing educators without access to resources at a disadvantage.
- The study acknowledges potential ethical concerns regarding the exacerbation of educational inequality.

Overall, the study provides valuable insights into LLMs' limitations and offers a novel approach to address concerns about academic dishonesty. However, it is important to address potential problems related to the perceived difficulty level, logical coherence, and educational inequality. Further research is needed to validate the approach's impact on educational standards and student evaluation.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.17916v1](https://arxiv.org/abs/2402.17916v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.17916v1](https://browse.arxiv.org/html/2402.17916v1)       |
| Truncated       | False       |
| Word Count       | 8288       |