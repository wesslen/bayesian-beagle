
---
title: "De-Hallucinator: Iterative Grounding for LLM-Based Code Completion"
id: "2401.01701v1"
description: "LLMs have limitations in code completion due to a lack of project-specific context. De-Hallucinator addresses this by integrating API references, improving code predictions."
author: Aryaz Eghbali, Michael Pradel
date: "2024-01-03"
image: "https://browse.arxiv.org/html/2401.01701v1/x1.png"
categories: ['robustness', 'programming']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.01701v1/x1.png)

# Summary

## Takeaways
- Large language models (LLMs) have been successful in code completion, but they lack knowledge of project-specific APIs, resulting in inaccurate completions and "hallucinated" code.
- De-Hallucinator addresses this challenge by iteratively querying the LLM with increasingly suitable context information, thus improving the predicted code and recall of correctly predicted API usages.
- The approach is language-agnostic and designed to work with any off-the-shelf LLM trained on code, making it a versatile solution for improving code completion accuracy.

## Introduction
- Large language models (LLMs) have shown promise in code completion tasks, but they lack project-specific API knowledge, leading to incomplete and inaccurate code predictions.

## Approach
### Static Pre-Analysis
- The approach utilizes CodeQL to statically analyze code and extract API references for fast retrieval during the code completion process. The extracted API references are then indexed for efficient querying.

### Retrieval of Related APIs
- De-Hallucinator retrieves relevant API references based on similarity to the input code, providing a ranked list of project-specific API references to be added to the prompt.

### Prompt Construction
- The augmented prompt is designed to resemble "normal" code and consists of a commented block of relevant API references followed by the original prompt.

### Integration with the LLM
- De-Hallucinator queries the LLM as a black box and post-processes the completion to make it syntactically correct and remove extraneous completions.

## Evaluation
- The approach is evaluated on four state-of-the-art LLMs for code completion, demonstrating consistent improvements in predicted code, edit distance, and recall of correctly predicted API usages compared to querying the model with a fixed prompt.

# Critique
- The paper does not address potential trade-offs or limitations of the De-Hallucinator approach.
- There is no discussion regarding the scalability of the approach to larger codebases or its real-world applicability.
- The evaluation could benefit from a broader set of programming languages and a comparison with other state-of-the-art code completion techniques.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-05       |
| Abstract | [http://arxiv.org/abs/2401.01701v1](http://arxiv.org/abs/2401.01701v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.01701v1](https://browse.arxiv.org/html/2401.01701v1)       |
| Truncated       | True       |
| Word Count       | 14084       |