
---
title: "Blinded by Generated Contexts: How Language Models Merge Generated and Retrieved Contexts for Open-Domain QA?"
id: "2401.11911v1"
description: "LLMs favor generated over retrieved contexts due to similarity and segmentation issues."
author: Hexiang Tan, Fei Sun, Wanli Yang, Yuanzhuo Wang, Qi Cao, Xueqi Cheng
date: "2024-01-22"
image: "../../../bayesian-beagle.png"
categories: ['architectures', 'hci']
format:
  html:
    code-overflow: wrap
---

![](None)

### Summary:

The article addresses the issue of context utilization in Large Language Models (LLMs) and the bias towards generated contexts over retrieved contexts. It discusses the construction of context-conflicting datasets, the impact of context length on LLMs' merging mechanisms, and the regulation of generated context length. The study also compares the performance of different LLMs in generating context and analyzes the similarity distribution with aggregation strategies.

### Major Findings:
1. LLMs exhibit a significant bias towards generated contexts over retrieved contexts.
2. The semantic completeness and passage segmentation of retrieved contexts significantly impact LLMs' preference for context utilization.
3. Different LLMs struggle with controlling the length of generated contexts, with GPT 4 being more effective in this aspect.

### Analysis and Critique:
The article provides valuable insights into the bias of LLMs towards generated contexts and the challenges in effectively merging generated and retrieved contexts. The study highlights the importance of semantic completeness and passage segmentation in addressing this bias and emphasizes the need for improved integration methods. However, the article could benefit from further exploration of advanced passage segmentation strategies and the development of more accurate language models. Additionally, the comparison of LLMs' performance in generating context offers practical implications for enhancing question-answering tasks.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-02       |
| Abstract | [https://arxiv.org/abs/2401.11911v1](https://arxiv.org/abs/2401.11911v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.11911v1](https://browse.arxiv.org/html/2401.11911v1)       |
| Truncated       | True       |
| Word Count       | 30195       |