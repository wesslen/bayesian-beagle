
---
title: "TrustNavGPT: Modeling Uncertainty to Improve Trustworthiness of Audio-Guided LLM-Based Robot Navigation"
id: "2408.01867v1"
description: "LLM-based agent, TrustNavGPT, uses affective cues in speech for trust assessment, improving robotic navigation and resisting adversarial attacks."
author: Xingpeng Sun, Yiran Zhang, Xindi Tang, Amrit Singh Bedi, Aniket Bera
date: "2024-08-03"
image: "https://browse.arxiv.org/html/2408.01867v1/extracted/5772728/imgs/cover_v2.png"
categories: ['hci', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.01867v1/extracted/5772728/imgs/cover_v2.png)

### Summary:

The paper introduces TrustNavGPT, an LLM-based audio-guided navigation agent that uses affective cues in spoken communication to assess the trustworthiness of human commands and make effective, safe decisions. The system integrates both audio transcription and affective vocal features, including pitch, loudness, and speech rate, to improve robot ability in audio-guided navigation under uncertainty. The paper also proposes a motion planning tool library that translates high-level LLM language commands into robot actions, dynamic perception, and prediction.

### Major Findings:

1. TrustNavGPT achieves over an 80% success rate in robot navigation tasks, significantly refining LLMs' proficiency in interpreting human uncertainty within navigational contexts.
2. The integration of a motion planning tool library allows for a more human-like, audio-guided navigational capability in robots.
3. TrustNavGPT significantly surpasses existing LLM-based navigation techniques, by a 55% improvement in achieving successful target arrival under conditions of human navigational uncertainty with 70%+ closer to the target.

### Analysis and Critique:

The paper presents a novel approach to improving the trustworthiness of audio-guided LLM-based robot navigation by incorporating affective cues in spoken communication. The proposed system, TrustNavGPT, demonstrates promising results in handling human uncertainty and improving the success rate of robot navigation tasks. However, the paper does not discuss the potential limitations of the system, such as its performance in noisy environments or with speakers with different accents or speech patterns. Additionally, the paper does not provide a detailed comparison with other existing methods for handling uncertainty in LLM-based navigation. Further research is needed to evaluate the system's performance in real-world scenarios and compare it with other state-of-the-art methods.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-06       |
| Abstract | [https://arxiv.org/abs/2408.01867v1](https://arxiv.org/abs/2408.01867v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.01867v1](https://browse.arxiv.org/html/2408.01867v1)       |
| Truncated       | False       |
| Word Count       | 6149       |