
---
title: "Learning Fine-Grained Grounded Citations for Attributed Large Language Models"
id: "2408.04568v1"
description: "FRONT framework improves LLM citation quality, outperforming baselines and ChatGPT in ALCE benchmark."
author: Lei Huang, Xiaocheng Feng, Weitao Ma, Yuxuan Gu, Weihong Zhong, Xiachong Feng, Weijiang Yu, Weihua Peng, Duyu Tang, Dandan Tu, Bing Qin
date: "2024-08-08"
image: "../../img/2408.04568v1/image_1.png"
categories: ['robustness']
format:
  html:
    code-overflow: wrap
---

![](../../img/2408.04568v1/image_1.png)

**Summary:**

This paper introduces FRONT, a training framework designed to teach large language models (LLMs) to generate Fine-gRained grOuNded citations. The framework aims to improve citation quality and facilitate fine-grained verification by grounding model outputs in fine-grained supporting quotes. The authors evaluate FRONT on the ALCE benchmark and demonstrate its efficacy in generating superior grounded responses and highly supportive citations. The framework significantly outperforms all baselines, achieving an average of 14.21% improvement in citation quality across all datasets.

**Major Findings:**

1. FRONT demonstrates superior performance in generating grounded responses and highly supportive citations, outperforming all baselines on the ALCE benchmark.
2. The framework significantly improves citation quality, achieving an average of 14.21% improvement across all datasets.
3. FRONT enables LLMs to generate less hallucination and demonstrates remarkable generalization across different base models.

**Analysis and Critique:**

The paper presents a novel approach to improving citation quality and fine-grained verification in LLMs. The proposed framework, FRONT, demonstrates promising results in generating grounded responses and highly supportive citations. However, the paper does not discuss the potential limitations or shortcomings of the framework, such as the computational resources required for training or the scalability of the approach. Additionally, the evaluation is limited to the ALCE benchmark, and further experiments on other datasets would provide a more comprehensive understanding of the framework's performance. The authors also do not discuss the potential impact of the framework on the interpretability and transparency of LLMs, which is an important consideration in the development of AI systems.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-13       |
| Abstract | [https://arxiv.org/abs/2408.04568v1](https://arxiv.org/abs/2408.04568v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.04568v1](https://browse.arxiv.org/html/2408.04568v1)       |
| Truncated       | False       |
| Word Count       | 22635       |