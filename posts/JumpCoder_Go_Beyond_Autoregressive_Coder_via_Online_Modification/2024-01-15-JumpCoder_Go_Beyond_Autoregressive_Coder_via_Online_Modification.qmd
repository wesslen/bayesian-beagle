
---
title: "JumpCoder: Go Beyond Autoregressive Coder via Online Modification"
id: "2401.07870v1"
description: "JumpCoder improves code large language models with non-sequential generation, achieving significant performance gains."
author: Mouxiang Chen, Hao Tian, Zhongxin Liu, Xiaoxue Ren, Jianling Sun
date: "2024-01-15"
image: "../../../bayesian-beagle.png"
categories: ['programming']
format:
  html:
    code-overflow: wrap
---

![](None)

### Summary:

The article introduces JUMPCODER, a model-agnostic framework designed to enhance code generation performance by allowing online modification and non-sequential generation. It addresses the limitations of autoregressive generation in code language models (LLMs) and consistently improves performance across multiple benchmarks and programming languages. The results demonstrate the effectiveness of JUMPCODER in enhancing the overall quality of generated code and improving the efficiency of code generation tasks.

### Major Findings:
1. JUMPCODER consistently enhances performance across various benchmarks and programming languages.
2. The framework addresses the limitations of autoregressive generation and provides online modification during the generation process.
3. The example programs showcase the versatility and applicability of JUMPCODER across different programming languages.

### Analysis and Critique:
The article presents a significant contribution to the field of code generation by introducing a novel framework, JUMPCODER, that addresses the limitations of autoregressive generation in code LLMs. The results demonstrate consistent enhancements in performance, highlighting the potential of JUMPCODER to improve the overall quality of generated code. The framework's innovative approach, including the infill-first, judge-later strategy and the use of AST parser and Generation Model Scoring, sets it apart as a valuable advancement in code generation. However, further research is needed to explore the generalization of online modification to other tasks and to enhance collaboration between generation and infilling models. Additionally, the article could benefit from a more in-depth discussion of potential biases or limitations in the experimental design.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-31       |
| Abstract | [https://arxiv.org/abs/2401.07870v1](https://arxiv.org/abs/2401.07870v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.07870v1](https://browse.arxiv.org/html/2401.07870v1)       |
| Truncated       | True       |
| Word Count       | 18949       |