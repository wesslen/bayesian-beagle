
---
title: "Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models"
id: "2408.08210v1"
description: "LLMs' reasoning abilities are assessed using probability of necessity and sufficiency, offering insights into their real-world reasoning capabilities."
author: Javier Gonz√°lez, Aditya V. Nori
date: "2024-08-15"
image: "https://browse.arxiv.org/html/2408.08210v1/extracted/5793885/prompts.png"
categories: ['social-sciences', 'education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.08210v1/extracted/5793885/prompts.png)

### Summary:

This paper introduces a theoretical and practical framework to assess the reasoning abilities of large language models (LLMs) using probabilistic measures of necessity (PN) and sufficiency (PS). The authors argue that LLMs can be viewed as abstract machines that process information through a natural language interface, and they examine the conditions under which it is possible to compute suitable approximations of PN and PS. The research aims to gain a deeper understanding of when LLMs are capable of reasoning, as illustrated by a series of math examples.

### Major Findings:

1. LLMs can be viewed as abstract machines that process information through a natural language interface, and their reasoning abilities can be assessed using probabilistic measures of necessity (PN) and sufficiency (PS).
2. The paper introduces a systematic method to assess the reasoning capabilities of LLMs by examining the concepts of necessity and sufficiency, which are key elements of logical reasoning.
3. The authors show that when a problem can be solved via a reasoning graph of boolean conditions, denoted by G, the PN and PS can be computed using a causal model underlying G.
4. The paper presents an informal illustration of the reasoning test advocated in this paper, focusing on the specific problem of determining whether a number N is divisible by 6.
5. The authors demonstrate that the closer the estimated PN/PS values to the actual PN/PS values, the better the LLM is at reasoning.

### Analysis and Critique:

The paper presents a novel approach to assessing the reasoning abilities of LLMs using probabilistic measures of necessity and sufficiency. The authors provide a clear and well-structured framework for evaluating LLMs' reasoning abilities, which could be useful for future research in this area. However, the paper does not address the limitations of this approach, such as the dependence on causal reasoning graphs and the restriction to boolean variables. Additionally, the findings are based on an LLM's reasoning abilities as determined by two specific types of prompts, which may not be representative of the LLM's overall reasoning abilities. Overall, the paper provides valuable insights into the reasoning abilities of LLMs, but further research is needed to address the limitations of this approach.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-20       |
| Abstract | [https://arxiv.org/abs/2408.08210v1](https://arxiv.org/abs/2408.08210v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.08210v1](https://browse.arxiv.org/html/2408.08210v1)       |
| Truncated       | False       |
| Word Count       | 8021       |