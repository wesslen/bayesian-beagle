
---
title: "Evaluation of Instruction-Following Ability for Large Language Models on Story-Ending Generation"
id: "2406.16356v1"
description: "LLMs' instruction-following ability in story-ending generation aligns with human evaluation, with open-source models nearing GPT-3.5 performance."
author: Rem Hida, Junki Ohmura, Toshiyuki Sekiya
date: "2024-06-24"
image: "https://browse.arxiv.org/html/2406.16356v1/extracted/5686874/figure/TaskDescription.png"
categories: ['social-sciences', 'education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.16356v1/extracted/5686874/figure/TaskDescription.png)

### Summary:

- The paper focuses on evaluating the instruction-following ability of Large Language Models (LLMs) in the context of story-ending generation.
- The authors propose an automatic evaluation pipeline that utilizes a machine reading comprehension (MRC) model to determine whether the generated story-ending reflects the instruction.
- The proposed metric, Instruction Following Score from the MRC model (IFSM), is shown to align with human evaluation.
- The experiments confirm that recent open-source LLMs can achieve instruction-following performance close to GPT-3.5.

### Major Findings:

1. The proposed IFSM metric aligns with human evaluation, demonstrating its validity for assessing instruction-following ability in story-ending generation.
2. Recent open-source LLMs, such as Mistral-7B and Llama2-7B, perform best on the IFSM, and Llama3-8B achieves high Dissimilarity.
3. The open-source LLMs are comparable to GPT-3.5 in terms of instruction-following ability.

### Analysis and Critique:

- The paper's focus on evaluating instruction-following ability in story-ending generation is a valuable contribution to the field, as it requires creativity and elicits various user instructions for LLMs.
- The proposed IFSM metric provides a reliable way to assess instruction-following ability, which can help researchers quantify the capabilities of LLMs beyond easily verifiable instructions.
- However, the paper has some limitations, such as being limited to the use of the Possible Datasets and not addressing the multilingual aspect of instruction-following.
- The paper also acknowledges potential risks, such as LLMs following instructions aimed at eliciting toxic or harmful information, and the need for further analysis of biases in LLM evaluations.
- The authors suggest that their approach can be adapted to existing multilingual datasets for instruction-following evaluation, which is a promising direction for future work.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-07       |
| Abstract | [https://arxiv.org/abs/2406.16356v1](https://arxiv.org/abs/2406.16356v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.16356v1](https://browse.arxiv.org/html/2406.16356v1)       |
| Truncated       | False       |
| Word Count       | 4154       |