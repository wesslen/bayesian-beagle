
---
title: "Semantic Structure-Mapping in LLM and Human Analogical Reasoning"
id: "2406.13803v1"
description: "LLMs approach human-level performance in semantic structure-mapping tasks but aren't entirely human-like."
author: Sam Musker, Alex Duchnowski, Raphaël Millière, Ellie Pavlick
date: "2024-06-19"
image: "https://browse.arxiv.org/html/2406.13803v1/extracted/5679376/Images/Comparison_Default_MMLU.png"
categories: ['education', 'hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.13803v1/extracted/5679376/Images/Comparison_Default_MMLU.png)

### Summary:

This study investigates the ability of humans and Large Language Models (LLMs) to perform analogical reasoning tasks that require the transfer of semantic structure and content from one domain to another. The researchers tested human subjects and LLMs on various task variations and found that advanced LLMs match human performance across many tasks. However, humans and LLMs respond differently to certain task variations and semantic distractors. The data suggest that LLMs are approaching human-level performance on these important cognitive tasks but are not entirely human-like.

### Major Findings:

1. Advanced LLMs match human performance across many task variations in analogical reasoning tasks that require the transfer of semantic structure and content.
2. Humans and LLMs respond differently to certain task variations and semantic distractors, indicating that LLMs are not entirely human-like in their cognitive abilities.
3. The study's findings contribute to the ongoing debate about analogical reasoning and corroborate both work arguing for impressive LLM performance and work highlighting important mechanistic differences between humans and LLMs.

### Analysis and Critique:

The study provides valuable insights into the cognitive abilities of LLMs and their potential to serve as computational models of human behavior. However, several limitations and unanswered questions remain. The study focuses on a specific type of analogical reasoning task, and it is unclear how well the findings generalize to other cognitive tasks. Additionally, the study does not explore the potential impact of different LLM architectures or training methods on performance. Further research is needed to address these questions and to better understand the underlying mechanisms that enable LLMs to perform analogical reasoning tasks.

Markdown formatted summary:

**Summary:**

- The study investigates the ability of humans and LLMs to perform analogical reasoning tasks that require the transfer of semantic structure and content.
- Advanced LLMs match human performance across many task variations, but humans and LLMs respond differently to certain task variations and semantic distractors.
- The data suggest that LLMs are approaching human-level performance on these important cognitive tasks but are not entirely human-like.

**Major Findings:**

1. Advanced LLMs match human performance across many task variations.
2. Humans and LLMs respond differently to certain task variations and semantic distractors.
3. The

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-23       |
| Abstract | [https://arxiv.org/abs/2406.13803v1](https://arxiv.org/abs/2406.13803v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.13803v1](https://browse.arxiv.org/html/2406.13803v1)       |
| Truncated       | False       |
| Word Count       | 12911       |