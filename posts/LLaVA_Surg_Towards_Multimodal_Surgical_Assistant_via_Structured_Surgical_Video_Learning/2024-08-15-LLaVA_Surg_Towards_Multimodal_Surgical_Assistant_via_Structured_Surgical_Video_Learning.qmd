
---
title: "LLaVA-Surg: Towards Multimodal Surgical Assistant via Structured Surgical Video Learning"
id: "2408.07981v1"
description: "New dataset Surg-QA enables training of LLaVA-Surg, a model excelling in open-ended surgical video Q&A, outperforming general-domain models."
author: Jiajie Li, Garrett Skinner, Gene Yang, Brian R Quaranto, Steven D Schwaitzberg, Peter C W Kim, Jinjun Xiong
date: "2024-08-15"
image: "https://browse.arxiv.org/html/2408.07981v1/x1.png"
categories: ['robustness', 'education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.07981v1/x1.png)

### Summary:

The paper introduces LLaVA-Surg, a novel vision-language conversational assistant designed to answer open-ended questions about surgical videos. The authors create a new dataset, Surg-QA, consisting of 102,000 surgical video-instruction pairs, the largest of its kind. They propose a novel two-stage question-answer generation pipeline with LLM to learn surgical knowledge in a structured manner from publicly available surgical lecture videos. This pipeline significantly reduces task complexity and mitigates the risk of LLM hallucinations during question-answer generation. The authors train LLaVA-Surg on this Surg-QA dataset and conduct comprehensive evaluations on zero-shot surgical video question-answering tasks. The results show that LLaVA-Surg significantly outperforms all previous general-domain models, demonstrating exceptional multimodal conversational skills in answering open-ended questions about surgical videos.

### Major Findings:

1. The authors create a new dataset, Surg-QA, consisting of 102,000 surgical video-instruction pairs, the largest of its kind.
2. They propose a novel two-stage question-answer generation pipeline with LLM to learn surgical knowledge in a structured manner from publicly available surgical lecture videos.
3. The authors train LLaVA-Surg, a novel vision-language conversational assistant, on the Surg-QA dataset and conduct comprehensive evaluations on zero-shot surgical video question-answering tasks.
4. LLaVA-Surg significantly outperforms all previous general-domain models, demonstrating exceptional multimodal conversational skills in answering open-ended questions about surgical videos.

### Analysis and Critique:

The paper presents a significant contribution to the field of surgical video understanding and question-answering. The creation of the Surg-QA dataset and the development of the LLaVA-Surg model are important steps towards improving the quality of surgical video analysis and understanding. However, the paper does not discuss any potential limitations or shortcomings of the proposed method. It would be beneficial to include an analysis of the potential biases in the data or the model, as well as any methodological issues that may have arisen during

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-20       |
| Abstract | [https://arxiv.org/abs/2408.07981v1](https://arxiv.org/abs/2408.07981v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.07981v1](https://browse.arxiv.org/html/2408.07981v1)       |
| Truncated       | False       |
| Word Count       | 5596       |