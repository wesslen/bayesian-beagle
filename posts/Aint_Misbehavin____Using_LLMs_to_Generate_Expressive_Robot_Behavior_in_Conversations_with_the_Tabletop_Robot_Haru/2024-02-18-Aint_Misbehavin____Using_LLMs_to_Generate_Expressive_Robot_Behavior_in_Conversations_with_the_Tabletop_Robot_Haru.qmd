
---
title: "Ain't Misbehavin' -- Using LLMs to Generate Expressive Robot Behavior in Conversations with the Tabletop Robot Haru"
id: "2402.11571v1"
description: "TL;DR: Social robots use large language models for dynamic, expressive conversations, with some limitations."
author: Zining Wang, Paul Reisert, Eric Nichols, Randy Gomez
date: "2024-02-18"
image: "../../img/2402.11571v1/image_1.png"
categories: ['robustness', 'education', 'prompt-engineering', 'social-sciences', 'hci']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.11571v1/image_1.png)

### Summary:
- This article discusses the integration of large language models (LLMs) into social robots to achieve more dynamic and expressive conversations.
- The authors introduce a fully-automated conversation system that leverages LLMs to generate robot responses with expressive behaviors congruent with the robotâ€™s personality.
- The system incorporates robot behavior with two modalities: a text-to-speech (TTS) engine capable of various delivery styles and a library of physical actions for the robot.
- A pilot study was conducted where volunteers chatted with a social robot using the proposed system, and their feedback was analyzed.

### Major Findings:
1. LLM-Driven Conversations: The article discusses the application of LLMs to enable social robots to understand and participate in open-ended conversations while generating context-appropriate expressive robot behavior.
2. Social Robot: The tabletop robot Haru is selected for the study, designed to excel in multimodal communication and convey emotions with its expressive capabilities.
3. Emo-text: The article introduces the Emo-text module, which is responsible for the generation of expressive robot behaviors to enhance the robot's expressiveness during conversations.

### Analysis and Critique:
- Feedback Analysis: The pilot study showed that participants found the robot to be engaging, empathetic, and helpful. However, issues with the LLM, such as slow responses, repetitive or confusing outputs, and excessively lengthy responses, were identified as potential problems.
- Error Analysis: The study revealed that ASR problems were a common source of errors, but the LLM was often able to recover conversations. However, a small class of more serious LLM errors, including ethical violations, hallucinations, and repetitions, threaten to derail conversations and hamper adoption.
- Discussion: The article highlights the need for improvements in both LLM response handling and the ASR system, as well as a reconsideration of the conversational structure employed.

Overall, the article provides valuable insights into the integration of LLMs into social robots for more dynamic and expressive conversations. However, it also raises important issues related to LLM errors and ASR problems that need to be addressed for successful adoption. Further research and refinement of the proposed system are recommended.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.11571v1](https://arxiv.org/abs/2402.11571v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.11571v1](https://browse.arxiv.org/html/2402.11571v1)       |
| Truncated       | False       |
| Word Count       | 8246       |