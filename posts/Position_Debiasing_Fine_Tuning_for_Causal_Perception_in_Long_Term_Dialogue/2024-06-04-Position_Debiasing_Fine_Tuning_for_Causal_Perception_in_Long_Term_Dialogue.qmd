
---
title: "Position Debiasing Fine-Tuning for Causal Perception in Long-Term Dialogue"
id: "2406.02002v1"
description: "CPD method alleviates position bias in LLMs, improving long-term dialogue relevance."
author: Shixuan Fan, Wei Wei, Wendi Li, Xian-Ling Mao, Wenfeng Xie, Dangyang Chen
date: "2024-06-04"
image: "https://browse.arxiv.org/html/2406.02002v1/x1.png"
categories: ['programming']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.02002v1/x1.png)

**Summary:**

The paper proposes a novel method, Causal Perception long-term Dialogue framework (CPD), to alleviate the position bias in large language models (LLMs) for long-term dialogue tasks. The CPD framework employs perturbation-based causal variable discovery to extract causally relevant utterances from dialogue history and enhances the model's causal perception during fine-tuning. The framework includes a local-position awareness method for inter-sentence position correlation elimination and a causal-perception fine-tuning strategy to improve the model's ability to discover causal invariant factors. Experimental results on two datasets demonstrate that the proposed method effectively alleviates position bias and achieves significant progress compared to existing baselines.

**Major Findings:**

1. The CPD framework effectively alleviates position bias in LLMs for long-term dialogue tasks.
2. The local-position awareness method helps models extract causally relevant utterances based on perturbations.
3. The causal-perception fine-tuning strategy enhances the model's ability to discover causal invariant factors.

**Analysis and Critique:**

The paper presents a well-structured and coherent summary of the proposed CPD framework for addressing position bias in LLMs for long-term dialogue tasks. The use of perturbation-based causal variable discovery and the local-position awareness method are innovative approaches to extract causally relevant utterances from dialogue history. The causal-perception fine-tuning strategy also provides a promising direction for improving the model's ability to discover causal invariant factors.

However, the paper could benefit from a more detailed analysis of the limitations and potential biases of the proposed method. For instance, the paper does not discuss the potential impact of the perturbation-based approach on the model's performance or the generalizability of the method to other types of dialogue tasks. Additionally, the paper could provide more insights into the potential challenges and trade-offs in implementing the proposed method in real-world applications.

Overall, the paper presents a promising approach to addressing position bias in LLMs for long-term dialogue tasks. The proposed CPD framework and the experimental results provide valuable insights into the potential of perturbation-based causal variable discovery and causal-perception fine-t

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-23       |
| Abstract | [https://arxiv.org/abs/2406.02002v1](https://arxiv.org/abs/2406.02002v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.02002v1](https://browse.arxiv.org/html/2406.02002v1)       |
| Truncated       | False       |
| Word Count       | 7030       |