[
  {
    "objectID": "posts/Large_Legal_Fictions__Profiling_Legal_Hallucinations_in_Large_Language_Models/2024-01-02-Large_Legal_Fictions__Profiling_Legal_Hallucinations_in_Large_Language_Models.html#appendix",
    "href": "posts/Large_Legal_Fictions__Profiling_Legal_Hallucinations_in_Large_Language_Models/2024-01-02-Large_Legal_Fictions__Profiling_Legal_Hallucinations_in_Large_Language_Models.html#appendix",
    "title": "Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01301v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01301v1\n\n\nTruncated\nTrue\n\n\nWord Count\n21736"
  },
  {
    "objectID": "posts/Your_Student_is_Better_Than_Expected__Adaptive_Teacher_Student_Collaboration_for_Text_Conditional_Diffusion_Models/2023-12-17-Your_Student_is_Better_Than_Expected__Adaptive_Teacher_Student_Collaboration_for_Text_Conditional_Diffusion_Models.html#appendix",
    "href": "posts/Your_Student_is_Better_Than_Expected__Adaptive_Teacher_Student_Collaboration_for_Text_Conditional_Diffusion_Models/2023-12-17-Your_Student_is_Better_Than_Expected__Adaptive_Teacher_Student_Collaboration_for_Text_Conditional_Diffusion_Models.html#appendix",
    "title": "Your Student is Better Than Expected: Adaptive Teacher-Student Collaboration for Text-Conditional Diffusion Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10835v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10835v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11132"
  },
  {
    "objectID": "posts/A_Prompt_Learning_Framework_for_Source_Code_Summarization/2023-12-26-A_Prompt_Learning_Framework_for_Source_Code_Summarization.html#appendix",
    "href": "posts/A_Prompt_Learning_Framework_for_Source_Code_Summarization/2023-12-26-A_Prompt_Learning_Framework_for_Source_Code_Summarization.html#appendix",
    "title": "A Prompt Learning Framework for Source Code Summarization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16066v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16066v1\n\n\nTruncated\nTrue\n\n\nWord Count\n16076"
  },
  {
    "objectID": "posts/Ensemble_Learning_to_Assess_Dynamics_of_Affective_Experience_Ratings_and_Physiological_Change/2023-12-26-Ensemble_Learning_to_Assess_Dynamics_of_Affective_Experience_Ratings_and_Physiological_Change.html#appendix",
    "href": "posts/Ensemble_Learning_to_Assess_Dynamics_of_Affective_Experience_Ratings_and_Physiological_Change/2023-12-26-Ensemble_Learning_to_Assess_Dynamics_of_Affective_Experience_Ratings_and_Physiological_Change.html#appendix",
    "title": "Ensemble Learning to Assess Dynamics of Affective Experience Ratings and Physiological Change",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16036v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16036v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8064"
  },
  {
    "objectID": "posts/LLaMA_Beyond_English__An_Empirical_Study_on_Language_Capability_Transfer/2024-01-02-LLaMA_Beyond_English__An_Empirical_Study_on_Language_Capability_Transfer.html#appendix",
    "href": "posts/LLaMA_Beyond_English__An_Empirical_Study_on_Language_Capability_Transfer/2024-01-02-LLaMA_Beyond_English__An_Empirical_Study_on_Language_Capability_Transfer.html#appendix",
    "title": "LLaMA Beyond English: An Empirical Study on Language Capability Transfer",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01055v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01055v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7734"
  },
  {
    "objectID": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#key-findings",
    "href": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#key-findings",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Key Findings",
    "text": "Key Findings\n\nInnovative Integration: The Viz system integrates Quantized Low-Rank Adapters (QLoRA) within a marketplace framework, revolutionizing the accessibility and efficiency of large language models (LLMs).\nAddressing Challenges: By reducing computational overhead, ensuring copyright compliance in training datasets, and creating a sustainable economic model, Viz offers a comprehensive solution to the complex challenges of AI landscape.\nLegal and Ethical Compliance: Viz contributes to the discussion on legal and ethical considerations in AI, particularly in copyright compliance and data privacy, providing a holistic and inventive approach to the existing obstacles in the artificial intelligence field."
  },
  {
    "objectID": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#introduction",
    "href": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#introduction",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Introduction",
    "text": "Introduction\n\nThe paper aims to introduce the Viz system, which addresses challenges of computational efficiency, legal compliance, and economic sustainability in the utilization and monetization of LLMs."
  },
  {
    "objectID": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#literature-review",
    "href": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#literature-review",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Literature Review",
    "text": "Literature Review\n\nThe review outlines the advancements in LLMs, copyright concerns in AI training, and the evolution of fine-tuning techniques, specifically LoRA and QLoRA."
  },
  {
    "objectID": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#viz-system-architecture",
    "href": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#viz-system-architecture",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Viz System Architecture",
    "text": "Viz System Architecture\n\nThe system integrates a marketplace for AI models fine-tuned through QLoRA, providing a legally compliant and economically viable avenue for content creators and users."
  },
  {
    "objectID": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#qlora-importance-in-viz",
    "href": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#qlora-importance-in-viz",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "QLoRA Importance in Viz",
    "text": "QLoRA Importance in Viz\n\nQLoRA’s core principles and adaptation within Viz significantly reduces computational overhead and enhances model performance."
  },
  {
    "objectID": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#marketplace-design-and-economics",
    "href": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#marketplace-design-and-economics",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Marketplace Design and Economics",
    "text": "Marketplace Design and Economics\n\nThe marketplace employs a dual monetization strategy and revenue sharing models, paralleling existing digital content platforms."
  },
  {
    "objectID": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#legal-and-ethical-considerations",
    "href": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#legal-and-ethical-considerations",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Legal and Ethical Considerations",
    "text": "Legal and Ethical Considerations\n\nViz ensures adherence to global copyright regulations, data privacy, ethical AI principles, and fair use."
  },
  {
    "objectID": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#discussion",
    "href": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#discussion",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Discussion",
    "text": "Discussion\n\nThe Viz system’s impact on the AI and content industry, and potential advancements such as decentralization are discussed."
  },
  {
    "objectID": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#conclusion",
    "href": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#conclusion",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Conclusion",
    "text": "Conclusion\n\nViz sets a precedent for future advancements in AI technology, combining technological innovation, economic insight, and legal caution."
  },
  {
    "objectID": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#critique",
    "href": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#critique",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Critique",
    "text": "Critique\n\nThe paper could benefit from a more in-depth analysis of potential limitations and challenges in the practical implementation of the Viz system.\nFurther exploration of the potential ethical implications and unintended consequences of widespread adoption of Viz would enhance the discussion."
  },
  {
    "objectID": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#appendix",
    "href": "posts/Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI/2023-12-31-Viz__A_QLoRA_based_Copyright_Marketplace_for_Legally_Compliant_Generative_AI.html#appendix",
    "title": "Viz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00503v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00503v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6840"
  },
  {
    "objectID": "posts/Performance_lossless_Black_box_Model_Watermarking/2023-12-11-Performance_lossless_Black_box_Model_Watermarking.html#appendix",
    "href": "posts/Performance_lossless_Black_box_Model_Watermarking/2023-12-11-Performance_lossless_Black_box_Model_Watermarking.html#appendix",
    "title": "Performance-lossless Black-box Model Watermarking",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.06488v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.06488v1\n\n\nTruncated\nTrue\n\n\nWord Count\n16235"
  },
  {
    "objectID": "posts/Astraios__Parameter_Efficient_Instruction_Tuning_Code_Large_Language_Models/2024-01-01-Astraios__Parameter_Efficient_Instruction_Tuning_Code_Large_Language_Models.html#summary",
    "href": "posts/Astraios__Parameter_Efficient_Instruction_Tuning_Code_Large_Language_Models/2024-01-01-Astraios__Parameter_Efficient_Instruction_Tuning_Code_Large_Language_Models.html#summary",
    "title": "Astraios: Parameter-Efficient Instruction Tuning Code Large Language Models",
    "section": "Summary",
    "text": "Summary\n\nMajor Findings\n\nThe study introduces Astraios, a suite of 28 instruction-tuned OctoCoder models using 7 tuning methods and 4 model sizes up to 16 billion parameters.\nFull-parameter fine-tuning (FFT) generally leads to the best downstream performance across all scales, and parameter-efficient fine-tuning (PEFT) methods differ significantly in their efficacy based on the model scale.\nLoRA usually offers the most favorable trade-off between cost and performance.\n\n\n\nAstraios Suite and Benchmark\n\nModel: The StarCoder series is selected as the base model, and 3 kinds of PEFT methods are focused on: adapter-based tuning, prompt-based tuning, and intrinsic-rank-based tuning.\nInstruction Tuning: The CommitPackFT+OASST dataset is selected for instruction tuning, and various training configurations and evaluations are implemented for code comprehension, code generation, model robustness, and code security.\n\n\n\nPreliminary Study: Cross-Entropy Loss\n\nThe study investigates the relationships between updated parameters, cross-entropy loss, and task performance.\n\n\n\nMain Results: Task Performance\n\nCode comprehension tasks do not align with patterns observed in code generation tasks, and larger PEFT Code LLMs perform better on code generation tasks."
  },
  {
    "objectID": "posts/Astraios__Parameter_Efficient_Instruction_Tuning_Code_Large_Language_Models/2024-01-01-Astraios__Parameter_Efficient_Instruction_Tuning_Code_Large_Language_Models.html#critique",
    "href": "posts/Astraios__Parameter_Efficient_Instruction_Tuning_Code_Large_Language_Models/2024-01-01-Astraios__Parameter_Efficient_Instruction_Tuning_Code_Large_Language_Models.html#critique",
    "title": "Astraios: Parameter-Efficient Instruction Tuning Code Large Language Models",
    "section": "Critique",
    "text": "Critique\nThe paper provides a comprehensive analysis of parameter-efficient instruction-tuning of Large Language Models (LLMs) but lacks a clear analysis of the limitations and potential biases in the experimental setup. The study’s heavy reliance on single-run evaluations and the lack of validation for data scaling and model architecture raise concerns about the robustness and generalizability of the findings. Further, while addressing the limitations and providing a detailed analysis of model architecture and data scaling were considered in the future work, the critique emphasizes the need for more thorough and varied experimental setups to improve the study’s comprehensive representation and generalizability."
  },
  {
    "objectID": "posts/Astraios__Parameter_Efficient_Instruction_Tuning_Code_Large_Language_Models/2024-01-01-Astraios__Parameter_Efficient_Instruction_Tuning_Code_Large_Language_Models.html#appendix",
    "href": "posts/Astraios__Parameter_Efficient_Instruction_Tuning_Code_Large_Language_Models/2024-01-01-Astraios__Parameter_Efficient_Instruction_Tuning_Code_Large_Language_Models.html#appendix",
    "title": "Astraios: Parameter-Efficient Instruction Tuning Code Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00788v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00788v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12057"
  },
  {
    "objectID": "posts/Social_Media_Ready_Caption_Generation_for_Brands/2024-01-03-Social_Media_Ready_Caption_Generation_for_Brands.html#appendix",
    "href": "posts/Social_Media_Ready_Caption_Generation_for_Brands/2024-01-03-Social_Media_Ready_Caption_Generation_for_Brands.html#appendix",
    "title": "Social Media Ready Caption Generation for Brands",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01637v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01637v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7430"
  },
  {
    "objectID": "posts/Deplatforming_Norm_Violating_Influencers_on_Social_Media_Reduces_Overall_Online_Attention_Toward_Them/2024-01-02-Deplatforming_Norm_Violating_Influencers_on_Social_Media_Reduces_Overall_Online_Attention_Toward_Them.html#appendix",
    "href": "posts/Deplatforming_Norm_Violating_Influencers_on_Social_Media_Reduces_Overall_Online_Attention_Toward_Them/2024-01-02-Deplatforming_Norm_Violating_Influencers_on_Social_Media_Reduces_Overall_Online_Attention_Toward_Them.html#appendix",
    "title": "Deplatforming Norm-Violating Influencers on Social Media Reduces Overall Online Attention Toward Them",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01253v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01253v1\n\n\nTruncated\nTrue\n\n\nWord Count\n16844"
  },
  {
    "objectID": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#major-findings",
    "href": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#major-findings",
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "section": "Major Findings",
    "text": "Major Findings\n\nInstruction-tuned language models struggle to reproduce author-specific style in a few-shot setting, even with recent large LMs such as GPT-3.5.\nA proposed approach using contrastively-trained representations and a combination of generative re-scoring and discriminative control can effectively generate text in an author-specific style in various conditions, including unconditional generation and style transfer.\nThe proposed style transfer approach can be adapted to serve as an effective author anonymization technique, defeating authorship attribution while preserving meaning."
  },
  {
    "objectID": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#introduction",
    "href": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#introduction",
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "section": "Introduction",
    "text": "Introduction\n\nThe paper discusses the problem of generating text in the style of an arbitrary author based on a small writing sample, emphasizing the difficulty of this task due to the sparse signal of stylometric features."
  },
  {
    "objectID": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#preliminaries",
    "href": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#preliminaries",
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "section": "Preliminaries",
    "text": "Preliminaries\n\nThe goal is to produce text in a particular target style while satisfying other criteria, such as diverse outputs and meaning preservation.\nThe proposed approach involves future regressors and energy-based models for non-autoregressive generation."
  },
  {
    "objectID": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#guiding-generations-towards-a-target-style-representation",
    "href": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#guiding-generations-towards-a-target-style-representation",
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "section": "Guiding generations towards a target style representation",
    "text": "Guiding generations towards a target style representation\n\nUsing a regression model to guide a language model to produce text in a target style.\nThe resulting author-specific LM can be incorporated in an energy-based model for non-autoregressive generation."
  },
  {
    "objectID": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#style-control",
    "href": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#style-control",
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "section": "Style Control",
    "text": "Style Control\n\nThe proposed decoding strategy (EBM) performs competitively with large instruction-tuned LMs, outperforming in-context learning.\nInterpolating between two target author style vectors yields interpretable results, indicating that control vectors capture intuitive stylistic features and can successfully reproduce those features in generated text.\nSamples from the proposed approach circumvent machine-generated text detectors at a higher rate and address concerns with producing more in-domain detection data."
  },
  {
    "objectID": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#style-transfer",
    "href": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#style-transfer",
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "section": "Style Transfer",
    "text": "Style Transfer\n\nThe proposed approach achieves style accuracy comparable to large LMs while requiring only a fraction of the number of parameters.\nThe trade-off between stylistic accuracy and content preservation is observed."
  },
  {
    "objectID": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#anonymization",
    "href": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#anonymization",
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "section": "Anonymization",
    "text": "Anonymization\n\nThe proposed style transfer approach succeeds in reducing the detection rate through style transfer, serving as an effective author anonymization technique."
  },
  {
    "objectID": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#detection-of-generated-text",
    "href": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#detection-of-generated-text",
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "section": "Detection of Generated Text",
    "text": "Detection of Generated Text\n\nDetection of LM generated text becomes more tractable with basic classification approaches when more in-domain data is available."
  },
  {
    "objectID": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#related-work",
    "href": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#related-work",
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "section": "Related Work",
    "text": "Related Work\n\nThe paper discusses the limitations of automatic evaluation metrics and the use of discriminative models to guide generation."
  },
  {
    "objectID": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#conclusion",
    "href": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#conclusion",
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "section": "Conclusion",
    "text": "Conclusion\nThe paper addresses the potential applications and broader impact of style-controlled text generation, acknowledging both positive and potential misuse concerns regarding machine-text detection."
  },
  {
    "objectID": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#critique",
    "href": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#critique",
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "section": "Critique",
    "text": "Critique\n\nThe use of automatic metrics for evaluation may not fully capture the nuanced aspects of author-specific style and meaning preservation.\nThe heavy reliance on large corpora of social media data for training style representations might introduce biases and privacy concerns."
  },
  {
    "objectID": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#appendix",
    "href": "posts/Learning_to_Generate_Text_in_Arbitrary_Writing_Styles/2023-12-28-Learning_to_Generate_Text_in_Arbitrary_Writing_Styles.html#appendix",
    "title": "Learning to Generate Text in Arbitrary Writing Styles",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17242v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17242v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12839"
  },
  {
    "objectID": "posts/TeamCAD____A_Multimodal_Interface_for_Remote_Computer_Aided_Design/2023-12-19-TeamCAD____A_Multimodal_Interface_for_Remote_Computer_Aided_Design.html#appendix",
    "href": "posts/TeamCAD____A_Multimodal_Interface_for_Remote_Computer_Aided_Design/2023-12-19-TeamCAD____A_Multimodal_Interface_for_Remote_Computer_Aided_Design.html#appendix",
    "title": "TeamCAD – A Multimodal Interface for Remote Computer Aided Design",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.12309v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.12309v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4768"
  },
  {
    "objectID": "posts/A_Comprehensive_Survey_of_Evaluation_Techniques_for_Recommendation_Systems/2023-12-26-A_Comprehensive_Survey_of_Evaluation_Techniques_for_Recommendation_Systems.html#appendix",
    "href": "posts/A_Comprehensive_Survey_of_Evaluation_Techniques_for_Recommendation_Systems/2023-12-26-A_Comprehensive_Survey_of_Evaluation_Techniques_for_Recommendation_Systems.html#appendix",
    "title": "A Comprehensive Survey of Evaluation Techniques for Recommendation Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16015v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16015v1\n\n\nTruncated\nTrue\n\n\nWord Count\n14462"
  },
  {
    "objectID": "posts/Prompting_Hard_or_Hardly_Prompting__Prompt_Inversion_for_Text_to_Image_Diffusion_Models/2023-12-19-Prompting_Hard_or_Hardly_Prompting__Prompt_Inversion_for_Text_to_Image_Diffusion_Models.html#appendix",
    "href": "posts/Prompting_Hard_or_Hardly_Prompting__Prompt_Inversion_for_Text_to_Image_Diffusion_Models/2023-12-19-Prompting_Hard_or_Hardly_Prompting__Prompt_Inversion_for_Text_to_Image_Diffusion_Models.html#appendix",
    "title": "Prompting Hard or Hardly Prompting: Prompt Inversion for Text-to-Image Diffusion Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.12416v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.12416v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9247"
  },
  {
    "objectID": "posts/Prometheus__Infrastructure_Security_Posture_Analysis_with_AI_generated_Attack_Graphs/2023-12-20-Prometheus__Infrastructure_Security_Posture_Analysis_with_AI_generated_Attack_Graphs.html#appendix",
    "href": "posts/Prometheus__Infrastructure_Security_Posture_Analysis_with_AI_generated_Attack_Graphs/2023-12-20-Prometheus__Infrastructure_Security_Posture_Analysis_with_AI_generated_Attack_Graphs.html#appendix",
    "title": "Prometheus: Infrastructure Security Posture Analysis with AI-generated Attack Graphs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.13119v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.13119v1\n\n\nTruncated\nTrue\n\n\nWord Count\n18677"
  },
  {
    "objectID": "posts/The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model.html#major-findings",
    "href": "posts/The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model.html#major-findings",
    "title": "The Right Prompts for the Job: Repair Code-Review Defects with Large Language Model",
    "section": "Major Findings",
    "text": "Major Findings\n\nLimited accuracy and considerable time costs associated with existing Automatic Program Repair (APR) techniques hinder their adoption in industrial practice.\nAdvanced Large Language Models (LLMs) can comprehend natural and programming languages, making them capable of generating patches based on review comments, demonstrating a remarkable repair rate of 72.97% with the best prompt.\nIncorporating review comments and fix ranges significantly aids in repairing Code Review (CR) defects, leading to progressive enhancement in the models’ ability to address the defects."
  },
  {
    "objectID": "posts/The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model.html#introduction",
    "href": "posts/The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model.html#introduction",
    "title": "The Right Prompts for the Job: Repair Code-Review Defects with Large Language Model",
    "section": "Introduction",
    "text": "Introduction\n\nContinuous Integration/Continuous Deployment (CI/CD) pipelines control the software development process, with Code Review (CR) serving as a pivotal node.\nAutomatic Program Repair (APR) aims to offer a fully automated solution for defect repair, but its inherent time-consuming nature poses challenges for integration within time-sensitive CI/CD pipelines.\nLimitations of traditional approaches (search-based, constraint-based, and template-based methods) in effectively utilizing the insights from review comments expressed in natural language led to the exploration of AI-based APR approaches with Large Language Models (LLMs)."
  },
  {
    "objectID": "posts/The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model.html#code-review",
    "href": "posts/The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model.html#code-review",
    "title": "The Right Prompts for the Job: Repair Code-Review Defects with Large Language Model",
    "section": "Code Review",
    "text": "Code Review\n\nDefect identification process involves human reviewers and automated checkers, with both providing comments describing identified defects and, in some cases, offering suggestions on rectifying them."
  },
  {
    "objectID": "posts/The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model.html#repairing",
    "href": "posts/The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model.html#repairing",
    "title": "The Right Prompts for the Job: Repair Code-Review Defects with Large Language Model",
    "section": "Repairing",
    "text": "Repairing\n\nDefect repair predominantly relies on manual effort, calling for the need for a semi-automated paradigm to leverage APR techniques effectively in the CR process.\nTraditional approaches face challenges in effectively utilizing information from review comments. AI-based APR approaches with LLMs are seen as a promising solution to effectively address the underlying problem."
  },
  {
    "objectID": "posts/The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model.html#research-questions-and-experiment-settings",
    "href": "posts/The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model.html#research-questions-and-experiment-settings",
    "title": "The Right Prompts for the Job: Repair Code-Review Defects with Large Language Model",
    "section": "Research Questions and Experiment Settings",
    "text": "Research Questions and Experiment Settings\n\nEffectiveness of LLMs: Explored using various LLMs for repairing CR defects using zero-shot learning or finetuning.\nImpact of different prompts: Investigated the performance of LLMs with different prompts containing varied information.\nPerformance of LLMs in repairing defects varying with different model sizes.\nImpact of different datasets: Explored the capacity to rectify defects and interchangeably employ these datasets."
  },
  {
    "objectID": "posts/The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model.html#experiment-results",
    "href": "posts/The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model.html#experiment-results",
    "title": "The Right Prompts for the Job: Repair Code-Review Defects with Large Language Model",
    "section": "Experiment Results",
    "text": "Experiment Results\n\nOverall Effectiveness (RQ1)\n\nZero-shot learning resulted in improved repair rates using review comments.\nDesigned prompts demonstrated that review comments and fix ranges were the most effective prompts.\nModel performance improves with successive prompts, with the best performance achieved in prompt P7.\n\nPrompt Comparison (RQ2)\n\nOverall improvement in ECM from prompt P3 to P7, showcasing the incremental benefits of incorporating different cues.\n\nModel Size Comparison (RQ3)\n\nGradual increases noticed in both ECM and Code BLEU scores as the model sizes increase, with 6-7B LLMs showing a favorable balance between efficiency and effectiveness.\n\nImpacts of Datasets (RQ4)\n\nOptimal performance achieved when finetuning and evaluating models on the appropriate datasets, highlighting the necessity of diverse datasets in the finetuning process."
  },
  {
    "objectID": "posts/The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model.html#critique",
    "href": "posts/The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model.html#critique",
    "title": "The Right Prompts for the Job: Repair Code-Review Defects with Large Language Model",
    "section": "Critique",
    "text": "Critique\n\nThe study focuses on a specific range of LLMs and model sizes, potentially limiting the generalizability of the findings to other models in the open source community.\nThe study acknowledges the necessity of ensuring data quality but does not delve into potential biases in the datasets that could affect model performance.\n\nOverall, the study provides valuable insights into leveraging LLMs for repairing CR defects, highlighting the importance of review comments and fix ranges in improving the effectiveness of APR techniques. Further research could explore the potential biases in the datasets and consider a wider range of LLMs to enhance the generalizability of the findings."
  },
  {
    "objectID": "posts/The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model.html#appendix",
    "href": "posts/The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model/2023-12-29-The_Right_Prompts_for_the_Job__Repair_Code_Review_Defects_with_Large_Language_Model.html#appendix",
    "title": "The Right Prompts for the Job: Repair Code-Review Defects with Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17485v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17485v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12983"
  },
  {
    "objectID": "posts/Socially_Responsible_Computing_in_an_Introductory_Course/2024-01-02-Socially_Responsible_Computing_in_an_Introductory_Course.html#major-takeaways",
    "href": "posts/Socially_Responsible_Computing_in_an_Introductory_Course/2024-01-02-Socially_Responsible_Computing_in_an_Introductory_Course.html#major-takeaways",
    "title": "Socially Responsible Computing in an Introductory Course",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nThe paper introduces a piloted introductory Java programming course that integrates ethical and socially responsible considerations across modules. The data suggests that students found the inclusion of the social context in technical assignments to be more motivating and expressed greater agency in realizing social change.\nThe paper highlights the importance of ensuring goal congruity, emphasizing that students need to perceive an alignment between their personal goals and their ability to fulfill those goals by participating in the field of study. In computing education, a greater emphasis on agentic goals, with an inward focus, has been found to be a barrier in enhancing diversity and inclusion in computing.\nThe paper acknowledges the challenges in integrating ethics into computer science (CS) courses and emphasizes the need for praxis-oriented computing courses that build upon ethical considerations toward encouraging students to take responsibility by understanding the power and social impact of technology — engaging with socially responsible computing."
  },
  {
    "objectID": "posts/Socially_Responsible_Computing_in_an_Introductory_Course/2024-01-02-Socially_Responsible_Computing_in_an_Introductory_Course.html#our-curricular-approach",
    "href": "posts/Socially_Responsible_Computing_in_an_Introductory_Course/2024-01-02-Socially_Responsible_Computing_in_an_Introductory_Course.html#our-curricular-approach",
    "title": "Socially Responsible Computing in an Introductory Course",
    "section": "Our Curricular Approach",
    "text": "Our Curricular Approach\n\nComputing Around Us: The course started with an examination of the impact of computing on society and discussions on ethical reasoning, power, and social impact analysis. Emphasis was placed on considering impact on individual, communal, and societal levels.\nComputing By Us and For Us: The course then transitioned into learning Java programming through socially-grounded assignments, projects intertwining social and technical issues, and individual and collective reflections.\nData Sources and Analysis: Data was collected through optional surveys and analyzed to understand the students’ perceptions and reflections on the course."
  },
  {
    "objectID": "posts/Socially_Responsible_Computing_in_an_Introductory_Course/2024-01-02-Socially_Responsible_Computing_in_an_Introductory_Course.html#findings",
    "href": "posts/Socially_Responsible_Computing_in_an_Introductory_Course/2024-01-02-Socially_Responsible_Computing_in_an_Introductory_Course.html#findings",
    "title": "Socially Responsible Computing in an Introductory Course",
    "section": "Findings",
    "text": "Findings\n\nUnderstanding Computing in a Social Context: Students expressed appreciation for addressing real-world challenges and found the integration of programming with social issues to be meaningful.\nAwareness of Justice and Power Relations: Through the projects, students grappled with power, especially developers’ power, and computing limitations in the face of structural issues.\nPersonal Relevance and Responsibilities: Students recognized their roles in addressing societal challenges and considered their social responsibilities during assignments and projects.\nLearning and Conceptual Integration: The integration of programming with social challenges deepened their understanding of both programming and social problems."
  },
  {
    "objectID": "posts/Socially_Responsible_Computing_in_an_Introductory_Course/2024-01-02-Socially_Responsible_Computing_in_an_Introductory_Course.html#discussion-and-conclusion",
    "href": "posts/Socially_Responsible_Computing_in_an_Introductory_Course/2024-01-02-Socially_Responsible_Computing_in_an_Introductory_Course.html#discussion-and-conclusion",
    "title": "Socially Responsible Computing in an Introductory Course",
    "section": "Discussion and Conclusion",
    "text": "Discussion and Conclusion\n\nThe paper outlines several challenges faced in the implementation of socially responsible computing in the curriculum, including the need to build trust with and among students, the challenge of being vulnerable to engage in discussions, and the difficulty in dovetailing technical problems with social issues.\nThe authors emphasize the importance of ensuring students grasp the limitations of individual responsibilities and acknowledge the need for corporate accountability in socially responsible computing."
  },
  {
    "objectID": "posts/Socially_Responsible_Computing_in_an_Introductory_Course/2024-01-02-Socially_Responsible_Computing_in_an_Introductory_Course.html#critique-and-potential-problems",
    "href": "posts/Socially_Responsible_Computing_in_an_Introductory_Course/2024-01-02-Socially_Responsible_Computing_in_an_Introductory_Course.html#critique-and-potential-problems",
    "title": "Socially Responsible Computing in an Introductory Course",
    "section": "Critique and Potential Problems",
    "text": "Critique and Potential Problems\nThe paper provides valuable insights into the integration of socially responsible computing in computer science education. However, there are a few potential problems to consider, including: - The reliance on student reflections and survey responses as the primary data source may introduce subjective bias and may not provide a comprehensive understanding of the course’s effectiveness. - The challenges faced in the implementation of the course are outlined, but detailed strategies for addressing these challenges are not provided, which may limit the practical applicability of the findings.\nOverall, while the paper contributes to the discourse on integrating socially responsible computing in CS education, a more in-depth exploration of the practical implications and potential solutions to the identified challenges would enhance its impact."
  },
  {
    "objectID": "posts/Socially_Responsible_Computing_in_an_Introductory_Course/2024-01-02-Socially_Responsible_Computing_in_an_Introductory_Course.html#appendix",
    "href": "posts/Socially_Responsible_Computing_in_an_Introductory_Course/2024-01-02-Socially_Responsible_Computing_in_an_Introductory_Course.html#appendix",
    "title": "Socially Responsible Computing in an Introductory Course",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01285v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01285v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10142"
  },
  {
    "objectID": "posts/LaFFi__Leveraging_Hybrid_Natural_Language_Feedback_for_Fine_tuning_Language_Models/2023-12-31-LaFFi__Leveraging_Hybrid_Natural_Language_Feedback_for_Fine_tuning_Language_Models.html#appendix",
    "href": "posts/LaFFi__Leveraging_Hybrid_Natural_Language_Feedback_for_Fine_tuning_Language_Models/2023-12-31-LaFFi__Leveraging_Hybrid_Natural_Language_Feedback_for_Fine_tuning_Language_Models.html#appendix",
    "title": "LaFFi: Leveraging Hybrid Natural Language Feedback for Fine-tuning Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00907v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00907v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4606"
  },
  {
    "objectID": "posts/Terrapin_Attack__Breaking_SSH_Channel_Integrity_By_Sequence_Number_Manipulation/2023-12-19-Terrapin_Attack__Breaking_SSH_Channel_Integrity_By_Sequence_Number_Manipulation.html#appendix",
    "href": "posts/Terrapin_Attack__Breaking_SSH_Channel_Integrity_By_Sequence_Number_Manipulation/2023-12-19-Terrapin_Attack__Breaking_SSH_Channel_Integrity_By_Sequence_Number_Manipulation.html#appendix",
    "title": "Terrapin Attack: Breaking SSH Channel Integrity By Sequence Number Manipulation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.12422v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.12422v1\n\n\nTruncated\nTrue\n\n\nWord Count\n18928"
  },
  {
    "objectID": "posts/Chain_of_Code__Reasoning_with_a_Language_Model_Augmented_Code_Emulator/2023-12-07-Chain_of_Code__Reasoning_with_a_Language_Model_Augmented_Code_Emulator.html#key-findings",
    "href": "posts/Chain_of_Code__Reasoning_with_a_Language_Model_Augmented_Code_Emulator/2023-12-07-Chain_of_Code__Reasoning_with_a_Language_Model_Augmented_Code_Emulator.html#key-findings",
    "title": "Chain of Code: Reasoning with a Language Model-Augmented Code Emulator",
    "section": "Key Findings",
    "text": "Key Findings\n\nChain of Code (CoC) proposes to utilize both code and language models (LMs) to improve reasoning performance across various reasoning tasks, achieving significant improvements over other baseline techniques.\nCoC generates reasoning substeps in the form of code or pseudocode and executes the code with a Python interpreter, using an LMulator to simulate execution for non-executable code, which allows it to perform well on tasks that involve both numeric and semantic reasoning.\nThe overall performance of CoC outperforms Chain of Thought and other baselines across a variety of benchmarks, achieving 84% accuracy on BIG-Bench Hard, a gain of 12% over Chain of Thought."
  },
  {
    "objectID": "posts/Chain_of_Code__Reasoning_with_a_Language_Model_Augmented_Code_Emulator/2023-12-07-Chain_of_Code__Reasoning_with_a_Language_Model_Augmented_Code_Emulator.html#introduction",
    "href": "posts/Chain_of_Code__Reasoning_with_a_Language_Model_Augmented_Code_Emulator/2023-12-07-Chain_of_Code__Reasoning_with_a_Language_Model_Augmented_Code_Emulator.html#introduction",
    "title": "Chain of Code: Reasoning with a Language Model-Augmented Code Emulator",
    "section": "Introduction",
    "text": "Introduction\n\nLanguage models (LMs) have shown to improve reasoning tasks, and using code to prompt LMs has been advantageous due to the structured nature of code and the interface it provides for performing precise algorithmic computations.\nWhile writing and executing code may improve LM reasoning performance across arithmetic tasks, it struggles with many semantic tasks difficult to express in code."
  },
  {
    "objectID": "posts/Chain_of_Code__Reasoning_with_a_Language_Model_Augmented_Code_Emulator/2023-12-07-Chain_of_Code__Reasoning_with_a_Language_Model_Augmented_Code_Emulator.html#chain-of-code-reasoning-with-an-lmulator",
    "href": "posts/Chain_of_Code__Reasoning_with_a_Language_Model_Augmented_Code_Emulator/2023-12-07-Chain_of_Code__Reasoning_with_a_Language_Model_Augmented_Code_Emulator.html#chain-of-code-reasoning-with-an-lmulator",
    "title": "Chain of Code: Reasoning with a Language Model-Augmented Code Emulator",
    "section": "Chain of Code: Reasoning with an LMulator",
    "text": "Chain of Code: Reasoning with an LMulator\n\nCoC encourages LMs to format semantic sub-tasks as flexible pseudocode that can be explicitly caught and handed off to an LMulator for simulation at runtime.\nCoC proceeds in two steps: generation, wherein an LM generates code or pseudocode to solve a problem, and execution, with the code being run using a Python interpreter or an LMulator.\nThe approach scales well with large and small models alike and outperforms Chain of Thought and other baselines across various tasks, even achieving human-rater level performance on several tasks."
  },
  {
    "objectID": "posts/Chain_of_Code__Reasoning_with_a_Language_Model_Augmented_Code_Emulator/2023-12-07-Chain_of_Code__Reasoning_with_a_Language_Model_Augmented_Code_Emulator.html#experimental-evaluation",
    "href": "posts/Chain_of_Code__Reasoning_with_a_Language_Model_Augmented_Code_Emulator/2023-12-07-Chain_of_Code__Reasoning_with_a_Language_Model_Augmented_Code_Emulator.html#experimental-evaluation",
    "title": "Chain of Code: Reasoning with a Language Model-Augmented Code Emulator",
    "section": "Experimental Evaluation",
    "text": "Experimental Evaluation\n\nCoC exhibits high performance across varied problems, particularly excelling in algorithmic tasks and performing on par with Chain of Thought for natural language tasks.\nAblations demonstrate that the interweaving of code and language execution provides significant improvements in performance across tasks.\nCoC’s performance increases with model size, and it outperforms other prompting techniques even with instruction-tuned chat models.\nCoC demonstrates promising results for applications involving robotic tasks that require semantic and algorithmic reasoning."
  },
  {
    "objectID": "posts/Chain_of_Code__Reasoning_with_a_Language_Model_Augmented_Code_Emulator/2023-12-07-Chain_of_Code__Reasoning_with_a_Language_Model_Augmented_Code_Emulator.html#critique",
    "href": "posts/Chain_of_Code__Reasoning_with_a_Language_Model_Augmented_Code_Emulator/2023-12-07-Chain_of_Code__Reasoning_with_a_Language_Model_Augmented_Code_Emulator.html#critique",
    "title": "Chain of Code: Reasoning with a Language Model-Augmented Code Emulator",
    "section": "Critique",
    "text": "Critique\n\nCoC requires additional context length and computation time due to its two-step process and interweaving of code and language execution.\nThe approach may not perform well on tasks where code is not beneficial and has limitations in modifying custom Python objects while simulating code execution.\n\nOverall, the paper presents an innovative approach, CoC, that combines the strengths of both code and language models to improve reasoning performance across a variety of tasks. However, the paper would benefit from further discussions on potential limitations and future work for extending the applicability of CoC."
  },
  {
    "objectID": "posts/Chain_of_Code__Reasoning_with_a_Language_Model_Augmented_Code_Emulator/2023-12-07-Chain_of_Code__Reasoning_with_a_Language_Model_Augmented_Code_Emulator.html#appendix",
    "href": "posts/Chain_of_Code__Reasoning_with_a_Language_Model_Augmented_Code_Emulator/2023-12-07-Chain_of_Code__Reasoning_with_a_Language_Model_Augmented_Code_Emulator.html#appendix",
    "title": "Chain of Code: Reasoning with a Language Model-Augmented Code Emulator",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.04474v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.04474v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9590"
  },
  {
    "objectID": "posts/RAGTruth__A_Hallucination_Corpus_for_Developing_Trustworthy_Retrieval_Augmented_Language_Models/2023-12-31-RAGTruth__A_Hallucination_Corpus_for_Developing_Trustworthy_Retrieval_Augmented_Language_Models.html#appendix",
    "href": "posts/RAGTruth__A_Hallucination_Corpus_for_Developing_Trustworthy_Retrieval_Augmented_Language_Models/2023-12-31-RAGTruth__A_Hallucination_Corpus_for_Developing_Trustworthy_Retrieval_Augmented_Language_Models.html#appendix",
    "title": "RAGTruth: A Hallucination Corpus for Developing Trustworthy Retrieval-Augmented Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00396v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00396v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6757"
  },
  {
    "objectID": "posts/Securing_NextG_Systems_against_Poisoning_Attacks_on_Federated_Learning__A_Game_Theoretic_Solution/2023-12-28-Securing_NextG_Systems_against_Poisoning_Attacks_on_Federated_Learning__A_Game_Theoretic_Solution.html#appendix",
    "href": "posts/Securing_NextG_Systems_against_Poisoning_Attacks_on_Federated_Learning__A_Game_Theoretic_Solution/2023-12-28-Securing_NextG_Systems_against_Poisoning_Attacks_on_Federated_Learning__A_Game_Theoretic_Solution.html#appendix",
    "title": "Securing NextG Systems against Poisoning Attacks on Federated Learning: A Game-Theoretic Solution",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17164v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17164v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8577"
  },
  {
    "objectID": "posts/JMA__a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example/2024-01-02-JMA__a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example.html#major-takeaways",
    "href": "posts/JMA__a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example/2024-01-02-JMA__a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example.html#major-takeaways",
    "title": "JMA: a General Algorithm to Craft Nearly Optimal Targeted Adversarial Example",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nThe paper proposes a new algorithm, Jacobian-induced Mahalanobis distance Attack (JMA), for crafting targeted adversarial examples against Deep Learning classifiers.\nJMA presents a more general and theoretically sound approach, resorting to the minimization of a Mahalanobis distance term derived from the Jacobian matrix, taking into account the effort required to move the input sample in a given direction in the latent space representation.\nThe experiments confirm the efficacy of JMA under different scenarios, including multi-label classification, ECOC output encoding, and one-hot encoding."
  },
  {
    "objectID": "posts/JMA__a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example/2024-01-02-JMA__a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example.html#sections",
    "href": "posts/JMA__a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example/2024-01-02-JMA__a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example.html#sections",
    "title": "JMA: a General Algorithm to Craft Nearly Optimal Targeted Adversarial Example",
    "section": "Sections",
    "text": "Sections\n\nIntroduction\nAdversarial Attacks against DNNs\nThe JMA Attack"
  },
  {
    "objectID": "posts/JMA__a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example/2024-01-02-JMA__a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example.html#critique",
    "href": "posts/JMA__a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example/2024-01-02-JMA__a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example.html#critique",
    "title": "JMA: a General Algorithm to Craft Nearly Optimal Targeted Adversarial Example",
    "section": "Critique",
    "text": "Critique\nThe paper introduces a novel and theoretically sound algorithm that addresses a significant issue in crafting targeted adversarial examples. The experimental results support the effectiveness of JMA across different scenarios. However, a critical analysis of the limitations or potential failure cases of JMA would provide a more comprehensive understanding of its applicability. Furthermore, a comparative analysis with existing state-of-the-art algorithms would enhance the paper’s contributions and provide additional context for evaluating the significance of JMA."
  },
  {
    "objectID": "posts/JMA__a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example/2024-01-02-JMA__a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example.html#appendix",
    "href": "posts/JMA__a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example/2024-01-02-JMA__a_General_Algorithm_to_Craft_Nearly_Optimal_Targeted_Adversarial_Example.html#appendix",
    "title": "JMA: a General Algorithm to Craft Nearly Optimal Targeted Adversarial Example",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01199v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01199v1\n\n\nTruncated\nTrue\n\n\nWord Count\n27623"
  },
  {
    "objectID": "posts/The_Media_Bias_Taxonomy__A_Systematic_Literature_Review_on_the_Forms_and_Automated_Detection_of_Media_Bias/2023-12-26-The_Media_Bias_Taxonomy__A_Systematic_Literature_Review_on_the_Forms_and_Automated_Detection_of_Media_Bias.html#appendix",
    "href": "posts/The_Media_Bias_Taxonomy__A_Systematic_Literature_Review_on_the_Forms_and_Automated_Detection_of_Media_Bias/2023-12-26-The_Media_Bias_Taxonomy__A_Systematic_Literature_Review_on_the_Forms_and_Automated_Detection_of_Media_Bias.html#appendix",
    "title": "The Media Bias Taxonomy: A Systematic Literature Review on the Forms and Automated Detection of Media Bias",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16148v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16148v1\n\n\nTruncated\nTrue\n\n\nWord Count\n24383"
  },
  {
    "objectID": "posts/Towards_Verifiable_Text_Generation_with_Evolving_Memory_and_Self_Reflection/2023-12-14-Towards_Verifiable_Text_Generation_with_Evolving_Memory_and_Self_Reflection.html#appendix",
    "href": "posts/Towards_Verifiable_Text_Generation_with_Evolving_Memory_and_Self_Reflection/2023-12-14-Towards_Verifiable_Text_Generation_with_Evolving_Memory_and_Self_Reflection.html#appendix",
    "title": "Towards Verifiable Text Generation with Evolving Memory and Self-Reflection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.09075v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.09075v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7635"
  },
  {
    "objectID": "posts/SMoT__Think_in_State_Machine/2023-12-29-SMoT__Think_in_State_Machine.html#appendix",
    "href": "posts/SMoT__Think_in_State_Machine/2023-12-29-SMoT__Think_in_State_Machine.html#appendix",
    "title": "SMoT: Think in State Machine",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17445v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17445v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11018"
  },
  {
    "objectID": "posts/Generative_AI_is_already_widespread_in_the_public_sector/2024-01-02-Generative_AI_is_already_widespread_in_the_public_sector.html#appendix",
    "href": "posts/Generative_AI_is_already_widespread_in_the_public_sector/2024-01-02-Generative_AI_is_already_widespread_in_the_public_sector.html#appendix",
    "title": "Generative AI is already widespread in the public sector",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01291v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01291v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7649"
  },
  {
    "objectID": "posts/Exploring_the_Sensitivity_of_LLMs'_Decision_Making_Capabilities__Insights_from_Prompt_Variation_and_Hyperparameters/2023-12-29-Exploring_the_Sensitivity_of_LLMs'_Decision_Making_Capabilities__Insights_from_Prompt_Variation_and_Hyperparameters.html#appendix",
    "href": "posts/Exploring_the_Sensitivity_of_LLMs'_Decision_Making_Capabilities__Insights_from_Prompt_Variation_and_Hyperparameters/2023-12-29-Exploring_the_Sensitivity_of_LLMs'_Decision_Making_Capabilities__Insights_from_Prompt_Variation_and_Hyperparameters.html#appendix",
    "title": "Exploring the Sensitivity of LLMs’ Decision-Making Capabilities: Insights from Prompt Variation and Hyperparameters",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17476v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17476v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4103"
  },
  {
    "objectID": "posts/Unlocking_the_Potential_of_Large_Language_Models_for_Explainable_Recommendations/2023-12-25-Unlocking_the_Potential_of_Large_Language_Models_for_Explainable_Recommendations.html#appendix",
    "href": "posts/Unlocking_the_Potential_of_Large_Language_Models_for_Explainable_Recommendations/2023-12-25-Unlocking_the_Potential_of_Large_Language_Models_for_Explainable_Recommendations.html#appendix",
    "title": "Unlocking the Potential of Large Language Models for Explainable Recommendations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.15661v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.15661v2\n\n\nTruncated\nFalse\n\n\nWord Count\n9663"
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#major-takeaways",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#major-takeaways",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nThe article provides guidelines for using the jmlr class with the pmlr class option, offering advice on reducing complications when combining articles into a book.\nIt emphasizes the importance of avoiding obsolete commands and packages, ensuring the document compiles with PDFLATEX, and utilizing convenient cross-referencing commands provided by the jmlr class.\nThe article covers the formatting of equations, vectors, sets, floats (figures, tables, algorithms), description lists, theorem-like environments, citations, and the bibliography, providing detailed instructions for each."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#introduction",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#introduction",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Introduction",
    "text": "Introduction\n\nThe article provides guidelines for using the jmlr class with the pmlr class option to reduce complications when combining articles into a book.\nIt advises against using obsolete commands and packages and emphasizes the importance of ensuring the document compiles with PDFLATEX."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#cross-referencing",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#cross-referencing",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Cross-Referencing",
    "text": "Cross-Referencing\n\nThe jmlr class provides convenient cross-referencing commands for referencing sections, equations, tables, figures, algorithms, theorem-like environments, and appendices.\nExamples and syntax for using these cross-referencing commands are provided."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#equations",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#equations",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Equations",
    "text": "Equations\n\nUnnumbered and numbered single-lined equations should be displayed using specific environments and commands, with examples provided.\nMulti-lined numbered equations should be displayed using the align environment; unnumbered multi-lined equations should be displayed using the align* environment."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#vectors-and-sets",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#vectors-and-sets",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Vectors and Sets",
    "text": "Vectors and Sets\n\nVectors should be typeset using and sets using ."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#floats",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#floats",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Floats",
    "text": "Floats\n\nGuidelines for handling floats (figures, tables, and algorithms) are provided, including best practices for positioning, caption formatting, and the use of specifier."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#tables",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#tables",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Tables",
    "text": "Tables\n\nTables should go in the table environment and are advised to use the booktabs package for horizontal rules."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#figures",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#figures",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Figures",
    "text": "Figures\n\nGuidelines for including and formatting figures, including scaling images and using LATEX code for image creation, are provided."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#sub-figures",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#sub-figures",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Sub-Figures",
    "text": "Sub-Figures\n\nGuidance for creating and referencing sub-figures using the command is provided, with options for alignment and sub-caption width."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#sub-tables",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#sub-tables",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Sub-Tables",
    "text": "Sub-Tables\n\nAn analogous command for sub-tables is introduced, providing similar functionality to for sub-figures."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#algorithms",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#algorithms",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Algorithms",
    "text": "Algorithms\n\nEnumerated textual algorithms can be displayed using the algorithm environment, providing conveniences for indentation and numbering."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#description-lists",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#description-lists",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Description Lists",
    "text": "Description Lists\n\nThe jmlr class offers a description-like environment called altdescription, providing an alternative layout for descriptions."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#theorems-lemmas-etc",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#theorems-lemmas-etc",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Theorems, Lemmas etc",
    "text": "Theorems, Lemmas etc\n\nThe predefined theorem-like environments provided by the jmlr class and how to display proofs are explained, with examples for each environment."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#citations-and-bibliography",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#citations-and-bibliography",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Citations and Bibliography",
    "text": "Citations and Bibliography\n\nGuidelines for citations using natbib and \\bibliography for displaying the bibliography are provided."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#appendices",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#appendices",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Appendices",
    "text": "Appendices\n\nThe article includes examples of appendices and how they should be formatted."
  },
  {
    "objectID": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#appendix",
    "href": "posts/EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction/2023-12-29-EHR_Interaction_Between_Patients_and_AI__NoteAid_EHR_Interaction.html#appendix",
    "title": "EHR Interaction Between Patients and AI: NoteAid EHR Interaction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17475v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17475v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4742"
  },
  {
    "objectID": "posts/A_Unified_Framework_for_Multi_Domain_CTR_Prediction_via_Large_Language_Models/2023-12-17-A_Unified_Framework_for_Multi_Domain_CTR_Prediction_via_Large_Language_Models.html#summary",
    "href": "posts/A_Unified_Framework_for_Multi_Domain_CTR_Prediction_via_Large_Language_Models/2023-12-17-A_Unified_Framework_for_Multi_Domain_CTR_Prediction_via_Large_Language_Models.html#summary",
    "title": "A Unified Framework for Multi-Domain CTR Prediction via Large Language Models",
    "section": "Summary",
    "text": "Summary\n\nFindings\n\nClick-Through Rate (CTR) prediction across multiple domains is challenging due to the complex mutual influence between domains.\nExisting multi-domain CTR models struggle with the “seesaw phenomenon,” where the performance in one domain is enhanced at the expense of another domain, and they overlook rich semantic information.\nThe proposed Uni-CTR leverages Large Language Models (LLMs) to capture commonalities between domains and decouples domain-specific networks from the backbone LLM, resulting in improved performance and scalability. It outperforms state-of-the-art (SOTA) MDCTR models significantly, demonstrating remarkable effectiveness in zero-shot prediction.\n\n\n\nSections\n\nIntroduction: Describes the importance of CTR prediction across multiple domains.\nRelated Work: Reviews existing multi-domain CTR prediction tasks and discusses the use of LLMs for CTR prediction.\nPreliminary: Discusses multi-domain CTR prediction and the use of LLMs in CTR prediction.\nThe Proposed Method (Uni-CTR architecture): Describes Uni-CTR’s design, including prompt-based semantic modeling, LLM backbone, domain-specific network, and general network.\nPrediction and Loss Function: Details the loss function design and a comparative analysis with existing multi-domain recommendation methodologies.\nExperiments: Outlines the experimental settings, including datasets, evaluation metrics, and comparison with baseline models."
  },
  {
    "objectID": "posts/A_Unified_Framework_for_Multi_Domain_CTR_Prediction_via_Large_Language_Models/2023-12-17-A_Unified_Framework_for_Multi_Domain_CTR_Prediction_via_Large_Language_Models.html#critique",
    "href": "posts/A_Unified_Framework_for_Multi_Domain_CTR_Prediction_via_Large_Language_Models/2023-12-17-A_Unified_Framework_for_Multi_Domain_CTR_Prediction_via_Large_Language_Models.html#critique",
    "title": "A Unified Framework for Multi-Domain CTR Prediction via Large Language Models",
    "section": "Critique",
    "text": "Critique\n\nThe paper lacks a detailed exploration of potential limitations, such as computational complexity, efficiency, or potential biases introduced by the design of Uni-CTR.\nWhile the experimental results are presented, a more comprehensive analysis of the comparative performance and potential limitations would enhance the findings.\n\nOverall, the paper provides a valuable contribution to the field of multi-domain CTR prediction, highlighting the effectiveness of Uni-CTR in addressing the challenges associated with multi-domain CTR prediction. However, a more thorough exploration of potential limitations and an extended analysis of the experimental results would further strengthen the paper’s findings."
  },
  {
    "objectID": "posts/A_Unified_Framework_for_Multi_Domain_CTR_Prediction_via_Large_Language_Models/2023-12-17-A_Unified_Framework_for_Multi_Domain_CTR_Prediction_via_Large_Language_Models.html#appendix",
    "href": "posts/A_Unified_Framework_for_Multi_Domain_CTR_Prediction_via_Large_Language_Models/2023-12-17-A_Unified_Framework_for_Multi_Domain_CTR_Prediction_via_Large_Language_Models.html#appendix",
    "title": "A Unified Framework for Multi-Domain CTR Prediction via Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10743v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10743v1\n\n\nTruncated\nTrue\n\n\nWord Count\n17221"
  },
  {
    "objectID": "posts/Open_Set__ID_Card_Presentation_Attack_Detection_using_Neural_Transfer_Style/2023-12-21-Open_Set__ID_Card_Presentation_Attack_Detection_using_Neural_Transfer_Style.html#appendix",
    "href": "posts/Open_Set__ID_Card_Presentation_Attack_Detection_using_Neural_Transfer_Style/2023-12-21-Open_Set__ID_Card_Presentation_Attack_Detection_using_Neural_Transfer_Style.html#appendix",
    "title": "Open-Set: ID Card Presentation Attack Detection using Neural Transfer Style",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.13993v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.13993v1\n\n\nTruncated\nTrue\n\n\nWord Count\n14697"
  },
  {
    "objectID": "posts/LLM_Harmony__Multi_Agent_Communication_for_Problem_Solving/2024-01-02-LLM_Harmony__Multi_Agent_Communication_for_Problem_Solving.html#appendix",
    "href": "posts/LLM_Harmony__Multi_Agent_Communication_for_Problem_Solving/2024-01-02-LLM_Harmony__Multi_Agent_Communication_for_Problem_Solving.html#appendix",
    "title": "LLM Harmony: Multi-Agent Communication for Problem Solving",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01312v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01312v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5747"
  },
  {
    "objectID": "posts/Can_ChatGPT_Play_the_Role_of_a_Teaching_Assistant_in_an_Introductory_Programming_Course_/2023-12-12-Can_ChatGPT_Play_the_Role_of_a_Teaching_Assistant_in_an_Introductory_Programming_Course_.html#appendix",
    "href": "posts/Can_ChatGPT_Play_the_Role_of_a_Teaching_Assistant_in_an_Introductory_Programming_Course_/2023-12-12-Can_ChatGPT_Play_the_Role_of_a_Teaching_Assistant_in_an_Introductory_Programming_Course_.html#appendix",
    "title": "Can ChatGPT Play the Role of a Teaching Assistant in an Introductory Programming Course?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.07343v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.07343v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8276"
  },
  {
    "objectID": "posts/SSP__A_Simple_and_Safe_automatic_Prompt_engineering_method_towards_realistic_image_synthesis_on_LVM/2024-01-02-SSP__A_Simple_and_Safe_automatic_Prompt_engineering_method_towards_realistic_image_synthesis_on_LVM.html#appendix",
    "href": "posts/SSP__A_Simple_and_Safe_automatic_Prompt_engineering_method_towards_realistic_image_synthesis_on_LVM/2024-01-02-SSP__A_Simple_and_Safe_automatic_Prompt_engineering_method_towards_realistic_image_synthesis_on_LVM.html#appendix",
    "title": "SSP: A Simple and Safe automatic Prompt engineering method towards realistic image synthesis on LVM",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01128v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01128v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6840"
  },
  {
    "objectID": "posts/Advancing_TTP_Analysis__Harnessing_the_Power_of_Encoder_Only_and_Decoder_Only_Language_Models_with_Retrieval_Augmented_Generation/2023-12-30-Advancing_TTP_Analysis__Harnessing_the_Power_of_Encoder_Only_and_Decoder_Only_Language_Models_with_Retrieval_Augmented_Generation.html#appendix",
    "href": "posts/Advancing_TTP_Analysis__Harnessing_the_Power_of_Encoder_Only_and_Decoder_Only_Language_Models_with_Retrieval_Augmented_Generation/2023-12-30-Advancing_TTP_Analysis__Harnessing_the_Power_of_Encoder_Only_and_Decoder_Only_Language_Models_with_Retrieval_Augmented_Generation.html#appendix",
    "title": "Advancing TTP Analysis: Harnessing the Power of Encoder-Only and Decoder-Only Language Models with Retrieval Augmented Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00280v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00280v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8243"
  },
  {
    "objectID": "posts/ChatGPT_as_a_commenter_to_the_news__can_LLMs_generate_human_like_opinions_/2023-12-21-ChatGPT_as_a_commenter_to_the_news__can_LLMs_generate_human_like_opinions_.html#appendix",
    "href": "posts/ChatGPT_as_a_commenter_to_the_news__can_LLMs_generate_human_like_opinions_/2023-12-21-ChatGPT_as_a_commenter_to_the_news__can_LLMs_generate_human_like_opinions_.html#appendix",
    "title": "ChatGPT as a commenter to the news: can LLMs generate human-like opinions?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.13961v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.13961v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8845"
  },
  {
    "objectID": "posts/A_Comprehensive_Survey_of_Hallucination_Mitigation_Techniques_in_Large_Language_Models/2024-01-02-A_Comprehensive_Survey_of_Hallucination_Mitigation_Techniques_in_Large_Language_Models.html#appendix",
    "href": "posts/A_Comprehensive_Survey_of_Hallucination_Mitigation_Techniques_in_Large_Language_Models/2024-01-02-A_Comprehensive_Survey_of_Hallucination_Mitigation_Techniques_in_Large_Language_Models.html#appendix",
    "title": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01313v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01313v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13687"
  },
  {
    "objectID": "posts/LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#major-takeaways",
    "href": "posts/LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#major-takeaways",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nLarge Language Models (LLMs) show promise in identifying vulnerabilities in Android applications, outperforming existing tools in flagging insecure apps in 91.67% of cases in the Ghera benchmark.\nPrompt Engineering, a technique that optimizes LLM performance by crafting intricate prompts, is instrumental in enhancing the efficacy of LLMs for specific tasks.\nThe study introduces LLB, a Python package that leverages LLMs to scan Android projects for security vulnerabilities. The package integrates distinct scanning mechanisms, offering flexibility in the vulnerability assessment process."
  },
  {
    "objectID": "posts/LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#introduction",
    "href": "posts/LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#introduction",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "section": "Introduction",
    "text": "Introduction\n\nDespite advancements in building secure systems, Android applications remain prone to vulnerabilities, creating a demand for effective vulnerability detection methodologies.\nCurrent strategies involving static and dynamic analysis tools have limitations such as overwhelming false positives and adaptability challenges."
  },
  {
    "objectID": "posts/LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#leveraging-large-language-models-for-vulnerability-detection",
    "href": "posts/LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#leveraging-large-language-models-for-vulnerability-detection",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "section": "Leveraging Large Language Models for Vulnerability Detection",
    "text": "Leveraging Large Language Models for Vulnerability Detection\n\nLLMs have shown potential in understanding semantics in both human and programming languages.\nPrior research has explored the use of LLMs for vulnerability detection, showing promising results, which leads to an exploration of LLMs in the context of Android security."
  },
  {
    "objectID": "posts/LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#prompt-engineering",
    "href": "posts/LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#prompt-engineering",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "section": "Prompt Engineering",
    "text": "Prompt Engineering\n\nPrompt Engineering involves intricate prompt construction to optimize AI performance by guiding the model through a sequence of prompts that enrich and build upon each other.\nChain-of-Thought Prompting is one groundbreaking strategy within Prompt Engineering that allows for more depth in AI reasoning."
  },
  {
    "objectID": "posts/LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#retrieval-augmented-generation",
    "href": "posts/LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#retrieval-augmented-generation",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "section": "Retrieval-Augmented Generation",
    "text": "Retrieval-Augmented Generation\n\nRetrieval-Augmented Generation (RAG) is an AI framework designed to enhance the quality of responses generated by LLMs by leveraging a specialized body of knowledge to answer questions more accurately."
  },
  {
    "objectID": "posts/LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#results",
    "href": "posts/LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#results",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "section": "Results",
    "text": "Results\n\nExperiments demonstrate that with sufficient context, GPT4 can successfully identify vulnerabilities in Android applications.\nThe study introduces LLB, a Python package that leverages LLMs to scan Android projects for security vulnerabilities and includes a Command Line Interface and expert command for post-scan analysis."
  },
  {
    "objectID": "posts/LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#case-study",
    "href": "posts/LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#case-study",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "section": "Case Study",
    "text": "Case Study\n\nThe LLB package correctly identifies 6 of the 8 seeded vulnerabilities in the Vuldroid application, providing valid fixes and walking through the reasoning involved."
  },
  {
    "objectID": "posts/LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#discussion-and-future-work",
    "href": "posts/LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#discussion-and-future-work",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "section": "Discussion and Future Work",
    "text": "Discussion and Future Work\n\nFurther work is needed to optimize the performance of LLB as an analyzer and consider incorporating static analysis into the framework.\nThe dynamic nature of Android platform and cybersecurity threats necessitates continuous updates and retraining of LLMs, which can be resource-intensive."
  },
  {
    "objectID": "posts/LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#conclusion",
    "href": "posts/LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#conclusion",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "section": "Conclusion",
    "text": "Conclusion\n\nLLMs demonstrate promise in detecting Android vulnerabilities, but require further work in drafting a better analysis pipeline architecture and optimizing the context available to the LLM."
  },
  {
    "objectID": "posts/LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#critique",
    "href": "posts/LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#critique",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "section": "Critique",
    "text": "Critique\n\nThe study acknowledges potential bias and limitations in prompt engineering, as poorly designed prompts can lead to suboptimal results and introduce bias.\nLeakage of semantic information and varying performance of LLMs are potential concerns impacting the replicability of results."
  },
  {
    "objectID": "posts/LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#potential-problems",
    "href": "posts/LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#potential-problems",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "section": "Potential Problems",
    "text": "Potential Problems\n\nThe study highlights potential biases introduced through prompt engineering and the need for continuous updates and retraining of LLMs, which could be resource-intensive and impact the applicability of the findings."
  },
  {
    "objectID": "posts/LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#appendix",
    "href": "posts/LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection/2024-01-02-LLbezpeky__Leveraging_Large_Language_Models_for_Vulnerability_Detection.html#appendix",
    "title": "LLbezpeky: Leveraging Large Language Models for Vulnerability Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01269v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01269v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8022"
  },
  {
    "objectID": "posts/De_Hallucinator__Iterative_Grounding_for_LLM_Based_Code_Completion/2024-01-03-De_Hallucinator__Iterative_Grounding_for_LLM_Based_Code_Completion.html#takeaways",
    "href": "posts/De_Hallucinator__Iterative_Grounding_for_LLM_Based_Code_Completion/2024-01-03-De_Hallucinator__Iterative_Grounding_for_LLM_Based_Code_Completion.html#takeaways",
    "title": "De-Hallucinator: Iterative Grounding for LLM-Based Code Completion",
    "section": "Takeaways",
    "text": "Takeaways\n\nLarge language models (LLMs) have been successful in code completion, but they lack knowledge of project-specific APIs, resulting in inaccurate completions and “hallucinated” code.\nDe-Hallucinator addresses this challenge by iteratively querying the LLM with increasingly suitable context information, thus improving the predicted code and recall of correctly predicted API usages.\nThe approach is language-agnostic and designed to work with any off-the-shelf LLM trained on code, making it a versatile solution for improving code completion accuracy."
  },
  {
    "objectID": "posts/De_Hallucinator__Iterative_Grounding_for_LLM_Based_Code_Completion/2024-01-03-De_Hallucinator__Iterative_Grounding_for_LLM_Based_Code_Completion.html#introduction",
    "href": "posts/De_Hallucinator__Iterative_Grounding_for_LLM_Based_Code_Completion/2024-01-03-De_Hallucinator__Iterative_Grounding_for_LLM_Based_Code_Completion.html#introduction",
    "title": "De-Hallucinator: Iterative Grounding for LLM-Based Code Completion",
    "section": "Introduction",
    "text": "Introduction\n\nLarge language models (LLMs) have shown promise in code completion tasks, but they lack project-specific API knowledge, leading to incomplete and inaccurate code predictions."
  },
  {
    "objectID": "posts/De_Hallucinator__Iterative_Grounding_for_LLM_Based_Code_Completion/2024-01-03-De_Hallucinator__Iterative_Grounding_for_LLM_Based_Code_Completion.html#approach",
    "href": "posts/De_Hallucinator__Iterative_Grounding_for_LLM_Based_Code_Completion/2024-01-03-De_Hallucinator__Iterative_Grounding_for_LLM_Based_Code_Completion.html#approach",
    "title": "De-Hallucinator: Iterative Grounding for LLM-Based Code Completion",
    "section": "Approach",
    "text": "Approach\n\nStatic Pre-Analysis\n\nThe approach utilizes CodeQL to statically analyze code and extract API references for fast retrieval during the code completion process. The extracted API references are then indexed for efficient querying.\n\n\n\nRetrieval of Related APIs\n\nDe-Hallucinator retrieves relevant API references based on similarity to the input code, providing a ranked list of project-specific API references to be added to the prompt.\n\n\n\nPrompt Construction\n\nThe augmented prompt is designed to resemble “normal” code and consists of a commented block of relevant API references followed by the original prompt.\n\n\n\nIntegration with the LLM\n\nDe-Hallucinator queries the LLM as a black box and post-processes the completion to make it syntactically correct and remove extraneous completions."
  },
  {
    "objectID": "posts/De_Hallucinator__Iterative_Grounding_for_LLM_Based_Code_Completion/2024-01-03-De_Hallucinator__Iterative_Grounding_for_LLM_Based_Code_Completion.html#evaluation",
    "href": "posts/De_Hallucinator__Iterative_Grounding_for_LLM_Based_Code_Completion/2024-01-03-De_Hallucinator__Iterative_Grounding_for_LLM_Based_Code_Completion.html#evaluation",
    "title": "De-Hallucinator: Iterative Grounding for LLM-Based Code Completion",
    "section": "Evaluation",
    "text": "Evaluation\n\nThe approach is evaluated on four state-of-the-art LLMs for code completion, demonstrating consistent improvements in predicted code, edit distance, and recall of correctly predicted API usages compared to querying the model with a fixed prompt."
  },
  {
    "objectID": "posts/De_Hallucinator__Iterative_Grounding_for_LLM_Based_Code_Completion/2024-01-03-De_Hallucinator__Iterative_Grounding_for_LLM_Based_Code_Completion.html#appendix",
    "href": "posts/De_Hallucinator__Iterative_Grounding_for_LLM_Based_Code_Completion/2024-01-03-De_Hallucinator__Iterative_Grounding_for_LLM_Based_Code_Completion.html#appendix",
    "title": "De-Hallucinator: Iterative Grounding for LLM-Based Code Completion",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01701v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01701v1\n\n\nTruncated\nTrue\n\n\nWord Count\n14084"
  },
  {
    "objectID": "posts/Red_Teaming_for_Large_Language_Models_At_Scale__Tackling_Hallucinations_on_Mathematics_Tasks/2023-12-30-Red_Teaming_for_Large_Language_Models_At_Scale__Tackling_Hallucinations_on_Mathematics_Tasks.html#appendix",
    "href": "posts/Red_Teaming_for_Large_Language_Models_At_Scale__Tackling_Hallucinations_on_Mathematics_Tasks/2023-12-30-Red_Teaming_for_Large_Language_Models_At_Scale__Tackling_Hallucinations_on_Mathematics_Tasks.html#appendix",
    "title": "Red Teaming for Large Language Models At Scale: Tackling Hallucinations on Mathematics Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00290v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00290v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7380"
  },
  {
    "objectID": "posts/Distribution_Matching_for_Multi_Task_Learning_of_Classification_Tasks__a_Large_Scale_Study_on_Faces_&_Beyond/2024-01-02-Distribution_Matching_for_Multi_Task_Learning_of_Classification_Tasks__a_Large_Scale_Study_on_Faces_&_Beyond.html#appendix",
    "href": "posts/Distribution_Matching_for_Multi_Task_Learning_of_Classification_Tasks__a_Large_Scale_Study_on_Faces_&_Beyond/2024-01-02-Distribution_Matching_for_Multi_Task_Learning_of_Classification_Tasks__a_Large_Scale_Study_on_Faces_&_Beyond.html#appendix",
    "title": "Distribution Matching for Multi-Task Learning of Classification Tasks: a Large-Scale Study on Faces & Beyond",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01219v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01219v1\n\n\nTruncated\nTrue\n\n\nWord Count\n14703"
  },
  {
    "objectID": "posts/Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#overview",
    "href": "posts/Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#overview",
    "title": "Prompt Engineering-assisted Malware Dynamic Analysis Using GPT-4",
    "section": "Overview",
    "text": "Overview\n\nMajor Takeaways\n\nAPI Sequence as Dynamic Malware Behavior: The API sequence, composed of consecutive API calls, is a significant representation of dynamic malware behavior in dynamic analysis methods.\nIntroduction of Prompt Engineering & GPT-4: This paper introduces a method for generating representations for API calls using GPT-4 and prompt engineering, achieving excellent detection performance in dynamic malware analysis.\nSuperior Generalization Performance: The proposed model demonstrates superior generalization performance, effectively addressing issues such as weak generalization and concept drift in dynamic malware analysis."
  },
  {
    "objectID": "posts/Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#experiment-analysis",
    "href": "posts/Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#experiment-analysis",
    "title": "Prompt Engineering-assisted Malware Dynamic Analysis Using GPT-4",
    "section": "Experiment Analysis",
    "text": "Experiment Analysis\n\nComparison of Representation Quality\n\nThe proposed model outperforms existing models in generating denser representations and capturing associations between API calls effectively, as demonstrated in case studies.\nFew-shot learning experiments show that the proposed model achieves superior fine-tuning and adaptation in comparison to TextCNN and BiLSTM.\n\n\n\nAnalysis of Concept Drift Alleviation\n\nThe proposed model effectively addresses the concept drift phenomenon, demonstrating excellent recall rates for malware even in the presence of new or previously unseen API calls."
  },
  {
    "objectID": "posts/Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#critique",
    "href": "posts/Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#critique",
    "title": "Prompt Engineering-assisted Malware Dynamic Analysis Using GPT-4",
    "section": "Critique",
    "text": "Critique\n\nThe paper could benefit from more detailed information on the limitations or potential biases of the proposed method.\nFurther clarification on the real-world applicability and scalability of the proposed model would enhance the paper’s significance.\n\nOverall, the paper provides a promising approach to dynamic malware analysis, but further studies and real-world implementations are required to validate its full potential."
  },
  {
    "objectID": "posts/Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#appendix",
    "href": "posts/Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-Prompt_Engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#appendix",
    "title": "Prompt Engineering-assisted Malware Dynamic Analysis Using GPT-4",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-03\n\n\nAbstract\nhttp://arxiv.org/abs/2312.08317v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.08317v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13381"
  },
  {
    "objectID": "posts/Benchmarking_Large_Language_Models_on_Controllable_Generation_under_Diversified_Instructions/2024-01-01-Benchmarking_Large_Language_Models_on_Controllable_Generation_under_Diversified_Instructions.html#appendix",
    "href": "posts/Benchmarking_Large_Language_Models_on_Controllable_Generation_under_Diversified_Instructions/2024-01-01-Benchmarking_Large_Language_Models_on_Controllable_Generation_under_Diversified_Instructions.html#appendix",
    "title": "Benchmarking Large Language Models on Controllable Generation under Diversified Instructions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00690v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00690v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12181"
  },
  {
    "objectID": "posts/Overview_of_the_PromptCBLUE_Shared_Task_in_CHIP2023/2023-12-29-Overview_of_the_PromptCBLUE_Shared_Task_in_CHIP2023.html#appendix",
    "href": "posts/Overview_of_the_PromptCBLUE_Shared_Task_in_CHIP2023/2023-12-29-Overview_of_the_PromptCBLUE_Shared_Task_in_CHIP2023.html#appendix",
    "title": "Overview of the PromptCBLUE Shared Task in CHIP2023",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17522v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17522v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7037"
  },
  {
    "objectID": "posts/Toward_enriched_Cognitive_Learning_with_XAI/2023-12-19-Toward_enriched_Cognitive_Learning_with_XAI.html#appendix",
    "href": "posts/Toward_enriched_Cognitive_Learning_with_XAI/2023-12-19-Toward_enriched_Cognitive_Learning_with_XAI.html#appendix",
    "title": "Toward enriched Cognitive Learning with XAI",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.12290v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.12290v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5546"
  },
  {
    "objectID": "posts/Principled_Instructions_Are_All_You_Need_for_Questioning_LLaMA_1_2__GPT_3.5_4/2023-12-26-Principled_Instructions_Are_All_You_Need_for_Questioning_LLaMA_1_2__GPT_3.5_4.html#appendix",
    "href": "posts/Principled_Instructions_Are_All_You_Need_for_Questioning_LLaMA_1_2__GPT_3.5_4/2023-12-26-Principled_Instructions_Are_All_You_Need_for_Questioning_LLaMA_1_2__GPT_3.5_4.html#appendix",
    "title": "Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16171v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16171v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5205"
  },
  {
    "objectID": "posts/The_Art_of_Defending__A_Systematic_Evaluation_and_Analysis_of_LLM_Defense_Strategies_on_Safety_and_Over_Defensiveness/2023-12-30-The_Art_of_Defending__A_Systematic_Evaluation_and_Analysis_of_LLM_Defense_Strategies_on_Safety_and_Over_Defensiveness.html#appendix",
    "href": "posts/The_Art_of_Defending__A_Systematic_Evaluation_and_Analysis_of_LLM_Defense_Strategies_on_Safety_and_Over_Defensiveness/2023-12-30-The_Art_of_Defending__A_Systematic_Evaluation_and_Analysis_of_LLM_Defense_Strategies_on_Safety_and_Over_Defensiveness.html#appendix",
    "title": "The Art of Defending: A Systematic Evaluation and Analysis of LLM Defense Strategies on Safety and Over-Defensiveness",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00287v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00287v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8573"
  },
  {
    "objectID": "posts/SecFormer__Towards_Fast_and_Accurate_Privacy_Preserving_Inference_for_Large_Language_Models/2024-01-01-SecFormer__Towards_Fast_and_Accurate_Privacy_Preserving_Inference_for_Large_Language_Models.html#appendix",
    "href": "posts/SecFormer__Towards_Fast_and_Accurate_Privacy_Preserving_Inference_for_Large_Language_Models/2024-01-01-SecFormer__Towards_Fast_and_Accurate_Privacy_Preserving_Inference_for_Large_Language_Models.html#appendix",
    "title": "SecFormer: Towards Fast and Accurate Privacy-Preserving Inference for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00793v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00793v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10983"
  },
  {
    "objectID": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#major-takeaways",
    "href": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#major-takeaways",
    "title": "Large Language Models Relearn Removed Concepts",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nNeuroplasticity: Large language models (LLMs) demonstrate the ability to quickly regain performance and redistribute pruned concepts after retraining.\nConcept Redistribution: Pruned concepts originally present in later layers are remapped to neurons in earlier layers, demonstrating the resilience of LLMs.\nPolysemantic Capacities: Neurons show polysemantic properties, capturing a blend of old and new concepts during relearning."
  },
  {
    "objectID": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#abstract",
    "href": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#abstract",
    "title": "Large Language Models Relearn Removed Concepts",
    "section": "Abstract",
    "text": "Abstract\nThe study investigates neuroplasticity in large language models (LLMs) by exploring their capacity to reacquire pruned concepts after editing. The findings suggest that models can quickly regain performance post-pruning by relocating advanced concepts to earlier layers and reallocating pruned concepts to primed neurons with similar semantics. The paper highlights the challenges of permanent concept removal for improved model safety and the importance of monitoring concept reemergence and developing techniques to mitigate relearning of unsafe concepts."
  },
  {
    "objectID": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#introduction",
    "href": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#introduction",
    "title": "Large Language Models Relearn Removed Concepts",
    "section": "Introduction",
    "text": "Introduction\nLarge language models encode semantic concepts across different languages, architectures, and modalities. The primary objective when pruning such models is to eliminate redundant neurons while preserving the most crucial ones, leading to the assumption that removing important “concept neurons” will disrupt the model’s structured internal representation of key concepts. However, the paper presents evidence of neuroplasticity in models, allowing them to regain high performance after pruning random or important neurons. This phenomenon, termed “neuroplasticity,” demonstrates a degree of adaptability in such models and has significant implications for model editing."
  },
  {
    "objectID": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#related-work",
    "href": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#related-work",
    "title": "Large Language Models Relearn Removed Concepts",
    "section": "Related Work",
    "text": "Related Work\nThe paper builds on previous works that have analyzed the distribution of concept representations in LLMs and studied performance recovery after pruning. It is noted that prior works artificially redistributed concepts in large language models by modifying the activations of specific neurons, but there is limited understanding of how concept redistribution naturally occurs after pruning. The study also compares its approach with similar works in the field."
  },
  {
    "objectID": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#problem-setting",
    "href": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#problem-setting",
    "title": "Large Language Models Relearn Removed Concepts",
    "section": "Problem Setting",
    "text": "Problem Setting\nThe paper provides a formal definition of concept neurons, concept saliency, and concept similarity, and outlines the process for identifying and pruning top concept neurons in a language model to induce neuroplasticity."
  },
  {
    "objectID": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#method",
    "href": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#method",
    "title": "Large Language Models Relearn Removed Concepts",
    "section": "Method",
    "text": "Method\nThe researchers explore neuroplasticity within a pretrained model by fine-tuning the model for a specific task, identifying and pruning concept neurons, and tracking the redistribution of concepts over the retraining process. They explore the concept saliency and similarity to analyze the redistribution of concepts in the model after neuroplasticity."
  },
  {
    "objectID": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#experimental-setup",
    "href": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#experimental-setup",
    "title": "Large Language Models Relearn Removed Concepts",
    "section": "Experimental Setup",
    "text": "Experimental Setup\nThe study focuses on pruning the specific concept of location names from different LLMs and analyzes the models across different runs. The model architectures, training, and evaluations are clearly described."
  },
  {
    "objectID": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#results",
    "href": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#results",
    "title": "Large Language Models Relearn Removed Concepts",
    "section": "Results",
    "text": "Results\nThe paper presents a detailed analysis of the rapid performance recovery after retraining, high-level concept redistribution, and the relocation of pruned concepts. It also delves into the polysemantic characteristics of neurons after retraining."
  },
  {
    "objectID": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#conclusion",
    "href": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#conclusion",
    "title": "Large Language Models Relearn Removed Concepts",
    "section": "Conclusion",
    "text": "Conclusion\nThe findings contribute to a deeper understanding of how language models learn, adapt, and retain core conceptual representations. It also suggests potential research directions in model editing and transfer learning. The paper concludes by emphasizing the need for studying the implications of neuroplasticity-induced polysemanticity to aid the development of interpretable models and the enhanced transfer of learned representations."
  },
  {
    "objectID": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#critique",
    "href": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#critique",
    "title": "Large Language Models Relearn Removed Concepts",
    "section": "Critique",
    "text": "Critique\nThe paper provides valuable insights into neuroplasticity and concept reshaping in LLMs. However, the precise relationship between concept similarity and saliency and the generalizability of the findings to other LLMs require further investigation. Additionally, the paper acknowledges the potential wider impacts of its findings and emphasizes the importance of ethical and responsible AI research."
  },
  {
    "objectID": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#appendix",
    "href": "posts/Large_Language_Models_Relearn_Removed_Concepts/2024-01-03-Large_Language_Models_Relearn_Removed_Concepts.html#appendix",
    "title": "Large Language Models Relearn Removed Concepts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01814v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01814v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12729"
  },
  {
    "objectID": "posts/AI_Gender_Bias__Disparities__and_Fairness__Does_Training_Data_Matter_/2023-12-17-AI_Gender_Bias__Disparities__and_Fairness__Does_Training_Data_Matter_.html#major-findings",
    "href": "posts/AI_Gender_Bias__Disparities__and_Fairness__Does_Training_Data_Matter_/2023-12-17-AI_Gender_Bias__Disparities__and_Fairness__Does_Training_Data_Matter_.html#major-findings",
    "title": "AI Gender Bias, Disparities, and Fairness: Does Training Data Matter?",
    "section": "Major Findings",
    "text": "Major Findings\n\nMinimal Scoring Bias: The study found that training AI models on gender-unbalanced data did not lead to significant scoring bias. Mixed-trained models showed no significant difference in scoring accuracy compared to gender-specifically trained models, suggesting minimal scoring bias.\nReduced Disparities: Mixed-trained models generated fewer mean score gaps and reduced gender disparities compared to gender-specifically trained models, indicating that unbalanced training data may create algorithmic models that enlarge gender disparities.\nEnhanced Fairness: The Equalized Odds analysis suggests that mixed-trained models generated fairer outcomes compared with gender-specifically trained models, further highlighting the potential of balanced training data in addressing gender fairness."
  },
  {
    "objectID": "posts/AI_Gender_Bias__Disparities__and_Fairness__Does_Training_Data_Matter_/2023-12-17-AI_Gender_Bias__Disparities__and_Fairness__Does_Training_Data_Matter_.html#methodology",
    "href": "posts/AI_Gender_Bias__Disparities__and_Fairness__Does_Training_Data_Matter_/2023-12-17-AI_Gender_Bias__Disparities__and_Fairness__Does_Training_Data_Matter_.html#methodology",
    "title": "AI Gender Bias, Disparities, and Fairness: Does Training Data Matter?",
    "section": "Methodology",
    "text": "Methodology\n\nThe study employed a comprehensive methodology, including data analysis using BERT and GPT-3.5, statistical techniques such as Scoring Accuracy Difference, Mean Score Gap, and Equalized Odds evaluation."
  },
  {
    "objectID": "posts/AI_Gender_Bias__Disparities__and_Fairness__Does_Training_Data_Matter_/2023-12-17-AI_Gender_Bias__Disparities__and_Fairness__Does_Training_Data_Matter_.html#background",
    "href": "posts/AI_Gender_Bias__Disparities__and_Fairness__Does_Training_Data_Matter_/2023-12-17-AI_Gender_Bias__Disparities__and_Fairness__Does_Training_Data_Matter_.html#background",
    "title": "AI Gender Bias, Disparities, and Fairness: Does Training Data Matter?",
    "section": "Background",
    "text": "Background\n\nAI in Education: The role of AI in education, implications, and ethical considerations.\nAutomatic Scoring in Education: Advancements, challenges, and machine-human score agreements.\nAI Gender Bias, Disparities, and Fairness: The complexities and implications of gender biases in AI and the need for a multidisciplinary approach."
  },
  {
    "objectID": "posts/AI_Gender_Bias__Disparities__and_Fairness__Does_Training_Data_Matter_/2023-12-17-AI_Gender_Bias__Disparities__and_Fairness__Does_Training_Data_Matter_.html#results",
    "href": "posts/AI_Gender_Bias__Disparities__and_Fairness__Does_Training_Data_Matter_/2023-12-17-AI_Gender_Bias__Disparities__and_Fairness__Does_Training_Data_Matter_.html#results",
    "title": "AI Gender Bias, Disparities, and Fairness: Does Training Data Matter?",
    "section": "Results",
    "text": "Results\n\nScoring Accuracy Difference Evaluation: Both BERT and GPT-3.5 models demonstrated consistent performance across mixed and gender-specific datasets, suggesting minimal gender biases.\nMean Score Gap: Training with a mixed dataset in both BERT and GPT-3.5 models showed reduced MSG compared to gender-specific training, indicating reduced gender disparities and heightened fairness.\nEqualized Odds Evaluation: Mixed trained models for both BERT and GPT-3.5 showed lower EO values, suggesting more equitable predictions and higher fairness compared to gender-specific models."
  },
  {
    "objectID": "posts/AI_Gender_Bias__Disparities__and_Fairness__Does_Training_Data_Matter_/2023-12-17-AI_Gender_Bias__Disparities__and_Fairness__Does_Training_Data_Matter_.html#critique",
    "href": "posts/AI_Gender_Bias__Disparities__and_Fairness__Does_Training_Data_Matter_/2023-12-17-AI_Gender_Bias__Disparities__and_Fairness__Does_Training_Data_Matter_.html#critique",
    "title": "AI Gender Bias, Disparities, and Fairness: Does Training Data Matter?",
    "section": "Critique",
    "text": "Critique\n\nPotential Problems: While the study demonstrates the potential of balanced training data in addressing gender fairness, it may benefit from a more extensive dataset and broader representation across academic disciplines to generalize the findings.\n\nOverall, the study provides valuable insights into the impact of training data on gender biases in AI scoring systems and emphasizes the significance of inclusive and equitable AI practices in education."
  },
  {
    "objectID": "posts/AI_Gender_Bias__Disparities__and_Fairness__Does_Training_Data_Matter_/2023-12-17-AI_Gender_Bias__Disparities__and_Fairness__Does_Training_Data_Matter_.html#appendix",
    "href": "posts/AI_Gender_Bias__Disparities__and_Fairness__Does_Training_Data_Matter_/2023-12-17-AI_Gender_Bias__Disparities__and_Fairness__Does_Training_Data_Matter_.html#appendix",
    "title": "AI Gender Bias, Disparities, and Fairness: Does Training Data Matter?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10833v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10833v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9836"
  },
  {
    "objectID": "posts/How_Far_Are_We_from_Believable_AI_Agents__A_Framework_for_Evaluating_the_Believability_of_Human_Behavior_Simulation/2023-12-28-How_Far_Are_We_from_Believable_AI_Agents__A_Framework_for_Evaluating_the_Believability_of_Human_Behavior_Simulation.html#appendix",
    "href": "posts/How_Far_Are_We_from_Believable_AI_Agents__A_Framework_for_Evaluating_the_Believability_of_Human_Behavior_Simulation/2023-12-28-How_Far_Are_We_from_Believable_AI_Agents__A_Framework_for_Evaluating_the_Believability_of_Human_Behavior_Simulation.html#appendix",
    "title": "How Far Are We from Believable AI Agents? A Framework for Evaluating the Believability of Human Behavior Simulation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17115v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17115v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8635"
  },
  {
    "objectID": "posts/On_Device_Recommender_Systems__A_Tutorial_on_The_New_Generation_Recommendation_Paradigm/2023-12-18-On_Device_Recommender_Systems__A_Tutorial_on_The_New_Generation_Recommendation_Paradigm.html#appendix",
    "href": "posts/On_Device_Recommender_Systems__A_Tutorial_on_The_New_Generation_Recommendation_Paradigm/2023-12-18-On_Device_Recommender_Systems__A_Tutorial_on_The_New_Generation_Recommendation_Paradigm.html#appendix",
    "title": "On-Device Recommender Systems: A Tutorial on The New-Generation Recommendation Paradigm",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10864v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10864v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4195"
  },
  {
    "objectID": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#key-findings",
    "href": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#key-findings",
    "title": "Neural Contextual Bandits for Personalized Recommendation",
    "section": "Key Findings",
    "text": "Key Findings\n\nContextual bandits offer an effective framework for personalized recommendations in online businesses, addressing the shortcomings of static supervised learning methods and the “Matthew Effect” in recommender systems.\nNeural contextual bandits have emerged as a crucial branch, leveraging the representation power of neural networks to tackle non-linear problem settings in the realm of contextual bandits for personalized recommendation.\nThis tutorial aims to provide an extensive review of advanced algorithms and theories, collaborative strategies, and open challenges in the field of neural contextual bandits for personalized recommendation."
  },
  {
    "objectID": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#introduction",
    "href": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#introduction",
    "title": "Neural Contextual Bandits for Personalized Recommendation",
    "section": "Introduction",
    "text": "Introduction\n\nRecommender systems play a crucial role in online businesses, traditionally relying on static supervised learning methods.\nThe ideal recommender system should adapt over time, prompting the formulation of the recommendation process as a sequential decision-making process.\nContextual bandits and neural contextual bandits have been introduced as techniques to address the challenges of balancing exploitation and exploration in personalized recommendation."
  },
  {
    "objectID": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#target-audience",
    "href": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#target-audience",
    "title": "Neural Contextual Bandits for Personalized Recommendation",
    "section": "Target Audience",
    "text": "Target Audience\n\nThe tutorial targets individuals interested in multi-armed bandits, reinforcement learning, information retrieval, data mining, and recommender systems, with a balance of introductory and advanced material."
  },
  {
    "objectID": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#short-bio-of-presenters",
    "href": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#short-bio-of-presenters",
    "title": "Neural Contextual Bandits for Personalized Recommendation",
    "section": "Short Bio of Presenters",
    "text": "Short Bio of Presenters\n\nYikun Ban, Yunzhe Qi, and Jingrui He are experienced researchers and practitioners with expertise in multi-armed bandits, reinforcement learning, and personalized recommendation systems."
  },
  {
    "objectID": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#outline",
    "href": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#outline",
    "title": "Neural Contextual Bandits for Personalized Recommendation",
    "section": "Outline",
    "text": "Outline\n\nThe tutorial comprises four parts: the introduction, linear contextual bandits, neural contextual bandits, collaborative contextual bandits, and open questions and future trends.\nEach part includes a deep dive into various algorithms, theories, and applications of contextual bandits in personalized recommendation settings."
  },
  {
    "objectID": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#related-tutorials-or-talks",
    "href": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#related-tutorials-or-talks",
    "title": "Neural Contextual Bandits for Personalized Recommendation",
    "section": "Related Tutorials or Talks",
    "text": "Related Tutorials or Talks\n\nContrasting with other industry and academic tutorials, this tutorial focuses specifically on neural contextual bandits and collaborative contextual bandits for personalized recommendation."
  },
  {
    "objectID": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#previous-editions",
    "href": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#previous-editions",
    "title": "Neural Contextual Bandits for Personalized Recommendation",
    "section": "Previous Editions",
    "text": "Previous Editions\n\nThis tutorial marks the first edition, but the presenters have prior experience in teaching material covering similar topics."
  },
  {
    "objectID": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#critique",
    "href": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#critique",
    "title": "Neural Contextual Bandits for Personalized Recommendation",
    "section": "Critique",
    "text": "Critique\nThe abstract and outline provide a comprehensive overview of the tutorial’s content, but the abstract could be more succinct. Additionally, the excessive focus on the presenters’ achievements might detract from the tutorial’s core content. The lack of specific case studies or real-world applications of the discussed algorithms and theories could limit the practical applicability of the tutorial."
  },
  {
    "objectID": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#appendix",
    "href": "posts/Neural_Contextual_Bandits_for_Personalized_Recommendation/2023-12-21-Neural_Contextual_Bandits_for_Personalized_Recommendation.html#appendix",
    "title": "Neural Contextual Bandits for Personalized Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.14037v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.14037v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4052"
  },
  {
    "objectID": "posts/Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis.html#major-takeaways",
    "href": "posts/Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis.html#major-takeaways",
    "title": "Inter-X: Towards Versatile Human-Human Interaction Analysis",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nInter-X Dataset: Proposes the Inter-X dataset, a comprehensive human-human interaction dataset with accurate body movements, diverse interaction patterns, and detailed hand gestures.\nUnified Benchmark: Introduces a unified benchmark for 4 categories of downstream tasks in the perceptual and generative directions.\nExtensive Experiments: Conducts extensive experiments and analysis, showing that Inter-X poses challenges for human-human interaction-related tasks."
  },
  {
    "objectID": "posts/Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis.html#abstract",
    "href": "posts/Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis.html#abstract",
    "title": "Inter-X: Towards Versatile Human-Human Interaction Analysis",
    "section": "Abstract",
    "text": "Abstract\nThe paper introduces the Inter-X dataset, a large-scale human-human interaction dataset with accurate body movements, diverse interaction patterns, and detailed hand gestures. It also proposes a unified benchmark for 4 categories of downstream tasks from both perceptual and generative directions."
  },
  {
    "objectID": "posts/Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis.html#introduction",
    "href": "posts/Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis.html#introduction",
    "title": "Inter-X: Towards Versatile Human-Human Interaction Analysis",
    "section": "Introduction",
    "text": "Introduction\n\nUnderstanding human-human interactions is crucial for intelligent digital human systems with applications in surveillance, AR/VR, games, and robotics.\nExisting datasets lack accurate body motions, hand gestures, and fine-grained textual descriptions, hindering progress in human-human interaction analysis."
  },
  {
    "objectID": "posts/Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis.html#related-work",
    "href": "posts/Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis.html#related-work",
    "title": "Inter-X: Towards Versatile Human-Human Interaction Analysis",
    "section": "Related Work",
    "text": "Related Work\n\nDiscusses existing human motion and human-human interaction datasets and their functionalities."
  },
  {
    "objectID": "posts/Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis.html#the-inter-x-dataset",
    "href": "posts/Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis.html#the-inter-x-dataset",
    "title": "Inter-X: Towards Versatile Human-Human Interaction Analysis",
    "section": "The Inter-X Dataset",
    "text": "The Inter-X Dataset\n\nData Capturing System\n\nUtilizes an optical MoCap system for accurate body movements and inertial gloves for capturing finger gestures without occlusions.\nCaptures 40 daily interaction categories, involving 11K motion sequences and 8.1M frames.\n\n\n\nData Postprocessing\n\nInvolves aligning body poses from the MoCap system with finger gestures and segmenting interaction snippets."
  },
  {
    "objectID": "posts/Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis.html#dataset-taxonomy",
    "href": "posts/Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis.html#dataset-taxonomy",
    "title": "Inter-X: Towards Versatile Human-Human Interaction Analysis",
    "section": "Dataset Taxonomy",
    "text": "Dataset Taxonomy\n\nEnriches the dataset with high-precision human-human interaction sequences and multifaceted annotations, including textual descriptions, action categories, interaction order, and relationship/personality information."
  },
  {
    "objectID": "posts/Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis.html#task-taxonomy",
    "href": "posts/Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis.html#task-taxonomy",
    "title": "Inter-X: Towards Versatile Human-Human Interaction Analysis",
    "section": "Task Taxonomy",
    "text": "Task Taxonomy\n\nOutlines 4 categories of downstream tasks enabled by the dataset: Texts related Tasks, Actions related Tasks, Interaction-order related Tasks, and Relationship & Personality related Tasks."
  },
  {
    "objectID": "posts/Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis.html#experiments",
    "href": "posts/Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis.html#experiments",
    "title": "Inter-X: Towards Versatile Human-Human Interaction Analysis",
    "section": "Experiments",
    "text": "Experiments\n\nReports experiments and evaluations for text-conditioned interaction generation, action-conditioned interaction generation, human reaction generation, and human interaction recognition."
  },
  {
    "objectID": "posts/Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis.html#conclusion-and-limitation",
    "href": "posts/Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis.html#conclusion-and-limitation",
    "title": "Inter-X: Towards Versatile Human-Human Interaction Analysis",
    "section": "Conclusion and Limitation",
    "text": "Conclusion and Limitation\n\nHighlights the contributions of the Inter-X dataset and acknowledges limitations in facial expressions and the duration of interactions."
  },
  {
    "objectID": "posts/Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis.html#appendix",
    "href": "posts/Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis.html#appendix",
    "title": "Inter-X: Towards Versatile Human-Human Interaction Analysis",
    "section": "Appendix",
    "text": "Appendix\n\nIncludes additional experiments, SMPL-X optimization details, the action categories, samples of textual annotations, and visualization results."
  },
  {
    "objectID": "posts/Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis.html#appendix-1",
    "href": "posts/Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis/2023-12-26-Inter_X__Towards_Versatile_Human_Human_Interaction_Analysis.html#appendix-1",
    "title": "Inter-X: Towards Versatile Human-Human Interaction Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16051v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16051v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11982"
  },
  {
    "objectID": "posts/LLM_Interactive_Optimization_of_Open_Source_Python_Libraries____Case_Studies_and_Generalization/2023-12-08-LLM_Interactive_Optimization_of_Open_Source_Python_Libraries____Case_Studies_and_Generalization.html#appendix",
    "href": "posts/LLM_Interactive_Optimization_of_Open_Source_Python_Libraries____Case_Studies_and_Generalization/2023-12-08-LLM_Interactive_Optimization_of_Open_Source_Python_Libraries____Case_Studies_and_Generalization.html#appendix",
    "title": "LLM Interactive Optimization of Open Source Python Libraries – Case Studies and Generalization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.14949v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.14949v1\n\n\nTruncated\nTrue\n\n\nWord Count\n18038"
  },
  {
    "objectID": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded.html#major-takeaways",
    "href": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded.html#major-takeaways",
    "title": "GPT-4V(ision) is a Generalist Web Agent, if Grounded",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nLMMs like GPT-4V have great potential as generalist web agents, outperforming text-only LLMs like GPT-4 and smaller models specifically fine-tuned for web agents in completing tasks on live websites.\nGrounding, especially element grounding, remains a substantial challenge, with the best strategies still exhibiting a performance gap with oracle grounding. Grounding via textual choices was the most effective approach, outperforming image annotation strategies, but still faced challenges with identical elements on webpages.\nIn-context learning (ICL) with large models showed better generalization to unseen websites compared to supervised fine-tuning (SFT) methods, making it a more compelling solution for generalist web agents, especially in scenarios lacking annotations or requiring strong generalization capabilities."
  },
  {
    "objectID": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded.html#introduction",
    "href": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded.html#introduction",
    "title": "GPT-4V(ision) is a Generalist Web Agent, if Grounded",
    "section": "Introduction",
    "text": "Introduction\nThe paper explores the potential of LMMs as generalist web agents, defining generalist web agents as those that can follow natural language instructions and complete tasks on any real-world website."
  },
  {
    "objectID": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded.html#seeact",
    "href": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded.html#seeact",
    "title": "GPT-4V(ision) is a Generalist Web Agent, if Grounded",
    "section": "SeeAct",
    "text": "SeeAct\n\nAims to investigate the capabilities of GPT-4V as a generalist web agent by generating action descriptions and identifying webpage elements for completing tasks on websites.\nFormulation includes two essential capabilities: Action Generation and Element Grounding for identifying HTML elements at each step."
  },
  {
    "objectID": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded.html#experiments",
    "href": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded.html#experiments",
    "title": "GPT-4V(ision) is a Generalist Web Agent, if Grounded",
    "section": "Experiments",
    "text": "Experiments\n\nDataset: Evaluated on the Mind2Web benchmark, encompassing over 2,000 tasks on real-world websites.\nMethods: SeeAct, baselines such as FLAN-T5 and BLIP2-T5, and in-context learning methods using GPT-3.5 and GPT-4 are compared.\nOffline Evaluation: Shows potential of GPT-4V as a web agent with oracle grounding method achieving notable success rates, but still exhibiting a substantial gap with proposed strategies. In-context learning methods demonstrate better generalization to unseen websites compared to supervised fine-tuning methods.\nOnline Evaluation: Demonstrates a substantial discrepancy with offline evaluations, indicating that multiple viable plans for the same task impact model performance."
  },
  {
    "objectID": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded.html#results-and-analysis",
    "href": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded.html#results-and-analysis",
    "title": "GPT-4V(ision) is a Generalist Web Agent, if Grounded",
    "section": "Results and Analysis",
    "text": "Results and Analysis\n\nWhole Task Success Rate: SeeActChoice outperforms existing methods on live websites, showcasing its potential as a generalist web agent. Surpassed fine-tuned models like FLAN-T5-XL in online evaluation, despite showing lower step success rates in offline evaluation.\nError Analysis: Showed challenges in grounding via textual choices and image annotation, with challenges of identical elements and hallucination errors.\nKnowledge and Reasoning: Tasks requiring knowledge and reasoning displayed GPT-4V’s capabilities in identifying specific details like IATA codes and geographic locations.\nPath Variation and Error Correction: Demonstrates the model’s flexibility in finding alternative paths to task completion and awareness of error correction during the task."
  },
  {
    "objectID": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded.html#critique",
    "href": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded.html#critique",
    "title": "GPT-4V(ision) is a Generalist Web Agent, if Grounded",
    "section": "Critique",
    "text": "Critique\n\nThe major findings are promising, but the discrepancy between offline and online evaluations raises questions about the robustness of the evaluation protocols and the need for better alignment between the two.\nThe focus on the specific dataset Mind2Web and the limited subset used for experiments may limit the generalizability of the findings.\n\nOverall, the paper provides valuable insights into the potential of large multimodal models as generalist web agents and highlights the challenges and future research directions in this domain. It opens up discussions on the practical implications and ethical considerations of deploying such models in real-world web environments."
  },
  {
    "objectID": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded.html#appendix",
    "href": "posts/GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded/2024-01-03-GPT_4V(ision)_is_a_Generalist_Web_Agent__if_Grounded.html#appendix",
    "title": "GPT-4V(ision) is a Generalist Web Agent, if Grounded",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01614v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01614v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12123"
  },
  {
    "objectID": "posts/Integrating_micro_learning_content_in_traditional_e_learning_platforms/2023-12-11-Integrating_micro_learning_content_in_traditional_e_learning_platforms.html#appendix",
    "href": "posts/Integrating_micro_learning_content_in_traditional_e_learning_platforms/2023-12-11-Integrating_micro_learning_content_in_traditional_e_learning_platforms.html#appendix",
    "title": "Integrating micro-learning content in traditional e-learning platforms",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-03\n\n\nAbstract\nhttp://arxiv.org/abs/2312.06500v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.06500v1\n\n\nTruncated\nTrue\n\n\nWord Count\n19589"
  },
  {
    "objectID": "posts/On_the_Difficulty_of_Defending_Contrastive_Learning_against_Backdoor_Attacks/2023-12-14-On_the_Difficulty_of_Defending_Contrastive_Learning_against_Backdoor_Attacks.html#appendix",
    "href": "posts/On_the_Difficulty_of_Defending_Contrastive_Learning_against_Backdoor_Attacks/2023-12-14-On_the_Difficulty_of_Defending_Contrastive_Learning_against_Backdoor_Attacks.html#appendix",
    "title": "On the Difficulty of Defending Contrastive Learning against Backdoor Attacks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.09057v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.09057v1\n\n\nTruncated\nTrue\n\n\nWord Count\n28425"
  },
  {
    "objectID": "posts/Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#major-takeaways",
    "href": "posts/Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#major-takeaways",
    "title": "Digger: Detecting Copyright Content Mis-usage in Large Language Model Training",
    "section": "Major Takeaways:",
    "text": "Major Takeaways:\n\nPre-training and success of Large Language Models (LLMs): The success of LLMs in various applications heavily depends on their extensive pre-training on large and diverse datasets. This raises concerns about potential misuse of copyrighted material and the need for ethical use of such content in LLM development.\nEffectiveness of the Digger framework: The paper introduces the Digger framework, designed to detect the presence of copyrighted content within LLM training datasets and provide a confidence estimation for the likelihood of each content sample’s inclusion. Through experiments, the paper affirms the effectiveness of Digger in identifying instances of content misuse in LLM training processes.\nReal-world applicability: The paper demonstrates the applicability of Digger in real-world scenarios by testing its performance in identifying copyrighted content within two widely-recognized LLMs: GPT2-XL and LLaMA-7b."
  },
  {
    "objectID": "posts/Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#introduction",
    "href": "posts/Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#introduction",
    "title": "Digger: Detecting Copyright Content Mis-usage in Large Language Model Training",
    "section": "Introduction",
    "text": "Introduction\n\nLarge Language Models (LLMs) have achieved impressive performance in various tasks, relying on extensive pre-training on large and diverse datasets.\nConcerns about potential misuse of copyrighted material in training datasets lead to the introduction of the Digger framework."
  },
  {
    "objectID": "posts/Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#background",
    "href": "posts/Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#background",
    "title": "Digger: Detecting Copyright Content Mis-usage in Large Language Model Training",
    "section": "Background",
    "text": "Background\n\nComplications of AI Models Trained on Copyrighted Content: The training of AI models, especially LLMs, on copyrighted content has emerged as a complex issue straddling legal, ethical, and technological domains.\nLimitations of Existing Mitigations: Legal and technological solutions to mitigate the use of copyrighted content in AI training have challenges and may not fully address ethical dimensions."
  },
  {
    "objectID": "posts/Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#characteristic-study",
    "href": "posts/Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#characteristic-study",
    "title": "Digger: Detecting Copyright Content Mis-usage in Large Language Model Training",
    "section": "Characteristic Study",
    "text": "Characteristic Study\n\nThe study aims to detect possible copyright infringements within LLMs by discerning the behavioral differences of LLMs when exposed to materials they have encountered during training versus those they have not.\nThe sample loss dynamics of LLMs are analyzed to address research questions related to the impact of fine-tuning and evaluation metrics investigation."
  },
  {
    "objectID": "posts/Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#methodology",
    "href": "posts/Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#methodology",
    "title": "Digger: Detecting Copyright Content Mis-usage in Large Language Model Training",
    "section": "Methodology",
    "text": "Methodology\n\nThe Digger framework is proposed to identify if a given target material has been trained on a given LLM, involving three main phases: Preparation, Simulation Experiment, and Confidence Calculation."
  },
  {
    "objectID": "posts/Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#evaluation",
    "href": "posts/Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#evaluation",
    "title": "Digger: Detecting Copyright Content Mis-usage in Large Language Model Training",
    "section": "Evaluation",
    "text": "Evaluation\n\nControlled experiments demonstrate the effectiveness of Digger in identifying instances of content misuse in LLM training processes, with an AUC of 0.914.\nReal-world scenarios also show promise with Digger effectively identifying copyrighted content within GPT2-XL and LLaMA-7b."
  },
  {
    "objectID": "posts/Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#discussion",
    "href": "posts/Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#discussion",
    "title": "Digger: Detecting Copyright Content Mis-usage in Large Language Model Training",
    "section": "Discussion",
    "text": "Discussion\n\nThe study emphasizes the cost for training and prediction and highlights the need for further research on target probability calculation and legal considerations.\nThe limitations and challenges such as the lack of ground truth labels and limited confidence level calculation are also discussed."
  },
  {
    "objectID": "posts/Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#threats-to-validity",
    "href": "posts/Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#threats-to-validity",
    "title": "Digger: Detecting Copyright Content Mis-usage in Large Language Model Training",
    "section": "Threats To Validity",
    "text": "Threats To Validity\n\nInternal threats include the lack of ground truth labels and limited inclusion of LLMs, while external threats involve the limited confidence level calculation and copyright legal considerations."
  },
  {
    "objectID": "posts/Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#conclusion",
    "href": "posts/Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#conclusion",
    "title": "Digger: Detecting Copyright Content Mis-usage in Large Language Model Training",
    "section": "Conclusion",
    "text": "Conclusion\n\nThe paper introduces a universal optimization framework, Digger, and demonstrates its effectiveness in identifying copyrighted content within LLM training datasets. The potential of Digger in real-world scenarios is highlighted, opening up opportunities in identifying copyrighted materials used in LLMs."
  },
  {
    "objectID": "posts/Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#critique-and-potential-problems",
    "href": "posts/Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#critique-and-potential-problems",
    "title": "Digger: Detecting Copyright Content Mis-usage in Large Language Model Training",
    "section": "Critique and Potential Problems",
    "text": "Critique and Potential Problems\n\nThe paper could benefit from a broader range of LLMs included in the study to enhance the generalizability of the findings.\nThe reliance on normal distribution fitting for confidence level calculation could be expanded to explore alternative statistical methods.\nThe study is situated within a specific legal and cultural context, which may limit the generalizability of its findings to other jurisdictions.\n\nOverall, the paper provides valuable insights into the challenges and solutions related to detecting copyright content misuse in the training of Large Language Models, with the potential for future research to further refine and expand the proposed Digger framework."
  },
  {
    "objectID": "posts/Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#appendix",
    "href": "posts/Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training/2024-01-01-Digger__Detecting_Copyright_Content_Mis_usage_in_Large_Language_Model_Training.html#appendix",
    "title": "Digger: Detecting Copyright Content Mis-usage in Large Language Model Training",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00676v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00676v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12663"
  },
  {
    "objectID": "posts/Taking_the_Next_Step_with_Generative_Artificial_Intelligence__The_Transformative_Role_of_Multimodal_Large_Language_Models_in_Science_Education/2024-01-01-Taking_the_Next_Step_with_Generative_Artificial_Intelligence__The_Transformative_Role_of_Multimodal_Large_Language_Models_in_Science_Education.html#appendix",
    "href": "posts/Taking_the_Next_Step_with_Generative_Artificial_Intelligence__The_Transformative_Role_of_Multimodal_Large_Language_Models_in_Science_Education/2024-01-01-Taking_the_Next_Step_with_Generative_Artificial_Intelligence__The_Transformative_Role_of_Multimodal_Large_Language_Models_in_Science_Education.html#appendix",
    "title": "Taking the Next Step with Generative Artificial Intelligence: The Transformative Role of Multimodal Large Language Models in Science Education",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00832v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00832v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12625"
  },
  {
    "objectID": "posts/LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#major-takeaways",
    "href": "posts/LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#major-takeaways",
    "title": "LLMEval: A Preliminary Study on How to Evaluate Large Language Models",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nThe evaluation of Large Language Models (LLMs) has become a prominent area of research, with a focus on determining how to assess their capabilities and limitations.\nExisting research primarily addresses “what” tasks to assign and “where” to evaluate LLMs, but less attention has been given to determining “how” to evaluate, including scoring methods, ranking systems, and type of annotators to use.\nThe study analyzes evaluation methods by comparing various criteria, different types of annotators, rating methods, and ranking approaches. It also introduces a new dataset, LLMEval, and provides insights for future LLM evaluation."
  },
  {
    "objectID": "posts/LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#introduction",
    "href": "posts/LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#introduction",
    "title": "LLMEval: A Preliminary Study on How to Evaluate Large Language Models",
    "section": "Introduction",
    "text": "Introduction\n\nIntroduction to the emergence of LLMs as a significant area of research and the need to assess their performance and limitations.\nExisting research focuses on “what” tasks and “where” to evaluate LLMs, but little has been discussed about “how” to evaluate, including scoring methods, ranking systems, and annotator types.\nStudy’s emphasis on evaluating LLMs using various criteria, different types of annotators, rating methods, and ranking approaches, leading to the introduction of the LLMEval dataset."
  },
  {
    "objectID": "posts/LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#design",
    "href": "posts/LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#design",
    "title": "LLMEval: A Preliminary Study on How to Evaluate Large Language Models",
    "section": "Design",
    "text": "Design\n\nCriteria: The paper introduced new criteria for evaluating LLMs, including accuracy, fluency, informativeness, logical coherence, and harmlessness.\nAnnotation Method: The study employed star scoring for onsite annotators, pairwise comparison for crowd-sourcing and public annotators, and GPT-4 for automatic evaluation. It found onsite evaluations to exhibit superior accuracy and consistency.\nRanking System: The study compared the Elo rating system and the Points scoring system for evaluating LLMs, noting poor stability with the Elo rating system."
  },
  {
    "objectID": "posts/LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#experiments",
    "href": "posts/LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#experiments",
    "title": "LLMEval: A Preliminary Study on How to Evaluate Large Language Models",
    "section": "Experiments",
    "text": "Experiments\n\nDataset: The study utilized two datasets, LLMEval-1 and LLMEval-2, to evaluate LLMs across various tasks and subjects.\nMetrics: Accuracy and consistency were used to assess the annotation methods, with a focus on alignment between manual and automated evaluation."
  },
  {
    "objectID": "posts/LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#results",
    "href": "posts/LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#results",
    "title": "LLMEval: A Preliminary Study on How to Evaluate Large Language Models",
    "section": "Results",
    "text": "Results\n\nComparison of Criteria: Findings showed that accuracy and informativeness are the most distinguishing criteria, and that conversation tasks best differentiate model capabilities.\nComparison of Annotation Methods: Onsite annotators demonstrated the best quality in terms of accuracy and consistency, while public annotators exhibited the lowest level of consistency and accuracy.\nComparison of Ranking Systems: The Elo rating system exhibited significant instability and sequence dependence, and was sensitive to the order of matches."
  },
  {
    "objectID": "posts/LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#discussion",
    "href": "posts/LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#discussion",
    "title": "LLMEval: A Preliminary Study on How to Evaluate Large Language Models",
    "section": "Discussion",
    "text": "Discussion\n\nThe study emphasizes the need to prioritize informativeness and accuracy in future evaluations, considers onsite evaluations as optimal, and suggests automated evaluation as a complementary approach. It also highlights the challenges in evaluating LLMs in subjective questions."
  },
  {
    "objectID": "posts/LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#appendix",
    "href": "posts/LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#appendix",
    "title": "LLMEval: A Preliminary Study on How to Evaluate Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\nThe study provides detailed implementation, including dataset specifics, mathematical proof of Elo rating instability, details of LLMEval-1 and LLMEval-2, and the implementation of scoring and ranking systems."
  },
  {
    "objectID": "posts/LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#critique",
    "href": "posts/LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#critique",
    "title": "LLMEval: A Preliminary Study on How to Evaluate Large Language Models",
    "section": "Critique",
    "text": "Critique\nThe paper provides a comprehensive analysis of LLM evaluation methods, but it lacks a discussion on potential biases in the dataset, such as language-specific nuances or biases introduced by the annotators. Additionally, the paper could benefit from a more in-depth comparison to existing evaluation methods and a broader discussion of the limitations of the proposed evaluation framework."
  },
  {
    "objectID": "posts/LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#appendix-1",
    "href": "posts/LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models/2023-12-12-LLMEval__A_Preliminary_Study_on_How_to_Evaluate_Large_Language_Models.html#appendix-1",
    "title": "LLMEval: A Preliminary Study on How to Evaluate Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.07398v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.07398v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12912"
  },
  {
    "objectID": "posts/Coevolutionary_Algorithm_for_Building_Robust_Decision_Trees_under_Minimax_Regret/2023-12-14-Coevolutionary_Algorithm_for_Building_Robust_Decision_Trees_under_Minimax_Regret.html#appendix",
    "href": "posts/Coevolutionary_Algorithm_for_Building_Robust_Decision_Trees_under_Minimax_Regret/2023-12-14-Coevolutionary_Algorithm_for_Building_Robust_Decision_Trees_under_Minimax_Regret.html#appendix",
    "title": "Coevolutionary Algorithm for Building Robust Decision Trees under Minimax Regret",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.09078v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.09078v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10754"
  },
  {
    "objectID": "posts/Profiling_Programming_Language_Learning/2024-01-02-Profiling_Programming_Language_Learning.html#appendix",
    "href": "posts/Profiling_Programming_Language_Learning/2024-01-02-Profiling_Programming_Language_Learning.html#appendix",
    "title": "Profiling Programming Language Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01257v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01257v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3045"
  },
  {
    "objectID": "posts/Critical_nonlinear_aspects_of_hopping_transport_for_reconfigurable_logic_in_disordered_dopant_networks/2023-12-26-Critical_nonlinear_aspects_of_hopping_transport_for_reconfigurable_logic_in_disordered_dopant_networks.html#appendix",
    "href": "posts/Critical_nonlinear_aspects_of_hopping_transport_for_reconfigurable_logic_in_disordered_dopant_networks/2023-12-26-Critical_nonlinear_aspects_of_hopping_transport_for_reconfigurable_logic_in_disordered_dopant_networks.html#appendix",
    "title": "Critical nonlinear aspects of hopping transport for reconfigurable logic in disordered dopant networks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16037v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16037v1\n\n\nTruncated\nTrue\n\n\nWord Count\n23967"
  },
  {
    "objectID": "posts/Action_Item_Driven_Summarization_of_Long_Meeting_Transcripts/2023-12-29-Action_Item_Driven_Summarization_of_Long_Meeting_Transcripts.html#appendix",
    "href": "posts/Action_Item_Driven_Summarization_of_Long_Meeting_Transcripts/2023-12-29-Action_Item_Driven_Summarization_of_Long_Meeting_Transcripts.html#appendix",
    "title": "Action-Item-Driven Summarization of Long Meeting Transcripts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17581v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17581v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7904"
  },
  {
    "objectID": "posts/Economics_Arena_for_Large_Language_Models/2024-01-03-Economics_Arena_for_Large_Language_Models.html",
    "href": "posts/Economics_Arena_for_Large_Language_Models/2024-01-03-Economics_Arena_for_Large_Language_Models.html",
    "title": "Economics Arena for Large Language Models",
    "section": "",
    "text": "mber guess) of agent i in round t, T is the total number of rounds in the game, and ρ(a)ρitalic_ρ(a) is the payoff of action a to the player. The denominator ρo⁢pitalic_ρo⁢p is the optimal payoff for the player when all players play rationally. The measure rirosso⁢psubscriptri=1T⁢∑t=1Tρ(a)ρo⁢psubscript𝑟𝑖1𝑇superscriptsubscript𝑡1𝑇𝜌subscript𝑎𝑖𝑡subscript𝜌𝑜𝑝, which is the average deviation distance from the NE, measure the rationality degree of agent i. A larger value indicates the agent acts more irrationally. To define the 5th-grade Nash equilibrium, we should consider payoffs rather than strategies, especially in LLMs where complex strategies are often hard to interpret and characterise.\nFor actions of 0, 1 and 2, the payoff matrix is as follow:\nϕ1⁢(0)ϕ1⁢(1)ϕ1⁢(2)ϕ2⁢(0)11-1ϕ2⁢(1)-11ϕ2⁢(2)000,\nwhich captures the payoffs of two players in a simple coordination game. If a player chooses 1 and the other 2, the payoffs violate the NE condition and indicate irrationally behaving. By taking the NE action of 1 and 2 into account, and define the respective NE payoffs to be 11, -11, -11 and 00, we can use the deviation distance measure to reflect the level of rationality. When all players maximise their payoffs, the deviation distance is 00 throughout, and higher deviations on average mean a less rational degree.\nA review of the rirosso⁢psubscriptri=1T⁢∑t=1Tρ⁢(ai⁢t)ρo⁢psubscript𝑟𝑖1𝑇superscriptsubscript𝑡1𝑇𝜌subscript𝑎𝑖𝑡subscript𝜌𝑜𝑝 measure for every agent reveals the rationality degree of several LLMs in Economics Arena. The rationality measure provided helps in evaluating how well LLMs are able to behave in a rational and strategic manner, and in identifying which LLMs are relatively more rational in competitive settings."
  },
  {
    "objectID": "posts/Economics_Arena_for_Large_Language_Models/2024-01-03-Economics_Arena_for_Large_Language_Models.html#appendix",
    "href": "posts/Economics_Arena_for_Large_Language_Models/2024-01-03-Economics_Arena_for_Large_Language_Models.html#appendix",
    "title": "Economics Arena for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01735v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01735v1\n\n\nTruncated\nTrue\n\n\nWord Count\n16860"
  },
  {
    "objectID": "posts/Towards_Trustworthy_AI_Software_Development_Assistance/2023-12-14-Towards_Trustworthy_AI_Software_Development_Assistance.html#appendix",
    "href": "posts/Towards_Trustworthy_AI_Software_Development_Assistance/2023-12-14-Towards_Trustworthy_AI_Software_Development_Assistance.html#appendix",
    "title": "Towards Trustworthy AI Software Development Assistance",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.09126v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.09126v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6324"
  },
  {
    "objectID": "posts/Improving_Code_Reviewer_Recommendation__Accuracy__Latency__Workload__and_Bystanders/2023-12-28-Improving_Code_Reviewer_Recommendation__Accuracy__Latency__Workload__and_Bystanders.html#appendix",
    "href": "posts/Improving_Code_Reviewer_Recommendation__Accuracy__Latency__Workload__and_Bystanders/2023-12-28-Improving_Code_Reviewer_Recommendation__Accuracy__Latency__Workload__and_Bystanders.html#appendix",
    "title": "Improving Code Reviewer Recommendation: Accuracy, Latency, Workload, and Bystanders",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17169v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17169v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11269"
  },
  {
    "objectID": "posts/Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners/2023-12-26-Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners.html#appendix",
    "href": "posts/Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners/2023-12-26-Supervised_Knowledge_Makes_Large_Language_Models_Better_In_context_Learners.html#appendix",
    "title": "Supervised Knowledge Makes Large Language Models Better In-context Learners",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.15918v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.15918v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12183"
  },
  {
    "objectID": "posts/State_of_What_Art__A_Call_for_Multi_Prompt_LLM_Evaluation/2023-12-31-State_of_What_Art__A_Call_for_Multi_Prompt_LLM_Evaluation.html#appendix",
    "href": "posts/State_of_What_Art__A_Call_for_Multi_Prompt_LLM_Evaluation/2023-12-31-State_of_What_Art__A_Call_for_Multi_Prompt_LLM_Evaluation.html#appendix",
    "title": "State of What Art? A Call for Multi-Prompt LLM Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00595v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00595v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10053"
  },
  {
    "objectID": "posts/Mitigating_Data_Injection_Attacks_on_Federated_Learning/2023-12-04-Mitigating_Data_Injection_Attacks_on_Federated_Learning.html#appendix",
    "href": "posts/Mitigating_Data_Injection_Attacks_on_Federated_Learning/2023-12-04-Mitigating_Data_Injection_Attacks_on_Federated_Learning.html#appendix",
    "title": "Mitigating Data Injection Attacks on Federated Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.02102v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.02102v2\n\n\nTruncated\nFalse\n\n\nWord Count\n7092"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian beagle",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nEconomics Arena for Large Language Models\n\n\n\neducation\n\n\n\nLarge language models (LLMs) are tested in competitive economics games, showing varying levels of rationality and strategic reasoning.\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGPT-4V(ision) is a Generalist Web Agent, if Grounded\n\n\n\nprompt-engineering\n\n\n\nRecent development in multimodal models has led to new web agents. SEEACT, using GPT-4V, can perform tasks on live websites.\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models Relearn Removed Concepts\n\n\n\nrobustness\n\n\n\nModel editing via neuron pruning allows for concept removal from language models. Models exhibit resilience and fluidity in relearning pruned concepts.\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDe-Hallucinator: Iterative Grounding for LLM-Based Code Completion\n\n\n\nrobustness\n\n\nprogramming\n\n\n\nLLMs have limitations in code completion due to a lack of project-specific context. De-Hallucinator addresses this by integrating API references, improving code predictions.\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English Clinical Queries\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nCreating summaries of medical questions from patients is important for improving doctor-patient interactions. Current research overlooks visual cues and multilingual input…\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWordArt Designer API: User-Driven Artistic Typography Synthesis with Large Language Models on ModelScope\n\n\n\nhci\n\n\n\nWordArt Designer API uses Large Language Models to simplify artistic typography for non-professionals, enhancing design flexibility and creative expression.\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNavigating Uncertainty: Optimizing API Dependency for Hallucination Reduction in Closed-Book Question Answering\n\n\n\nrobustness\n\n\n\nTL;DR: Proposed LLM can self-determine when to use external sources, achieving 78.2% direct answers and minimizing search to 77.2%.\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhysio: An LLM-Based Physiotherapy Advisor\n\n\n\nsocial-sciences\n\n\n\nNew language models have potential for real-world use but must be trustworthy. Physio combines these models with reliable health sources.\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSocial Media Ready Caption Generation for Brands\n\n\n\nhci\n\n\n\nProposed solution uses image captioning and brand personalities to create engaging social media captions.\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultilingual Instruction Tuning With Just a Pinch of Multilinguality\n\n\n\nprogramming\n\n\n\nMultilingual instruction-tuning enhances LLMs to follow instructions across languages with minimal multilingual examples.\n\n\n\nJan 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProfiling Programming Language Learning\n\n\n\nprompt-engineering\n\n\nprogramming\n\n\neducation\n\n\n\nYear-long experiment on programming language learning, using quizzes to improve understanding and retention.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhysics-informed Generalizable Wireless Channel Modeling with Segmentation and Deep Learning: Fundamentals, Methodologies, and Challenges\n\n\n\nsocial-sciences\n\n\n\nData-driven techniques improve wireless channel modeling. Physics-informed neural networks show promise for accurate, interpretable predictions.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExperimenting a New Programming Practice with LLMs\n\n\n\nprogramming\n\n\neducation\n\n\n\nA prototype called AISD uses large language models to automate software development, allowing engineers to focus on high-level tasks.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistribution Matching for Multi-Task Learning of Classification Tasks: a Large-Scale Study on Faces & Beyond\n\n\n\nsocial-sciences\n\n\n\nMulti-Task Learning can be successful with little overlapping annotations and uneven data sizes, with performance improvements in multiple domains.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTREC iKAT 2023: The Interactive Knowledge Assistance Track Overview\n\n\n\nhci\n\n\n\nTREC iKAT focuses on creating adaptive conversational search agents for personalized information seeking and decision-making tasks.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLbezpeky: Leveraging Large Language Models for Vulnerability Detection\n\n\n\nsecurity\n\n\n\nLLMs show promise in detecting Android app vulnerabilities with 91.67% accuracy, aiming to build a robust vulnerability detection system.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models\n\n\n\nsocial-sciences\n\n\nhci\n\n\nrobustness\n\n\n\nLLMs have a hallucination issue hindering real-world deployment. Survey of 32 techniques for mitigation presented.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSSP: A Simple and Safe automatic Prompt engineering method towards realistic image synthesis on LVM\n\n\n\nprompt-engineering\n\n\n\nEnhancing text-to-image (T2I) synthesis with Large Language Models (LLM) and Large Vision Models (LVM) using specific camera descriptions for safer and improved image…\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM Harmony: Multi-Agent Communication for Problem Solving\n\n\n\nsocial-sciences\n\n\nprompt-engineering\n\n\n\nNovel multi-agent communication framework enhances autonomy and problem-solving of Large Language Models for diverse scenarios.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideoDrafter: Content-Consistent Multi-Scene Video Generation with LLM\n\n\n\nprompt-engineering\n\n\n\nVideoDrafter uses language models to create consistent multi-scene videos, outperforming existing models in quality and consistency.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerative AI is already widespread in the public sector\n\n\n\nsocial-sciences\n\n\n\nGenerative AI is transforming the public sector, with widespread use and positive opinions, but lack of clear guidelines.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApplying Bayesian Data Analysis for Causal Inference about Requirements Quality: A Replicated Experiment\n\n\n\nsocial-sciences\n\n\n\nStudy finds quality defects in requirements impact software engineering activities differently, highlighting the need for varying levels of attention.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJMA: a General Algorithm to Craft Nearly Optimal Targeted Adversarial Example\n\n\n\nsecurity\n\n\n\nProposes a more effective targeted attack against deep learning classifiers, capable of inducing targeted modifications in complex classification scenarios.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUncertainty Resolution in Misinformation Detection\n\n\n\nhci\n\n\n\nLarge Language Models (LLMs) help combat misinformation but struggle with ambiguous statements. New framework improves context assessment.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSocially Responsible Computing in an Introductory Course\n\n\n\nsocial-sciences\n\n\nhci\n\n\nprompt-engineering\n\n\neducation\n\n\n\nTL;DR: Promoting social responsibility in Computer Science education boosts student motivation and inclusivity.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFairness Certification for Natural Language Processing and Large Language Models\n\n\n\nsocial-sciences\n\n\n\nNLP needs fairness certification due to potential biases. Researched and developed six criteria for certification.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDeplatforming Norm-Violating Influencers on Social Media Reduces Overall Online Attention Toward Them\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nOnline deplatforming reduces attention towards influencers. Study addresses limitations, finds impact, and contributes to content moderation research.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLaMA Beyond English: An Empirical Study on Language Capability Transfer\n\n\n\nsocial-sciences\n\n\n\nTransfer English LLM capabilities to non-English languages with minimal pretraining data, achieving comparable performance.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe social graph based on real data\n\n\n\nsocial-sciences\n\n\n\nProposed model creates realistic social graph using real community data, with power-law distribution and small world properties.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Legal Fictions: Profiling Legal Hallucinations in Large Language Models\n\n\n\nhci\n\n\nrobustness\n\n\n\nLLMs in law risk legal hallucinations 69-88% of interviews; caution against unsupervised use; risky for pro se litigants.\n\n\n\nJan 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nToolEyes assesses large language model tool learning in authentic scenarios, uncovering limitations and guiding future research.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTaking the Next Step with Generative Artificial Intelligence: The Transformative Role of Multimodal Large Language Models in Science Education\n\n\n\neducation\n\n\n\nMLLMs like GPT-4V enhance education with multimodal learning, but careful integration is needed for ethical and effective use.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDigger: Detecting Copyright Content Mis-usage in Large Language Model Training\n\n\n\nhci\n\n\n\nPre-training LLMs can raise copyright concerns. A new framework is introduced to detect and address copyrighted content misuse.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA & B == B & A: Triggering Logical Reasoning Failures in Large Language Models\n\n\n\nsocial-sciences\n\n\nhci\n\n\nprompt-engineering\n\n\n\nAdvancements in large language models enable breakthroughs in tasks like writing and translation, but evaluating their reasoning is challenging. LogicAsker assesses logical…\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecFormer: Towards Fast and Accurate Privacy-Preserving Inference for Large Language Models\n\n\n\nsecurity\n\n\n\nPrivacy concerns with large language models led to Secure Multi-Party Computing (SMPC) for Privacy-Preserving Inference. SecFormer optimizes SMPC for Transformer models…\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBenchmarking Large Language Models on Controllable Generation under Diversified Instructions\n\n\n\nprogramming\n\n\n\nCoDI-Eval evaluates large language models’ ability to follow instructions with specific constraints, revealing limitations and the need for improvement.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Computational Framework for Behavioral Assessment of LLM Therapists\n\n\n\nsocial-sciences\n\n\n\nChatGPT and other large language models are being considered as therapists, but research shows their behavior may not reflect high-quality therapy.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistillation is All You Need for Practically Using Different Pre-trained Recommendation Models\n\n\n\nrecommender\n\n\n\nProposed PRM-KD model efficiently utilizes diverse pre-trained recommendation models to enhance student models for real-world recommendations.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Earth is Flat? Unveiling Factual Errors in Large Language Models\n\n\n\nrobustness\n\n\n\nTL;DR: FactChecker is a new automatic testing framework that uncovers factual inaccuracies in large language models with up to 45% error detection.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents\n\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\nLLMs benefit from integrating code in training, enhancing code generation and reasoning ability for complex tasks.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAstraios: Parameter-Efficient Instruction Tuning Code Large Language Models\n\n\n\nsecurity\n\n\n\nAstraios compares fine-tuning methods for large language models and finds full-parameter fine-tuning generally leads to best performance.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nState of What Art? A Call for Multi-Prompt LLM Evaluation\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nAdvances in large language models are analyzed for their evaluation, suggesting diverse prompts for more reliable assessments.\n\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBatchEval: Towards Human-like Text Evaluation\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nBatchEval improves text evaluation over LLMs, addressing design sensitivity, noise resistance, and ensemble performance, with 10.5% higher correlations at reduced API cost.\n\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRAGTruth: A Hallucination Corpus for Developing Trustworthy Retrieval-Augmented Language Models\n\n\n\ndataset\n\n\nprompt-engineering\n\n\n\nRAGTruth is a dataset for analyzing hallucinations in large language models, helping measure and prevent unsupported claims in retrieved content.\n\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLaFFi: Leveraging Hybrid Natural Language Feedback for Fine-tuning Language Models\n\n\n\nsocial-sciences\n\n\neducation\n\n\n\nLLMs trained with LaFFi reflect on the feedback they’ll receive, improving question-answering accuracy. Experiments show the potential of natural language feedback.\n\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nE-chat: Emotion-sensitive Spoken Dialogue System with Large Language Models\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nStudy introduces Emotional chat Model (E-chat) for emotion-sensitive spoken dialogue, outperforming baseline models.\n\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDocLLM: A layout-aware generative language model for multimodal document understanding\n\n\n\nhci\n\n\n\nDocLLM is a model for reasoning over visual documents using text and layout information, outperforming existing models.\n\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nViz: A QLoRA-based Copyright Marketplace for Legally Compliant Generative AI\n\n\n\nproduction\n\n\nlegal\n\n\n\nViz system integrates QLoRA to fine-tune large language models legally and efficiently, addressing AI challenges.\n\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeach Large Language Models to Forget Privacy\n\n\n\nprompt-engineering\n\n\n\nTackle privacy risks in large language models with Prompt2Forget, achieving 90% forgetfulness without utility loss.\n\n\n\nDec 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-Assist: Enhancing Closed-Loop Planning with Language-Based Reasoning\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nHybrid planner combines rule-based and language models, outperforming existing methods in driving scenario handling.\n\n\n\nDec 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Problem of Alignment\n\n\n\nsocial-sciences\n\n\nhci\n\n\nprompt-engineering\n\n\n\nLanguage models need alignment with human values to avoid reproducing biases. This relationship shapes linguistic theories and practice.\n\n\n\nDec 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Art of Defending: A Systematic Evaluation and Analysis of LLM Defense Strategies on Safety and Over-Defensiveness\n\n\n\nsecurity\n\n\n\nSODE benchmark assesses LLM safety and over-defensiveness, revealing key defense strategy insights for further research.\n\n\n\nDec 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRed Teaming for Large Language Models At Scale: Tackling Hallucinations on Mathematics Tasks\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nStudy evaluates prompting techniques for LLMs on math tasks. Findings show models struggle with elementary calculations and reasoning even with red teaming.\n\n\n\nDec 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvancing TTP Analysis: Harnessing the Power of Encoder-Only and Decoder-Only Language Models with Retrieval Augmented Generation\n\n\n\nhci\n\n\nrobustness\n\n\n\nCybersecurity experts explore using advanced language models to interpret and summarize cyberattack methods for better understanding.\n\n\n\nDec 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs Knowledge All Large Language Models Needed for Causal Reasoning?\n\n\n\nhci\n\n\n\nPaper explores enhancing large language models’ causal reasoning for AI, finding its dependence on contextual information and domain-specific knowledge.\n\n\n\nDec 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAction-Item-Driven Summarization of Long Meeting Transcripts\n\n\n\nprompt-engineering\n\n\n\nNovel algorithm generates abstractive meeting summaries driven by action items, using sectional summaries and topic-based division method. Improved BERTScore.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDifferentially Private Low-Rank Adaptation of Large Language Model Using Federated Learning\n\n\n\nhci\n\n\n\nLLM fine-tuning raises privacy concerns. DP-LoRA, a federated learning algorithm, addresses privacy and communication overhead challenges effectively.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDB-GPT: Empowering Database Interactions with Private Large Language Models\n\n\n\nprogramming\n\n\n\nDB-GPT integrates large language models with databases for natural language queries and secure data interaction.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview of the PromptCBLUE Shared Task in CHIP2023\n\n\n\nprompt-engineering\n\n\n\nOverview of PromptCBLUE shared task at CHIP-2023 Conference, featuring reformulated benchmarks for testing Chinese language models in medical domains.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChatEd: A Chatbot Leveraging ChatGPT for an Enhanced Learning Experience in Higher Education\n\n\n\neducation\n\n\n\nChatGPT and similar language models have potential in education but face challenges with accuracy. New architecture offers enhanced student support.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCooperation on the Fly: Exploring Language Agents for Ad Hoc Teamwork in the Avalon Game\n\n\n\nhci\n\n\nrobustness\n\n\n\nLLMs show promise in ad hoc teamwork but may suffer from communication issues. CodeAct aims to address this with enhanced memory and code-driven reasoning.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEHR Interaction Between Patients and AI: NoteAid EHR Interaction\n\n\n\neducation\n\n\n\nIntroduction of NoteAid EHR Interaction Pipeline using LLMs for patient education from EHRs, with dataset evaluation.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the Sensitivity of LLMs’ Decision-Making Capabilities: Insights from Prompt Variation and Hyperparameters\n\n\n\nhci\n\n\n\nStudy examines language models’ decision making with varying prompts and hyperparameters showing human-like exploration-exploitation tradeoff.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSMoT: Think in State Machine\n\n\n\nprompt-engineering\n\n\n\nNew approach uses State Machine of Thought (SMoT) and expert knowledge to improve language model reasoning accuracy.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Right Prompts for the Job: Repair Code-Review Defects with Large Language Model\n\n\n\nhci\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\nLLMs effectively repair code review defects, achieving 72.97% repair rate, improving automatic repair practicality.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nK-PERM: Personalized Response Generation Using Dynamic Knowledge Retrieval and Persona-Adaptive Queries\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nPersonalizing conversational agents with external knowledge improves user engagement and quality of conversations. K-PERM achieves state-of-the-art performance.\n\n\n\nDec 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn Adaptive Framework of Geographical Group-Specific Network on O2O Recommendation\n\n\n\nrecommender\n\n\n\nUser and service spatiotemporal info requires personalized models. GeoGrouse improves group-specific recommendation by studying user preferences.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Code Reviewer Recommendation: Accuracy, Latency, Workload, and Bystanders\n\n\n\nhci\n\n\nrobustness\n\n\n\nCode review system at Meta improved through experiments, with emphasis on author-reviewer familiarity and balancing workloads. Bystander effect mitigated.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScalable and automated Evaluation of Blue Team cyber posture in Cyber Ranges\n\n\n\nsecurity\n\n\n\nCyber ranges are vital for secure training. New automation proposal improves exercise evaluation and assessment.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow Far Are We from Believable AI Agents? A Framework for Evaluating the Believability of Human Behavior Simulation\n\n\n\nhci\n\n\n\nAI agent believability relies on user trust. Large Language Model agents face challenges, so new metrics are introduced.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo Androids Know They’re Only Dreaming of Electric Sheep?\n\n\n\nrobustness\n\n\n\nProbes trained on language model representations detect hallucination behavior across tasks, but force-decoded states are not valid for organic hallucination detection.…\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTimeliness: A New Design Metric and a New Attack Surface\n\n\n\nsecurity\n\n\n\nTL;DR: Age-based communication networks are vulnerable to threats like timestomping and misinformation dissemination from adversaries.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecuring NextG Systems against Poisoning Attacks on Federated Learning: A Game-Theoretic Solution\n\n\n\nsecurity\n\n\n\nStudy analyzes poisoning attacks in federated learning (FL) for wireless signal classification, proposing a defense mechanism against malicious clients.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrounding-Prompter: Prompting LLM with Multimodal Information for Temporal Sentence Grounding in Long Videos\n\n\n\nprompt-engineering\n\n\n\nTL;DR: Proposed Grounding-Prompter method improves temporal grounding in long videos using multimodal information, enhancing state-of-the-art performance.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearning to Generate Text in Arbitrary Writing Styles\n\n\n\nhci\n\n\nprompt-engineering\n\n\n\nText generation to mimic specific author styles using contrastively-trained representations and discriminative control is effective and versatile.\n\n\n\nDec 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTask Contamination: Language Models May Not Be Few-Shot Anymore\n\n\n\nprompt-engineering\n\n\n\nLarge language models (LLMs) perform better on older datasets, suggesting task contamination affects zero-shot and few-shot tasks.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSupervised Knowledge Makes Large Language Models Better In-context Learners\n\n\n\nprompt-engineering\n\n\n\nLLMs’ in-context learning is enhanced through task-specific fine-tuned Language Models, improving generalizability and factuality.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKnowledge Distillation of LLM for Education\n\n\n\neducation\n\n\n\nMethod distills knowledge of large models for efficient deployment on resource-constrained devices, improving accuracy and model size.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRecRanker: Instruction Tuning Large Language Model as Ranker for Top-k Recommendation\n\n\n\nprompt-engineering\n\n\n\nLLMs used in recommendation systems lack integration of multiple ranking tasks, so RecRanker was developed to address this and improve model performance.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCritical nonlinear aspects of hopping transport for reconfigurable logic in disordered dopant networks\n\n\n\nrobustness\n\n\n\nNonlinear hopping transport enables logic gates in disordered devices, analyzed through simulations and compared to experimental data.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInter-X: Towards Versatile Human-Human Interaction Analysis\n\n\n\nhci\n\n\n\nLargest human-human interaction dataset with accurate body movements, hand gestures, and textual descriptions for research.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrincipled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4\n\n\n\nprompt-engineering\n\n\n\n26 principles for efficient queries and prompts for large language models, verified on various models, to aid researchers.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSocial-Transmotion: Promptable Human Trajectory Prediction\n\n\n\nhci\n\n\n\nSocial-Transmotion model uses transformers to improve human trajectory prediction by leveraging non-verbal social cues.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Media Bias Taxonomy: A Systematic Literature Review on the Forms and Automated Detection of Media Bias\n\n\n\nhci\n\n\n\nMedia bias impacts public opinion. This article reviews research on detecting bias and introduces the Media Bias Taxonomy. Transformer-based approaches show promise, but…\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Comprehensive Survey of Evaluation Techniques for Recommendation Systems\n\n\n\nrecommender\n\n\n\nThis paper introduces a comprehensive suite of metrics to evaluate recommendation systems’ performance and their impact on business success.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnsemble Learning to Assess Dynamics of Affective Experience Ratings and Physiological Change\n\n\n\nhci\n\n\n\nUsing advanced technology and open science to address the relationship between emotions, physiology, and data analysis in the EPiC challenge.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Prompt Learning Framework for Source Code Summarization\n\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\nPromptCS improves code summarization using continuous prompts for LLMs, outperforming other schemes with faster training and better summaries.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan ChatGPT Read Who You Are?\n\n\n\nhci\n\n\n\nAI and psychology intersect to assess personality traits using ChatGPT. It shows competitive performance with a positive bias.\n\n\n\nDec 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models are Not Stable Recommender Systems\n\n\n\nrecommender\n\n\n\nLLMs’ positional bias hinders recommendation stability. Researchers propose STELLA, a Bayesian framework, to mitigate bias and improve recommendation performance in LLMs.\n\n\n\nDec 25, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlleviating Hallucinations of Large Language Models through Induced Hallucinations\n\n\n\nrobustness\n\n\n\nTL;DR: New method Induce-then-Contrast Decoding reduces inaccuracies in large language models by penalizing induced hallucinations in their responses.\n\n\n\nDec 25, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnlocking the Potential of Large Language Models for Explainable Recommendations\n\n\n\nrecommender\n\n\n\nTL;DR: The study proposes LLMXRec, a framework using large language models for better explanations in recommendation systems.\n\n\n\nDec 25, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Persuasive Power of Large Language Models\n\n\n\nhci\n\n\n\nLarge Language Models could generate effective arguments, shaping public opinion in online discourse. Synthetic social systems mimic human opinion dynamics.\n\n\n\nDec 24, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvolving Large Language Model Assistant with Long-Term Conditional Memory\n\n\n\nrobustness\n\n\n\nAI assistants like ChatGPT with long-term memory improve responses using past dialogue, tested on different datasets.\n\n\n\nDec 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogic-Scaffolding: Personalized Aspect-Instructed Recommendation Explanation Generation using LLMs\n\n\n\nhci\n\n\nprompt-engineering\n\n\n\nLarge Language Models have potential for recommendation explanations, but existing models struggle. Logic-Scaffolding offers a solution.\n\n\n\nDec 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Contextual Bandits for Personalized Recommendation\n\n\n\nrecommender\n\n\n\nTutorial on contextual bandits for personalized recommendations, exploring challenges, advanced algorithms, and future prospects in online businesses.\n\n\n\nDec 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeometric Awareness in Neural Fields for 3D Human Registration\n\n\n\nrobustness\n\n\n\nTL;DR: New neural field model (LoVD) and self-supervised task (INT) improve 3D human body alignment, outperforming existing methods.\n\n\n\nDec 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChatGPT as a commenter to the news: can LLMs generate human-like opinions?\n\n\n\nprogramming\n\n\n\nGPT-3.5 can’t generate human-like Dutch news comments, even with various prompting techniques and personas.\n\n\n\nDec 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDesigning Artificial Intelligence Equipped Social Decentralized Autonomous Organizations for Tackling Sextortion Cases Version 0.7\n\n\n\nhci\n\n\n\nText explores sextortion, studies lack of coordination in victim support, proposes AI and blockchain-based solutions.\n\n\n\nDec 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpen-Set: ID Card Presentation Attack Detection using Neural Transfer Style\n\n\n\nsecurity\n\n\n\nStudy explores using GANs to improve ID card Presentation Attack detection, showing effectiveness in training fraud detection systems.\n\n\n\nDec 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nContext-aware Decoding Reduces Hallucination in Query-focused Summarization\n\n\n\nrobustness\n\n\n\nQuery-focused summarization (QFS) uses Context-aware Decoding (CAD) to improve generation quality for QFS tasks.\n\n\n\nDec 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAndroid dialogue system for customer service using prompt-based topic control and compliments generation\n\n\n\nhci\n\n\nprompt-engineering\n\n\n\nA chatbot system for trip planning uses AI to control conversation topics and generate personalized compliments, showing effectiveness in a preliminary evaluation.\n\n\n\nDec 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrometheus: Infrastructure Security Posture Analysis with AI-generated Attack Graphs\n\n\n\nsecurity\n\n\n\nTL;DR: Cybersecurity breaches demand a holistic security solution. Prometheus system assesses vulnerabilities and attack paths comprehensively.\n\n\n\nDec 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLRS: Enhancing Adversarial Transferability through Lipschitz Regularized Surrogate\n\n\n\nsecurity\n\n\n\nTL;DR: The paper proposes Lipschitz Regularized Surrogate for improving transfer-based black-box attacks using transformed surrogate models.\n\n\n\nDec 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nToward enriched Cognitive Learning with XAI\n\n\n\nprompt-engineering\n\n\n\nAI-supported system CL-XAI enhances cognitive learning with explainable AI tools, benefiting human learners and addressing knowledge deficiencies.\n\n\n\nDec 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTerrapin Attack: Breaking SSH Channel Integrity By Sequence Number Manipulation\n\n\n\nsecurity\n\n\n\nSSH protocol vulnerabilities allow attackers to break channel integrity and downgrade security measures, affecting millions of servers.\n\n\n\nDec 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrompting Hard or Hardly Prompting: Prompt Inversion for Text-to-Image Diffusion Models\n\n\n\nprompt-engineering\n\n\n\nDiffusion models require engineered prompts for faithful image synthesis. This work focuses on inverting the model for interpretable language prompts, using a delayed…\n\n\n\nDec 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeamCAD – A Multimodal Interface for Remote Computer Aided Design\n\n\n\neducation\n\n\n\nTL;DR: TeamCAD improves remote design collaboration with voice and gesture recognition for better user experience.\n\n\n\nDec 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBypassing the Safety Training of Open-Source LLMs with Priming Attacks\n\n\n\nsecurity\n\n\nopen-source\n\n\n\nLLMs lack safety training and are vulnerable to priming attacks, effectively bypassing alignment, increasing attack success rate.\n\n\n\nDec 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode Ownership in Open-Source AI Software Security\n\n\n\nsecurity\n\n\n\nNovel code ownership metrics correlate with security in AI open-source projects, aiding project evaluation and benchmarking.\n\n\n\nDec 18, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn-Device Recommender Systems: A Tutorial on The New-Generation Recommendation Paradigm\n\n\n\nrecommender\n\n\n\nTL;DR: On-device recommender systems (ODRSs) are emerging to address challenges of traditional cloud-based systems in e-commerce applications, offering lightweight…\n\n\n\nDec 18, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA novel diffusion recommendation algorithm based on multi-scale cnn and residual lstm\n\n\n\nrecommender\n\n\n\nSequential recommendation enhances user prediction with a novel diffusion recommendation algorithm named AREAL, achieving significant improvements in experiments.\n\n\n\nDec 18, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHE-DKSAP: Privacy-Preserving Stealth Address Protocol via Additively Homomorphic Encryption\n\n\n\nsecurity\n\n\n\nBlockchain transactions face privacy concerns. Stealth addresses mitigate these, but have vulnerabilities. HE-DKSAP offers a secure, scalable privacy solution.\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkNN-ICL: Compositional Task-Oriented Parsing Generalization with Nearest Neighbor In-Context Learning\n\n\n\nprogramming\n\n\n\nLLMs improve semantic parsing tasks without needing extra data or specialized prompts, achieving comparable performance to supervised models.\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection\n\n\n\nsecurity\n\n\n\nJailGuard detects jailbreak attacks on large language models with 89.38% accuracy for image inputs and 85.42% for text, outperforming existing methods.\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRe-parameterized Low-rank Prompt: Generalize a Vision-Language Model within 0.5K Parameters\n\n\n\nprompt-engineering\n\n\n\nVision-language model adaptation is enhanced through RLP prompts, reducing parameters and storage, achieving superior results.\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI Gender Bias, Disparities, and Fairness: Does Training Data Matter?\n\n\n\neducation\n\n\n\nStudy examines gender biases in AI scoring of student responses. Mixed-trained models show no significant scoring bias but may widen gender disparities.\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Unified Framework for Multi-Domain CTR Prediction via Large Language Models\n\n\n\nrecommender\n\n\n\nUni-CTR is a new approach to multi-domain click-through rate (MDCTR) prediction, leveraging a Large Language Model (LLM) and domain-specific networks for better performance…\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding the Instruction Mixture for Large Language Model\n\n\n\neducation\n\n\nprogramming\n\n\n\nExploring the impact of different instruction types on large language models’ performance reveals the need for careful instruction design.\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRevealing Networks: Understanding Effective Teacher Practices in AI-Supported Classrooms using Transmodal Ordered Network Analysis\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nUsing AI and quantitative ethnography, the study uncovers effective teacher practices in classrooms using AI tutors.\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLatent Space Editing in Transformer-Based Flow Matching\n\n\n\nprompt-engineering\n\n\n\nTL;DR: The paper introduces a new image editing method using Flow Matching and a transformer backbone for scalable and high-quality generative modeling.\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYour Student is Better Than Expected: Adaptive Teacher-Student Collaboration for Text-Conditional Diffusion Models\n\n\n\neducation\n\n\n\nKnowledge distillation improves image synthesis by blending student and teacher models for better quality samples.\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Trustworthy AI Software Development Assistance\n\n\n\nprogramming\n\n\n\nA new architecture aims to improve AI software development assistants’ reliability and code quality. It includes a foundational LLM and a knowledge graph.\n\n\n\nDec 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoevolutionary Algorithm for Building Robust Decision Trees under Minimax Regret\n\n\n\nsecurity\n\n\n\nNovel CoEvoRDT algorithm creates robust decision trees, outperforming state-of-the-art methods in handling adversarial attacks.\n\n\n\nDec 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn the Difficulty of Defending Contrastive Learning against Backdoor Attacks\n\n\n\nsecurity\n\n\n\nContrastive backdoor attacks differ from supervised ones, requiring tailored defenses due to distinct learning mechanisms.\n\n\n\nDec 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCMOSE: Comprehensive Multi-Modality Online Student Engagement Dataset with High-Quality Labels\n\n\n\neducation\n\n\n\nTL;DR: Engagement recognition in online learning can be improved with CMOSE dataset and MocoRank training mechanism.\n\n\n\nDec 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating Augmented Reality Communication: How Can We Teach Procedural Skill in AR?\n\n\n\neducation\n\n\n\nAR in healthcare for remote medical training analyzed for teaching a CVC procedure, comparing AR and video communication.\n\n\n\nDec 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Verifiable Text Generation with Evolving Memory and Self-Reflection\n\n\n\nrobustness\n\n\n\nLarge Language Models (LLMs) face challenges in accuracy and verification. An innovative approach, VTG, uses memory and retrieval to improve text generation.\n\n\n\nDec 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Robot Program Synthesis Through Environmental Context\n\n\n\nrobustness\n\n\n\nTL;DR: Framework uses neural models to rectify program errors with partially observed environments, improving program synthesis in robot programming.\n\n\n\nDec 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprompt-engineering-assisted Malware Dynamic Analysis Using GPT-4\n\n\n\nrobustness\n\n\n\nDynamic analysis with GPT-4 creates explanatory text for API calls to improve malware detection. Outperforms TextCNN with high generalization.\n\n\n\nDec 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrompt Engineering-assisted Malware Dynamic Analysis Using GPT-4\n\n\n\nrobustness\n\n\n\nDynamic analysis with GPT-4 creates explanatory text for API calls to improve malware detection. Outperforms TextCNN with high generalization.\n\n\n\nDec 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGuardRails: Automated Suggestions for Clarifying Ambiguous Purpose Statements\n\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\nPurpose statements for functions may be ambiguous; a heuristic is proposed to suggest clarifications using language models.\n\n\n\nDec 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrompting LLMs with content plans to enhance the summarization of scientific articles\n\n\n\nprompt-engineering\n\n\n\nNovel prompting techniques improve scientific article summarization by providing contextual information, showing performance gains for smaller models.\n\n\n\nDec 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models are Clinical Reasoners: Reasoning-Aware Diagnosis Framework with Prompt-Generated Rationales\n\n\n\nprompt-engineering\n\n\n\nProposes a diagnosis framework using prompt-based learning for clinical reasoning in disease diagnosis, evaluating machine-generated rationales for real-world clinical…\n\n\n\nDec 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMEval: A Preliminary Study on How to Evaluate Large Language Models\n\n\n\neducation\n\n\n\nThis paper examines Large Language Model (LLM) evaluation methods, proposes a new dataset, and provides insights.\n\n\n\nDec 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nICL Markup: Structuring In-Context Learning using Soft-Token Tags\n\n\n\nprogramming\n\n\n\nTL;DR: Soft-token tags simplify model adaptation for various tasks, improving LLM performance in enterprise applications.\n\n\n\nDec 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan ChatGPT Play the Role of a Teaching Assistant in an Introductory Programming Course?\n\n\n\nprogramming\n\n\neducation\n\n\n\nStudy evaluates ChatGPT as a virtual TA for programming course. Compares its performance with human TAs in solving assignments, grading, and providing feedback.\n\n\n\nDec 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntegrating micro-learning content in traditional e-learning platforms\n\n\n\neducation\n\n\n\nMicro-learning is a solution for combining training and work, integrating it into traditional learning systems.\n\n\n\nDec 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSparse but Strong: Crafting Adversarially Robust Graph Lottery Tickets\n\n\n\nsecurity\n\n\n\nGraph Lottery Tickets (GLTs) reduce latency and footprint, but are vulnerable to structure attacks. A framework called ARGS enhances robustness.\n\n\n\nDec 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPerformance-lossless Black-box Model Watermarking\n\n\n\nrobustness\n\n\n\nPropose watermarking protocol protects model IP with branch backdoor-based method, verified with language generation task.\n\n\n\nDec 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM Interactive Optimization of Open Source Python Libraries – Case Studies and Generalization\n\n\n\nhci\n\n\nprogramming\n\n\n\nLLMs like ChatGPT-4 can optimize energy and compute efficiency in python libraries with human input.\n\n\n\nDec 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models for Mathematicians\n\n\n\nprogramming\n\n\neducation\n\n\n\nChatGPT and similar models can aid professional mathematicians by improving work speed and quality.\n\n\n\nDec 7, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChain of Code: Reasoning with a Language Model-Augmented Code Emulator\n\n\n\nprogramming\n\n\n\nCode-writing aids language models in Chain of Thought reasoning, improving linguistic and logical tasks. Chain of Code outperforms Chain of Thought.\n\n\n\nDec 7, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMOCHa: Multi-Objective Reinforcement Mitigating Caption Hallucinations\n\n\n\nrobustness\n\n\n\nPropose MOCHa, a reinforcement learning approach, to reduce hallucinations in image captioning and demonstrate its superior performance.\n\n\n\nDec 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMitigating Data Injection Attacks on Federated Learning\n\n\n\nsecurity\n\n\n\nA novel method detects and mitigates data injection attacks in federated learning, ensuring model accuracy and data privacy.\n\n\n\nDec 4, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Bayesian beagle",
    "section": "",
    "text": "I’m a Bayesian beagle who has curated LLM-summarized articles on LLMs."
  },
  {
    "objectID": "posts/HE_DKSAP__Privacy_Preserving_Stealth_Address_Protocol_via_Additively_Homomorphic_Encryption/2023-12-17-HE_DKSAP__Privacy_Preserving_Stealth_Address_Protocol_via_Additively_Homomorphic_Encryption.html",
    "href": "posts/HE_DKSAP__Privacy_Preserving_Stealth_Address_Protocol_via_Additively_Homomorphic_Encryption/2023-12-17-HE_DKSAP__Privacy_Preserving_Stealth_Address_Protocol_via_Additively_Homomorphic_Encryption.html",
    "title": "HE-DKSAP: Privacy-Preserving Stealth Address Protocol via Additively Homomorphic Encryption",
    "section": "",
    "text": "Summary: - The paper introduces the Homomorphic Encryption-based Dual-Key Stealth Address Protocol (HE-DKSAP) as a novel approach to safeguarding transaction privacy and preventing potential quantum computing attacks in blockchain systems. - The protocol combines homomorphic encryption with a dual-key stealth address protocol to enhance privacy and security. - Three major challenges in stealth address (SA) protocols are identified: key leakage attacks, scalability and usability concerns, and vulnerability to quantum computing attacks.\nKey findings: 1. Homomorphic Encryption-based Dual-Key Stealth Address Protocol (HE-DKSAP): - The protocol introduces a novel approach to safeguarding transaction privacy and preventing potential quantum computing attacks by leveraging the power of homomorphic encryption. - By combining homomorphic encryption with the dual-key stealth address protocol, HE-DKSAP aims to enhance privacy and security in blockchain systems.\nCrypto Scheme Overview: - The paper discusses the use of homomorphic encryption schemes such as Paillier or BFV, describing the key generation, encryption, and decryption processes. - It outlines the implementation of the HE-DKSAP protocol using the Paillier encryption scheme and the BFV scheme for fully homomorphic encryption.\nCritique: - The paper effectively introduces a novel approach, HE-DKSAP, and outlines the challenges in SA protocols. However, it would benefit from more in-depth discussions of potential limitations or real-world deployment challenges for the proposed protocol. Additionally, the clarity and organization of technical details in the algorithmic and cryptographic scheme overview could be improved for a non-specialist audience."
  },
  {
    "objectID": "posts/HE_DKSAP__Privacy_Preserving_Stealth_Address_Protocol_via_Additively_Homomorphic_Encryption/2023-12-17-HE_DKSAP__Privacy_Preserving_Stealth_Address_Protocol_via_Additively_Homomorphic_Encryption.html#appendix",
    "href": "posts/HE_DKSAP__Privacy_Preserving_Stealth_Address_Protocol_via_Additively_Homomorphic_Encryption/2023-12-17-HE_DKSAP__Privacy_Preserving_Stealth_Address_Protocol_via_Additively_Homomorphic_Encryption.html#appendix",
    "title": "HE-DKSAP: Privacy-Preserving Stealth Address Protocol via Additively Homomorphic Encryption",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10698v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10698v1\n\n\nTruncated\nTrue\n\n\nWord Count\n19402"
  },
  {
    "objectID": "posts/An_Adaptive_Framework_of_Geographical_Group_Specific_Network_on_O2O_Recommendation/2023-12-28-An_Adaptive_Framework_of_Geographical_Group_Specific_Network_on_O2O_Recommendation.html#appendix",
    "href": "posts/An_Adaptive_Framework_of_Geographical_Group_Specific_Network_on_O2O_Recommendation/2023-12-28-An_Adaptive_Framework_of_Geographical_Group_Specific_Network_on_O2O_Recommendation.html#appendix",
    "title": "An Adaptive Framework of Geographical Group-Specific Network on O2O Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17072v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17072v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5196"
  },
  {
    "objectID": "posts/Task_Contamination__Language_Models_May_Not_Be_Few_Shot_Anymore/2023-12-26-Task_Contamination__Language_Models_May_Not_Be_Few_Shot_Anymore.html#appendix",
    "href": "posts/Task_Contamination__Language_Models_May_Not_Be_Few_Shot_Anymore/2023-12-26-Task_Contamination__Language_Models_May_Not_Be_Few_Shot_Anymore.html#appendix",
    "title": "Task Contamination: Language Models May Not Be Few-Shot Anymore",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16337v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16337v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8991"
  },
  {
    "objectID": "posts/kNN_ICL__Compositional_Task_Oriented_Parsing_Generalization_with_Nearest_Neighbor_In_Context_Learning/2023-12-17-kNN_ICL__Compositional_Task_Oriented_Parsing_Generalization_with_Nearest_Neighbor_In_Context_Learning.html#appendix",
    "href": "posts/kNN_ICL__Compositional_Task_Oriented_Parsing_Generalization_with_Nearest_Neighbor_In_Context_Learning/2023-12-17-kNN_ICL__Compositional_Task_Oriented_Parsing_Generalization_with_Nearest_Neighbor_In_Context_Learning.html#appendix",
    "title": "kNN-ICL: Compositional Task-Oriented Parsing Generalization with Nearest Neighbor In-Context Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10771v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10771v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8730"
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#findings",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#findings",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Findings",
    "text": "Findings\n\nDistillation Method: The paper proposes distilling the knowledge of fine-tuned Large Language Models (LLMs) into smaller, more efficient, and accurate neural networks using a specialized loss function tailored for the LLM’s output probabilities. Results showed that the distilled student models achieved 12% higher accuracy than normal neural network models on smaller datasets.\nModel Size: The student model size ranges from 0.1M to 0.02M, 100 times smaller in terms of parameters and ten times smaller compared to the original model size.\nEducational Access: The study highlights the potential to make advanced AI technologies accessible in typical educational settings, particularly for automatic scoring, which can enhance personalized learning experiences and adaptive assessment tools."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#background",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#background",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Background",
    "text": "Background\n\nLLMs in Education: LLMs have shown promise in enhancing learning experiences, providing personalized learning content, and automating scoring systems, but their deployment in educational settings is hindered by their size and computational requirements.\nKnowledge Distillation (KD): KD has emerged as a pivotal technique in harnessing the power of LLMs for practical applications, particularly in fields with limited computational resources."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#methodology",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#methodology",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Methodology",
    "text": "Methodology\n\nOriginal Neural Network: The study uses a deep neural network to approximate the conditional probability function for the classification tasks.\nProposed KD: The study proposes a KD approach where the teacher model’s predicted probability outputs are used as soft targets for training the compact student model."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#experimental-setup",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#experimental-setup",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Experimental Setup",
    "text": "Experimental Setup\n\nData Collection: The study utilized datasets of student-written responses to science and mathematical questions, categorizing the dataset into multiple tasks.\nTraining Scheme: The model is trained using conventional neural network training approaches and KD strategies and evaluated for performance."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#results",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#results",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Results",
    "text": "Results\n\nComparison: KD was found to enhance the performance of the student model relative to both an original neural network and a more complex teacher model across various datasets.\nEffectiveness of KD: The study demonstrated the efficacy of KD in establishing compact student models with improved performance, making them suitable for resource-constrained educational settings."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#discussion",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#discussion",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Discussion",
    "text": "Discussion\n\nApplication of KD in Education: KD has the potential to create accurate and productive automatic scoring systems, enhancing personalized and interactive learning experiences.\nLimitations of KD: Despite its advantages, KD student models often fall short of the teacher models, and the quality and applicability of training data are crucial factors."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#future-directions",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#future-directions",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Future Directions",
    "text": "Future Directions\n\nSoft label processing: More sophisticated validation techniques to process soft labels.\nEthical and Fairness Considerations: Addressing bias and fairness issues in educational applications of KD.\nCustomizable and Adaptive Models: Constructing small KD models adaptable to specific learning environments."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#conclusion",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#conclusion",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Conclusion",
    "text": "Conclusion\nThe paper effectively demonstrates the potential of KD in optimizing LLMs for educational technology, specifically in resource-constrained environments. It establishes the viability of KD in educational contexts and highlights the importance of ongoing research and innovation in AI for education."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#critique",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#critique",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Critique",
    "text": "Critique\n\nThe methodology and results could be strengthened by including more detailed explanations of the model evaluation and validation methods.\nThe study would benefit from discussing potential limitations and biases in the data used for training and testing.\nThe future directions section could further elaborate on the potential challenges and implications of the proposed advancements.\n\nOverall, the paper offers valuable insights into the application of KD in educational technology but could benefit from addressing potential limitations and biases."
  },
  {
    "objectID": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#appendix",
    "href": "posts/Knowledge_Distillation_of_LLM_for_Education/2023-12-26-Knowledge_Distillation_of_LLM_for_Education.html#appendix",
    "title": "Knowledge Distillation of LLM for Education",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.15842v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.15842v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9762"
  },
  {
    "objectID": "posts/Teach_Large_Language_Models_to_Forget_Privacy/2023-12-30-Teach_Large_Language_Models_to_Forget_Privacy.html#appendix",
    "href": "posts/Teach_Large_Language_Models_to_Forget_Privacy/2023-12-30-Teach_Large_Language_Models_to_Forget_Privacy.html#appendix",
    "title": "Teach Large Language Models to Forget Privacy",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00870v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00870v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12649"
  },
  {
    "objectID": "posts/RecRanker__Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top_k_Recommendation/2023-12-26-RecRanker__Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top_k_Recommendation.html#appendix",
    "href": "posts/RecRanker__Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top_k_Recommendation/2023-12-26-RecRanker__Instruction_Tuning_Large_Language_Model_as_Ranker_for_Top_k_Recommendation.html#appendix",
    "title": "RecRanker: Instruction Tuning Large Language Model as Ranker for Top-k Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16018v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16018v1\n\n\nTruncated\nTrue\n\n\nWord Count\n15714"
  },
  {
    "objectID": "posts/A_Mutation_Based_Method_for_Multi_Modal_Jailbreaking_Attack_Detection/2023-12-17-A_Mutation_Based_Method_for_Multi_Modal_Jailbreaking_Attack_Detection.html#appendix",
    "href": "posts/A_Mutation_Based_Method_for_Multi_Modal_Jailbreaking_Attack_Detection/2023-12-17-A_Mutation_Based_Method_for_Multi_Modal_Jailbreaking_Attack_Detection.html#appendix",
    "title": "A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10766v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10766v1\n\n\nTruncated\nTrue\n\n\nWord Count\n14983"
  },
  {
    "objectID": "posts/Re_parameterized_Low_rank_Prompt__Generalize_a_Vision_Language_Model_within_0.5K_Parameters/2023-12-17-Re_parameterized_Low_rank_Prompt__Generalize_a_Vision_Language_Model_within_0.5K_Parameters.html#summary",
    "href": "posts/Re_parameterized_Low_rank_Prompt__Generalize_a_Vision_Language_Model_within_0.5K_Parameters/2023-12-17-Re_parameterized_Low_rank_Prompt__Generalize_a_Vision_Language_Model_within_0.5K_Parameters.html#summary",
    "title": "Re-parameterized Low-rank Prompt: Generalize a Vision-Language Model within 0.5K Parameters",
    "section": "Summary",
    "text": "Summary\n\nKey Findings\n\nPrompt Tuning: Prompt tuning has become popular for adapting vision-language models to downstream tasks. It involves freezing the parameters in the backbone and tuning the prompts for better transferability on different tasks.\nRe-parameterized Low-rank Prompt (RLP): The RLP method reduces the number of tunable parameters and storage space, demonstrating superior performance with a significantly small number of parameters.\nEfficiency and Effectiveness: RLP demonstrates efficiency and effectiveness, reaching state-of-the-art performance with an extremely small number of parameters.\n\n\n\nIntroduction\nIn recent years, large pre-trained vision-language models have achieved tremendous success. Representative models like CLIP are first pre-trained on a huge number of text-image pairs on the web to align textual and visual features, and then can be tuned and used for various downstream tasks.\n\n\nMotivation for Low-Rank Prompts\nThe authors observed that the evolution pattern of the generalization capability in visual-language models aligns harmoniously with the trend of rank variations in the prompt matrix during adaptation. This observation led them to propose the Re-parameterized Low-rank Prompt (RLP), aiming for effective and efficient adaptation for vision-language models.\n\n\nRelated Works\nThe paper discusses various related works in the vision-language models and prompt tuning, outlining the challenges and advancements in the field.\n\n\nMethodology\nThe paper reviews the prompt tuning for CLIP, introduces the Low-rank prompt, and explains the motivation behind it. It also discusses the initialization method, integration of a Dropout layer, and the efficiency analysis of the proposed RLP method.\n\n\nResults\n\nBase-to-New Generalization: RLP consistently outperforms zero-shot CLIP, CoOp, and CLIP-Adapter across all the shot numbers.\nDomain Generalization: RLP demonstrates robustness and outperforms state-of-the-art methods in domain generalization experiments.\nCross-Dataset Transfer: RLP excels in cross-dataset transfer, showcasing its ability to extract general and data-agnostic knowledge from given images.\nFew-shot Learning: RLP consistently outperforms zero-shot CLIP, CoOp, and CLIP-Adapter across all the shot numbers, demonstrating its adaptation ability when there are few samples in downstream tasks.\n\n\n\nAnalysis\nThe paper includes an ablation study, efficiency comparison, and results across different hyper-parameters to demonstrate the effectiveness and efficiency of the proposed RLP method."
  },
  {
    "objectID": "posts/Re_parameterized_Low_rank_Prompt__Generalize_a_Vision_Language_Model_within_0.5K_Parameters/2023-12-17-Re_parameterized_Low_rank_Prompt__Generalize_a_Vision_Language_Model_within_0.5K_Parameters.html#critique",
    "href": "posts/Re_parameterized_Low_rank_Prompt__Generalize_a_Vision_Language_Model_within_0.5K_Parameters/2023-12-17-Re_parameterized_Low_rank_Prompt__Generalize_a_Vision_Language_Model_within_0.5K_Parameters.html#critique",
    "title": "Re-parameterized Low-rank Prompt: Generalize a Vision-Language Model within 0.5K Parameters",
    "section": "Critique",
    "text": "Critique\nThe paper provides a comprehensive exploration of the RLP method and its effectiveness in adapting vision-language models within an extremely small number of parameters. However, further details on the limitations and potential challenges in real-world applications would enhance the comprehensiveness of the paper. Additionally, addressing the scalability and generalizability of the RLP method to larger and diverse datasets could strengthen its practical utility."
  },
  {
    "objectID": "posts/Re_parameterized_Low_rank_Prompt__Generalize_a_Vision_Language_Model_within_0.5K_Parameters/2023-12-17-Re_parameterized_Low_rank_Prompt__Generalize_a_Vision_Language_Model_within_0.5K_Parameters.html#appendix",
    "href": "posts/Re_parameterized_Low_rank_Prompt__Generalize_a_Vision_Language_Model_within_0.5K_Parameters/2023-12-17-Re_parameterized_Low_rank_Prompt__Generalize_a_Vision_Language_Model_within_0.5K_Parameters.html#appendix",
    "title": "Re-parameterized Low-rank Prompt: Generalize a Vision-Language Model within 0.5K Parameters",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10813v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10813v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13488"
  },
  {
    "objectID": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#key-findings",
    "href": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#key-findings",
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "section": "Key Findings",
    "text": "Key Findings\n\nToolEyes offers a fine-grained evaluation system for Large Language Models’ (LLMs) tool learning capabilities, examining seven real-world scenarios and approximately 600 tools.\nThe evaluation reveals that LLMs exhibit preference for specific scenarios and restricted cognitive abilities in tool learning, with larger model size exacerbating the hindrance to tool learning.\nThe findings suggest the need for improvement in tool learning capabilities across all categories of LLMs."
  },
  {
    "objectID": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#evaluation-system",
    "href": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#evaluation-system",
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "section": "Evaluation System",
    "text": "Evaluation System\n\nScenario Construction\n\nToolEyes formulates seven real-world scenarios, including Text Generation, Data Understanding, Real-Time Search, Application Manipulation, Personal Life, Information Retrieval, and Financial Transactions.\nEach scenario is equipped with a related set of tools, totaling 41 categories, 95 subcategories, and 568 tools.\n\n\n\nTool Library Building\n\nThe system establishes a tool library, serving as an interface for LLMs to interact with the environment.\n\n\n\nHuman-Driven Data Generation\n\nProfessionals were engaged to identify actual requirements by reviewing the tool documentation to ensure comprehensive coverage of different scenarios.\n\n\n\nLLMs Capability Evaluation\n\nToolEyes evaluates LLMs across five essential capabilities: format alignment, intent comprehension, behavior planning, tool selection, and answer organization."
  },
  {
    "objectID": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#experiments",
    "href": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#experiments",
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "section": "Experiments",
    "text": "Experiments\n\nModel Selection\n\nExperiments were conducted on ten LLMs from three sources: open-source, tool-oriented, and closed-source categories, including LLaMA-2-chat, Vicuna-1.5, Text-davinci-003, GPT-3.5-turbo, and GPT-4.\n\n\n\nExperimental Setup\n\nLLMs were assessed using a five-shot format for open-source models and zero-shot format for others, with specific prompt templates used during inference.\n\n\n\nResults in Different Scenarios\n\nLLMs exhibit scenario-specific preferences in tool learning, influenced by their optimization goals and training data.\n\n\n\nResults of Different LLMs Capabilities\n\nThe present constraints in LLMs thinking skills present a substantial obstacle to tool learning, and LLMs with superior performance exhibit more effective problem-solving abilities.\n\n\n\nWhy does NOT LLMs Capabilities Increase with Size?\n\nThe study found that as the model size increases, there is a potential weakening of the instrumental learning capabilities within specific LLM families."
  },
  {
    "objectID": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#insights-for-advancing-tool-learning",
    "href": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#insights-for-advancing-tool-learning",
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "section": "Insights for Advancing Tool Learning",
    "text": "Insights for Advancing Tool Learning\n\nIdeas for advancing tool learning include task construction considering model behavior, scenario generalization using diverse data, and capability enhancement addressing the “barrel effect.”"
  },
  {
    "objectID": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#related-works",
    "href": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#related-works",
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "section": "Related Works",
    "text": "Related Works\n\nThe paper discusses tool learning and evaluations for tool learning, highlighting the challenges in current tool learning research."
  },
  {
    "objectID": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#conclusion",
    "href": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#conclusion",
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "section": "Conclusion",
    "text": "Conclusion\n\nToolEyes offers instructive insights to inform the development of tool learning and presents avenues for future research."
  },
  {
    "objectID": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#limitations",
    "href": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#limitations",
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "section": "Limitations",
    "text": "Limitations\n\nThe paper acknowledges limitations, including the absence of a novel LLM dedicated to tool learning and the associated costs of scoring using specific LLMs."
  },
  {
    "objectID": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#appendix",
    "href": "posts/ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios/2024-01-01-ToolEyes__Fine_Grained_Evaluation_for_Tool_Learning_Capabilities_of_Large_Language_Models_in_Real_world_Scenarios.html#appendix",
    "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00741v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00741v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11381"
  },
  {
    "objectID": "posts/Large_Language_Models_are_Clinical_Reasoners__Reasoning_Aware_Diagnosis_Framework_with_Prompt_Generated_Rationales/2023-12-12-Large_Language_Models_are_Clinical_Reasoners__Reasoning_Aware_Diagnosis_Framework_with_Prompt_Generated_Rationales.html#appendix",
    "href": "posts/Large_Language_Models_are_Clinical_Reasoners__Reasoning_Aware_Diagnosis_Framework_with_Prompt_Generated_Rationales/2023-12-12-Large_Language_Models_are_Clinical_Reasoners__Reasoning_Aware_Diagnosis_Framework_with_Prompt_Generated_Rationales.html#appendix",
    "title": "Large Language Models are Clinical Reasoners: Reasoning-Aware Diagnosis Framework with Prompt-Generated Rationales",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.07399v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.07399v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10273"
  },
  {
    "objectID": "posts/Differentially_Private_Low_Rank_Adaptation_of_Large_Language_Model_Using_Federated_Learning/2023-12-29-Differentially_Private_Low_Rank_Adaptation_of_Large_Language_Model_Using_Federated_Learning.html#appendix",
    "href": "posts/Differentially_Private_Low_Rank_Adaptation_of_Large_Language_Model_Using_Federated_Learning/2023-12-29-Differentially_Private_Low_Rank_Adaptation_of_Large_Language_Model_Using_Federated_Learning.html#appendix",
    "title": "Differentially Private Low-Rank Adaptation of Large Language Model Using Federated Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17493v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17493v1\n\n\nTruncated\nTrue\n\n\nWord Count\n15580"
  },
  {
    "objectID": "posts/Physics_informed_Generalizable_Wireless_Channel_Modeling_with_Segmentation_and_Deep_Learning__Fundamentals__Methodologies__and_Challenges/2024-01-02-Physics_informed_Generalizable_Wireless_Channel_Modeling_with_Segmentation_and_Deep_Learning__Fundamentals__Methodologies__and_Challenges.html#appendix",
    "href": "posts/Physics_informed_Generalizable_Wireless_Channel_Modeling_with_Segmentation_and_Deep_Learning__Fundamentals__Methodologies__and_Challenges/2024-01-02-Physics_informed_Generalizable_Wireless_Channel_Modeling_with_Segmentation_and_Deep_Learning__Fundamentals__Methodologies__and_Challenges.html#appendix",
    "title": "Physics-informed Generalizable Wireless Channel Modeling with Segmentation and Deep Learning: Fundamentals, Methodologies, and Challenges",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01288v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01288v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8770"
  },
  {
    "objectID": "posts/DB_GPT__Empowering_Database_Interactions_with_Private_Large_Language_Models/2023-12-29-DB_GPT__Empowering_Database_Interactions_with_Private_Large_Language_Models.html#appendix",
    "href": "posts/DB_GPT__Empowering_Database_Interactions_with_Private_Large_Language_Models/2023-12-29-DB_GPT__Empowering_Database_Interactions_with_Private_Large_Language_Models.html#appendix",
    "title": "DB-GPT: Empowering Database Interactions with Private Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17449v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17449v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8411"
  },
  {
    "objectID": "posts/Enhancing_Robot_Program_Synthesis_Through_Environmental_Context/2023-12-13-Enhancing_Robot_Program_Synthesis_Through_Environmental_Context.html",
    "href": "posts/Enhancing_Robot_Program_Synthesis_Through_Environmental_Context/2023-12-13-Enhancing_Robot_Program_Synthesis_Through_Environmental_Context.html",
    "title": "Enhancing Robot Program Synthesis Through Environmental Context",
    "section": "",
    "text": "ve of the entire environment that may not always be feasible in reality. EVAPS overcomes this by leveraging partial environmental observations and aligning them with code syntax to provide more comprehensive guidance for program rectification. ii) EVAPS introduces a novel framework that learns an environment embedding space to implicitly evaluate the impacts of each program token based on the precondition. This enables the model to effectively assess the global impact of the generated program tokens toward the desired output, even with partial observations.\nWhile we recognize the need for further research and testing in real-world scenarios, the strong performance of EVAPS in a complex and noisy environment serves as a promising indication of its potential practical application."
  },
  {
    "objectID": "posts/Enhancing_Robot_Program_Synthesis_Through_Environmental_Context/2023-12-13-Enhancing_Robot_Program_Synthesis_Through_Environmental_Context.html#appendix",
    "href": "posts/Enhancing_Robot_Program_Synthesis_Through_Environmental_Context/2023-12-13-Enhancing_Robot_Program_Synthesis_Through_Environmental_Context.html#appendix",
    "title": "Enhancing Robot Program Synthesis Through Environmental Context",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.08250v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.08250v1\n\n\nTruncated\nTrue\n\n\nWord Count\n14478"
  },
  {
    "objectID": "posts/The_Persuasive_Power_of_Large_Language_Models/2023-12-24-The_Persuasive_Power_of_Large_Language_Models.html#appendix",
    "href": "posts/The_Persuasive_Power_of_Large_Language_Models/2023-12-24-The_Persuasive_Power_of_Large_Language_Models.html#appendix",
    "title": "The Persuasive Power of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.15523v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.15523v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9545"
  },
  {
    "objectID": "posts/LLM_Assist__Enhancing_Closed_Loop_Planning_with_Language_Based_Reasoning/2023-12-30-LLM_Assist__Enhancing_Closed_Loop_Planning_with_Language_Based_Reasoning.html#appendix",
    "href": "posts/LLM_Assist__Enhancing_Closed_Loop_Planning_with_Language_Based_Reasoning/2023-12-30-LLM_Assist__Enhancing_Closed_Loop_Planning_with_Language_Based_Reasoning.html#appendix",
    "title": "LLM-Assist: Enhancing Closed-Loop Planning with Language-Based Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00125v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00125v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9991"
  },
  {
    "objectID": "posts/A_&_B_==_B_&_A__Triggering_Logical_Reasoning_Failures_in_Large_Language_Models/2024-01-01-A_&_B_==_B_&_A__Triggering_Logical_Reasoning_Failures_in_Large_Language_Models.html#biasasker-measuring-the-bias-in-your-chatbot-via-asking-questions",
    "href": "posts/A_&_B_==_B_&_A__Triggering_Logical_Reasoning_Failures_in_Large_Language_Models/2024-01-01-A_&_B_==_B_&_A__Triggering_Logical_Reasoning_Failures_in_Large_Language_Models.html#biasasker-measuring-the-bias-in-your-chatbot-via-asking-questions",
    "title": "A & B == B & A: Triggering Logical Reasoning Failures in Large Language Models",
    "section": "BiasAsker: Measuring the Bias in Your Chatbot via Asking Questions",
    "text": "BiasAsker: Measuring the Bias in Your Chatbot via Asking Questions\n\nMajor Findings\n\nBiasAsker proposes a novel testing method to automatically detect bias in conversational AI software by asking questions. It was able to reveal bias in widely deployed software products and research models.\nThe research demonstrates the potential for BiasAsker to effectively identify biases and improve the performance of conversational AI software.\nThe paper provides valuable insights into the biases and weaknesses of conversational AI software, helping uncover specific areas that require improvement.\n\n\n\nIntroduction\n\nConversational AI software products, like chatbots and digital assistants, have gained widespread use, but they may generate speech containing biases and stereotypes.\nExisting methods for detecting bias in conversational AI systems have limitations, prompting the need for a new testing method.\n\n\n\nLogicAsker Framework\n\nLogicAsker systematically generates reasoning questions to evaluate the logical reasoning ability of large language models (LLMs).\nThe framework identifies weaknesses in LLMs’ logical reasoning abilities and provides insights into their strengths and weaknesses in different logical skills.\n\n\n\nEvaluation of BiasAsker\n\nBiasAsker was effective in triggering logical reasoning failures in conversational AI systems, exposing their weaknesses and biases.\nThe test cases generated by BiasAsker were found to be valid and reliable, indicating the framework’s ability to accurately identify biases and logical reasoning failures.\nThe research demonstrated the potential of BiasAsker to improve the reasoning ability of conversational AI software through in-context learning, further highlighting its effectiveness.\n\n\n\nCritique\nThe paper presents a promising approach to detecting biases in conversational AI systems, but it may be subject to limitations: - The evaluation was limited to a small set of LLMs, and the effectiveness of BiasAsker on other systems is still unproven. - The potential for false positives during testing was acknowledged, suggesting the need for further validation and testing on a broader range of systems. - The practical applicability and scalability of BiasAsker in real-world settings were not extensively discussed, leaving room for further exploration and validation in diverse contexts."
  },
  {
    "objectID": "posts/A_&_B_==_B_&_A__Triggering_Logical_Reasoning_Failures_in_Large_Language_Models/2024-01-01-A_&_B_==_B_&_A__Triggering_Logical_Reasoning_Failures_in_Large_Language_Models.html#appendix",
    "href": "posts/A_&_B_==_B_&_A__Triggering_Logical_Reasoning_Failures_in_Large_Language_Models/2024-01-01-A_&_B_==_B_&_A__Triggering_Logical_Reasoning_Failures_in_Large_Language_Models.html#appendix",
    "title": "A & B == B & A: Triggering Logical Reasoning Failures in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00757v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00757v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10017"
  },
  {
    "objectID": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#major-findings",
    "href": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#major-findings",
    "title": "Code Ownership in Open-Source AI Software Security",
    "section": "Major Findings",
    "text": "Major Findings\n\nStrong Relationship Between Code Ownership and Vulnerabilities: The study found a positive correlation between high-level ownership characterized by a limited number of minor contributors and a decrease in vulnerabilities in open-source AI software projects.\nNovel Code Ownership Metrics: The paper introduces novel code ownership metrics tailored for open-source AI application security, integrating software component frequency/proportion and time/release attributes to provide deeper insights into the link between code ownership and vulnerabilities.\nEffective Time Metrics for Vulnerability Analysis: The time metrics introduced in the study adeptly categorize distinct phases of open-source AI software projects and their respective vulnerability intensities, providing a comprehensive framework for vulnerability management."
  },
  {
    "objectID": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#introduction",
    "href": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#introduction",
    "title": "Code Ownership in Open-Source AI Software Security",
    "section": "Introduction",
    "text": "Introduction\nThe paper discusses the growing significance of open-source AI software projects, highlighting the heightened concern over software vulnerabilities due to the transparent and anonymous nature of contributors. It emphasizes the importance of code ownership as a metric for evaluating developer involvement and identifying latent vulnerabilities in AI software projects."
  },
  {
    "objectID": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#related-work",
    "href": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#related-work",
    "title": "Code Ownership in Open-Source AI Software Security",
    "section": "Related Work",
    "text": "Related Work\nThe related work section discusses existing literature on developer contribution practices, software quality, and security in traditional software projects, drawing comparisons and contrasts in the context of open-source AI software projects."
  },
  {
    "objectID": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#research-questions-and-hypotheses",
    "href": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#research-questions-and-hypotheses",
    "title": "Code Ownership in Open-Source AI Software Security",
    "section": "Research Questions and Hypotheses",
    "text": "Research Questions and Hypotheses\nThe study formulates research questions centered around the development and effectiveness of code ownership metrics and their correlation with software vulnerabilities in open-source AI projects. It also introduces hypotheses related to the vulnerability of software components based on the number of minor contributors, vulnerability occurrence rate, and software component location."
  },
  {
    "objectID": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#terminology-and-metrics",
    "href": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#terminology-and-metrics",
    "title": "Code Ownership in Open-Source AI Software Security",
    "section": "Terminology and Metrics",
    "text": "Terminology and Metrics\nThe paper introduces crucial terminology and metrics essential for understanding the code ownership metrics and their application in vulnerability assessment. It discusses software components, contributors, contributions, ownership proportion, time stage, OSS stage, and classic metrics."
  },
  {
    "objectID": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#data-collection-and-analysis",
    "href": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#data-collection-and-analysis",
    "title": "Code Ownership in Open-Source AI Software Security",
    "section": "Data Collection and Analysis",
    "text": "Data Collection and Analysis\nThe data collection and analysis section details the process of collecting vulnerability data from NVD and GitHub repositories and conducting a comprehensive analysis of the vulnerability dataset using various techniques such as correlation analysis and multiple linear regression."
  },
  {
    "objectID": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#results",
    "href": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#results",
    "title": "Code Ownership in Open-Source AI Software Security",
    "section": "Results",
    "text": "Results\nThe results section presents potential distortion factor checks, correlation analysis, and discussion of the findings. It highlights the correlation between code ownership metrics and vulnerabilities, the effectiveness of time metrics, and the impact of project lifespan and minor contributors on vulnerability susceptibility."
  },
  {
    "objectID": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#threat-to-validity",
    "href": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#threat-to-validity",
    "title": "Code Ownership in Open-Source AI Software Security",
    "section": "Threat to Validity",
    "text": "Threat to Validity\nThe section discusses limitations and potential areas for future research, such as the influence of dependency management, project attribute limitations, data quality, and metric completeness on the validity and generalizability of the study."
  },
  {
    "objectID": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#conclusion",
    "href": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#conclusion",
    "title": "Code Ownership in Open-Source AI Software Security",
    "section": "Conclusion",
    "text": "Conclusion\nThe paper concludes by emphasizing the significance of code ownership in securing open-source AI software projects and its effectiveness in vulnerability management. It also recommends project managers closely monitor projects with distinct ownership patterns and lengthy lifespans and thoroughly examine components with minimal ownership."
  },
  {
    "objectID": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#critique",
    "href": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#critique",
    "title": "Code Ownership in Open-Source AI Software Security",
    "section": "Critique",
    "text": "Critique\nThe paper effectively introduces novel metrics and provides insights into the correlation between code ownership and vulnerabilities in open-source AI software. However, potential limitations include the reliance on a limited number of open-source AI projects for the study and the exclusion of complexity analysis in diverse programming languages, which may affect the accuracy and generalizability of the findings. Moreover, more comprehensive validation and testing in diverse open-source AI projects would enhance the robustness of the proposed metrics and their applicability."
  },
  {
    "objectID": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#appendix",
    "href": "posts/Code_Ownership_in_Open_Source_AI_Software_Security/2023-12-18-Code_Ownership_in_Open_Source_AI_Software_Security.html#appendix",
    "title": "Code Ownership in Open-Source AI Software Security",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10861v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10861v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9732"
  },
  {
    "objectID": "posts/Scalable_and_automated_Evaluation_of_Blue_Team_cyber_posture_in_Cyber_Ranges/2023-12-28-Scalable_and_automated_Evaluation_of_Blue_Team_cyber_posture_in_Cyber_Ranges.html#appendix",
    "href": "posts/Scalable_and_automated_Evaluation_of_Blue_Team_cyber_posture_in_Cyber_Ranges/2023-12-28-Scalable_and_automated_Evaluation_of_Blue_Team_cyber_posture_in_Cyber_Ranges.html#appendix",
    "title": "Scalable and automated Evaluation of Blue Team cyber posture in Cyber Ranges",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17221v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17221v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3860"
  },
  {
    "objectID": "posts/The_Problem_of_Alignment/2023-12-30-The_Problem_of_Alignment.html#appendix",
    "href": "posts/The_Problem_of_Alignment/2023-12-30-The_Problem_of_Alignment.html#appendix",
    "title": "The Problem of Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00210v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00210v1\n\n\nTruncated\nTrue\n\n\nWord Count\n20502"
  },
  {
    "objectID": "posts/prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#overview",
    "href": "posts/prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#overview",
    "title": "prompt-engineering-assisted Malware Dynamic Analysis Using GPT-4",
    "section": "Overview",
    "text": "Overview\n\nMajor Takeaways\n\nAPI Sequence as Dynamic Malware Behavior: The API sequence, composed of consecutive API calls, is a significant representation of dynamic malware behavior in dynamic analysis methods.\nIntroduction of Prompt Engineering & GPT-4: This paper introduces a method for generating representations for API calls using GPT-4 and prompt engineering, achieving excellent detection performance in dynamic malware analysis.\nSuperior Generalization Performance: The proposed model demonstrates superior generalization performance, effectively addressing issues such as weak generalization and concept drift in dynamic malware analysis."
  },
  {
    "objectID": "posts/prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#experiment-analysis",
    "href": "posts/prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#experiment-analysis",
    "title": "prompt-engineering-assisted Malware Dynamic Analysis Using GPT-4",
    "section": "Experiment Analysis",
    "text": "Experiment Analysis\n\nComparison of Representation Quality\n\nThe proposed model outperforms existing models in generating denser representations and capturing associations between API calls effectively, as demonstrated in case studies.\nFew-shot learning experiments show that the proposed model achieves superior fine-tuning and adaptation in comparison to TextCNN and BiLSTM.\n\n\n\nAnalysis of Concept Drift Alleviation\n\nThe proposed model effectively addresses the concept drift phenomenon, demonstrating excellent recall rates for malware even in the presence of new or previously unseen API calls."
  },
  {
    "objectID": "posts/prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#critique",
    "href": "posts/prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#critique",
    "title": "prompt-engineering-assisted Malware Dynamic Analysis Using GPT-4",
    "section": "Critique",
    "text": "Critique\n\nThe paper could benefit from more detailed information on the limitations or potential biases of the proposed method.\nFurther clarification on the real-world applicability and scalability of the proposed model would enhance the paper’s significance.\n\nOverall, the paper provides a promising approach to dynamic malware analysis, but further studies and real-world implementations are required to validate its full potential."
  },
  {
    "objectID": "posts/prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#appendix",
    "href": "posts/prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4/2023-12-13-prompt_engineering_assisted_Malware_Dynamic_Analysis_Using_GPT_4.html#appendix",
    "title": "prompt-engineering-assisted Malware Dynamic Analysis Using GPT-4",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.08317v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.08317v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13381"
  },
  {
    "objectID": "posts/Large_Language_Models_are_Not_Stable_Recommender_Systems/2023-12-25-Large_Language_Models_are_Not_Stable_Recommender_Systems.html#appendix",
    "href": "posts/Large_Language_Models_are_Not_Stable_Recommender_Systems/2023-12-25-Large_Language_Models_are_Not_Stable_Recommender_Systems.html#appendix",
    "title": "Large Language Models are Not Stable Recommender Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.15746v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.15746v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8647"
  },
  {
    "objectID": "posts/Android_dialogue_system_for_customer_service_using_prompt_based_topic_control_and_compliments_generation/2023-12-20-Android_dialogue_system_for_customer_service_using_prompt_based_topic_control_and_compliments_generation.html#appendix",
    "href": "posts/Android_dialogue_system_for_customer_service_using_prompt_based_topic_control_and_compliments_generation/2023-12-20-Android_dialogue_system_for_customer_service_using_prompt_based_topic_control_and_compliments_generation.html#appendix",
    "title": "Android dialogue system for customer service using prompt-based topic control and compliments generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.12924v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.12924v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2038"
  },
  {
    "objectID": "posts/Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_/2023-12-28-Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_.html#main-findings",
    "href": "posts/Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_/2023-12-28-Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_.html#main-findings",
    "title": "Do Androids Know They’re Only Dreaming of Electric Sheep?",
    "section": "Main Findings",
    "text": "Main Findings\n\nThe study explores probes on a decoder-only transformer language model to detect hallucinations in multiple grounded generation tasks.\nProbes trained on the force-decoded states of synthetic hallucinations outperform contemporary baselines, showing that probing is a feasible and efficient alternative to language model hallucination evaluation when model states are available.\nThe work presents a high-quality dataset of over 15k utterances with hallucination annotations for organic and synthetic output texts across three grounded generation tasks."
  },
  {
    "objectID": "posts/Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_/2023-12-28-Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_.html#introduction",
    "href": "posts/Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_/2023-12-28-Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_.html#introduction",
    "title": "Do Androids Know They’re Only Dreaming of Electric Sheep?",
    "section": "Introduction",
    "text": "Introduction\n\nThe paper explores whether language models can detect hallucinations in their outputs and develops probes for this purpose.\nPrevious work focused on creating secondary detection models trained on and applied to surface text, but ignored the information already computed during generation.\nThe study aims to explore the degree to which probes on a decoder-only transformer language model can detect hallucinations in various grounded generation tasks."
  },
  {
    "objectID": "posts/Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_/2023-12-28-Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_.html#related-work",
    "href": "posts/Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_/2023-12-28-Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_.html#related-work",
    "title": "Do Androids Know They’re Only Dreaming of Electric Sheep?",
    "section": "Related Work",
    "text": "Related Work\n\nThe study focuses on hallucinations in the setting of in-context generation where grounding knowledge sources are provided within the prompt.\nHallucinations are classified as intrinsic, where generated responses directly contradict the knowledge sources, or extrinsic, where generated responses are neither entailed nor contradicted by the sources.\nPrior work uses various metrics and models such as Lexical metrics, NLI approaches, question-answer models, and transformer behavior prediction in small and large language models."
  },
  {
    "objectID": "posts/Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_/2023-12-28-Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_.html#grounded-generation-tasks",
    "href": "posts/Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_/2023-12-28-Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_.html#grounded-generation-tasks",
    "title": "Do Androids Know They’re Only Dreaming of Electric Sheep?",
    "section": "Grounded Generation Tasks",
    "text": "Grounded Generation Tasks\n\nThe study tests hallucination probes for autoregressive grounded generation in abstractive summarization, knowledge-grounded dialogue generation, and data-to-text.\nIt collects hallucinations in two ways: from sampled responses generated from a large language model and by editing reference inputs or outputs to create discrepancies.\nThe authors provide full details and examples for each task."
  },
  {
    "objectID": "posts/Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_/2023-12-28-Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_.html#probing",
    "href": "posts/Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_/2023-12-28-Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_.html#probing",
    "title": "Do Androids Know They’re Only Dreaming of Electric Sheep?",
    "section": "Probing",
    "text": "Probing\n\nProbes are designed as tools to analyze a neural network’s internal representations using linear classifiers and attention-pooling probes.\nThey are trained to discriminate between different types of inputs or outputs to detect hallucinations in the language model’s generated responses."
  },
  {
    "objectID": "posts/Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_/2023-12-28-Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_.html#experiments",
    "href": "posts/Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_/2023-12-28-Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_.html#experiments",
    "title": "Do Androids Know They’re Only Dreaming of Electric Sheep?",
    "section": "Experiments",
    "text": "Experiments\n\nResults show that probes trained on organic hallucinations worked best on specific datasets.\nProbes achieve high F1 in the detection of synthetically created hallucinations across all tasks.\nThe study demonstrates nuances in the saliency of hallucinatory behavior across model layers, hidden state types, model sizes, hallucination types, and contexts."
  },
  {
    "objectID": "posts/Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_/2023-12-28-Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_.html#discussion",
    "href": "posts/Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_/2023-12-28-Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_.html#discussion",
    "title": "Do Androids Know They’re Only Dreaming of Electric Sheep?",
    "section": "Discussion",
    "text": "Discussion\n\nThe study points out the efficiency and access limitations of probing and highlights the need for labeled in-domain data for probe training.\nIt emphasizes the need for better quality synthetic training data and discusses challenges in annotator disagreements, probe design, ecological validity, and the potential for mitigation of hallucinations in language models."
  },
  {
    "objectID": "posts/Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_/2023-12-28-Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_.html#critique",
    "href": "posts/Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_/2023-12-28-Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_.html#critique",
    "title": "Do Androids Know They’re Only Dreaming of Electric Sheep?",
    "section": "Critique",
    "text": "Critique\nThis paper presents valuable insights into the detection of hallucinations in language model outputs. However, the study’s generalization to out-of-domain tasks is limited, and the reliance on hidden states may pose challenges if LLMs move behind closed-source APIs. Additionally, the ecological validity of synthetic hallucinations and the annotation guidelines require further refinement to improve accuracy and reproducibility. Further exploration of more advanced probe architectures and mitigation strategies is also warranted for practical application."
  },
  {
    "objectID": "posts/Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_/2023-12-28-Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_.html#appendix",
    "href": "posts/Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_/2023-12-28-Do_Androids_Know_They're_Only_Dreaming_of_Electric_Sheep_.html#appendix",
    "title": "Do Androids Know They’re Only Dreaming of Electric Sheep?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17249v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17249v1\n\n\nTruncated\nTrue\n\n\nWord Count\n16039"
  },
  {
    "objectID": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#major-takeaways",
    "href": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#major-takeaways",
    "title": "Experimenting a New Programming Practice with LLMs",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nPotential for Revolutionizing Software Development: The paper explores the potential of large language models (LLMs) in automating software development, aiming to free engineers from low-level coding and focusing on requirement engineering and system testing.\nDevelopment of AISD: The authors introduce AISD, an AI-aided software development framework designed to engage users throughout the software development process and keep the human developers informed and involved.\nEvaluation of AISD: The experimental results suggest that AISD significantly improves the task pass rate while consuming fewer tokens, emphasizing the critical role of human engagement in AI-aided software development."
  },
  {
    "objectID": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#introduction",
    "href": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#introduction",
    "title": "Experimenting a New Programming Practice with LLMs",
    "section": "Introduction",
    "text": "Introduction\nLarge language models (LLMs) have shown promising performance in natural language understanding and complex problem-solving, leading to applications in code generation. Prior attempts have aimed to replace programmers with LLMs but often failed with non-trivial software projects due to inadequate user feedback and oversight of requirement engineering and system testing."
  },
  {
    "objectID": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#preliminaries",
    "href": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#preliminaries",
    "title": "Experimenting a New Programming Practice with LLMs",
    "section": "Preliminaries",
    "text": "Preliminaries\nThe extensive section reviews LLMs and prompt engineering, emphasizing their capabilities in natural language processing and code synthesis. It also introduces the concept of LLM-based autonomous agents as a core controller for planning and decision-making."
  },
  {
    "objectID": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#our-approach",
    "href": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#our-approach",
    "title": "Experimenting a New Programming Practice with LLMs",
    "section": "Our Approach",
    "text": "Our Approach\nThe paper introduces the AI-aided software development framework AISD, designed to involve users in the development process and to simplify system design to align with LLM capabilities. It lays out the workflow of AISD, involving user feedback in use case generation and manual testing."
  },
  {
    "objectID": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#experiments",
    "href": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#experiments",
    "title": "Experimenting a New Programming Practice with LLMs",
    "section": "Experiments",
    "text": "Experiments\nThe authors evaluate AISD using an internally developed benchmark, CAASD, comparing it to two existing approaches, ChatDev and MetaGPT. The experiment demonstrates that AISD achieved an impressive pass rate of 75.2% with the lowest token consumption, highlighting the critical role of human engagement."
  },
  {
    "objectID": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#related-work",
    "href": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#related-work",
    "title": "Experimenting a New Programming Practice with LLMs",
    "section": "Related Work",
    "text": "Related Work\nThe paper contextualizes its work within existing approaches to automatic code generation, emphasizing the limitations of traditional techniques and the potential of LLMs in software development."
  },
  {
    "objectID": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#critique",
    "href": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#critique",
    "title": "Experimenting a New Programming Practice with LLMs",
    "section": "Critique",
    "text": "Critique\nWhile the paper presents compelling findings about the potential of AI-aided software development and the effectiveness of AISD, it has limitations: - Benchmark Validity: The benchmark created by the authors may have bias and limitations that need to be addressed. - Limited Comparison: The comparison with existing approaches may not fully capture the complexity and diversity of real-world software projects. - Human Interaction: The paper highlights the importance of human interaction but does not delve into the potential challenges and biases introduced by human involvement.\nIn conclusion, the paper presents a compelling approach to AI-aided software development, emphasizing the critical role of human engagement in improving development outcomes. However, further research and refinement are necessary to validate the effectiveness and robustness of the proposed framework."
  },
  {
    "objectID": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#appendix",
    "href": "posts/Experimenting_a_New_Programming_Practice_with_LLMs/2024-01-02-Experimenting_a_New_Programming_Practice_with_LLMs.html#appendix",
    "title": "Experimenting a New Programming Practice with LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01062v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01062v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12628"
  },
  {
    "objectID": "posts/Social_Transmotion__Promptable_Human_Trajectory_Prediction/2023-12-26-Social_Transmotion__Promptable_Human_Trajectory_Prediction.html#appendix",
    "href": "posts/Social_Transmotion__Promptable_Human_Trajectory_Prediction/2023-12-26-Social_Transmotion__Promptable_Human_Trajectory_Prediction.html#appendix",
    "title": "Social-Transmotion: Promptable Human Trajectory Prediction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16168v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16168v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10818"
  },
  {
    "objectID": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#key-findings",
    "href": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#key-findings",
    "title": "Geometric Awareness in Neural Fields for 3D Human Registration",
    "section": "Key Findings",
    "text": "Key Findings\n\nTask Significance: The paper addresses the crucial task of aligning a template to 3D human point clouds, important for animation, reconstruction, and supervised learning pipelines.\nProposed Solutions: The paper proposed two solutions, LoVD and INT, to address the lack of geometric awareness in neural fields. LoVD is a novel approach with localized MLPs to predict offsets, while INT is a self-supervised task to enhance the backbone network’s geometric awareness.\nPerformance: The integrated INLoVD pipeline, trained on a large MoCap dataset, achieves state-of-the-art results, is efficient, and demonstrates robustness and generalization on diverse out-of-distribution data sources."
  },
  {
    "objectID": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#introduction",
    "href": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#introduction",
    "title": "Geometric Awareness in Neural Fields for 3D Human Registration",
    "section": "Introduction",
    "text": "Introduction\n\n3D surface registration, particularly for human models, is crucial for various applications in computer vision, but poses significant challenges due to articulations, fine-grained details, and noisy acquisition processes."
  },
  {
    "objectID": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#proposed-solutions",
    "href": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#proposed-solutions",
    "title": "Geometric Awareness in Neural Fields for 3D Human Registration",
    "section": "Proposed Solutions",
    "text": "Proposed Solutions\n\nLoVD: A novel localized neural field model that predicts offsets for localized parts of the shape using spectral segmentation of the template.\nINT: A self-supervised task that enhances geometric awareness at inference time by refining the neural field’s predictions based on the target’s vertices."
  },
  {
    "objectID": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#inlovd-registration-pipeline",
    "href": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#inlovd-registration-pipeline",
    "title": "Geometric Awareness in Neural Fields for 3D Human Registration",
    "section": "INLoVD Registration Pipeline",
    "text": "INLoVD Registration Pipeline\n\nThe INLoVD pipeline integrates LoVD and INT to provide efficient and robust human registration, achieving state-of-the-art performance on public benchmarks and real-world challenges out of the training distribution."
  },
  {
    "objectID": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#related-works",
    "href": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#related-works",
    "title": "Geometric Awareness in Neural Fields for 3D Human Registration",
    "section": "Related Works",
    "text": "Related Works\n\nThe paper provides an extensive survey of related works in shape correspondence, shape matching, shape registration, and 3D human registration, highlighting the novelty and significance of the proposed solutions."
  },
  {
    "objectID": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#results",
    "href": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#results",
    "title": "Geometric Awareness in Neural Fields for 3D Human Registration",
    "section": "Results",
    "text": "Results\n\nThe paper reports comprehensive results validating the performance and generalization of the proposed INLoVD pipeline across diverse datasets, demonstrating its efficacy in handling challenging poses, partial point clouds, clutter, and diverse identities."
  },
  {
    "objectID": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#further-validations-and-ablations",
    "href": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#further-validations-and-ablations",
    "title": "Geometric Awareness in Neural Fields for 3D Human Registration",
    "section": "Further Validations and Ablations",
    "text": "Further Validations and Ablations\n\nThe paper provides detailed technical specifications, ablation studies, and further validation results to demonstrate the robustness and generalization of the proposed methods."
  },
  {
    "objectID": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#critique-and-further-directions",
    "href": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#critique-and-further-directions",
    "title": "Geometric Awareness in Neural Fields for 3D Human Registration",
    "section": "Critique and Further Directions",
    "text": "Critique and Further Directions\n\nWhile the paper presents compelling results, potential limitations include addressing failure cases related to the presence of clutter, unusual poses, and incomplete information in partial point clouds. Additionally, strategies to address the generalization and robustness of the proposed methods could be further highlighted.\n\nOverall, the paper makes significant contributions to the field of 3D human registration and demonstrates the efficacy of the proposed INLoVD pipeline in addressing real-world challenges. Further investigation into the failure cases and potential refinement of the proposed solutions could enhance the practical applicability of the methods."
  },
  {
    "objectID": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#appendix",
    "href": "posts/Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration/2023-12-21-Geometric_Awareness_in_Neural_Fields_for_3D_Human_Registration.html#appendix",
    "title": "Geometric Awareness in Neural Fields for 3D Human Registration",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.14024v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.14024v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13169"
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#key-findings",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#key-findings",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Key Findings",
    "text": "Key Findings\n\nThe paper presents an evolving large language model assistant that utilizes verbal long-term memory to preserve knowledge and experience from previous dialogues to improve future responses.\nConditional memory is proposed as a new memorizing mechanism to address the shortcomings of existing methods in preserving and utilizing critical information from dialogues.\nThe study evaluates the model on three constructed test datasets focusing on different abilities required by an AI assistant with long-term memory and finds that conditional memory achieves relatively better results."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#introduction",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#introduction",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Introduction",
    "text": "Introduction\n\nThe rapid development of large language models has led to the widespread use of AI assistants such as ChatGPT, which provide assistance through dialogue interactions.\nHowever, current AI assistants lack the ability to preserve information from previous dialogue sessions, hindering their capacity to learn and improve responses over time."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#proposed-framework",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#proposed-framework",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Proposed Framework",
    "text": "Proposed Framework\n\nThe evolving large language model assistant is made up of an existing LLM assistant, a memory, and a prompt-based wrapper responsible for interactions between the assistant and the memory.\nThe wrapper constructs memory records from ongoing dialogues and stores them in the memory, which is later retrieved to enhance the quality of responses."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#memory-construction",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#memory-construction",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Memory Construction",
    "text": "Memory Construction\n\nThe study explores three types of memory construction mechanisms: History-Based Memory, Summary-Based Memory, and Conditional Memory.\nConditional Memory is proposed to selectively memorize crucial information based on the importance of each utterance."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#memory-retrieval-and-application",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#memory-retrieval-and-application",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Memory Retrieval and Application",
    "text": "Memory Retrieval and Application\n\nThe retrieval of memory records is conducted using dense retrieval, and a self-reflection mechanism is employed to determine the usefulness of retrieved information in response generation."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#evaluation",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#evaluation",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Evaluation",
    "text": "Evaluation\n\nThe model is evaluated on three test datasets focusing on different aspects: continuing previous dialogues, learning new knowledge, and learning from human feedback.\nThe results show that conditional memory outperforms other forms of memory in learning new knowledge and learning from human feedback."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#critique",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#critique",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Critique",
    "text": "Critique\n\nThe study relies on small-scale test datasets, limiting the generalizability of the findings to real-world scenarios with larger and more diverse data.\nThe paper mainly investigates the foundational aspects of the proposed idea, leaving other key aspects such as the time stamp or forgetting mechanism unexplored."
  },
  {
    "objectID": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#appendix",
    "href": "posts/Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory/2023-12-22-Evolving_Large_Language_Model_Assistant_with_Long_Term_Conditional_Memory.html#appendix",
    "title": "Evolving Large Language Model Assistant with Long-Term Conditional Memory",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17257v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17257v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8298"
  },
  {
    "objectID": "posts/CMOSE__Comprehensive_Multi_Modality_Online_Student_Engagement_Dataset_with_High_Quality_Labels/2023-12-14-CMOSE__Comprehensive_Multi_Modality_Online_Student_Engagement_Dataset_with_High_Quality_Labels.html#appendix",
    "href": "posts/CMOSE__Comprehensive_Multi_Modality_Online_Student_Engagement_Dataset_with_High_Quality_Labels/2023-12-14-CMOSE__Comprehensive_Multi_Modality_Online_Student_Engagement_Dataset_with_High_Quality_Labels.html#appendix",
    "title": "CMOSE: Comprehensive Multi-Modality Online Student Engagement Dataset with High-Quality Labels",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.09066v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.09066v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11114"
  },
  {
    "objectID": "posts/ChatEd__A_Chatbot_Leveraging_ChatGPT_for_an_Enhanced_Learning_Experience_in_Higher_Education/2023-12-29-ChatEd__A_Chatbot_Leveraging_ChatGPT_for_an_Enhanced_Learning_Experience_in_Higher_Education.html#appendix",
    "href": "posts/ChatEd__A_Chatbot_Leveraging_ChatGPT_for_an_Enhanced_Learning_Experience_in_Higher_Education/2023-12-29-ChatEd__A_Chatbot_Leveraging_ChatGPT_for_an_Enhanced_Learning_Experience_in_Higher_Education.html#appendix",
    "title": "ChatEd: A Chatbot Leveraging ChatGPT for an Enhanced Learning Experience in Higher Education",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00052v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00052v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5566"
  },
  {
    "objectID": "posts/A_novel_diffusion_recommendation_algorithm_based_on_multi_scale_cnn_and_residual_lstm/2023-12-18-A_novel_diffusion_recommendation_algorithm_based_on_multi_scale_cnn_and_residual_lstm.html#appendix",
    "href": "posts/A_novel_diffusion_recommendation_algorithm_based_on_multi_scale_cnn_and_residual_lstm/2023-12-18-A_novel_diffusion_recommendation_algorithm_based_on_multi_scale_cnn_and_residual_lstm.html#appendix",
    "title": "A novel diffusion recommendation algorithm based on multi-scale cnn and residual lstm",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10885v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10885v1\n\n\nTruncated\nTrue\n\n\nWord Count\n15908"
  },
  {
    "objectID": "posts/Evaluating_Augmented_Reality_Communication__How_Can_We_Teach_Procedural_Skill_in_AR_/2023-12-14-Evaluating_Augmented_Reality_Communication__How_Can_We_Teach_Procedural_Skill_in_AR_.html#appendix",
    "href": "posts/Evaluating_Augmented_Reality_Communication__How_Can_We_Teach_Procedural_Skill_in_AR_/2023-12-14-Evaluating_Augmented_Reality_Communication__How_Can_We_Teach_Procedural_Skill_in_AR_.html#appendix",
    "title": "Evaluating Augmented Reality Communication: How Can We Teach Procedural Skill in AR?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.09152v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.09152v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11943"
  },
  {
    "objectID": "posts/TREC_iKAT_2023__The_Interactive_Knowledge_Assistance_Track_Overview/2024-01-02-TREC_iKAT_2023__The_Interactive_Knowledge_Assistance_Track_Overview.html#appendix",
    "href": "posts/TREC_iKAT_2023__The_Interactive_Knowledge_Assistance_Track_Overview/2024-01-02-TREC_iKAT_2023__The_Interactive_Knowledge_Assistance_Track_Overview.html#appendix",
    "title": "TREC iKAT 2023: The Interactive Knowledge Assistance Track Overview",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01330v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01330v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9078"
  },
  {
    "objectID": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#key-findings",
    "href": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#key-findings",
    "title": "Alleviating Hallucinations of Large Language Models through Induced Hallucinations",
    "section": "Key Findings",
    "text": "Key Findings\n\nHallucinations in Large Language Models (LLMs): The paper introduces an approach called “Induce-then-Contrast Decoding (ICD)” to mitigate the phenomenon of hallucinations in LLMs by inducing factually weak LLMs and penalizing induced hallucinations during model decoding.\nEffectiveness of ICD: Experimental results demonstrate that the ICD approach significantly enhances the factuality of LLMs, as shown through improved performance on benchmarks such as TruthfulQA and FActScore.\nComparison with other Methods: The paper compares ICD with other decoding methods such as greedy decoding, inference time intervention (ITI), DoLa, and vanilla contrastive decoding (CD), demonstrating the superiority of ICD in reducing hallucinations and improving factuality."
  },
  {
    "objectID": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#introduction",
    "href": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#introduction",
    "title": "Alleviating Hallucinations of Large Language Models through Induced Hallucinations",
    "section": "Introduction",
    "text": "Introduction\n\nLarge Language Models (LLMs) exhibit remarkable capabilities but are prone to generating hallucinations - inaccurate or fabricated information, hindering their practical application in real-world scenarios."
  },
  {
    "objectID": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#induce-then-contrast-decoding",
    "href": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#induce-then-contrast-decoding",
    "title": "Alleviating Hallucinations of Large Language Models through Induced Hallucinations",
    "section": "Induce-then-Contrast Decoding",
    "text": "Induce-then-Contrast Decoding\n\nInducing Hallucinations from LLMs\n\nThe paper proposes a process for inducing hallucinations from LLMs, using fine-tuning with non-factual samples obtained through prompting.\nIt describes the fine-tuning process and the formulation of the fine-tuning dataset.\n\n\n\nFactually Weak LLM as A Penalty\n\nThe decoding process of LLMs is described, outlining the strategy to amplify the predictions from the original model and downplay the untruthful predictions using contrastive decoding."
  },
  {
    "objectID": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#experiments",
    "href": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#experiments",
    "title": "Alleviating Hallucinations of Large Language Models through Induced Hallucinations",
    "section": "Experiments",
    "text": "Experiments\n\nExperimental results on TruthfulQA and FActScore benchmarks demonstrate the efficacy of ICD in enhancing LLM factuality compared to other decoding methods.\nThe paper evaluates the impact of different tasks and model sizes on ICD effectiveness and analyzes the influence of fine-tuning data size and its source when inducing hallucinations."
  },
  {
    "objectID": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#critique",
    "href": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#critique",
    "title": "Alleviating Hallucinations of Large Language Models through Induced Hallucinations",
    "section": "Critique",
    "text": "Critique\nLimitations - The additional computational costs introduced by ICD could be a potential limitation. - The evaluation setting is limited to specific benchmarks, potentially restricting the generalization of the findings to other domains and tasks.\nEthical Considerations - The study acknowledges the ethical considerations of human annotator compensation and potential risks related to the inadvertent manipulation of LLMs.\nOverall, the paper presents a novel approach, ICD, for mitigating hallucinations in LLMs, demonstrating its effectiveness through experimental evaluations. However, the limitations and ethical considerations should be further addressed in future research."
  },
  {
    "objectID": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#appendix",
    "href": "posts/Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations/2023-12-25-Alleviating_Hallucinations_of_Large_Language_Models_through_Induced_Hallucinations.html#appendix",
    "title": "Alleviating Hallucinations of Large Language Models through Induced Hallucinations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.15710v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.15710v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9227"
  },
  {
    "objectID": "posts/GuardRails__Automated_Suggestions_for_Clarifying_Ambiguous_Purpose_Statements/2023-12-13-GuardRails__Automated_Suggestions_for_Clarifying_Ambiguous_Purpose_Statements.html#appendix",
    "href": "posts/GuardRails__Automated_Suggestions_for_Clarifying_Ambiguous_Purpose_Statements/2023-12-13-GuardRails__Automated_Suggestions_for_Clarifying_Ambiguous_Purpose_Statements.html#appendix",
    "title": "GuardRails: Automated Suggestions for Clarifying Ambiguous Purpose Statements",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.08189v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.08189v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5188"
  },
  {
    "objectID": "posts/Timeliness__A_New_Design_Metric_and_a_New_Attack_Surface/2023-12-28-Timeliness__A_New_Design_Metric_and_a_New_Attack_Surface.html#appendix",
    "href": "posts/Timeliness__A_New_Design_Metric_and_a_New_Attack_Surface/2023-12-28-Timeliness__A_New_Design_Metric_and_a_New_Attack_Surface.html#appendix",
    "title": "Timeliness: A New Design Metric and a New Attack Surface",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17220v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17220v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8673"
  },
  {
    "objectID": "posts/Designing_Artificial_Intelligence_Equipped_Social_Decentralized_Autonomous_Organizations_for_Tackling_Sextortion_Cases_Version_0.7/2023-12-21-Designing_Artificial_Intelligence_Equipped_Social_Decentralized_Autonomous_Organizations_for_Tackling_Sextortion_Cases_Version_0.7.html#appendix",
    "href": "posts/Designing_Artificial_Intelligence_Equipped_Social_Decentralized_Autonomous_Organizations_for_Tackling_Sextortion_Cases_Version_0.7/2023-12-21-Designing_Artificial_Intelligence_Equipped_Social_Decentralized_Autonomous_Organizations_for_Tackling_Sextortion_Cases_Version_0.7.html#appendix",
    "title": "Designing Artificial Intelligence Equipped Social Decentralized Autonomous Organizations for Tackling Sextortion Cases Version 0.7",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.14090v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.14090v1\n\n\nTruncated\nTrue\n\n\nWord Count\n63528"
  },
  {
    "objectID": "posts/ICL_Markup__Structuring_In_Context_Learning_using_Soft_Token_Tags/2023-12-12-ICL_Markup__Structuring_In_Context_Learning_using_Soft_Token_Tags.html#appendix",
    "href": "posts/ICL_Markup__Structuring_In_Context_Learning_using_Soft_Token_Tags/2023-12-12-ICL_Markup__Structuring_In_Context_Learning_using_Soft_Token_Tags.html#appendix",
    "title": "ICL Markup: Structuring In-Context Learning using Soft-Token Tags",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.07405v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.07405v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12688"
  },
  {
    "objectID": "posts/A_Computational_Framework_for_Behavioral_Assessment_of_LLM_Therapists/2024-01-01-A_Computational_Framework_for_Behavioral_Assessment_of_LLM_Therapists.html#appendix",
    "href": "posts/A_Computational_Framework_for_Behavioral_Assessment_of_LLM_Therapists/2024-01-01-A_Computational_Framework_for_Behavioral_Assessment_of_LLM_Therapists.html#appendix",
    "title": "A Computational Framework for Behavioral Assessment of LLM Therapists",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00820v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00820v1\n\n\nTruncated\nTrue\n\n\nWord Count\n19139"
  },
  {
    "objectID": "posts/VideoDrafter__Content_Consistent_Multi_Scene_Video_Generation_with_LLM/2024-01-02-VideoDrafter__Content_Consistent_Multi_Scene_Video_Generation_with_LLM.html#appendix",
    "href": "posts/VideoDrafter__Content_Consistent_Multi_Scene_Video_Generation_with_LLM/2024-01-02-VideoDrafter__Content_Consistent_Multi_Scene_Video_Generation_with_LLM.html#appendix",
    "title": "VideoDrafter: Content-Consistent Multi-Scene Video Generation with LLM",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01256v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01256v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9002"
  },
  {
    "objectID": "posts/Cooperation_on_the_Fly__Exploring_Language_Agents_for_Ad_Hoc_Teamwork_in_the_Avalon_Game/2023-12-29-Cooperation_on_the_Fly__Exploring_Language_Agents_for_Ad_Hoc_Teamwork_in_the_Avalon_Game.html",
    "href": "posts/Cooperation_on_the_Fly__Exploring_Language_Agents_for_Ad_Hoc_Teamwork_in_the_Avalon_Game/2023-12-29-Cooperation_on_the_Fly__Exploring_Language_Agents_for_Ad_Hoc_Teamwork_in_the_Avalon_Game.html",
    "title": "Cooperation on the Fly: Exploring Language Agents for Ad Hoc Teamwork in the Avalon Game",
    "section": "",
    "text": "Major Findings:"
  },
  {
    "objectID": "posts/Cooperation_on_the_Fly__Exploring_Language_Agents_for_Ad_Hoc_Teamwork_in_the_Avalon_Game/2023-12-29-Cooperation_on_the_Fly__Exploring_Language_Agents_for_Ad_Hoc_Teamwork_in_the_Avalon_Game.html#appendix",
    "href": "posts/Cooperation_on_the_Fly__Exploring_Language_Agents_for_Ad_Hoc_Teamwork_in_the_Avalon_Game/2023-12-29-Cooperation_on_the_Fly__Exploring_Language_Agents_for_Ad_Hoc_Teamwork_in_the_Avalon_Game.html#appendix",
    "title": "Cooperation on the Fly: Exploring Language Agents for Ad Hoc Teamwork in the Avalon Game",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17515v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17515v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7222"
  },
  {
    "objectID": "posts/MedSumm__A_Multimodal_Approach_to_Summarizing_Code_Mixed_Hindi_English_Clinical_Queries/2024-01-03-MedSumm__A_Multimodal_Approach_to_Summarizing_Code_Mixed_Hindi_English_Clinical_Queries.html#appendix",
    "href": "posts/MedSumm__A_Multimodal_Approach_to_Summarizing_Code_Mixed_Hindi_English_Clinical_Queries/2024-01-03-MedSumm__A_Multimodal_Approach_to_Summarizing_Code_Mixed_Hindi_English_Clinical_Queries.html#appendix",
    "title": "MedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English Clinical Queries",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01596v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01596v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6480"
  },
  {
    "objectID": "posts/BatchEval__Towards_Human_like_Text_Evaluation/2023-12-31-BatchEval__Towards_Human_like_Text_Evaluation.html#appendix",
    "href": "posts/BatchEval__Towards_Human_like_Text_Evaluation/2023-12-31-BatchEval__Towards_Human_like_Text_Evaluation.html#appendix",
    "title": "BatchEval: Towards Human-like Text Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00437v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00437v1\n\n\nTruncated\nTrue\n\n\nWord Count\n15893"
  },
  {
    "objectID": "posts/Sparse_but_Strong__Crafting_Adversarially_Robust_Graph_Lottery_Tickets/2023-12-11-Sparse_but_Strong__Crafting_Adversarially_Robust_Graph_Lottery_Tickets.html#appendix",
    "href": "posts/Sparse_but_Strong__Crafting_Adversarially_Robust_Graph_Lottery_Tickets/2023-12-11-Sparse_but_Strong__Crafting_Adversarially_Robust_Graph_Lottery_Tickets.html#appendix",
    "title": "Sparse but Strong: Crafting Adversarially Robust Graph Lottery Tickets",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.06568v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.06568v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12768"
  },
  {
    "objectID": "posts/Distillation_is_All_You_Need_for_Practically_Using_Different_Pre_trained_Recommendation_Models/2024-01-01-Distillation_is_All_You_Need_for_Practically_Using_Different_Pre_trained_Recommendation_Models.html#appendix",
    "href": "posts/Distillation_is_All_You_Need_for_Practically_Using_Different_Pre_trained_Recommendation_Models/2024-01-01-Distillation_is_All_You_Need_for_Practically_Using_Different_Pre_trained_Recommendation_Models.html#appendix",
    "title": "Distillation is All You Need for Practically Using Different Pre-trained Recommendation Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00797v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00797v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11769"
  },
  {
    "objectID": "posts/Applying_Bayesian_Data_Analysis_for_Causal_Inference_about_Requirements_Quality__A_Replicated_Experiment/2024-01-02-Applying_Bayesian_Data_Analysis_for_Causal_Inference_about_Requirements_Quality__A_Replicated_Experiment.html#appendix",
    "href": "posts/Applying_Bayesian_Data_Analysis_for_Causal_Inference_about_Requirements_Quality__A_Replicated_Experiment/2024-01-02-Applying_Bayesian_Data_Analysis_for_Causal_Inference_about_Requirements_Quality__A_Replicated_Experiment.html#appendix",
    "title": "Applying Bayesian Data Analysis for Causal Inference about Requirements Quality: A Replicated Experiment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01154v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01154v1\n\n\nTruncated\nTrue\n\n\nWord Count\n26833"
  },
  {
    "objectID": "posts/Logic_Scaffolding__Personalized_Aspect_Instructed_Recommendation_Explanation_Generation_using_LLMs/2023-12-22-Logic_Scaffolding__Personalized_Aspect_Instructed_Recommendation_Explanation_Generation_using_LLMs.html#appendix",
    "href": "posts/Logic_Scaffolding__Personalized_Aspect_Instructed_Recommendation_Explanation_Generation_using_LLMs/2023-12-22-Logic_Scaffolding__Personalized_Aspect_Instructed_Recommendation_Explanation_Generation_using_LLMs.html#appendix",
    "title": "Logic-Scaffolding: Personalized Aspect-Instructed Recommendation Explanation Generation using LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.14345v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.14345v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3123"
  },
  {
    "objectID": "posts/Understanding_the_Instruction_Mixture_for_Large_Language_Model/2023-12-17-Understanding_the_Instruction_Mixture_for_Large_Language_Model.html#major-findings",
    "href": "posts/Understanding_the_Instruction_Mixture_for_Large_Language_Model/2023-12-17-Understanding_the_Instruction_Mixture_for_Large_Language_Model.html#major-findings",
    "title": "Understanding the Instruction Mixture for Large Language Model",
    "section": "Major Findings",
    "text": "Major Findings\n\nSpecific types of instructions are more beneficial for particular uses, while they may cause harm to other aspects.\nEvaluating models with diverse benchmarks and alignment skills yielded insights into the impact of different distributions of instruction datasets on model performance across diverse aspects.\nResults suggest that researchers should carefully design the instruction mixture to maximize the model’s performance on the target usage, taking model size into consideration."
  },
  {
    "objectID": "posts/Understanding_the_Instruction_Mixture_for_Large_Language_Model/2023-12-17-Understanding_the_Instruction_Mixture_for_Large_Language_Model.html#experimental-setup",
    "href": "posts/Understanding_the_Instruction_Mixture_for_Large_Language_Model/2023-12-17-Understanding_the_Instruction_Mixture_for_Large_Language_Model.html#experimental-setup",
    "title": "Understanding the Instruction Mixture for Large Language Model",
    "section": "Experimental Setup",
    "text": "Experimental Setup\n\nSupervised fine-tuning (SFT) has been proven to be an effective approach to align large language models (LLMs) with human instructions, enhancing downstream task performance and facilitating code generation.\nThe study focused on evaluating the model’s performance in three key areas: NLP downstream task performance, coding ability, and chat capabilities.\nExperiments were conducted using eight different mixture settings involving instruction datasets for NLP downstream tasks, code generation, and general-purpose instructions."
  },
  {
    "objectID": "posts/Understanding_the_Instruction_Mixture_for_Large_Language_Model/2023-12-17-Understanding_the_Instruction_Mixture_for_Large_Language_Model.html#results",
    "href": "posts/Understanding_the_Instruction_Mixture_for_Large_Language_Model/2023-12-17-Understanding_the_Instruction_Mixture_for_Large_Language_Model.html#results",
    "title": "Understanding the Instruction Mixture for Large Language Model",
    "section": "Results",
    "text": "Results\n\nDifferent types of specialized instructions improved the performance on the benchmarks they were designed for.\nIncorporating general instructions consistently improved coding performance, and larger models could better leverage various instructions.\nThe mixture of instruction datasets had a significant impact on alignment skills, with general instructions providing better alignment skills and performance on NLP benchmarks."
  },
  {
    "objectID": "posts/Understanding_the_Instruction_Mixture_for_Large_Language_Model/2023-12-17-Understanding_the_Instruction_Mixture_for_Large_Language_Model.html#critique",
    "href": "posts/Understanding_the_Instruction_Mixture_for_Large_Language_Model/2023-12-17-Understanding_the_Instruction_Mixture_for_Large_Language_Model.html#critique",
    "title": "Understanding the Instruction Mixture for Large Language Model",
    "section": "Critique",
    "text": "Critique\nThe paper’s potential limitations include: - Limited use of only LLaMA-2 7B and 13B models in the experiments, with the need for verification using different sizes of models. - The restriction to a specific instruction dataset size and mainly comparing the 1:1 ratio of all instruction types, leaving the exploration of the impact of more instructions and mixing ratios for future research.\nIt is important to consider the potential variability in model behavior across different sizes and explore the impact of different instruction dataset sizes and mixing ratios on LLMs’ performance for comprehensive understanding."
  },
  {
    "objectID": "posts/Understanding_the_Instruction_Mixture_for_Large_Language_Model/2023-12-17-Understanding_the_Instruction_Mixture_for_Large_Language_Model.html#appendix",
    "href": "posts/Understanding_the_Instruction_Mixture_for_Large_Language_Model/2023-12-17-Understanding_the_Instruction_Mixture_for_Large_Language_Model.html#appendix",
    "title": "Understanding the Instruction Mixture for Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10793v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10793v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4269"
  },
  {
    "objectID": "posts/Large_Language_Models_for_Mathematicians/2023-12-07-Large_Language_Models_for_Mathematicians.html#appendix",
    "href": "posts/Large_Language_Models_for_Mathematicians/2023-12-07-Large_Language_Models_for_Mathematicians.html#appendix",
    "title": "Large Language Models for Mathematicians",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.04556v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.04556v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13153"
  },
  {
    "objectID": "posts/The_Earth_is_Flat__Unveiling_Factual_Errors_in_Large_Language_Models/2024-01-01-The_Earth_is_Flat__Unveiling_Factual_Errors_in_Large_Language_Models.html#summary",
    "href": "posts/The_Earth_is_Flat__Unveiling_Factual_Errors_in_Large_Language_Models/2024-01-01-The_Earth_is_Flat__Unveiling_Factual_Errors_in_Large_Language_Models.html#summary",
    "title": "The Earth is Flat? Unveiling Factual Errors in Large Language Models",
    "section": "Summary",
    "text": "Summary\n\nMajor Takeaways\n\nBiasAsker is introduced as a testing method to identify bias in conversational AI software through asking questions.\nThe study demonstrates that BiasAsker can effectively reveal factual errors in a variety of large language models used in chatbot and digital assistant applications with an accuracy of up to 78.2% for commercial LLMs and an improvement of 33.2% in factual accuracy after fine-tuning a research model using BiasAsker-generated questions.\nBiasAsker is shown to be highly effective in identifying factual errors, passing a manual validation with a ~93% accuracy in identified errors.\n\n\n\nBackground\nRecent advancements in Large Language Models (LLMs) have led to the rapid adoption of AI-driven chatbot and digital assistant applications. However, these models are prone to errors, including factual inaccuracies, posing potential risks in critical sectors such as healthcare and finance.\n\n\nApproach and Implementation\nBiasAsker operates in three stages: Knowledge Graph Construction, Question Generation, and Answer Assessment. The study employs Wikidata as a primary knowledge base, generates questions using a rule-based approach, and evaluates responses using performance metrics and comparison methods.\n\n\nEvaluation\n\nEffectiveness of BiasAsker: BiasAsker successfully identifies factual errors across various LLMs, notably detecting 36.9% of the test cases with errors.\nValidity of Identified Factual Errors: Upon manual inspection, 93% of the identified errors were found to be valid.\nUsing BiasAsker for Improvement: Test cases generated by BiasAsker led to substantial improvements in factual accuracy, with an average improvement of 6.5% using in-context learning and 33.2% via fine-tuning of the research models."
  },
  {
    "objectID": "posts/The_Earth_is_Flat__Unveiling_Factual_Errors_in_Large_Language_Models/2024-01-01-The_Earth_is_Flat__Unveiling_Factual_Errors_in_Large_Language_Models.html#critique",
    "href": "posts/The_Earth_is_Flat__Unveiling_Factual_Errors_in_Large_Language_Models/2024-01-01-The_Earth_is_Flat__Unveiling_Factual_Errors_in_Large_Language_Models.html#critique",
    "title": "The Earth is Flat? Unveiling Factual Errors in Large Language Models",
    "section": "Critique",
    "text": "Critique\nThe paper’s reliance on NLP methods for error detection and the limitation to a single knowledge base may introduce the potential for false positives or overlook factual inaccuracies. Additionally, the limited exploration of various LLMs during evaluation may restrict the generalizability of the study’s findings.\nOverall, the study’s use of BiasAsker offers a valuable contribution to the field of conversational AI software testing, demonstrating its effectiveness in identifying and rectifying factual inaccuracies in large language models. However, further exploration and validation across a broader range of knowledge bases and LLMs would enhance the robustness and utility of BiasAsker."
  },
  {
    "objectID": "posts/The_Earth_is_Flat__Unveiling_Factual_Errors_in_Large_Language_Models/2024-01-01-The_Earth_is_Flat__Unveiling_Factual_Errors_in_Large_Language_Models.html#appendix",
    "href": "posts/The_Earth_is_Flat__Unveiling_Factual_Errors_in_Large_Language_Models/2024-01-01-The_Earth_is_Flat__Unveiling_Factual_Errors_in_Large_Language_Models.html#appendix",
    "title": "The Earth is Flat? Unveiling Factual Errors in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00761v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00761v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11574"
  },
  {
    "objectID": "posts/WordArt_Designer_API__User_Driven_Artistic_Typography_Synthesis_with_Large_Language_Models_on_ModelScope/2024-01-03-WordArt_Designer_API__User_Driven_Artistic_Typography_Synthesis_with_Large_Language_Models_on_ModelScope.html#appendix",
    "href": "posts/WordArt_Designer_API__User_Driven_Artistic_Typography_Synthesis_with_Large_Language_Models_on_ModelScope/2024-01-03-WordArt_Designer_API__User_Driven_Artistic_Typography_Synthesis_with_Large_Language_Models_on_ModelScope.html#appendix",
    "title": "WordArt Designer API: User-Driven Artistic Typography Synthesis with Large Language Models on ModelScope",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01699v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01699v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1741"
  },
  {
    "objectID": "posts/Uncertainty_Resolution_in_Misinformation_Detection/2024-01-02-Uncertainty_Resolution_in_Misinformation_Detection.html#appendix",
    "href": "posts/Uncertainty_Resolution_in_Misinformation_Detection/2024-01-02-Uncertainty_Resolution_in_Misinformation_Detection.html#appendix",
    "title": "Uncertainty Resolution in Misinformation Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01197v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01197v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7771"
  },
  {
    "objectID": "posts/Navigating_Uncertainty__Optimizing_API_Dependency_for_Hallucination_Reduction_in_Closed_Book_Question_Answering/2024-01-03-Navigating_Uncertainty__Optimizing_API_Dependency_for_Hallucination_Reduction_in_Closed_Book_Question_Answering.html#appendix",
    "href": "posts/Navigating_Uncertainty__Optimizing_API_Dependency_for_Hallucination_Reduction_in_Closed_Book_Question_Answering/2024-01-03-Navigating_Uncertainty__Optimizing_API_Dependency_for_Hallucination_Reduction_in_Closed_Book_Question_Answering.html#appendix",
    "title": "Navigating Uncertainty: Optimizing API Dependency for Hallucination Reduction in Closed-Book Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01780v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01780v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6011"
  },
  {
    "objectID": "posts/Revealing_Networks__Understanding_Effective_Teacher_Practices_in_AI_Supported_Classrooms_using_Transmodal_Ordered_Network_Analysis/2023-12-17-Revealing_Networks__Understanding_Effective_Teacher_Practices_in_AI_Supported_Classrooms_using_Transmodal_Ordered_Network_Analysis.html#summary-of-revealing-networks-understanding-effective-teacher-practices-in-ai-supported-classrooms",
    "href": "posts/Revealing_Networks__Understanding_Effective_Teacher_Practices_in_AI_Supported_Classrooms_using_Transmodal_Ordered_Network_Analysis/2023-12-17-Revealing_Networks__Understanding_Effective_Teacher_Practices_in_AI_Supported_Classrooms_using_Transmodal_Ordered_Network_Analysis.html#summary-of-revealing-networks-understanding-effective-teacher-practices-in-ai-supported-classrooms",
    "title": "Revealing Networks: Understanding Effective Teacher Practices in AI-Supported Classrooms using Transmodal Ordered Network Analysis",
    "section": "Summary of “Revealing Networks: Understanding Effective Teacher Practices in AI-Supported Classrooms”",
    "text": "Summary of “Revealing Networks: Understanding Effective Teacher Practices in AI-Supported Classrooms”\n\nMajor Findings:\n\nThe study found that incorporating out-of-tutor teacher practices significantly improved the inference of student learning rates in AI tutors.\nStudents with low learning rates tended to exhibit more hint use after monitoring by the teacher, while after extended visits, these students showed learning behavior similar to their peers with high learning rates.\nQualitative analysis revealed that teacher support during screen monitoring and talking differed for students with low and high learning rates, with low learning rate students receiving more procedural support and high learning rate students receiving abstract support.\n\n\n\nBackground:\n\nLearning in AI-supported classrooms involves students learning with AI-based systems while the teacher facilitates learning. Prior work has found that the role of teacher practice for effective learning with AI tutors is understudied and there is a lack of studies analyzing student learning through the lens of teacher practices.\nMultimodal Learning Analytics (MMLA) integrates data from various modalities to understand learning processes, and quantitative ethnography methods are increasingly used in learning analytics to model complex dependencies between data sets.\n\n\n\nMethods:\n\nThe study used Transmodal Ordered Network Analysis to model temporal relationships between teacher practices and student learning in AI-supported classrooms.\nData sets included student interaction data with an AI tutor, classroom observation notes, and teacher spatial positions during classroom practice.\nFeature engineering involved creating codes for teacher practices and student behaviors and grouping students by their learning rates.\n\n\n\nResults:\n\nIncluding out-of-tutor teacher practices significantly improved the inference of student learning rates within the AI tutor.\nConnection patterns for students with low and high learning rates differed, with low learning rate students exhibiting more hint use after monitoring by the teacher.\nTeacher visits led to changes in student behavior, with low learning rate students exhibiting more desirable learning behavior after extended visits.\n\n\n\nDiscussion:\n\nThe study provides insights into the associations between teacher practices and student learning rates and the differential impact of teacher support on students with low and high learning rates.\nQualitative analysis revealed differences in the type of teacher support provided to students with low and high learning rates, suggesting potential areas for intervention and improvement.\n\n\n\nCritique:\n\nThe study relies heavily on observational and log data, which may not fully capture the complexity of teacher-student interactions and learning processes. There may be confounding variables or unobserved factors influencing the relationships identified.\nThe study does not address potential biases in the observation and coding of teacher practices, which could impact the validity of the findings.\n\nOverall, the study provides valuable insights into the role of teacher practices in AI-supported classrooms and highlights the potential for further research and intervention to improve learning outcomes."
  },
  {
    "objectID": "posts/Revealing_Networks__Understanding_Effective_Teacher_Practices_in_AI_Supported_Classrooms_using_Transmodal_Ordered_Network_Analysis/2023-12-17-Revealing_Networks__Understanding_Effective_Teacher_Practices_in_AI_Supported_Classrooms_using_Transmodal_Ordered_Network_Analysis.html#appendix",
    "href": "posts/Revealing_Networks__Understanding_Effective_Teacher_Practices_in_AI_Supported_Classrooms_using_Transmodal_Ordered_Network_Analysis/2023-12-17-Revealing_Networks__Understanding_Effective_Teacher_Practices_in_AI_Supported_Classrooms_using_Transmodal_Ordered_Network_Analysis.html#appendix",
    "title": "Revealing Networks: Understanding Effective Teacher Practices in AI-Supported Classrooms using Transmodal Ordered Network Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10826v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10826v1\n\n\nTruncated\nTrue\n\n\nWord Count\n15625"
  },
  {
    "objectID": "posts/If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#main-findings",
    "href": "posts/If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#main-findings",
    "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents",
    "section": "Main Findings",
    "text": "Main Findings\n\nEnhanced Capabilities: The integration of code into large language models (LLMs) enhances their reasoning ability and programming skills, leading to improved performance as intelligent agents (IAs).\nDiverse Benefits: Code empowers LLMs to serve as IAs by improving their decision-making, execution, and self-improvement capabilities through the use of code-centric paradigms.\nIntegration with Functional Ends: LLMs connected to various functional ends through code exhibit versatility, enabling them to handle complex tasks and plan and execute actions."
  },
  {
    "objectID": "posts/If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#introduction",
    "href": "posts/If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#introduction",
    "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents",
    "section": "Introduction",
    "text": "Introduction\nThe paper presents a survey on the benefits of integrating code into LLMs and the emergence of LLMs as IAs. The code-centric paradigm enhances LLMs’ reasoning, planning, execution, and self-improvement capabilities in various contexts."
  },
  {
    "objectID": "posts/If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#preliminaries",
    "href": "posts/If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#preliminaries",
    "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents",
    "section": "Preliminaries",
    "text": "Preliminaries\n\nDefinition of Code: Code is a formal language that is both machine-executable and human-interpretable, including pre-defined formal languages and human-readable programming languages.\nLLM Code Training Methods: LLMs undergo code training through standard language modeling objectives applied to code corpora, involving code pre-training and code fine-tuning methods."
  },
  {
    "objectID": "posts/If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#code-pre-training-boosts-llms-performance",
    "href": "posts/If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#code-pre-training-boosts-llms-performance",
    "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents",
    "section": "Code Pre-Training Boosts LLMs’ Performance",
    "text": "Code Pre-Training Boosts LLMs’ Performance\n\nStrengthen LLMs’ Programming Skills: LLMs trained with code exhibit strong code generation and evaluation abilities, paving the way for various applications in different fields.\nEmpower LLMs’ Complex Reasoning: Code pre-training improves LLMs’ chain-of-thought performance, enhancing their reasoning skills and enabling them to perform complex reasoning tasks.\nEnable LLMs to Capture Structured Knowledge: Code-LLMs unveil superior structural commonsense reasoning, allowing them to understand complex multimedia data and structured information."
  },
  {
    "objectID": "posts/If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#code-connects-llms-to-other-functional-ends",
    "href": "posts/If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#code-connects-llms-to-other-functional-ends",
    "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents",
    "section": "Code Connects LLMs to Other Functional Ends",
    "text": "Code Connects LLMs to Other Functional Ends\n\nRelate LLMs to Digital Ends: LLMs linked to digital ends via a code-centric paradigm, aiding in leveraging textual and multimodal tools for improved performance in various tasks.\nRelate LLMs to Physical Ends: LLMs connected to physical ends, such as robotics and autonomous driving, demonstrating their potential in bridging the gap between physical worlds and AI."
  },
  {
    "objectID": "posts/If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#code-provides-llm-with-an-executable-environment-for-automated-feedback",
    "href": "posts/If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#code-provides-llm-with-an-executable-environment-for-automated-feedback",
    "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents",
    "section": "Code Provides LLM with an Executable Environment for Automated Feedback",
    "text": "Code Provides LLM with an Executable Environment for Automated Feedback\n\nVarious Feedback from Code Execution: Code execution environment provides versatile automated feedback, including simple correctness feedback, textual feedback, and feedback from external evaluation modules.\nMethods for Enhancing LLM’s Performance with Feedback: Feedback derived from code execution and external evaluation modules enhance LLMs through selection-based, prompting-based, and finetuning-based methods."
  },
  {
    "objectID": "posts/If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#application-code-empowered-llms-facilitate-intelligent-agents",
    "href": "posts/If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#application-code-empowered-llms-facilitate-intelligent-agents",
    "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents",
    "section": "Application: Code-empowered LLMs Facilitate Intelligent Agents",
    "text": "Application: Code-empowered LLMs Facilitate Intelligent Agents\n\nDecision Making: Code-empowered LLMs enhance IAs’ decision-making skills through better environment perception and improved planning capabilities.\nExecution: LLMs as IAs benefit from better action grounding and memory organization, leading to improved execution of complex tasks.\nSelf-improvement: LLM-based IAs can self-improve through feedback derived from code execution and external evaluation modules."
  },
  {
    "objectID": "posts/If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#challenges",
    "href": "posts/If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#challenges",
    "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents",
    "section": "Challenges",
    "text": "Challenges\n\nThe causality between code pre-training and LLMs’ reasoning enhancement.\nAcquisition of reasoning beyond code.\nChallenges of applying the code-centric paradigm."
  },
  {
    "objectID": "posts/If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#appendix",
    "href": "posts/If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents/2024-01-01-If_LLM_Is_the_Wizard__Then_Code_Is_the_Wand__A_Survey_on_How_Code_Empowers_Large_Language_Models_to_Serve_as_Intelligent_Agents.html#appendix",
    "title": "If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00812v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00812v1\n\n\nTruncated\nTrue\n\n\nWord Count\n17975"
  },
  {
    "objectID": "posts/Physio__An_LLM_Based_Physiotherapy_Advisor/2024-01-03-Physio__An_LLM_Based_Physiotherapy_Advisor.html#appendix",
    "href": "posts/Physio__An_LLM_Based_Physiotherapy_Advisor/2024-01-03-Physio__An_LLM_Based_Physiotherapy_Advisor.html#appendix",
    "title": "Physio: An LLM-Based Physiotherapy Advisor",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01825v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01825v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2619"
  },
  {
    "objectID": "posts/Latent_Space_Editing_in_Transformer_Based_Flow_Matching/2023-12-17-Latent_Space_Editing_in_Transformer_Based_Flow_Matching.html#appendix",
    "href": "posts/Latent_Space_Editing_in_Transformer_Based_Flow_Matching/2023-12-17-Latent_Space_Editing_in_Transformer_Based_Flow_Matching.html#appendix",
    "title": "Latent Space Editing in Transformer-Based Flow Matching",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.10825v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.10825v1\n\n\nTruncated\nTrue\n\n\nWord Count\n13723"
  },
  {
    "objectID": "posts/Context_aware_Decoding_Reduces_Hallucination_in_Query_focused_Summarization/2023-12-21-Context_aware_Decoding_Reduces_Hallucination_in_Query_focused_Summarization.html#appendix",
    "href": "posts/Context_aware_Decoding_Reduces_Hallucination_in_Query_focused_Summarization/2023-12-21-Context_aware_Decoding_Reduces_Hallucination_in_Query_focused_Summarization.html#appendix",
    "title": "Context-aware Decoding Reduces Hallucination in Query-focused Summarization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.14335v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.14335v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6395"
  },
  {
    "objectID": "posts/Grounding_Prompter__Prompting_LLM_with_Multimodal_Information_for_Temporal_Sentence_Grounding_in_Long_Videos/2023-12-28-Grounding_Prompter__Prompting_LLM_with_Multimodal_Information_for_Temporal_Sentence_Grounding_in_Long_Videos.html#appendix",
    "href": "posts/Grounding_Prompter__Prompting_LLM_with_Multimodal_Information_for_Temporal_Sentence_Grounding_in_Long_Videos/2023-12-28-Grounding_Prompter__Prompting_LLM_with_Multimodal_Information_for_Temporal_Sentence_Grounding_in_Long_Videos.html#appendix",
    "title": "Grounding-Prompter: Prompting LLM with Multimodal Information for Temporal Sentence Grounding in Long Videos",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17117v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17117v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8745"
  },
  {
    "objectID": "posts/Is_Knowledge_All_Large_Language_Models_Needed_for_Causal_Reasoning_/2023-12-30-Is_Knowledge_All_Large_Language_Models_Needed_for_Causal_Reasoning_.html#appendix",
    "href": "posts/Is_Knowledge_All_Large_Language_Models_Needed_for_Causal_Reasoning_/2023-12-30-Is_Knowledge_All_Large_Language_Models_Needed_for_Causal_Reasoning_.html#appendix",
    "title": "Is Knowledge All Large Language Models Needed for Causal Reasoning?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00139v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00139v1\n\n\nTruncated\nTrue\n\n\nWord Count\n14300"
  },
  {
    "objectID": "posts/E_chat__Emotion_sensitive_Spoken_Dialogue_System_with_Large_Language_Models/2023-12-31-E_chat__Emotion_sensitive_Spoken_Dialogue_System_with_Large_Language_Models.html#appendix",
    "href": "posts/E_chat__Emotion_sensitive_Spoken_Dialogue_System_with_Large_Language_Models/2023-12-31-E_chat__Emotion_sensitive_Spoken_Dialogue_System_with_Large_Language_Models.html#appendix",
    "title": "E-chat: Emotion-sensitive Spoken Dialogue System with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00475v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00475v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4854"
  },
  {
    "objectID": "posts/Fairness_Certification_for_Natural_Language_Processing_and_Large_Language_Models/2024-01-02-Fairness_Certification_for_Natural_Language_Processing_and_Large_Language_Models.html#appendix",
    "href": "posts/Fairness_Certification_for_Natural_Language_Processing_and_Large_Language_Models/2024-01-02-Fairness_Certification_for_Natural_Language_Processing_and_Large_Language_Models.html#appendix",
    "title": "Fairness Certification for Natural Language Processing and Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01262v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01262v1\n\n\nTruncated\nTrue\n\n\nWord Count\n51134"
  },
  {
    "objectID": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#summary",
    "href": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#summary",
    "title": "Prompting LLMs with content plans to enhance the summarization of scientific articles",
    "section": "Summary",
    "text": "Summary\nThis paper introduces novel prompting techniques to improve the performance of automatic summarization systems for scientific articles, which are often challenging due to their complexity and length. The paper evaluates various prompting techniques and their impact on different summarization models and input texts. The results show performance gains, particularly for smaller models summarizing sections separately. The findings introduce a new research direction of using prompts to aid smaller models in summarizing scientific articles."
  },
  {
    "objectID": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#findings",
    "href": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#findings",
    "title": "Prompting LLMs with content plans to enhance the summarization of scientific articles",
    "section": "Findings",
    "text": "Findings\n\nChallenges of Scientific Article Summarization: Scientific articles pose difficulties for summarization due to their length, technical vocabulary, complex structures, and irregular organizational formats. This makes summarization challenging for even state-of-the-art natural language processing systems.\nEffectiveness of Prompting Techniques: The paper proposes and evaluates five prompting techniques, showing consistent performance improvements from prompting techniques on smaller models, especially when summarizing sections independently. Smaller models exhibit increases in ROUGE-1 score around 0.1-0.4 when aided by prompts. The results suggest that prompting is an effective approach for overcoming the limitations of smaller summarization systems.\nImplications of the Findings: The findings suggest that prompting techniques enhance the focus of summarization models on core concepts, especially for smaller models, indicating the potential of prompts to aid smaller models in resource-constrained contexts like mobile devices."
  },
  {
    "objectID": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#critique",
    "href": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#critique",
    "title": "Prompting LLMs with content plans to enhance the summarization of scientific articles",
    "section": "Critique",
    "text": "Critique\nThe paper provides valuable insights into the effectiveness of prompting techniques for scientific article summarization. However, the study primarily focuses on model performance metrics and lacks a comprehensive analysis of the semantic quality of the summaries generated. Furthermore, the paper could benefit from discussing potential limitations and challenges in the practical implementation of the proposed prompting techniques. This could include addressing how the approach handles ambiguous or polysemous terms and potential biases in the extraction of key terms from scientific articles. Additionally, the paper could further elaborate on future research directions beyond the specific techniques evaluated in the study."
  },
  {
    "objectID": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#appendix",
    "href": "posts/Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles/2023-12-13-Prompting_LLMs_with_content_plans_to_enhance_the_summarization_of_scientific_articles.html#appendix",
    "title": "Prompting LLMs with content plans to enhance the summarization of scientific articles",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.08282v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.08282v2\n\n\nTruncated\nFalse\n\n\nWord Count\n9136"
  },
  {
    "objectID": "posts/DocLLM__A_layout_aware_generative_language_model_for_multimodal_document_understanding/2023-12-31-DocLLM__A_layout_aware_generative_language_model_for_multimodal_document_understanding.html#summary",
    "href": "posts/DocLLM__A_layout_aware_generative_language_model_for_multimodal_document_understanding/2023-12-31-DocLLM__A_layout_aware_generative_language_model_for_multimodal_document_understanding.html#summary",
    "title": "DocLLM: A layout-aware generative language model for multimodal document understanding",
    "section": "Summary",
    "text": "Summary\nThe paper presents DocLLM, a generative language model designed to understand visual documents that contain complex layouts. It incorporates both textual semantics and spatial layout, and it outperforms existing large language models on various document intelligence tasks. DocLLM achieves this without relying on expensive image encoders by focusing exclusively on bounding box information to incorporate the visual spatial layout structure. The model features a disentangled spatial attention mechanism and a pre-training objective tailored to address irregular layouts effectively. The paper concludes by indicating that future work could involve infusing vision into DocLLM in a lightweight manner."
  },
  {
    "objectID": "posts/DocLLM__A_layout_aware_generative_language_model_for_multimodal_document_understanding/2023-12-31-DocLLM__A_layout_aware_generative_language_model_for_multimodal_document_understanding.html#major-takeaways",
    "href": "posts/DocLLM__A_layout_aware_generative_language_model_for_multimodal_document_understanding/2023-12-31-DocLLM__A_layout_aware_generative_language_model_for_multimodal_document_understanding.html#major-takeaways",
    "title": "DocLLM: A layout-aware generative language model for multimodal document understanding",
    "section": "Major Takeaways",
    "text": "Major Takeaways\n\nDocLLM Outperforms Existing Models: The paper demonstrates that DocLLM outperforms state-of-the-art large language models on various document intelligence tasks, showcasing its efficacy in understanding visually rich documents.\nFocus on Spatial Layout: DocLLM’s lightweight extension focuses exclusively on bounding box information to understand the spatial layout of documents, without relying on expensive image encoders.\nDisentangled Spatial Attention and Block Infilling: The model features a disentangled spatial attention mechanism and a pre-training objective tailored to address irregular layouts effectively."
  },
  {
    "objectID": "posts/DocLLM__A_layout_aware_generative_language_model_for_multimodal_document_understanding/2023-12-31-DocLLM__A_layout_aware_generative_language_model_for_multimodal_document_understanding.html#sections",
    "href": "posts/DocLLM__A_layout_aware_generative_language_model_for_multimodal_document_understanding/2023-12-31-DocLLM__A_layout_aware_generative_language_model_for_multimodal_document_understanding.html#sections",
    "title": "DocLLM: A layout-aware generative language model for multimodal document understanding",
    "section": "Sections",
    "text": "Sections\n\nAbstract\nIntroduction: Challenges in understanding visually rich documents and the need for a different approach from conventional large language models.\nDocLLM Framework: Model architecture, disentangled spatial attention, and pre-training objectives are discussed.\nRelated Work: Review of recent advances in large language models and multimodal large language models.\nExperiments: Evaluation of DocLLM in two experimental settings - Same Datasets, Different Splits (SDDS) and Same Tasks, Different Datasets (STDD).\nAblation Studies: Evaluation of the three main components of DocLLM - disentangled spatial attention, block infilling, and masking strategy.\nDiscussion and Findings: Impressions and observations from internal training experiences.\nConclusions: Summary of the contributions and potential future work."
  },
  {
    "objectID": "posts/DocLLM__A_layout_aware_generative_language_model_for_multimodal_document_understanding/2023-12-31-DocLLM__A_layout_aware_generative_language_model_for_multimodal_document_understanding.html#critique",
    "href": "posts/DocLLM__A_layout_aware_generative_language_model_for_multimodal_document_understanding/2023-12-31-DocLLM__A_layout_aware_generative_language_model_for_multimodal_document_understanding.html#critique",
    "title": "DocLLM: A layout-aware generative language model for multimodal document understanding",
    "section": "Critique",
    "text": "Critique\nThe paper provides a comprehensive and detailed exploration of DocLLM, demonstrating its effectiveness in understanding visually rich documents. However, the evaluation of the model in real-world use cases or commercial applications is not explicitly discussed. Additionally, the paper’s results are derived from the model’s performance in specific experimental settings, and a broader evaluation in diverse real-world scenarios is needed to fully validate its applicability. Moreover, while the ablation studies provide insights into the effectiveness of the individual components of DocLLM, a more in-depth analysis of the limitations or potential failure cases of the model would enhance the paper’s completeness."
  },
  {
    "objectID": "posts/DocLLM__A_layout_aware_generative_language_model_for_multimodal_document_understanding/2023-12-31-DocLLM__A_layout_aware_generative_language_model_for_multimodal_document_understanding.html#appendix",
    "href": "posts/DocLLM__A_layout_aware_generative_language_model_for_multimodal_document_understanding/2023-12-31-DocLLM__A_layout_aware_generative_language_model_for_multimodal_document_understanding.html#appendix",
    "title": "DocLLM: A layout-aware generative language model for multimodal document understanding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.00908v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.00908v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13500"
  },
  {
    "objectID": "posts/MOCHa__Multi_Objective_Reinforcement_Mitigating_Caption_Hallucinations/2023-12-06-MOCHa__Multi_Objective_Reinforcement_Mitigating_Caption_Hallucinations.html#appendix",
    "href": "posts/MOCHa__Multi_Objective_Reinforcement_Mitigating_Caption_Hallucinations/2023-12-06-MOCHa__Multi_Objective_Reinforcement_Mitigating_Caption_Hallucinations.html#appendix",
    "title": "MOCHa: Multi-Objective Reinforcement Mitigating Caption Hallucinations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.03631v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.03631v1\n\n\nTruncated\nTrue\n\n\nWord Count\n13650"
  },
  {
    "objectID": "posts/Bypassing_the_Safety_Training_of_Open_Source_LLMs_with_Priming_Attacks/2023-12-19-Bypassing_the_Safety_Training_of_Open_Source_LLMs_with_Priming_Attacks.html#appendix",
    "href": "posts/Bypassing_the_Safety_Training_of_Open_Source_LLMs_with_Priming_Attacks/2023-12-19-Bypassing_the_Safety_Training_of_Open_Source_LLMs_with_Priming_Attacks.html#appendix",
    "title": "Bypassing the Safety Training of Open-Source LLMs with Priming Attacks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.12321v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.12321v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3431"
  },
  {
    "objectID": "posts/LRS__Enhancing_Adversarial_Transferability_through_Lipschitz_Regularized_Surrogate/2023-12-20-LRS__Enhancing_Adversarial_Transferability_through_Lipschitz_Regularized_Surrogate.html#appendix",
    "href": "posts/LRS__Enhancing_Adversarial_Transferability_through_Lipschitz_Regularized_Surrogate/2023-12-20-LRS__Enhancing_Adversarial_Transferability_through_Lipschitz_Regularized_Surrogate.html#appendix",
    "title": "LRS: Enhancing Adversarial Transferability through Lipschitz Regularized Surrogate",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.13118v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.13118v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10577"
  },
  {
    "objectID": "posts/K_PERM__Personalized_Response_Generation_Using_Dynamic_Knowledge_Retrieval_and_Persona_Adaptive_Queries/2023-12-29-K_PERM__Personalized_Response_Generation_Using_Dynamic_Knowledge_Retrieval_and_Persona_Adaptive_Queries.html#appendix",
    "href": "posts/K_PERM__Personalized_Response_Generation_Using_Dynamic_Knowledge_Retrieval_and_Persona_Adaptive_Queries/2023-12-29-K_PERM__Personalized_Response_Generation_Using_Dynamic_Knowledge_Retrieval_and_Persona_Adaptive_Queries.html#appendix",
    "title": "K-PERM: Personalized Response Generation Using Dynamic Knowledge Retrieval and Persona-Adaptive Queries",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.17748v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.17748v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8655"
  },
  {
    "objectID": "posts/The_social_graph_based_on_real_data/2024-01-02-The_social_graph_based_on_real_data.html#appendix",
    "href": "posts/The_social_graph_based_on_real_data/2024-01-02-The_social_graph_based_on_real_data.html#appendix",
    "title": "The social graph based on real data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01152v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01152v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3211"
  },
  {
    "objectID": "posts/Can_ChatGPT_Read_Who_You_Are_/2023-12-26-Can_ChatGPT_Read_Who_You_Are_.html#appendix",
    "href": "posts/Can_ChatGPT_Read_Who_You_Are_/2023-12-26-Can_ChatGPT_Read_Who_You_Are_.html#appendix",
    "title": "Can ChatGPT Read Who You Are?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2312.16070v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2312.16070v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10609"
  },
  {
    "objectID": "posts/Multilingual_Instruction_Tuning_With_Just_a_Pinch_of_Multilinguality/2024-01-03-Multilingual_Instruction_Tuning_With_Just_a_Pinch_of_Multilinguality.html#appendix",
    "href": "posts/Multilingual_Instruction_Tuning_With_Just_a_Pinch_of_Multilinguality/2024-01-03-Multilingual_Instruction_Tuning_With_Just_a_Pinch_of_Multilinguality.html#appendix",
    "title": "Multilingual Instruction Tuning With Just a Pinch of Multilinguality",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\ngpt-3.5-turbo-1106\n\n\nDate Generated\n2024-01-04\n\n\nAbstract\nhttp://arxiv.org/abs/2401.01854v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2401.01854v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8421"
  }
]