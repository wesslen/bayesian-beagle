
---
title: "C2P: Featuring Large Language Models with Causal Reasoning"
id: "2407.18069v1"
description: "C2P framework boosts LLMs' causal reasoning, improving accuracy by over 33% in real-world scenarios with few-shot learning."
author: Abdolmahdi Bagheri, Matin Alinejad, Kevin Bello, Alireza Akhondi-Asl
date: "2024-07-25"
image: "https://browse.arxiv.org/html/2407.18069v1/x1.png"
categories: ['prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2407.18069v1/x1.png)

### Summary:

The paper introduces the Causal Chain of Prompting (C2P) framework, a novel reasoning framework designed to equip current Large Language Models (LLMs) with causal reasoning capabilities. C2P operates autonomously, without relying on external tools or modules during both the causal learning and reasoning phases. The framework can be seamlessly implemented during the training or fine-tuning of LLMs.

Experimental results across various benchmark datasets demonstrate a significant improvement in causal learning and subsequent reasoning accuracy of LLMs. The paper illustrates how C2P enhances LLMs' ability to causally reason in real-world scenarios, addressing complex problems in fields such as healthcare, medicine, economics, education, social sciences, environmental science, and marketing.

With few-shot learning, GPT-4 Turbo using C2P with as few as six examples achieves significant performance improvements, boasting over a 33% increase in reasoning accuracy over the most state-of-the-art LLMs, which perform nearly randomly in similar circumstances. This demonstrates the transformative potential of integrating C2P into LLM training or fine-tuning processes, thereby empowering these models with advanced causal reasoning capabilities.

### Major Findings:

1. The Causal Chain of Prompting (C2P) framework is introduced as the first reasoning framework to equip LLMs with causal reasoning capabilities within real-world scenarios, without relying on external tools.
2. Extensive experiments with the C2P framework demonstrate a significant improvement in LLMs' causal reasoning in various benchmarks and complex, real-world scenarios in various domains.
3. Few-shot learning experiments with GPT-4 Turbo using the C2P framework show that integrating C2P during the training or fine-tuning of LLMs can revolutionize existing models, equipping them with causal reasoning capabilities akin to the transformative impact of 'Chain of Thought' on LLMs.

### Analysis and Critique:

1. The paper presents a promising approach to addressing the causal reasoning bottleneck in LLMs, which has been a significant challenge in the field.
2. The experimental results are compelling, demonstrating significant improvements in causal reasoning accuracy across various benchmark datasets and real-world scenarios.
3

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-30       |
| Abstract | [https://arxiv.org/abs/2407.18069v1](https://arxiv.org/abs/2407.18069v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.18069v1](https://browse.arxiv.org/html/2407.18069v1)       |
| Truncated       | False       |
| Word Count       | 10834       |