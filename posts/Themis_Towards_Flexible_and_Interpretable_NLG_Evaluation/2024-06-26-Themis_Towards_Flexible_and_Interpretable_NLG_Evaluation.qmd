
---
title: "Themis: Towards Flexible and Interpretable NLG Evaluation"
id: "2406.18365v1"
description: "New NLG Evaluation Corpus and Model, Themis, Outperforms GPT-4 in Flexible, Reference-Free Evaluations."
author: Xinyu Hu, Li Lin, Mingqi Gao, Xunjian Yin, Xiaojun Wan
date: "2024-06-26"
image: "https://browse.arxiv.org/html/2406.18365v1/extracted/5693260/image.png"
categories: ['hci', 'social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.18365v1/extracted/5693260/image.png)

### Summary:

The paper introduces Themis, an 8B-parameter LLM specifically designed and trained for NLG evaluation. Themis can evaluate various NLG tasks, including uncommon ones like question-answering evaluation, in a reference-free manner. It allows for specific and customized evaluation aspects and criteria, including overall quality and more fine-grained aspects. Themis also provides corresponding analysis and explanation together with the rating, making it more interpretable.

The authors construct a large-scale NLG evaluation corpus, NLG-Eval, which contains about 0.5 million samples and 58 datasets across 9 NLG tasks, with detailed meta-information, aspect criteria, and evaluations. They propose a multi-perspective consistency verification method to select relatively more reliable data from the constructed NLG-Eval corpus and design specific preference alignment to improve the evaluation capabilities of the fine-tuned model.

Extensive experiments demonstrate the superior evaluation performance of Themis in common NLG tasks, as well as good generalization and robustness. The model and relevant resource are released to facilitate related research.

### Major Findings:

1. Themis, an 8B-parameter LLM, is specifically designed and trained for NLG evaluation, offering versatility, independence, flexibility, and interpretability.
2. A large-scale NLG evaluation corpus, NLG-Eval, is constructed, containing about 0.5 million samples and 58 datasets across 9 NLG tasks, with detailed meta-information, aspect criteria, and evaluations.
3. A multi-perspective consistency verification method is proposed to select relatively more reliable data from the constructed NLG-Eval corpus.
4. Specific preference alignment is designed to improve the evaluation capabilities of the fine-tuned model.
5. Extensive experiments demonstrate the superior evaluation performance of Themis in common NLG tasks, as well as good generalization and robustness.

### Analysis and Critique:

The paper presents a comprehensive approach to NLG evaluation, addressing the limitations of existing methods. The authors construct a large-scale NLG evaluation corpus and propose a specialized LLM, Themis, for NLG evaluation. The model demonstrates superior performance in various NLG tasks and can be generalized well to un

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-07       |
| Abstract | [https://arxiv.org/abs/2406.18365v1](https://arxiv.org/abs/2406.18365v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.18365v1](https://browse.arxiv.org/html/2406.18365v1)       |
| Truncated       | False       |
| Word Count       | 6245       |