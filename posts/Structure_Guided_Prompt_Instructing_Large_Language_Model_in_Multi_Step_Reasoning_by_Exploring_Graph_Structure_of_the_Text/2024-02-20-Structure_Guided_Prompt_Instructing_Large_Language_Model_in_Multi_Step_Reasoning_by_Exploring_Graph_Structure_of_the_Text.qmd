
---
title: "Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text"
id: "2402.13415v1"
description: "LLMs struggle with complex reasoning, but Structure Guided Prompt improves multi-step reasoning capabilities."
author: Kewei Cheng, Nesreen K. Ahmed, Theodore Willke, Yizhou Sun
date: "2024-02-20"
image: "https://browse.arxiv.org/html/2402.13415v1/x1.png"
categories: ['education', 'prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.13415v1/x1.png)

### Major Findings:
1. The Structure Guided Prompt framework significantly improves the reasoning capabilities of Large Language Models (LLMs) across a broader spectrum of natural language scenarios.
2. The proposed framework accurately predicts relationships and identifies entities but struggles with drawing accurate conclusions in some cases.
3. The Structure Guided Prompt model shows proficiency in inferring relationships and identifying entities but makes mistakes during the conclusion-drawing phase.

### Analysis and Critique:
- The examples demonstrate the strengths and limitations of the Structure Guided Prompt in making accurate predictions based on the given information.
- The model shows proficiency in inferring relationships and identifying entities but struggles with drawing accurate conclusions in some cases, highlighting the need for further refinement and improvement in the model's reasoning and inference capabilities.
- The proposed Structure Guided Prompt model's performance in comparison to the 0-CoT model in various tasks demonstrates the accuracy and inaccuracies of the proposed model in predicting correct answers based on the given prompts.
- The inference process of the proposed model is accurate, but it makes mistakes during the conclusion-drawing phase, as observed in the experiments. The section also provides the prompts used for querying the LLMs for all six tasks and the raw numeric results for each task. Overall, the section presents a detailed evaluation of the proposed Structure Guided Prompt model's performance in comparison to the 0-CoT model in various tasks.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.13415v1](https://arxiv.org/abs/2402.13415v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.13415v1](https://browse.arxiv.org/html/2402.13415v1)       |
| Truncated       | True       |
| Word Count       | 16874       |