
---
title: "Discovery of the Hidden World with Large Language Models"
id: "2402.03941v1"
description: "COAT uses large language models to discover causal factors from unstructured data."
author: Chenxi Liu, Yongqiang Chen, Tongliang Liu, Mingming Gong, James Cheng, Bo Han, Kun Zhang
date: "2024-02-06"
image: "../../img/2402.03941v1/image_1.png"
categories: ['production']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.03941v1/image_1.png)

### Summary:
- The paper introduces COAT, a framework that leverages Large Language Models (LLMs) to propose and annotate potential causal factors from unstructured data.
- COAT incorporates LLMs as a factor proposer to extract potential causal factors and instructs LLMs to provide additional information to collect data values and parse raw unstructured data into structured data.
- The annotated data is then fed to a causal learning module to provide explanations of the data and feedback to improve the extraction of causal factors by LLMs.
- The effectiveness of COAT is verified through case studies of review rating analysis and neuropathic diagnosis.

### Major Findings:
1. COAT effectively leverages LLMs to propose and annotate potential causal factors from unstructured data.
2. The framework demonstrates significant improvements in factor proposal and causal relation recovery compared to direct reasoning with LLMs.
3. COAT addresses the limitations of LLMs in identifying faithfulness issues and recovering causal graphs, contributing to the advancement of causal representation learning and causal discovery approaches.

### Analysis and Critique:
- The integration of LLMs and causal discovery algorithms in COAT opens up new possibilities for extending traditional causal discovery algorithms to a broader scope of applications.
- The results highlight the effectiveness of COAT in uncovering causal relationships and addressing faithfulness issues in the data, with the potential to enhance causal discovery in complex real-world scenarios.
- The section emphasizes the potential of COAT to address the limitations of LLMs in identifying faithfulness issues and recovering causal graphs, contributing to the advancement of causal representation learning and causal discovery approaches.
- The section also highlights the ongoing debate regarding the reliability and utility of LLMs in causal learning, which is crucial for understanding the broader context of the paper.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-07       |
| Abstract | [https://arxiv.org/abs/2402.03941v1](https://arxiv.org/abs/2402.03941v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.03941v1](https://browse.arxiv.org/html/2402.03941v1)       |
| Truncated       | True       |
| Word Count       | 17111       |