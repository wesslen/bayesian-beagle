
---
title: "Assessing Language Models' Worldview for Fiction Generation"
id: "2408.07904v1"
description: "LLMs struggle to maintain consistent worldview for fiction writing, often producing uniform narratives, highlighting their limitations in this area."
author: Aisha Khatun, Daniel G. Brown
date: "2024-08-15"
image: "../../../bayesian-beagle.png"
categories: ['programming', 'hci']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### Summary:

The study investigates the ability of Large Language Models (LLMs) to maintain a consistent worldview, which is essential for generating fiction. Through a series of questions to nine LLMs, the authors find that only two models exhibit consistent worldview, while the rest are self-conflicting. Subsequent analysis of stories generated by four models revealed a strikingly uniform narrative pattern. This uniformity across models further suggests a lack of 'state' necessary for fiction. The study highlights the limitations of current LLMs in fiction writing and advocates for future research to test and create story worlds for LLMs to reside in.

### Major Findings:

1. Only two out of nine LLMs exhibit consistent worldview, while the rest are self-conflicting.
2. Subsequent analysis of stories generated by four models revealed a strikingly uniform narrative pattern.
3. The uniformity across models further suggests a lack of 'state' necessary for fiction.

### Analysis and Critique:

The study provides valuable insights into the limitations of current LLMs in generating fiction. However, the small sample size of nine LLMs may not be representative of all LLMs. Additionally, the study does not explore the potential of fine-tuning or prompt engineering to improve the performance of LLMs in generating fiction. The study also does not consider the potential impact of different training data on the ability of LLMs to maintain a consistent worldview. Future research should address these limitations to provide a more comprehensive understanding of the capabilities and limitations of LLMs in generating fiction.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-20       |
| Abstract | [https://arxiv.org/abs/2408.07904v1](https://arxiv.org/abs/2408.07904v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.07904v1](https://browse.arxiv.org/html/2408.07904v1)       |
| Truncated       | False       |
| Word Count       | 9708       |