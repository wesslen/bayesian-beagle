
---
title: "Identifying Performance-Sensitive Configurations in Software Systems through Code Analysis with LLM Agents"
id: "2406.12806v1"
description: "PerfSense, an LLM-based framework, accurately identifies performance-sensitive configurations, outperforming previous methods and offering insights for future research."
author: Zehao Wang, Dong Jae Kim, Tse-Hsun Chen
date: "2024-06-18"
image: "https://browse.arxiv.org/html/2406.12806v1/x1.png"
categories: ['robustness', 'education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.12806v1/x1.png)

### Summary:

The paper presents PerfSense, a lightweight framework that leverages Large Language Models (LLMs) to efficiently identify performance-sensitive configurations in software systems. The framework employs LLM agents to simulate interactions between developers and performance engineers using advanced prompting techniques such as prompt chaining and retrieval-augmented generation (RAG). The evaluation of seven open-source Java systems demonstrates that PerfSense achieves an average accuracy of 64.77% in classifying performance-sensitive configurations, outperforming both the LLM baseline (50.36%) and the previous state-of-the-art method (61.75%). The prompt chaining technique improves recall by 10% to 30% while maintaining similar precision levels. A manual analysis of 362 misclassifications reveals common issues, including LLMs’ misunderstandings of requirements (26.8%).

### Major Findings:

1. PerfSense achieves an average accuracy of 64.77% in classifying performance-sensitive configurations, outperforming both the LLM baseline (50.36%) and the previous state-of-the-art method (61.75%).
2. The prompt chaining technique improves recall by 10% to 30% while maintaining similar precision levels.
3. A manual analysis of 362 misclassifications reveals common issues, including LLMs’ misunderstandings of requirements (26.8%).

### Analysis and Critique:

The paper presents a novel approach to identifying performance-sensitive configurations using LLMs. The results are promising, with PerfSense outperforming both the LLM baseline and the previous state-of-the-art method. However, the paper does not discuss the limitations of the approach, such as the potential for LLMs to misunderstand requirements or the need for manual analysis of misclassifications. Additionally, the paper does not discuss the potential for bias in the LLMs or the impact of the size of the LLMs on the results. Further research is needed to address these limitations and to evaluate the approach on a larger and more diverse set of software systems.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-23       |
| Abstract | [https://arxiv.org/abs/2406.12806v1](https://arxiv.org/abs/2406.12806v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.12806v1](https://browse.arxiv.org/html/2406.12806v1)       |
| Truncated       | False       |
| Word Count       | 9569       |