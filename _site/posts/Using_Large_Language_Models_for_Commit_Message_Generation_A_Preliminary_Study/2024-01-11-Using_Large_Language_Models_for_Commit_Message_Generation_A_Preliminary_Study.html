<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Linghao Zhang">
<meta name="author" content="Jingshu Zhao">
<meta name="author" content="Chong Wang">
<meta name="author" content="Peng Liang">
<meta name="dcterms.date" content="2024-01-11">
<meta name="description" content="Study evaluates using large language models like Llama 2 and ChatGPT to generate Git commit messages. Results show promising potential.">

<title>Bayesian beagle - Using Large Language Models for Commit Message Generation: A Preliminary Study</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Bayesian beagle - Using Large Language Models for Commit Message Generation: A Preliminary Study">
<meta property="og:description" content="Study evaluates using large language models like Llama 2 and ChatGPT to generate Git commit messages. Results show promising potential.">
<meta property="og:image" content="https://browse.arxiv.org/html/2401.05926v1/x1.png">
<meta property="og:site-name" content="Bayesian beagle">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../icon.jpg" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Bayesian beagle</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">Bayesian beagle</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/wesslen/bayesian-beagle" rel="" target=""><i class="bi bi-github" role="img" aria-label="github">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Using Large Language Models for Commit Message Generation: A Preliminary Study</h1>
  <div class="quarto-categories">
    <div class="quarto-category">production</div>
    <div class="quarto-category">architectures</div>
    <div class="quarto-category">robustness</div>
    <div class="quarto-category">programming</div>
  </div>
  </div>

<div>
  <div class="description">
    Study evaluates using large language models like Llama 2 and ChatGPT to generate Git commit messages. Results show promising potential.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Authors</div>
    <div class="quarto-title-meta-contents">
             <p>Linghao Zhang </p>
             <p>Jingshu Zhao </p>
             <p>Chong Wang </p>
             <p>Peng Liang </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 11, 2024</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p><img src="https://browse.arxiv.org/html/2401.05926v1/x1.png" class="img-fluid"></p>
<section id="major-findings" class="level3">
<h3 class="anchored" data-anchor-id="major-findings">Major Findings</h3>
<ol type="1">
<li><strong>Large language models (LLMs)</strong>, such as Llama 2 and ChatGPT, outperformed existing methods in <strong>human evaluations</strong> for commit message generation in 78% of the 366 samples.</li>
<li>LLMs demonstrated comparable performance to previous techniques on <strong>BLEU and Rouge-L metrics</strong> but showed a distinct advantage over all existing methods in <strong>human evaluation</strong>.</li>
<li>The study highlighted the limitations of existing metrics, <strong>BLEU and Rouge-L</strong>, in evaluating the quality of automatically generated commit messages, raising the need for more robust evaluation metrics.</li>
</ol>
</section>
<section id="i-introduction" class="level3">
<h3 class="anchored" data-anchor-id="i-introduction">I Introduction</h3>
<ul>
<li>Commit messages are crucial in the Git version control system, but manually writing them is time-consuming, leading to the need for automatic generation methods.</li>
<li>Large Language Models (LLMs) have shown promise in various domains, but their application in <strong>commit message generation</strong> has been underexplored.</li>
</ul>
</section>
<section id="ii-related-work" class="level3">
<h3 class="anchored" data-anchor-id="ii-related-work">II Related Work</h3>
<ul>
<li>Previous studies have proposed <strong>generation-based and retrieval-based methods</strong> for commit message generation, but this work introduces the novel application of LLMs to this task.</li>
<li>Existing methods provide baselines for <strong>evaluation and comparative analysis</strong> of LLMs.</li>
</ul>
</section>
<section id="iii-research-design" class="level3">
<h3 class="anchored" data-anchor-id="iii-research-design">III Research Design</h3>
<ul>
<li>The research question focuses on exploring the feasibility and effectiveness of LLMs in <strong>commit message generation</strong>. The study uses a <strong>two-phase evaluation</strong> to assess the quality of generated commit messages.</li>
</ul>
</section>
<section id="iii-a-overview-of-our-approach" class="level3">
<h3 class="anchored" data-anchor-id="iii-a-overview-of-our-approach">III-A Overview of Our Approach</h3>
<ul>
<li>The study leverages two LLMs, ChatGPT and Llama 2, to generate commit messages and implements a <strong>two-phase evaluation</strong> process.</li>
<li>The dataset used for the study is publicly available and contains pairs of code diffs and their corresponding commit messages.</li>
</ul>
</section>
<section id="iii-b-selection-and-settings-of-llms" class="level3">
<h3 class="anchored" data-anchor-id="iii-b-selection-and-settings-of-llms">III-B Selection and Settings of LLMs</h3>
<ul>
<li>Two representative LLMs, ChatGPT and Llama 2, are selected for the study based on their generality and zero-shot prompting capabilities.</li>
</ul>
</section>
<section id="iii-c-metrics-and-baselines-used-in-evaluation-phase-i" class="level3">
<h3 class="anchored" data-anchor-id="iii-c-metrics-and-baselines-used-in-evaluation-phase-i">III-C Metrics and Baselines used in Evaluation: Phase I</h3>
<ul>
<li>Evaluation metrics including <strong>BLEU and Rouge-L</strong> are employed to compare the quality of commit messages generated by LLMs with existing baseline models.</li>
</ul>
</section>
<section id="iii-f-human-evaluation-phase-ii" class="level3">
<h3 class="anchored" data-anchor-id="iii-f-human-evaluation-phase-ii">III-F Human Evaluation: Phase II</h3>
<ul>
<li>A <strong>human evaluation</strong> is conducted to assess which method of commit message generation best fits the code differences, with LLMs outperforming other methods in human preference.</li>
</ul>
</section>
<section id="iv-results-discussion" class="level3">
<h3 class="anchored" data-anchor-id="iv-results-discussion">IV Results &amp; Discussion</h3>
<ul>
<li>LLMs achieve decent scores compared to baseline models on the <strong>metrics evaluation</strong> and are preferred by humans in the <strong>human evaluation</strong>.</li>
<li>The study uncovers quality issues in <strong>human-written commit messages</strong>, highlighting the need for more robust evaluation metrics aligning with human judgment.</li>
</ul>
</section>
<section id="v-limitations" class="level3">
<h3 class="anchored" data-anchor-id="v-limitations">V Limitations</h3>
<ul>
<li>The study points out limitations such as the closed-source nature of ChatGPT, the preliminary nature of the evaluation, and potential subjective biases in human evaluation.</li>
</ul>
</section>
<section id="vi-conclusions-future-work" class="level3">
<h3 class="anchored" data-anchor-id="vi-conclusions-future-work">VI Conclusions &amp; Future Work</h3>
<ul>
<li>The study demonstrates the potential of LLMs for <strong>commit message generation</strong> and calls for the development of <strong>robust evaluation metrics</strong> aligning with human judgment.</li>
<li>Future work aims to explore more prompt strategies to improve LLM performance and develop <strong>LLM-integrated commit message generation methods</strong>.</li>
</ul>
</section>
<section id="critique" class="level3">
<h3 class="anchored" data-anchor-id="critique">Critique</h3>
<p>The study provides valuable insights into the use of LLMs for commit message generation and highlights important limitations of existing evaluation metrics. However, there are potential issues with the closed-source nature of ChatGPT, and the relatively small sample size in the human evaluation could introduce bias. Additionally, further research is needed to address the observed limitations and expand the scope of evaluation metrics.</p>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>gpt-3.5-turbo-1106</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-02-02</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="http://arxiv.org/abs/2401.05926v1">http://arxiv.org/abs/2401.05926v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2401.05926v1">https://browse.arxiv.org/html/2401.05926v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>False</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>5302</td>
</tr>
</tbody>
</table>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="wesslen/bayesian-beagle" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/wesslen/bayesian-beagle/edit/main/posts/Using_Large_Language_Models_for_Commit_Message_Generation_A_Preliminary_Study/2024-01-11-Using_Large_Language_Models_for_Commit_Message_Generation_A_Preliminary_Study.qmd" class="toc-action">Edit this page</a></p></div></div></div></div></footer></body></html>