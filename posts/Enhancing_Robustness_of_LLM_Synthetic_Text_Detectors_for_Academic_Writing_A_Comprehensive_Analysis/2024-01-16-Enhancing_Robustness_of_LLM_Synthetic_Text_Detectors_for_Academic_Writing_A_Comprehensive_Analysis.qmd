
---
title: "Enhancing Robustness of LLM-Synthetic Text Detectors for Academic Writing: A Comprehensive Analysis"
id: "2401.08046v1"
description: "TL;DR: Large language models have pros and cons, but Synthetic-Siamese detector improves reliability in academic writing."
author: Zhicheng Dou, Yuchen Guo, Ching-Chun Chang, Huy H. Nguyen, Isao Echizen
date: "2024-01-16"
image: "../../../bayesian-beagle.png"
categories: ['social-sciences', 'robustness', 'hci', 'prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](None)

### **Summary:**
The article discusses the impact of large language models (LLMs) on academic writing and the development of detectors to address potential misuse of LLMs. The authors propose a reference-based Siamese detector named Synthetic-Siamese to address the lack of robustness in existing detectors and significantly improve performance in realistic academic writing scenarios.

### **Major Findings:**
1. The authors highlight the potential lack of robustness in existing state-of-the-art GPT detectors, which prioritize achieving higher accuracy on restricted datasets, neglecting the crucial aspect of generalizability.
2. Synthetic-Siamese, the proposed detector, effectively addresses the issue of insufficient robustness and significantly improves baseline performances in realistic academic writing scenarios by approximately 67% to 95%.
3. The study demonstrates that prompt adjustments alone can significantly affect the robustness of the detector, particularly in the context of academic cheating.

### **Analysis and Critique:**
The article provides a comprehensive analysis of the impact of prompts on text generated by LLMs and highlights the potential lack of robustness in existing detectors. However, the study is limited to specific LLMs and prompts, and the generalizability of the proposed Synthetic-Siamese detector to other LLMs needs further investigation. Additionally, the study does not address potential ethical concerns related to the use of detectors for academic writing. Further research is needed to explore the broader implications and ethical considerations of using detectors to address academic cheating facilitated by LLMs.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-31       |
| Abstract | [https://arxiv.org/abs/2401.08046v1](https://arxiv.org/abs/2401.08046v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.08046v1](https://browse.arxiv.org/html/2401.08046v1)       |
| Truncated       | False       |
| Word Count       | 7549       |