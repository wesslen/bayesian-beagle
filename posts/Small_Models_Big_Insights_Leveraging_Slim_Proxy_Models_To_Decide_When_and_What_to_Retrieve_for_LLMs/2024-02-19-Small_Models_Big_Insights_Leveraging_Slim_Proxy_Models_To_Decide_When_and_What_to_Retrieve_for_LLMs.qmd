
---
title: "Small Models, Big Insights: Leveraging Slim Proxy Models To Decide When and What to Retrieve for LLMs"
id: "2402.12052v1"
description: "SlimPLM enhances large language models' knowledge acquisition, improving question-answering performance with lower computational costs."
author: Jiejun Tan, Zhicheng Dou, Yutao Zhu, Peidong Guo, Kun Fang, Ji-Rong Wen
date: "2024-02-19"
image: "https://browse.arxiv.org/html/2402.12052v1/x1.png"
categories: ['education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.12052v1/x1.png)

### Summary:
The article introduces a novel approach, SlimPLM, which uses a slim proxy model to detect missing knowledge in large language models (LLMs) and enhance the knowledge acquisition process. The method employs a proxy model with far fewer parameters to generate heuristic answers, which are then used to predict the knowledge required to answer user questions and determine known and unknown knowledge within the LLM. Experimental results demonstrate a notable improvement in the end-to-end performance of LLMs in question-answering tasks, achieving or surpassing current state-of-the-art models with lower LLM inference costs.

### Major Findings:
1. SlimPLM utilizes a slim proxy model to detect missing knowledge in LLMs and enhance the knowledge acquisition process.
2. The method significantly improves the end-to-end performance of LLMs in question-answering tasks, achieving or surpassing current state-of-the-art models with lower LLM inference costs.
3. Experimental results on five datasets demonstrate the effectiveness of SlimPLM in determining the necessity for retrieval and improving retrieval results.

### Analysis and Critique:
- The article provides a comprehensive and effective approach to enhancing the performance of LLMs in question-answering tasks.
- The method significantly reduces the computational costs of LLM inference while improving the accuracy and relevance of retrieved information.
- The article acknowledges limitations in scenarios where the method may not be suitable and the gap in knowledge capabilities between proxy models and LLMs.
- The experimental results and analysis provide a strong theoretical basis for the proposed method and demonstrate its practical effectiveness.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.12052v1](https://arxiv.org/abs/2402.12052v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.12052v1](https://browse.arxiv.org/html/2402.12052v1)       |
| Truncated       | False       |
| Word Count       | 7194       |