
---
title: "ScholarChemQA: Unveiling the Power of Language Models in Chemical Research Question Answering"
id: "2407.16931v1"
description: "ScholarChemQA: New Chemistry QA Dataset & QAMatch Model for Improved Performance"
author: Xiuying Chen, Tairan Wang, Taicheng Guo, Kehan Guo, Juexiao Zhou, Haoyang Li, Mingchen Zhuge, JÃ¼rgen Schmidhuber, Xin Gao, Xiangliang Zhang
date: "2024-07-24"
image: "https://browse.arxiv.org/html/2407.16931v1/x1.png"
categories: ['education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2407.16931v1/x1.png)

### Summary:

The paper introduces ScholarChemQA, a large-scale QA dataset constructed from chemical papers, with questions sourced from paper titles with a question mark and multi-choice answers reasoned out based on the corresponding abstracts. The dataset reflects real-world challenges, including an imbalanced data distribution and a substantial amount of unlabeled data. The paper also presents the QAMatch model, specifically designed to effectively answer chemical questions by fully leveraging the collected data. The model addresses the issue of imbalanced label distribution by re-weighting the instance-wise loss based on the inverse frequency of each class and utilizes the unlabeled data to enrich the learning process. Experiments show that the QAMatch model significantly outperforms recent similar-scale baselines and LLMs on the ScholarChemQA dataset and four benchmark datasets.

### Major Findings:
1. The paper introduces ScholarChemQA, a large-scale QA dataset constructed from chemical papers, with up to 40k instances and 1,050 answer labels for training, validation, and testing.
2. The QAMatch model is presented, specifically designed to effectively answer chemical questions by fully leveraging the collected data and addressing the issue of imbalanced label distribution.
3. Experiments show that the QAMatch model significantly outperforms recent similar-scale baselines and LLMs on the ScholarChemQA dataset and four benchmark datasets.

### Analysis and Critique:

The paper presents a valuable contribution to the field of chemical question answering by introducing a large-scale QA dataset and a model specifically designed to address the challenges of imbalanced data distribution and unlabeled data. The QAMatch model's performance in outperforming recent similar-scale baselines and LLMs is a significant achievement. However, the paper does not discuss any potential limitations or shortcomings of the dataset or the model. It would be beneficial to include an analysis of the model's performance on different types of chemical questions and its generalizability to other domains. Additionally, the paper could discuss any potential biases in the dataset and how they might impact the model's performance.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-30       |
| Abstract | [https://arxiv.org/abs/2407.16931v1](https://arxiv.org/abs/2407.16931v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.16931v1](https://browse.arxiv.org/html/2407.16931v1)       |
| Truncated       | False       |
| Word Count       | 10882       |