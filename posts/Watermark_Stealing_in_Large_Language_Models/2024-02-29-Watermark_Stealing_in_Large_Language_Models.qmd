
---
title: "Watermark Stealing in Large Language Models"
id: "2402.19361v1"
description: "New study reveals LLM watermarking vulnerability: Under $50, attackers can spoof and scrub state-of-the-art schemes with 80% success rate."
author: Nikola JovanoviÄ‡, Robin Staab, Martin Vechev
date: "2024-02-29"
image: "../../../bayesian-beagle.png"
categories: ['robustness', 'security']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### **Summary:**

- Watermark stealing (WS) is identified as a fundamental vulnerability in large language model (LLM) watermarking schemes.
- WS enables spoofing and scrubbing attacks, which were previously unnoticed or less effective.
- An automated WS algorithm is proposed and used in the first comprehensive study of spoofing and scrubbing in realistic settings.
- For under $50, an attacker can both spoof and scrub state-of-the-art schemes with an average success rate of over 80%.

### Major Findings:

1. Watermark stealing (WS) is a fundamental vulnerability in LLM watermarking schemes, enabling practical spoofing and scrubbing attacks.
2. The first automated WS algorithm is proposed, demonstrating that for under $50, an attacker can successfully spoof and scrub state-of-the-art watermarking schemes with an average success rate of over 80%.
3. The findings challenge common beliefs about LLM watermarking, highlighting the need for more robust schemes.

### Analysis and Critique:

- The study focuses on watermarking schemes for LLMs, which may not generalize to other types of models or watermarking methods.
- The effectiveness of the proposed WS algorithm depends on the availability and quality of the API and the auxiliary model.
- The paper assumes a specific pricing model for the API, which may not reflect the actual costs of using LLMs in different scenarios.
- The paper could benefit from a more detailed discussion of the ethical implications of watermarking and WS, especially in the context of AI-generated content.
- Further research is needed to evaluate the robustness of LLM watermarking schemes against other types of attacks and to develop more robust watermarking methods.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x7b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.19361v1](https://arxiv.org/abs/2402.19361v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.19361v1](https://browse.arxiv.org/html/2402.19361v1)       |
| Truncated       | False       |
| Word Count       | 21936       |