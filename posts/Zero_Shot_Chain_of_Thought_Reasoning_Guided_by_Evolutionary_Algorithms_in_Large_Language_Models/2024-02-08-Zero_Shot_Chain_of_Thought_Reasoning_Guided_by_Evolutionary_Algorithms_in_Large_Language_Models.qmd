
---
title: "Zero-Shot Chain-of-Thought Reasoning Guided by Evolutionary Algorithms in Large Language Models"
id: "2402.05376v1"
description: "Novel zero-shot CoT prompting method improves LLM performance across reasoning tasks. Code available."
author: Feihu Jin, Yifan Liu, Ying Tan
date: "2024-02-08"
image: "https://browse.arxiv.org/html/2402.05376v1/x1.png"
categories: ['prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.05376v1/x1.png)

### Summary:
- Large Language Models (LLMs) have demonstrated impressive reasoning abilities by applying zero-shot Chain-of-Thought (CoT) prompting.
- Existing zero-shot CoT prompting methods may not be optimal due to the evolving nature of sentence prefixes during the pre-training phase.
- The paper introduces a novel zero-shot prompting method that leverages evolutionary algorithms to generate diverse promptings for LLMs dynamically.
- Extensive experiments demonstrate the superior performance of the proposed method compared to current zero-shot CoT prompting methods on GPT-3.5-turbo and GPT-4.

### Major Findings:
1. The paper introduces a novel zero-shot prompting method that leverages evolutionary algorithms to generate diverse promptings for LLMs dynamically.
2. Extensive experiments demonstrate the superior performance of the proposed method compared to current zero-shot CoT prompting methods on GPT-3.5-turbo and GPT-4.
3. The proposed method outperforms existing zero-shot CoT prompting and PS+ prompting methods across all reasoning datasets.

### Analysis and Critique:
- The paper does not evaluate the proposed method under the few-shot setting due to substantial costs associated with API usage.
- The method's effectiveness is validated across various reasoning datasets, showcasing its potential to enhance LLMs' reasoning capabilities.
- The paper leaves room for further exploration of refining the application of evolutionary algorithms based on LLMs to enhance model reasoning capabilities.

### Related Work:
- The paper discusses related work on LLMs and prompting, LLMs and optimization algorithms, and Chain-of-Thought prompting.

### Additional Experiments and Analysis:
- The paper presents additional experiments and analyses on the results of EoT prompting in GPT-4, ablation study of EoT, results of prompting with self-consistency, effect of population size, and effect of initialization prompts.

### Conclusion:
- The paper concludes by highlighting the potential for refining the application of evolutionary algorithms based on LLMs to enhance model reasoning capabilities and leaves room for further exploration in the future.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-09       |
| Abstract | [https://arxiv.org/abs/2402.05376v1](https://arxiv.org/abs/2402.05376v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.05376v1](https://browse.arxiv.org/html/2402.05376v1)       |
| Truncated       | False       |
| Word Count       | 5835       |