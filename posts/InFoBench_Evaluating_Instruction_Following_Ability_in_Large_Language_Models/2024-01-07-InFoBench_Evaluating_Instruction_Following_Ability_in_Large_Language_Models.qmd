
---
title: "InFoBench: Evaluating Instruction Following Ability in Large Language Models"
id: "2401.03601v1"
description: "TL;DR: Introduces DRFR metric for evaluating Language Models' instruction-following, presents InFoBench benchmark, and evaluates LLMs' performance."
author: ['Yiwei Qin', 'Kaiqiang Song', 'Yebowen Hu', 'Wenlin Yao', 'Sangwoo Cho', 'Xiaoyang Wang', 'Xuansheng Wu', 'Fei Liu', 'Pengfei Liu', 'Dong Yu']
date: "2024-01-07"
image: "https://browse.arxiv.org/html/2401.03601v1/x1.png"
categories: ['architectures', 'education', 'prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.03601v1/x1.png)

## Summary

### Findings
1. The paper introduces a new metric, the **Decomposed Requirements Following Ratio (DRFR)**, for evaluating Large Language Models’ (LLMs) ability to follow instructions.
2. The study compares DRFR with traditional scoring methods and explores annotation sources, finding DRFR to have higher reliability and GPT-4 to be a cost-effective annotator.
3. The evaluation of several advanced LLMs using this framework reveals their strengths and areas needing improvement, particularly in complex instruction-following.

### Introduction
The paper addresses the lack of evaluation methodologies dedicated to the crucial aspect of instruction-following in Large Language Models (LLMs) and aims to establish a reliable protocol and benchmark for appraising the instruction-following aptitude of LLMs.

### InFoBench
- Introduces **DRFR** and **InFoBench**, a benchmark dataset, for assessing LLMs’ proficiency in adhering to complex instructions in a detailed and structured manner.
- DRFR decomposes each instruction into distinct, simpler criteria, allowing a granular analysis of a model’s performance.
- InFoBench dataset presents diverse instructions and decomposed questions across different constraint categories.

### Experiments
1. Compared DRFR with traditional Direct Scoring (DS), results showed higher annotator consensus with DRFR, indicating its enhanced reliability.
2. Explored cost-efficient annotation sources, finding GPT-4 to be highly accurate, cost-effective, and time-efficient.
3. Employed GPT-4 as an annotator and evaluated advanced LLMs, revealing the need for improvement in handling complex instructions.

## Critique
The paper presents significant contributions to the evaluation of LLMs' instruction-following abilities. However, it has limitations:
1. The reliance on human annotation for only a fraction of the instruction set limits the reliability of comparisons among different annotations.
2. The dataset size is limited, and the manual nature of instruction writing restricts scalability.
3. The evaluation primarily focuses on the explicit intentions contained within the provided instructions, neglecting crucial factors such as truthfulness and harmlessness.

Overall, while the paper's contributions pave the way for future research and development in LLM evaluation, the limitations in dataset size and human annotation demonstrate areas for potential improvement.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [http://arxiv.org/abs/2401.03601v1](http://arxiv.org/abs/2401.03601v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.03601v1](https://browse.arxiv.org/html/2401.03601v1)       |
| Truncated       | False       |
| Word Count       | 13442       |