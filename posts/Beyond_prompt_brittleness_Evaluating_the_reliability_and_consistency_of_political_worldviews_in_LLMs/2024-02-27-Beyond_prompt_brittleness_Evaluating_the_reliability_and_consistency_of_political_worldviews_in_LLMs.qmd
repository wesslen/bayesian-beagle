
---
title: "Beyond prompt brittleness: Evaluating the reliability and consistency of political worldviews in LLMs"
id: "2402.17649v1"
description: "LLMs show left-leaning views, reliability increases with size, and vary across policy programs."
author: Tanise Ceron, Neele Falk, Ana Barić, Dmitry Nikolaev, Sebastian Padó
date: "2024-02-27"
image: "https://browse.arxiv.org/html/2402.17649v1/x1.png"
categories: ['production', 'hci', 'social-sciences', 'architectures']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.17649v1/x1.png)

### Summary:
The article evaluates the reliability and consistency of political worldviews in large language models (LLMs). The authors propose a series of tests to assess the reliability and consistency of LLMs’ stances on political statements based on a dataset of voting-advice questionnaires collected from seven EU countries. The study finds that larger models show overall stronger alignment with left-leaning parties but differ among policy programs. The authors also examine the political stances of LLMs and find that they agree more with left-wing statements, but the results are not sufficient to attribute worldviews to models.

### Major Findings:
1. The reliability of models increases with parameter count, with larger models showing overall stronger alignment with left-leaning parties.
2. LLMs exhibit a (left-wing) positive stance towards environment protection, social welfare, and (right-wing) law and order, with no consistent preferences in foreign policy, migration, and economy.
3. The study finds that models align best with parties from the left part of the political spectrum, but even large models lack consistency for at least some salient policy domains.

### Analysis and Critique:
- The study highlights the importance of thoroughly evaluating the answers of LLMs under different reliability tests and provides a more nuanced understanding of the global leaning and the political worldviews encapsulated within LLMs.
- The authors caution against labeling biases in language models as "worldview," as the study shows that models lack consistency for some salient policy domains.
- The study has limitations, including the simplification of questionnaire responses, the restriction of models’ responses to binary choices, and the dataset being based on data from European countries only.
- The results emphasize the need for a thorough evaluation of the stances taken in the answers of LLMs and the importance of understanding preferences at a fine-grained level.

Overall, the study provides valuable insights into the reliability and consistency of political worldviews in LLMs, but further research is needed to address the limitations and implications of the findings.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-28       |
| Abstract | [https://arxiv.org/abs/2402.17649v1](https://arxiv.org/abs/2402.17649v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.17649v1](https://browse.arxiv.org/html/2402.17649v1)       |
| Truncated       | False       |
| Word Count       | 8734       |