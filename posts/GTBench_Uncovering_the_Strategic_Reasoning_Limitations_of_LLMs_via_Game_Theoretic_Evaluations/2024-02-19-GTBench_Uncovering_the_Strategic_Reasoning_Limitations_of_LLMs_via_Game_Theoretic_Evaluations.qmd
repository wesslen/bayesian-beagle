
---
title: "GTBench: Uncovering the Strategic Reasoning Limitations of LLMs via Game-Theoretic Evaluations"
id: "2402.12348v1"
description: "LLMs' reasoning in game tasks varies; open-source LLMs less competitive than commercial ones."
author: Jinhao Duan, Renming Zhang, James Diffenderfer, Bhavya Kailkhura, Lichao Sun, Elias Stengel-Eskin, Mohit Bansal, Tianlong Chen, Kaidi Xu
date: "2024-02-19"
image: "https://browse.arxiv.org/html/2402.12348v1/x2.png"
categories: ['production', 'prompt-engineering', 'architectures', 'programming']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.12348v1/x2.png)

### Summary:
This academic article evaluates the reasoning abilities of Large Language Models (LLMs) in competitive environments through game-theoretic tasks. The authors propose GTBench, a language-driven environment composed of 10 widely-recognized tasks across a comprehensive game taxonomy. The study investigates LLMs' game-theoretic reasoning and characterizes their distinct behaviors in various gaming scenarios. The findings reveal that LLMs have different levels of competitiveness in different gaming scenarios, and code-pretraining greatly benefits strategic reasoning. However, advanced reasoning methods do not always help, and open-source LLMs are less competitive than commercial LLMs in complex games.

### Major Findings:
1. LLMs have distinct behaviors regarding various gaming scenarios, failing in complete and deterministic games but being competitive in probabilistic gaming scenarios.
2. Open-source LLMs are less competitive than commercial LLMs in complex games with large action/state space.
3. Code-pretraining benefits game-theoretic reasoning, while advanced reasoning methods such as Chain-of-Thought (CoT) and Tree-of-Thought (ToT) do not always help.

### Analysis and Critique:
- The study provides valuable insights into the reasoning abilities of LLMs in game-theoretic scenarios, shedding light on their strengths and limitations.
- The article effectively communicates the essential information from the academic article, providing a comprehensive overview of the study's findings and implications.
- The study could benefit from a more detailed discussion of potential biases and limitations in the evaluation of LLMs' reasoning abilities.
- The article could also provide more context on the broader implications of the findings for the field of natural language processing and artificial intelligence.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-20       |
| Abstract | [https://arxiv.org/abs/2402.12348v1](https://arxiv.org/abs/2402.12348v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.12348v1](https://browse.arxiv.org/html/2402.12348v1)       |
| Truncated       | False       |
| Word Count       | 13629       |