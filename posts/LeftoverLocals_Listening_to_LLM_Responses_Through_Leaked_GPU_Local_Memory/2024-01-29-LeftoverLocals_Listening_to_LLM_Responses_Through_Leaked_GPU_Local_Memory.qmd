
---
title: "LeftoverLocals: Listening to LLM Responses Through Leaked GPU Local Memory"
id: "2401.16603v1"
description: "LeftoverLocals vulnerability allows data recovery from GPU memory, impacting security of GPU applications."
author: Tyler Sorensen, Heidy Khlaaf
date: "2024-01-29"
image: "https://browse.arxiv.org/html/2401.16603v1/extracted/5376362/pics/screenshot.png"
categories: ['security', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.16603v1/extracted/5376362/pics/screenshot.png)

### Summary:
This paper describes the vulnerability LeftoverLocals, which allows data recovery from GPU memory created by another process on Apple, Qualcomm, and AMD GPUs. The vulnerability impacts the security posture of GPU applications, particularly LLMs and ML models that run on affected GPUs. The vulnerability allows an attacker to listen into another user's interactive LLM session across process or container boundaries.

### Major Findings:
1. **Data Recovery Vulnerability**: LeftoverLocals can leak approximately 5.5 MB per GPU invocation on an AMD Radeon RX 7900 XT, allowing an attacker to reconstruct LLM responses with high precision.
2. **Impacted Vendors**: Apple, AMD, and Qualcomm have been confirmed to be impacted by LeftoverLocals, with varying levels of response and mitigation plans.
3. **Exploitation Requirements**: The vulnerability is a co-resident exploit, meaning that a threat actor's avenue of attack could be implemented as another application, app, or user on a shared machine. The attacker only requires the ability to run GPU compute applications, such as OpenCL, Vulkan, or Metal.

### Analysis and Critique:
The vulnerability poses significant security risks to ML applications and highlights the need for rigorous security reviews of the GPU development stack. The paper discusses the impact on LLM security, GPU providers, applications, and vendors, as well as the coordinated disclosure process with major GPU vendors. The authors emphasize the need for a detailed threat model, exploration of the GPU execution stack, and significant testing and auditing to fortify the GPU ecosystem, which is the computational foundation of machine learning. The paper also outlines potential mitigations and the impact of LeftoverLocals on various GPU platforms and environments. However, the paper does not provide a detailed discussion of potential solutions or future research directions to address the vulnerability. Additionally, the impact on privacy-sensitive domains and the potential for further complex and sophisticated malicious scenarios are not fully explored. Further research is needed to address these limitations and provide comprehensive solutions to mitigate the vulnerability.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-31       |
| Abstract | [https://arxiv.org/abs/2401.16603v1](https://arxiv.org/abs/2401.16603v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.16603v1](https://browse.arxiv.org/html/2401.16603v1)       |
| Truncated       | False       |
| Word Count       | 10159       |