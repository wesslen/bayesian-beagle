
---
title: "I've got the Answer! Interpretation of LLMs Hidden States in Question Answering"
id: "2406.02060v1"
description: "TL;DR: Study shows LLMs' correct/incorrect behavior can be distinguished in hidden states, proposes additional training for weak layers to improve performance."
author: Valeriya Goloviznina, Evgeny Kotelnikov
date: "2024-06-04"
image: "../../img/2406.02060v1/image_1.png"
categories: ['education', 'hci']
format:
  html:
    code-overflow: wrap
---

![](../../img/2406.02060v1/image_1.png)

### Summary:

* The paper investigates the interpretation of LLMs in the context of knowledge-based question answering.
* The main hypothesis is that correct and incorrect model behavior can be distinguished at the level of hidden states.
* The quantized models LLaMA-2-7B-Chat, Mistral-7B, Vicuna-7B, and the MuSeRC question-answering dataset are used to test this hypothesis.
* The results of the analysis support the proposed hypothesis.
* The paper also identifies the layers which have a negative effect on the model’s behavior.
* As a prospect of practical application, the paper proposes to train such "weak" layers additionally in order to improve the quality of the task solution.

### Major Findings:

1. The paper proposes a hypothesis of partitioning the hidden state space of a model into subspaces corresponding to its correct and incorrect behavior within a certain generative task.
2. The paper proposes a procedure for verifying this hypothesis on the basis of analyzing the hidden states of the LLM in a knowledge-based question answering.
3. The paper confirms the hypothesis for three LLMs using the MuSeRC dataset.
4. The paper identifies the layers which have a negative effect on the model’s behavior.

### Analysis and Critique:

* The paper provides a novel approach to interpreting the behavior of LLMs in the context of knowledge-based question answering.
* The use of quantized models and the MuSeRC dataset is a strength of the paper.
* The paper's findings have practical implications for improving the quality of task solutions in LLMs.
* However, the paper does not provide a detailed analysis of the limitations of the proposed approach.
* The paper also does not discuss the potential impact of the proposed approach on the interpretability and explainability of LLMs.
* Further research is needed to evaluate the proposed approach in other generative tasks and languages.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2406.02060v1](https://arxiv.org/abs/2406.02060v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.02060v1](https://browse.arxiv.org/html/2406.02060v1)       |
| Truncated       | False       |
| Word Count       | 8569       |