
---
title: "Can AI Write Classical Chinese Poetry like Humans? An Empirical Study Inspired by Turing Test"
id: "2401.04952v1"
description: "This paper challenges the belief that AI cannot match human creativity and sentiment, showing recent LLMs can compose classical Chinese poetry indistinguishable from humans."
author: Zekun Deng, Hao Yang, Jun Wang
date: "2024-01-10"
image: "https://browse.arxiv.org/html/2401.04952v1/extracted/5339257/fig/yan_ratio.png"
categories: ['social-sciences', 'architectures', 'production']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.04952v1/extracted/5339257/fig/yan_ratio.png)

### Major Takeaways
1. The study explores whether AI can compose poetry as effectively as humans, particularly focusing on classical Chinese poetry, challenging the notion that machines cannot replicate human creativity and sentiment.
2. The authors introduce a new evaluation framework inspired by the Turing test, called ProFTAP, to assess AI-generated poetry's quality compared to human-authored poetry. The framework emphasizes **distinguishability** to measure AI's poetry writing ability.
3. The study finds that current large language models (LLMs) exhibit the capability to write classical Chinese poems almost indistinguishable from those created by humans, and certain open-source LLMs even outperform leading proprietary models like GPT-4.

### Introduction
- The paper addresses the ongoing debate about the potential of artificial intelligence surpassing human capabilities.
- It emphasizes the significance of poetry as a form of human art and creativity, encapsulating intricate emotions and ideas in a condensed and evocative manner.

### Evaluation Framework for AI-generated Poetry
- The authors propose the **Probabilistic Feigenbaum Test for AI-generated Poetry (ProFTAP)**, inspired by the Turing test, where AI's ability to compose poems is measured based on its **distinguishability** from human-authored poems.
- ProFTAP's procedures include obtaining titles as conditions, preparing AI models, generating poems, post-processing to prevent plagiarism, human judgment, and deriving metrics.

### Experimental Results
- The study applies ProFTAP to major current LLMs for classical Chinese poetry writing, including open-source and proprietary models.
- It finds that finetuned open-source LLMs can write classical Chinese poems nearly indistinguishable from those authored by ancient Chinese poets, highlighting their potential in poetry generation.

### Discussion
- The impact of explicit features such as line length and character repetition on the evaluation of AI-generated poems is explored.
- The research highlights the possibility of improving LLMs' poetry generation capabilities through advanced prompting techniques.

### Conclusion
- The paper concludes by emphasizing the novelty and potential of the ProFTAP framework for evaluating AI-generated poetry and highlights the scope for future research in this area.
- It underscores the need for further advancements in AI poetry generation and evaluation.

### Critique
The paper could benefit from a more comprehensive discussion on the limitations of the ProFTAP framework, potential biases in human judgment, and the ethical implications of AI mimicking human creativity and sentiment. Additionally, considering the subjective nature of poetry, there might be diverse interpretations and preferences not fully captured by the framework.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-12       |
| Abstract | [http://arxiv.org/abs/2401.04952v1](http://arxiv.org/abs/2401.04952v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.04952v1](https://browse.arxiv.org/html/2401.04952v1)       |
| Truncated       | False       |
| Word Count       | 6278       |