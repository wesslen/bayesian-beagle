
---
title: "Focus on Your Question! Interpreting and Mitigating Toxic CoT Problems in Commonsense Reasoning"
id: "2402.18344v1"
description: "Large language models struggle with toxic Chain-of-Thought reasoning, but a new method improves performance."
author: Jiachun Li, Pengfei Cao, Chenhao Wang, Zhuoran Jin, Yubo Chen, Daojian Zeng, Kang Liu, Jun Zhao
date: "2024-02-28"
image: "https://browse.arxiv.org/html/2402.18344v1/x1.png"
categories: ['prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.18344v1/x1.png)

### **Summary:**
- Large language models exhibit high-level commonsense reasoning abilities, especially with enhancement methods like Chain-of-Thought (CoT).
- The Toxic CoT problem occurs when CoT-like methods lead to a considerable number of originally correct answers turning wrong.
- The authors propose a novel method called (Residual decodIng and sERial-position Swap) to compensate for the information deficit in the model from both decoding and serial-position perspectives.

### Major Findings:
1. Toxic CoT problem: CoT-like methods lead to a considerable number of originally correct answers turning wrong.
2. Information loss: The model exhibits information loss from the question in the shallow attention layers when generating rationales or answers.
3. Mitigation method: The (Residual decodIng and sERial-position Swap) method effectively eliminates Toxic CoT problems and improves the modelâ€™s overall commonsense reasoning performance.

### Analysis and Critique:
- The study provides valuable insights into the Toxic CoT problem and proposes a novel method to address it.
- The research focuses on multi-choice questions, and there is a need for advancements in benchmark-related research to address open-ended commonsense reasoning.
- The study refrains from analyzing Toxic CoT problems in additional reasoning tasks such as math and logic, which could be a potential area for future research.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.18344v1](https://arxiv.org/abs/2402.18344v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.18344v1](https://browse.arxiv.org/html/2402.18344v1)       |
| Truncated       | False       |
| Word Count       | 7940       |