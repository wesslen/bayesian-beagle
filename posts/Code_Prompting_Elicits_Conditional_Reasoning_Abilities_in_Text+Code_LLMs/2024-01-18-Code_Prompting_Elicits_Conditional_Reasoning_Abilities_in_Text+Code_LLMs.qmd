
---
title: "Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs"
id: "2401.10065v1"
description: "Code prompts trigger conditional reasoning in language models, improving performance on reasoning tasks. They require natural language text and high-quality code."
author: Haritz Puerto, Martin Tutek, Somak Aditya, Xiaodan Zhu, Iryna Gurevych
date: "2024-01-18"
image: "https://browse.arxiv.org/html/2401.10065v1/extracted/5355524/latex/images/overview.png"
categories: ['programming', 'education', 'prompt-engineering', 'architectures']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.10065v1/extracted/5355524/latex/images/overview.png)

### Summary of the Article:

The article investigates the triggering of conditional reasoning abilities in large language models (LLMs) by using code prompts. Conditional reasoning, the ability to draw different conclusions depending on certain conditions, has been understudied in LLMs. The authors hypothesize that code prompts can trigger conditional reasoning in LLMs trained on text and code. The experiments find that code prompts show a performance boost on reasoning tasks across multiple datasets and are more efficient, requiring fewer demonstrations than text prompts. Moreover, code prompts improve variable state tracking in LLMs. The article concludes that code prompts can elicit conditional reasoning abilities in text+code LLMs and are more sample-efficient compared to text prompts.

### Major Findings:
1. Code prompts exhibit a performance boost on GPT 3.5 between  and  points across multiple datasets requiring conditional reasoning.
2. Code prompts are more efficient, requiring fewer demonstrations compared to text prompts.
3. Code prompts trigger superior state tracking of variables or key entities in LLMs.

### Analysis and Critique:
The article provides valuable insights into the triggering of conditional reasoning abilities in LLMs through the use of code prompts. However, it is important to note the following shortcomings and potential areas for further research:

1. **Limited Generalization:** The study primarily focuses on GPT 3.5 and does not extensively explore the generalization of the findings to other LLMs. Further research is needed to verify the applicability of code prompts to a wider range of reasoning abilities and LLM architectures.

2. **Cost Considerations:** The article acknowledges the high costs associated with running experiments using code prompts. Future work should prioritize minimizing the cost of using code prompts without compromising performance.

3. **Faithfulness of Reasoning Chains:** The article highlights the difficulty of automatically evaluating the faithfulness of reasoning chains generated by LLMs. Further investigations on the accuracy and faithfulness of the generated chains of thought are essential for a comprehensive understanding of the model's reasoning abilities.

In conclusion, while the article provides valuable insights into the use of code prompts to trigger conditional reasoning abilities in LLMs, further research is needed to address the limitations and uncertainties identified in the study.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-19       |
| Abstract | [http://arxiv.org/abs/2401.10065v1](http://arxiv.org/abs/2401.10065v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.10065v1](https://browse.arxiv.org/html/2401.10065v1)       |
| Truncated       | False       |
| Word Count       | 9550       |