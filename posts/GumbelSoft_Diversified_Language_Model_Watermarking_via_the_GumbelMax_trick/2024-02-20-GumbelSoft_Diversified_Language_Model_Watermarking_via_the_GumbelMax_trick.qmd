
---
title: "GumbelSoft: Diversified Language Model Watermarking via the GumbelMax-trick"
id: "2402.12948v1"
description: "Large language models raise concerns about misuse, but GumbelSoft watermark enhances diversity and performance."
author: Jiayi Fu, Xuandong Zhao, Ruihan Yang, Yuansen Zhang, Jiangjie Chen, Yanghua Xiao
date: "2024-02-20"
image: "https://browse.arxiv.org/html/2402.12948v1/x1.png"
categories: ['robustness', 'security']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.12948v1/x1.png)

### Summary:
- Large language models (LLMs) have raised concerns about misuse in fake news and academic dishonesty.
- The GumbelMax-trick-based watermark (GM watermark) is a solution for safeguarding machine-generated texts but has a limitation in generation diversity.
- The Logits-Addition watermark, specifically the GumbelSoft watermark, demonstrates superior performance in high diversity settings.

### Major Findings:
1. GumbelMax-trick-based watermark (GM watermark) has a limitation in generation diversity, always yielding identical outputs for the same prompt.
2. The Logits-Addition watermark, specifically the GumbelSoft watermark, outperforms other variants in high diversity settings, with its AUROC score surpassing other decoding-based watermarking methods.
3. The GumbelSoft watermark maintains low perplexity and surpasses other decoding-based watermarks in AUROC by at least 0.1 on QA tasks.

### Analysis and Critique:
- The deterministic nature of the Pseudo-random and Decoder functions in the GM watermark is a major limitation.
- Integrating a dropout probability and shifting the watermark key boosts diversity but also reduces detectability.
- The GumbelMax-trick has limitations in generating diverse outputs, leading to identical completions for the same prompts.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-26       |
| Abstract | [https://arxiv.org/abs/2402.12948v1](https://arxiv.org/abs/2402.12948v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.12948v1](https://browse.arxiv.org/html/2402.12948v1)       |
| Truncated       | False       |
| Word Count       | 3703       |