
---
title: "Fairness and Bias in Multimodal AI: A Survey"
id: "2406.19097v1"
description: "TL;DR: This survey highlights fairness and bias in Large Multimodal Models, offering 50 examples and discussing challenges, including a new preuse bias category."
author: Tosin Adewumi, Lama Alkhaled, Namrata Gurung, Goya van Boven, Irene Pagliai
date: "2024-06-27"
image: "../../../bayesian-beagle.png"
categories: ['social-sciences']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### Summary:

This survey paper aims to fill the gap in the literature regarding the study of fairness and bias in Large Multimodal Models (LMMs) compared to Large Language Models (LLMs). The authors provide 50 examples of datasets and models along with the challenges affecting them. They identify a new category of quantifying bias (preuse) in addition to the two well-known ones in the literature: intrinsic and extrinsic. The paper also critically discusses various ways researchers are addressing these challenges.

The authors conducted a filtered search on Google Scholar with two slightly differently-worded phrases: "Fairness and Bias in Large Multimodal Models" and "Fairness and Bias in Large Language Models." The search was filtered to the period 2014-2024, during which deep learning made significant progress. The results revealed that there are fewer scientific papers on the former.

The paper reviews some LMMs and LLMs and the fairness and bias challenges they have. Tables 2 and 3 summarize some relevant datasets and the models, respectively. All the 25 datasets identified have their challenges, including stereotypes, porn, misogyny, racial, gender, religious, cultural, age, and demographic biases.

### Major Findings:

1. The paper identifies a new category of quantifying bias (preuse) in addition to the two well-known ones in the literature: intrinsic and extrinsic.
2. The paper provides 50 examples of datasets and models along with the challenges affecting them.
3. The paper critically discusses various ways researchers are addressing the challenges of fairness and bias.

### Analysis and Critique:

The paper provides a comprehensive survey of fairness and bias across a wide spectrum of LMMs, LLMs, and multimodal datasets. However, the paper could have provided more details on the methodology used to identify the 50 examples of datasets and models. Additionally, the paper could have provided more in-depth analysis and critique of the various ways researchers are addressing the challenges of fairness and bias.

The paper also acknowledges that it may be almost impossible to automatically filter a dataset or debias a model to be 100% free of unfair, bias,

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-07       |
| Abstract | [https://arxiv.org/abs/2406.19097v1](https://arxiv.org/abs/2406.19097v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.19097v1](https://browse.arxiv.org/html/2406.19097v1)       |
| Truncated       | False       |
| Word Count       | 5909       |