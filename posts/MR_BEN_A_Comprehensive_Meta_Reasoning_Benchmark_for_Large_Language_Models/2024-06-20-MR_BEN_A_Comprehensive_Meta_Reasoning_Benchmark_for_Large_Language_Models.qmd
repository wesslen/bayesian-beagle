
---
title: "MR-BEN: A Comprehensive Meta-Reasoning Benchmark for Large Language Models"
id: "2406.13975v1"
description: "TL;DR: Mr-Ben benchmark evaluates LLMs' meta-reasoning skills, revealing gaps in reasoning capabilities."
author: Zhongshen Zeng, Yinhong Liu, Yingjia Wan, Jingyao Li, Pengguang Chen, Jianbo Dai, Yuxuan Yao, Rongwu Xu, Zehan Qi, Wanru Zhao, Linling Shen, Jianqiao Lu, Haochen Tan, Yukang Chen, Hao Zhang, Zhan Shi, Bailin Wang, Zhijiang Guo, Jiaya Jia
date: "2024-06-20"
image: "https://browse.arxiv.org/html/2406.13975v1/x1.png"
categories: ['hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.13975v1/x1.png)

# Summary:

The paper introduces a comprehensive meta-reasoning benchmark, Mr-Ben, for evaluating the reasoning capabilities of large language models (LLMs). Unlike existing outcome-based benchmarks, Mr-Ben focuses on the process of reasoning, demanding a meta-reasoning skill from LLMs. The benchmark comprises 5,975 questions collected from human experts, covering various subjects such as physics, chemistry, logic, coding, and more.

## Major Findings:

1. Mr-Ben is a comprehensive benchmark that employs a meta-reasoning paradigm, where LLMs are challenged to reason about different forms of reasoning. This paradigm involves LLMs acting as teachers, evaluating the reasoning process by assessing correctness, analyzing potential errors, and providing corrections.

2. The analyses of various LLMs on Mr-Ben reveal distinct limitations and previously unidentified weaknesses in their reasoning abilities. While many LLMs can generate the correct answer to a question, they struggle to pinpoint errors in the reasoning process and correct them. This suggests that existing LLMs have yet to master reasoning, particularly the smaller models.

3. Techniques such as the use of high-quality synthetic data can significantly improve reasoning abilities, offering a potential pathway to enhance performance regardless of model size. However, different LLMs excel in different reasoning paradigms, challenging the assumption that domain-specific enhancements necessarily lead to broad cognitive improvements.

## Analysis and Critique:

While Mr-Ben provides a comprehensive evaluation of LLMs' reasoning abilities, it has some limitations. The benchmark's applicability may be restricted when it comes to subjects that are inherently holistic or creative in nature, such as humanities or sociology. Additionally, Mr-Ben is currently confined to questions in English, which could potentially limit the scope of reasoning challenges that can be explored. Furthermore, the analysis and correction of errors in the reasoning steps are currently based on solutions generated by three LLMs, which may not represent the diverse reasoning and error patterns of different LLMs and individuals.

Moreover, the benchmark may present potential negative societal impacts, such as the risk of LLMs being misused or used maliciously. For instance, LLMs with advanced reasoning capabilities could be used to manipulate information or deceive people. The use

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-23       |
| Abstract | [https://arxiv.org/abs/2406.13975v1](https://arxiv.org/abs/2406.13975v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.13975v1](https://browse.arxiv.org/html/2406.13975v1)       |
| Truncated       | False       |
| Word Count       | 8416       |