
---
title: "PermLLM: Private Inference of Large Language Models within 3 Seconds under WAN"
id: "2405.18744v1"
description: "TL;DR: PermLLM accelerates private LLM inference, offering 2-party private inference of ChatGLM-6B at 3s/token, significantly faster than existing MPC solutions."
author: Fei Zheng, Chaochao Chen, Zhongxuan Han, Xiaolin Zheng
date: "2024-05-29"
image: "https://browse.arxiv.org/html/2405.18744v1/x1.png"
categories: ['hci', 'robustness', 'social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2405.18744v1/x1.png)

### Summary:

The paper introduces PermLLM, a fast private inference framework for large language models (LLMs). The framework aims to address privacy concerns in LLM applications, such as exposing user queries to the model provider or revealing model parameters to the user. PermLLM combines cryptographic technologies with random permutation to realize efficient secure inference of LLMs. The framework adopts a two-party setting with a semi-honest third party, where one party is the model provider and the other is the user. The third party participates in the preparation and offline phase to generate pre-computed Beaver's triples and permutation triples.

### Major Findings:

1. PermLLM enables fast private inference for LLMs, achieving a token generation speed of 3s/token under a realistic WAN setting, as demonstrated by implementing it on the ChatGLM-6B model.
2. The framework computes nonlinear functions such as GeLU and Softmax on randomly permuted plaintext elements based on the secure secret-shared permutation protocol, avoiding heavy cryptographic operations while maintaining negligible privacy leakage.
3. PermLLM optimizes the secret-shared secure multiplication by leveraging the properties of LLM inference, incorporating it with secure random permutation, homomorphic encryption, and other techniques, achieving a reduction of magnitudes in computation and communication cost compared with existing private LLM inference solutions.

### Analysis and Critique:

The paper presents an innovative approach to addressing privacy concerns in LLM applications. The use of random permutation to compute nonlinear functions is a novel idea that could potentially improve the efficiency of private inference in LLMs. However, the paper does not provide a detailed analysis of the security implications of using random permutation. The assumption that the hidden representations in LLM contain thousands of elements, yielding an almost infinite number of possible permutations, may not hold in all cases. Additionally, the paper does not discuss the potential impact of the proposed framework on the accuracy of LLM inference. Further research is needed to evaluate the security and accuracy of PermLLM in different LLM applications.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2405.18744v1](https://arxiv.org/abs/2405.18744v1)        |
| HTML     | [https://browse.arxiv.org/html/2405.18744v1](https://browse.arxiv.org/html/2405.18744v1)       |
| Truncated       | False       |
| Word Count       | 5840       |