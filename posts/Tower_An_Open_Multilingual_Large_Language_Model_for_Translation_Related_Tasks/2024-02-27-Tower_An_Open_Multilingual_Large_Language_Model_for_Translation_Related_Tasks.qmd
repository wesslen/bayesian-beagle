
---
title: "Tower: An Open Multilingual Large Language Model for Translation-Related Tasks"
id: "2402.17733v1"
description: "Tailoring LLMs for translation tasks improves performance, competitive with general-purpose models."
author: Duarte M. Alves, José Pombal, Nuno M. Guerreiro, Pedro H. Martins, João Alves, Amin Farajian, Ben Peters, Ricardo Rei, Patrick Fernandes, Sweta Agrawal, Pierre Colombo, José G. C. de Souza, André F. T. Martins
date: "2024-02-27"
image: "../../img/2402.17733v1/image_1.png"
categories: ['production', 'architectures']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.17733v1/image_1.png)

### Summary:
- The article discusses the development of TOWER, an open multilingual large language model (LLM) for translation-related tasks, addressing the limitations of open LLMs and achieving competitive results with closed LLMs.
- It presents the results of machine translation models on various language pairs, highlighting the effectiveness of TOWERINSTRUCT 13B in achieving high translation quality across different language directions.
- The section also discusses the release of TOWER models, TOWERBLOCKS, and TOWEREVAL code for benchmarking, providing transparency and reproducibility of the research.

### Major Findings:
1. TOWER addresses the limitations of open LLMs and achieves competitive results with closed LLMs for translation-related tasks.
2. TOWERINSTRUCT 13B demonstrates high translation quality across various language directions.
3. The availability of TOWER models, TOWERBLOCKS, and TOWEREVAL code contributes to the credibility and reproducibility of the research.

### Analysis and Critique:
- The article provides valuable insights into the development and challenges of large language models for translation tasks, emphasizing the need for further advancements in the field of machine translation.
- The findings demonstrate the effectiveness of alternative decoding strategies in improving translation quality for the TOWERINSTRUCT 13B model and shed light on potential areas for improvement in large language models.
- The empirical evidence of the translation quality of various language models across different language pairs offers valuable insights into the performance of these models and their effectiveness in multilingual translation tasks. Additionally, the detailed overview of the performance of various models in translation-related tasks provides valuable insights for researchers and practitioners in the field of natural language processing and machine translation.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-28       |
| Abstract | [https://arxiv.org/abs/2402.17733v1](https://arxiv.org/abs/2402.17733v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.17733v1](https://browse.arxiv.org/html/2402.17733v1)       |
| Truncated       | True       |
| Word Count       | 33486       |