
---
title: "CAT-LLM: Prompting Large Language Models with Text Style Definition for Chinese Article-style Transfer"
id: "2401.05707v1"
description: "A new framework, CAT-LLM, improves Chinese article-style transfer using large language models, enhancing accuracy and applicability."
author: ['Zhen Tao', 'Dinghao Xi', 'Zhiyu Li', 'Liumin Tang', 'Wei Xu']
date: "2024-01-11"
image: "https://browse.arxiv.org/html/2401.05707v1/x1.png"
categories: ['social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.05707v1/x1.png)

### Major Findings

1. **Text Style Transfer** plays a crucial role in NLP, but existing models are limited in their applicability to **Chinese** long texts, where LLMs have been shown to be effective in handling more complex NLP tasks.
  
2. The proposed Chinese Article-style Transfer framework (**CAT-LLM**) outperforms current research in terms of **transfer accuracy** and **content preservation**. CAT-LLM leverages a Text Style Definition (TSD) module to comprehensively analyze text features at both **words and sentences levels** and supports dynamic expansion of internal style trees.

3. Five Chinese articles with distinct styles were used to create parallel datasets using ChatGPT, *enhancing* the modelsâ€™ performance evaluation accuracy and establishing a novel paradigm for evaluating subsequent research on article-style transfer.

### Methodology

- **Task Definition and The Whole Framework**
  - The CAT-LLM framework is divided into five stages, including the usage of **ChatGPT** to transform **style definition** into stylishless text.
- **Text Style Definition Module**
  - The TSD module computes the style of the style definition part from both words and sentences levels and provides precise style definitions.
- **Style-enhanced Prompt**
  - A style-enhanced prompt is designed leveraging the style definition generated by the TSD module to enhance the **zero-shot learning capability** of LLMs.

### Experiment

- **Datasets**
  - Five literary works with diverse styles were selected, and their style transfer part and style definition part were used to create parallel Chinese article-style transfer datasets using ChatGPT.
- **Evaluation Metrics**
  - Style transfer accuracy and content preservation were the primary focus, with **BLEU-n** and **BERTScore** being used to measure lexical and semantic similarity between texts.
- **Experimental Results**
  - CAT-LLM achieved a better balance between style transfer and content preservation in each LLM transfer, showing competitive results in article-style transfer of various LLMs.

### Critique

The paper presents a comprehensive and innovative framework for Chinese article-style transfer utilizing LLMs. However, the evaluation metrics could be further expanded to include a wider variety of NLP tasks, and the ablation study could benefit from more in-depth analysis of the interactions between words level and sentences level style definitions.

Overall, the paper provides significant contributions to the advancement of Chinese article-style transfer and offers promising avenues for future research.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [http://arxiv.org/abs/2401.05707v1](http://arxiv.org/abs/2401.05707v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.05707v1](https://browse.arxiv.org/html/2401.05707v1)       |
| Truncated       | False       |
| Word Count       | 7518       |