
---
title: "Using Large Language Models for Humanitarian Frontline Negotiation: Opportunities and Considerations"
id: "2405.20195v1"
description: "AI can enhance frontline negotiations, but ethical and practical considerations are crucial."
author: Zilin Ma, 1 Susannah, Su, Nathan Zhao, Linn Bieske, Blake Bullwinkel, Yanyi Zhang, Sophia, Yang, Ziqing Luo, Siyao Li, Gekai Liao, Boxiang Wang, Jinglun Gao, Zihan Wen, Claude Bruderlein, Weiwei Pan
date: "2024-05-30"
image: "https://browse.arxiv.org/html/2405.20195v1/extracted/5632808/Flowchart.png"
categories: ['hci', 'education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2405.20195v1/extracted/5632808/Flowchart.png)

# Summary

The study explores the potential of large language models (LLMs) to aid decision-making in frontline humanitarian negotiations. Through interviews with 13 experienced negotiators, the authors identified needs for AI-assisted case analysis and creativity support, as well as concerns surrounding confidentiality and model bias. The authors evaluated the quality and stability of ChatGPT-based negotiation tools in the context of two real cases, highlighting the potential for LLMs to enhance humanitarian negotiations while underscoring the need for careful ethical and practical considerations.

## Major Findings

1. LLMs can generate reliable and useful frontline negotiation case summaries, as demonstrated by the strong consistency of GPT-4's responses in filling out the Island of Agreement (IoA) and Stakeholder Mapping (ShM) templates.
2. Additional use cases for LLMs in this domain include context analysis and ideation augmentation, such as automating parts of context analysis for long documents and unstructured texts, and proposing alternative plans, arguments, or solutions.
3. Concerns about integrating LLMs into negotiators' workflows include confidentiality, Western bias in LLMs, public and mandator opinions on AI, accuracy and trust, incompleteness, and overreliance.

## Analysis and Critique

The study provides valuable insights into the potential of LLMs to support frontline humanitarian negotiations. However, several limitations and areas for further research should be considered:

1. The study focuses on a small sample of 13 negotiators, which may not be representative of the broader population of humanitarian negotiators.
2. The evaluation of LLM-generated responses is primarily based on quantitative metrics, which may not fully capture the nuances and complexities of humanitarian negotiations.
3. The study does not address the potential for LLMs to exacerbate existing power imbalances in humanitarian negotiations, as more technologically advanced actors may have an advantage in leveraging LLMs for their benefit.
4. The authors acknowledge the need for further investigation into the risks associated with using LLMs in humanitarian negotiations, particularly in terms of data confidentiality and model bias.

In conclusion, the study highlights the potential for LLMs to enhance humanitarian negotiations while emphasizing the need for careful ethical and

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2405.20195v1](https://arxiv.org/abs/2405.20195v1)        |
| HTML     | [https://browse.arxiv.org/html/2405.20195v1](https://browse.arxiv.org/html/2405.20195v1)       |
| Truncated       | False       |
| Word Count       | 13991       |