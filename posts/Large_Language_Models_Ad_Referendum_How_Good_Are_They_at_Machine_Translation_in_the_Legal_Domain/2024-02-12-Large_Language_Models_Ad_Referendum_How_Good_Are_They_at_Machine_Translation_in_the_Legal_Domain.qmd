
---
title: "Large Language Models Ad Referendum: How Good Are They at Machine Translation in the Legal Domain?"
id: "2402.07681v1"
description: "Human evaluators rate large language models' legal translations highly, despite lower automated metric scores. Highlights need for better AEMs to assess nuanced LLM translations."
author: Vicent Briva-Iglesias, Joao Lucas Cavalheiro Camargo, Gokhan Dogru
date: "2024-02-12"
image: "../../img/2402.07681v1/image_1.png"
categories: ['architectures', 'production']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.07681v1/image_1.png)

### **Summary:**

- The article evaluates the performance of two large language models (LLMs), Google Translate, and a proprietary LLM (GPT-4) in machine translation (MT) in the legal domain.
- The study combines automatic evaluation metrics (AEMs) and human evaluation (HE) by professional translators to assess translation ranking, fluency, and adequacy.
- Results indicate that Google Translate outperforms LLMs in AEMs, but human evaluators rate LLMs, especially GPT-4, comparably or slightly better in terms of producing contextually adequate and fluent translations.
- The discrepancy between AEMs and HE suggests the potential of LLMs in handling specialized legal terminology and context, highlighting the importance of human evaluation methods in assessing MT quality.

### **Major Findings:**

1. Google Translate generally outperforms LLMs in AEMs, but human evaluators rate LLMs, especially GPT-4, comparably or slightly better in terms of producing contextually adequate and fluent translations.
2. The discrepancy between AEMs and HE suggests that LLMs have the potential to handle specialized legal terminology and context better than AEMs indicate.
3. The study underscores the evolving capabilities of LLMs in specialized domains and calls for reevaluation of traditional AEMs to better capture the nuances of LLM-generated translations.

### **Analysis and Critique:**

- The study could benefit from a more diverse set of languages to ensure broader applicability of the findings.
- While the study combines AEMs and HE, it would be beneficial to include more extensive HE from multiple evaluators to increase the reliability of the results.
- The authors acknowledge the need for further research on the role of AEMs in assessing LLM-generated translations, which should be addressed in future studies.
- The authors also mention the potential impact of LLMs on the language services industry, which requires further investigation to understand the implications of these technologies on the profession.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x7b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.07681v1](https://arxiv.org/abs/2402.07681v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.07681v1](https://browse.arxiv.org/html/2402.07681v1)       |
| Truncated       | False       |
| Word Count       | 17212       |