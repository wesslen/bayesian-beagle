
---
title: "Position Debiasing Fine-Tuning for Causal Perception in Long-Term Dialogue"
id: "2406.02002v1"
description: "CPD method alleviates position bias in LLMs, improving long-term dialogue relevance and coherence."
author: Shixuan Fan, Wei Wei, Wendi Li, Xian-Ling Mao, Wenfeng Xie, Dangyang Chen
date: "2024-06-04"
image: "https://browse.arxiv.org/html/2406.02002v1/x1.png"
categories: ['programming']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.02002v1/x1.png)

# Summary:
The paper proposes a novel method called Causal Perception long-term Dialogue framework (CPD) to alleviate the position bias problem in large language models (LLMs) for long-term dialogue tasks. The CPD framework employs perturbation-based causal variable discovery to extract causally relevant utterances from dialogue history and enhances the model's causal perception during fine-tuning. The framework includes a local-position awareness method for inter-sentence position correlation elimination and a causal-perception fine-tuning strategy to enhance the model's ability to discover causal invariant factors. Experimental results on two datasets demonstrate that the proposed method can effectively alleviate position bias and achieve significant progress compared to existing baselines.

# Major Findings:
1. The CPD framework can effectively alleviate position bias in LLMs for long-term dialogue tasks.
2. The local-position awareness method can help models extract causally relevant utterances based on perturbations.
3. The causal-perception fine-tuning strategy can enhance the model's ability to discover causal invariant factors.

# Analysis and Critique:
1. The paper provides a comprehensive analysis of the position bias problem in LLMs for long-term dialogue tasks.
2. The proposed CPD framework is a novel approach to alleviate the position bias problem and improve the model's causal perception.
3. The experimental results demonstrate the effectiveness of the proposed method, but the evaluation is limited to two datasets.
4. The paper does not discuss the potential limitations or shortcomings of the proposed method.
5. The paper does not provide a comparison with other position debiasing methods for long-term dialogue tasks.
6. The paper does not discuss the potential impact of the proposed method on other NLP tasks.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2406.02002v1](https://arxiv.org/abs/2406.02002v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.02002v1](https://browse.arxiv.org/html/2406.02002v1)       |
| Truncated       | False       |
| Word Count       | 7030       |