
---
title: "Benchmarking LLMs on the Semantic Overlap Summarization Task"
id: "2402.17008v1"
description: "Semantic Overlap Summarization (SOS) task evaluates LLMs' ability to summarize common information from alternative narratives."
author: John Salvador, Naman Bansal, Mousumi Akter, Souvika Sarkar, Anupam Das, Shubhra Kanti Karmaker
date: "2024-02-26"
image: "https://browse.arxiv.org/html/2402.17008v1/extracted/5428274/resource/Scenario.png"
categories: ['prompt-engineering', 'hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.17008v1/extracted/5428274/resource/Scenario.png)

### **Summary:**
- The paper evaluates Large Language Models (LLMs) on the Semantic Overlap Summarization (SOS) task using the TELeR taxonomy to design prompts for LLMs.
- The study uses two datasets, AllSides and PrivacyPolicyPairs (3P), to assess the LLMs' ability to summarize overlapping information from multiple alternative narratives.
- The evaluation is based on well-established metrics like ROUGE, BERTscore, and SEM- on both datasets.

### **Major Findings:**
1. LLMs' performance varies across different prompt levels, with TELeR level 1 consistently performing the best.
2. The AllSides dataset yields higher evaluation scores compared to the 3P dataset, indicating that LLMs may have seen more news data than privacy policy narratives.
3. The study finds that LLMs' responses to complex prompts (Levels 3 and 4) do not necessarily improve their performance compared to simpler prompts (Level 1).

### **Analysis and Critique:**
- The study's primary limitation is the size of the dataset, which may impact the generalizability of the findings.
- The evaluation was conducted using pre-trained LLMs without fine-tuning, potentially limiting the models' performance.
- The paper effectively sets new baselines for the SOS task but acknowledges the need for larger-scale efforts to increase the dataset size and further improve LLM performance.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.17008v1](https://arxiv.org/abs/2402.17008v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.17008v1](https://browse.arxiv.org/html/2402.17008v1)       |
| Truncated       | False       |
| Word Count       | 6088       |