
---
title: "kNN-ICL: Compositional Task-Oriented Parsing Generalization with Nearest Neighbor In-Context Learning"
description: "LLMs improve semantic parsing tasks without needing extra data or specialized prompts, achieving comparable performance to supervised models."
author: Wenting Zhao, Ye Liu, Yao Wan, Yibo Wang, Qingyang Wu, Zhongfen Deng, Jiangshu Du, Shuaiqi Liu, Yunlong Xu, Philip S. Yu
date: "2023-12-17"
image: "https://browse.arxiv.org/html/2312.10771v1/x1.png"
categories: ['programming']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2312.10771v1/x1.png)

### Major Takeaways

1. **kNN-ICL** is introduced for harnessing the capabilities of Large Language Models (LLMs) for semantic parsing tasks, improving prompt engineering by enabling access to all demo examples.
  
2. The effectiveness of prompt design for LLMs in the context of Task-Oriented Parsing (TOP) is examined by framing TOP as a code generation task and introducing a similarity-based demo selection strategy.

3. kNN-ICL significantly outperforms kNN-LM across all domains, demonstrating effectiveness in leveraging prompts for TOP.

### Methodology
- **Prompt Design for Semantic Parsing**: Variations in prompt components, including API documentation and three exemplar selection strategies, were ablated to evaluate their exact match scores.
- **kNN-ICL Integration**: All exemplars are integrated into LLMs using kNN-ICL, enabling the collective knowledge from the exemplars within the demo pool to enhance the generation of semantic parse APIs.

### Experiments
- **ICL vs. Supervised Methods**: Codex consistently outperforms RINE on average across four domains, with significant improvements in the Reminder, Alarm, and Weather domains.
- **kNN-ICL Results**: kNN-ICL demonstrates improved performance compared to kNN-LM, achieving an uplift in exact match scores across all domains.

### Critique
The paper does not consider potential drawbacks or limitations of the introduced kNN-ICL methodology, or address the impact of the limited size of the datastore on the generalization of the findings. Additionally, the focus on specific models such as GPT-NeoX and CodeGen could limit the applicability of the findings to other LLMs.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-03       |
| Abstract | [http://arxiv.org/abs/2312.10771v1](http://arxiv.org/abs/2312.10771v1)        |
| HTML     | [https://browse.arxiv.org/html/2312.10771v1](https://browse.arxiv.org/html/2312.10771v1)       |
| Truncated       | False       |
| Word Count       | 8730       |