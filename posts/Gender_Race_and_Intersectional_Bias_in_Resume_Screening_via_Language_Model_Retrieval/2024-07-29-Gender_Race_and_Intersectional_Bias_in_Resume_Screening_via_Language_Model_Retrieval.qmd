
---
title: "Gender, Race, and Intersectional Bias in Resume Screening via Language Model Retrieval"
id: "2407.20371v1"
description: "LLMs used in resume screening favor White and female names, disadvantaging Black males, reflecting real-world biases."
author: Kyra Wilson, Aylin Caliskan
date: "2024-07-29"
image: "https://browse.arxiv.org/html/2407.20371v1/extracted/5762177/mistral_flow.png"
categories: ['social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2407.20371v1/extracted/5762177/mistral_flow.png)

### Summary:

This study investigates the potential for biased outcomes when using Large Language Models (LLMs) for resume screening. The authors use a document retrieval framework to simulate resume screening and analyze outcomes with respect to race and gender. They find that the models exhibit biases, significantly favoring White-associated names in 85.1% of cases and female-associated names in only 11.1% of cases. Black males are disadvantaged in up to 100% of cases, replicating real-world patterns of bias in employment settings. The study also finds an impact of document length and the corpus frequency of names in the selection of resumes.

### Major Findings:

1. LLMs exhibit biases in resume screening, significantly favoring White-associated names in 85.1% of cases and female-associated names in only 11.1% of cases.
2. Black males are disadvantaged in up to 100% of cases, replicating real-world patterns of bias in employment settings.
3. The study validates three hypotheses of intersectionality.
4. The features of race and gender signals such as name frequency and resume length impact screening outcomes.

### Analysis and Critique:

The study provides a comprehensive analysis of the potential biases in LLMs when used for resume screening. However, there are some limitations and areas for further research. The study only considers two of the most commonly studied race (White and Black) and gender (male and female) groups via associated names. Hiring discrimination is not limited to these groups or signals, and it is important to investigate additional groups to fully quantify the risks in using LLMs for hiring. Additionally, investigating realistic variations in resume length is an important direction for future research.

The study also highlights the need for policy and mechanisms to comprehensively audit resume screening systems, whether proprietary or open source, in order to evaluate their fairness and improve or remove these systems accordingly. The results of this study exemplify the risks associated with using LLMs for resume screening, as they consistently replicate existing societal patterns of discrimination, further disadvantaging the groups already experiencing inequity in resume screening.

In conclusion, this study provides valuable insights into the potential biases in LLMs when used for resume screening

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-06       |
| Abstract | [https://arxiv.org/abs/2407.20371v1](https://arxiv.org/abs/2407.20371v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.20371v1](https://browse.arxiv.org/html/2407.20371v1)       |
| Truncated       | False       |
| Word Count       | 9882       |