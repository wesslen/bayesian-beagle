<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Qianli Wang">
<meta name="author" content="Tatiana Anikina">
<meta name="author" content="Nils Feldhus">
<meta name="author" content="Josef van Genabith">
<meta name="author" content="Leonhard Hennig">
<meta name="author" content="Sebastian Möller">
<meta name="dcterms.date" content="2024-01-23">
<meta name="description" content="Interpretable AI tool LLMCheckup enables interactive dialogue with large language models and supports multiple input modalities.">

<title>Bayesian beagle - LLMCheckup: Conversational Examination of Large Language Models via Interpretability Tools</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Bayesian beagle - LLMCheckup: Conversational Examination of Large Language Models via Interpretability Tools">
<meta property="og:description" content="Interpretable AI tool LLMCheckup enables interactive dialogue with large language models and supports multiple input modalities.">
<meta property="og:image" content="https://browse.arxiv.org/html/2401.12576v1/extracted/5363462/figures/architecture_with_model_name.png">
<meta property="og:site-name" content="Bayesian beagle">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../icon.jpg" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Bayesian beagle</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">Bayesian beagle</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/wesslen/bayesian-beagle" rel="" target=""><i class="bi bi-github" role="img" aria-label="github">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">LLMCheckup: Conversational Examination of Large Language Models via Interpretability Tools</h1>
  <div class="quarto-categories">
    <div class="quarto-category">prompt-engineering</div>
    <div class="quarto-category">production</div>
    <div class="quarto-category">education</div>
    <div class="quarto-category">programming</div>
  </div>
  </div>

<div>
  <div class="description">
    Interpretable AI tool LLMCheckup enables interactive dialogue with large language models and supports multiple input modalities.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Authors</div>
    <div class="quarto-title-meta-contents">
             <p>Qianli Wang </p>
             <p>Tatiana Anikina </p>
             <p>Nils Feldhus </p>
             <p>Josef van Genabith </p>
             <p>Leonhard Hennig </p>
             <p>Sebastian Möller </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 23, 2024</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p><img src="https://browse.arxiv.org/html/2401.12576v1/extracted/5363462/figures/architecture_with_model_name.png" class="img-fluid"></p>
<p><strong>Summary:</strong> The article introduces LLMCheckup, an interpretability tool designed to enhance user understanding of large language models (LLMs) through interactive dialogue-based explanations. LLMCheckup provides an accessible platform for users to converse with LLMs, enabling the models to generate self-explanations and recognize user intent without requiring fine-tuning. The tool incorporates a broad spectrum of explainable AI (XAI) tools, supports various input modalities, and offers tutorials for users with different levels of expertise in XAI. LLMCheckup is demonstrated with tasks such as fact checking and commonsense question answering, showcasing its effectiveness in enhancing model interpretability.</p>
<section id="major-findings" class="level3">
<h3 class="anchored" data-anchor-id="major-findings">Major Findings:</h3>
<ol type="1">
<li><strong>Conversational Interpretability:</strong> Moving beyond one-off explanations, LLMCheckup embraces dialogue-based explanations, facilitating a more effective understanding of model behavior through interactive conversations.</li>
<li><strong>Unified Framework:</strong> LLMCheckup streamlines interpretability processes by consolidating parsing, downstream task prediction, explanation generation, and response generation within a single framework, enhancing the accessibility and usability of XAI tools.</li>
<li><strong>Diverse Functionality:</strong> The tool supports multiple input modalities, including text, images, and audio, while also offering external information retrieval capabilities and customized inputs and prompts, providing a comprehensive and tailored user experience.</li>
</ol>
</section>
<section id="analysis-and-critique" class="level3">
<h3 class="anchored" data-anchor-id="analysis-and-critique">Analysis and Critique:</h3>
<p>The article offers a comprehensive overview of LLMCheckup, highlighting its potential to address the challenges associated with model interpretability. However, several limitations and considerations should be noted: 1. <strong>Language Limitations:</strong> The tool currently focuses on English language, and while it can be adapted for other languages, the effectiveness of multilingual LLMs in self-explanation and parsing tasks remains to be seen. 2. <strong>Model Limitations:</strong> Smaller LLMs may exhibit limitations in certain types of explanation generation and parsing, potentially impacting the tool’s performance for specific operations, requiring further investigation and potential enhancements. 3. <strong>Data-Centric Interpretability:</strong> LLMCheckup primarily focuses on model responses to single inputs, potentially limiting its applicability in scenarios where data-centric interpretability is required, such as medical report generation or gender-aware translation. 4. <strong>Usability for Custom Inputs:</strong> While the tool allows for customized inputs and prompts, the adaptability of model-generated explanations to users’ expertise levels may require further exploration for reliable simplicity. 5. <strong>Modalities for Explanations:</strong> While LLMCheckup supports multiple input modalities, the generation of explanations and responses is currently limited to text formats, potentially restricting its comprehensive analysis of image or audio inputs without converting them to textual format.</p>
<p>In conclusion, while LLMCheckup demonstrates significant potential in improving the interpretability of large language models, further research and development are needed to address its limitations and enhance its applicability across diverse language and modalities.</p>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>gpt-3.5-turbo-1106</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-02-26</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="http://arxiv.org/abs/2401.12576v1">http://arxiv.org/abs/2401.12576v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2401.12576v1">https://browse.arxiv.org/html/2401.12576v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>False</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>7746</td>
</tr>
</tbody>
</table>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="wesslen/bayesian-beagle" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/wesslen/bayesian-beagle/edit/main/posts/LLMCheckup_Conversational_Examination_of_Large_Language_Models_via_Interpretability_Tools/2024-01-23-LLMCheckup_Conversational_Examination_of_Large_Language_Models_via_Interpretability_Tools.qmd" class="toc-action">Edit this page</a></p></div></div></div></div></footer></body></html>