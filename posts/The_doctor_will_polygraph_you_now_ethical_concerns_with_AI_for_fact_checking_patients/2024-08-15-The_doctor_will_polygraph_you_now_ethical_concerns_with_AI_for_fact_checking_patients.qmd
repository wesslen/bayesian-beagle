
---
title: "The doctor will polygraph you now: ethical concerns with AI for fact-checking patients"
id: "2408.07896v1"
description: "AI for predicting social behaviors raises ethical concerns about patient data use, accuracy, and trust in healthcare."
author: James Anibal, Jasmine Gunkel, Hannah Huth, Hang Nguyen, Shaheen Awan, Yael Bensoussan, Bradford Wood
date: "2024-08-15"
image: "../../img/2408.07896v1/image_1.png"
categories: ['social-sciences']
format:
  html:
    code-overflow: wrap
---

![](../../img/2408.07896v1/image_1.png)

### Summary:

The article discusses the ethical concerns surrounding the use of artificial intelligence (AI) for fact-checking patients in clinical settings. The authors highlight three main ethical issues: (1) the use of patient data retrospectively without informed consent for verification, (2) the potential for inaccuracies or biases within such systems, and (3) the impact on trust in patient-provider relationships with the introduction of automated AI systems for "fact-checking". The authors also demonstrate the simulated misuse of a verification system and identify a potential LLM bias against patient-reported information in favor of multimodal data, published literature, and the outputs of other AI methods (i.e., "AI self-trust"). Finally, the article presents recommendations for mitigating the risk that AI verification systems will cause harm to patients or undermine the purpose of the healthcare system.

### Major Findings:

1. The use of AI methods to identify potentially concealed information may violate the data privacy rights of patients.
2. The concept of a "clinical AI system for social behavior verification" raises ethical concerns, including the potential for biases and the impact on trust in patient-provider relationships.
3. The authors demonstrate the potential application of LLMs in a health verification system and identify a potential LLM bias against patient-reported information.

### Analysis and Critique:

* The article raises important ethical concerns about the use of AI for fact-checking patients in clinical settings. However, the authors do not provide a comprehensive analysis of the potential benefits and drawbacks of such systems.
* The authors' recommendations for mitigating the risks of AI verification systems are limited in scope and do not address the broader ethical implications of using AI in healthcare.
* The authors' demonstration of the potential application of LLMs in a health verification system is based on a limited set of experiments and may not be generalizable to other contexts.
* The authors' identification of a potential LLM bias against patient-reported information is an important finding, but further research is needed to confirm this bias and explore its implications.
* The article does not discuss the potential role of patients in shaping the development and use of AI verification systems, which is an important consideration in ensuring that such systems are ethical and patient-centered.
* The authors' focus

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-20       |
| Abstract | [https://arxiv.org/abs/2408.07896v1](https://arxiv.org/abs/2408.07896v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.07896v1](https://browse.arxiv.org/html/2408.07896v1)       |
| Truncated       | False       |
| Word Count       | 6122       |