
---
title: "A Comprehensive Study of Multilingual Confidence Estimation on Large Language Models"
id: "2402.13606v1"
description: "LLMs need reliable confidence estimations; MlingConf improves cross-lingual confidence scores for diverse languages."
author: Boyang Xue, Hongru Wang, Weichao Wang, Rui Wang, Sheng Wang, Zeming Liu, Kam-Fai Wong
date: "2024-02-21"
image: "https://browse.arxiv.org/html/2402.13606v1/extracted/5422187/figs/frame.png"
categories: ['robustness', 'social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.13606v1/extracted/5422187/figs/frame.png)

### Summary:
- Large Language Models (LLMs) have been found to generate hallucinations and exhibit overconfidence in predictions, raising concerns about their reliability.
- This paper introduces a comprehensive investigation of Multilingual Confidence estimation (MlingConf) on LLMs, focusing on the performance of confidence estimations and proposing a cross-lingual confidence estimation method.
- The experimental results showcase the performance of various confidence estimation methods across different languages and present that the proposed cross-lingual confidence estimation technique significantly enhances confidence estimation and outperforms several baseline methods.

### Major Findings:
1. The verbalized numerical confidence estimation method emerges as the optimal method among all other estimation methods.
2. Shared language family can significantly improve the cross-lingual confidence estimation while more distinct family languages cannot bring more improvements.
3. Cross-lingual confidence estimation as self-refinement feedback performs better to improve accuracy.

### Analysis and Critique:
- The study is limited by the substantial cost associated with the API cost using GPT-4 and DeepL for translation as well as human verification checks by linguistics.
- The cross-lingual estimation simply averages the confidence scores from different languages, and more aggregation methods to ensemble multilingual confidence scores remain under-explored.
- The study makes a significant contribution towards the advancement of confidence estimation techniques to generalize across diverse linguistic contexts, thereby enhancing the reliability of the global AI system. However, further research is needed to address the limitations and explore other cross-lingual confidence estimation methods for further improvements.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.13606v1](https://arxiv.org/abs/2402.13606v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.13606v1](https://browse.arxiv.org/html/2402.13606v1)       |
| Truncated       | False       |
| Word Count       | 6443       |