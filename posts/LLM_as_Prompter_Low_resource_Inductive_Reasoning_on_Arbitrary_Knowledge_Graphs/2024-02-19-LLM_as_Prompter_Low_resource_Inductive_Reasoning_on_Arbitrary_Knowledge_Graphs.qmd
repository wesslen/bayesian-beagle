
---
title: "LLM as Prompter: Low-resource Inductive Reasoning on Arbitrary Knowledge Graphs"
id: "2402.11804v1"
description: "KG inductive reasoning with LLMs improves low-resource scenarios, outperforming previous methods in reasoning tasks."
author: Kai Wang, Yuwei Xu, Zhiyong Wu, Siqiang Luo
date: "2024-02-19"
image: "../../img/2402.11804v1/image_1.png"
categories: ['prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.11804v1/image_1.png)

### Summary:
- The PROLINK framework addresses the challenge of low-resource inductive reasoning on Knowledge Graphs (KGs) using Large Language Models (LLMs) and Graph Neural Networks (GNNs).
- The prompt calibrator component improves the quality of the LLM-based prompt graph by extracting high-confidence prompting edges that link the query relation with other relations in the KG.
- The results of inductive reasoning experiments on three series of datasets and the performance of different prompt settings in GPT-4 highlight the importance of prompt settings and the effectiveness of the proposed PROLINK framework.
- The implementation details and hyperparameters for the PROLINK model, including efficiency analysis, case studies, and detailed related work, provide crucial information about the practical aspects and implications of the model in the context of knowledge graph completion.

### Major Findings:
1. The PROLINK framework outperforms previous methods in three-shot, one-shot, and zero-shot reasoning tasks, exhibiting average performance improvements by 20%, 45%, and 147%, respectively.
2. The prompt calibrator component plays a crucial role in enhancing the quality of the prompt graph, leading to improved performance in low-resource scenarios.
3. The results of inductive reasoning experiments and the performance of different prompt settings in GPT-4 emphasize the significance of prompt settings and the effectiveness of the proposed PROLINK framework.

### Analysis and Critique:
- The PROLINK framework introduces a novel approach to address the challenge of low-resource inductive reasoning on KGs, demonstrating significant performance improvements in various reasoning tasks.
- The results provide valuable insights into the performance of different prompt settings and the impact of various components on model performance, with implications for the development of efficient and scalable methods for low-resource inductive reasoning.
- The limitations and future work outlined in the sections highlight potential areas for improvement and further research, contributing to the advancement of natural language processing research.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.11804v1](https://arxiv.org/abs/2402.11804v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.11804v1](https://browse.arxiv.org/html/2402.11804v1)       |
| Truncated       | True       |
| Word Count       | 28778       |