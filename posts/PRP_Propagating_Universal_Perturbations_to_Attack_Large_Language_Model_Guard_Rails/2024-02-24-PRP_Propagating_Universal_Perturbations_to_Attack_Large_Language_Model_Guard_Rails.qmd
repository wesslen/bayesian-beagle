
---
title: "PRP: Propagating Universal Perturbations to Attack Large Language Model Guard-Rails"
id: "2402.15911v1"
description: "LLMs vulnerable to jailbreak attacks, Guard Models ineffective against PRP attack strategy."
author: Neal Mangaokar, Ashish Hooda, Jihye Choi, Shreyas Chandrashekaran, Kassem Fawaz, Somesh Jha, Atul Prakash
date: "2024-02-24"
image: "https://browse.arxiv.org/html/2402.15911v1/x1.png"
categories: ['robustness', 'social-sciences', 'security']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.15911v1/x1.png)

### Summary:
- Large language models (LLMs) are designed to be harmless to humans, but recent work has shown that they are susceptible to automated jailbreak attacks that induce them to generate harmful content.
- Guard Models, a second LLM designed to check and moderate the output response of the primary LLM, have been incorporated into more recent LLMs to provide an additional layer of defense.
- The PRP attack strategy is successful against several open-source and closed-source implementations of Guard Models, leveraging a two-step prefix-based attack to induce harmful responses from LLMs.

### Major Findings:
1. LLMs are susceptible to automated jailbreak attacks that induce them to generate harmful content.
2. Guard Models, designed to check and moderate the output response of LLMs, are vulnerable to the PRP attack strategy.
3. The PRP attack strategy is effective across multiple threat models, including those in which the adversary has no access to the Guard Model.

### Analysis and Critique:
- The study raises concerns about the effectiveness of Guard Models in protecting LLMs from jailbreak attacks, indicating the need for further advances in defense strategies.
- The trade-off between the success of the propagation prefix and the universal adversarial prefix highlights the challenges in developing effective defense strategies against jailbreak attacks.
- The study's ethical considerations and acknowledgment of limitations demonstrate a responsible approach to disseminating findings and acknowledging the need for further evaluation.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.15911v1](https://arxiv.org/abs/2402.15911v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.15911v1](https://browse.arxiv.org/html/2402.15911v1)       |
| Truncated       | False       |
| Word Count       | 6317       |