
---
title: "Large Language Models for Secure Code Assessment: A Multi-Language Empirical Study"
id: "2408.06428v1"
description: "LLMs, like GPT-4o, effectively detect vulnerabilities in diverse languages; CodeGuardian, an LLM-assisted tool, aids developers in real-time vulnerability analysis."
author: Kohei Dozono, Tiago Espinha Gasiba, Andrea Stocco
date: "2024-08-12"
image: "https://browse.arxiv.org/html/2408.06428v1/x1.png"
categories: ['security', 'programming', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.06428v1/x1.png)

### Summary:

This paper evaluates the effectiveness of Large Language Models (LLMs) in detecting and classifying Common Weakness Enumerations (CWE) using different prompt and role strategies. The study targets six state-of-the-art pre-trained LLMs (GPT-3.5-Turbo, GPT-4 Turbo, GPT-4o, CodeLLama-7B, CodeLLama-13B, and Gemini 1.5 Pro) and five programming languages: Python, C, C++, Java, and JavaScript. The authors compiled a multi-language vulnerability dataset from different sources to ensure representativeness. The results showed that GPT-4o achieves the highest vulnerability detection and CWE classification scores using a few-shot setting. Additionally, the authors developed a library called CodeGuardian integrated with VSCode, which enables developers to perform LLM-assisted real-time vulnerability analysis in real-world security scenarios. A user study involving 22 developers from the industry showed that developers are more accurate and faster at detecting vulnerabilities using CodeGuardian.

### Major Findings:

1. GPT-4o achieves the highest vulnerability detection and CWE classification scores using a few-shot setting.
2. The study targets six state-of-the-art pre-trained LLMs and five programming languages: Python, C, C++, Java, and JavaScript.
3. The authors compiled a multi-language vulnerability dataset from different sources to ensure representativeness.
4. A library called CodeGuardian was developed, integrated with VSCode, which enables developers to perform LLM-assisted real-time vulnerability analysis in real-world security scenarios.
5. A user study involving 22 developers from the industry showed that developers are more accurate and faster at detecting vulnerabilities using CodeGuardian.

### Analysis and Critique:

The paper presents a comprehensive study on the effectiveness of LLMs in detecting and classifying CWEs using different prompt and role strategies. The authors have compiled a multi-language vulnerability dataset from different sources to ensure representativeness, which is a significant contribution to the field. The study targets six state-of-the-art pre-trained LLMs and five programming languages, making it a comprehensive evaluation

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-20       |
| Abstract | [https://arxiv.org/abs/2408.06428v1](https://arxiv.org/abs/2408.06428v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.06428v1](https://browse.arxiv.org/html/2408.06428v1)       |
| Truncated       | False       |
| Word Count       | 8522       |