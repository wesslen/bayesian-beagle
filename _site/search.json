[
  {
    "objectID": "posts/Virtual_Agents_for_Alcohol_Use_Counseling_Exploring_LLM_Powered_Motivational_Interviewing/2024-07-10-Virtual_Agents_for_Alcohol_Use_Counseling_Exploring_LLM_Powered_Motivational_Interviewing.html#major-findings",
    "href": "posts/Virtual_Agents_for_Alcohol_Use_Counseling_Exploring_LLM_Powered_Motivational_Interviewing/2024-07-10-Virtual_Agents_for_Alcohol_Use_Counseling_Exploring_LLM_Powered_Motivational_Interviewing.html#major-findings",
    "title": "Virtual Agents for Alcohol Use Counseling: Exploring LLM-Powered Motivational Interviewing",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nLLM-powered virtual agents match human counselors’ empathetic and adaptive conversational skills, presenting a significant step forward in virtual health counseling.\nThe LLM-powered virtual agent demonstrates the ability to effectively use elements of MI to facilitate behavior change.\nFrom a clinical perspective, LLM-powered virtual agents provide conversational quality that surpasses therapeutic thresholds for MI competence."
  },
  {
    "objectID": "posts/Virtual_Agents_for_Alcohol_Use_Counseling_Exploring_LLM_Powered_Motivational_Interviewing/2024-07-10-Virtual_Agents_for_Alcohol_Use_Counseling_Exploring_LLM_Powered_Motivational_Interviewing.html#analysis-and-critique",
    "href": "posts/Virtual_Agents_for_Alcohol_Use_Counseling_Exploring_LLM_Powered_Motivational_Interviewing/2024-07-10-Virtual_Agents_for_Alcohol_Use_Counseling_Exploring_LLM_Powered_Motivational_Interviewing.html#analysis-and-critique",
    "title": "Virtual Agents for Alcohol Use Counseling: Exploring LLM-Powered Motivational Interviewing",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe study’s findings suggest that LLMs have the potential to support complex counseling tasks across various health contexts.\nHowever, the study’s limitations include the small convenience samples used and the potential for LLMs to have seen and memorized data from the Anno-MI dataset.\nFuture research should focus on refining LLMs’ capabilities, such as developing prompting strategies for greater personalization and knowledge integration, enhancing the interface with multi-modal communication features, and addressing safety concerns before LLMs can be used to provide health advice directly to patients without oversight.\n\nOverall, the article presents a promising approach to addressing the global burden of health problems, including mental health disorders and substance abuse, by leveraging the capabilities of LLMs in virtual counseling. However, further research is needed to address the limitations and concerns raised in the study."
  },
  {
    "objectID": "posts/Virtual_Agents_for_Alcohol_Use_Counseling_Exploring_LLM_Powered_Motivational_Interviewing/2024-07-10-Virtual_Agents_for_Alcohol_Use_Counseling_Exploring_LLM_Powered_Motivational_Interviewing.html#appendix",
    "href": "posts/Virtual_Agents_for_Alcohol_Use_Counseling_Exploring_LLM_Powered_Motivational_Interviewing/2024-07-10-Virtual_Agents_for_Alcohol_Use_Counseling_Exploring_LLM_Powered_Motivational_Interviewing.html#appendix",
    "title": "Virtual Agents for Alcohol Use Counseling: Exploring LLM-Powered Motivational Interviewing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08095v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08095v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10434"
  },
  {
    "objectID": "posts/LLM_Internal_States_Reveal_Hallucination_Risk_Faced_With_a_Query/2024-07-03-LLM_Internal_States_Reveal_Hallucination_Risk_Faced_With_a_Query.html#appendix",
    "href": "posts/LLM_Internal_States_Reveal_Hallucination_Risk_Faced_With_a_Query/2024-07-03-LLM_Internal_States_Reveal_Hallucination_Risk_Faced_With_a_Query.html#appendix",
    "title": "LLM Internal States Reveal Hallucination Risk Faced With a Query",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03282v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03282v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11970"
  },
  {
    "objectID": "posts/Exploring_Large_Scale_Language_Models_to_Evaluate_EEG_Based_Multimodal_Data_for_Mental_Health/2024-08-14-Exploring_Large_Scale_Language_Models_to_Evaluate_EEG_Based_Multimodal_Data_for_Mental_Health.html#appendix",
    "href": "posts/Exploring_Large_Scale_Language_Models_to_Evaluate_EEG_Based_Multimodal_Data_for_Mental_Health/2024-08-14-Exploring_Large_Scale_Language_Models_to_Evaluate_EEG_Based_Multimodal_Data_for_Mental_Health.html#appendix",
    "title": "Exploring Large-Scale Language Models to Evaluate EEG-Based Multimodal Data for Mental Health",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07313v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07313v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4823"
  },
  {
    "objectID": "posts/Transferring_Backdoors_between_Large_Language_Models_by_Knowledge_Distillation/2024-08-19-Transferring_Backdoors_between_Large_Language_Models_by_Knowledge_Distillation.html#appendix",
    "href": "posts/Transferring_Backdoors_between_Large_Language_Models_by_Knowledge_Distillation/2024-08-19-Transferring_Backdoors_between_Large_Language_Models_by_Knowledge_Distillation.html#appendix",
    "title": "Transferring Backdoors between Large Language Models by Knowledge Distillation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09878v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09878v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8063"
  },
  {
    "objectID": "posts/DiscoveryBench_Towards_Data_Driven_Discovery_with_Large_Language_Models/2024-07-01-DiscoveryBench_Towards_Data_Driven_Discovery_with_Large_Language_Models.html#appendix",
    "href": "posts/DiscoveryBench_Towards_Data_Driven_Discovery_with_Large_Language_Models/2024-07-01-DiscoveryBench_Towards_Data_Driven_Discovery_with_Large_Language_Models.html#appendix",
    "title": "DiscoveryBench: Towards Data-Driven Discovery with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01725v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01725v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11425"
  },
  {
    "objectID": "posts/Can_Large_Language_Models_Reason_A_Characterization_via_3_SAT/2024-08-13-Can_Large_Language_Models_Reason_A_Characterization_via_3_SAT.html#appendix",
    "href": "posts/Can_Large_Language_Models_Reason_A_Characterization_via_3_SAT/2024-08-13-Can_Large_Language_Models_Reason_A_Characterization_via_3_SAT.html#appendix",
    "title": "Can Large Language Models Reason? A Characterization via 3-SAT",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07215v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07215v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7117"
  },
  {
    "objectID": "posts/ARMADA_Attribute_Based_Multimodal_Data_Augmentation/2024-08-19-ARMADA_Attribute_Based_Multimodal_Data_Augmentation.html#appendix",
    "href": "posts/ARMADA_Attribute_Based_Multimodal_Data_Augmentation/2024-08-19-ARMADA_Attribute_Based_Multimodal_Data_Augmentation.html#appendix",
    "title": "ARMADA: Attribute-Based Multimodal Data Augmentation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10086v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10086v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7291"
  },
  {
    "objectID": "posts/EPiC_Cost_effective_Search_based_Prompt_Engineering_of_LLMs_for_Code_Generation/2024-08-20-EPiC_Cost_effective_Search_based_Prompt_Engineering_of_LLMs_for_Code_Generation.html",
    "href": "posts/EPiC_Cost_effective_Search_based_Prompt_Engineering_of_LLMs_for_Code_Generation/2024-08-20-EPiC_Cost_effective_Search_based_Prompt_Engineering_of_LLMs_for_Code_Generation.html",
    "title": "EPiC: Cost-effective Search-based Prompt Engineering of LLMs for Code Generation",
    "section": "",
    "text": "Summary:\nThe paper introduces EPiC, a cost-effective search-based prompt engineering approach for improving code generation using Large Language Models (LLMs). EPiC leverages an evolutionary algorithm to refine prompts, resulting in enhanced code generation performance. The proposed method outperforms state-of-the-art (SOTA) methods in terms of accuracy while maintaining a competitive cost. EPiC achieved a 93.5% pass@1 rate on the HumanEval dataset and a 79% pass@1 rate on the MBPP dataset, outperforming other methods with a lower or comparable cost. The experiments also showed that incorporating randomness in the mutation process and adjusting the population size can impact the performance and cost-effectiveness of the algorithm. Furthermore, EPiC was evaluated using an open-source LLM, MagicCoder, and was found to enhance the performance of smaller models, indicating its potential applicability across various LLMs.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel approach to prompt engineering for code generation using LLMs. The proposed method, EPiC, demonstrates promising results in terms of accuracy and cost-effectiveness. However, there are some potential limitations and areas for improvement."
  },
  {
    "objectID": "posts/EPiC_Cost_effective_Search_based_Prompt_Engineering_of_LLMs_for_Code_Generation/2024-08-20-EPiC_Cost_effective_Search_based_Prompt_Engineering_of_LLMs_for_Code_Generation.html#appendix",
    "href": "posts/EPiC_Cost_effective_Search_based_Prompt_Engineering_of_LLMs_for_Code_Generation/2024-08-20-EPiC_Cost_effective_Search_based_Prompt_Engineering_of_LLMs_for_Code_Generation.html#appendix",
    "title": "EPiC: Cost-effective Search-based Prompt Engineering of LLMs for Code Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11198v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11198v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12719"
  },
  {
    "objectID": "posts/ConvoCache_Smart_Re_Use_of_Chatbot_Responses/2024-06-26-ConvoCache_Smart_Re_Use_of_Chatbot_Responses.html#appendix",
    "href": "posts/ConvoCache_Smart_Re_Use_of_Chatbot_Responses/2024-06-26-ConvoCache_Smart_Re_Use_of_Chatbot_Responses.html#appendix",
    "title": "ConvoCache: Smart Re-Use of Chatbot Responses",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18133v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18133v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4233"
  },
  {
    "objectID": "posts/Can_LLMs_Beat_Humans_in_Debating_A_Dynamic_Multi_agent_Framework_for_Competitive_Debate/2024-08-08-Can_LLMs_Beat_Humans_in_Debating_A_Dynamic_Multi_agent_Framework_for_Competitive_Debate.html#appendix",
    "href": "posts/Can_LLMs_Beat_Humans_in_Debating_A_Dynamic_Multi_agent_Framework_for_Competitive_Debate/2024-08-08-Can_LLMs_Beat_Humans_in_Debating_A_Dynamic_Multi_agent_Framework_for_Competitive_Debate.html#appendix",
    "title": "Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive Debate",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04472v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04472v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6382"
  },
  {
    "objectID": "posts/Should_We_Fine_Tune_or_RAG_Evaluating_Different_Techniques_to_Adapt_LLMs_for_Dialogue/2024-06-10-Should_We_Fine_Tune_or_RAG_Evaluating_Different_Techniques_to_Adapt_LLMs_for_Dialogue.html#appendix",
    "href": "posts/Should_We_Fine_Tune_or_RAG_Evaluating_Different_Techniques_to_Adapt_LLMs_for_Dialogue/2024-06-10-Should_We_Fine_Tune_or_RAG_Evaluating_Different_Techniques_to_Adapt_LLMs_for_Dialogue.html#appendix",
    "title": "Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06399v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06399v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3367"
  },
  {
    "objectID": "posts/Large_Language_Model_as_an_Assignment_Evaluator_Insights_Feedback_and_Challenges_in_a_1000+_Student_Course/2024-07-07-Large_Language_Model_as_an_Assignment_Evaluator_Insights_Feedback_and_Challenges_in_a_1000+_Student_Course.html#appendix",
    "href": "posts/Large_Language_Model_as_an_Assignment_Evaluator_Insights_Feedback_and_Challenges_in_a_1000+_Student_Course/2024-07-07-Large_Language_Model_as_an_Assignment_Evaluator_Insights_Feedback_and_Challenges_in_a_1000+_Student_Course.html#appendix",
    "title": "Large Language Model as an Assignment Evaluator: Insights, Feedback, and Challenges in a 1000+ Student Course",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05216v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05216v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5931"
  },
  {
    "objectID": "posts/OpenDevin_An_Open_Platform_for_AI_Software_Developers_as_Generalist_Agents/2024-07-23-OpenDevin_An_Open_Platform_for_AI_Software_Developers_as_Generalist_Agents.html",
    "href": "posts/OpenDevin_An_Open_Platform_for_AI_Software_Developers_as_Generalist_Agents/2024-07-23-OpenDevin_An_Open_Platform_for_AI_Software_Developers_as_Generalist_Agents.html",
    "title": "OpenDevin: An Open Platform for AI Software Developers as Generalist Agents",
    "section": "",
    "text": "Summary:\nOpenDevin is an open platform designed for AI software developers, offering a powerful and flexible environment for the development of AI agents that interact with the world through software. The platform supports the implementation of new agents, safe interaction with sandboxed environments for code execution, coordination between multiple agents, and incorporation of evaluation benchmarks. The architecture of OpenDevin includes an interaction mechanism, an environment consisting of a sandboxed operating system and a web browser, and an interface for agents to create complex software, execute code, and browse websites. The platform also supports multi-agent delegation and an evaluation framework for assessing agents across various tasks.\nKey Terms:\nMajor Findings:"
  },
  {
    "objectID": "posts/OpenDevin_An_Open_Platform_for_AI_Software_Developers_as_Generalist_Agents/2024-07-23-OpenDevin_An_Open_Platform_for_AI_Software_Developers_as_Generalist_Agents.html#appendix",
    "href": "posts/OpenDevin_An_Open_Platform_for_AI_Software_Developers_as_Generalist_Agents/2024-07-23-OpenDevin_An_Open_Platform_for_AI_Software_Developers_as_Generalist_Agents.html#appendix",
    "title": "OpenDevin: An Open Platform for AI Software Developers as Generalist Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16741v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16741v1\n\n\nTruncated\nTrue\n\n\nWord Count\n31157"
  },
  {
    "objectID": "posts/AI_Assisted_Generation_of_Difficult_Math_Questions/2024-07-30-AI_Assisted_Generation_of_Difficult_Math_Questions.html",
    "href": "posts/AI_Assisted_Generation_of_Difficult_Math_Questions/2024-07-30-AI_Assisted_Generation_of_Difficult_Math_Questions.html",
    "title": "AI-Assisted Generation of Difficult Math Questions",
    "section": "",
    "text": "Summary:\nThe paper presents a design framework that combines the strengths of large language models (LLMs) with a human-in-the-loop approach to generate a diverse array of challenging math questions. The framework leverages LLM metacognition skills to extract core “skills” from existing math datasets, which serve as the basis for generating novel and difficult questions. The use of two very different skills within each question makes finding such questions an “out of distribution” task for both LLMs and humans. The pipeline employs LLMs to iteratively generate and refine questions and solutions through multi-turn prompting, with human annotators verifying and further refining the questions. The proposed framework was applied to skills extracted from the MATH dataset, resulting in a dataset of higher quality math questions, as evidenced by lower performance of all models on MATH2 than on MATH and higher performance on MATH when using MATH2 questions as in-context examples.\nMajor Findings:\nAnalysis and Critique:\nThe proposed framework presents a promising approach to generating challenging math questions by combining the strengths of LLMs with a human-in-the-loop approach. The use of LLM metacognition skills to extract core “skills” from existing math datasets is an innovative approach to generating novel and difficult questions. However, the framework relies on the"
  },
  {
    "objectID": "posts/AI_Assisted_Generation_of_Difficult_Math_Questions/2024-07-30-AI_Assisted_Generation_of_Difficult_Math_Questions.html#appendix",
    "href": "posts/AI_Assisted_Generation_of_Difficult_Math_Questions/2024-07-30-AI_Assisted_Generation_of_Difficult_Math_Questions.html#appendix",
    "title": "AI-Assisted Generation of Difficult Math Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21009v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21009v1\n\n\nTruncated\nFalse\n\n\nWord Count\n22429"
  },
  {
    "objectID": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#major-findings",
    "href": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#major-findings",
    "title": "Solution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe team proposes a new instruction-tuned vision-language model with two novel ideas: grounding visual cues in the text modality and utilizing an object detection algorithm to capture complex diagrammatic visual patterns.\nThe team achieves a 27.11 WOSA score on the challenge split and qualitatively validates the effectiveness of their proposed approach.\nThe team utilizes the Segmentation Anything Model (SAM) algorithm to capture the complex visual features and uses this information as input for the LLM."
  },
  {
    "objectID": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#analysis-and-critique",
    "href": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#analysis-and-critique",
    "title": "Solution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper does not provide a detailed analysis of the performance of the proposed method compared to other state-of-the-art methods.\nThe paper does not discuss the limitations of the proposed method or any potential biases that were apparent while reviewing the text.\nThe paper does not discuss any methodological issues, conflicting evidence, or areas that require further research or clarification.\nThe paper does not provide a detailed analysis of the performance of the proposed method on different types of puzzles.\nThe paper does not discuss the generalizability of the proposed method to other types of multimodal reasoning tasks."
  },
  {
    "objectID": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#appendix",
    "href": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#appendix",
    "title": "Solution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05963v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05963v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3407"
  },
  {
    "objectID": "posts/Are_Large_Language_Models_Really_Bias_Free_Jailbreak_Prompts_for_Assessing_Adversarial_Robustness_to_Bias_Elicitation/2024-07-11-Are_Large_Language_Models_Really_Bias_Free_Jailbreak_Prompts_for_Assessing_Adversarial_Robustness_to_Bias_Elicitation.html#appendix",
    "href": "posts/Are_Large_Language_Models_Really_Bias_Free_Jailbreak_Prompts_for_Assessing_Adversarial_Robustness_to_Bias_Elicitation/2024-07-11-Are_Large_Language_Models_Really_Bias_Free_Jailbreak_Prompts_for_Assessing_Adversarial_Robustness_to_Bias_Elicitation.html#appendix",
    "title": "Are Large Language Models Really Bias-Free? Jailbreak Prompts for Assessing Adversarial Robustness to Bias Elicitation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08441v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08441v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5194"
  },
  {
    "objectID": "posts/Large_Language_Models_for_Anomaly_Detection_in_Computational_Workflows_from_Supervised_Fine_Tuning_to_In_Context_Learning/2024-07-24-Large_Language_Models_for_Anomaly_Detection_in_Computational_Workflows_from_Supervised_Fine_Tuning_to_In_Context_Learning.html#appendix",
    "href": "posts/Large_Language_Models_for_Anomaly_Detection_in_Computational_Workflows_from_Supervised_Fine_Tuning_to_In_Context_Learning/2024-07-24-Large_Language_Models_for_Anomaly_Detection_in_Computational_Workflows_from_Supervised_Fine_Tuning_to_In_Context_Learning.html#appendix",
    "title": "Large Language Models for Anomaly Detection in Computational Workflows: from Supervised Fine-Tuning to In-Context Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17545v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17545v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8769"
  },
  {
    "objectID": "posts/NeBuLa_A_discourse_aware_Minecraft_Builder/2024-06-26-NeBuLa_A_discourse_aware_Minecraft_Builder.html#appendix",
    "href": "posts/NeBuLa_A_discourse_aware_Minecraft_Builder/2024-06-26-NeBuLa_A_discourse_aware_Minecraft_Builder.html#appendix",
    "title": "NeBuLa: A discourse aware Minecraft Builder",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18164v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18164v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6185"
  },
  {
    "objectID": "posts/Enhancing_Repository_Level_Code_Generation_with_Integrated_Contextual_Information/2024-06-05-Enhancing_Repository_Level_Code_Generation_with_Integrated_Contextual_Information.html#appendix",
    "href": "posts/Enhancing_Repository_Level_Code_Generation_with_Integrated_Contextual_Information/2024-06-05-Enhancing_Repository_Level_Code_Generation_with_Integrated_Contextual_Information.html#appendix",
    "title": "Enhancing Repository-Level Code Generation with Integrated Contextual Information",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03283v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03283v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9447"
  },
  {
    "objectID": "posts/Customizing_Language_Models_with_Instance_wise_LoRA_for_Sequential_Recommendation/2024-08-19-Customizing_Language_Models_with_Instance_wise_LoRA_for_Sequential_Recommendation.html#appendix",
    "href": "posts/Customizing_Language_Models_with_Instance_wise_LoRA_for_Sequential_Recommendation/2024-08-19-Customizing_Language_Models_with_Instance_wise_LoRA_for_Sequential_Recommendation.html#appendix",
    "title": "Customizing Language Models with Instance-wise LoRA for Sequential Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10159v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10159v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7624"
  },
  {
    "objectID": "posts/AutoCAP_Towards_Automatic_Cross_lingual_Alignment_Planning_for_Zero_shot_Chain_of_Thought/2024-06-20-AutoCAP_Towards_Automatic_Cross_lingual_Alignment_Planning_for_Zero_shot_Chain_of_Thought.html#appendix",
    "href": "posts/AutoCAP_Towards_Automatic_Cross_lingual_Alignment_Planning_for_Zero_shot_Chain_of_Thought/2024-06-20-AutoCAP_Towards_Automatic_Cross_lingual_Alignment_Planning_for_Zero_shot_Chain_of_Thought.html#appendix",
    "title": "AutoCAP: Towards Automatic Cross-lingual Alignment Planning for Zero-shot Chain-of-Thought",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13940v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13940v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4960"
  },
  {
    "objectID": "posts/Accessing_GPT_4_level_Mathematical_Olympiad_Solutions_via_Monte_Carlo_Tree_Self_refine_with_LLaMa_3_8B/2024-06-11-Accessing_GPT_4_level_Mathematical_Olympiad_Solutions_via_Monte_Carlo_Tree_Self_refine_with_LLaMa_3_8B.html#appendix",
    "href": "posts/Accessing_GPT_4_level_Mathematical_Olympiad_Solutions_via_Monte_Carlo_Tree_Self_refine_with_LLaMa_3_8B/2024-06-11-Accessing_GPT_4_level_Mathematical_Olympiad_Solutions_via_Monte_Carlo_Tree_Self_refine_with_LLaMa_3_8B.html#appendix",
    "title": "Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07394v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07394v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5818"
  },
  {
    "objectID": "posts/MMTrail_A_Multimodal_Trailer_Video_Dataset_with_Language_and_Music_Descriptions/2024-07-30-MMTrail_A_Multimodal_Trailer_Video_Dataset_with_Language_and_Music_Descriptions.html#appendix",
    "href": "posts/MMTrail_A_Multimodal_Trailer_Video_Dataset_with_Language_and_Music_Descriptions/2024-07-30-MMTrail_A_Multimodal_Trailer_Video_Dataset_with_Language_and_Music_Descriptions.html#appendix",
    "title": "MMTrail: A Multimodal Trailer Video Dataset with Language and Music Descriptions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20962v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20962v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6360"
  },
  {
    "objectID": "posts/Causal_Inference_with_Latent_Variables_Recent_Advances_and_Future_Prospectives/2024-06-20-Causal_Inference_with_Latent_Variables_Recent_Advances_and_Future_Prospectives.html#appendix",
    "href": "posts/Causal_Inference_with_Latent_Variables_Recent_Advances_and_Future_Prospectives/2024-06-20-Causal_Inference_with_Latent_Variables_Recent_Advances_and_Future_Prospectives.html#appendix",
    "title": "Causal Inference with Latent Variables: Recent Advances and Future Prospectives",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13966v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13966v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11886"
  },
  {
    "objectID": "posts/S2D_Sorted_Speculative_Decoding_For_More_Efficient_Deployment_of_Nested_Large_Language_Models/2024-07-02-S2D_Sorted_Speculative_Decoding_For_More_Efficient_Deployment_of_Nested_Large_Language_Models.html#appendix",
    "href": "posts/S2D_Sorted_Speculative_Decoding_For_More_Efficient_Deployment_of_Nested_Large_Language_Models/2024-07-02-S2D_Sorted_Speculative_Decoding_For_More_Efficient_Deployment_of_Nested_Large_Language_Models.html#appendix",
    "title": "S2D: Sorted Speculative Decoding For More Efficient Deployment of Nested Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01955v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01955v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6189"
  },
  {
    "objectID": "posts/Paraphrase_and_Aggregate_with_Large_Language_Models_for_Minimizing_Intent_Classification_Errors/2024-06-24-Paraphrase_and_Aggregate_with_Large_Language_Models_for_Minimizing_Intent_Classification_Errors.html#appendix",
    "href": "posts/Paraphrase_and_Aggregate_with_Large_Language_Models_for_Minimizing_Intent_Classification_Errors/2024-06-24-Paraphrase_and_Aggregate_with_Large_Language_Models_for_Minimizing_Intent_Classification_Errors.html#appendix",
    "title": "Paraphrase and Aggregate with Large Language Models for Minimizing Intent Classification Errors",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17163v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17163v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4269"
  },
  {
    "objectID": "posts/CogMG_Collaborative_Augmentation_Between_Large_Language_Model_and_Knowledge_Graph/2024-06-25-CogMG_Collaborative_Augmentation_Between_Large_Language_Model_and_Knowledge_Graph.html#appendix",
    "href": "posts/CogMG_Collaborative_Augmentation_Between_Large_Language_Model_and_Knowledge_Graph/2024-06-25-CogMG_Collaborative_Augmentation_Between_Large_Language_Model_and_Knowledge_Graph.html#appendix",
    "title": "CogMG: Collaborative Augmentation Between Large Language Model and Knowledge Graph",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17231v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17231v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4470"
  },
  {
    "objectID": "posts/Icing_on_the_Cake_Automatic_Code_Summarization_at_Ericsson/2024-08-19-Icing_on_the_Cake_Automatic_Code_Summarization_at_Ericsson.html#appendix",
    "href": "posts/Icing_on_the_Cake_Automatic_Code_Summarization_at_Ericsson/2024-08-19-Icing_on_the_Cake_Automatic_Code_Summarization_at_Ericsson.html#appendix",
    "title": "Icing on the Cake: Automatic Code Summarization at Ericsson",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09735v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09735v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7985"
  },
  {
    "objectID": "posts/Explicit_Inductive_Inference_using_Large_Language_Models/2024-08-26-Explicit_Inductive_Inference_using_Large_Language_Models.html#appendix",
    "href": "posts/Explicit_Inductive_Inference_using_Large_Language_Models/2024-08-26-Explicit_Inductive_Inference_using_Large_Language_Models.html#appendix",
    "title": "Explicit Inductive Inference using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.14467v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.14467v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4032"
  },
  {
    "objectID": "posts/Digital_Avatars_Framework_Development_and_Their_Evaluation/2024-08-07-Digital_Avatars_Framework_Development_and_Their_Evaluation.html#appendix",
    "href": "posts/Digital_Avatars_Framework_Development_and_Their_Evaluation/2024-08-07-Digital_Avatars_Framework_Development_and_Their_Evaluation.html#appendix",
    "title": "Digital Avatars: Framework Development and Their Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04068v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04068v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2722"
  },
  {
    "objectID": "posts/Whats_in_an_embedding_Would_a_rose_by_any_embedding_smell_as_sweet/2024-06-11-Whats_in_an_embedding_Would_a_rose_by_any_embedding_smell_as_sweet.html#appendix",
    "href": "posts/Whats_in_an_embedding_Would_a_rose_by_any_embedding_smell_as_sweet/2024-06-11-Whats_in_an_embedding_Would_a_rose_by_any_embedding_smell_as_sweet.html#appendix",
    "title": "What’s in an embedding? Would a rose by any embedding smell as sweet?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06870v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06870v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5609"
  },
  {
    "objectID": "posts/Draw_Like_an_Artist_Complex_Scene_Generation_with_Diffusion_Model_via_Composition_Painting_and_Retouching/2024-08-25-Draw_Like_an_Artist_Complex_Scene_Generation_with_Diffusion_Model_via_Composition_Painting_and_Retouching.html#appendix",
    "href": "posts/Draw_Like_an_Artist_Complex_Scene_Generation_with_Diffusion_Model_via_Composition_Painting_and_Retouching/2024-08-25-Draw_Like_an_Artist_Complex_Scene_Generation_with_Diffusion_Model_via_Composition_Painting_and_Retouching.html#appendix",
    "title": "Draw Like an Artist: Complex Scene Generation with Diffusion Model via Composition, Painting, and Retouching",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.13858v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.13858v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4933"
  },
  {
    "objectID": "posts/Knowledge_Mechanisms_in_Large_Language_Models_A_Survey_and_Perspective/2024-07-22-Knowledge_Mechanisms_in_Large_Language_Models_A_Survey_and_Perspective.html",
    "href": "posts/Knowledge_Mechanisms_in_Large_Language_Models_A_Survey_and_Perspective/2024-07-22-Knowledge_Mechanisms_in_Large_Language_Models_A_Survey_and_Perspective.html",
    "title": "Knowledge Mechanisms in Large Language Models: A Survey and Perspective",
    "section": "",
    "text": "Summary:\nThis paper reviews the knowledge mechanisms in Large Language Models (LLMs) and proposes a novel taxonomy across the entire life cycle of LLMs. The taxonomy encompasses knowledge utilization at a specific time and knowledge evolution across all periods of LLMs. The paper introduces preliminaries of this field and reviews knowledge utilization mechanisms from a new perspective. It also delves into the fundamental principles for knowledge evolution and discusses challenges of knowledge utilization, and posits some promising hypotheses to explore potential avenues for developing powerful and trustworthy models. The paper also provides some future directions and tools for knowledge mechanism analysis.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive review of the knowledge mechanisms in LLMs and proposes a novel taxonomy for knowledge mechanisms in LLMs. The paper introduces a new perspective to analyze knowledge utilization mechanisms from three levels: memorization, comprehension and application, and creation. The paper also discusses knowledge evolution in individual and group LLMs, and analyzes the inherent conflicts and integration in this process. However, the paper does not provide empirical evidence to support its hypotheses and does not discuss the limitations of its proposed taxonomy. The paper also does not discuss the ethical implications of its proposed taxonomy."
  },
  {
    "objectID": "posts/Knowledge_Mechanisms_in_Large_Language_Models_A_Survey_and_Perspective/2024-07-22-Knowledge_Mechanisms_in_Large_Language_Models_A_Survey_and_Perspective.html#appendix",
    "href": "posts/Knowledge_Mechanisms_in_Large_Language_Models_A_Survey_and_Perspective/2024-07-22-Knowledge_Mechanisms_in_Large_Language_Models_A_Survey_and_Perspective.html#appendix",
    "title": "Knowledge Mechanisms in Large Language Models: A Survey and Perspective",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.15017v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.15017v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18185"
  },
  {
    "objectID": "posts/PostMark_A_Robust_Blackbox_Watermark_for_Large_Language_Models/2024-06-20-PostMark_A_Robust_Blackbox_Watermark_for_Large_Language_Models.html#appendix",
    "href": "posts/PostMark_A_Robust_Blackbox_Watermark_for_Large_Language_Models/2024-06-20-PostMark_A_Robust_Blackbox_Watermark_for_Large_Language_Models.html#appendix",
    "title": "PostMark: A Robust Blackbox Watermark for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14517v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14517v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10409"
  },
  {
    "objectID": "posts/Do_they_mean_us_Interpreting_Referring_Expressions_in_Intergroup_Bias/2024-06-25-Do_they_mean_us_Interpreting_Referring_Expressions_in_Intergroup_Bias.html",
    "href": "posts/Do_they_mean_us_Interpreting_Referring_Expressions_in_Intergroup_Bias/2024-06-25-Do_they_mean_us_Interpreting_Referring_Expressions_in_Intergroup_Bias.html",
    "title": "Do they mean ‘us’? Interpreting Referring Expressions in Intergroup Bias",
    "section": "",
    "text": "Summary:\nThis paper presents a study on intergroup bias in language, focusing on the variations in language used by in-group and out-group members in online sports forums. The authors curate a unique dataset of over 6 million game-time comments from opposing perspectives in NFL team subreddits, each comment grounded in non-linguistic descriptions of the events that precipitated these comments. The study reveals that modeling the bias through tagging of implicit and explicit referring expressions requires a rich, contextual understanding of language and the world. The authors use LLMs for automated tagging and discover that some LLMs perform best when prompted with linguistic descriptions of the win probability at the time of the comment. Large-scale tagging of comments using LLMs uncovers linear variations in the form of referent across win probabilities that distinguish in-group and out-group utterances.\nMajor Findings:"
  },
  {
    "objectID": "posts/Do_they_mean_us_Interpreting_Referring_Expressions_in_Intergroup_Bias/2024-06-25-Do_they_mean_us_Interpreting_Referring_Expressions_in_Intergroup_Bias.html#appendix",
    "href": "posts/Do_they_mean_us_Interpreting_Referring_Expressions_in_Intergroup_Bias/2024-06-25-Do_they_mean_us_Interpreting_Referring_Expressions_in_Intergroup_Bias.html#appendix",
    "title": "Do they mean ‘us’? Interpreting Referring Expressions in Intergroup Bias",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17947v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17947v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14790"
  },
  {
    "objectID": "posts/Investigating_the_Influence_of_Prompt_Specific_Shortcuts_in_AI_Generated_Text_Detection/2024-06-24-Investigating_the_Influence_of_Prompt_Specific_Shortcuts_in_AI_Generated_Text_Detection.html#appendix",
    "href": "posts/Investigating_the_Influence_of_Prompt_Specific_Shortcuts_in_AI_Generated_Text_Detection/2024-06-24-Investigating_the_Influence_of_Prompt_Specific_Shortcuts_in_AI_Generated_Text_Detection.html#appendix",
    "title": "Investigating the Influence of Prompt-Specific Shortcuts in AI Generated Text Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16275v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16275v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8427"
  },
  {
    "objectID": "posts/Large_Language_Models_are_Good_Attackers_Efficient_and_Stealthy_Textual_Backdoor_Attacks/2024-08-21-Large_Language_Models_are_Good_Attackers_Efficient_and_Stealthy_Textual_Backdoor_Attacks.html#appendix",
    "href": "posts/Large_Language_Models_are_Good_Attackers_Efficient_and_Stealthy_Textual_Backdoor_Attacks/2024-08-21-Large_Language_Models_are_Good_Attackers_Efficient_and_Stealthy_Textual_Backdoor_Attacks.html#appendix",
    "title": "Large Language Models are Good Attackers: Efficient and Stealthy Textual Backdoor Attacks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11587v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11587v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10651"
  },
  {
    "objectID": "posts/New_intelligent_empowerment_for_digital_transformation/2024-06-26-New_intelligent_empowerment_for_digital_transformation.html",
    "href": "posts/New_intelligent_empowerment_for_digital_transformation/2024-06-26-New_intelligent_empowerment_for_digital_transformation.html",
    "title": "New intelligent empowerment for digital transformation",
    "section": "",
    "text": "Summary:\nThis study proposes a novel evaluation method for measuring the digital transformation (DT) process of enterprises based on large language models (LLMs). The authors analyzed annual reports of 4407 companies listed on the New York Stock Exchange and Nasdaq from 2005 to 2022, constructing a comprehensive set of DT indicators. The findings reveal that DT significantly improves a company’s financial performance, but different digital technologies have varying effects on financial performance. Specifically, blockchain technology has a relatively limited positive impact on financial performance. Additionally, DT can promote the growth of financial performance by enhancing operational efficiency and reducing costs.\nMajor Findings:\nAnalysis and Critique:\nThe study provides a novel DT evaluation tool for the academic community and expands the application scope of generative artificial intelligence technology in economic research. However, several limitations and potential biases should be considered:"
  },
  {
    "objectID": "posts/New_intelligent_empowerment_for_digital_transformation/2024-06-26-New_intelligent_empowerment_for_digital_transformation.html#appendix",
    "href": "posts/New_intelligent_empowerment_for_digital_transformation/2024-06-26-New_intelligent_empowerment_for_digital_transformation.html#appendix",
    "title": "New intelligent empowerment for digital transformation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18440v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18440v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17294"
  },
  {
    "objectID": "posts/Detecting_and_Understanding_Vulnerabilities_in_Language_Models_via_Mechanistic_Interpretability/2024-07-29-Detecting_and_Understanding_Vulnerabilities_in_Language_Models_via_Mechanistic_Interpretability.html#appendix",
    "href": "posts/Detecting_and_Understanding_Vulnerabilities_in_Language_Models_via_Mechanistic_Interpretability/2024-07-29-Detecting_and_Understanding_Vulnerabilities_in_Language_Models_via_Mechanistic_Interpretability.html#appendix",
    "title": "Detecting and Understanding Vulnerabilities in Language Models via Mechanistic Interpretability",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19842v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19842v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6824"
  },
  {
    "objectID": "posts/Every_Language_Counts_Learn_and_Unlearn_in_Multilingual_LLMs/2024-06-19-Every_Language_Counts_Learn_and_Unlearn_in_Multilingual_LLMs.html#appendix",
    "href": "posts/Every_Language_Counts_Learn_and_Unlearn_in_Multilingual_LLMs/2024-06-19-Every_Language_Counts_Learn_and_Unlearn_in_Multilingual_LLMs.html#appendix",
    "title": "Every Language Counts: Learn and Unlearn in Multilingual LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13748v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13748v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5047"
  },
  {
    "objectID": "posts/Can_Reinforcement_Learning_Unlock_the_Hidden_Dangers_in_Aligned_Large_Language_Models/2024-08-05-Can_Reinforcement_Learning_Unlock_the_Hidden_Dangers_in_Aligned_Large_Language_Models.html#appendix",
    "href": "posts/Can_Reinforcement_Learning_Unlock_the_Hidden_Dangers_in_Aligned_Large_Language_Models/2024-08-05-Can_Reinforcement_Learning_Unlock_the_Hidden_Dangers_in_Aligned_Large_Language_Models.html#appendix",
    "title": "Can Reinforcement Learning Unlock the Hidden Dangers in Aligned Large Language Models?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02651v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02651v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5420"
  },
  {
    "objectID": "posts/Advancing_Multimodal_Large_Language_Models_in_Chart_Question_Answering_with_Visualization_Referenced_Instruction_Tuning/2024-07-29-Advancing_Multimodal_Large_Language_Models_in_Chart_Question_Answering_with_Visualization_Referenced_Instruction_Tuning.html#appendix",
    "href": "posts/Advancing_Multimodal_Large_Language_Models_in_Chart_Question_Answering_with_Visualization_Referenced_Instruction_Tuning/2024-07-29-Advancing_Multimodal_Large_Language_Models_in_Chart_Question_Answering_with_Visualization_Referenced_Instruction_Tuning.html#appendix",
    "title": "Advancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20174v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20174v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11032"
  },
  {
    "objectID": "posts/Estimating_Contribution_Quality_in_Online_Deliberations_Using_a_Large_Language_Model/2024-08-21-Estimating_Contribution_Quality_in_Online_Deliberations_Using_a_Large_Language_Model.html#appendix",
    "href": "posts/Estimating_Contribution_Quality_in_Online_Deliberations_Using_a_Large_Language_Model/2024-08-21-Estimating_Contribution_Quality_in_Online_Deliberations_Using_a_Large_Language_Model.html#appendix",
    "title": "Estimating Contribution Quality in Online Deliberations Using a Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11936v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11936v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8672"
  },
  {
    "objectID": "posts/Talk_With_Human_like_Agents_Empathetic_Dialogue_Through_Perceptible_Acoustic_Reception_and_Reaction/2024-06-18-Talk_With_Human_like_Agents_Empathetic_Dialogue_Through_Perceptible_Acoustic_Reception_and_Reaction.html#appendix",
    "href": "posts/Talk_With_Human_like_Agents_Empathetic_Dialogue_Through_Perceptible_Acoustic_Reception_and_Reaction/2024-06-18-Talk_With_Human_like_Agents_Empathetic_Dialogue_Through_Perceptible_Acoustic_Reception_and_Reaction.html#appendix",
    "title": "Talk With Human-like Agents: Empathetic Dialogue Through Perceptible Acoustic Reception and Reaction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12707v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12707v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6339"
  },
  {
    "objectID": "posts/Evidence_of_a_log_scaling_law_for_political_persuasion_with_large_language_models/2024-06-20-Evidence_of_a_log_scaling_law_for_political_persuasion_with_large_language_models.html#appendix",
    "href": "posts/Evidence_of_a_log_scaling_law_for_political_persuasion_with_large_language_models/2024-06-20-Evidence_of_a_log_scaling_law_for_political_persuasion_with_large_language_models.html#appendix",
    "title": "Evidence of a log scaling law for political persuasion with large language models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14508v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14508v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9012"
  },
  {
    "objectID": "posts/AutoScale_Automatic_Prediction_of_Compute_optimal_Data_Composition_for_Training_LLMs/2024-07-29-AutoScale_Automatic_Prediction_of_Compute_optimal_Data_Composition_for_Training_LLMs.html#appendix",
    "href": "posts/AutoScale_Automatic_Prediction_of_Compute_optimal_Data_Composition_for_Training_LLMs/2024-07-29-AutoScale_Automatic_Prediction_of_Compute_optimal_Data_Composition_for_Training_LLMs.html#appendix",
    "title": "AutoScale: Automatic Prediction of Compute-optimal Data Composition for Training LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20177v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20177v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11502"
  },
  {
    "objectID": "posts/Gender_Race_and_Intersectional_Bias_in_Resume_Screening_via_Language_Model_Retrieval/2024-07-29-Gender_Race_and_Intersectional_Bias_in_Resume_Screening_via_Language_Model_Retrieval.html#appendix",
    "href": "posts/Gender_Race_and_Intersectional_Bias_in_Resume_Screening_via_Language_Model_Retrieval/2024-07-29-Gender_Race_and_Intersectional_Bias_in_Resume_Screening_via_Language_Model_Retrieval.html#appendix",
    "title": "Gender, Race, and Intersectional Bias in Resume Screening via Language Model Retrieval",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20371v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20371v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9882"
  },
  {
    "objectID": "posts/What_can_Large_Language_Models_Capture_about_Code_Functional_Equivalence/2024-08-20-What_can_Large_Language_Models_Capture_about_Code_Functional_Equivalence.html",
    "href": "posts/What_can_Large_Language_Models_Capture_about_Code_Functional_Equivalence/2024-08-20-What_can_Large_Language_Models_Capture_about_Code_Functional_Equivalence.html",
    "title": "What can Large Language Models Capture about Code Functional Equivalence?",
    "section": "",
    "text": "Summary: The paper “What can Large Language Models Capture about Code Functional Equivalence?” by Nickil Maveli, Antonio Vergari, and Shay B. Cohen explores the ability of Code-LLMs (LLMs pre-trained on large code corpora) to understand code semantics and functional equivalence. The authors introduce SeqCoBench, a benchmark for evaluating Code-LLMs’ ability to capture code functional equivalence. SeqCoBench contains over 20 code transformations that either preserve or alter the semantics of Python programs. The paper presents extensive evaluations of state-of-the-art (Code-)LLMs in different settings, including zero-shot and parameter-efficient finetuning methods. The results show that the performance gap between these LLMs and classical match-based retrieval scores is minimal, with both approaches showing a concerning lack of depth in understanding code semantics"
  },
  {
    "objectID": "posts/What_can_Large_Language_Models_Capture_about_Code_Functional_Equivalence/2024-08-20-What_can_Large_Language_Models_Capture_about_Code_Functional_Equivalence.html#appendix",
    "href": "posts/What_can_Large_Language_Models_Capture_about_Code_Functional_Equivalence/2024-08-20-What_can_Large_Language_Models_Capture_about_Code_Functional_Equivalence.html#appendix",
    "title": "What can Large Language Models Capture about Code Functional Equivalence?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11081v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11081v1\n\n\nTruncated\nTrue\n\n\nWord Count\n33204"
  },
  {
    "objectID": "posts/LayoutCopilot_An_LLM_powered_Multi_agent_Collaborative_Framework_for_Interactive_Analog_Layout_Design/2024-06-27-LayoutCopilot_An_LLM_powered_Multi_agent_Collaborative_Framework_for_Interactive_Analog_Layout_Design.html#appendix",
    "href": "posts/LayoutCopilot_An_LLM_powered_Multi_agent_Collaborative_Framework_for_Interactive_Analog_Layout_Design/2024-06-27-LayoutCopilot_An_LLM_powered_Multi_agent_Collaborative_Framework_for_Interactive_Analog_Layout_Design.html#appendix",
    "title": "LayoutCopilot: An LLM-powered Multi-agent Collaborative Framework for Interactive Analog Layout Design",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18873v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18873v1\n\n\nTruncated\nFalse\n\n\nWord Count\n91"
  },
  {
    "objectID": "posts/Themis_Towards_Flexible_and_Interpretable_NLG_Evaluation/2024-06-26-Themis_Towards_Flexible_and_Interpretable_NLG_Evaluation.html#appendix",
    "href": "posts/Themis_Towards_Flexible_and_Interpretable_NLG_Evaluation/2024-06-26-Themis_Towards_Flexible_and_Interpretable_NLG_Evaluation.html#appendix",
    "title": "Themis: Towards Flexible and Interpretable NLG Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18365v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18365v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6245"
  },
  {
    "objectID": "posts/Raccoon_Prompt_Extraction_Benchmark_of_LLM_Integrated_Applications/2024-06-10-Raccoon_Prompt_Extraction_Benchmark_of_LLM_Integrated_Applications.html#appendix",
    "href": "posts/Raccoon_Prompt_Extraction_Benchmark_of_LLM_Integrated_Applications/2024-06-10-Raccoon_Prompt_Extraction_Benchmark_of_LLM_Integrated_Applications.html#appendix",
    "title": "Raccoon: Prompt Extraction Benchmark of LLM-Integrated Applications",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06737v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06737v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6069"
  },
  {
    "objectID": "posts/CollectiveSFT_Scaling_Large_Language_Models_for_Chinese_Medical_Benchmark_with_Collective_Instructions_in_Healthcare/2024-07-30-CollectiveSFT_Scaling_Large_Language_Models_for_Chinese_Medical_Benchmark_with_Collective_Instructions_in_Healthcare.html#appendix",
    "href": "posts/CollectiveSFT_Scaling_Large_Language_Models_for_Chinese_Medical_Benchmark_with_Collective_Instructions_in_Healthcare/2024-07-30-CollectiveSFT_Scaling_Large_Language_Models_for_Chinese_Medical_Benchmark_with_Collective_Instructions_in_Healthcare.html#appendix",
    "title": "CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19705v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19705v2\n\n\nTruncated\nFalse\n\n\nWord Count\n3001"
  },
  {
    "objectID": "posts/Do_Large_Language_Models_Have_Compositional_Ability_An_Investigation_into_Limitations_and_Scalability/2024-07-22-Do_Large_Language_Models_Have_Compositional_Ability_An_Investigation_into_Limitations_and_Scalability.html#appendix",
    "href": "posts/Do_Large_Language_Models_Have_Compositional_Ability_An_Investigation_into_Limitations_and_Scalability/2024-07-22-Do_Large_Language_Models_Have_Compositional_Ability_An_Investigation_into_Limitations_and_Scalability.html#appendix",
    "title": "Do Large Language Models Have Compositional Ability? An Investigation into Limitations and Scalability",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.15720v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.15720v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12338"
  },
  {
    "objectID": "posts/ObscurePrompt_Jailbreaking_Large_Language_Models_via_Obscure_Input/2024-06-19-ObscurePrompt_Jailbreaking_Large_Language_Models_via_Obscure_Input.html#appendix",
    "href": "posts/ObscurePrompt_Jailbreaking_Large_Language_Models_via_Obscure_Input/2024-06-19-ObscurePrompt_Jailbreaking_Large_Language_Models_via_Obscure_Input.html#appendix",
    "title": "ObscurePrompt: Jailbreaking Large Language Models via Obscure Input",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13662v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13662v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7246"
  },
  {
    "objectID": "posts/Learning_to_Generate_Answers_with_Citations_via_Factual_Consistency_Models/2024-06-19-Learning_to_Generate_Answers_with_Citations_via_Factual_Consistency_Models.html#appendix",
    "href": "posts/Learning_to_Generate_Answers_with_Citations_via_Factual_Consistency_Models/2024-06-19-Learning_to_Generate_Answers_with_Citations_via_Factual_Consistency_Models.html#appendix",
    "title": "Learning to Generate Answers with Citations via Factual Consistency Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13124v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13124v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13245"
  },
  {
    "objectID": "posts/LIT_Large_Language_Model_Driven_Intention_Tracking_for_Proactive_Human_Robot_Collaboration____A_Robot_Sous_Chef_Application/2024-06-19-LIT_Large_Language_Model_Driven_Intention_Tracking_for_Proactive_Human_Robot_Collaboration____A_Robot_Sous_Chef_Application.html#appendix",
    "href": "posts/LIT_Large_Language_Model_Driven_Intention_Tracking_for_Proactive_Human_Robot_Collaboration____A_Robot_Sous_Chef_Application/2024-06-19-LIT_Large_Language_Model_Driven_Intention_Tracking_for_Proactive_Human_Robot_Collaboration____A_Robot_Sous_Chef_Application.html#appendix",
    "title": "LIT: Large Language Model Driven Intention Tracking for Proactive Human-Robot Collaboration – A Robot Sous-Chef Application",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13787v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13787v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3696"
  },
  {
    "objectID": "posts/Galapagos_Automated_N_Version_Programming_with_LLMs/2024-08-18-Galapagos_Automated_N_Version_Programming_with_LLMs.html",
    "href": "posts/Galapagos_Automated_N_Version_Programming_with_LLMs/2024-08-18-Galapagos_Automated_N_Version_Programming_with_LLMs.html",
    "title": "Galápagos: Automated N-Version Programming with LLMs",
    "section": "",
    "text": "Summary:\nGalápagos is a tool for automated N-Version programming using large language models (LLMs). It generates program variants, validates their correctness and equivalence, and assembles N-Version binaries. The tool is evaluated by creating N-Version components of real-world C code. The results show that Galápagos can produce functionally equivalent program variants, even when written in different programming languages. The variants exhibit static and dynamic diversity, and can protect C code against miscompilation bugs in the Clang compiler.\nMajor Findings:\nAnalysis and Critique:\nWhile Galápagos shows promising results in automating N-Version programming with LLMs, there are potential limitations and areas for improvement. The tool’s reliance on LLMs for generating variants introduces the risk of incorrect or non-equivalent code, which is mitigated by formal verification but may still impact the overall performance and reliability of the generated N-Version components. Additionally, the evaluation focuses on C code and the Clang compiler, and further research is needed to assess the tool’s effectiveness with other programming languages and compilers. Lastly, the scalability and efficiency of Galápagos in handling larger and more complex codebases should be investigated to ensure its practical applicability in real-world software development scenarios."
  },
  {
    "objectID": "posts/Galapagos_Automated_N_Version_Programming_with_LLMs/2024-08-18-Galapagos_Automated_N_Version_Programming_with_LLMs.html#appendix",
    "href": "posts/Galapagos_Automated_N_Version_Programming_with_LLMs/2024-08-18-Galapagos_Automated_N_Version_Programming_with_LLMs.html#appendix",
    "title": "Galápagos: Automated N-Version Programming with LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09536v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09536v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11203"
  },
  {
    "objectID": "posts/Blending_LLMs_into_Cascaded_Speech_Translation_KITs_Offline_Speech_Translation_System_for_IWSLT_2024/2024-06-24-Blending_LLMs_into_Cascaded_Speech_Translation_KITs_Offline_Speech_Translation_System_for_IWSLT_2024.html#appendix",
    "href": "posts/Blending_LLMs_into_Cascaded_Speech_Translation_KITs_Offline_Speech_Translation_System_for_IWSLT_2024/2024-06-24-Blending_LLMs_into_Cascaded_Speech_Translation_KITs_Offline_Speech_Translation_System_for_IWSLT_2024.html#appendix",
    "title": "Blending LLMs into Cascaded Speech Translation: KIT’s Offline Speech Translation System for IWSLT 2024",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16777v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16777v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4916"
  },
  {
    "objectID": "posts/Improving_Weak_to_Strong_Generalization_with_Reliability_Aware_Alignment/2024-06-27-Improving_Weak_to_Strong_Generalization_with_Reliability_Aware_Alignment.html",
    "href": "posts/Improving_Weak_to_Strong_Generalization_with_Reliability_Aware_Alignment/2024-06-27-Improving_Weak_to_Strong_Generalization_with_Reliability_Aware_Alignment.html",
    "title": "Improving Weak-to-Strong Generalization with Reliability-Aware Alignment",
    "section": "",
    "text": "Summary: The paper addresses the challenge of aligning strong language models with weak supervision signals, focusing on the “super-alignment” problem of aligning super-human language models with human knowledge. The authors propose an unsupervised method to enhance weak-to-strong generalization through reliability-aware alignment. This involves generating prompt variations, assessing the reliability of responses using entropy-based uncertainty and probability-based reliability metrics, and applying reliability-aware techniques such as uncertainty filtering and reliability re-weighting during the alignment process. Experimental results on four datasets demonstrated that the proposed methods effectively identified high-quality weak labels and significantly improved alignment robustness compared to baseline approaches.\nMajor Findings: 1. The proposed unsupervised method for enhancing weak-to-strong generalization through reliability-aware alignment effectively identifies high-quality weak labels and significantly improves alignment robustness compared to baseline approaches. 2. The method involves generating prompt variations, assessing the reliability of responses using entropy-based uncertainty and probability-based reliability metrics, and applying reliability-aware techniques such as uncertainty filtering and reliability re-weighting during the alignment process. 3. Experimental results on four datasets demonstrated the effectiveness of the proposed methods in improving weak-to-strong generalization.\nAnalysis and Critique: 1. The proposed method introduces significant computational overhead due to querying the weak supervisor multiple times and performing additional computations for uncertainty filtering and reliability re-weighting. This could limit the scalability of the approach, especially when dealing with large-scale datasets or complex models. 2. The overall performance of the method heavily relies on the quality of the weak supervisor. If the weak supervisor consistently provides highly unreliable or incorrect labels, the effectiveness of the reliability-aware methods may diminish. 3. The inherent subjectivity and variability in human-generated labels could introduce challenges not fully addressed by the current reliability estimation techniques. Further research is needed to tailor the methods specifically for human-annotated data, considering factors like annotator bias and expertise."
  },
  {
    "objectID": "posts/Improving_Weak_to_Strong_Generalization_with_Reliability_Aware_Alignment/2024-06-27-Improving_Weak_to_Strong_Generalization_with_Reliability_Aware_Alignment.html#appendix",
    "href": "posts/Improving_Weak_to_Strong_Generalization_with_Reliability_Aware_Alignment/2024-06-27-Improving_Weak_to_Strong_Generalization_with_Reliability_Aware_Alignment.html#appendix",
    "title": "Improving Weak-to-Strong Generalization with Reliability-Aware Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19032v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19032v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6944"
  },
  {
    "objectID": "posts/M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering/2024-06-06-M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering.html",
    "href": "posts/M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering/2024-06-06-M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering.html",
    "title": "M-QALM: A Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall in Large Language Models via Question Answering",
    "section": "",
    "text": "Summary:\nThe paper introduces M-QALM, a benchmark for evaluating clinical reading comprehension and knowledge recall in large language models (LLMs) through question answering. The authors conduct a large-scale empirical study using 22 datasets in three generalist and three specialist biomedical sub-domains. They analyze the performance of 15 LLMs, focusing on factors such as instruction tuning, domain-adapted models, and fine-tuning on medical knowledge datasets. The results show that while recent domain-adapted models may lack adequate knowledge, fine-tuning on medical knowledge datasets shows encouraging results, even generalizing to unseen specialist sub-domains. The paper also includes a skill-oriented manual error analysis, revealing a significant gap between the models’ capabilities to recall necessary knowledge and integrate it with the presented context.\nMajor Findings:"
  },
  {
    "objectID": "posts/M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering/2024-06-06-M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering.html#appendix",
    "href": "posts/M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering/2024-06-06-M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering.html#appendix",
    "title": "M-QALM: A Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall in Large Language Models via Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03699v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03699v1\n\n\nTruncated\nTrue\n\n\nWord Count\n32275"
  },
  {
    "objectID": "posts/Turn_Level_Empathy_Prediction_Using_Psychological_Indicators/2024-07-11-Turn_Level_Empathy_Prediction_Using_Psychological_Indicators.html#appendix",
    "href": "posts/Turn_Level_Empathy_Prediction_Using_Psychological_Indicators/2024-07-11-Turn_Level_Empathy_Prediction_Using_Psychological_Indicators.html#appendix",
    "title": "Turn-Level Empathy Prediction Using Psychological Indicators",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08607v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08607v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3044"
  },
  {
    "objectID": "posts/AutoPureData_Automated_Filtering_of_Web_Data_for_LLM_Fine_tuning/2024-06-27-AutoPureData_Automated_Filtering_of_Web_Data_for_LLM_Fine_tuning.html#appendix",
    "href": "posts/AutoPureData_Automated_Filtering_of_Web_Data_for_LLM_Fine_tuning/2024-06-27-AutoPureData_Automated_Filtering_of_Web_Data_for_LLM_Fine_tuning.html#appendix",
    "title": "AutoPureData: Automated Filtering of Web Data for LLM Fine-tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19271v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19271v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2024"
  },
  {
    "objectID": "posts/Large_Language_Models_for_cross_language_code_clone_detection/2024-08-08-Large_Language_Models_for_cross_language_code_clone_detection.html",
    "href": "posts/Large_Language_Models_for_cross_language_code_clone_detection/2024-08-08-Large_Language_Models_for_cross_language_code_clone_detection.html",
    "title": "Large Language Models for cross-language code clone detection",
    "section": "",
    "text": "Summary:\nThis paper investigates the use of Large Language Models (LLMs) and Embedding Models (EMs) for cross-lingual code clone detection. The study focuses on four LLMs (Falcon-7B-Instruct, LLAMA2-Chat-7B, Starchat-, and GPT-3.5-Turbo) and one EM (Text-Embedding-Ada-002). The authors design various prompts for LLMs and evaluate their performance on two datasets, XLCoST and CodeNet. The results show that GPT-3.5-Turbo achieves the highest F1 score, while the “improved simple prompt” enables all LLMs to achieve their best performance. The EM outperforms all LLMs, even though LLMs yield satisfactory results when combined with CoT-based prompts.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/Large_Language_Models_for_cross_language_code_clone_detection/2024-08-08-Large_Language_Models_for_cross_language_code_clone_detection.html#appendix",
    "href": "posts/Large_Language_Models_for_cross_language_code_clone_detection/2024-08-08-Large_Language_Models_for_cross_language_code_clone_detection.html#appendix",
    "title": "Large Language Models for cross-language code clone detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04430v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04430v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9785"
  },
  {
    "objectID": "posts/Language_Conditioned_Offline_RL_for_Multi_Robot_Navigation/2024-07-29-Language_Conditioned_Offline_RL_for_Multi_Robot_Navigation.html#appendix",
    "href": "posts/Language_Conditioned_Offline_RL_for_Multi_Robot_Navigation/2024-07-29-Language_Conditioned_Offline_RL_for_Multi_Robot_Navigation.html#appendix",
    "title": "Language-Conditioned Offline RL for Multi-Robot Navigation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20164v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20164v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8102"
  },
  {
    "objectID": "posts/SPL_A_Socratic_Playground_for_Learning_Powered_by_Large_Language_Mode/2024-06-20-SPL_A_Socratic_Playground_for_Learning_Powered_by_Large_Language_Mode.html#appendix",
    "href": "posts/SPL_A_Socratic_Playground_for_Learning_Powered_by_Large_Language_Mode/2024-06-20-SPL_A_Socratic_Playground_for_Learning_Powered_by_Large_Language_Mode.html#appendix",
    "title": "SPL: A Socratic Playground for Learning Powered by Large Language Mode",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13919v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13919v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7284"
  },
  {
    "objectID": "posts/The_Career_Interests_of_Large_Language_Models/2024-07-11-The_Career_Interests_of_Large_Language_Models.html#appendix",
    "href": "posts/The_Career_Interests_of_Large_Language_Models/2024-07-11-The_Career_Interests_of_Large_Language_Models.html#appendix",
    "title": "The Career Interests of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08564v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08564v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8543"
  },
  {
    "objectID": "posts/Multimodal_Causal_Reasoning_Benchmark_Challenging_Vision_Large_Language_Models_to_Infer_Causal_Links_Between_Siamese_Images/2024-08-15-Multimodal_Causal_Reasoning_Benchmark_Challenging_Vision_Large_Language_Models_to_Infer_Causal_Links_Between_Siamese_Images.html#appendix",
    "href": "posts/Multimodal_Causal_Reasoning_Benchmark_Challenging_Vision_Large_Language_Models_to_Infer_Causal_Links_Between_Siamese_Images/2024-08-15-Multimodal_Causal_Reasoning_Benchmark_Challenging_Vision_Large_Language_Models_to_Infer_Causal_Links_Between_Siamese_Images.html#appendix",
    "title": "Multimodal Causal Reasoning Benchmark: Challenging Vision Large Language Models to Infer Causal Links Between Siamese Images",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.08105v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.08105v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4315"
  },
  {
    "objectID": "posts/Balancing_Act_Prioritization_Strategies_for_LLM_Designed_Restless_Bandit_Rewards/2024-08-22-Balancing_Act_Prioritization_Strategies_for_LLM_Designed_Restless_Bandit_Rewards.html",
    "href": "posts/Balancing_Act_Prioritization_Strategies_for_LLM_Designed_Restless_Bandit_Rewards/2024-08-22-Balancing_Act_Prioritization_Strategies_for_LLM_Designed_Restless_Bandit_Rewards.html",
    "title": "Balancing Act: Prioritization Strategies for LLM-Designed Restless Bandit Rewards",
    "section": "",
    "text": "Summary:\nThe paper presents a novel approach to designing reward functions for Restless Multi-Armed Bandits (RMABs) using Large Language Models (LLMs). The authors propose a Social Choice Language Model (SCLM) that separates the generation and selection of reward functions, allowing for a more transparent and configurable process. The SCLM consists of a generator, which uses LLM-powered evolutionary search to create a pool of candidate reward functions, and an adjudicator, which selects a reward function based on a user-selected social welfare function. The authors demonstrate that their model can reliably select more effective, aligned, and balanced reward functions compared to purely LLM-based approaches.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a promising approach to designing reward functions for RMABs using LLMs. The separation of the generation and selection of reward functions in the SCLM model allows for a more transparent and configurable process, which is a significant improvement over purely LLM-based approaches. The use of a user-selected social welfare function in the adjudicator also allows for the control of the preferred trade-off between objectives, which is a valuable feature for real-world applications.\nHowever, the paper does not provide a detailed comparison of the SCLM model with other existing approaches to designing reward functions for RMABs. It would be beneficial to see how the SCLM model compares to other methods in terms of performance and computational efficiency. Additionally, the paper does not discuss the potential limitations or drawbacks of the SCLM model, such as the computational cost of generating a large pool of candidate reward functions or the potential for bias in the selection process.\nOverall, the paper presents a valuable contribution to the field"
  },
  {
    "objectID": "posts/Balancing_Act_Prioritization_Strategies_for_LLM_Designed_Restless_Bandit_Rewards/2024-08-22-Balancing_Act_Prioritization_Strategies_for_LLM_Designed_Restless_Bandit_Rewards.html#appendix",
    "href": "posts/Balancing_Act_Prioritization_Strategies_for_LLM_Designed_Restless_Bandit_Rewards/2024-08-22-Balancing_Act_Prioritization_Strategies_for_LLM_Designed_Restless_Bandit_Rewards.html#appendix",
    "title": "Balancing Act: Prioritization Strategies for LLM-Designed Restless Bandit Rewards",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12112v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12112v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12104"
  },
  {
    "objectID": "posts/Evaluating_the_Performance_of_Large_Language_Models_for_SDG_Mapping_(Technical_Report)/2024-08-05-Evaluating_the_Performance_of_Large_Language_Models_for_SDG_Mapping_(Technical_Report).html#appendix",
    "href": "posts/Evaluating_the_Performance_of_Large_Language_Models_for_SDG_Mapping_(Technical_Report)/2024-08-05-Evaluating_the_Performance_of_Large_Language_Models_for_SDG_Mapping_(Technical_Report).html#appendix",
    "title": "Evaluating the Performance of Large Language Models for SDG Mapping (Technical Report)",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02201v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02201v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3184"
  },
  {
    "objectID": "posts/Fine_tuning_multilingual_language_models_in_TwitterX_sentiment_analysis_a_study_on_Eastern_European_V4_languages/2024-08-04-Fine_tuning_multilingual_language_models_in_TwitterX_sentiment_analysis_a_study_on_Eastern_European_V4_languages.html#appendix",
    "href": "posts/Fine_tuning_multilingual_language_models_in_TwitterX_sentiment_analysis_a_study_on_Eastern_European_V4_languages/2024-08-04-Fine_tuning_multilingual_language_models_in_TwitterX_sentiment_analysis_a_study_on_Eastern_European_V4_languages.html#appendix",
    "title": "Fine-tuning multilingual language models in Twitter/X sentiment analysis: a study on Eastern-European V4 languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02044v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02044v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5758"
  },
  {
    "objectID": "posts/Scaling_Laws_for_Data_Poisoning_in_LLMs/2024-08-06-Scaling_Laws_for_Data_Poisoning_in_LLMs.html#appendix",
    "href": "posts/Scaling_Laws_for_Data_Poisoning_in_LLMs/2024-08-06-Scaling_Laws_for_Data_Poisoning_in_LLMs.html#appendix",
    "title": "Scaling Laws for Data Poisoning in LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02946v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02946v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7565"
  },
  {
    "objectID": "posts/Revealing_Fine_Grained_Values_and_Opinions_in_Large_Language_Models/2024-06-27-Revealing_Fine_Grained_Values_and_Opinions_in_Large_Language_Models.html#appendix",
    "href": "posts/Revealing_Fine_Grained_Values_and_Opinions_in_Large_Language_Models/2024-06-27-Revealing_Fine_Grained_Values_and_Opinions_in_Large_Language_Models.html#appendix",
    "title": "Revealing Fine-Grained Values and Opinions in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19238v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19238v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8950"
  },
  {
    "objectID": "posts/Categorical_Syllogisms_Revisited_A_Review_of_the_Logical_Reasoning_Abilities_of_LLMs_for_Analyzing_Categorical_Syllogism/2024-06-26-Categorical_Syllogisms_Revisited_A_Review_of_the_Logical_Reasoning_Abilities_of_LLMs_for_Analyzing_Categorical_Syllogism.html",
    "href": "posts/Categorical_Syllogisms_Revisited_A_Review_of_the_Logical_Reasoning_Abilities_of_LLMs_for_Analyzing_Categorical_Syllogism/2024-06-26-Categorical_Syllogisms_Revisited_A_Review_of_the_Logical_Reasoning_Abilities_of_LLMs_for_Analyzing_Categorical_Syllogism.html",
    "title": "Categorical Syllogisms Revisited: A Review of the Logical Reasoning Abilities of LLMs for Analyzing Categorical Syllogism",
    "section": "",
    "text": "Summary:\nThis paper provides a systematic overview of prior works on the logical reasoning ability of large language models (LLMs) for analyzing categorical syllogisms. The authors investigate all possible variations of categorical syllogisms from a purely logical perspective and examine the underlying configurations tested by existing datasets. The results indicate that compared to template-based synthetic datasets, crowdsourcing approaches sacrifice the coverage of configurations for more language variations, thus bringing challenges to fully testing LLMs under different situations. The paper also summarizes the findings and observations for the performances of LLMs in inferring the validity of syllogisms from the current literature. The error rate breakdown analyses suggest that the interpretation of quantifiers is the current bottleneck that limits the performances of LLMs. Finally, the paper discusses several points that might be worth considering when researchers plan on the future release of categorical syllogism datasets.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive review of the current literature regarding categorical syllogisms and the logical reasoning abilities of LLMs. The authors’ analysis of the limitations of existing datasets and the bottlenecks in LLMs’ performance is insightful and valuable for future research. However, the paper does not provide a clear solution to the identified problems or propose new models to improve LLMs’ performance. Additionally, the paper does not discuss the potential biases or methodological issues in the existing literature, which could be a limitation of the review. Overall, the paper is well-structured, coherent, and effectively communicates the essential information from the academic article."
  },
  {
    "objectID": "posts/Categorical_Syllogisms_Revisited_A_Review_of_the_Logical_Reasoning_Abilities_of_LLMs_for_Analyzing_Categorical_Syllogism/2024-06-26-Categorical_Syllogisms_Revisited_A_Review_of_the_Logical_Reasoning_Abilities_of_LLMs_for_Analyzing_Categorical_Syllogism.html#appendix",
    "href": "posts/Categorical_Syllogisms_Revisited_A_Review_of_the_Logical_Reasoning_Abilities_of_LLMs_for_Analyzing_Categorical_Syllogism/2024-06-26-Categorical_Syllogisms_Revisited_A_Review_of_the_Logical_Reasoning_Abilities_of_LLMs_for_Analyzing_Categorical_Syllogism.html#appendix",
    "title": "Categorical Syllogisms Revisited: A Review of the Logical Reasoning Abilities of LLMs for Analyzing Categorical Syllogism",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18762v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18762v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7262"
  },
  {
    "objectID": "posts/LICO_Large_Language_Models_for_In_Context_Molecular_Optimization/2024-06-27-LICO_Large_Language_Models_for_In_Context_Molecular_Optimization.html#appendix",
    "href": "posts/LICO_Large_Language_Models_for_In_Context_Molecular_Optimization/2024-06-27-LICO_Large_Language_Models_for_In_Context_Molecular_Optimization.html#appendix",
    "title": "LICO: Large Language Models for In-Context Molecular Optimization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18851v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18851v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11485"
  },
  {
    "objectID": "posts/Methodology_of_Adapting_Large_English_Language_Models_for_Specific_Cultural_Contexts/2024-06-27-Methodology_of_Adapting_Large_English_Language_Models_for_Specific_Cultural_Contexts.html#appendix",
    "href": "posts/Methodology_of_Adapting_Large_English_Language_Models_for_Specific_Cultural_Contexts/2024-06-27-Methodology_of_Adapting_Large_English_Language_Models_for_Specific_Cultural_Contexts.html#appendix",
    "title": "Methodology of Adapting Large English Language Models for Specific Cultural Contexts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18192v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18192v2\n\n\nTruncated\nFalse\n\n\nWord Count\n4216"
  },
  {
    "objectID": "posts/NoviCode_Generating_Programs_from_Natural_Language_Utterances_by_Novices/2024-07-15-NoviCode_Generating_Programs_from_Natural_Language_Utterances_by_Novices.html#appendix",
    "href": "posts/NoviCode_Generating_Programs_from_Natural_Language_Utterances_by_Novices/2024-07-15-NoviCode_Generating_Programs_from_Natural_Language_Utterances_by_Novices.html#appendix",
    "title": "NoviCode: Generating Programs from Natural Language Utterances by Novices",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10626v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10626v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9676"
  },
  {
    "objectID": "posts/Polaris_Open_ended_Interactive_Robotic_Manipulation_via_Syn2Real_Visual_Grounding_and_Large_Language_Models/2024-08-15-Polaris_Open_ended_Interactive_Robotic_Manipulation_via_Syn2Real_Visual_Grounding_and_Large_Language_Models.html#appendix",
    "href": "posts/Polaris_Open_ended_Interactive_Robotic_Manipulation_via_Syn2Real_Visual_Grounding_and_Large_Language_Models/2024-08-15-Polaris_Open_ended_Interactive_Robotic_Manipulation_via_Syn2Real_Visual_Grounding_and_Large_Language_Models.html#appendix",
    "title": "Polaris: Open-ended Interactive Robotic Manipulation via Syn2Real Visual Grounding and Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07975v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07975v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5882"
  },
  {
    "objectID": "posts/Using_Retriever_Augmented_Large_Language_Models_for_Attack_Graph_Generation/2024-08-11-Using_Retriever_Augmented_Large_Language_Models_for_Attack_Graph_Generation.html#appendix",
    "href": "posts/Using_Retriever_Augmented_Large_Language_Models_for_Attack_Graph_Generation/2024-08-11-Using_Retriever_Augmented_Large_Language_Models_for_Attack_Graph_Generation.html#appendix",
    "title": "Using Retriever Augmented Large Language Models for Attack Graph Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.05855v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.05855v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11751"
  },
  {
    "objectID": "posts/Teaching_LLMs_at_Charles_University_Assignments_and_Activities/2024-07-29-Teaching_LLMs_at_Charles_University_Assignments_and_Activities.html#appendix",
    "href": "posts/Teaching_LLMs_at_Charles_University_Assignments_and_Activities/2024-07-29-Teaching_LLMs_at_Charles_University_Assignments_and_Activities.html#appendix",
    "title": "Teaching LLMs at Charles University: Assignments and Activities",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19798v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19798v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2201"
  },
  {
    "objectID": "posts/In_Context_Learning_and_Fine_Tuning_GPT_for_Argument_Mining/2024-06-10-In_Context_Learning_and_Fine_Tuning_GPT_for_Argument_Mining.html#appendix",
    "href": "posts/In_Context_Learning_and_Fine_Tuning_GPT_for_Argument_Mining/2024-06-10-In_Context_Learning_and_Fine_Tuning_GPT_for_Argument_Mining.html#appendix",
    "title": "In-Context Learning and Fine-Tuning GPT for Argument Mining",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06699v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06699v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2590"
  },
  {
    "objectID": "posts/Multi_tool_Integration_Application_for_Math_Reasoning_Using_Large_Language_Model/2024-08-22-Multi_tool_Integration_Application_for_Math_Reasoning_Using_Large_Language_Model.html#appendix",
    "href": "posts/Multi_tool_Integration_Application_for_Math_Reasoning_Using_Large_Language_Model/2024-08-22-Multi_tool_Integration_Application_for_Math_Reasoning_Using_Large_Language_Model.html#appendix",
    "title": "Multi-tool Integration Application for Math Reasoning Using Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12148v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12148v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2337"
  },
  {
    "objectID": "posts/FuxiTranyu_A_Multilingual_Large_Language_Model_Trained_with_Balanced_Data/2024-08-12-FuxiTranyu_A_Multilingual_Large_Language_Model_Trained_with_Balanced_Data.html#appendix",
    "href": "posts/FuxiTranyu_A_Multilingual_Large_Language_Model_Trained_with_Balanced_Data/2024-08-12-FuxiTranyu_A_Multilingual_Large_Language_Model_Trained_with_Balanced_Data.html#appendix",
    "title": "FuxiTranyu: A Multilingual Large Language Model Trained with Balanced Data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.06273v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.06273v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9897"
  },
  {
    "objectID": "posts/Instruct_Not_Assist_LLM_based_Multi_Turn_Planning_and_Hierarchical_Questioning_for_Socratic_Code_Debugging/2024-06-17-Instruct_Not_Assist_LLM_based_Multi_Turn_Planning_and_Hierarchical_Questioning_for_Socratic_Code_Debugging.html#appendix",
    "href": "posts/Instruct_Not_Assist_LLM_based_Multi_Turn_Planning_and_Hierarchical_Questioning_for_Socratic_Code_Debugging/2024-06-17-Instruct_Not_Assist_LLM_based_Multi_Turn_Planning_and_Hierarchical_Questioning_for_Socratic_Code_Debugging.html#appendix",
    "title": "Instruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11709v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11709v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9274"
  },
  {
    "objectID": "posts/From_Artificial_Needles_to_Real_Haystacks_Improving_Retrieval_Capabilities_in_LLMs_by_Finetuning_on_Synthetic_Data/2024-06-27-From_Artificial_Needles_to_Real_Haystacks_Improving_Retrieval_Capabilities_in_LLMs_by_Finetuning_on_Synthetic_Data.html",
    "href": "posts/From_Artificial_Needles_to_Real_Haystacks_Improving_Retrieval_Capabilities_in_LLMs_by_Finetuning_on_Synthetic_Data/2024-06-27-From_Artificial_Needles_to_Real_Haystacks_Improving_Retrieval_Capabilities_in_LLMs_by_Finetuning_on_Synthetic_Data.html",
    "title": "From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data",
    "section": "",
    "text": "Summary:\nThe paper “From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data” by Zheyang Xiong, Vasilis Papageorgiou, Kangwook Lee, and Dimitris Papailiopoulos from the University of Wisconsin-Madison proposes a finetuning approach to address the limitations of Large Language Models (LLMs) in accurately retrieving information and maintaining reasoning capabilities when processing long-context inputs. The authors propose a finetuning approach utilizing a carefully designed synthetic dataset comprising numerical key-value retrieval tasks. The experiments conducted on models like GPT-3.5 Turbo and Mistral 7B demonstrate that finetuning LLMs on this dataset significantly improves LLMs’ information retrieval and reasoning capabilities in longer-context settings. The study highlights the potential of finetuning on synthetic data for improving the performance of LLMs on longer-context tasks.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an innovative approach to improving the performance of LLMs on longer-context tasks by finetuning on synthetic data. The authors provide a well-structured and coherent summary of their findings, highlighting the potential of their proposed method. However, the paper does not discuss the limitations of the proposed approach or potential biases that may have been introduced during the finetuning process. Additionally, the paper does not provide a comparison with other finetuning methods or discuss the generalizability of the proposed approach to other LLMs. Further research is needed to address these limitations and validate the proposed approach"
  },
  {
    "objectID": "posts/From_Artificial_Needles_to_Real_Haystacks_Improving_Retrieval_Capabilities_in_LLMs_by_Finetuning_on_Synthetic_Data/2024-06-27-From_Artificial_Needles_to_Real_Haystacks_Improving_Retrieval_Capabilities_in_LLMs_by_Finetuning_on_Synthetic_Data.html#appendix",
    "href": "posts/From_Artificial_Needles_to_Real_Haystacks_Improving_Retrieval_Capabilities_in_LLMs_by_Finetuning_on_Synthetic_Data/2024-06-27-From_Artificial_Needles_to_Real_Haystacks_Improving_Retrieval_Capabilities_in_LLMs_by_Finetuning_on_Synthetic_Data.html#appendix",
    "title": "From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19292v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19292v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11448"
  },
  {
    "objectID": "posts/TextGrad_Automatic_Differentiation_via_Text/2024-06-11-TextGrad_Automatic_Differentiation_via_Text.html#appendix",
    "href": "posts/TextGrad_Automatic_Differentiation_via_Text/2024-06-11-TextGrad_Automatic_Differentiation_via_Text.html#appendix",
    "title": "TextGrad: Automatic Differentiation via Text",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07496v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07496v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14644"
  },
  {
    "objectID": "posts/Walking_in_Others_Shoes_How_Perspective_Taking_Guides_Large_Language_Models_in_Reducing_Toxicity_and_Bias/2024-07-22-Walking_in_Others_Shoes_How_Perspective_Taking_Guides_Large_Language_Models_in_Reducing_Toxicity_and_Bias.html#major-findings",
    "href": "posts/Walking_in_Others_Shoes_How_Perspective_Taking_Guides_Large_Language_Models_in_Reducing_Toxicity_and_Bias/2024-07-22-Walking_in_Others_Shoes_How_Perspective_Taking_Guides_Large_Language_Models_in_Reducing_Toxicity_and_Bias.html#major-findings",
    "title": "Walking in Others’ Shoes: How Perspective-Taking Guides Large Language Models in Reducing Toxicity and Bias",
    "section": "Major Findings",
    "text": "Major Findings\n\nThe proposed perspective-taking prompting (PeT) strategy can significantly reduce toxicity (up to 30%) and bias (up to 20%) in LLMs’ responses.\nPeT outperforms existing prompting methods that depend on external tool feedback and fail to simultaneously lessen toxicity and bias.\nPeT is a superior method for producing less harmful responses, as demonstrated by evaluations on two commercial LLMs (ChatGPT and GLM) and three open-source LLMs."
  },
  {
    "objectID": "posts/Walking_in_Others_Shoes_How_Perspective_Taking_Guides_Large_Language_Models_in_Reducing_Toxicity_and_Bias/2024-07-22-Walking_in_Others_Shoes_How_Perspective_Taking_Guides_Large_Language_Models_in_Reducing_Toxicity_and_Bias.html#analysis-and-critique",
    "href": "posts/Walking_in_Others_Shoes_How_Perspective_Taking_Guides_Large_Language_Models_in_Reducing_Toxicity_and_Bias/2024-07-22-Walking_in_Others_Shoes_How_Perspective_Taking_Guides_Large_Language_Models_in_Reducing_Toxicity_and_Bias.html#analysis-and-critique",
    "title": "Walking in Others’ Shoes: How Perspective-Taking Guides Large Language Models in Reducing Toxicity and Bias",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\n\nThe paper does not provide a detailed comparison of the proposed method with other existing methods for reducing toxicity and bias in LLMs.\nThe paper does not discuss the potential limitations or drawbacks of the proposed method, such as its applicability to different types of LLMs or the computational resources required for its implementation.\nThe paper does not provide a clear explanation of how the perspective-taking prompting strategy is implemented in practice, making it difficult to replicate the results.\nThe paper does not discuss the potential ethical implications of using LLMs to generate less harmful responses, such as the potential for biased or discriminatory outputs.\nThe paper does not provide a clear explanation of how the proposed method can be integrated into existing LLM architectures or training pipelines.\n\nOverall, the paper presents an interesting and promising approach for reducing toxicity and bias in LLMs. However, more detailed comparisons with existing methods, a discussion of potential limitations and drawbacks, and a clear explanation of the implementation details are needed to fully evaluate the proposed method. Additionally, a discussion of the ethical implications and integration with existing LLM architectures would be"
  },
  {
    "objectID": "posts/Walking_in_Others_Shoes_How_Perspective_Taking_Guides_Large_Language_Models_in_Reducing_Toxicity_and_Bias/2024-07-22-Walking_in_Others_Shoes_How_Perspective_Taking_Guides_Large_Language_Models_in_Reducing_Toxicity_and_Bias.html#appendix",
    "href": "posts/Walking_in_Others_Shoes_How_Perspective_Taking_Guides_Large_Language_Models_in_Reducing_Toxicity_and_Bias/2024-07-22-Walking_in_Others_Shoes_How_Perspective_Taking_Guides_Large_Language_Models_in_Reducing_Toxicity_and_Bias.html#appendix",
    "title": "Walking in Others’ Shoes: How Perspective-Taking Guides Large Language Models in Reducing Toxicity and Bias",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.15366v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.15366v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14332"
  },
  {
    "objectID": "posts/AI_Gadget_Kit_Integrating_Swarm_User_Interfaces_with_LLM_driven_Agents_for_Rich_Tabletop_Game_Applications/2024-07-24-AI_Gadget_Kit_Integrating_Swarm_User_Interfaces_with_LLM_driven_Agents_for_Rich_Tabletop_Game_Applications.html#appendix",
    "href": "posts/AI_Gadget_Kit_Integrating_Swarm_User_Interfaces_with_LLM_driven_Agents_for_Rich_Tabletop_Game_Applications/2024-07-24-AI_Gadget_Kit_Integrating_Swarm_User_Interfaces_with_LLM_driven_Agents_for_Rich_Tabletop_Game_Applications.html#appendix",
    "title": "AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop Game Applications",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17086v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17086v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11548"
  },
  {
    "objectID": "posts/All_Roads_Lead_to_Rome_Unveiling_the_Trajectory_of_Recommender_Systems_Across_the_LLM_Era/2024-07-14-All_Roads_Lead_to_Rome_Unveiling_the_Trajectory_of_Recommender_Systems_Across_the_LLM_Era.html#appendix",
    "href": "posts/All_Roads_Lead_to_Rome_Unveiling_the_Trajectory_of_Recommender_Systems_Across_the_LLM_Era/2024-07-14-All_Roads_Lead_to_Rome_Unveiling_the_Trajectory_of_Recommender_Systems_Across_the_LLM_Era.html#appendix",
    "title": "All Roads Lead to Rome: Unveiling the Trajectory of Recommender Systems Across the LLM Era",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10081v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10081v1\n\n\nTruncated\nFalse\n\n\nWord Count\n19034"
  },
  {
    "objectID": "posts/Is_In_Context_Learning_a_Type_of_Gradient_Based_Learning_Evidence_from_the_Inverse_Frequency_Effect_in_Structural_Priming/2024-06-26-Is_In_Context_Learning_a_Type_of_Gradient_Based_Learning_Evidence_from_the_Inverse_Frequency_Effect_in_Structural_Priming.html#appendix",
    "href": "posts/Is_In_Context_Learning_a_Type_of_Gradient_Based_Learning_Evidence_from_the_Inverse_Frequency_Effect_in_Structural_Priming/2024-06-26-Is_In_Context_Learning_a_Type_of_Gradient_Based_Learning_Evidence_from_the_Inverse_Frequency_Effect_in_Structural_Priming.html#appendix",
    "title": "Is In-Context Learning a Type of Gradient-Based Learning? Evidence from the Inverse Frequency Effect in Structural Priming",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18501v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18501v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8453"
  },
  {
    "objectID": "posts/Faux_Polyglot_A_Study_on_Information_Disparity_in_Multilingual_Large_Language_Models/2024-07-07-Faux_Polyglot_A_Study_on_Information_Disparity_in_Multilingual_Large_Language_Models.html#appendix",
    "href": "posts/Faux_Polyglot_A_Study_on_Information_Disparity_in_Multilingual_Large_Language_Models/2024-07-07-Faux_Polyglot_A_Study_on_Information_Disparity_in_Multilingual_Large_Language_Models.html#appendix",
    "title": "Faux Polyglot: A Study on Information Disparity in Multilingual Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05502v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05502v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8494"
  },
  {
    "objectID": "posts/SD_Eval_A_Benchmark_Dataset_for_Spoken_Dialogue_Understanding_Beyond_Words/2024-06-19-SD_Eval_A_Benchmark_Dataset_for_Spoken_Dialogue_Understanding_Beyond_Words.html#appendix",
    "href": "posts/SD_Eval_A_Benchmark_Dataset_for_Spoken_Dialogue_Understanding_Beyond_Words/2024-06-19-SD_Eval_A_Benchmark_Dataset_for_Spoken_Dialogue_Understanding_Beyond_Words.html#appendix",
    "title": "SD-Eval: A Benchmark Dataset for Spoken Dialogue Understanding Beyond Words",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13340v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13340v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5962"
  },
  {
    "objectID": "posts/Can_You_Trust_Your_Metric_Automatic_Concatenation_Based_Tests_for_Metric_Validity/2024-08-22-Can_You_Trust_Your_Metric_Automatic_Concatenation_Based_Tests_for_Metric_Validity.html#appendix",
    "href": "posts/Can_You_Trust_Your_Metric_Automatic_Concatenation_Based_Tests_for_Metric_Validity/2024-08-22-Can_You_Trust_Your_Metric_Automatic_Concatenation_Based_Tests_for_Metric_Validity.html#appendix",
    "title": "Can You Trust Your Metric? Automatic Concatenation-Based Tests for Metric Validity",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12259v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12259v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4848"
  },
  {
    "objectID": "posts/Human_AI_Collaborative_Taxonomy_Construction_A_Case_Study_in_Profession_Specific_Writing_Assistants/2024-06-26-Human_AI_Collaborative_Taxonomy_Construction_A_Case_Study_in_Profession_Specific_Writing_Assistants.html#appendix",
    "href": "posts/Human_AI_Collaborative_Taxonomy_Construction_A_Case_Study_in_Profession_Specific_Writing_Assistants/2024-06-26-Human_AI_Collaborative_Taxonomy_Construction_A_Case_Study_in_Profession_Specific_Writing_Assistants.html#appendix",
    "title": "Human-AI Collaborative Taxonomy Construction: A Case Study in Profession-Specific Writing Assistants",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18675v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18675v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3979"
  },
  {
    "objectID": "posts/Mutual_Reasoning_Makes_Smaller_LLMs_Stronger_Problem_Solvers/2024-08-12-Mutual_Reasoning_Makes_Smaller_LLMs_Stronger_Problem_Solvers.html#appendix",
    "href": "posts/Mutual_Reasoning_Makes_Smaller_LLMs_Stronger_Problem_Solvers/2024-08-12-Mutual_Reasoning_Makes_Smaller_LLMs_Stronger_Problem_Solvers.html#appendix",
    "title": "Mutual Reasoning Makes Smaller LLMs Stronger Problem-Solvers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.06195v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.06195v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7311"
  },
  {
    "objectID": "posts/Transforming_Agency._On_the_mode_of_existence_of_Large_Language_Models/2024-07-15-Transforming_Agency._On_the_mode_of_existence_of_Large_Language_Models.html",
    "href": "posts/Transforming_Agency._On_the_mode_of_existence_of_Large_Language_Models/2024-07-15-Transforming_Agency._On_the_mode_of_existence_of_Large_Language_Models.html",
    "title": "Transforming Agency. On the mode of existence of Large Language Models",
    "section": "",
    "text": "Summary:\nThe article “Transforming Agency” by Xabier E. Barandiaran and Lola S. Almendros explores the ontological characterization of Large Language Models (LLMs) like ChatGPT. The authors focus on their status as agents and explain the architecture, processing, and training procedures that enable LLMs to display their capacities. They argue that LLMs fail to meet necessary and sufficient conditions for autonomous agency in the light of embodied theories of mind. The authors conclude that ChatGPT should be characterized as an interlocutor or linguistic automaton, devoid of (autonomous) agency, but capable of engaging performatively on non-purposeful yet purpose-structured and purpose-bounded tasks. Despite their lack of sensorimotor and biological embodiment, LLMs significantly transform existing forms of human agency.\nMajor Findings:"
  },
  {
    "objectID": "posts/Transforming_Agency._On_the_mode_of_existence_of_Large_Language_Models/2024-07-15-Transforming_Agency._On_the_mode_of_existence_of_Large_Language_Models.html#appendix",
    "href": "posts/Transforming_Agency._On_the_mode_of_existence_of_Large_Language_Models/2024-07-15-Transforming_Agency._On_the_mode_of_existence_of_Large_Language_Models.html#appendix",
    "title": "Transforming Agency. On the mode of existence of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10735v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10735v1\n\n\nTruncated\nTrue\n\n\nWord Count\n36805"
  },
  {
    "objectID": "posts/Exploring_the_extent_of_similarities_in_software_failures_across_industries_using_LLMs/2024-08-08-Exploring_the_extent_of_similarities_in_software_failures_across_industries_using_LLMs.html#appendix",
    "href": "posts/Exploring_the_extent_of_similarities_in_software_failures_across_industries_using_LLMs/2024-08-08-Exploring_the_extent_of_similarities_in_software_failures_across_industries_using_LLMs.html#appendix",
    "title": "Exploring the extent of similarities in software failures across industries using LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03528v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03528v2\n\n\nTruncated\nFalse\n\n\nWord Count\n4343"
  },
  {
    "objectID": "posts/HuatuoGPT_Vision_Towards_Injecting_Medical_Visual_Knowledge_into_Multimodal_LLMs_at_Scale/2024-06-27-HuatuoGPT_Vision_Towards_Injecting_Medical_Visual_Knowledge_into_Multimodal_LLMs_at_Scale.html#appendix",
    "href": "posts/HuatuoGPT_Vision_Towards_Injecting_Medical_Visual_Knowledge_into_Multimodal_LLMs_at_Scale/2024-06-27-HuatuoGPT_Vision_Towards_Injecting_Medical_Visual_Knowledge_into_Multimodal_LLMs_at_Scale.html#appendix",
    "title": "HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19280v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19280v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6836"
  },
  {
    "objectID": "posts/BEYOND_DIALOGUE_A_Profile_Dialogue_Alignment_Framework_Towards_General_Role_Playing_Language_Model/2024-08-20-BEYOND_DIALOGUE_A_Profile_Dialogue_Alignment_Framework_Towards_General_Role_Playing_Language_Model.html#appendix",
    "href": "posts/BEYOND_DIALOGUE_A_Profile_Dialogue_Alignment_Framework_Towards_General_Role_Playing_Language_Model/2024-08-20-BEYOND_DIALOGUE_A_Profile_Dialogue_Alignment_Framework_Towards_General_Role_Playing_Language_Model.html#appendix",
    "title": "BEYOND DIALOGUE: A Profile-Dialogue Alignment Framework Towards General Role-Playing Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10903v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10903v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11582"
  },
  {
    "objectID": "posts/Mind_the_Privacy_Unit!_User_Level_Differential_Privacy_for_Language_Model_Fine_Tuning/2024-06-20-Mind_the_Privacy_Unit!_User_Level_Differential_Privacy_for_Language_Model_Fine_Tuning.html#appendix",
    "href": "posts/Mind_the_Privacy_Unit!_User_Level_Differential_Privacy_for_Language_Model_Fine_Tuning/2024-06-20-Mind_the_Privacy_Unit!_User_Level_Differential_Privacy_for_Language_Model_Fine_Tuning.html#appendix",
    "title": "Mind the Privacy Unit! User-Level Differential Privacy for Language Model Fine-Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14322v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14322v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7165"
  },
  {
    "objectID": "posts/Jogging_the_Memory_of_Unlearned_Model_Through_Targeted_Relearning_Attack/2024-06-19-Jogging_the_Memory_of_Unlearned_Model_Through_Targeted_Relearning_Attack.html#appendix",
    "href": "posts/Jogging_the_Memory_of_Unlearned_Model_Through_Targeted_Relearning_Attack/2024-06-19-Jogging_the_Memory_of_Unlearned_Model_Through_Targeted_Relearning_Attack.html#appendix",
    "title": "Jogging the Memory of Unlearned Model Through Targeted Relearning Attack",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13356v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13356v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5602"
  },
  {
    "objectID": "posts/Lifelong_Personalized_Low_Rank_Adaptation_of_Large_Language_Models_for_Recommendation/2024-08-07-Lifelong_Personalized_Low_Rank_Adaptation_of_Large_Language_Models_for_Recommendation.html#appendix",
    "href": "posts/Lifelong_Personalized_Low_Rank_Adaptation_of_Large_Language_Models_for_Recommendation/2024-08-07-Lifelong_Personalized_Low_Rank_Adaptation_of_Large_Language_Models_for_Recommendation.html#appendix",
    "title": "Lifelong Personalized Low-Rank Adaptation of Large Language Models for Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03533v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03533v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10390"
  },
  {
    "objectID": "posts/Exploring_User_Retrieval_Integration_towards_Large_Language_Models_for_Cross_Domain_Sequential_Recommendation/2024-06-05-Exploring_User_Retrieval_Integration_towards_Large_Language_Models_for_Cross_Domain_Sequential_Recommendation.html#appendix",
    "href": "posts/Exploring_User_Retrieval_Integration_towards_Large_Language_Models_for_Cross_Domain_Sequential_Recommendation/2024-06-05-Exploring_User_Retrieval_Integration_towards_Large_Language_Models_for_Cross_Domain_Sequential_Recommendation.html#appendix",
    "title": "Exploring User Retrieval Integration towards Large Language Models for Cross-Domain Sequential Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03085v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03085v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8121"
  },
  {
    "objectID": "posts/Sunnie_An_Anthropomorphic_LLM_Based_Conversational_Agent_for_Mental_Well_Being_Activity_Recommendation/2024-05-22-Sunnie_An_Anthropomorphic_LLM_Based_Conversational_Agent_for_Mental_Well_Being_Activity_Recommendation.html#appendix",
    "href": "posts/Sunnie_An_Anthropomorphic_LLM_Based_Conversational_Agent_for_Mental_Well_Being_Activity_Recommendation/2024-05-22-Sunnie_An_Anthropomorphic_LLM_Based_Conversational_Agent_for_Mental_Well_Being_Activity_Recommendation.html#appendix",
    "title": "Sunnie: An Anthropomorphic LLM-Based Conversational Agent for Mental Well-Being Activity Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.13803v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.13803v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1391"
  },
  {
    "objectID": "posts/PDSS_A_Privacy_Preserving_Framework_for_Step_by_Step_Distillation_of_Large_Language_Models/2024-06-18-PDSS_A_Privacy_Preserving_Framework_for_Step_by_Step_Distillation_of_Large_Language_Models.html#appendix",
    "href": "posts/PDSS_A_Privacy_Preserving_Framework_for_Step_by_Step_Distillation_of_Large_Language_Models/2024-06-18-PDSS_A_Privacy_Preserving_Framework_for_Step_by_Step_Distillation_of_Large_Language_Models.html#appendix",
    "title": "PDSS: A Privacy-Preserving Framework for Step-by-Step Distillation of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12403v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12403v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6497"
  },
  {
    "objectID": "posts/Evaluating_Language_Models_for_Efficient_Code_Generation/2024-08-12-Evaluating_Language_Models_for_Efficient_Code_Generation.html#appendix",
    "href": "posts/Evaluating_Language_Models_for_Efficient_Code_Generation/2024-08-12-Evaluating_Language_Models_for_Efficient_Code_Generation.html#appendix",
    "title": "Evaluating Language Models for Efficient Code Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.06450v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.06450v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8516"
  },
  {
    "objectID": "posts/Zero_Delay_QKV_Compression_for_Mitigating_KV_Cache_and_Network_Bottlenecks_in_LLM_Inference/2024-08-07-Zero_Delay_QKV_Compression_for_Mitigating_KV_Cache_and_Network_Bottlenecks_in_LLM_Inference.html#major-findings",
    "href": "posts/Zero_Delay_QKV_Compression_for_Mitigating_KV_Cache_and_Network_Bottlenecks_in_LLM_Inference/2024-08-07-Zero_Delay_QKV_Compression_for_Mitigating_KV_Cache_and_Network_Bottlenecks_in_LLM_Inference.html#major-findings",
    "title": "Zero-Delay QKV Compression for Mitigating KV Cache and Network Bottlenecks in LLM Inference",
    "section": "Major Findings",
    "text": "Major Findings\n\nCompressing KV values offers more benefits in terms of accuracy and job completion time (JCT) compared to compressing the model itself.\nExisting methods for compressing KV values, such as quantization and KVC eviction, incur significant runtime computational time overhead, resulting in notable delays in JCT.\nZDC, a Zero-Delay QKV Compression system, eliminates time overhead and even reduces computation and communication time of the model operations.\nZDC achieves up to 80% lower average JCT, 35% lower average perplexity, and 2.8× higher throughput with the same latency compared to state-of-the-art compression methods."
  },
  {
    "objectID": "posts/Zero_Delay_QKV_Compression_for_Mitigating_KV_Cache_and_Network_Bottlenecks_in_LLM_Inference/2024-08-07-Zero_Delay_QKV_Compression_for_Mitigating_KV_Cache_and_Network_Bottlenecks_in_LLM_Inference.html#analysis-and-critique",
    "href": "posts/Zero_Delay_QKV_Compression_for_Mitigating_KV_Cache_and_Network_Bottlenecks_in_LLM_Inference/2024-08-07-Zero_Delay_QKV_Compression_for_Mitigating_KV_Cache_and_Network_Bottlenecks_in_LLM_Inference.html#analysis-and-critique",
    "title": "Zero-Delay QKV Compression for Mitigating KV Cache and Network Bottlenecks in LLM Inference",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\nThe paper presents a well-structured and coherent summary of the proposed ZDC system for mitigating KV cache and network bottlenecks in LLM inference. The authors provide a clear and concise summary of the text, highlighting the major findings and contributions of the paper. The proposed system, ZDC, addresses the limitations of existing methods for compressing KV values and offers significant improvements in terms of accuracy, JCT, and throughput.\nHowever, the paper does not discuss the potential limitations or shortcomings of the proposed system. For instance, the authors do not address the potential impact of the"
  },
  {
    "objectID": "posts/Zero_Delay_QKV_Compression_for_Mitigating_KV_Cache_and_Network_Bottlenecks_in_LLM_Inference/2024-08-07-Zero_Delay_QKV_Compression_for_Mitigating_KV_Cache_and_Network_Bottlenecks_in_LLM_Inference.html#appendix",
    "href": "posts/Zero_Delay_QKV_Compression_for_Mitigating_KV_Cache_and_Network_Bottlenecks_in_LLM_Inference/2024-08-07-Zero_Delay_QKV_Compression_for_Mitigating_KV_Cache_and_Network_Bottlenecks_in_LLM_Inference.html#appendix",
    "title": "Zero-Delay QKV Compression for Mitigating KV Cache and Network Bottlenecks in LLM Inference",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04107v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04107v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12427"
  },
  {
    "objectID": "posts/BIPED_Pedagogically_Informed_Tutoring_System_for_ESL_Education/2024-06-05-BIPED_Pedagogically_Informed_Tutoring_System_for_ESL_Education.html#appendix",
    "href": "posts/BIPED_Pedagogically_Informed_Tutoring_System_for_ESL_Education/2024-06-05-BIPED_Pedagogically_Informed_Tutoring_System_for_ESL_Education.html#appendix",
    "title": "BIPED: Pedagogically Informed Tutoring System for ESL Education",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03486v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03486v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7759"
  },
  {
    "objectID": "posts/Generalization_Enhanced_Code_Vulnerability_Detection_via_Multi_Task_Instruction_Fine_Tuning/2024-06-06-Generalization_Enhanced_Code_Vulnerability_Detection_via_Multi_Task_Instruction_Fine_Tuning.html#appendix",
    "href": "posts/Generalization_Enhanced_Code_Vulnerability_Detection_via_Multi_Task_Instruction_Fine_Tuning/2024-06-06-Generalization_Enhanced_Code_Vulnerability_Detection_via_Multi_Task_Instruction_Fine_Tuning.html#appendix",
    "title": "Generalization-Enhanced Code Vulnerability Detection via Multi-Task Instruction Fine-Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03718v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03718v1\n\n\nTruncated\nFalse\n\n\nWord Count\n22567"
  },
  {
    "objectID": "posts/CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only/2024-06-11-CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only.html",
    "href": "posts/CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only/2024-06-11-CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only.html",
    "title": "CAAP: Context-Aware Action Planning Prompting to Solve Computer Tasks with Front-End UI Only",
    "section": "",
    "text": "Summary:\nThe paper introduces an LLM-based agent that operates solely on the basis of screenshots for recognizing environments, while leveraging in-context learning to eliminate the need for collecting large datasets of human demonstration. The proposed method, named Context-Aware Action Planning (CAAP) prompting, encourages the agent to meticulously review the context in various angles. The agent achieves a success rate of 94.4% on 67 types of MiniWoB++ problems, utilizing only 1.48 demonstrations per problem type. The method offers the potential for broader applications, especially for tasks that require inter-application coordination on computers or smartphones.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel approach to LLM-based agents that addresses the limitations of existing methods reliant on HTML or DOM inputs and those that combine supervised learning (SL) and reinforcement learning (RL). The proposed agent operates solely on visual inputs and utilizes a large language model (LLM). The CAAP prompting approach is introduced to enhance the decision-making capabilities of ICL-based agents. The evaluations using the MiniWoB++ benchmark demonstrate the superiority of the proposed method. However, the scope of validation remains limited, and further research is needed to evaluate the agent across a broader array of benchmarks. Additionally, the agent’s reliance on visual observation data may lead to observation failures, as demonstrated in the case study. The paper also acknowledges the limitations of the benchmark directives and the need for more comprehensive assessment from a research perspective."
  },
  {
    "objectID": "posts/CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only/2024-06-11-CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only.html#appendix",
    "href": "posts/CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only/2024-06-11-CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only.html#appendix",
    "title": "CAAP: Context-Aware Action Planning Prompting to Solve Computer Tasks with Front-End UI Only",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06947v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06947v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10877"
  },
  {
    "objectID": "posts/MMREC_LLM_Based_Multi_Modal_Recommender_System/2024-08-08-MMREC_LLM_Based_Multi_Modal_Recommender_System.html#appendix",
    "href": "posts/MMREC_LLM_Based_Multi_Modal_Recommender_System/2024-08-08-MMREC_LLM_Based_Multi_Modal_Recommender_System.html#appendix",
    "title": "MMREC: LLM Based Multi-Modal Recommender System",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04211v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04211v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6170"
  },
  {
    "objectID": "posts/Unlocking_Adversarial_Suffix_Optimization_Without_Affirmative_Phrases_Efficient_Black_box_Jailbreaking_via_LLM_as_Optimizer/2024-08-21-Unlocking_Adversarial_Suffix_Optimization_Without_Affirmative_Phrases_Efficient_Black_box_Jailbreaking_via_LLM_as_Optimizer.html#appendix",
    "href": "posts/Unlocking_Adversarial_Suffix_Optimization_Without_Affirmative_Phrases_Efficient_Black_box_Jailbreaking_via_LLM_as_Optimizer/2024-08-21-Unlocking_Adversarial_Suffix_Optimization_Without_Affirmative_Phrases_Efficient_Black_box_Jailbreaking_via_LLM_as_Optimizer.html#appendix",
    "title": "Unlocking Adversarial Suffix Optimization Without Affirmative Phrases: Efficient Black-box Jailbreaking via LLM as Optimizer",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11313v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11313v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7430"
  },
  {
    "objectID": "posts/Towards_Boosting_LLMs_driven_Relevance_Modeling_with_Progressive_Retrieved_Behavior_augmented_Prompting/2024-08-18-Towards_Boosting_LLMs_driven_Relevance_Modeling_with_Progressive_Retrieved_Behavior_augmented_Prompting.html#appendix",
    "href": "posts/Towards_Boosting_LLMs_driven_Relevance_Modeling_with_Progressive_Retrieved_Behavior_augmented_Prompting/2024-08-18-Towards_Boosting_LLMs_driven_Relevance_Modeling_with_Progressive_Retrieved_Behavior_augmented_Prompting.html#appendix",
    "title": "Towards Boosting LLMs-driven Relevance Modeling with Progressive Retrieved Behavior-augmented Prompting",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09439v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09439v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7328"
  },
  {
    "objectID": "posts/Probabilistic_Medical_Predictions_of_Large_Language_Models/2024-08-21-Probabilistic_Medical_Predictions_of_Large_Language_Models.html",
    "href": "posts/Probabilistic_Medical_Predictions_of_Large_Language_Models/2024-08-21-Probabilistic_Medical_Predictions_of_Large_Language_Models.html",
    "title": "Probabilistic Medical Predictions of Large Language Models",
    "section": "",
    "text": "Summary:\nThis study examines the credibility of probabilistic medical predictions made by Large Language Models (LLMs) by comparing explicit probabilities derived from text generation to implicit probabilities calculated based on the likelihood of predicting the correct label token. The authors experimented with six advanced open-source LLMs across five medical datasets and found that the performance of explicit probabilities was consistently lower than implicit probabilities with respect to discrimination, precision, and recall. These differences were more pronounced on small LLMs and imbalanced datasets, emphasizing the need for cautious interpretation and applications, as well as further research into robust probability estimation methods for LLMs in clinical contexts.\nMajor Findings:\nAnalysis and Critique:\nThe study provides a valuable contribution to the understanding of the reliability of probabilistic medical predictions made by LLMs. However, there are some limitations and potential areas for improvement. The study only focuses on open-source LLMs, which may not be representative of the performance of proprietary LLMs. Additionally, the experiments were simplified to binary classification settings, which may not fully capture the complexity of real-world clinical scenarios. The study also does not examine the probability performance using Chain of Thought (CoT) prompting, which could be a promising approach for improving the performance of LLMs. Finally, the study does not address the potential impact of data leakage on the performance of LLMs. Despite these limitations, the study provides important insights into the reliability of LLMs for probabilistic medical predictions and highlights the need for further research in this area."
  },
  {
    "objectID": "posts/Probabilistic_Medical_Predictions_of_Large_Language_Models/2024-08-21-Probabilistic_Medical_Predictions_of_Large_Language_Models.html#appendix",
    "href": "posts/Probabilistic_Medical_Predictions_of_Large_Language_Models/2024-08-21-Probabilistic_Medical_Predictions_of_Large_Language_Models.html#appendix",
    "title": "Probabilistic Medical Predictions of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11316v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11316v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17222"
  },
  {
    "objectID": "posts/Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients/2024-06-23-Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients.html#major-findings",
    "href": "posts/Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients/2024-06-23-Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients.html#major-findings",
    "title": "Effectiveness of ChatGPT in explaining complex medical reports to patients",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nInaccurate Information: ChatGPT’s explanations contained errors, including incorrect interpretation of abbreviations, URLs, and test results.\nInappropriate Language: The language used by ChatGPT was sometimes too complex, grammatically incorrect, or used American English, which is inappropriate in the UK.\nLimited Personalization: The responses were not always tailored to the patient, and the content was often too vague or technical.\nAI Distrust: Patients and doctors expressed reluctance to trust ChatGPT responses unless they were checked, preferably by clinicians. Some patients did not want to use them at all.\nIntegration Challenges: Integrating ChatGPT into existing clinical workflows, including getting approval from the NHS, poses significant challenges."
  },
  {
    "objectID": "posts/Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients/2024-06-23-Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients.html#analysis-and-critique",
    "href": "posts/Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients/2024-06-23-Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients.html#analysis-and-critique",
    "title": "Effectiveness of ChatGPT in explaining complex medical reports to patients",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe study highlights the potential of ChatGPT in assisting with complex medical reports but also underscores the need for improvements. The issues identified, such as inaccurate information, inappropriate language, limited personalization, and AI distrust, need to be addressed before LLMs can be effectively used to explain complex personal medical information to patients. The study also points out the challenges of integrating LLMs into clinical workflow and the need for more research on what patients and doctors need from such tools.\nThe study’s limitations include the small sample size for annotations and the lack of comprehensive data on focus group participants, which may have introduced bias. The use of only the webpage version of ChatGPT4 also limits the applicability of the findings to other LLMs.\nEthical considerations were addressed, with two ethical approvals obtained and all experiments conducted with the informed consent of the participants."
  },
  {
    "objectID": "posts/Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients/2024-06-23-Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients.html#appendix",
    "href": "posts/Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients/2024-06-23-Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients.html#appendix",
    "title": "Effectiveness of ChatGPT in explaining complex medical reports to patients",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.15963v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.15963v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7576"
  },
  {
    "objectID": "posts/Semantically_Diverse_Language_Generation_for_Uncertainty_Estimation_in_Language_Models/2024-06-06-Semantically_Diverse_Language_Generation_for_Uncertainty_Estimation_in_Language_Models.html#appendix",
    "href": "posts/Semantically_Diverse_Language_Generation_for_Uncertainty_Estimation_in_Language_Models/2024-06-06-Semantically_Diverse_Language_Generation_for_Uncertainty_Estimation_in_Language_Models.html#appendix",
    "title": "Semantically Diverse Language Generation for Uncertainty Estimation in Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04306v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04306v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10058"
  },
  {
    "objectID": "posts/Depression_Detection_and_Analysis_using_Large_Language_Models_on_Textual_and_Audio_Visual_Modalities/2024-07-08-Depression_Detection_and_Analysis_using_Large_Language_Models_on_Textual_and_Audio_Visual_Modalities.html#appendix",
    "href": "posts/Depression_Detection_and_Analysis_using_Large_Language_Models_on_Textual_and_Audio_Visual_Modalities/2024-07-08-Depression_Detection_and_Analysis_using_Large_Language_Models_on_Textual_and_Audio_Visual_Modalities.html#appendix",
    "title": "Depression Detection and Analysis using Large Language Models on Textual and Audio-Visual Modalities",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06125v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06125v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9401"
  },
  {
    "objectID": "posts/Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents/2024-06-10-Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents.html",
    "href": "posts/Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents/2024-06-10-Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents.html",
    "title": "Transforming Wearable Data into Health Insights using Large Language Model Agents",
    "section": "",
    "text": "Summary: The paper presents a study on the Personal Health Insights Agent (PHIA), an AI model designed to answer personal health queries using wearable data. PHIA outperforms the Code Generation baseline by 14% (84% vs. 74%) in exact matching accuracy for objective personal health queries. In open-ended reasoning quality, PHIA demonstrates a significant advantage over the Code Generation baseline in all ratings except for personalization. Expert evaluation shows that PHIA has a significant advantage over the Code Generation baseline in overall code quality, avoiding hallucinations, and personalization. PHIA is also quantitatively less likely to generate code that raises an error.\nMajor Findings: 1. PHIA outperforms the Code Generation baseline by 14% in exact matching accuracy for objective personal health queries. 2. PHIA demonstrates a significant advantage over the Code Generation baseline in open-ended reasoning quality."
  },
  {
    "objectID": "posts/Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents/2024-06-10-Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents.html#appendix",
    "href": "posts/Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents/2024-06-10-Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents.html#appendix",
    "title": "Transforming Wearable Data into Health Insights using Large Language Model Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06464v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06464v1\n\n\nTruncated\nTrue\n\n\nWord Count\n28809"
  },
  {
    "objectID": "posts/Natural_Language_Mechanisms_via_Self_Resolution_with_Foundation_Models/2024-07-10-Natural_Language_Mechanisms_via_Self_Resolution_with_Foundation_Models.html#appendix",
    "href": "posts/Natural_Language_Mechanisms_via_Self_Resolution_with_Foundation_Models/2024-07-10-Natural_Language_Mechanisms_via_Self_Resolution_with_Foundation_Models.html#appendix",
    "title": "Natural Language Mechanisms via Self-Resolution with Foundation Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07845v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07845v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3100"
  },
  {
    "objectID": "posts/Diagnosing_and_Remedying_Knowledge_Deficiencies_in_LLMs_via_Label_free_Curricular_Meaningful_Learning/2024-08-21-Diagnosing_and_Remedying_Knowledge_Deficiencies_in_LLMs_via_Label_free_Curricular_Meaningful_Learning.html#appendix",
    "href": "posts/Diagnosing_and_Remedying_Knowledge_Deficiencies_in_LLMs_via_Label_free_Curricular_Meaningful_Learning/2024-08-21-Diagnosing_and_Remedying_Knowledge_Deficiencies_in_LLMs_via_Label_free_Curricular_Meaningful_Learning.html#appendix",
    "title": "Diagnosing and Remedying Knowledge Deficiencies in LLMs via Label-free Curricular Meaningful Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11431v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11431v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8515"
  },
  {
    "objectID": "posts/ThinkRepair_Self_Directed_Automated_Program_Repair/2024-07-30-ThinkRepair_Self_Directed_Automated_Program_Repair.html#appendix",
    "href": "posts/ThinkRepair_Self_Directed_Automated_Program_Repair/2024-07-30-ThinkRepair_Self_Directed_Automated_Program_Repair.html#appendix",
    "title": "ThinkRepair: Self-Directed Automated Program Repair",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20898v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20898v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13579"
  },
  {
    "objectID": "posts/CodeNav_Beyond_tool_use_to_using_real_world_codebases_with_LLM_agents/2024-06-18-CodeNav_Beyond_tool_use_to_using_real_world_codebases_with_LLM_agents.html#appendix",
    "href": "posts/CodeNav_Beyond_tool_use_to_using_real_world_codebases_with_LLM_agents/2024-06-18-CodeNav_Beyond_tool_use_to_using_real_world_codebases_with_LLM_agents.html#appendix",
    "title": "CodeNav: Beyond tool-use to using real-world codebases with LLM agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12276v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12276v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10119"
  },
  {
    "objectID": "posts/WorldAPIs_The_World_Is_Worth_How_Many_APIs_A_Thought_Experiment/2024-07-10-WorldAPIs_The_World_Is_Worth_How_Many_APIs_A_Thought_Experiment.html#appendix",
    "href": "posts/WorldAPIs_The_World_Is_Worth_How_Many_APIs_A_Thought_Experiment/2024-07-10-WorldAPIs_The_World_Is_Worth_How_Many_APIs_A_Thought_Experiment.html#appendix",
    "title": "WorldAPIs: The World Is Worth How Many APIs? A Thought Experiment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07778v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07778v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6679"
  },
  {
    "objectID": "posts/RepoMasterEval_Evaluating_Code_Completion_via_Real_World_Repositories/2024-08-07-RepoMasterEval_Evaluating_Code_Completion_via_Real_World_Repositories.html#appendix",
    "href": "posts/RepoMasterEval_Evaluating_Code_Completion_via_Real_World_Repositories/2024-08-07-RepoMasterEval_Evaluating_Code_Completion_via_Real_World_Repositories.html#appendix",
    "title": "RepoMasterEval: Evaluating Code Completion via Real-World Repositories",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03519v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03519v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7803"
  },
  {
    "objectID": "posts/SLMRec_Empowering_Small_Language_Models_for_Sequential_Recommendation/2024-05-28-SLMRec_Empowering_Small_Language_Models_for_Sequential_Recommendation.html#appendix",
    "href": "posts/SLMRec_Empowering_Small_Language_Models_for_Sequential_Recommendation/2024-05-28-SLMRec_Empowering_Small_Language_Models_for_Sequential_Recommendation.html#appendix",
    "title": "SLMRec: Empowering Small Language Models for Sequential Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.17890v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.17890v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6690"
  },
  {
    "objectID": "posts/Modular_Pluralism_Pluralistic_Alignment_via_Multi_LLM_Collaboration/2024-06-22-Modular_Pluralism_Pluralistic_Alignment_via_Multi_LLM_Collaboration.html#appendix",
    "href": "posts/Modular_Pluralism_Pluralistic_Alignment_via_Multi_LLM_Collaboration/2024-06-22-Modular_Pluralism_Pluralistic_Alignment_via_Multi_LLM_Collaboration.html#appendix",
    "title": "Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.15951v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.15951v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8836"
  },
  {
    "objectID": "posts/Improving_Faithfulness_of_Large_Language_Models_in_Summarization_via_Sliding_Generation_and_Self_Consistency/2024-07-31-Improving_Faithfulness_of_Large_Language_Models_in_Summarization_via_Sliding_Generation_and_Self_Consistency.html#appendix",
    "href": "posts/Improving_Faithfulness_of_Large_Language_Models_in_Summarization_via_Sliding_Generation_and_Self_Consistency/2024-07-31-Improving_Faithfulness_of_Large_Language_Models_in_Summarization_via_Sliding_Generation_and_Self_Consistency.html#appendix",
    "title": "Improving Faithfulness of Large Language Models in Summarization via Sliding Generation and Self-Consistency",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21443v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21443v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7621"
  },
  {
    "objectID": "posts/ShieldGemma_Generative_AI_Content_Moderation_Based_on_Gemma/2024-07-31-ShieldGemma_Generative_AI_Content_Moderation_Based_on_Gemma.html#appendix",
    "href": "posts/ShieldGemma_Generative_AI_Content_Moderation_Based_on_Gemma/2024-07-31-ShieldGemma_Generative_AI_Content_Moderation_Based_on_Gemma.html#appendix",
    "title": "ShieldGemma: Generative AI Content Moderation Based on Gemma",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21772v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21772v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5579"
  },
  {
    "objectID": "posts/Critique_out_Loud_Reward_Models/2024-08-21-Critique_out_Loud_Reward_Models.html#appendix",
    "href": "posts/Critique_out_Loud_Reward_Models/2024-08-21-Critique_out_Loud_Reward_Models.html#appendix",
    "title": "Critique-out-Loud Reward Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11791v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11791v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8502"
  },
  {
    "objectID": "posts/Enabling_Uniform_Computer_Interaction_Experience_for_Blind_Users_through_Large_Language_Models/2024-07-28-Enabling_Uniform_Computer_Interaction_Experience_for_Blind_Users_through_Large_Language_Models.html#appendix",
    "href": "posts/Enabling_Uniform_Computer_Interaction_Experience_for_Blind_Users_through_Large_Language_Models/2024-07-28-Enabling_Uniform_Computer_Interaction_Experience_for_Blind_Users_through_Large_Language_Models.html#appendix",
    "title": "Enabling Uniform Computer Interaction Experience for Blind Users through Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19537v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19537v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13074"
  },
  {
    "objectID": "posts/Game_Development_as_Human_LLM_Interaction/2024-08-18-Game_Development_as_Human_LLM_Interaction.html#appendix",
    "href": "posts/Game_Development_as_Human_LLM_Interaction/2024-08-18-Game_Development_as_Human_LLM_Interaction.html#appendix",
    "title": "Game Development as Human-LLM Interaction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09386v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09386v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5925"
  },
  {
    "objectID": "posts/Confidence_weighted_integration_of_human_and_machine_judgments_for_superior_decision_making/2024-08-15-Confidence_weighted_integration_of_human_and_machine_judgments_for_superior_decision_making.html#appendix",
    "href": "posts/Confidence_weighted_integration_of_human_and_machine_judgments_for_superior_decision_making/2024-08-15-Confidence_weighted_integration_of_human_and_machine_judgments_for_superior_decision_making.html#appendix",
    "title": "Confidence-weighted integration of human and machine judgments for superior decision-making",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.08083v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.08083v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4433"
  },
  {
    "objectID": "posts/Concise_Thoughts_Impact_of_Output_Length_on_LLM_Reasoning_and_Cost/2024-07-29-Concise_Thoughts_Impact_of_Output_Length_on_LLM_Reasoning_and_Cost.html#appendix",
    "href": "posts/Concise_Thoughts_Impact_of_Output_Length_on_LLM_Reasoning_and_Cost/2024-07-29-Concise_Thoughts_Impact_of_Output_Length_on_LLM_Reasoning_and_Cost.html#appendix",
    "title": "Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19825v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19825v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9488"
  },
  {
    "objectID": "posts/Empirical_Study_of_Symmetrical_Reasoning_in_Conversational_Chatbots/2024-07-08-Empirical_Study_of_Symmetrical_Reasoning_in_Conversational_Chatbots.html#appendix",
    "href": "posts/Empirical_Study_of_Symmetrical_Reasoning_in_Conversational_Chatbots/2024-07-08-Empirical_Study_of_Symmetrical_Reasoning_in_Conversational_Chatbots.html#appendix",
    "title": "Empirical Study of Symmetrical Reasoning in Conversational Chatbots",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05734v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05734v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4950"
  },
  {
    "objectID": "posts/Simulating_Field_Experiments_with_Large_Language_Models/2024-08-19-Simulating_Field_Experiments_with_Large_Language_Models.html#appendix",
    "href": "posts/Simulating_Field_Experiments_with_Large_Language_Models/2024-08-19-Simulating_Field_Experiments_with_Large_Language_Models.html#appendix",
    "title": "Simulating Field Experiments with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09682v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09682v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7412"
  },
  {
    "objectID": "posts/MAPLE_Enhancing_Review_Generation_with_Multi_Aspect_Prompt_LEarning_in_Explainable_Recommendation/2024-08-19-MAPLE_Enhancing_Review_Generation_with_Multi_Aspect_Prompt_LEarning_in_Explainable_Recommendation.html#appendix",
    "href": "posts/MAPLE_Enhancing_Review_Generation_with_Multi_Aspect_Prompt_LEarning_in_Explainable_Recommendation/2024-08-19-MAPLE_Enhancing_Review_Generation_with_Multi_Aspect_Prompt_LEarning_in_Explainable_Recommendation.html#appendix",
    "title": "MAPLE: Enhancing Review Generation with Multi-Aspect Prompt LEarning in Explainable Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09865v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09865v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8535"
  },
  {
    "objectID": "posts/Selective_Prompting_Tuning_for_Personalized_Conversations_with_LLMs/2024-06-26-Selective_Prompting_Tuning_for_Personalized_Conversations_with_LLMs.html#appendix",
    "href": "posts/Selective_Prompting_Tuning_for_Personalized_Conversations_with_LLMs/2024-06-26-Selective_Prompting_Tuning_for_Personalized_Conversations_with_LLMs.html#appendix",
    "title": "Selective Prompting Tuning for Personalized Conversations with LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18187v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18187v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8201"
  },
  {
    "objectID": "posts/Comparison_of_Static_Application_Security_Testing_Tools_and_Large_Language_Models_for_Repo_level_Vulnerability_Detection/2024-07-23-Comparison_of_Static_Application_Security_Testing_Tools_and_Large_Language_Models_for_Repo_level_Vulnerability_Detection.html#appendix",
    "href": "posts/Comparison_of_Static_Application_Security_Testing_Tools_and_Large_Language_Models_for_Repo_level_Vulnerability_Detection/2024-07-23-Comparison_of_Static_Application_Security_Testing_Tools_and_Large_Language_Models_for_Repo_level_Vulnerability_Detection.html#appendix",
    "title": "Comparison of Static Application Security Testing Tools and Large Language Models for Repo-level Vulnerability Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16235v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16235v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12620"
  },
  {
    "objectID": "posts/Ferret_Faster_and_Effective_Automated_Red_Teaming_with_Reward_Based_Scoring_Technique/2024-08-20-Ferret_Faster_and_Effective_Automated_Red_Teaming_with_Reward_Based_Scoring_Technique.html#appendix",
    "href": "posts/Ferret_Faster_and_Effective_Automated_Red_Teaming_with_Reward_Based_Scoring_Technique/2024-08-20-Ferret_Faster_and_Effective_Automated_Red_Teaming_with_Reward_Based_Scoring_Technique.html#appendix",
    "title": "Ferret: Faster and Effective Automated Red Teaming with Reward-Based Scoring Technique",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10701v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10701v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14352"
  },
  {
    "objectID": "posts/Leveraging_Large_Language_Models_for_Efficient_Failure_Analysis_in_Game_Development/2024-06-11-Leveraging_Large_Language_Models_for_Efficient_Failure_Analysis_in_Game_Development.html#appendix",
    "href": "posts/Leveraging_Large_Language_Models_for_Efficient_Failure_Analysis_in_Game_Development/2024-06-11-Leveraging_Large_Language_Models_for_Efficient_Failure_Analysis_in_Game_Development.html#appendix",
    "title": "Leveraging Large Language Models for Efficient Failure Analysis in Game Development",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07084v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07084v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6064"
  },
  {
    "objectID": "posts/Single_Codec_Single_Codebook_Speech_Codec_towards_High_Performance_Speech_Generation/2024-06-11-Single_Codec_Single_Codebook_Speech_Codec_towards_High_Performance_Speech_Generation.html#appendix",
    "href": "posts/Single_Codec_Single_Codebook_Speech_Codec_towards_High_Performance_Speech_Generation/2024-06-11-Single_Codec_Single_Codebook_Speech_Codec_towards_High_Performance_Speech_Generation.html#appendix",
    "title": "Single-Codec: Single-Codebook Speech Codec towards High-Performance Speech Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07422v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07422v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4062"
  },
  {
    "objectID": "posts/Towards_interfacing_large_language_models_with_ASR_systems_using_confidence_measures_and_prompting/2024-07-31-Towards_interfacing_large_language_models_with_ASR_systems_using_confidence_measures_and_prompting.html#appendix",
    "href": "posts/Towards_interfacing_large_language_models_with_ASR_systems_using_confidence_measures_and_prompting/2024-07-31-Towards_interfacing_large_language_models_with_ASR_systems_using_confidence_measures_and_prompting.html#appendix",
    "title": "Towards interfacing large language models with ASR systems using confidence measures and prompting",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21414v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21414v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4127"
  },
  {
    "objectID": "posts/A_Survey_on_Human_Preference_Learning_for_Large_Language_Models/2024-06-17-A_Survey_on_Human_Preference_Learning_for_Large_Language_Models.html#appendix",
    "href": "posts/A_Survey_on_Human_Preference_Learning_for_Large_Language_Models/2024-06-17-A_Survey_on_Human_Preference_Learning_for_Large_Language_Models.html#appendix",
    "title": "A Survey on Human Preference Learning for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11191v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11191v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12223"
  },
  {
    "objectID": "posts/Academic_collaboration_on_large_language_model_studies_increases_overall_but_varies_across_disciplines/2024-08-08-Academic_collaboration_on_large_language_model_studies_increases_overall_but_varies_across_disciplines.html#appendix",
    "href": "posts/Academic_collaboration_on_large_language_model_studies_increases_overall_but_varies_across_disciplines/2024-08-08-Academic_collaboration_on_large_language_model_studies_increases_overall_but_varies_across_disciplines.html#appendix",
    "title": "Academic collaboration on large language model studies increases overall but varies across disciplines",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04163v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04163v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9002"
  },
  {
    "objectID": "posts/LangSuitE_Planning_Controlling_and_Interacting_with_Large_Language_Models_in_Embodied_Text_Environments/2024-06-24-LangSuitE_Planning_Controlling_and_Interacting_with_Large_Language_Models_in_Embodied_Text_Environments.html#appendix",
    "href": "posts/LangSuitE_Planning_Controlling_and_Interacting_with_Large_Language_Models_in_Embodied_Text_Environments/2024-06-24-LangSuitE_Planning_Controlling_and_Interacting_with_Large_Language_Models_in_Embodied_Text_Environments.html#appendix",
    "title": "LangSuitE: Planning, Controlling and Interacting with Large Language Models in Embodied Text Environments",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16294v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16294v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7622"
  },
  {
    "objectID": "posts/Against_All_Odds_Overcoming_Typology_Script_and_Language_Confusion_in_Multilingual_Embedding_Inversion_Attacks/2024-08-21-Against_All_Odds_Overcoming_Typology_Script_and_Language_Confusion_in_Multilingual_Embedding_Inversion_Attacks.html#appendix",
    "href": "posts/Against_All_Odds_Overcoming_Typology_Script_and_Language_Confusion_in_Multilingual_Embedding_Inversion_Attacks/2024-08-21-Against_All_Odds_Overcoming_Typology_Script_and_Language_Confusion_in_Multilingual_Embedding_Inversion_Attacks.html#appendix",
    "title": "Against All Odds: Overcoming Typology, Script, and Language Confusion in Multilingual Embedding Inversion Attacks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11749v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11749v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7373"
  },
  {
    "objectID": "posts/Privacy_in_LLM_based_Recommendation_Recent_Advances_and_Future_Directions/2024-06-03-Privacy_in_LLM_based_Recommendation_Recent_Advances_and_Future_Directions.html#appendix",
    "href": "posts/Privacy_in_LLM_based_Recommendation_Recent_Advances_and_Future_Directions/2024-06-03-Privacy_in_LLM_based_Recommendation_Recent_Advances_and_Future_Directions.html#appendix",
    "title": "Privacy in LLM-based Recommendation: Recent Advances and Future Directions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01363v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01363v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3447"
  },
  {
    "objectID": "posts/Fine_tuned_network_relies_on_generic_representation_to_solve_unseen_cognitive_task/2024-06-27-Fine_tuned_network_relies_on_generic_representation_to_solve_unseen_cognitive_task.html#appendix",
    "href": "posts/Fine_tuned_network_relies_on_generic_representation_to_solve_unseen_cognitive_task/2024-06-27-Fine_tuned_network_relies_on_generic_representation_to_solve_unseen_cognitive_task.html#appendix",
    "title": "Fine-tuned network relies on generic representation to solve unseen cognitive task",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18926v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18926v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4648"
  },
  {
    "objectID": "posts/Speculative_RAG_Enhancing_Retrieval_Augmented_Generation_through_Drafting/2024-07-11-Speculative_RAG_Enhancing_Retrieval_Augmented_Generation_through_Drafting.html#appendix",
    "href": "posts/Speculative_RAG_Enhancing_Retrieval_Augmented_Generation_through_Drafting/2024-07-11-Speculative_RAG_Enhancing_Retrieval_Augmented_Generation_through_Drafting.html#appendix",
    "title": "Speculative RAG: Enhancing Retrieval Augmented Generation through Drafting",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08223v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08223v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7800"
  },
  {
    "objectID": "posts/MIRAI_Evaluating_LLM_Agents_for_Event_Forecasting/2024-07-01-MIRAI_Evaluating_LLM_Agents_for_Event_Forecasting.html#appendix",
    "href": "posts/MIRAI_Evaluating_LLM_Agents_for_Event_Forecasting/2024-07-01-MIRAI_Evaluating_LLM_Agents_for_Event_Forecasting.html#appendix",
    "title": "MIRAI: Evaluating LLM Agents for Event Forecasting",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01231v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01231v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4187"
  },
  {
    "objectID": "posts/A_Comparison_of_Large_Language_Model_and_Human_Performance_on_Random_Number_Generation_Tasks/2024-08-19-A_Comparison_of_Large_Language_Model_and_Human_Performance_on_Random_Number_Generation_Tasks.html#appendix",
    "href": "posts/A_Comparison_of_Large_Language_Model_and_Human_Performance_on_Random_Number_Generation_Tasks/2024-08-19-A_Comparison_of_Large_Language_Model_and_Human_Performance_on_Random_Number_Generation_Tasks.html#appendix",
    "title": "A Comparison of Large Language Model and Human Performance on Random Number Generation Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09656v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09656v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4221"
  },
  {
    "objectID": "posts/Prose_to_P4_Leveraging_High_Level_Languages/2024-06-19-Prose_to_P4_Leveraging_High_Level_Languages.html#appendix",
    "href": "posts/Prose_to_P4_Leveraging_High_Level_Languages/2024-06-19-Prose_to_P4_Leveraging_High_Level_Languages.html#appendix",
    "title": "Prose-to-P4: Leveraging High Level Languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13679v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13679v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4347"
  },
  {
    "objectID": "posts/TRIZ_GPT_An_LLM_augmented_method_for_problem_solving/2024-08-12-TRIZ_GPT_An_LLM_augmented_method_for_problem_solving.html",
    "href": "posts/TRIZ_GPT_An_LLM_augmented_method_for_problem_solving/2024-08-12-TRIZ_GPT_An_LLM_augmented_method_for_problem_solving.html",
    "title": "TRIZ-GPT: An LLM-augmented method for problem-solving",
    "section": "",
    "text": "Summary:\nThe study explores the application of Large Language Models (LLMs) within the TRIZ-based problem-solving process. The authors construct TRIZ case collections and design a workflow that utilizes step-by-step reasoning and evaluation-validated prompt strategies to transform concrete problems into TRIZ problems and generate inventive solutions. The main contributions of the research include the development of TRIZ case collections, workflow design, and evaluations and case studies.\nMajor Findings:\nAnalysis and Critique:\nThe study presents a novel approach to addressing the challenges associated with the acquisition and application of TRIZ knowledge by leveraging the extensive knowledge bases and reasoning capabilities of LLMs. The use of TRIZ case collections and a specifically designed workflow allows for the transformation of concrete problems into TRIZ problems and the generation of inventive solutions. However, the study does not address potential limitations, unanswered questions, or biases that may have arisen during the research process. Additionally, the methodological issues, conflicting evidence, or areas that require further research or clarification are not discussed. The study could benefit from a more comprehensive analysis of the potential problems and shortcomings of the proposed approach."
  },
  {
    "objectID": "posts/TRIZ_GPT_An_LLM_augmented_method_for_problem_solving/2024-08-12-TRIZ_GPT_An_LLM_augmented_method_for_problem_solving.html#appendix",
    "href": "posts/TRIZ_GPT_An_LLM_augmented_method_for_problem_solving/2024-08-12-TRIZ_GPT_An_LLM_augmented_method_for_problem_solving.html#appendix",
    "title": "TRIZ-GPT: An LLM-augmented method for problem-solving",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.05897v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.05897v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9497"
  },
  {
    "objectID": "posts/Image_Score_Learning_and_Evaluating_Human_Preferences_for_Mercari_Search/2024-08-21-Image_Score_Learning_and_Evaluating_Human_Preferences_for_Mercari_Search.html#appendix",
    "href": "posts/Image_Score_Learning_and_Evaluating_Human_Preferences_for_Mercari_Search/2024-08-21-Image_Score_Learning_and_Evaluating_Human_Preferences_for_Mercari_Search.html#appendix",
    "title": "Image Score: Learning and Evaluating Human Preferences for Mercari Search",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11349v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11349v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6076"
  },
  {
    "objectID": "posts/SceneMotifCoder_Example_driven_Visual_Program_Learning_for_Generating_3D_Object_Arrangements/2024-08-05-SceneMotifCoder_Example_driven_Visual_Program_Learning_for_Generating_3D_Object_Arrangements.html#appendix",
    "href": "posts/SceneMotifCoder_Example_driven_Visual_Program_Learning_for_Generating_3D_Object_Arrangements/2024-08-05-SceneMotifCoder_Example_driven_Visual_Program_Learning_for_Generating_3D_Object_Arrangements.html#appendix",
    "title": "SceneMotifCoder: Example-driven Visual Program Learning for Generating 3D Object Arrangements",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02211v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02211v1\n\n\nTruncated\nTrue\n\n\nWord Count\n37815"
  },
  {
    "objectID": "posts/Embodied_AI_in_Mobile_Robots_Coverage_Path_Planning_with_Large_Language_Models/2024-07-02-Embodied_AI_in_Mobile_Robots_Coverage_Path_Planning_with_Large_Language_Models.html#appendix",
    "href": "posts/Embodied_AI_in_Mobile_Robots_Coverage_Path_Planning_with_Large_Language_Models/2024-07-02-Embodied_AI_in_Mobile_Robots_Coverage_Path_Planning_with_Large_Language_Models.html#appendix",
    "title": "Embodied AI in Mobile Robots: Coverage Path Planning with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02220v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02220v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4205"
  },
  {
    "objectID": "posts/RES_Q_Evaluating_Code_Editing_Large_Language_Model_Systems_at_the_Repository_Scale/2024-06-24-RES_Q_Evaluating_Code_Editing_Large_Language_Model_Systems_at_the_Repository_Scale.html#appendix",
    "href": "posts/RES_Q_Evaluating_Code_Editing_Large_Language_Model_Systems_at_the_Repository_Scale/2024-06-24-RES_Q_Evaluating_Code_Editing_Large_Language_Model_Systems_at_the_Repository_Scale.html#appendix",
    "title": "RES-Q: Evaluating Code-Editing Large Language Model Systems at the Repository Scale",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16801v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16801v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3509"
  },
  {
    "objectID": "posts/I_Couldve_Asked_That_Reformulating_Unanswerable_Questions/2024-07-24-I_Couldve_Asked_That_Reformulating_Unanswerable_Questions.html#appendix",
    "href": "posts/I_Couldve_Asked_That_Reformulating_Unanswerable_Questions/2024-07-24-I_Couldve_Asked_That_Reformulating_Unanswerable_Questions.html#appendix",
    "title": "I Could’ve Asked That: Reformulating Unanswerable Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17469v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17469v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1972"
  },
  {
    "objectID": "posts/SDoH_GPT_Using_Large_Language_Models_to_Extract_Social_Determinants_of_Health_(SDoH)/2024-07-24-SDoH_GPT_Using_Large_Language_Models_to_Extract_Social_Determinants_of_Health_(SDoH).html#appendix",
    "href": "posts/SDoH_GPT_Using_Large_Language_Models_to_Extract_Social_Determinants_of_Health_(SDoH)/2024-07-24-SDoH_GPT_Using_Large_Language_Models_to_Extract_Social_Determinants_of_Health_(SDoH).html#appendix",
    "title": "SDoH-GPT: Using Large Language Models to Extract Social Determinants of Health (SDoH)",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17126v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17126v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9716"
  },
  {
    "objectID": "posts/Self_Evaluation_as_a_Defense_Against_Adversarial_Attacks_on_LLMs/2024-07-03-Self_Evaluation_as_a_Defense_Against_Adversarial_Attacks_on_LLMs.html#appendix",
    "href": "posts/Self_Evaluation_as_a_Defense_Against_Adversarial_Attacks_on_LLMs/2024-07-03-Self_Evaluation_as_a_Defense_Against_Adversarial_Attacks_on_LLMs.html#appendix",
    "title": "Self-Evaluation as a Defense Against Adversarial Attacks on LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03234v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03234v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18444"
  },
  {
    "objectID": "posts/Out_of_distribution_generalization_via_composition_a_lens_through_induction_heads_in_Transformers/2024-08-18-Out_of_distribution_generalization_via_composition_a_lens_through_induction_heads_in_Transformers.html",
    "href": "posts/Out_of_distribution_generalization_via_composition_a_lens_through_induction_heads_in_Transformers/2024-08-18-Out_of_distribution_generalization_via_composition_a_lens_through_induction_heads_in_Transformers.html",
    "title": "Out-of-distribution generalization via composition: a lens through induction heads in Transformers",
    "section": "",
    "text": "Summary:\nThis paper explores the out-of-distribution (OOD) generalization capabilities of large language models (LLMs) through the lens of induction heads in Transformers. The authors examine OOD generalization in settings where instances are generated according to hidden rules, including in-context learning with symbolic reasoning. They empirically investigate the training dynamics of Transformers on a synthetic example and conduct extensive experiments on various pretrained LLMs, focusing on induction heads. The study reveals that OOD generalization and composition are intertwined, with models learning rules by composing two self-attention layers, thereby achieving OOD generalization. Furthermore, a shared latent subspace in the embedding space acts as a bridge for composition by aligning early layers and later layers, a concept referred to as the common bridge representation hypothesis.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides valuable insights into the OOD generalization capabilities of LLMs and the role of induction heads in Transformers. However, the study is limited to a specific set of tasks and models, and further research is needed to explore the generalizability of the findings. Additionally, the paper does not address the potential impact of model size and architecture on OOD generalization. The authors acknowledge these limitations and suggest that future work should explore alternative mechanisms for compositions and examine variants or practical techniques in LLMs that may impact the common bridge representation hypothesis."
  },
  {
    "objectID": "posts/Out_of_distribution_generalization_via_composition_a_lens_through_induction_heads_in_Transformers/2024-08-18-Out_of_distribution_generalization_via_composition_a_lens_through_induction_heads_in_Transformers.html#appendix",
    "href": "posts/Out_of_distribution_generalization_via_composition_a_lens_through_induction_heads_in_Transformers/2024-08-18-Out_of_distribution_generalization_via_composition_a_lens_through_induction_heads_in_Transformers.html#appendix",
    "title": "Out-of-distribution generalization via composition: a lens through induction heads in Transformers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09503v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09503v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11571"
  },
  {
    "objectID": "posts/A_Proposed_S.C.O.R.E._Evaluation_Framework_for_Large_Language_Models__Safety_Consensus_Objectivity_Reproducibility_and_Explainability/2024-07-10-A_Proposed_S.C.O.R.E._Evaluation_Framework_for_Large_Language_Models__Safety_Consensus_Objectivity_Reproducibility_and_Explainability.html#appendix",
    "href": "posts/A_Proposed_S.C.O.R.E._Evaluation_Framework_for_Large_Language_Models__Safety_Consensus_Objectivity_Reproducibility_and_Explainability/2024-07-10-A_Proposed_S.C.O.R.E._Evaluation_Framework_for_Large_Language_Models__Safety_Consensus_Objectivity_Reproducibility_and_Explainability.html#appendix",
    "title": "A Proposed S.C.O.R.E. Evaluation Framework for Large Language Models : Safety, Consensus, Objectivity, Reproducibility and Explainability",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07666v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07666v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5995"
  },
  {
    "objectID": "posts/Teaching_LLMs_to_Abstain_across_Languages_via_Multilingual_Feedback/2024-06-22-Teaching_LLMs_to_Abstain_across_Languages_via_Multilingual_Feedback.html",
    "href": "posts/Teaching_LLMs_to_Abstain_across_Languages_via_Multilingual_Feedback/2024-06-22-Teaching_LLMs_to_Abstain_across_Languages_via_Multilingual_Feedback.html",
    "title": "Teaching LLMs to Abstain across Languages via Multilingual Feedback",
    "section": "",
    "text": "Summary:\nThe paper presents a study on teaching multilingual large language models (LLMs) to abstain from answering when they encounter knowledge gaps, with a focus on mitigating hallucinations in multilingual settings. The authors propose a strategy that involves generating and learning from multilingual feedback in related languages, which helps identify knowledge gaps across diverse languages, cultures, and communities. The proposed approach is evaluated on three datasets featuring open-book, closed-book, and commonsense QA, and is shown to outperform various strong baselines, achieving up to 9.2% improvement for low-resource languages. The study also reveals that multilingual feedback is an effective and more equitable abstain strategy, with cultural factors playing a significant role in language selection and LLM abstention behavior.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel approach to teaching LLMs to abstain from answering in the face of knowledge gaps, with a focus on multilingual settings. The proposed strategy of generating and learning from multilingual feedback in related languages is shown to be effective in identifying knowledge gaps and improving LLM abstention behavior. However, the study is limited in its evaluation of the proposed approach on only three datasets, and it is unclear how well the approach would generalize to other datasets and tasks. Additionally, the study does not address potential issues related to the quality and reliability of the generated feedback, which could impact the effectiveness of the proposed approach. Further research is needed to address these limitations and evaluate the proposed approach in a more comprehensive manner."
  },
  {
    "objectID": "posts/Teaching_LLMs_to_Abstain_across_Languages_via_Multilingual_Feedback/2024-06-22-Teaching_LLMs_to_Abstain_across_Languages_via_Multilingual_Feedback.html#appendix",
    "href": "posts/Teaching_LLMs_to_Abstain_across_Languages_via_Multilingual_Feedback/2024-06-22-Teaching_LLMs_to_Abstain_across_Languages_via_Multilingual_Feedback.html#appendix",
    "title": "Teaching LLMs to Abstain across Languages via Multilingual Feedback",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.15948v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.15948v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8591"
  },
  {
    "objectID": "posts/Defending_Jailbreak_Attack_in_VLMs_via_Cross_modality_Information_Detector/2024-07-31-Defending_Jailbreak_Attack_in_VLMs_via_Cross_modality_Information_Detector.html#major-findings",
    "href": "posts/Defending_Jailbreak_Attack_in_VLMs_via_Cross_modality_Information_Detector/2024-07-31-Defending_Jailbreak_Attack_in_VLMs_via_Cross_modality_Information_Detector.html#major-findings",
    "title": "Defending Jailbreak Attack in VLMs via Cross-modality Information Detector",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nCIDER is a simple yet effective cross-modality information detector that is independent of the target VLMs and requires less computation cost.\nExtensive experimental results demonstrate the effectiveness and efficiency of CIDER, as well as its transferability to both white-box and black-box VLMs.\nCIDER is a plug-and-play jailbreaking detector that can effectively safeguard VLMs while incurring almost no additional computational overhead."
  },
  {
    "objectID": "posts/Defending_Jailbreak_Attack_in_VLMs_via_Cross_modality_Information_Detector/2024-07-31-Defending_Jailbreak_Attack_in_VLMs_via_Cross_modality_Information_Detector.html#analysis-and-critique",
    "href": "posts/Defending_Jailbreak_Attack_in_VLMs_via_Cross_modality_Information_Detector/2024-07-31-Defending_Jailbreak_Attack_in_VLMs_via_Cross_modality_Information_Detector.html#analysis-and-critique",
    "title": "Defending Jailbreak Attack in VLMs via Cross-modality Information Detector",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a promising approach to enhancing the security of VLMs against jailbreak attacks. However, the following limitations and potential areas for improvement should be considered:\n\nThe effectiveness of CIDER heavily relies on the quality of the cross-modal embeddings used to represent the image and text inputs. The performance of CIDER may be affected by the choice of the embedding method and the quality of the pre-trained models used to generate the embeddings.\nThe paper does not provide a detailed analysis of the robustness of CIDER against different types of adversarial attacks. It would be interesting to evaluate the performance of CIDER against a wider range of adversarial attacks, including those that target the image and text modalities separately.\nThe paper does not discuss the potential impact of CIDER on the performance of VLMs in downstream tasks. It would be important to evaluate the trade-off between the security benefits of using CIDER and the potential impact on the performance of VLMs in real-world applications.\n\nOverall, the paper presents a promising approach to enhancing the security of VLMs against jailbreak attacks. However, further research is needed to address the limitations and potential areas for improvement identified in this analysis."
  },
  {
    "objectID": "posts/Defending_Jailbreak_Attack_in_VLMs_via_Cross_modality_Information_Detector/2024-07-31-Defending_Jailbreak_Attack_in_VLMs_via_Cross_modality_Information_Detector.html#appendix",
    "href": "posts/Defending_Jailbreak_Attack_in_VLMs_via_Cross_modality_Information_Detector/2024-07-31-Defending_Jailbreak_Attack_in_VLMs_via_Cross_modality_Information_Detector.html#appendix",
    "title": "Defending Jailbreak Attack in VLMs via Cross-modality Information Detector",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21659v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21659v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6517"
  },
  {
    "objectID": "posts/Safety_Alignment_Should_Be_Made_More_Than_Just_a_Few_Tokens_Deep/2024-06-10-Safety_Alignment_Should_Be_Made_More_Than_Just_a_Few_Tokens_Deep.html#appendix",
    "href": "posts/Safety_Alignment_Should_Be_Made_More_Than_Just_a_Few_Tokens_Deep/2024-06-10-Safety_Alignment_Should_Be_Made_More_Than_Just_a_Few_Tokens_Deep.html#appendix",
    "title": "Safety Alignment Should Be Made More Than Just a Few Tokens Deep",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05946v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05946v1\n\n\nTruncated\nFalse\n\n\nWord Count\n16740"
  },
  {
    "objectID": "posts/WaDec_Decompile_WebAssembly_Using_Large_Language_Model/2024-06-17-WaDec_Decompile_WebAssembly_Using_Large_Language_Model.html#appendix",
    "href": "posts/WaDec_Decompile_WebAssembly_Using_Large_Language_Model/2024-06-17-WaDec_Decompile_WebAssembly_Using_Large_Language_Model.html#appendix",
    "title": "WaDec: Decompile WebAssembly Using Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11346v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11346v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10923"
  },
  {
    "objectID": "posts/PrimeGuard_Safe_and_Helpful_LLMs_through_Tuning_Free_Routing/2024-07-23-PrimeGuard_Safe_and_Helpful_LLMs_through_Tuning_Free_Routing.html#major-findings",
    "href": "posts/PrimeGuard_Safe_and_Helpful_LLMs_through_Tuning_Free_Routing/2024-07-23-PrimeGuard_Safe_and_Helpful_LLMs_through_Tuning_Free_Routing.html#major-findings",
    "title": "PrimeGuard: Safe and Helpful LLMs through Tuning-Free Routing",
    "section": "Major Findings",
    "text": "Major Findings\n\nPrimeGuard, a novel ITG method, utilizes structured control flow and exception handling to overcome the guardrail tax, a trade-off between safety and helpfulness.\nThe method employs two language models, LLMMain and LLMGuard, with LLMGuard evaluating the risk of answering a user query based on system guidelines.\nPrimeGuard achieves high levels of both safety and helpfulness by routing queries posing higher risks to refusals or re-evaluation against restrictive system instructions, while low-risk queries are encouraged to adhere to directive instructions.\nThe method is evaluated across multiple relevant defense directions, including the safe-eval dataset, XSTest, and TAP, a state-of-the-art automated method for red-teaming.\nPrimeGuard significantly outperforms the present-day Pareto frontier by achieving high safety and usefulness across different model sizes."
  },
  {
    "objectID": "posts/PrimeGuard_Safe_and_Helpful_LLMs_through_Tuning_Free_Routing/2024-07-23-PrimeGuard_Safe_and_Helpful_LLMs_through_Tuning_Free_Routing.html#analysis-and-critique",
    "href": "posts/PrimeGuard_Safe_and_Helpful_LLMs_through_Tuning_Free_Routing/2024-07-23-PrimeGuard_Safe_and_Helpful_LLMs_through_Tuning_Free_Routing.html#analysis-and-critique",
    "title": "PrimeGuard: Safe and Helpful LLMs through Tuning-Free Routing",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\nThe paper presents a promising approach to addressing the guardrail tax, a significant challenge in deploying language models. The proposed method, PrimeGuard, demonstrates impressive results in maintaining helpfulness while maximizing adherence to custom safety guidelines. The use of structured control flow and exception handling to dynamically overcome the guardrail tax is a novel and effective approach.\nHowever, the paper does not discuss potential limitations or shortcomings of the proposed method. For instance, the reliance on two language models, LLMMain and LLMGuard, may introduce additional"
  },
  {
    "objectID": "posts/PrimeGuard_Safe_and_Helpful_LLMs_through_Tuning_Free_Routing/2024-07-23-PrimeGuard_Safe_and_Helpful_LLMs_through_Tuning_Free_Routing.html#appendix",
    "href": "posts/PrimeGuard_Safe_and_Helpful_LLMs_through_Tuning_Free_Routing/2024-07-23-PrimeGuard_Safe_and_Helpful_LLMs_through_Tuning_Free_Routing.html#appendix",
    "title": "PrimeGuard: Safe and Helpful LLMs through Tuning-Free Routing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16318v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16318v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17231"
  },
  {
    "objectID": "posts/An_Evaluation_of_Requirements_Modeling_for_Cyber_Physical_Systems_via_LLMs/2024-08-05-An_Evaluation_of_Requirements_Modeling_for_Cyber_Physical_Systems_via_LLMs.html",
    "href": "posts/An_Evaluation_of_Requirements_Modeling_for_Cyber_Physical_Systems_via_LLMs/2024-08-05-An_Evaluation_of_Requirements_Modeling_for_Cyber_Physical_Systems_via_LLMs.html",
    "title": "An Evaluation of Requirements Modeling for Cyber-Physical Systems via LLMs",
    "section": "",
    "text": "Summary:\nThis paper evaluates the performance of large language models (LLMs) in modeling cyber-physical systems (CPSs) requirements using problem diagrams. The authors propose a benchmark called CPSBench, which consists of 12 enterprise-level requirements documents and 30 tutorial cases. They apply a few-shot reasoning strategy to evaluate the capabilities and limitations of seven advanced LLMs. The evaluation reveals that LLMs have limited effectiveness in modeling CPSs requirements using problem diagrams for practical applications, with a recall rate of only around 60%. LLMs have a better understanding of general requirements concepts than specialized concepts, and their performance can be improved with more shots in the prompt. The authors also establish a taxonomy of LLMs hallucinations in CPSs requirements modeling.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive evaluation of the capabilities and limitations of LLMs in CPSs requirements modeling using problem diagrams. However, the evaluation is limited to seven advanced LLMs, and the results may not generalize to other LLMs. Additionally, the authors do not discuss the potential impact of the quality and complexity of the requirements documents on the performance of LLMs. The paper also does not provide a detailed comparison of the performance of LLMs with other approaches for CPSs requirements modeling. Finally, the authors do not discuss the potential ethical implications of using LLMs for CPSs requirements modeling, such as the risk of introducing biases or errors in the requirements."
  },
  {
    "objectID": "posts/An_Evaluation_of_Requirements_Modeling_for_Cyber_Physical_Systems_via_LLMs/2024-08-05-An_Evaluation_of_Requirements_Modeling_for_Cyber_Physical_Systems_via_LLMs.html#appendix",
    "href": "posts/An_Evaluation_of_Requirements_Modeling_for_Cyber_Physical_Systems_via_LLMs/2024-08-05-An_Evaluation_of_Requirements_Modeling_for_Cyber_Physical_Systems_via_LLMs.html#appendix",
    "title": "An Evaluation of Requirements Modeling for Cyber-Physical Systems via LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02450v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02450v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8576"
  },
  {
    "objectID": "posts/A_Transcription_Prompt_based_Efficient_Audio_Large_Language_Model_for_Robust_Speech_Recognition/2024-08-18-A_Transcription_Prompt_based_Efficient_Audio_Large_Language_Model_for_Robust_Speech_Recognition.html#appendix",
    "href": "posts/A_Transcription_Prompt_based_Efficient_Audio_Large_Language_Model_for_Robust_Speech_Recognition/2024-08-18-A_Transcription_Prompt_based_Efficient_Audio_Large_Language_Model_for_Robust_Speech_Recognition.html#appendix",
    "title": "A Transcription Prompt-based Efficient Audio Large Language Model for Robust Speech Recognition",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09491v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09491v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3902"
  },
  {
    "objectID": "posts/African_or_European_Swallow_Benchmarking_Large_Vision_Language_Models_for_Fine_Grained_Object_Classification/2024-06-20-African_or_European_Swallow_Benchmarking_Large_Vision_Language_Models_for_Fine_Grained_Object_Classification.html#appendix",
    "href": "posts/African_or_European_Swallow_Benchmarking_Large_Vision_Language_Models_for_Fine_Grained_Object_Classification/2024-06-20-African_or_European_Swallow_Benchmarking_Large_Vision_Language_Models_for_Fine_Grained_Object_Classification.html#appendix",
    "title": "African or European Swallow? Benchmarking Large Vision-Language Models for Fine-Grained Object Classification",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14496v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14496v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8786"
  },
  {
    "objectID": "posts/CoRA_Collaborative_Information_Perception_by_Large_Language_Models_Weights_for_Recommendation/2024-08-20-CoRA_Collaborative_Information_Perception_by_Large_Language_Models_Weights_for_Recommendation.html#appendix",
    "href": "posts/CoRA_Collaborative_Information_Perception_by_Large_Language_Models_Weights_for_Recommendation/2024-08-20-CoRA_Collaborative_Information_Perception_by_Large_Language_Models_Weights_for_Recommendation.html#appendix",
    "title": "CoRA: Collaborative Information Perception by Large Language Model’s Weights for Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10645v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10645v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6279"
  },
  {
    "objectID": "posts/MMBench_Video_A_Long_Form_Multi_Shot_Benchmark_for_Holistic_Video_Understanding/2024-06-20-MMBench_Video_A_Long_Form_Multi_Shot_Benchmark_for_Holistic_Video_Understanding.html#appendix",
    "href": "posts/MMBench_Video_A_Long_Form_Multi_Shot_Benchmark_for_Holistic_Video_Understanding/2024-06-20-MMBench_Video_A_Long_Form_Multi_Shot_Benchmark_for_Holistic_Video_Understanding.html#appendix",
    "title": "MMBench-Video: A Long-Form Multi-Shot Benchmark for Holistic Video Understanding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14515v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14515v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8501"
  },
  {
    "objectID": "posts/Q_Sparse_All_Large_Language_Models_can_be_Fully_Sparsely_Activated/2024-07-15-Q_Sparse_All_Large_Language_Models_can_be_Fully_Sparsely_Activated.html#appendix",
    "href": "posts/Q_Sparse_All_Large_Language_Models_can_be_Fully_Sparsely_Activated/2024-07-15-Q_Sparse_All_Large_Language_Models_can_be_Fully_Sparsely_Activated.html#appendix",
    "title": "Q-Sparse: All Large Language Models can be Fully Sparsely-Activated",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10969v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10969v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5530"
  },
  {
    "objectID": "posts/Multi_Agent_Software_Development_through_Cross_Team_Collaboration/2024-06-13-Multi_Agent_Software_Development_through_Cross_Team_Collaboration.html#appendix",
    "href": "posts/Multi_Agent_Software_Development_through_Cross_Team_Collaboration/2024-06-13-Multi_Agent_Software_Development_through_Cross_Team_Collaboration.html#appendix",
    "title": "Multi-Agent Software Development through Cross-Team Collaboration",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.08979v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.08979v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8963"
  },
  {
    "objectID": "posts/Assessing_Language_Models_Worldview_for_Fiction_Generation/2024-08-15-Assessing_Language_Models_Worldview_for_Fiction_Generation.html#appendix",
    "href": "posts/Assessing_Language_Models_Worldview_for_Fiction_Generation/2024-08-15-Assessing_Language_Models_Worldview_for_Fiction_Generation.html#appendix",
    "title": "Assessing Language Models’ Worldview for Fiction Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07904v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07904v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9708"
  },
  {
    "objectID": "posts/LLM4VV_Exploring_LLM_as_a_Judge_for_Validation_and_Verification_Testsuites/2024-08-21-LLM4VV_Exploring_LLM_as_a_Judge_for_Validation_and_Verification_Testsuites.html#appendix",
    "href": "posts/LLM4VV_Exploring_LLM_as_a_Judge_for_Validation_and_Verification_Testsuites/2024-08-21-LLM4VV_Exploring_LLM_as_a_Judge_for_Validation_and_Verification_Testsuites.html#appendix",
    "title": "LLM4VV: Exploring LLM-as-a-Judge for Validation and Verification Testsuites",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11729v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11729v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5702"
  },
  {
    "objectID": "posts/Hello_Again!_LLM_powered_Personalized_Agent_for_Long_term_Dialogue/2024-06-09-Hello_Again!_LLM_powered_Personalized_Agent_for_Long_term_Dialogue.html#appendix",
    "href": "posts/Hello_Again!_LLM_powered_Personalized_Agent_for_Long_term_Dialogue/2024-06-09-Hello_Again!_LLM_powered_Personalized_Agent_for_Long_term_Dialogue.html#appendix",
    "title": "Hello Again! LLM-powered Personalized Agent for Long-term Dialogue",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05925v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05925v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6818"
  },
  {
    "objectID": "posts/Rectifier_Code_Translation_with_Corrector_via_LLMs/2024-07-10-Rectifier_Code_Translation_with_Corrector_via_LLMs.html#appendix",
    "href": "posts/Rectifier_Code_Translation_with_Corrector_via_LLMs/2024-07-10-Rectifier_Code_Translation_with_Corrector_via_LLMs.html#appendix",
    "title": "Rectifier: Code Translation with Corrector via LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07472v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07472v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11178"
  },
  {
    "objectID": "posts/Text_to_Drive_Diverse_Driving_Behavior_Synthesis_via_Large_Language_Models/2024-06-06-Text_to_Drive_Diverse_Driving_Behavior_Synthesis_via_Large_Language_Models.html#appendix",
    "href": "posts/Text_to_Drive_Diverse_Driving_Behavior_Synthesis_via_Large_Language_Models/2024-06-06-Text_to_Drive_Diverse_Driving_Behavior_Synthesis_via_Large_Language_Models.html#appendix",
    "title": "Text-to-Drive: Diverse Driving Behavior Synthesis via Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04300v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04300v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10490"
  },
  {
    "objectID": "posts/Public_Health_in_Disaster_Emotional_Health_and_Life_Incidents_Extraction_during_Hurricane_Harvey/2024-08-20-Public_Health_in_Disaster_Emotional_Health_and_Life_Incidents_Extraction_during_Hurricane_Harvey.html#appendix",
    "href": "posts/Public_Health_in_Disaster_Emotional_Health_and_Life_Incidents_Extraction_during_Hurricane_Harvey/2024-08-20-Public_Health_in_Disaster_Emotional_Health_and_Life_Incidents_Extraction_during_Hurricane_Harvey.html#appendix",
    "title": "Public Health in Disaster: Emotional Health and Life Incidents Extraction during Hurricane Harvey",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11133v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11133v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5316"
  },
  {
    "objectID": "posts/Data_Contamination_Can_Cross_Language_Barriers/2024-06-19-Data_Contamination_Can_Cross_Language_Barriers.html#appendix",
    "href": "posts/Data_Contamination_Can_Cross_Language_Barriers/2024-06-19-Data_Contamination_Can_Cross_Language_Barriers.html#appendix",
    "title": "Data Contamination Can Cross Language Barriers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13236v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13236v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7163"
  },
  {
    "objectID": "posts/HiAgent_Hierarchical_Working_Memory_Management_for_Solving_Long_Horizon_Agent_Tasks_with_Large_Language_Model/2024-08-18-HiAgent_Hierarchical_Working_Memory_Management_for_Solving_Long_Horizon_Agent_Tasks_with_Large_Language_Model.html#major-findings",
    "href": "posts/HiAgent_Hierarchical_Working_Memory_Management_for_Solving_Long_Horizon_Agent_Tasks_with_Large_Language_Model/2024-08-18-HiAgent_Hierarchical_Working_Memory_Management_for_Solving_Long_Horizon_Agent_Tasks_with_Large_Language_Model.html#major-findings",
    "title": "HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nHIAGENT outperforms the baseline model across all tasks, with an overall success rate more than double that of the baseline model.\nHIAGENT is more efficient than the baseline model, accomplishing tasks with fewer steps, in less runtime, and using shorter context.\nThe ablation study confirms the effectiveness of the individual modules of HIAGENT.\nHIAGENT is more likely to generate executable actions than the baseline model, even with longer steps.\nThe observed performance improvements in HIAGENT are statistically significant compared to the baseline model."
  },
  {
    "objectID": "posts/HiAgent_Hierarchical_Working_Memory_Management_for_Solving_Long_Horizon_Agent_Tasks_with_Large_Language_Model/2024-08-18-HiAgent_Hierarchical_Working_Memory_Management_for_Solving_Long_Horizon_Agent_Tasks_with_Large_Language_Model.html#analysis-and-critique",
    "href": "posts/HiAgent_Hierarchical_Working_Memory_Management_for_Solving_Long_Horizon_Agent_Tasks_with_Large_Language_Model/2024-08-18-HiAgent_Hierarchical_Working_Memory_Management_for_Solving_Long_Horizon_Agent_Tasks_with_Large_Language_Model.html#analysis-and-critique",
    "title": "HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a well-structured and coherent summary of the proposed HIAGENT framework. The authors provide a clear motivation for the research and a detailed explanation of the framework’s components. The experimental results demonstrate the effectiveness and efficiency of HIAGENT in handling long-horizon tasks.\nHowever, the paper could benefit from a more in-depth discussion of the limitations and potential biases of the proposed framework. For instance, the authors could discuss the potential challenges of applying HIAGENT to other domains or tasks, as well as the computational resources required to implement the framework. Additionally, the paper could provide more details on the evaluation metrics used in the experiments and the criteria for selecting the final parameter settings.\nOverall, the paper presents a promising approach to improving the performance of LLM-based agents in handling long-horizon tasks. The proposed HIAGENT framework offers a flexible and effective solution to managing working memory, which could inspire further research in this area."
  },
  {
    "objectID": "posts/HiAgent_Hierarchical_Working_Memory_Management_for_Solving_Long_Horizon_Agent_Tasks_with_Large_Language_Model/2024-08-18-HiAgent_Hierarchical_Working_Memory_Management_for_Solving_Long_Horizon_Agent_Tasks_with_Large_Language_Model.html#appendix",
    "href": "posts/HiAgent_Hierarchical_Working_Memory_Management_for_Solving_Long_Horizon_Agent_Tasks_with_Large_Language_Model/2024-08-18-HiAgent_Hierarchical_Working_Memory_Management_for_Solving_Long_Horizon_Agent_Tasks_with_Large_Language_Model.html#appendix",
    "title": "HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09559v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09559v1\n\n\nTruncated\nFalse\n\n\nWord Count\n21678"
  },
  {
    "objectID": "posts/FSM_A_Finite_State_Machine_Based_Zero_Shot_Prompting_Paradigm_for_Multi_Hop_Question_Answering/2024-07-03-FSM_A_Finite_State_Machine_Based_Zero_Shot_Prompting_Paradigm_for_Multi_Hop_Question_Answering.html#appendix",
    "href": "posts/FSM_A_Finite_State_Machine_Based_Zero_Shot_Prompting_Paradigm_for_Multi_Hop_Question_Answering/2024-07-03-FSM_A_Finite_State_Machine_Based_Zero_Shot_Prompting_Paradigm_for_Multi_Hop_Question_Answering.html#appendix",
    "title": "FSM: A Finite State Machine Based Zero-Shot Prompting Paradigm for Multi-Hop Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02964v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02964v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4635"
  },
  {
    "objectID": "posts/ObfuscaTune_Obfuscated_Offsite_Fine_tuning_and_Inference_of_Proprietary_LLMs_on_Private_Datasets/2024-07-03-ObfuscaTune_Obfuscated_Offsite_Fine_tuning_and_Inference_of_Proprietary_LLMs_on_Private_Datasets.html#appendix",
    "href": "posts/ObfuscaTune_Obfuscated_Offsite_Fine_tuning_and_Inference_of_Proprietary_LLMs_on_Private_Datasets/2024-07-03-ObfuscaTune_Obfuscated_Offsite_Fine_tuning_and_Inference_of_Proprietary_LLMs_on_Private_Datasets.html#appendix",
    "title": "ObfuscaTune: Obfuscated Offsite Fine-tuning and Inference of Proprietary LLMs on Private Datasets",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02960v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02960v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4546"
  },
  {
    "objectID": "posts/COMCAT_Leveraging_Human_Judgment_to_Improve_Automatic_Documentation_and_Summarization/2024-07-18-COMCAT_Leveraging_Human_Judgment_to_Improve_Automatic_Documentation_and_Summarization.html#appendix",
    "href": "posts/COMCAT_Leveraging_Human_Judgment_to_Improve_Automatic_Documentation_and_Summarization/2024-07-18-COMCAT_Leveraging_Human_Judgment_to_Improve_Automatic_Documentation_and_Summarization.html#appendix",
    "title": "COMCAT: Leveraging Human Judgment to Improve Automatic Documentation and Summarization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.13648v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.13648v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11075"
  },
  {
    "objectID": "posts/Suri_Multi_constraint_Instruction_Following_for_Long_form_Text_Generation/2024-06-27-Suri_Multi_constraint_Instruction_Following_for_Long_form_Text_Generation.html#appendix",
    "href": "posts/Suri_Multi_constraint_Instruction_Following_for_Long_form_Text_Generation/2024-06-27-Suri_Multi_constraint_Instruction_Following_for_Long_form_Text_Generation.html#appendix",
    "title": "Suri: Multi-constraint Instruction Following for Long-form Text Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19371v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19371v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8097"
  },
  {
    "objectID": "posts/CFinBench_A_Comprehensive_Chinese_Financial_Benchmark_for_Large_Language_Models/2024-07-02-CFinBench_A_Comprehensive_Chinese_Financial_Benchmark_for_Large_Language_Models.html#appendix",
    "href": "posts/CFinBench_A_Comprehensive_Chinese_Financial_Benchmark_for_Large_Language_Models/2024-07-02-CFinBench_A_Comprehensive_Chinese_Financial_Benchmark_for_Large_Language_Models.html#appendix",
    "title": "CFinBench: A Comprehensive Chinese Financial Benchmark for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02301v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02301v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7394"
  },
  {
    "objectID": "posts/GRUtopia_Dream_General_Robots_in_a_City_at_Scale/2024-07-15-GRUtopia_Dream_General_Robots_in_a_City_at_Scale.html#major-findings",
    "href": "posts/GRUtopia_Dream_General_Robots_in_a_City_at_Scale/2024-07-15-GRUtopia_Dream_General_Robots_in_a_City_at_Scale.html#major-findings",
    "title": "GRUtopia: Dream General Robots in a City at Scale",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nGRScenes significantly expands the scope of environments in which robots can operate, covering both indoor and outdoor environments, including restaurants, supermarkets, offices, libraries, museums, hospitals, exhibition halls, amusement parks, and homes.\nGRResidents, the NPC system, introduces a new dimension to human-robot interaction within simulations. NPCs are motivated by the goal that robots are ultimately meant to serve humans, and interaction with users is often helpful or necessary for task completion.\nGRBench serves as a comprehensive evaluation tool for assessing robot agents’ capabilities. It comprises three benchmarks: Object Loco-Navigation, Social Loco-Navigation, and Loco-Manipulation, designed to progressively increase in difficulty, demanding enhanced robotic skills."
  },
  {
    "objectID": "posts/GRUtopia_Dream_General_Robots_in_a_City_at_Scale/2024-07-15-GRUtopia_Dream_General_Robots_in_a_City_at_Scale.html#analysis-and-critique",
    "href": "posts/GRUtopia_Dream_General_Robots_in_a_City_at_Scale/2024-07-15-GRUtopia_Dream_General_Robots_in_a_City_at_Scale.html#analysis-and-critique",
    "title": "GRUtopia: Dream General Robots in a City at Scale",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a comprehensive platform for training and evaluating embodied agents in a simulated environment. The large-scale scene dataset and diverse NPC system provide a rich and realistic setting for testing various robots. However, the paper does not discuss the potential limitations or challenges of deploying these agents in real-world scenarios. Additionally, the evaluation metrics used in the benchmark may not fully capture the complexity and nuances of real-world tasks. Further research is needed to address these issues and validate the effectiveness of the proposed platform in real-world applications."
  },
  {
    "objectID": "posts/GRUtopia_Dream_General_Robots_in_a_City_at_Scale/2024-07-15-GRUtopia_Dream_General_Robots_in_a_City_at_Scale.html#appendix",
    "href": "posts/GRUtopia_Dream_General_Robots_in_a_City_at_Scale/2024-07-15-GRUtopia_Dream_General_Robots_in_a_City_at_Scale.html#appendix",
    "title": "GRUtopia: Dream General Robots in a City at Scale",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10943v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10943v1\n\n\nTruncated\nFalse\n\n\nWord Count\n21853"
  },
  {
    "objectID": "posts/Do_LLMs_Know_When_to_NOT_Answer_Investigating_Abstention_Abilities_of_Large_Language_Models/2024-07-23-Do_LLMs_Know_When_to_NOT_Answer_Investigating_Abstention_Abilities_of_Large_Language_Models.html#appendix",
    "href": "posts/Do_LLMs_Know_When_to_NOT_Answer_Investigating_Abstention_Abilities_of_Large_Language_Models/2024-07-23-Do_LLMs_Know_When_to_NOT_Answer_Investigating_Abstention_Abilities_of_Large_Language_Models.html#appendix",
    "title": "Do LLMs Know When to NOT Answer? Investigating Abstention Abilities of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16221v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16221v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4731"
  },
  {
    "objectID": "posts/A_RAG_Based_Question_Answering_Solution_for_Cyber_Attack_Investigation_and_Attribution/2024-08-12-A_RAG_Based_Question_Answering_Solution_for_Cyber_Attack_Investigation_and_Attribution.html#appendix",
    "href": "posts/A_RAG_Based_Question_Answering_Solution_for_Cyber_Attack_Investigation_and_Attribution/2024-08-12-A_RAG_Based_Question_Answering_Solution_for_Cyber_Attack_Investigation_and_Attribution.html#appendix",
    "title": "A RAG-Based Question-Answering Solution for Cyber-Attack Investigation and Attribution",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.06272v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.06272v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7723"
  },
  {
    "objectID": "posts/Optimal_Decision_Making_Through_Scenario_Simulations_Using_Large_Language_Models/2024-07-09-Optimal_Decision_Making_Through_Scenario_Simulations_Using_Large_Language_Models.html#appendix",
    "href": "posts/Optimal_Decision_Making_Through_Scenario_Simulations_Using_Large_Language_Models/2024-07-09-Optimal_Decision_Making_Through_Scenario_Simulations_Using_Large_Language_Models.html#appendix",
    "title": "Optimal Decision Making Through Scenario Simulations Using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06486v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06486v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4425"
  },
  {
    "objectID": "posts/Nothing_in_Excess_Mitigating_the_Exaggerated_Safety_for_LLMs_via_Safety_Conscious_Activation_Steering/2024-08-21-Nothing_in_Excess_Mitigating_the_Exaggerated_Safety_for_LLMs_via_Safety_Conscious_Activation_Steering.html",
    "href": "posts/Nothing_in_Excess_Mitigating_the_Exaggerated_Safety_for_LLMs_via_Safety_Conscious_Activation_Steering/2024-08-21-Nothing_in_Excess_Mitigating_the_Exaggerated_Safety_for_LLMs_via_Safety_Conscious_Activation_Steering.html",
    "title": "Nothing in Excess: Mitigating the Exaggerated Safety for LLMs via Safety-Conscious Activation Steering",
    "section": "",
    "text": "Summary:\nThe paper “Nothing in Excess: Mitigating the Exaggerated Safety for LLMs via Safety-Conscious Activation Steering” by Zouying Cao, Yifei Yang, and Hai Zhao proposes a method called SCANS to address the issue of exaggerated safety in aligned large language models (LLMs). The authors observe that safety-aligned LLMs often refuse benign queries due to the exaggerated safety issue, which limits their helpfulness.\nSCANS extracts refusal steering vectors within the activation space and utilizes vocabulary projection to anchor specific safety-critical layers that influence model refusal behavior. By tracking the hidden state transition, SCANS identifies the steering direction and steers the model behavior accordingly, achieving a balance between exaggerated safety and adequate safety.\nThe paper presents experiments on four LLMs, demonstrating that SCANS outperforms both training-free and training-based baselines in mitigating exaggerated safety without compromising adequate safety. SCANS maintains almost unchanged model capability, with minimal increase in perplexity. The contributions of the paper include introducing SCANS, discovering the extracted refusal steering vectors from middle layers that promote refusal tokens, and effectively mitigating exaggerated safety in aligned LLMs without undermining adequate safety and general capability.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel approach to addressing the exaggerated safety issue in aligned LLMs. The proposed method, SCANS, demonstrates promising results in mitigating exaggerated safety without compromising adequate safety and general capability. However, the paper does not discuss the potential limitations or shortcomings of the proposed method, such as"
  },
  {
    "objectID": "posts/Nothing_in_Excess_Mitigating_the_Exaggerated_Safety_for_LLMs_via_Safety_Conscious_Activation_Steering/2024-08-21-Nothing_in_Excess_Mitigating_the_Exaggerated_Safety_for_LLMs_via_Safety_Conscious_Activation_Steering.html#appendix",
    "href": "posts/Nothing_in_Excess_Mitigating_the_Exaggerated_Safety_for_LLMs_via_Safety_Conscious_Activation_Steering/2024-08-21-Nothing_in_Excess_Mitigating_the_Exaggerated_Safety_for_LLMs_via_Safety_Conscious_Activation_Steering.html#appendix",
    "title": "Nothing in Excess: Mitigating the Exaggerated Safety for LLMs via Safety-Conscious Activation Steering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11491v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11491v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15883"
  },
  {
    "objectID": "posts/DIDUP_Dynamic_Iterative_Development_for_UI_Prototyping/2024-07-11-DIDUP_Dynamic_Iterative_Development_for_UI_Prototyping.html#appendix",
    "href": "posts/DIDUP_Dynamic_Iterative_Development_for_UI_Prototyping/2024-07-11-DIDUP_Dynamic_Iterative_Development_for_UI_Prototyping.html#appendix",
    "title": "DIDUP: Dynamic Iterative Development for UI Prototyping",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08474v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08474v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3335"
  },
  {
    "objectID": "posts/Empowering_1000_tokenssecond_on_device_LLM_prefilling_with_mllm_NPU/2024-07-08-Empowering_1000_tokenssecond_on_device_LLM_prefilling_with_mllm_NPU.html#appendix",
    "href": "posts/Empowering_1000_tokenssecond_on_device_LLM_prefilling_with_mllm_NPU/2024-07-08-Empowering_1000_tokenssecond_on_device_LLM_prefilling_with_mllm_NPU.html#appendix",
    "title": "Empowering 1000 tokens/second on-device LLM prefilling with mllm-NPU",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05858v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05858v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11855"
  },
  {
    "objectID": "posts/Evaluating_the_Retrieval_Component_in_LLM_Based_Question_Answering_Systems/2024-06-10-Evaluating_the_Retrieval_Component_in_LLM_Based_Question_Answering_Systems.html#appendix",
    "href": "posts/Evaluating_the_Retrieval_Component_in_LLM_Based_Question_Answering_Systems/2024-06-10-Evaluating_the_Retrieval_Component_in_LLM_Based_Question_Answering_Systems.html#appendix",
    "title": "Evaluating the Retrieval Component in LLM-Based Question Answering Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06458v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06458v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4825"
  },
  {
    "objectID": "posts/Fine_Tuning_with_Divergent_Chains_of_Thought_Boosts_Reasoning_Through_Self_Correction_in_Language_Models/2024-07-03-Fine_Tuning_with_Divergent_Chains_of_Thought_Boosts_Reasoning_Through_Self_Correction_in_Language_Models.html#appendix",
    "href": "posts/Fine_Tuning_with_Divergent_Chains_of_Thought_Boosts_Reasoning_Through_Self_Correction_in_Language_Models/2024-07-03-Fine_Tuning_with_Divergent_Chains_of_Thought_Boosts_Reasoning_Through_Self_Correction_in_Language_Models.html#appendix",
    "title": "Fine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03181v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03181v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8440"
  },
  {
    "objectID": "posts/Learning_to_Rewrite_Generalized_LLM_Generated_Text_Detection/2024-08-08-Learning_to_Rewrite_Generalized_LLM_Generated_Text_Detection.html#major-findings",
    "href": "posts/Learning_to_Rewrite_Generalized_LLM_Generated_Text_Detection/2024-08-08-Learning_to_Rewrite_Generalized_LLM_Generated_Text_Detection.html#major-findings",
    "title": "Learning to Rewrite: Generalized LLM-Generated Text Detection",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nEffective LLM-Generated Text Detection: L2R effectively detects machine-generated text by training LLMs to capture the rich structure of LLM content and strengthening it through targeted training.\nGeneralization Across Domains: L2R generalizes well across different domains, outperforming the state-of-the-art zero-shot classifier by up to 20.6% on AUROC score and the rewriting classifier by 9.2% on F1 score.\nDiverse AI Text Dataset: The authors built the world’s most diverse AI text dataset, encompassing 21 distinct domains, to demonstrate the effectiveness of L2R in detecting LLM-generated text."
  },
  {
    "objectID": "posts/Learning_to_Rewrite_Generalized_LLM_Generated_Text_Detection/2024-08-08-Learning_to_Rewrite_Generalized_LLM_Generated_Text_Detection.html#analysis-and-critique",
    "href": "posts/Learning_to_Rewrite_Generalized_LLM_Generated_Text_Detection/2024-08-08-Learning_to_Rewrite_Generalized_LLM_Generated_Text_Detection.html#analysis-and-critique",
    "title": "Learning to Rewrite: Generalized LLM-Generated Text Detection",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nLimited Evaluation of LLMs: The paper focuses on evaluating L2R with three popular LLMs (GPT-4o, Gemini, and Llama-3). Further evaluation with a broader range of LLMs could provide a more comprehensive understanding of L2R’s performance.\nPotential Overfitting: The authors mention the risk of overfitting during the fine-tuning process. While they propose a calibration loss to prevent this, it is unclear how effective this method is in preventing overfitting in all cases.\nSlow Inference Runtime: The authors acknowledge that L2R has a relatively slow inference runtime compared to zero-shot detectors. This limitation could impact the practicality of L2R in real-world applications."
  },
  {
    "objectID": "posts/Learning_to_Rewrite_Generalized_LLM_Generated_Text_Detection/2024-08-08-Learning_to_Rewrite_Generalized_LLM_Generated_Text_Detection.html#appendix",
    "href": "posts/Learning_to_Rewrite_Generalized_LLM_Generated_Text_Detection/2024-08-08-Learning_to_Rewrite_Generalized_LLM_Generated_Text_Detection.html#appendix",
    "title": "Learning to Rewrite: Generalized LLM-Generated Text Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04237v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04237v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5177"
  },
  {
    "objectID": "posts/Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models/2024-06-17-Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models.html",
    "href": "posts/Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models/2024-06-17-Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models.html",
    "title": "Long Code Arena: a Set of Benchmarks for Long-Context Code Models",
    "section": "",
    "text": "Summary:\nThe paper introduces Long Code Arena, a suite of six benchmarks for code processing tasks that require project-wide context. These tasks include library-based code generation, CI builds repair, project-level code completion, commit message generation, bug localization, and module summarization. The paper highlights the limitations of existing ML4SE benchmarks, such as short context length and limited resemblance to practical use cases. Long Code Arena aims to address these issues by providing manually verified datasets, evaluation suites, and open-source baseline solutions based on popular LLMs. The benchmark page, leaderboard, and links to datasets are available on HuggingFace Spaces.\nMajor Findings:"
  },
  {
    "objectID": "posts/Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models/2024-06-17-Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models.html#appendix",
    "href": "posts/Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models/2024-06-17-Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models.html#appendix",
    "title": "Long Code Arena: a Set of Benchmarks for Long-Context Code Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11612v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11612v1\n\n\nTruncated\nTrue\n\n\nWord Count\n31007"
  },
  {
    "objectID": "posts/DDK_Distilling_Domain_Knowledge_for_Efficient_Large_Language_Models/2024-07-23-DDK_Distilling_Domain_Knowledge_for_Efficient_Large_Language_Models.html#appendix",
    "href": "posts/DDK_Distilling_Domain_Knowledge_for_Efficient_Large_Language_Models/2024-07-23-DDK_Distilling_Domain_Knowledge_for_Efficient_Large_Language_Models.html#appendix",
    "title": "DDK: Distilling Domain Knowledge for Efficient Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16154v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16154v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3334"
  },
  {
    "objectID": "posts/Experiments_with_truth_using_Machine_Learning_Spectral_analysis_and_explainable_classification_of_synthetic_false_and_genuine_information/2024-07-07-Experiments_with_truth_using_Machine_Learning_Spectral_analysis_and_explainable_classification_of_synthetic_false_and_genuine_information.html#appendix",
    "href": "posts/Experiments_with_truth_using_Machine_Learning_Spectral_analysis_and_explainable_classification_of_synthetic_false_and_genuine_information/2024-07-07-Experiments_with_truth_using_Machine_Learning_Spectral_analysis_and_explainable_classification_of_synthetic_false_and_genuine_information.html#appendix",
    "title": "Experiments with truth using Machine Learning: Spectral analysis and explainable classification of synthetic, false, and genuine information",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05464v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05464v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9665"
  },
  {
    "objectID": "posts/On_the_Transformations_across_Reward_Model_Parameter_Update_and_In_Context_Prompt/2024-06-24-On_the_Transformations_across_Reward_Model_Parameter_Update_and_In_Context_Prompt.html",
    "href": "posts/On_the_Transformations_across_Reward_Model_Parameter_Update_and_In_Context_Prompt/2024-06-24-On_the_Transformations_across_Reward_Model_Parameter_Update_and_In_Context_Prompt.html",
    "title": "On the Transformations across Reward Model, Parameter Update, and In-Context Prompt",
    "section": "",
    "text": "Summary:\nThis paper presents a holistic view of the interchangeability among three popular and distinct adaptation tools for pre-trained large language models (LLMs): parameter updating, reward modeling, and in-context prompting. The authors establish a triangular framework with six transformation directions, each facilitating various applications. The primary contribution of this work is to offer a unified perspective that connects numerous existing studies and outlines potential future research directions.\nMajor Findings:\nAnalysis and Critique:\nThe paper offers a comprehensive and unified view of the interchangeability among parameter updating, reward modeling, and in-context prompting in adapting pre-trained LLMs. This framework serves as a useful guide for researchers and practitioners in the field of LLMs, empowering them to make more informed decisions in their research and applications. However, the paper does not address the limitations and unanswered questions that may arise from the proposed framework. Additionally, the authors do not discuss any methodological issues, conflicting evidence, or areas that require further research or clarification.\nIn conclusion, the paper provides a valuable contribution to the field of LLMs by offering a unified perspective on the interchangeability of adaptation tools. However, further research is needed to address the limitations and unanswered questions that may arise from the proposed framework."
  },
  {
    "objectID": "posts/On_the_Transformations_across_Reward_Model_Parameter_Update_and_In_Context_Prompt/2024-06-24-On_the_Transformations_across_Reward_Model_Parameter_Update_and_In_Context_Prompt.html#appendix",
    "href": "posts/On_the_Transformations_across_Reward_Model_Parameter_Update_and_In_Context_Prompt/2024-06-24-On_the_Transformations_across_Reward_Model_Parameter_Update_and_In_Context_Prompt.html#appendix",
    "title": "On the Transformations across Reward Model, Parameter Update, and In-Context Prompt",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16377v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16377v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14264"
  },
  {
    "objectID": "posts/DOCE_Finding_the_Sweet_Spot_for_Execution_Based_Code_Generation/2024-08-25-DOCE_Finding_the_Sweet_Spot_for_Execution_Based_Code_Generation.html#appendix",
    "href": "posts/DOCE_Finding_the_Sweet_Spot_for_Execution_Based_Code_Generation/2024-08-25-DOCE_Finding_the_Sweet_Spot_for_Execution_Based_Code_Generation.html#appendix",
    "title": "DOCE: Finding the Sweet Spot for Execution-Based Code Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.13745v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.13745v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10157"
  },
  {
    "objectID": "posts/GraphReader_Building_Graph_based_Agent_to_Enhance_Long_Context_Abilities_of_Large_Language_Models/2024-06-20-GraphReader_Building_Graph_based_Agent_to_Enhance_Long_Context_Abilities_of_Large_Language_Models.html#appendix",
    "href": "posts/GraphReader_Building_Graph_based_Agent_to_Enhance_Long_Context_Abilities_of_Large_Language_Models/2024-06-20-GraphReader_Building_Graph_based_Agent_to_Enhance_Long_Context_Abilities_of_Large_Language_Models.html#appendix",
    "title": "GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14550v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14550v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7927"
  },
  {
    "objectID": "posts/Benchmarking_LLMs_for_Translating_Classical_Chinese_PoetryEvaluating_Adequacy_Fluency_and_Elegance/2024-08-19-Benchmarking_LLMs_for_Translating_Classical_Chinese_PoetryEvaluating_Adequacy_Fluency_and_Elegance.html#major-findings",
    "href": "posts/Benchmarking_LLMs_for_Translating_Classical_Chinese_PoetryEvaluating_Adequacy_Fluency_and_Elegance/2024-08-19-Benchmarking_LLMs_for_Translating_Classical_Chinese_PoetryEvaluating_Adequacy_Fluency_and_Elegance.html#major-findings",
    "title": "Benchmarking LLMs for Translating Classical Chinese Poetry:Evaluating Adequacy, Fluency, and Elegance",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nExisting LLMs fall short in translating classical Chinese poetry into English, which requires adequacy, fluency, and elegance.\nThe authors propose RAT, a Retrieval-Augmented machine Translation method, to enhance the translation process by incorporating knowledge related to classical poetry.\nAn automatic evaluation metric based on GPT-4 is proposed, which better assesses translation quality in terms of adequacy, fluency, and elegance."
  },
  {
    "objectID": "posts/Benchmarking_LLMs_for_Translating_Classical_Chinese_PoetryEvaluating_Adequacy_Fluency_and_Elegance/2024-08-19-Benchmarking_LLMs_for_Translating_Classical_Chinese_PoetryEvaluating_Adequacy_Fluency_and_Elegance.html#analysis-and-critique",
    "href": "posts/Benchmarking_LLMs_for_Translating_Classical_Chinese_PoetryEvaluating_Adequacy_Fluency_and_Elegance/2024-08-19-Benchmarking_LLMs_for_Translating_Classical_Chinese_PoetryEvaluating_Adequacy_Fluency_and_Elegance.html#analysis-and-critique",
    "title": "Benchmarking LLMs for Translating Classical Chinese Poetry:Evaluating Adequacy, Fluency, and Elegance",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe study provides a valuable contribution to the field of machine translation by introducing a benchmark for evaluating LLMs in translating classical Chinese poetry. The proposed RAT method and the GPT-4-based evaluation metric are promising approaches to improve translation quality. However, the study does not provide a comprehensive evaluation of the proposed methods, and it is unclear how they compare to other existing methods. Additionally, the study does not discuss potential limitations or biases in the proposed methods. Further research is needed to evaluate the effectiveness and generalizability of the proposed methods."
  },
  {
    "objectID": "posts/Benchmarking_LLMs_for_Translating_Classical_Chinese_PoetryEvaluating_Adequacy_Fluency_and_Elegance/2024-08-19-Benchmarking_LLMs_for_Translating_Classical_Chinese_PoetryEvaluating_Adequacy_Fluency_and_Elegance.html#appendix",
    "href": "posts/Benchmarking_LLMs_for_Translating_Classical_Chinese_PoetryEvaluating_Adequacy_Fluency_and_Elegance/2024-08-19-Benchmarking_LLMs_for_Translating_Classical_Chinese_PoetryEvaluating_Adequacy_Fluency_and_Elegance.html#appendix",
    "title": "Benchmarking LLMs for Translating Classical Chinese Poetry:Evaluating Adequacy, Fluency, and Elegance",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09945v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09945v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7016"
  },
  {
    "objectID": "posts/Bridging_the_Language_Gap_Enhancing_Multilingual_Prompt_Based_Code_Generation_in_LLMs_via_Zero_Shot_Cross_Lingual_Transfer/2024-08-19-Bridging_the_Language_Gap_Enhancing_Multilingual_Prompt_Based_Code_Generation_in_LLMs_via_Zero_Shot_Cross_Lingual_Transfer.html#appendix",
    "href": "posts/Bridging_the_Language_Gap_Enhancing_Multilingual_Prompt_Based_Code_Generation_in_LLMs_via_Zero_Shot_Cross_Lingual_Transfer/2024-08-19-Bridging_the_Language_Gap_Enhancing_Multilingual_Prompt_Based_Code_Generation_in_LLMs_via_Zero_Shot_Cross_Lingual_Transfer.html#appendix",
    "title": "Bridging the Language Gap: Enhancing Multilingual Prompt-Based Code Generation in LLMs via Zero-Shot Cross-Lingual Transfer",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09701v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09701v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5578"
  },
  {
    "objectID": "posts/Security_Vulnerability_Detection_with_Multitask_Self_Instructed_Fine_Tuning_of_Large_Language_Models/2024-06-09-Security_Vulnerability_Detection_with_Multitask_Self_Instructed_Fine_Tuning_of_Large_Language_Models.html#appendix",
    "href": "posts/Security_Vulnerability_Detection_with_Multitask_Self_Instructed_Fine_Tuning_of_Large_Language_Models/2024-06-09-Security_Vulnerability_Detection_with_Multitask_Self_Instructed_Fine_Tuning_of_Large_Language_Models.html#appendix",
    "title": "Security Vulnerability Detection with Multitask Self-Instructed Fine-Tuning of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05892v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05892v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10513"
  },
  {
    "objectID": "posts/The_Synergy_between_Data_and_Multi_Modal_Large_Language_Models_A_Survey_from_Co_Development_Perspective/2024-07-11-The_Synergy_between_Data_and_Multi_Modal_Large_Language_Models_A_Survey_from_Co_Development_Perspective.html",
    "href": "posts/The_Synergy_between_Data_and_Multi_Modal_Large_Language_Models_A_Survey_from_Co_Development_Perspective/2024-07-11-The_Synergy_between_Data_and_Multi_Modal_Large_Language_Models_A_Survey_from_Co_Development_Perspective.html",
    "title": "The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective",
    "section": "",
    "text": "Summary:\nThe paper discusses the development of multi-modal large language models (MLLMs) and the importance of data in their performance. The authors propose a new taxonomy that emphasizes the synergy between multi-modal data and MLLMs, aiming to understand and mine the mutual benefits for both data and model development. The taxonomy is organized based on the hierarchy of data-related technologies essential for developing MLLMs. The paper also provides a comprehensive review of existing works related to MLLMs from the data-model co-development perspective and a regularly maintained project associated with this survey.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive review of the development of MLLMs and the importance of data in their performance. The proposed taxonomy and the review of existing works offer a new perspective for MLLM development and a roadmap for future research. However, the paper does not discuss the limitations or potential biases in the reviewed works, which could be a topic for future research. Additionally, the paper does not discuss the potential ethical implications of MLLMs, which is an important consideration in the development and deployment of these models."
  },
  {
    "objectID": "posts/The_Synergy_between_Data_and_Multi_Modal_Large_Language_Models_A_Survey_from_Co_Development_Perspective/2024-07-11-The_Synergy_between_Data_and_Multi_Modal_Large_Language_Models_A_Survey_from_Co_Development_Perspective.html#appendix",
    "href": "posts/The_Synergy_between_Data_and_Multi_Modal_Large_Language_Models_A_Survey_from_Co_Development_Perspective/2024-07-11-The_Synergy_between_Data_and_Multi_Modal_Large_Language_Models_A_Survey_from_Co_Development_Perspective.html#appendix",
    "title": "The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08583v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08583v1\n\n\nTruncated\nFalse\n\n\nWord Count\n26789"
  },
  {
    "objectID": "posts/Reprogramming_Foundational_Large_Language_Models(LLMs)_for_Enterprise_Adoption_for_Spatio_Temporal_Forecasting_Applications_Unveiling_a_New_Era_in_Copilot_Guided_Cross_Modal_Time_Series_Representation_Learning/2024-08-26-Reprogramming_Foundational_Large_Language_Models(LLMs)_for_Enterprise_Adoption_for_Spatio_Temporal_Forecasting_Applications_Unveiling_a_New_Era_in_Copilot_Guided_Cross_Modal_Time_Series_Representation_Learning.html#appendix",
    "href": "posts/Reprogramming_Foundational_Large_Language_Models(LLMs)_for_Enterprise_Adoption_for_Spatio_Temporal_Forecasting_Applications_Unveiling_a_New_Era_in_Copilot_Guided_Cross_Modal_Time_Series_Representation_Learning/2024-08-26-Reprogramming_Foundational_Large_Language_Models(LLMs)_for_Enterprise_Adoption_for_Spatio_Temporal_Forecasting_Applications_Unveiling_a_New_Era_in_Copilot_Guided_Cross_Modal_Time_Series_Representation_Learning.html#appendix",
    "title": "Reprogramming Foundational Large Language Models(LLMs) for Enterprise Adoption for Spatio-Temporal Forecasting Applications: Unveiling a New Era in Copilot-Guided Cross-Modal Time Series Representation Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.14387v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.14387v1\n\n\nTruncated\nFalse\n\n\nWord Count\n16638"
  },
  {
    "objectID": "posts/Meta_Rewarding_Language_Models_Self_Improving_Alignment_with_LLM_as_a_Meta_Judge/2024-07-28-Meta_Rewarding_Language_Models_Self_Improving_Alignment_with_LLM_as_a_Meta_Judge.html#appendix",
    "href": "posts/Meta_Rewarding_Language_Models_Self_Improving_Alignment_with_LLM_as_a_Meta_Judge/2024-07-28-Meta_Rewarding_Language_Models_Self_Improving_Alignment_with_LLM_as_a_Meta_Judge.html#appendix",
    "title": "Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19594v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19594v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7667"
  },
  {
    "objectID": "posts/LEXI_Large_Language_Models_Experimentation_Interface/2024-07-02-LEXI_Large_Language_Models_Experimentation_Interface.html#appendix",
    "href": "posts/LEXI_Large_Language_Models_Experimentation_Interface/2024-07-02-LEXI_Large_Language_Models_Experimentation_Interface.html#appendix",
    "title": "LEXI: Large Language Models Experimentation Interface",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01488v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01488v2\n\n\nTruncated\nFalse\n\n\nWord Count\n8957"
  },
  {
    "objectID": "posts/Robust_Few_shot_Transfer_Learning_for_Knowledge_Base_Question_Answering_with_Unanswerable_Questions/2024-06-20-Robust_Few_shot_Transfer_Learning_for_Knowledge_Base_Question_Answering_with_Unanswerable_Questions.html#appendix",
    "href": "posts/Robust_Few_shot_Transfer_Learning_for_Knowledge_Base_Question_Answering_with_Unanswerable_Questions/2024-06-20-Robust_Few_shot_Transfer_Learning_for_Knowledge_Base_Question_Answering_with_Unanswerable_Questions.html#appendix",
    "title": "Robust Few-shot Transfer Learning for Knowledge Base Question Answering with Unanswerable Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14313v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14313v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10473"
  },
  {
    "objectID": "posts/Investigating_Mysteries_of_CoT_Augmented_Distillation/2024-06-20-Investigating_Mysteries_of_CoT_Augmented_Distillation.html#appendix",
    "href": "posts/Investigating_Mysteries_of_CoT_Augmented_Distillation/2024-06-20-Investigating_Mysteries_of_CoT_Augmented_Distillation.html#appendix",
    "title": "Investigating Mysteries of CoT-Augmented Distillation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14511v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14511v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8455"
  },
  {
    "objectID": "posts/OriGenEnhancing_RTL_Code_Generation_with_Code_to_Code_Augmentation_and_Self_Reflection/2024-07-23-OriGenEnhancing_RTL_Code_Generation_with_Code_to_Code_Augmentation_and_Self_Reflection.html#appendix",
    "href": "posts/OriGenEnhancing_RTL_Code_Generation_with_Code_to_Code_Augmentation_and_Self_Reflection/2024-07-23-OriGenEnhancing_RTL_Code_Generation_with_Code_to_Code_Augmentation_and_Self_Reflection.html#appendix",
    "title": "OriGen:Enhancing RTL Code Generation with Code-to-Code Augmentation and Self-Reflection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16237v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16237v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6014"
  },
  {
    "objectID": "posts/Paying_More_Attention_to_Image_A_Training_Free_Method_for_Alleviating_Hallucination_in_LVLMs/2024-07-31-Paying_More_Attention_to_Image_A_Training_Free_Method_for_Alleviating_Hallucination_in_LVLMs.html#appendix",
    "href": "posts/Paying_More_Attention_to_Image_A_Training_Free_Method_for_Alleviating_Hallucination_in_LVLMs/2024-07-31-Paying_More_Attention_to_Image_A_Training_Free_Method_for_Alleviating_Hallucination_in_LVLMs.html#appendix",
    "title": "Paying More Attention to Image: A Training-Free Method for Alleviating Hallucination in LVLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21771v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21771v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7624"
  },
  {
    "objectID": "posts/Constructing_Mechanical_Design_Agent_Based_on_Large_Language_Models/2024-08-04-Constructing_Mechanical_Design_Agent_Based_on_Large_Language_Models.html#appendix",
    "href": "posts/Constructing_Mechanical_Design_Agent_Based_on_Large_Language_Models/2024-08-04-Constructing_Mechanical_Design_Agent_Based_on_Large_Language_Models.html#appendix",
    "title": "Constructing Mechanical Design Agent Based on Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02087v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02087v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6452"
  },
  {
    "objectID": "posts/Assessing_the_Code_Clone_Detection_Capability_of_Large_Language_Models/2024-07-02-Assessing_the_Code_Clone_Detection_Capability_of_Large_Language_Models.html#appendix",
    "href": "posts/Assessing_the_Code_Clone_Detection_Capability_of_Large_Language_Models/2024-07-02-Assessing_the_Code_Clone_Detection_Capability_of_Large_Language_Models.html#appendix",
    "title": "Assessing the Code Clone Detection Capability of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02402v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02402v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4970"
  },
  {
    "objectID": "posts/Bridging_and_Modeling_Correlations_in_Pairwise_Data_for_Direct_Preference_Optimization/2024-08-14-Bridging_and_Modeling_Correlations_in_Pairwise_Data_for_Direct_Preference_Optimization.html#appendix",
    "href": "posts/Bridging_and_Modeling_Correlations_in_Pairwise_Data_for_Direct_Preference_Optimization/2024-08-14-Bridging_and_Modeling_Correlations_in_Pairwise_Data_for_Direct_Preference_Optimization.html#appendix",
    "title": "Bridging and Modeling Correlations in Pairwise Data for Direct Preference Optimization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07471v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07471v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7170"
  },
  {
    "objectID": "posts/BADGE_BADminton_report_Generation_and_Evaluation_with_LLM/2024-06-26-BADGE_BADminton_report_Generation_and_Evaluation_with_LLM.html#appendix",
    "href": "posts/BADGE_BADminton_report_Generation_and_Evaluation_with_LLM/2024-06-26-BADGE_BADminton_report_Generation_and_Evaluation_with_LLM.html#appendix",
    "title": "BADGE: BADminton report Generation and Evaluation with LLM",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18116v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18116v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6049"
  },
  {
    "objectID": "posts/Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems/2024-06-18-Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems.html",
    "href": "posts/Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems/2024-06-18-Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems.html",
    "title": "Navigating the Labyrinth: Evaluating and Enhancing LLMs’ Ability to Reason About Search Problems",
    "section": "",
    "text": "Summary:\nThe paper introduces a new benchmark, SearchBench, to evaluate the reasoning abilities of Large Language Models (LLMs) on search problems. SearchBench consists of 11 unique search problems, each with automated pipelines for generating instances and analyzing solutions. The authors demonstrate that even advanced LLMs struggle with these problems, with GPT4 solving only 1.4% end-to-end in text. The paper proposes in-context learning with A* algorithm implementations and a Multi-Stage-Multi-Try (MSMT) method to enhance performance, raising GPT-4’s performance above 57%.\nKey Terminology:\nMajor Findings:"
  },
  {
    "objectID": "posts/Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems/2024-06-18-Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems.html#appendix",
    "href": "posts/Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems/2024-06-18-Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems.html#appendix",
    "title": "Navigating the Labyrinth: Evaluating and Enhancing LLMs’ Ability to Reason About Search Problems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12172v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12172v1\n\n\nTruncated\nTrue\n\n\nWord Count\n72494"
  },
  {
    "objectID": "posts/Retrieval_Augmented_Code_Generation_for_Situated_Action_Generation_A_Case_Study_on_Minecraft/2024-06-25-Retrieval_Augmented_Code_Generation_for_Situated_Action_Generation_A_Case_Study_on_Minecraft.html#appendix",
    "href": "posts/Retrieval_Augmented_Code_Generation_for_Situated_Action_Generation_A_Case_Study_on_Minecraft/2024-06-25-Retrieval_Augmented_Code_Generation_for_Situated_Action_Generation_A_Case_Study_on_Minecraft.html#appendix",
    "title": "Retrieval-Augmented Code Generation for Situated Action Generation: A Case Study on Minecraft",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17553v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17553v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4809"
  },
  {
    "objectID": "posts/Spoken_Stereoset_On_Evaluating_Social_Bias_Toward_Speaker_in_Speech_Large_Language_Models/2024-08-14-Spoken_Stereoset_On_Evaluating_Social_Bias_Toward_Speaker_in_Speech_Large_Language_Models.html#major-findings",
    "href": "posts/Spoken_Stereoset_On_Evaluating_Social_Bias_Toward_Speaker_in_Speech_Large_Language_Models/2024-08-14-Spoken_Stereoset_On_Evaluating_Social_Bias_Toward_Speaker_in_Speech_Large_Language_Models.html#major-findings",
    "title": "Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe study curates Spoken Stereoset, the first bias evaluation dataset for SLLM.\nThe evaluation of SOTA SLLMs on Spoken Stereoset shows that these models exhibit minimal bias on the dataset.\nText-based LLMs are proven to be fair in the dataset when speaker information is not given."
  },
  {
    "objectID": "posts/Spoken_Stereoset_On_Evaluating_Social_Bias_Toward_Speaker_in_Speech_Large_Language_Models/2024-08-14-Spoken_Stereoset_On_Evaluating_Social_Bias_Toward_Speaker_in_Speech_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/Spoken_Stereoset_On_Evaluating_Social_Bias_Toward_Speaker_in_Speech_Large_Language_Models/2024-08-14-Spoken_Stereoset_On_Evaluating_Social_Bias_Toward_Speaker_in_Speech_Large_Language_Models.html#analysis-and-critique",
    "title": "Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe study focuses on biases related to gender and age, but other demographic attributes, such as accent and ethnicity, are not addressed.\nThe dataset is limited to cultural and social norms prevalent in the United States, which may not accurately reflect biases in other social contexts.\nThe study does not provide a clear methodology for mitigating biases in SLLMs, which is crucial for promoting fairness and inclusivity.\nThe potential risks of releasing a dataset that includes stereotypes and biases should be carefully considered, and the dataset should be used solely for research and evaluation purposes.\n\nOverall, the study provides valuable insights into the biases present in SLLMs and highlights the need for ongoing evaluation and mitigation strategies. However, the limitations of the dataset and the lack of a clear methodology for mitigating biases should be addressed in future research."
  },
  {
    "objectID": "posts/Spoken_Stereoset_On_Evaluating_Social_Bias_Toward_Speaker_in_Speech_Large_Language_Models/2024-08-14-Spoken_Stereoset_On_Evaluating_Social_Bias_Toward_Speaker_in_Speech_Large_Language_Models.html#appendix",
    "href": "posts/Spoken_Stereoset_On_Evaluating_Social_Bias_Toward_Speaker_in_Speech_Large_Language_Models/2024-08-14-Spoken_Stereoset_On_Evaluating_Social_Bias_Toward_Speaker_in_Speech_Large_Language_Models.html#appendix",
    "title": "Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07665v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07665v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4788"
  },
  {
    "objectID": "posts/DICE_Detecting_In_distribution_Contamination_in_LLMs_Fine_tuning_Phase_for_Math_Reasoning/2024-06-06-DICE_Detecting_In_distribution_Contamination_in_LLMs_Fine_tuning_Phase_for_Math_Reasoning.html#appendix",
    "href": "posts/DICE_Detecting_In_distribution_Contamination_in_LLMs_Fine_tuning_Phase_for_Math_Reasoning/2024-06-06-DICE_Detecting_In_distribution_Contamination_in_LLMs_Fine_tuning_Phase_for_Math_Reasoning.html#appendix",
    "title": "DICE: Detecting In-distribution Contamination in LLM’s Fine-tuning Phase for Math Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04197v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04197v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6104"
  },
  {
    "objectID": "posts/Translating_Across_Cultures_LLMs_for_Intralingual_Cultural_Adaptation/2024-06-20-Translating_Across_Cultures_LLMs_for_Intralingual_Cultural_Adaptation.html#appendix",
    "href": "posts/Translating_Across_Cultures_LLMs_for_Intralingual_Cultural_Adaptation/2024-06-20-Translating_Across_Cultures_LLMs_for_Intralingual_Cultural_Adaptation.html#appendix",
    "title": "Translating Across Cultures: LLMs for Intralingual Cultural Adaptation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14504v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14504v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7296"
  },
  {
    "objectID": "posts/iLLM_TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement/2024-07-08-iLLM_TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement.html",
    "href": "posts/iLLM_TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement/2024-07-08-iLLM_TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement.html",
    "title": "iLLM-TSC: Integration reinforcement learning and large language model for traffic signal control policy improvement",
    "section": "",
    "text": "Summary:\nThe paper introduces a novel integration framework, iLLM-TSC, which combines a large language model (LLM) with reinforcement learning (RL) to address the limitations of existing RL-based traffic signal control (TSC) systems. These limitations include imperfect observations caused by degraded communication and the absence of rare real-life events in the reward function, such as unconsidered emergency vehicles. The iLLM-TSC framework allows RL agents to make initial decisions based on observed data, leveraging their ability to learn from specific environments. Subsequently, the LLM model refines these decisions by incorporating additional real-time information not initially used by the RL agents. This integration approach can be seamlessly integrated with existing RL-based TSC systems without requiring modifications. Extensive testing confirms that the iLLM-TSC approach reduces the average waiting time by 17.5% in degraded communication conditions compared to traditional RL methods.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/iLLM_TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement/2024-07-08-iLLM_TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement.html#appendix",
    "href": "posts/iLLM_TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement/2024-07-08-iLLM_TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement.html#appendix",
    "title": "iLLM-TSC: Integration reinforcement learning and large language model for traffic signal control policy improvement",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06025v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06025v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8535"
  },
  {
    "objectID": "posts/Arctic_TILT._Business_Document_Understanding_at_Sub_Billion_Scale/2024-08-08-Arctic_TILT._Business_Document_Understanding_at_Sub_Billion_Scale.html#appendix",
    "href": "posts/Arctic_TILT._Business_Document_Understanding_at_Sub_Billion_Scale/2024-08-08-Arctic_TILT._Business_Document_Understanding_at_Sub_Billion_Scale.html#appendix",
    "title": "Arctic-TILT. Business Document Understanding at Sub-Billion Scale",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04632v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04632v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7255"
  },
  {
    "objectID": "posts/Beyond_Numeric_Awards_In_Context_Dueling_Bandits_with_LLM_Agents/2024-07-02-Beyond_Numeric_Awards_In_Context_Dueling_Bandits_with_LLM_Agents.html",
    "href": "posts/Beyond_Numeric_Awards_In_Context_Dueling_Bandits_with_LLM_Agents/2024-07-02-Beyond_Numeric_Awards_In_Context_Dueling_Bandits_with_LLM_Agents.html",
    "title": "Beyond Numeric Awards: In-Context Dueling Bandits with LLM Agents",
    "section": "",
    "text": "Summary:\nThis paper investigates the performance of Large Language Models (LLMs) as decision-makers in the context of Dueling Bandits (DB). The study compares GPT-3.5 Turbo, GPT-4, and GPT-4 Turbo against established DB algorithms. The results reveal that LLMs, particularly GPT-4 Turbo, quickly identify the Condorcet winner, outperforming existing state-of-the-art algorithms in terms of weak regret. However, LLMs struggle to converge even when explicitly prompted to do so and are sensitive to prompt variations. To overcome these issues, the paper introduces an LLM-augmented algorithm, IF-Enhanced LLM, which combines the in-context decision-making capabilities of LLMs and theoretical guarantees inherited from classic DB algorithms. The proposed algorithm has theoretical guarantees on both weak and strong regret and is robust even with noisy and adversarial prompts.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an interesting approach to using LLMs in the context of DB. The findings that LLMs can quickly identify the Condorcet winner are promising, but the lack of convergence and sensitivity to prompt variations are limitations that need to be addressed. The proposed LLM-augmented algorithm, IF-Enhanced LLM, is a step in the right direction, as it combines the strengths of LLMs and classic DB algorithms. However, the robustness of this algorithm to noisy and adversarial prompts needs to be further validated in different scenarios and with different types of LLMs. Additionally,"
  },
  {
    "objectID": "posts/Beyond_Numeric_Awards_In_Context_Dueling_Bandits_with_LLM_Agents/2024-07-02-Beyond_Numeric_Awards_In_Context_Dueling_Bandits_with_LLM_Agents.html#appendix",
    "href": "posts/Beyond_Numeric_Awards_In_Context_Dueling_Bandits_with_LLM_Agents/2024-07-02-Beyond_Numeric_Awards_In_Context_Dueling_Bandits_with_LLM_Agents.html#appendix",
    "title": "Beyond Numeric Awards: In-Context Dueling Bandits with LLM Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01887v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01887v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11940"
  },
  {
    "objectID": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#major-findings",
    "href": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#major-findings",
    "title": "Characterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People",
    "section": "Major Findings",
    "text": "Major Findings\n\nThe proposed method enables the characterization of conversational tones and their taxonomies in any target human population as well as LLMs, without relying on predefined taxonomies or constrained sets of stimuli.\nThe study addresses the challenges of biased apriori taxonomy and biased stimulus set in existing research on conversational tones.\nThe paper presents an additional experiment where humans and GPT-4 annotated all sentences with all tones, resulting in an interpretable geometric representation of relations between conversational tones in humans and GPT-4."
  },
  {
    "objectID": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#analysis-and-critique",
    "href": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#analysis-and-critique",
    "title": "Characterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\nThe paper presents a novel and promising approach to characterize conversational tones and their taxonomies in humans and LLMs. The proposed method addresses the limitations"
  },
  {
    "objectID": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#appendix",
    "href": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#appendix",
    "title": "Characterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04278v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04278v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14313"
  },
  {
    "objectID": "posts/Attribution_Analysis_Meets_Model_Editing_Advancing_Knowledge_Correction_in_Vision_Language_Models_with_VisEdit/2024-08-19-Attribution_Analysis_Meets_Model_Editing_Advancing_Knowledge_Correction_in_Vision_Language_Models_with_VisEdit.html#appendix",
    "href": "posts/Attribution_Analysis_Meets_Model_Editing_Advancing_Knowledge_Correction_in_Vision_Language_Models_with_VisEdit/2024-08-19-Attribution_Analysis_Meets_Model_Editing_Advancing_Knowledge_Correction_in_Vision_Language_Models_with_VisEdit.html#appendix",
    "title": "Attribution Analysis Meets Model Editing: Advancing Knowledge Correction in Vision Language Models with VisEdit",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09916v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09916v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9519"
  },
  {
    "objectID": "posts/A_Three_Pronged_Approach_to_Cross_Lingual_Adaptation_with_Multilingual_LLMs/2024-06-25-A_Three_Pronged_Approach_to_Cross_Lingual_Adaptation_with_Multilingual_LLMs.html#appendix",
    "href": "posts/A_Three_Pronged_Approach_to_Cross_Lingual_Adaptation_with_Multilingual_LLMs/2024-06-25-A_Three_Pronged_Approach_to_Cross_Lingual_Adaptation_with_Multilingual_LLMs.html#appendix",
    "title": "A Three-Pronged Approach to Cross-Lingual Adaptation with Multilingual LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17377v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17377v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6250"
  },
  {
    "objectID": "posts/GeoReasoner_Reasoning_On_Geospatially_Grounded_Context_For_Natural_Language_Understanding/2024-08-21-GeoReasoner_Reasoning_On_Geospatially_Grounded_Context_For_Natural_Language_Understanding.html#appendix",
    "href": "posts/GeoReasoner_Reasoning_On_Geospatially_Grounded_Context_For_Natural_Language_Understanding/2024-08-21-GeoReasoner_Reasoning_On_Geospatially_Grounded_Context_For_Natural_Language_Understanding.html#appendix",
    "title": "GeoReasoner: Reasoning On Geospatially Grounded Context For Natural Language Understanding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11366v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11366v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3839"
  },
  {
    "objectID": "posts/OptiMUS_0.3_Using_Large_Language_Models_to_Model_and_Solve_Optimization_Problems_at_Scale/2024-07-29-OptiMUS_0.3_Using_Large_Language_Models_to_Model_and_Solve_Optimization_Problems_at_Scale.html#appendix",
    "href": "posts/OptiMUS_0.3_Using_Large_Language_Models_to_Model_and_Solve_Optimization_Problems_at_Scale/2024-07-29-OptiMUS_0.3_Using_Large_Language_Models_to_Model_and_Solve_Optimization_Problems_at_Scale.html#appendix",
    "title": "OptiMUS-0.3: Using Large Language Models to Model and Solve Optimization Problems at Scale",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19633v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19633v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9822"
  },
  {
    "objectID": "posts/Identity_Driven_Hierarchical_Role_Playing_Agents/2024-07-28-Identity_Driven_Hierarchical_Role_Playing_Agents.html#appendix",
    "href": "posts/Identity_Driven_Hierarchical_Role_Playing_Agents/2024-07-28-Identity_Driven_Hierarchical_Role_Playing_Agents.html#appendix",
    "title": "Identity-Driven Hierarchical Role-Playing Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19412v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19412v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6038"
  },
  {
    "objectID": "posts/RAGSys_Item_Cold_Start_Recommender_as_RAG_System/2024-05-27-RAGSys_Item_Cold_Start_Recommender_as_RAG_System.html#appendix",
    "href": "posts/RAGSys_Item_Cold_Start_Recommender_as_RAG_System/2024-05-27-RAGSys_Item_Cold_Start_Recommender_as_RAG_System.html#appendix",
    "title": "RAGSys: Item-Cold-Start Recommender as RAG System",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.17587v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.17587v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9098"
  },
  {
    "objectID": "posts/CIBench_Evaluating_Your_LLMs_with_a_Code_Interpreter_Plugin/2024-07-15-CIBench_Evaluating_Your_LLMs_with_a_Code_Interpreter_Plugin.html#appendix",
    "href": "posts/CIBench_Evaluating_Your_LLMs_with_a_Code_Interpreter_Plugin/2024-07-15-CIBench_Evaluating_Your_LLMs_with_a_Code_Interpreter_Plugin.html#appendix",
    "title": "CIBench: Evaluating Your LLMs with a Code Interpreter Plugin",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10499v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10499v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6515"
  },
  {
    "objectID": "posts/MrRank_Improving_Question_Answering_Retrieval_System_through_Multi_Result_Ranking_Model/2024-06-09-MrRank_Improving_Question_Answering_Retrieval_System_through_Multi_Result_Ranking_Model.html#appendix",
    "href": "posts/MrRank_Improving_Question_Answering_Retrieval_System_through_Multi_Result_Ranking_Model/2024-06-09-MrRank_Improving_Question_Answering_Retrieval_System_through_Multi_Result_Ranking_Model.html#appendix",
    "title": "MrRank: Improving Question Answering Retrieval System through Multi-Result Ranking Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05733v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05733v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5268"
  },
  {
    "objectID": "posts/Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated/2024-06-26-Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated.html#major-findings",
    "href": "posts/Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated/2024-06-26-Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated.html#major-findings",
    "title": "Detecting Machine-Generated Texts: Not Just AI vs Humans and Explainability is Complicated",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe study introduces a novel ternary classification system for analyzing texts, adding an “undecided” category to the classification framework. This category recognizes that some texts may simultaneously share characteristics of both machine-generated and human-generated texts.\nThe authors developed a ternary classification dataset and designed experiments to test the validity of this approach. The methodology includes rigorous statistical and model-based analyses and incorporates detailed human evaluations to provide a nuanced understanding of the new ternary text classification task and the complexity of producing human-understandable explanations.\nThe study compares the explanatory power of human assessments with that of automated detectors, highlighting the current explanatory limitations faced by MGT detectors. The results show that the “undecided” category is much needed from the viewpoint of explainability."
  },
  {
    "objectID": "posts/Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated/2024-06-26-Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated.html#analysis-and-critique",
    "href": "posts/Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated/2024-06-26-Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated.html#analysis-and-critique",
    "title": "Detecting Machine-Generated Texts: Not Just AI vs Humans and Explainability is Complicated",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a well-structured and coherent summary of the academic article, effectively communicating the essential information. The major findings are clearly highlighted, and the analysis provides a critical evaluation of the article’s strengths and weaknesses. However, the critique could be more detailed, addressing specific methodological issues, conflicting evidence, or areas that require further research or clarification. Additionally, the summary could benefit from a more concise and focused presentation of the article’s main arguments and contributions.\nIn summary, the paper provides a valuable overview of the challenges and limitations of current methods for detecting machine-generated texts."
  },
  {
    "objectID": "posts/Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated/2024-06-26-Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated.html#appendix",
    "href": "posts/Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated/2024-06-26-Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated.html#appendix",
    "title": "Detecting Machine-Generated Texts: Not Just AI vs Humans and Explainability is Complicated",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18259v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18259v1\n\n\nTruncated\nFalse\n\n\nWord Count\n19402"
  },
  {
    "objectID": "posts/Large_Language_Models_Are_Self_Taught_Reasoners_Enhancing_LLM_Applications_via_Tailored_Problem_Solving_Demonstrations/2024-08-22-Large_Language_Models_Are_Self_Taught_Reasoners_Enhancing_LLM_Applications_via_Tailored_Problem_Solving_Demonstrations.html#appendix",
    "href": "posts/Large_Language_Models_Are_Self_Taught_Reasoners_Enhancing_LLM_Applications_via_Tailored_Problem_Solving_Demonstrations/2024-08-22-Large_Language_Models_Are_Self_Taught_Reasoners_Enhancing_LLM_Applications_via_Tailored_Problem_Solving_Demonstrations.html#appendix",
    "title": "Large Language Models Are Self-Taught Reasoners: Enhancing LLM Applications via Tailored Problem-Solving Demonstrations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12315v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12315v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9028"
  },
  {
    "objectID": "posts/Chain_of_Scrutiny_Detecting_Backdoor_Attacks_for_Large_Language_Models/2024-06-10-Chain_of_Scrutiny_Detecting_Backdoor_Attacks_for_Large_Language_Models.html#appendix",
    "href": "posts/Chain_of_Scrutiny_Detecting_Backdoor_Attacks_for_Large_Language_Models/2024-06-10-Chain_of_Scrutiny_Detecting_Backdoor_Attacks_for_Large_Language_Models.html#appendix",
    "title": "Chain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05948v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05948v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6961"
  },
  {
    "objectID": "posts/Cambrian_1_A_Fully_Open_Vision_Centric_Exploration_of_Multimodal_LLMs/2024-06-24-Cambrian_1_A_Fully_Open_Vision_Centric_Exploration_of_Multimodal_LLMs.html",
    "href": "posts/Cambrian_1_A_Fully_Open_Vision_Centric_Exploration_of_Multimodal_LLMs/2024-06-24-Cambrian_1_A_Fully_Open_Vision_Centric_Exploration_of_Multimodal_LLMs.html",
    "title": "Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs",
    "section": "",
    "text": "Summary:\nThe paper introduces Cambrian-1, a family of multimodal large language models (MLLMs) that adopt a vision-centric approach. The authors argue that the design choices for vision components in MLLMs are often insufficiently explored and disconnected from visual representation learning research, hindering accurate sensory grounding in real-world scenarios. The study uses LLMs and visual instruction tuning as an interface to evaluate various visual representations, offering new insights into different models and architectures. The authors critically examine existing MLLM benchmarks and introduce a new vision-centric benchmark, CV-Bench. They also propose the Spatial Vision Aggregator (SVA), a dynamic and spatially-aware connector that integrates high-resolution vision features with LLMs while reducing the number of tokens.\nMajor Findings:"
  },
  {
    "objectID": "posts/Cambrian_1_A_Fully_Open_Vision_Centric_Exploration_of_Multimodal_LLMs/2024-06-24-Cambrian_1_A_Fully_Open_Vision_Centric_Exploration_of_Multimodal_LLMs.html#appendix",
    "href": "posts/Cambrian_1_A_Fully_Open_Vision_Centric_Exploration_of_Multimodal_LLMs/2024-06-24-Cambrian_1_A_Fully_Open_Vision_Centric_Exploration_of_Multimodal_LLMs.html#appendix",
    "title": "Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16860v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16860v1\n\n\nTruncated\nTrue\n\n\nWord Count\n44586"
  },
  {
    "objectID": "posts/SEC_QA_A_Systematic_Evaluation_Corpus_for_Financial_QA/2024-06-20-SEC_QA_A_Systematic_Evaluation_Corpus_for_Financial_QA.html#appendix",
    "href": "posts/SEC_QA_A_Systematic_Evaluation_Corpus_for_Financial_QA/2024-06-20-SEC_QA_A_Systematic_Evaluation_Corpus_for_Financial_QA.html#appendix",
    "title": "SEC-QA: A Systematic Evaluation Corpus for Financial QA",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14394v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14394v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6714"
  },
  {
    "objectID": "posts/WildHallucinations_Evaluating_Long_form_Factuality_in_LLMs_with_Real_World_Entity_Queries/2024-07-24-WildHallucinations_Evaluating_Long_form_Factuality_in_LLMs_with_Real_World_Entity_Queries.html#appendix",
    "href": "posts/WildHallucinations_Evaluating_Long_form_Factuality_in_LLMs_with_Real_World_Entity_Queries/2024-07-24-WildHallucinations_Evaluating_Long_form_Factuality_in_LLMs_with_Real_World_Entity_Queries.html#appendix",
    "title": "WildHallucinations: Evaluating Long-form Factuality in LLMs with Real-World Entity Queries",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17468v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17468v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6178"
  },
  {
    "objectID": "posts/Beyond_Inter_Item_Relations_Dynamic_Adaptive_Mixture_of_Experts_for_LLM_Based_Sequential_Recommendation/2024-08-14-Beyond_Inter_Item_Relations_Dynamic_Adaptive_Mixture_of_Experts_for_LLM_Based_Sequential_Recommendation.html#appendix",
    "href": "posts/Beyond_Inter_Item_Relations_Dynamic_Adaptive_Mixture_of_Experts_for_LLM_Based_Sequential_Recommendation/2024-08-14-Beyond_Inter_Item_Relations_Dynamic_Adaptive_Mixture_of_Experts_for_LLM_Based_Sequential_Recommendation.html#appendix",
    "title": "Beyond Inter-Item Relations: Dynamic Adaptive Mixture-of-Experts for LLM-Based Sequential Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07427v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07427v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9137"
  },
  {
    "objectID": "posts/An_Empirical_Study_of_Unit_Test_Generation_with_Large_Language_Models/2024-06-26-An_Empirical_Study_of_Unit_Test_Generation_with_Large_Language_Models.html#appendix",
    "href": "posts/An_Empirical_Study_of_Unit_Test_Generation_with_Large_Language_Models/2024-06-26-An_Empirical_Study_of_Unit_Test_Generation_with_Large_Language_Models.html#appendix",
    "title": "An Empirical Study of Unit Test Generation with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18181v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18181v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13168"
  },
  {
    "objectID": "posts/RedAgent_Red_Teaming_Large_Language_Models_with_Context_aware_Autonomous_Language_Agent/2024-07-23-RedAgent_Red_Teaming_Large_Language_Models_with_Context_aware_Autonomous_Language_Agent.html",
    "href": "posts/RedAgent_Red_Teaming_Large_Language_Models_with_Context_aware_Autonomous_Language_Agent/2024-07-23-RedAgent_Red_Teaming_Large_Language_Models_with_Context_aware_Autonomous_Language_Agent.html",
    "title": "RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent",
    "section": "",
    "text": "Summary:\nThe paper introduces RedAgent, a multi-agent language model system designed to generate context-aware jailbreak prompts for testing the security of large language models (LLMs). The system leverages a concept called “jailbreak strategy” to model existing attacks and improve the efficiency of red teaming methods. RedAgent can jailbreak most black-box LLMs within five queries, improving the efficiency of existing red teaming methods by two times. The system can also jailbreak customized LLM applications more efficiently, discovering 60 severe vulnerabilities in real-world applications with only two queries per vulnerability.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an innovative approach to testing the security of LLMs by generating context-aware jailbreak prompts. The use of a multi-agent language model system and the concept of “jailbreak strategy” are promising developments in the field of LLM security. However, the paper does not discuss the potential risks associated with using such a system, such as the possibility of malicious actors using it to exploit vulnerabilities in LLMs. Additionally, the paper does not provide a detailed analysis of the limitations of the system or the potential biases that may be introduced during the red teaming process. Further research is needed to address these concerns and ensure the responsible use of such systems."
  },
  {
    "objectID": "posts/RedAgent_Red_Teaming_Large_Language_Models_with_Context_aware_Autonomous_Language_Agent/2024-07-23-RedAgent_Red_Teaming_Large_Language_Models_with_Context_aware_Autonomous_Language_Agent.html#appendix",
    "href": "posts/RedAgent_Red_Teaming_Large_Language_Models_with_Context_aware_Autonomous_Language_Agent/2024-07-23-RedAgent_Red_Teaming_Large_Language_Models_with_Context_aware_Autonomous_Language_Agent.html#appendix",
    "title": "RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16667v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16667v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12111"
  },
  {
    "objectID": "posts/Using_Grammar_Masking_to_Ensure_Syntactic_Validity_in_LLM_based_Modeling_Tasks/2024-07-08-Using_Grammar_Masking_to_Ensure_Syntactic_Validity_in_LLM_based_Modeling_Tasks.html#appendix",
    "href": "posts/Using_Grammar_Masking_to_Ensure_Syntactic_Validity_in_LLM_based_Modeling_Tasks/2024-07-08-Using_Grammar_Masking_to_Ensure_Syntactic_Validity_in_LLM_based_Modeling_Tasks.html#appendix",
    "title": "Using Grammar Masking to Ensure Syntactic Validity in LLM-based Modeling Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06146v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06146v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6526"
  },
  {
    "objectID": "posts/Exploring_Automatic_Cryptographic_API_Misuse_Detection_in_the_Era_of_LLMs/2024-07-23-Exploring_Automatic_Cryptographic_API_Misuse_Detection_in_the_Era_of_LLMs.html",
    "href": "posts/Exploring_Automatic_Cryptographic_API_Misuse_Detection_in_the_Era_of_LLMs/2024-07-23-Exploring_Automatic_Cryptographic_API_Misuse_Detection_in_the_Era_of_LLMs.html",
    "title": "Exploring Automatic Cryptographic API Misuse Detection in the Era of LLMs",
    "section": "",
    "text": "Summary:\nThis paper explores the use of Large Language Models (LLMs) for detecting cryptographic misuses, a task that has traditionally been performed by pattern-based static analysis tools (SATs). The authors introduce a systematic evaluation framework to assess LLMs in this context, using a comprehensive dataset that includes both manually-crafted samples and real-world projects. The study reveals that LLMs can exhibit inherent instabilities, with over half of the reports being false positives. However, the authors demonstrate that a constrained problem scope and LLMs’ self-correction capability can significantly enhance the reliability of the detection. The optimized approach achieves a remarkable detection rate of nearly 90%, surpassing traditional methods and uncovering previously unknown misuses in established benchmarks. The study also identifies failure patterns that hinder LLMs’ reliability, including cryptographic knowledge deficiency and code semantics misinterpretation. The authors then develop an LLM-based workflow to examine open-source repositories, leading to the discovery of 63 real-world cryptographic misuses, of which 46 have been acknowledged by the development community.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a comprehensive evaluation of LLMs for cryptographic misuse detection, highlighting their potential and limitations. The authors’ systematic approach to evalu"
  },
  {
    "objectID": "posts/Exploring_Automatic_Cryptographic_API_Misuse_Detection_in_the_Era_of_LLMs/2024-07-23-Exploring_Automatic_Cryptographic_API_Misuse_Detection_in_the_Era_of_LLMs.html#appendix",
    "href": "posts/Exploring_Automatic_Cryptographic_API_Misuse_Detection_in_the_Era_of_LLMs/2024-07-23-Exploring_Automatic_Cryptographic_API_Misuse_Detection_in_the_Era_of_LLMs.html#appendix",
    "title": "Exploring Automatic Cryptographic API Misuse Detection in the Era of LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16576v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16576v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14418"
  },
  {
    "objectID": "posts/GoNoGo_An_Efficient_LLM_based_Multi_Agent_System_for_Streamlining_Automotive_Software_Release_Decision_Making/2024-08-19-GoNoGo_An_Efficient_LLM_based_Multi_Agent_System_for_Streamlining_Automotive_Software_Release_Decision_Making.html#appendix",
    "href": "posts/GoNoGo_An_Efficient_LLM_based_Multi_Agent_System_for_Streamlining_Automotive_Software_Release_Decision_Making/2024-08-19-GoNoGo_An_Efficient_LLM_based_Multi_Agent_System_for_Streamlining_Automotive_Software_Release_Decision_Making.html#appendix",
    "title": "GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive Software Release Decision-Making",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09785v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09785v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6011"
  },
  {
    "objectID": "posts/Keyword_driven_Retrieval_Augmented_Large_Language_Models_for_Cold_start_User_Recommendations/2024-05-30-Keyword_driven_Retrieval_Augmented_Large_Language_Models_for_Cold_start_User_Recommendations.html#appendix",
    "href": "posts/Keyword_driven_Retrieval_Augmented_Large_Language_Models_for_Cold_start_User_Recommendations/2024-05-30-Keyword_driven_Retrieval_Augmented_Large_Language_Models_for_Cold_start_User_Recommendations.html#appendix",
    "title": "Keyword-driven Retrieval-Augmented Large Language Models for Cold-start User Recommendations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.19612v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.19612v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8262"
  },
  {
    "objectID": "posts/Privacy_Checklist_Privacy_Violation_Detection_Grounding_on_Contextual_Integrity_Theory/2024-08-19-Privacy_Checklist_Privacy_Violation_Detection_Grounding_on_Contextual_Integrity_Theory.html#appendix",
    "href": "posts/Privacy_Checklist_Privacy_Violation_Detection_Grounding_on_Contextual_Integrity_Theory/2024-08-19-Privacy_Checklist_Privacy_Violation_Detection_Grounding_on_Contextual_Integrity_Theory.html#appendix",
    "title": "Privacy Checklist: Privacy Violation Detection Grounding on Contextual Integrity Theory",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10053v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10053v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6383"
  },
  {
    "objectID": "posts/From_Decoding_to_Meta_Generation_Inference_time_Algorithms_for_Large_Language_Models/2024-06-24-From_Decoding_to_Meta_Generation_Inference_time_Algorithms_for_Large_Language_Models.html",
    "href": "posts/From_Decoding_to_Meta_Generation_Inference_time_Algorithms_for_Large_Language_Models/2024-06-24-From_Decoding_to_Meta_Generation_Inference_time_Algorithms_for_Large_Language_Models.html",
    "title": "From Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models",
    "section": "",
    "text": "Summary:\nThe paper explores the use of large language models (LLMs) in natural language processing, focusing on three main themes: token-level generation algorithms, meta-generation algorithms, and efficient generation. Token-level generation algorithms, such as decoding algorithms, have a rich history in natural language processing and operate by sampling one token at a time or constructing a token-level search space. Recently, there has been growing interest in meta-generation algorithms, which operate on partial or full sequences and treat the LLM as a black box that is called as part of a larger generation program. These algorithms can increase the compute resources devoted to generation by making multiple model calls, augmenting the model with search algorithms, or incorporating external data sources. The paper also discusses the limitations of the Maximum A Posteriori (MAP) decoding objective in neural machine translation (NMT) and the use of reranking and transforming N-"
  },
  {
    "objectID": "posts/From_Decoding_to_Meta_Generation_Inference_time_Algorithms_for_Large_Language_Models/2024-06-24-From_Decoding_to_Meta_Generation_Inference_time_Algorithms_for_Large_Language_Models.html#appendix",
    "href": "posts/From_Decoding_to_Meta_Generation_Inference_time_Algorithms_for_Large_Language_Models/2024-06-24-From_Decoding_to_Meta_Generation_Inference_time_Algorithms_for_Large_Language_Models.html#appendix",
    "title": "From Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16838v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16838v1\n\n\nTruncated\nTrue\n\n\nWord Count\n45988"
  },
  {
    "objectID": "posts/A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions/2024-06-06-A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions.html",
    "href": "posts/A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions/2024-06-06-A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions.html",
    "title": "A Survey on Medical Large Language Models: Technology, Application, Trustworthiness, and Future Directions",
    "section": "",
    "text": "Summary:\nThis survey provides a comprehensive overview of Medical Large Language Models (Med-LLMs), outlining their evolution from general to medical-specific domains and their transformative impact on healthcare. The study explores the fundamental history and technology of LLMs, delving into the progressive adaptation and refinements of general LLM models in the medical domain. It emphasizes advanced algorithms that boost the LLMs’ performance in handling complicated medical environments, including clinical reasoning, knowledge graph, retrieval-augmented generation, human alignment, and multi-modal learning.\nThe survey also explores the extensive applications of Med-LLMs across domains such as clinical decision support, report generation, and medical education, illustrating their potential to streamline healthcare services and augment patient outcomes. Recognizing the imperative for responsible innovation, the study discusses the challenges of ensuring fairness, accountability, privacy, and robustness in Med-LLMs applications, where ethical considerations, rigorous evaluation methodologies, and the formulation of regulatory frameworks are pivotal to fostering trustworthiness in these systems.\nMajor Findings:\nAnalysis and Critique:\nThis survey provides a comprehensive investigation of the potential strengths and limitations of Med-LLMs for professionals and researchers, ensuring a responsible landscape in the healthcare setting. However, it is important to note that the study primarily focuses on"
  },
  {
    "objectID": "posts/A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions/2024-06-06-A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions.html#appendix",
    "href": "posts/A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions/2024-06-06-A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions.html#appendix",
    "title": "A Survey on Medical Large Language Models: Technology, Application, Trustworthiness, and Future Directions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03712v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03712v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18909"
  },
  {
    "objectID": "posts/Let_the_Code_LLM_Edit_Itself_When_You_Edit_the_Code/2024-07-03-Let_the_Code_LLM_Edit_Itself_When_You_Edit_the_Code.html#appendix",
    "href": "posts/Let_the_Code_LLM_Edit_Itself_When_You_Edit_the_Code/2024-07-03-Let_the_Code_LLM_Edit_Itself_When_You_Edit_the_Code.html#appendix",
    "title": "Let the Code LLM Edit Itself When You Edit the Code",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03157v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03157v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6193"
  },
  {
    "objectID": "posts/LLaSA_Large_Multimodal_Agent_for_Human_Activity_Analysis_Through_Wearable_Sensors/2024-06-20-LLaSA_Large_Multimodal_Agent_for_Human_Activity_Analysis_Through_Wearable_Sensors.html#appendix",
    "href": "posts/LLaSA_Large_Multimodal_Agent_for_Human_Activity_Analysis_Through_Wearable_Sensors/2024-06-20-LLaSA_Large_Multimodal_Agent_for_Human_Activity_Analysis_Through_Wearable_Sensors.html#appendix",
    "title": "LLaSA: Large Multimodal Agent for Human Activity Analysis Through Wearable Sensors",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14498v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14498v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3974"
  },
  {
    "objectID": "posts/Beyond_Under_Alignment_Atomic_Preference_Enhanced_Factuality_Tuning_for_Large_Language_Models/2024-06-18-Beyond_Under_Alignment_Atomic_Preference_Enhanced_Factuality_Tuning_for_Large_Language_Models.html#appendix",
    "href": "posts/Beyond_Under_Alignment_Atomic_Preference_Enhanced_Factuality_Tuning_for_Large_Language_Models/2024-06-18-Beyond_Under_Alignment_Atomic_Preference_Enhanced_Factuality_Tuning_for_Large_Language_Models.html#appendix",
    "title": "Beyond Under-Alignment: Atomic Preference Enhanced Factuality Tuning for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12416v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12416v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6437"
  },
  {
    "objectID": "posts/LLM_enhanced_Reranking_in_Recommender_Systems/2024-06-18-LLM_enhanced_Reranking_in_Recommender_Systems.html#appendix",
    "href": "posts/LLM_enhanced_Reranking_in_Recommender_Systems/2024-06-18-LLM_enhanced_Reranking_in_Recommender_Systems.html#appendix",
    "title": "LLM-enhanced Reranking in Recommender Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12433v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12433v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8439"
  },
  {
    "objectID": "posts/Seeing_and_Understanding_Bridging_Vision_with_Chemical_Knowledge_Via_ChemVLM/2024-08-14-Seeing_and_Understanding_Bridging_Vision_with_Chemical_Knowledge_Via_ChemVLM.html#appendix",
    "href": "posts/Seeing_and_Understanding_Bridging_Vision_with_Chemical_Knowledge_Via_ChemVLM/2024-08-14-Seeing_and_Understanding_Bridging_Vision_with_Chemical_Knowledge_Via_ChemVLM.html#appendix",
    "title": "Seeing and Understanding: Bridging Vision with Chemical Knowledge Via ChemVLM",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07246v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07246v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4903"
  },
  {
    "objectID": "posts/Improving_Multilingual_Instruction_Finetuning_via_Linguistically_Natural_and_Diverse_Datasets/2024-07-01-Improving_Multilingual_Instruction_Finetuning_via_Linguistically_Natural_and_Diverse_Datasets.html#appendix",
    "href": "posts/Improving_Multilingual_Instruction_Finetuning_via_Linguistically_Natural_and_Diverse_Datasets/2024-07-01-Improving_Multilingual_Instruction_Finetuning_via_Linguistically_Natural_and_Diverse_Datasets.html#appendix",
    "title": "Improving Multilingual Instruction Finetuning via Linguistically Natural and Diverse Datasets",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01853v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01853v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6194"
  },
  {
    "objectID": "posts/medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs/2024-06-20-medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs.html",
    "href": "posts/medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs/2024-06-20-medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs.html",
    "title": "medIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced Clinical Diagnosis on EMRs",
    "section": "",
    "text": "Summary:\nThe paper introduces medIKAL, a framework that integrates Large Language Models (LLMs) with knowledge graphs (KGs) to enhance clinical diagnosis on Electronic Medical Records (EMRs). The framework assigns weighted importance to entities in medical records based on their type, enabling precise localization of candidate diseases within KGs. It employs a residual network-like approach, allowing initial diagnosis by the LLM to be merged into KG search results. The diagnostic process is further refined through a path-based reranking algorithm and a fill-in-the-blank style prompt template. The effectiveness of medIKAL is validated through extensive experiments on a newly introduced open-sourced Chinese EMR dataset.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs/2024-06-20-medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs.html#appendix",
    "href": "posts/medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs/2024-06-20-medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs.html#appendix",
    "title": "medIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced Clinical Diagnosis on EMRs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14326v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14326v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7194"
  },
  {
    "objectID": "posts/Conversational_Prompt_Engineering/2024-08-08-Conversational_Prompt_Engineering.html#appendix",
    "href": "posts/Conversational_Prompt_Engineering/2024-08-08-Conversational_Prompt_Engineering.html#appendix",
    "title": "Conversational Prompt Engineering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04560v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04560v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6089"
  },
  {
    "objectID": "posts/CMoralEval_A_Moral_Evaluation_Benchmark_for_Chinese_Large_Language_Models/2024-08-19-CMoralEval_A_Moral_Evaluation_Benchmark_for_Chinese_Large_Language_Models.html#appendix",
    "href": "posts/CMoralEval_A_Moral_Evaluation_Benchmark_for_Chinese_Large_Language_Models/2024-08-19-CMoralEval_A_Moral_Evaluation_Benchmark_for_Chinese_Large_Language_Models.html#appendix",
    "title": "CMoralEval: A Moral Evaluation Benchmark for Chinese Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09819v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09819v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8745"
  },
  {
    "objectID": "posts/FastMem_Fast_Memorization_of_Prompt_Improves_Context_Awareness_of_Large_Language_Models/2024-06-23-FastMem_Fast_Memorization_of_Prompt_Improves_Context_Awareness_of_Large_Language_Models.html#appendix",
    "href": "posts/FastMem_Fast_Memorization_of_Prompt_Improves_Context_Awareness_of_Large_Language_Models/2024-06-23-FastMem_Fast_Memorization_of_Prompt_Improves_Context_Awareness_of_Large_Language_Models.html#appendix",
    "title": "FastMem: Fast Memorization of Prompt Improves Context Awareness of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16069v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16069v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7001"
  },
  {
    "objectID": "posts/RoboMorph_Evolving_Robot_Morphology_using_Large_Language_Models/2024-07-11-RoboMorph_Evolving_Robot_Morphology_using_Large_Language_Models.html#appendix",
    "href": "posts/RoboMorph_Evolving_Robot_Morphology_using_Large_Language_Models/2024-07-11-RoboMorph_Evolving_Robot_Morphology_using_Large_Language_Models.html#appendix",
    "title": "RoboMorph: Evolving Robot Morphology using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08626v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08626v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6644"
  },
  {
    "objectID": "posts/Utilizing_Large_Language_Models_to_Optimize_the_Detection_and_Explainability_of_Phishing_Websites/2024-08-11-Utilizing_Large_Language_Models_to_Optimize_the_Detection_and_Explainability_of_Phishing_Websites.html#appendix",
    "href": "posts/Utilizing_Large_Language_Models_to_Optimize_the_Detection_and_Explainability_of_Phishing_Websites/2024-08-11-Utilizing_Large_Language_Models_to_Optimize_the_Detection_and_Explainability_of_Phishing_Websites.html#appendix",
    "title": "Utilizing Large Language Models to Optimize the Detection and Explainability of Phishing Websites",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.05667v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.05667v1\n\n\nTruncated\nFalse\n\n\nWord Count\n16293"
  },
  {
    "objectID": "posts/Revisiting_VerilogEval_Newer_LLMs_In_Context_Learning_and_Specification_to_RTL_Tasks/2024-08-20-Revisiting_VerilogEval_Newer_LLMs_In_Context_Learning_and_Specification_to_RTL_Tasks.html#appendix",
    "href": "posts/Revisiting_VerilogEval_Newer_LLMs_In_Context_Learning_and_Specification_to_RTL_Tasks/2024-08-20-Revisiting_VerilogEval_Newer_LLMs_In_Context_Learning_and_Specification_to_RTL_Tasks.html#appendix",
    "title": "Revisiting VerilogEval: Newer LLMs, In-Context Learning, and Specification-to-RTL Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11053v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11053v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4925"
  },
  {
    "objectID": "posts/SynDARin_Synthesising_Datasets_for_Automated_Reasoning_in_Low_Resource_Languages/2024-06-20-SynDARin_Synthesising_Datasets_for_Automated_Reasoning_in_Low_Resource_Languages.html#appendix",
    "href": "posts/SynDARin_Synthesising_Datasets_for_Automated_Reasoning_in_Low_Resource_Languages/2024-06-20-SynDARin_Synthesising_Datasets_for_Automated_Reasoning_in_Low_Resource_Languages.html#appendix",
    "title": "SynDARin: Synthesising Datasets for Automated Reasoning in Low-Resource Languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14425v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14425v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3686"
  },
  {
    "objectID": "posts/The_Geometry_of_Queries_Query_Based_Innovations_in_Retrieval_Augmented_Generation/2024-07-25-The_Geometry_of_Queries_Query_Based_Innovations_in_Retrieval_Augmented_Generation.html#appendix",
    "href": "posts/The_Geometry_of_Queries_Query_Based_Innovations_in_Retrieval_Augmented_Generation/2024-07-25-The_Geometry_of_Queries_Query_Based_Innovations_in_Retrieval_Augmented_Generation.html#appendix",
    "title": "The Geometry of Queries: Query-Based Innovations in Retrieval-Augmented Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.18044v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.18044v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12034"
  },
  {
    "objectID": "posts/Affordances_Oriented_Planning_using_Foundation_Models_for_Continuous_Vision_Language_Navigation/2024-07-08-Affordances_Oriented_Planning_using_Foundation_Models_for_Continuous_Vision_Language_Navigation.html#appendix",
    "href": "posts/Affordances_Oriented_Planning_using_Foundation_Models_for_Continuous_Vision_Language_Navigation/2024-07-08-Affordances_Oriented_Planning_using_Foundation_Models_for_Continuous_Vision_Language_Navigation.html#appendix",
    "title": "Affordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05890v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05890v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7091"
  },
  {
    "objectID": "posts/Hecaton_Training_and_Finetuning_Large_Language_Models_with_Scalable_Chiplet_Systems/2024-07-08-Hecaton_Training_and_Finetuning_Large_Language_Models_with_Scalable_Chiplet_Systems.html#appendix",
    "href": "posts/Hecaton_Training_and_Finetuning_Large_Language_Models_with_Scalable_Chiplet_Systems/2024-07-08-Hecaton_Training_and_Finetuning_Large_Language_Models_with_Scalable_Chiplet_Systems.html#appendix",
    "title": "Hecaton: Training and Finetuning Large Language Models with Scalable Chiplet Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05784v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05784v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9383"
  },
  {
    "objectID": "posts/Improving_Robustness_of_LLM_based_Speech_Synthesis_by_Learning_Monotonic_Alignment/2024-06-25-Improving_Robustness_of_LLM_based_Speech_Synthesis_by_Learning_Monotonic_Alignment.html#appendix",
    "href": "posts/Improving_Robustness_of_LLM_based_Speech_Synthesis_by_Learning_Monotonic_Alignment/2024-06-25-Improving_Robustness_of_LLM_based_Speech_Synthesis_by_Learning_Monotonic_Alignment.html#appendix",
    "title": "Improving Robustness of LLM-based Speech Synthesis by Learning Monotonic Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17957v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17957v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4644"
  },
  {
    "objectID": "posts/Open_Generative_Large_Language_Models_for_Galician/2024-06-19-Open_Generative_Large_Language_Models_for_Galician.html#appendix",
    "href": "posts/Open_Generative_Large_Language_Models_for_Galician/2024-06-19-Open_Generative_Large_Language_Models_for_Galician.html#appendix",
    "title": "Open Generative Large Language Models for Galician",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13893v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13893v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6815"
  },
  {
    "objectID": "posts/LLM_economicus_Mapping_the_Behavioral_Biases_of_LLMs_via_Utility_Theory/2024-08-05-LLM_economicus_Mapping_the_Behavioral_Biases_of_LLMs_via_Utility_Theory.html#appendix",
    "href": "posts/LLM_economicus_Mapping_the_Behavioral_Biases_of_LLMs_via_Utility_Theory/2024-08-05-LLM_economicus_Mapping_the_Behavioral_Biases_of_LLMs_via_Utility_Theory.html#appendix",
    "title": "LLM economicus? Mapping the Behavioral Biases of LLMs via Utility Theory",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02784v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02784v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7474"
  },
  {
    "objectID": "posts/Sonnet_or_Not_Bot_Poetry_Evaluation_for_Large_Models_and_Datasets/2024-06-27-Sonnet_or_Not_Bot_Poetry_Evaluation_for_Large_Models_and_Datasets.html#appendix",
    "href": "posts/Sonnet_or_Not_Bot_Poetry_Evaluation_for_Large_Models_and_Datasets/2024-06-27-Sonnet_or_Not_Bot_Poetry_Evaluation_for_Large_Models_and_Datasets.html#appendix",
    "title": "Sonnet or Not, Bot? Poetry Evaluation for Large Models and Datasets",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18906v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18906v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3809"
  },
  {
    "objectID": "posts/SecureNet_A_Comparative_Study_of_DeBERTa_and_Large_Language_Models_for_Phishing_Detection/2024-06-10-SecureNet_A_Comparative_Study_of_DeBERTa_and_Large_Language_Models_for_Phishing_Detection.html#appendix",
    "href": "posts/SecureNet_A_Comparative_Study_of_DeBERTa_and_Large_Language_Models_for_Phishing_Detection/2024-06-10-SecureNet_A_Comparative_Study_of_DeBERTa_and_Large_Language_Models_for_Phishing_Detection.html#appendix",
    "title": "SecureNet: A Comparative Study of DeBERTa and Large Language Models for Phishing Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06663v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06663v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8220"
  },
  {
    "objectID": "posts/CleanGen_Mitigating_Backdoor_Attacks_for_Generation_Tasks_in_Large_Language_Models/2024-06-18-CleanGen_Mitigating_Backdoor_Attacks_for_Generation_Tasks_in_Large_Language_Models.html#appendix",
    "href": "posts/CleanGen_Mitigating_Backdoor_Attacks_for_Generation_Tasks_in_Large_Language_Models/2024-06-18-CleanGen_Mitigating_Backdoor_Attacks_for_Generation_Tasks_in_Large_Language_Models.html#appendix",
    "title": "CleanGen: Mitigating Backdoor Attacks for Generation Tasks in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12257v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12257v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7540"
  },
  {
    "objectID": "posts/Course_Correction_Safety_Alignment_Using_Synthetic_Preferences/2024-07-23-Course_Correction_Safety_Alignment_Using_Synthetic_Preferences.html#appendix",
    "href": "posts/Course_Correction_Safety_Alignment_Using_Synthetic_Preferences/2024-07-23-Course_Correction_Safety_Alignment_Using_Synthetic_Preferences.html#appendix",
    "title": "Course-Correction: Safety Alignment Using Synthetic Preferences",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16637v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16637v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11071"
  },
  {
    "objectID": "posts/Safe_Unlearning_A_Surprisingly_Effective_and_Generalizable_Solution_to_Defend_Against_Jailbreak_Attacks/2024-07-03-Safe_Unlearning_A_Surprisingly_Effective_and_Generalizable_Solution_to_Defend_Against_Jailbreak_Attacks.html",
    "href": "posts/Safe_Unlearning_A_Surprisingly_Effective_and_Generalizable_Solution_to_Defend_Against_Jailbreak_Attacks/2024-07-03-Safe_Unlearning_A_Surprisingly_Effective_and_Generalizable_Solution_to_Defend_Against_Jailbreak_Attacks.html",
    "title": "Safe Unlearning: A Surprisingly Effective and Generalizable Solution to Defend Against Jailbreak Attacks",
    "section": "",
    "text": "Summary:\nThe paper “Safe Unlearning: A Surprisingly Effective and Generalizable Solution to Defend Against Jailbreak Attacks” presents a novel approach to address the vulnerability of large language models (LLMs) to jailbreak attacks. The authors propose unlearning harmful knowledge in the LLM as a more effective way to defend against such attacks than mainstream supervised fine-tuning (SFT) approaches. The proposed method, called Safe Unlearning, involves training the LLM with a small set of raw harmful questions without incorporating any jailbreak prompts. The results show that Safe Unlearning significantly outperforms Llama2-7B-Chat, which is fine-tuned on a large number of safety alignment samples, in terms of Attack Success Rate (ASR) on out-of-distribution (OOD) harmful questions wrapped with various complex jailbreak prompts. The authors attribute the strong generalization ability of Safe Unlearning to the intrinsic relatedness among harmful responses across harmful questions.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an interesting and novel approach to addressing the vulnerability of LLMs to jailbreak attacks. The proposed method, Safe Unlearning, shows promising results in terms of reducing the ASR on OOD harmful questions wrapped with various complex jailbreak prompts. However, the paper does not provide a detailed comparison of Safe Unlearning with other unlearning-based approaches, which could have strengthened the argument for the proposed method. Additionally, the paper does not discuss the potential limitations or shortcomings of Safe Unlearning, such as the impact of unlearning on the overall performance of the LLM or the potential for overfitting to the small set of raw harmful questions used in training. Overall, the paper provides a valuable"
  },
  {
    "objectID": "posts/Safe_Unlearning_A_Surprisingly_Effective_and_Generalizable_Solution_to_Defend_Against_Jailbreak_Attacks/2024-07-03-Safe_Unlearning_A_Surprisingly_Effective_and_Generalizable_Solution_to_Defend_Against_Jailbreak_Attacks.html#appendix",
    "href": "posts/Safe_Unlearning_A_Surprisingly_Effective_and_Generalizable_Solution_to_Defend_Against_Jailbreak_Attacks/2024-07-03-Safe_Unlearning_A_Surprisingly_Effective_and_Generalizable_Solution_to_Defend_Against_Jailbreak_Attacks.html#appendix",
    "title": "Safe Unlearning: A Surprisingly Effective and Generalizable Solution to Defend Against Jailbreak Attacks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02855v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02855v1\n\n\nTruncated\nFalse\n\n\nWord Count\n16311"
  },
  {
    "objectID": "posts/Benchmark_Data_Contamination_of_Large_Language_Models_A_Survey/2024-06-06-Benchmark_Data_Contamination_of_Large_Language_Models_A_Survey.html#appendix",
    "href": "posts/Benchmark_Data_Contamination_of_Large_Language_Models_A_Survey/2024-06-06-Benchmark_Data_Contamination_of_Large_Language_Models_A_Survey.html#appendix",
    "title": "Benchmark Data Contamination of Large Language Models: A Survey",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04244v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04244v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13688"
  },
  {
    "objectID": "posts/LLMCloudHunter_Harnessing_LLMs_for_Automated_Extraction_of_Detection_Rules_from_Cloud_Based_CTI/2024-07-06-LLMCloudHunter_Harnessing_LLMs_for_Automated_Extraction_of_Detection_Rules_from_Cloud_Based_CTI.html#appendix",
    "href": "posts/LLMCloudHunter_Harnessing_LLMs_for_Automated_Extraction_of_Detection_Rules_from_Cloud_Based_CTI/2024-07-06-LLMCloudHunter_Harnessing_LLMs_for_Automated_Extraction_of_Detection_Rules_from_Cloud_Based_CTI.html#appendix",
    "title": "LLMCloudHunter: Harnessing LLMs for Automated Extraction of Detection Rules from Cloud-Based CTI",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05194v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05194v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11552"
  },
  {
    "objectID": "posts/Audio_Entailment_Assessing_Deductive_Reasoning_for_Audio_Understanding/2024-07-25-Audio_Entailment_Assessing_Deductive_Reasoning_for_Audio_Understanding.html#appendix",
    "href": "posts/Audio_Entailment_Assessing_Deductive_Reasoning_for_Audio_Understanding/2024-07-25-Audio_Entailment_Assessing_Deductive_Reasoning_for_Audio_Understanding.html#appendix",
    "title": "Audio Entailment: Assessing Deductive Reasoning for Audio Understanding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.18062v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.18062v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9853"
  },
  {
    "objectID": "posts/No_Such_Thing_as_a_General_Learner_Language_models_and_their_dual_optimization/2024-08-18-No_Such_Thing_as_a_General_Learner_Language_models_and_their_dual_optimization.html#major-findings",
    "href": "posts/No_Such_Thing_as_a_General_Learner_Language_models_and_their_dual_optimization/2024-08-18-No_Such_Thing_as_a_General_Learner_Language_models_and_their_dual_optimization.html#major-findings",
    "title": "No Such Thing as a General Learner: Language models and their dual optimization",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nLLMs are not unbiased or unconstrained learners, as there is no such thing as a general learner. Their power comes from their specialization, which allows them to make inductive leaps and go beyond their data via opinionated learning.\nModern LLMs are engineering devices optimized for specific tasks, and their evolution-like optimization has been accelerated by the human hand for specific goals. They are not vanilla, off-the-shelf learners and cannot be used to dismiss a nativist approach to language learning.\nLLMs cannot be considered general learners under any reasonable interpretation of the term. This reduces the impact that a comparison between humans and LLMs can have and how this can inform debates from linguistics and cognitive sciences."
  },
  {
    "objectID": "posts/No_Such_Thing_as_a_General_Learner_Language_models_and_their_dual_optimization/2024-08-18-No_Such_Thing_as_a_General_Learner_Language_models_and_their_dual_optimization.html#analysis-and-critique",
    "href": "posts/No_Such_Thing_as_a_General_Learner_Language_models_and_their_dual_optimization/2024-08-18-No_Such_Thing_as_a_General_Learner_Language_models_and_their_dual_optimization.html#analysis-and-critique",
    "title": "No Such Thing as a General Learner: Language models and their dual optimization",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe article provides a novel perspective on the role of LLMs in understanding human cognition and language acquisition. However, it raises several questions and potential limitations:\n\nThe authors argue that LLMs are not general learners, but they do not provide a clear definition of what a general learner is. This lack of clarity makes it difficult to evaluate their argument.\nThe authors claim that LLMs are optimized for specific tasks, but they do not provide empirical evidence to support this claim. It would be helpful to see some examples of how LLMs have been optimized for specific tasks and how this optimization has affected their performance.\nThe authors argue that LLMs cannot be used to dismiss a nativist approach to language learning, but they do not provide a clear explanation of why this is the case. It would be helpful to see a more detailed discussion of the relationship between LLMs and nativist theories of language acquisition"
  },
  {
    "objectID": "posts/No_Such_Thing_as_a_General_Learner_Language_models_and_their_dual_optimization/2024-08-18-No_Such_Thing_as_a_General_Learner_Language_models_and_their_dual_optimization.html#appendix",
    "href": "posts/No_Such_Thing_as_a_General_Learner_Language_models_and_their_dual_optimization/2024-08-18-No_Such_Thing_as_a_General_Learner_Language_models_and_their_dual_optimization.html#appendix",
    "title": "No Such Thing as a General Learner: Language models and their dual optimization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09544v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09544v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9197"
  },
  {
    "objectID": "posts/MedExQA_Medical_Question_Answering_Benchmark_with_Multiple_Explanations/2024-06-10-MedExQA_Medical_Question_Answering_Benchmark_with_Multiple_Explanations.html#appendix",
    "href": "posts/MedExQA_Medical_Question_Answering_Benchmark_with_Multiple_Explanations/2024-06-10-MedExQA_Medical_Question_Answering_Benchmark_with_Multiple_Explanations.html#appendix",
    "title": "MedExQA: Medical Question Answering Benchmark with Multiple Explanations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06331v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06331v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7134"
  },
  {
    "objectID": "posts/From_Descriptive_Richness_to_Bias_Unveiling_the_Dark_Side_of_Generative_Image_Caption_Enrichment/2024-06-20-From_Descriptive_Richness_to_Bias_Unveiling_the_Dark_Side_of_Generative_Image_Caption_Enrichment.html#appendix",
    "href": "posts/From_Descriptive_Richness_to_Bias_Unveiling_the_Dark_Side_of_Generative_Image_Caption_Enrichment/2024-06-20-From_Descriptive_Richness_to_Bias_Unveiling_the_Dark_Side_of_Generative_Image_Caption_Enrichment.html#appendix",
    "title": "From Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13912v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13912v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3715"
  },
  {
    "objectID": "posts/Using_LLMs_to_Aid_Annotation_and_Collection_of_Clinically_Enriched_Data_in_Bipolar_Disorder_and_Schizophrenia/2024-06-18-Using_LLMs_to_Aid_Annotation_and_Collection_of_Clinically_Enriched_Data_in_Bipolar_Disorder_and_Schizophrenia.html#appendix",
    "href": "posts/Using_LLMs_to_Aid_Annotation_and_Collection_of_Clinically_Enriched_Data_in_Bipolar_Disorder_and_Schizophrenia/2024-06-18-Using_LLMs_to_Aid_Annotation_and_Collection_of_Clinically_Enriched_Data_in_Bipolar_Disorder_and_Schizophrenia.html#appendix",
    "title": "Using LLMs to Aid Annotation and Collection of Clinically-Enriched Data in Bipolar Disorder and Schizophrenia",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12687v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12687v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5994"
  },
  {
    "objectID": "posts/Analyzing_Cultural_Representations_of_Emotions_in_LLMs_through_Mixed_Emotion_Survey/2024-08-04-Analyzing_Cultural_Representations_of_Emotions_in_LLMs_through_Mixed_Emotion_Survey.html#major-findings",
    "href": "posts/Analyzing_Cultural_Representations_of_Emotions_in_LLMs_through_Mixed_Emotion_Survey/2024-08-04-Analyzing_Cultural_Representations_of_Emotions_in_LLMs_through_Mixed_Emotion_Survey.html#major-findings",
    "title": "Analyzing Cultural Representations of Emotions in LLMs through Mixed Emotion Survey",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe study finds that models have limited alignment with the evidence in the literature, indicating that LLMs may not fully capture cultural nuances in their responses.\nThe written language has a greater effect on LLMs’ response than information on participants’ origin, suggesting that language plays a more significant role in shaping LLMs’ emotional responses.\nLLMs responses were found to be more similar for East Asian languages than Western European languages, which may reflect cultural differences in emotional expression."
  },
  {
    "objectID": "posts/Analyzing_Cultural_Representations_of_Emotions_in_LLMs_through_Mixed_Emotion_Survey/2024-08-04-Analyzing_Cultural_Representations_of_Emotions_in_LLMs_through_Mixed_Emotion_Survey.html#analysis-and-critique",
    "href": "posts/Analyzing_Cultural_Representations_of_Emotions_in_LLMs_through_Mixed_Emotion_Survey/2024-08-04-Analyzing_Cultural_Representations_of_Emotions_in_LLMs_through_Mixed_Emotion_Survey.html#analysis-and-critique",
    "title": "Analyzing Cultural Representations of Emotions in LLMs through Mixed Emotion Survey",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe study raises concerns about potential biases towards Anglo-centric cultures and values due to the predominance of Western and US-based training data in LLMs.\nThe limited alignment of LLMs with the investigated phenomenon suggests that further research is needed to improve the cultural sensitivity of LLMs.\nThe methodology used in this paper could inspire future studies on cultural representations in LLMs, but the limited scope of the study and the focus on a specific cultural context may limit its generalizability to other cultures.\nThe study’s reliance on existing peer-reviewed literature may limit its ability to explore less well-researched cultures, and the use of a specific survey to evaluate mixed emotions may introduce biases in the results.\nThe study’s focus on mixed emotions does not allow for broader conclusions about overall cultural representation, and further research is needed to evaluate LLMs’ cultural alignment in other emotional contexts.\nThe study’s findings suggest that LLMs may not fully capture cultural nuances in their responses, which could have implications for their use in communication tools and other applications that require cultural sensitivity.\nThe study highlights the need for further research to improve"
  },
  {
    "objectID": "posts/Analyzing_Cultural_Representations_of_Emotions_in_LLMs_through_Mixed_Emotion_Survey/2024-08-04-Analyzing_Cultural_Representations_of_Emotions_in_LLMs_through_Mixed_Emotion_Survey.html#appendix",
    "href": "posts/Analyzing_Cultural_Representations_of_Emotions_in_LLMs_through_Mixed_Emotion_Survey/2024-08-04-Analyzing_Cultural_Representations_of_Emotions_in_LLMs_through_Mixed_Emotion_Survey.html#appendix",
    "title": "Analyzing Cultural Representations of Emotions in LLMs through Mixed Emotion Survey",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02143v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02143v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6299"
  },
  {
    "objectID": "posts/Enhancing_Medication_Recommendation_with_LLM_Text_Representation/2024-07-15-Enhancing_Medication_Recommendation_with_LLM_Text_Representation.html",
    "href": "posts/Enhancing_Medication_Recommendation_with_LLM_Text_Representation/2024-07-15-Enhancing_Medication_Recommendation_with_LLM_Text_Representation.html",
    "title": "Enhancing Medication Recommendation with LLM Text Representation",
    "section": "",
    "text": "Summary:\nThe paper proposes a method to enhance medication recommendation by utilizing Large Language Models (LLMs) for text representation. The method aims to increase the utilization of unstructured or semi-structured data, such as clinical notes, which contain complex terminology. The proposed method can be applied to existing base models and improve medication recommendation performance with the combination representation of text and medical codes. The experiments conducted on two different datasets demonstrate that LLM text representation alone can even demonstrate a comparable ability to medical code representation alone.\nMajor Findings:\n**Analysis and Critique"
  },
  {
    "objectID": "posts/Enhancing_Medication_Recommendation_with_LLM_Text_Representation/2024-07-15-Enhancing_Medication_Recommendation_with_LLM_Text_Representation.html#appendix",
    "href": "posts/Enhancing_Medication_Recommendation_with_LLM_Text_Representation/2024-07-15-Enhancing_Medication_Recommendation_with_LLM_Text_Representation.html#appendix",
    "title": "Enhancing Medication Recommendation with LLM Text Representation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10453v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10453v1\n\n\nTruncated\nTrue\n\n\nWord Count\n31783"
  },
  {
    "objectID": "posts/Effective_Demonstration_Annotation_for_In_Context_Learning_via_Language_Model_Based_Determinantal_Point_Process/2024-08-04-Effective_Demonstration_Annotation_for_In_Context_Learning_via_Language_Model_Based_Determinantal_Point_Process.html#major-findings",
    "href": "posts/Effective_Demonstration_Annotation_for_In_Context_Learning_via_Language_Model_Based_Determinantal_Point_Process/2024-08-04-Effective_Demonstration_Annotation_for_In_Context_Learning_via_Language_Model_Based_Determinantal_Point_Process.html#major-findings",
    "title": "Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe proposed LM-DPP approach outperforms the previous best-performing selection methods by a large relative improvement and exhibits commendable generalizability across model size and annotation budget scaling.\nLLMs benefit most significantly from subsets that are both low uncertainty and high diversity.\nLM-DPP can effectively balance two critical factors, uncertainty and diversity, in selecting canonical examples for ICL."
  },
  {
    "objectID": "posts/Effective_Demonstration_Annotation_for_In_Context_Learning_via_Language_Model_Based_Determinantal_Point_Process/2024-08-04-Effective_Demonstration_Annotation_for_In_Context_Learning_via_Language_Model_Based_Determinantal_Point_Process.html#analysis-and-critique",
    "href": "posts/Effective_Demonstration_Annotation_for_In_Context_Learning_via_Language_Model_Based_Determinantal_Point_Process/2024-08-04-Effective_Demonstration_Annotation_for_In_Context_Learning_via_Language_Model_Based_Determinantal_Point_Process.html#analysis-and-critique",
    "title": "Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper does not provide a detailed comparison with other active learning methods, which could have helped to better understand the advantages and limitations of LM-DPP.\nThe paper does not discuss the potential impact of the proposed method on the fairness and bias of the selected demonstrations, which is an important consideration in ICL.\nThe paper does not provide a detailed analysis of the computational complexity of LM-DPP, which could have helped to better understand its scalability and efficiency.\nThe paper does not discuss the potential impact of the proposed method on the interpretability and explainability of the selected demonstrations, which is an important consideration in ICL.\nThe paper does not provide a detailed analysis of the impact of the proposed method on the generalization performance of ICL, which is an important consideration in practical applications.\n\nOverall, the paper presents a novel and effective approach for selecting instances for annotation in ICL. However, further research is needed to better understand the advantages and limitations of LM-DPP, as well as its impact on the fairness, bias, interpretability, explainability, and generalization performance of ICL."
  },
  {
    "objectID": "posts/Effective_Demonstration_Annotation_for_In_Context_Learning_via_Language_Model_Based_Determinantal_Point_Process/2024-08-04-Effective_Demonstration_Annotation_for_In_Context_Learning_via_Language_Model_Based_Determinantal_Point_Process.html#appendix",
    "href": "posts/Effective_Demonstration_Annotation_for_In_Context_Learning_via_Language_Model_Based_Determinantal_Point_Process/2024-08-04-Effective_Demonstration_Annotation_for_In_Context_Learning_via_Language_Model_Based_Determinantal_Point_Process.html#appendix",
    "title": "Effective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02103v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02103v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7505"
  },
  {
    "objectID": "posts/CovScore_Evaluation_of_Multi_Document_Abstractive_Title_Set_Generation/2024-07-24-CovScore_Evaluation_of_Multi_Document_Abstractive_Title_Set_Generation.html#major-findings",
    "href": "posts/CovScore_Evaluation_of_Multi_Document_Abstractive_Title_Set_Generation/2024-07-24-CovScore_Evaluation_of_Multi_Document_Abstractive_Title_Set_Generation.html#major-findings",
    "title": "CovScore: Evaluation of Multi-Document Abstractive Title Set Generation",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nCovScore Methodology: The authors present a novel methodology for reference-less evaluation of title sets, which can be deployed manually or automatically. The methodology reports separate scores for each aspect, alongside an aggregate score, addressing the drawbacks of using aggregate metrics.\nCase Study on Holocaust Survivor Testimonies: The authors conduct a case study on a dataset of Holocaust survivor testimonies, demonstrating the importance of studying these testimonies for Holocaust research and the unique test case they provide due to the recounted common yet unique experiences.\nEffectiveness of the Methodology: The authors demonstrate the effectiveness of their methodology by experimenting with both naturalistic and synthetic title set generation systems and comparing their performance by studying the intricate trade-offs existing between the different sets."
  },
  {
    "objectID": "posts/CovScore_Evaluation_of_Multi_Document_Abstractive_Title_Set_Generation/2024-07-24-CovScore_Evaluation_of_Multi_Document_Abstractive_Title_Set_Generation.html#analysis-and-critique",
    "href": "posts/CovScore_Evaluation_of_Multi_Document_Abstractive_Title_Set_Generation/2024-07-24-CovScore_Evaluation_of_Multi_Document_Abstractive_Title_Set_Generation.html#analysis-and-critique",
    "title": "CovScore: Evaluation of Multi-Document Abstractive Title Set Generation",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nLimited Dataset: The methodology is tested on a single type of dataset (Holocaust survivor testimonies), which may limit its generalizability to other types of datasets.\nSample Size: The annotation process is based on a small sample (10 documents) from each domain, which may not sufficiently cover the entirety of the domain and could bias the annotation process.\nSegmentation of Testimonies: The prior ontology labeling of the segments was done on segments of constant 1-minute length, which could cause unrelated information to be included in the segment and misplace small but crucial segments.\nUse of LLMs: The use of LLMs as judge models for measurement annotation may be limited by their black-box nature, high cost, and lack of replicability.\nEthical Considerations: The use of Holocaust testimonies"
  },
  {
    "objectID": "posts/CovScore_Evaluation_of_Multi_Document_Abstractive_Title_Set_Generation/2024-07-24-CovScore_Evaluation_of_Multi_Document_Abstractive_Title_Set_Generation.html#appendix",
    "href": "posts/CovScore_Evaluation_of_Multi_Document_Abstractive_Title_Set_Generation/2024-07-24-CovScore_Evaluation_of_Multi_Document_Abstractive_Title_Set_Generation.html#appendix",
    "title": "CovScore: Evaluation of Multi-Document Abstractive Title Set Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17390v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17390v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9655"
  },
  {
    "objectID": "posts/MergeRepair_An_Exploratory_Study_on_Merging_Task_Specific_Adapters_in_Code_LLMs_for_Automated_Program_Repair/2024-08-18-MergeRepair_An_Exploratory_Study_on_Merging_Task_Specific_Adapters_in_Code_LLMs_for_Automated_Program_Repair.html#appendix",
    "href": "posts/MergeRepair_An_Exploratory_Study_on_Merging_Task_Specific_Adapters_in_Code_LLMs_for_Automated_Program_Repair/2024-08-18-MergeRepair_An_Exploratory_Study_on_Merging_Task_Specific_Adapters_in_Code_LLMs_for_Automated_Program_Repair.html#appendix",
    "title": "MergeRepair: An Exploratory Study on Merging Task-Specific Adapters in Code LLMs for Automated Program Repair",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09568v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09568v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6640"
  },
  {
    "objectID": "posts/Jump_Starting_Bandits_with_LLM_Generated_Prior_Knowledge/2024-06-27-Jump_Starting_Bandits_with_LLM_Generated_Prior_Knowledge.html#appendix",
    "href": "posts/Jump_Starting_Bandits_with_LLM_Generated_Prior_Knowledge/2024-06-27-Jump_Starting_Bandits_with_LLM_Generated_Prior_Knowledge.html#appendix",
    "title": "Jump Starting Bandits with LLM-Generated Prior Knowledge",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19317v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19317v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8270"
  },
  {
    "objectID": "posts/LLMs_as_Probabilistic_Minimally_Adequate_Teachers_for_DFA_Learning/2024-08-06-LLMs_as_Probabilistic_Minimally_Adequate_Teachers_for_DFA_Learning.html#appendix",
    "href": "posts/LLMs_as_Probabilistic_Minimally_Adequate_Teachers_for_DFA_Learning/2024-08-06-LLMs_as_Probabilistic_Minimally_Adequate_Teachers_for_DFA_Learning.html#appendix",
    "title": "LLMs as Probabilistic Minimally Adequate Teachers for DFA Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02999v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02999v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5985"
  },
  {
    "objectID": "posts/Fine_tuning_Large_Language_Models_with_Human_inspired_Learning_Strategies_in_Medical_Question_Answering/2024-08-15-Fine_tuning_Large_Language_Models_with_Human_inspired_Learning_Strategies_in_Medical_Question_Answering.html",
    "href": "posts/Fine_tuning_Large_Language_Models_with_Human_inspired_Learning_Strategies_in_Medical_Question_Answering/2024-08-15-Fine_tuning_Large_Language_Models_with_Human_inspired_Learning_Strategies_in_Medical_Question_Answering.html",
    "title": "Fine-tuning Large Language Models with Human-inspired Learning Strategies in Medical Question Answering",
    "section": "",
    "text": "Summary: This study evaluates the effectiveness of human-inspired learning strategies, such as curriculum learning, for fine-tuning large language models (LLMs) in medical question answering. The research extends previous work by assessing both curriculum-based and non-curriculum-based learning strategies across multiple LLMs, using human-defined and automated data labels. The results indicate a moderate impact of using human-inspired learning strategies for fine-tuning LLMs, with maximum accuracy gains of 1.77% per model and 1.81% per dataset. Crucially, the effectiveness of these strategies varies significantly across different model-dataset combinations, emphasizing that the benefits of a specific human-inspired strategy for fine-tuning LLMs do not generalize. Additionally, evidence suggests that curriculum learning using LLM-defined question difficulty outperforms human-defined difficulty, highlighting the potential of using model-generated measures for optimal curriculum design.\nMajor Findings: 1. Human-inspired learning strategies have a moderate impact on fine-tuning LLMs, with maximum accuracy gains of 1.77% per model and 1.81% per dataset. 2. The effectiveness of human-inspired learning strategies varies significantly across different model-dataset combinations, emphasizing the need for caution in generalizing these strategies across diverse contexts. 3. Curriculum learning using LLM-defined question difficulty outperforms human-defined difficulty, highlighting the potential of using model-generated measures for optimal curriculum design.\nAnalysis and Critique: The study provides valuable insights into the effectiveness and variability of human-inspired learning strategies for optimizing the fine-tuning process of LLMs. However, several limitations should be considered. First, the five-time repetition used for each model-data combination may not provide reliable confidence intervals and statistical testing. Second, the LLM-defined difficulty measure and the results for clustered categories heavily depend on the choice of LLMs and their pre-training knowledge, as well as the choice of clustering algorithm and selected hyperparameters. Third, the relatively small size of the LEK dataset may not fully reveal the effects of learning strategies that only emerge with more training data.\nFuture research could explore a medical curriculum that encompasses a broader spectrum of questions, spanning from fundamental medical"
  },
  {
    "objectID": "posts/Fine_tuning_Large_Language_Models_with_Human_inspired_Learning_Strategies_in_Medical_Question_Answering/2024-08-15-Fine_tuning_Large_Language_Models_with_Human_inspired_Learning_Strategies_in_Medical_Question_Answering.html#appendix",
    "href": "posts/Fine_tuning_Large_Language_Models_with_Human_inspired_Learning_Strategies_in_Medical_Question_Answering/2024-08-15-Fine_tuning_Large_Language_Models_with_Human_inspired_Learning_Strategies_in_Medical_Question_Answering.html#appendix",
    "title": "Fine-tuning Large Language Models with Human-inspired Learning Strategies in Medical Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07888v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07888v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6594"
  },
  {
    "objectID": "posts/SSPA_Split_and_Synthesize_Prompting_with_Gated_Alignments_for_Multi_Label_Image_Recognition/2024-07-30-SSPA_Split_and_Synthesize_Prompting_with_Gated_Alignments_for_Multi_Label_Image_Recognition.html#appendix",
    "href": "posts/SSPA_Split_and_Synthesize_Prompting_with_Gated_Alignments_for_Multi_Label_Image_Recognition/2024-07-30-SSPA_Split_and_Synthesize_Prompting_with_Gated_Alignments_for_Multi_Label_Image_Recognition.html#appendix",
    "title": "SSPA: Split-and-Synthesize Prompting with Gated Alignments for Multi-Label Image Recognition",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20920v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20920v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9132"
  },
  {
    "objectID": "posts/Semantic_Structure_Mapping_in_LLM_and_Human_Analogical_Reasoning/2024-06-19-Semantic_Structure_Mapping_in_LLM_and_Human_Analogical_Reasoning.html#appendix",
    "href": "posts/Semantic_Structure_Mapping_in_LLM_and_Human_Analogical_Reasoning/2024-06-19-Semantic_Structure_Mapping_in_LLM_and_Human_Analogical_Reasoning.html#appendix",
    "title": "Semantic Structure-Mapping in LLM and Human Analogical Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13803v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13803v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12911"
  },
  {
    "objectID": "posts/Pelican_Correcting_Hallucination_in_Vision_LLMs_via_Claim_Decomposition_and_Program_of_Thought_Verification/2024-07-02-Pelican_Correcting_Hallucination_in_Vision_LLMs_via_Claim_Decomposition_and_Program_of_Thought_Verification.html#appendix",
    "href": "posts/Pelican_Correcting_Hallucination_in_Vision_LLMs_via_Claim_Decomposition_and_Program_of_Thought_Verification/2024-07-02-Pelican_Correcting_Hallucination_in_Vision_LLMs_via_Claim_Decomposition_and_Program_of_Thought_Verification.html#appendix",
    "title": "Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02352v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02352v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8633"
  },
  {
    "objectID": "posts/FRAP_Faithful_and_Realistic_Text_to_Image_Generation_with_Adaptive_Prompt_Weighting/2024-08-21-FRAP_Faithful_and_Realistic_Text_to_Image_Generation_with_Adaptive_Prompt_Weighting.html#appendix",
    "href": "posts/FRAP_Faithful_and_Realistic_Text_to_Image_Generation_with_Adaptive_Prompt_Weighting/2024-08-21-FRAP_Faithful_and_Realistic_Text_to_Image_Generation_with_Adaptive_Prompt_Weighting.html#appendix",
    "title": "FRAP: Faithful and Realistic Text-to-Image Generation with Adaptive Prompt Weighting",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11706v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11706v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11663"
  },
  {
    "objectID": "posts/Persuasiveness_of_Generated_Free_Text_Rationales_in_Subjective_Decisions_A_Case_Study_on_Pairwise_Argument_Ranking/2024-06-20-Persuasiveness_of_Generated_Free_Text_Rationales_in_Subjective_Decisions_A_Case_Study_on_Pairwise_Argument_Ranking.html#appendix",
    "href": "posts/Persuasiveness_of_Generated_Free_Text_Rationales_in_Subjective_Decisions_A_Case_Study_on_Pairwise_Argument_Ranking/2024-06-20-Persuasiveness_of_Generated_Free_Text_Rationales_in_Subjective_Decisions_A_Case_Study_on_Pairwise_Argument_Ranking.html#appendix",
    "title": "Persuasiveness of Generated Free-Text Rationales in Subjective Decisions: A Case Study on Pairwise Argument Ranking",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13905v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13905v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6514"
  },
  {
    "objectID": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#major-findings",
    "href": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#major-findings",
    "title": "SemCoder: Training Code Language Models with Comprehensive Semantics",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe paper introduces a novel strategy to train Code LLMs with comprehensive semantics, including high-level functional descriptions, local execution effects of individual statements, and overall input/output behavior.\nThe authors propose training Code LLMs to write code and represent and reason about execution behaviors using natural language, mimicking human verbal debugging.\nThe paper presents SEMCODER, a Code LLM with only 6.7B parameters, which shows competitive performance with GPT-3.5-turbo on code generation and execution reasoning tasks.\nSEMCODER achieves 81.1% on HumanEval (GPT-3.5-turbo: 76.8%) and 54.5% on CRUXEval-I (GPT-3.5-turbo: 50.3%).\nThe paper also studies the effectiveness of SEMCODER’s monologue-style execution reasoning compared to concrete scratchpad reasoning, showing that their approach integrates semantics from multiple dimensions more smoothly."
  },
  {
    "objectID": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#analysis-and-critique",
    "href": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#analysis-and-critique",
    "title": "SemCoder: Training Code Language Models with Comprehensive Semantics",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a novel approach to training Code LLMs with comprehensive semantics, which has the potential to improve the performance of Code LLMs on code generation and execution reasoning tasks. The authors’ proposal to train Code LLMs to write code and represent and reason about execution behaviors using natural language is an interesting and promising direction.\nHowever, the paper does not provide a detailed comparison of SEMCODER with other state-of-the-art Code LLMs, which makes it difficult to evaluate the effectiveness of their approach. Additionally, the"
  },
  {
    "objectID": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#appendix",
    "href": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#appendix",
    "title": "SemCoder: Training Code Language Models with Comprehensive Semantics",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01006v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01006v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18724"
  },
  {
    "objectID": "posts/LLM_Aided_Compilation_for_Tensor_Accelerators/2024-08-06-LLM_Aided_Compilation_for_Tensor_Accelerators.html#major-findings",
    "href": "posts/LLM_Aided_Compilation_for_Tensor_Accelerators/2024-08-06-LLM_Aided_Compilation_for_Tensor_Accelerators.html#major-findings",
    "title": "LLM-Aided Compilation for Tensor Accelerators",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nLLMs, such as GPT-4, can be leveraged to build a compiler for tensor accelerators, achieving high pass rates in translating code to the Gemmini accelerator.\nA 2-phase workflow is proposed for utilizing LLMs to generate hardware-optimized code, focusing on functional correctness and performance optimization.\nThe paper emphasizes the need for an agile compiler framework that can adapt to changes at both application and hardware levels, enabling more efficient development and design space exploration of accelerators."
  },
  {
    "objectID": "posts/LLM_Aided_Compilation_for_Tensor_Accelerators/2024-08-06-LLM_Aided_Compilation_for_Tensor_Accelerators.html#analysis-and-critique",
    "href": "posts/LLM_Aided_Compilation_for_Tensor_Accelerators/2024-08-06-LLM_Aided_Compilation_for_Tensor_Accelerators.html#analysis-and-critique",
    "title": "LLM-Aided Compilation for Tensor Accelerators",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper provides a promising approach to building a compiler for tensor accelerators using LLMs. However, it does not provide a comprehensive evaluation of the proposed methodology, leaving room for further research and validation.\nThe paper does not discuss the potential limitations of using LLMs for code translation and optimization, such as the need for large amounts of training data and the risk of overfitting.\nThe proposed 2-phase workflow for utilizing LLMs to generate hardware-optimized code is not thoroughly evaluated, and its effectiveness in optimizing code for different hardware targets remains to be seen.\nThe paper does not discuss the potential impact of using LLMs for code translation and optimization on the overall performance and energy efficiency of tensor accelerators.\nThe paper does not provide a detailed comparison of the proposed approach with existing methods for code translation and optimization, making it difficult to assess its advantages and disadvantages."
  },
  {
    "objectID": "posts/LLM_Aided_Compilation_for_Tensor_Accelerators/2024-08-06-LLM_Aided_Compilation_for_Tensor_Accelerators.html#appendix",
    "href": "posts/LLM_Aided_Compilation_for_Tensor_Accelerators/2024-08-06-LLM_Aided_Compilation_for_Tensor_Accelerators.html#appendix",
    "title": "LLM-Aided Compilation for Tensor Accelerators",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03408v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03408v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4281"
  },
  {
    "objectID": "posts/PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine_tuning/2024-07-02-PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine_tuning.html",
    "href": "posts/PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine_tuning/2024-07-02-PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine_tuning.html",
    "title": "PromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt during Large Language Model Fine-tuning",
    "section": "",
    "text": "Summary:\nThe paper introduces a novel method called PromptIntern for internalizing prompt knowledge into the parameters of large language models (LLMs) during fine-tuning. The approach aims to reduce inference costs by emulating the human learning process, where detailed templates and examples are gradually internalized and phased out as the model becomes accustomed to the task. PromptIntern consists of several key steps, including classifying input prompts into three components (template, examples, and query), setting a schedule to decrease both the template compression rate and the number of few-shot examples across training stages, and implementing template compression and example absorption to pre-process the input prompts.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine_tuning/2024-07-02-PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine_tuning.html#appendix",
    "href": "posts/PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine_tuning/2024-07-02-PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine_tuning.html#appendix",
    "title": "PromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt during Large Language Model Fine-tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02211v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02211v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7224"
  },
  {
    "objectID": "posts/Can_LLMs_Reason_in_Music_An_Evaluation_of_LLMs_Capability_of_Music_Understanding_and_Generation/2024-07-31-Can_LLMs_Reason_in_Music_An_Evaluation_of_LLMs_Capability_of_Music_Understanding_and_Generation.html#appendix",
    "href": "posts/Can_LLMs_Reason_in_Music_An_Evaluation_of_LLMs_Capability_of_Music_Understanding_and_Generation/2024-07-31-Can_LLMs_Reason_in_Music_An_Evaluation_of_LLMs_Capability_of_Music_Understanding_and_Generation.html#appendix",
    "title": "Can LLMs Reason in Music? An Evaluation of LLMs’ Capability of Music Understanding and Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21531v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21531v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4918"
  },
  {
    "objectID": "posts/RuleAlign_Making_Large_Language_Models_Better_Physicians_with_Diagnostic_Rule_Alignment/2024-08-22-RuleAlign_Making_Large_Language_Models_Better_Physicians_with_Diagnostic_Rule_Alignment.html#major-findings",
    "href": "posts/RuleAlign_Making_Large_Language_Models_Better_Physicians_with_Diagnostic_Rule_Alignment/2024-08-22-RuleAlign_Making_Large_Language_Models_Better_Physicians_with_Diagnostic_Rule_Alignment.html#major-findings",
    "title": "RuleAlign: Making Large Language Models Better Physicians with Diagnostic Rule Alignment",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe RuleAlign framework is designed to align LLMs with specific diagnostic rules, improving their ability to make professional diagnoses, gather patient information, and reason the final diagnosis.\nThe authors develop a medical dialogue dataset, RuleAlign, which includes rule-based communications between patients and physicians.\nThe authors use a preference learning approach to train the model, demonstrating the effectiveness of the proposed approach through experimental results."
  },
  {
    "objectID": "posts/RuleAlign_Making_Large_Language_Models_Better_Physicians_with_Diagnostic_Rule_Alignment/2024-08-22-RuleAlign_Making_Large_Language_Models_Better_Physicians_with_Diagnostic_Rule_Alignment.html#analysis-and-critique",
    "href": "posts/RuleAlign_Making_Large_Language_Models_Better_Physicians_with_Diagnostic_Rule_Alignment/2024-08-22-RuleAlign_Making_Large_Language_Models_Better_Physicians_with_Diagnostic_Rule_Alignment.html#analysis-and-critique",
    "title": "RuleAlign: Making Large Language Models Better Physicians with Diagnostic Rule Alignment",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents an innovative approach to improving the performance of LLMs in medical diagnosis. The RuleAlign framework and the medical dialogue dataset are well-designed and provide a promising direction for future research. However, the paper does not discuss the limitations or potential biases of the proposed approach. Additionally, the paper does not provide a detailed comparison with other existing methods, making it difficult to evaluate the proposed approach’s performance relative to other methods.\nThe paper also does not discuss the potential ethical implications of using LLMs for medical diagnosis. As LLMs become more prevalent in healthcare, it is essential to consider the ethical implications of their use, including issues related to patient privacy, informed consent, and the potential for bias in decision-making.\nOverall, the paper presents a promising approach to improving the performance of LLMs in medical diagnosis. However, further research is needed to evaluate the proposed approach’s performance relative to other methods and to address the potential ethical implications of using LLMs for medical diagnosis."
  },
  {
    "objectID": "posts/RuleAlign_Making_Large_Language_Models_Better_Physicians_with_Diagnostic_Rule_Alignment/2024-08-22-RuleAlign_Making_Large_Language_Models_Better_Physicians_with_Diagnostic_Rule_Alignment.html#appendix",
    "href": "posts/RuleAlign_Making_Large_Language_Models_Better_Physicians_with_Diagnostic_Rule_Alignment/2024-08-22-RuleAlign_Making_Large_Language_Models_Better_Physicians_with_Diagnostic_Rule_Alignment.html#appendix",
    "title": "RuleAlign: Making Large Language Models Better Physicians with Diagnostic Rule Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12579v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12579v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14333"
  },
  {
    "objectID": "posts/Language_specific_Calibration_for_Pruning_Multilingual_Language_Models/2024-08-26-Language_specific_Calibration_for_Pruning_Multilingual_Language_Models.html#appendix",
    "href": "posts/Language_specific_Calibration_for_Pruning_Multilingual_Language_Models/2024-08-26-Language_specific_Calibration_for_Pruning_Multilingual_Language_Models.html#appendix",
    "title": "Language-specific Calibration for Pruning Multilingual Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.14398v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.14398v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5621"
  },
  {
    "objectID": "posts/Attribute_or_Abstain_Large_Language_Models_as_Long_Document_Assistants/2024-07-10-Attribute_or_Abstain_Large_Language_Models_as_Long_Document_Assistants.html#appendix",
    "href": "posts/Attribute_or_Abstain_Large_Language_Models_as_Long_Document_Assistants/2024-07-10-Attribute_or_Abstain_Large_Language_Models_as_Long_Document_Assistants.html#appendix",
    "title": "Attribute or Abstain: Large Language Models as Long Document Assistants",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07799v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07799v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9325"
  },
  {
    "objectID": "posts/Application_of_Large_Language_Models_in_Automated_Question_Generation_A_Case_Study_on_ChatGLMs_Structured_Questions_for_National_Teacher_Certification_Exams/2024-08-19-Application_of_Large_Language_Models_in_Automated_Question_Generation_A_Case_Study_on_ChatGLMs_Structured_Questions_for_National_Teacher_Certification_Exams.html#appendix",
    "href": "posts/Application_of_Large_Language_Models_in_Automated_Question_Generation_A_Case_Study_on_ChatGLMs_Structured_Questions_for_National_Teacher_Certification_Exams/2024-08-19-Application_of_Large_Language_Models_in_Automated_Question_Generation_A_Case_Study_on_ChatGLMs_Structured_Questions_for_National_Teacher_Certification_Exams.html#appendix",
    "title": "Application of Large Language Models in Automated Question Generation: A Case Study on ChatGLM’s Structured Questions for National Teacher Certification Exams",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09982v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09982v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8304"
  },
  {
    "objectID": "posts/Foundational_Autoraters_Taming_Large_Language_Models_for_Better_Automatic_Evaluation/2024-07-15-Foundational_Autoraters_Taming_Large_Language_Models_for_Better_Automatic_Evaluation.html#appendix",
    "href": "posts/Foundational_Autoraters_Taming_Large_Language_Models_for_Better_Automatic_Evaluation/2024-07-15-Foundational_Autoraters_Taming_Large_Language_Models_for_Better_Automatic_Evaluation.html#appendix",
    "title": "Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10817v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10817v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11875"
  },
  {
    "objectID": "posts/Richelieu_Self_Evolving_LLM_Based_Agents_for_AI_Diplomacy/2024-07-09-Richelieu_Self_Evolving_LLM_Based_Agents_for_AI_Diplomacy.html",
    "href": "posts/Richelieu_Self_Evolving_LLM_Based_Agents_for_AI_Diplomacy/2024-07-09-Richelieu_Self_Evolving_LLM_Based_Agents_for_AI_Diplomacy.html",
    "title": "Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy",
    "section": "",
    "text": "Summary:\nThe paper introduces Richelieu, a self-evolving LLM-based agent for AI diplomacy. The model enables hierarchical planning for multi-agent tasks and utilizes a memory module for reflective optimization. The model does not require human data and can evolve through self-play, ultimately outperforming existing models like Cicero in the Diplomacy game. The ablation study demonstrates the effectiveness of the modules established. Experiments using different LLMs validate the generalization of the framework to various LLMs.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an innovative approach to AI diplomacy using a self-evolving LLM-based agent, Richelieu. The model’s ability to outperform existing models without requiring human data is a significant achievement. The use of a memory module for reflective optimization is a novel approach to improving the model’s performance. The ablation study provides evidence of the effectiveness of the modules established in the model. However, the paper does not discuss the limitations of the model or potential areas for improvement. Additionally, the generalization of the framework to various LLMs is validated through experiments, but the paper does not provide details on the specific LLMs used or the results of these experiments. Overall, the paper provides a promising approach to AI diplomacy, but further research is needed to address these limitations and provide a more comprehensive evaluation of the model’s performance."
  },
  {
    "objectID": "posts/Richelieu_Self_Evolving_LLM_Based_Agents_for_AI_Diplomacy/2024-07-09-Richelieu_Self_Evolving_LLM_Based_Agents_for_AI_Diplomacy.html#appendix",
    "href": "posts/Richelieu_Self_Evolving_LLM_Based_Agents_for_AI_Diplomacy/2024-07-09-Richelieu_Self_Evolving_LLM_Based_Agents_for_AI_Diplomacy.html#appendix",
    "title": "Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06813v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06813v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7379"
  },
  {
    "objectID": "posts/TCSR_SQL_Towards_Table_Content_aware_Text_to_SQL_with_Self_retrieval/2024-07-01-TCSR_SQL_Towards_Table_Content_aware_Text_to_SQL_with_Self_retrieval.html#appendix",
    "href": "posts/TCSR_SQL_Towards_Table_Content_aware_Text_to_SQL_with_Self_retrieval/2024-07-01-TCSR_SQL_Towards_Table_Content_aware_Text_to_SQL_with_Self_retrieval.html#appendix",
    "title": "TCSR-SQL: Towards Table Content-aware Text-to-SQL with Self-retrieval",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01183v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01183v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10323"
  },
  {
    "objectID": "posts/VidyaRANG_Conversational_Learning_Based_Platform_powered_by_Large_Language_Model/2024-07-23-VidyaRANG_Conversational_Learning_Based_Platform_powered_by_Large_Language_Model.html#appendix",
    "href": "posts/VidyaRANG_Conversational_Learning_Based_Platform_powered_by_Large_Language_Model/2024-07-23-VidyaRANG_Conversational_Learning_Based_Platform_powered_by_Large_Language_Model.html#appendix",
    "title": "VidyaRANG: Conversational Learning Based Platform powered by Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16209v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16209v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3698"
  },
  {
    "objectID": "posts/Enhancing_Hallucination_Detection_through_Perturbation_Based_Synthetic_Data_Generation_in_System_Responses/2024-07-07-Enhancing_Hallucination_Detection_through_Perturbation_Based_Synthetic_Data_Generation_in_System_Responses.html#appendix",
    "href": "posts/Enhancing_Hallucination_Detection_through_Perturbation_Based_Synthetic_Data_Generation_in_System_Responses/2024-07-07-Enhancing_Hallucination_Detection_through_Perturbation_Based_Synthetic_Data_Generation_in_System_Responses.html#appendix",
    "title": "Enhancing Hallucination Detection through Perturbation-Based Synthetic Data Generation in System Responses",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05474v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05474v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5380"
  },
  {
    "objectID": "posts/Artificial_Intuition_Efficient_Classification_of_Scientific_Abstracts/2024-07-08-Artificial_Intuition_Efficient_Classification_of_Scientific_Abstracts.html#appendix",
    "href": "posts/Artificial_Intuition_Efficient_Classification_of_Scientific_Abstracts/2024-07-08-Artificial_Intuition_Efficient_Classification_of_Scientific_Abstracts.html#appendix",
    "title": "Artificial Intuition: Efficient Classification of Scientific Abstracts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06093v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06093v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5527"
  },
  {
    "objectID": "posts/CLEANANERCorp_Identifying_and_Correcting_Incorrect_Labels_in_the_ANERcorp_Dataset/2024-08-22-CLEANANERCorp_Identifying_and_Correcting_Incorrect_Labels_in_the_ANERcorp_Dataset.html#appendix",
    "href": "posts/CLEANANERCorp_Identifying_and_Correcting_Incorrect_Labels_in_the_ANERcorp_Dataset/2024-08-22-CLEANANERCorp_Identifying_and_Correcting_Incorrect_Labels_in_the_ANERcorp_Dataset.html#appendix",
    "title": "CLEANANERCorp: Identifying and Correcting Incorrect Labels in the ANERcorp Dataset",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12362v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12362v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7156"
  },
  {
    "objectID": "posts/ARVO_Atlas_of_Reproducible_Vulnerabilities_for_Open_Source_Software/2024-08-04-ARVO_Atlas_of_Reproducible_Vulnerabilities_for_Open_Source_Software.html",
    "href": "posts/ARVO_Atlas_of_Reproducible_Vulnerabilities_for_Open_Source_Software/2024-08-04-ARVO_Atlas_of_Reproducible_Vulnerabilities_for_Open_Source_Software.html",
    "title": "ARVO: Atlas of Reproducible Vulnerabilities for Open Source Software",
    "section": "",
    "text": "Summary:\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/ARVO_Atlas_of_Reproducible_Vulnerabilities_for_Open_Source_Software/2024-08-04-ARVO_Atlas_of_Reproducible_Vulnerabilities_for_Open_Source_Software.html#appendix",
    "href": "posts/ARVO_Atlas_of_Reproducible_Vulnerabilities_for_Open_Source_Software/2024-08-04-ARVO_Atlas_of_Reproducible_Vulnerabilities_for_Open_Source_Software.html#appendix",
    "title": "ARVO: Atlas of Reproducible Vulnerabilities for Open Source Software",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02153v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02153v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13734"
  },
  {
    "objectID": "posts/The_doctor_will_polygraph_you_now_ethical_concerns_with_AI_for_fact_checking_patients/2024-08-15-The_doctor_will_polygraph_you_now_ethical_concerns_with_AI_for_fact_checking_patients.html#appendix",
    "href": "posts/The_doctor_will_polygraph_you_now_ethical_concerns_with_AI_for_fact_checking_patients/2024-08-15-The_doctor_will_polygraph_you_now_ethical_concerns_with_AI_for_fact_checking_patients.html#appendix",
    "title": "The doctor will polygraph you now: ethical concerns with AI for fact-checking patients",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07896v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07896v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6122"
  },
  {
    "objectID": "posts/Large_Language_Models_are_Interpretable_Learners/2024-06-25-Large_Language_Models_are_Interpretable_Learners.html#major-findings",
    "href": "posts/Large_Language_Models_are_Interpretable_Learners/2024-06-25-Large_Language_Models_are_Interpretable_Learners.html#major-findings",
    "title": "Large Language Models are Interpretable Learners",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nLSPs effectively bridge the gap between expressiveness and interpretability in machine learning models by leveraging pretrained LLMs and symbolic programs.\nThe proposed divide-and-conquer approach to incrementally build the program from scratch, guided by LLMs, demonstrates superior performance compared to traditional methods.\nThe knowledge learned by LSPs is easily transferable to humans, other LLMs, and generalizes well to out-of-distribution samples."
  },
  {
    "objectID": "posts/Large_Language_Models_are_Interpretable_Learners/2024-06-25-Large_Language_Models_are_Interpretable_Learners.html#analysis-and-critique",
    "href": "posts/Large_Language_Models_are_Interpretable_Learners/2024-06-25-Large_Language_Models_are_Interpretable_Learners.html#analysis-and-critique",
    "title": "Large Language Models are Interpretable Learners",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents an innovative approach to addressing the trade-off between expressiveness and interpretability in machine learning models. The use of pretrained LLMs and symbolic programs in LSPs offers a promising solution to this long-standing challenge.\nHowever, the paper does not discuss potential limitations or unanswered questions that may arise from the proposed method. For instance, the reliance on pretrained LLMs may introduce biases or limitations in the learned programs, as these models are trained on specific datasets and may not generalize well to all scenarios. Additionally, the paper does not address the computational cost of training LSPs, which may be a significant concern for large-scale applications.\nFur"
  },
  {
    "objectID": "posts/Large_Language_Models_are_Interpretable_Learners/2024-06-25-Large_Language_Models_are_Interpretable_Learners.html#appendix",
    "href": "posts/Large_Language_Models_are_Interpretable_Learners/2024-06-25-Large_Language_Models_are_Interpretable_Learners.html#appendix",
    "title": "Large Language Models are Interpretable Learners",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17224v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17224v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8763"
  },
  {
    "objectID": "posts/CXSimulator_A_User_Behavior_Simulation_using_LLM_Embeddings_for_Web_Marketing_Campaign_Assessment/2024-07-31-CXSimulator_A_User_Behavior_Simulation_using_LLM_Embeddings_for_Web_Marketing_Campaign_Assessment.html#appendix",
    "href": "posts/CXSimulator_A_User_Behavior_Simulation_using_LLM_Embeddings_for_Web_Marketing_Campaign_Assessment/2024-07-31-CXSimulator_A_User_Behavior_Simulation_using_LLM_Embeddings_for_Web_Marketing_Campaign_Assessment.html#appendix",
    "title": "CXSimulator: A User Behavior Simulation using LLM Embeddings for Web-Marketing Campaign Assessment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21553v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21553v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4524"
  },
  {
    "objectID": "posts/Benchmarks_and_Metrics_for_Evaluations_of_Code_Generation_A_Critical_Review/2024-06-18-Benchmarks_and_Metrics_for_Evaluations_of_Code_Generation_A_Critical_Review.html#appendix",
    "href": "posts/Benchmarks_and_Metrics_for_Evaluations_of_Code_Generation_A_Critical_Review/2024-06-18-Benchmarks_and_Metrics_for_Evaluations_of_Code_Generation_A_Critical_Review.html#appendix",
    "title": "Benchmarks and Metrics for Evaluations of Code Generation: A Critical Review",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12655v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12655v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5871"
  },
  {
    "objectID": "posts/Creating_Arabic_LLM_Prompts_at_Scale/2024-08-12-Creating_Arabic_LLM_Prompts_at_Scale.html#appendix",
    "href": "posts/Creating_Arabic_LLM_Prompts_at_Scale/2024-08-12-Creating_Arabic_LLM_Prompts_at_Scale.html#appendix",
    "title": "Creating Arabic LLM Prompts at Scale",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.05882v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.05882v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3273"
  },
  {
    "objectID": "posts/Navigating_User_Experience_of_ChatGPT_based_Conversational_Recommender_Systems_The_Effects_of_Prompt_Guidance_and_Recommendation_Domain/2024-05-22-Navigating_User_Experience_of_ChatGPT_based_Conversational_Recommender_Systems_The_Effects_of_Prompt_Guidance_and_Recommendation_Domain.html#appendix",
    "href": "posts/Navigating_User_Experience_of_ChatGPT_based_Conversational_Recommender_Systems_The_Effects_of_Prompt_Guidance_and_Recommendation_Domain/2024-05-22-Navigating_User_Experience_of_ChatGPT_based_Conversational_Recommender_Systems_The_Effects_of_Prompt_Guidance_and_Recommendation_Domain.html#appendix",
    "title": "Navigating User Experience of ChatGPT-based Conversational Recommender Systems: The Effects of Prompt Guidance and Recommendation Domain",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.13560v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.13560v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8278"
  },
  {
    "objectID": "posts/AMBROSIA_A_Benchmark_for_Parsing_Ambiguous_Questions_into_Database_Queries/2024-06-27-AMBROSIA_A_Benchmark_for_Parsing_Ambiguous_Questions_into_Database_Queries.html",
    "href": "posts/AMBROSIA_A_Benchmark_for_Parsing_Ambiguous_Questions_into_Database_Queries/2024-06-27-AMBROSIA_A_Benchmark_for_Parsing_Ambiguous_Questions_into_Database_Queries.html",
    "title": "AMBROSIA: A Benchmark for Parsing Ambiguous Questions into Database Queries",
    "section": "",
    "text": "Summary:\nThe paper introduces a new benchmark, “, for text-to-SQL parsers capable of recognizing and interpreting ambiguous requests. The dataset contains questions showcasing three different types of ambiguity (scope ambiguity, attachment ambiguity, and vagueness), their interpretations, and corresponding SQL queries. The dataset includes 846 multi-table databases, ambiguous questions, unambiguous interpretations, and complex SQL queries (4,242 in total). The authors aim to mimic real-world semantic parsing scenarios with realistic and diverse databases, creating them automatically in three steps: specifying a domain of interest, generating key concepts and relations, and generating SQL statements to construct tables with the desired structure. The paper also presents the results of benchmarking multiple advanced large language models on “, revealing that even the most advanced models struggle to identify and interpret ambiguity in questions.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel benchmark for text-to-SQL parsers capable of recognizing and interpreting ambiguous requests. The dataset is diverse and covers a wide range of SQL queries, making it a valuable resource for researchers in the field. However, the paper does not provide a detailed analysis of the performance of the benchmarked models, making it difficult to assess the effectiveness of the proposed approach. Additionally, the paper does not discuss potential limitations or biases in the dataset, which could impact the generaliz"
  },
  {
    "objectID": "posts/AMBROSIA_A_Benchmark_for_Parsing_Ambiguous_Questions_into_Database_Queries/2024-06-27-AMBROSIA_A_Benchmark_for_Parsing_Ambiguous_Questions_into_Database_Queries.html#appendix",
    "href": "posts/AMBROSIA_A_Benchmark_for_Parsing_Ambiguous_Questions_into_Database_Queries/2024-06-27-AMBROSIA_A_Benchmark_for_Parsing_Ambiguous_Questions_into_Database_Queries.html#appendix",
    "title": "AMBROSIA: A Benchmark for Parsing Ambiguous Questions into Database Queries",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19073v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19073v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20704"
  },
  {
    "objectID": "posts/FactFinders_at_CheckThat!_2024_Refining_Check_worthy_Statement_Detection_with_LLMs_through_Data_Pruning/2024-06-26-FactFinders_at_CheckThat!_2024_Refining_Check_worthy_Statement_Detection_with_LLMs_through_Data_Pruning.html#appendix",
    "href": "posts/FactFinders_at_CheckThat!_2024_Refining_Check_worthy_Statement_Detection_with_LLMs_through_Data_Pruning/2024-06-26-FactFinders_at_CheckThat!_2024_Refining_Check_worthy_Statement_Detection_with_LLMs_through_Data_Pruning.html#appendix",
    "title": "FactFinders at CheckThat! 2024: Refining Check-worthy Statement Detection with LLMs through Data Pruning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18297v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18297v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7119"
  },
  {
    "objectID": "posts/SoP_Unlock_the_Power_of_Social_Facilitation_for_Automatic_Jailbreak_Attack/2024-07-02-SoP_Unlock_the_Power_of_Social_Facilitation_for_Automatic_Jailbreak_Attack.html#appendix",
    "href": "posts/SoP_Unlock_the_Power_of_Social_Facilitation_for_Automatic_Jailbreak_Attack/2024-07-02-SoP_Unlock_the_Power_of_Social_Facilitation_for_Automatic_Jailbreak_Attack.html#appendix",
    "title": "SoP: Unlock the Power of Social Facilitation for Automatic Jailbreak Attack",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01902v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01902v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14863"
  },
  {
    "objectID": "posts/What_Affects_the_Stability_of_Tool_Learning_An_Empirical_Study_on_the_Robustness_of_Tool_Learning_Frameworks/2024-07-03-What_Affects_the_Stability_of_Tool_Learning_An_Empirical_Study_on_the_Robustness_of_Tool_Learning_Frameworks.html#appendix",
    "href": "posts/What_Affects_the_Stability_of_Tool_Learning_An_Empirical_Study_on_the_Robustness_of_Tool_Learning_Frameworks/2024-07-03-What_Affects_the_Stability_of_Tool_Learning_An_Empirical_Study_on_the_Robustness_of_Tool_Learning_Frameworks.html#appendix",
    "title": "What Affects the Stability of Tool Learning? An Empirical Study on the Robustness of Tool Learning Frameworks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03007v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03007v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2525"
  },
  {
    "objectID": "posts/Context_Conquers_Parameters_Outperforming_Proprietary_LLM_in_Commit_Message_Generation/2024-08-05-Context_Conquers_Parameters_Outperforming_Proprietary_LLM_in_Commit_Message_Generation.html#appendix",
    "href": "posts/Context_Conquers_Parameters_Outperforming_Proprietary_LLM_in_Commit_Message_Generation/2024-08-05-Context_Conquers_Parameters_Outperforming_Proprietary_LLM_in_Commit_Message_Generation.html#appendix",
    "title": "Context Conquers Parameters: Outperforming Proprietary LLM in Commit Message Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02502v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02502v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10845"
  },
  {
    "objectID": "posts/LLM_ARC_Enhancing_LLMs_with_an_Automated_Reasoning_Critic/2024-06-25-LLM_ARC_Enhancing_LLMs_with_an_Automated_Reasoning_Critic.html#appendix",
    "href": "posts/LLM_ARC_Enhancing_LLMs_with_an_Automated_Reasoning_Critic/2024-06-25-LLM_ARC_Enhancing_LLMs_with_an_Automated_Reasoning_Critic.html#appendix",
    "title": "LLM-ARC: Enhancing LLMs with an Automated Reasoning Critic",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17663v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17663v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9705"
  },
  {
    "objectID": "posts/Aligning_Teacher_with_Student_Preferences_for_Tailored_Training_Data_Generation/2024-06-27-Aligning_Teacher_with_Student_Preferences_for_Tailored_Training_Data_Generation.html#appendix",
    "href": "posts/Aligning_Teacher_with_Student_Preferences_for_Tailored_Training_Data_Generation/2024-06-27-Aligning_Teacher_with_Student_Preferences_for_Tailored_Training_Data_Generation.html#appendix",
    "title": "Aligning Teacher with Student Preferences for Tailored Training Data Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19227v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19227v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8697"
  },
  {
    "objectID": "posts/Harnessing_Multimodal_Large_Language_Models_for_Multimodal_Sequential_Recommendation/2024-08-19-Harnessing_Multimodal_Large_Language_Models_for_Multimodal_Sequential_Recommendation.html#major-findings",
    "href": "posts/Harnessing_Multimodal_Large_Language_Models_for_Multimodal_Sequential_Recommendation/2024-08-19-Harnessing_Multimodal_Large_Language_Models_for_Multimodal_Sequential_Recommendation.html#major-findings",
    "title": "Harnessing Multimodal Large Language Models for Multimodal Sequential Recommendation",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe MLLM-MSR model is the first attempt to fine-tune multimodal large models for sequential multimodal recommendation, achieving significant improvements in recommendation performance.\nThe paper introduces a novel image summarizing method based on MLLMs to recurrently summarize user preferences on multi-modality, facilitating a deeper understanding of user interactions and interests over time.\nThe proposed approach is extensively validated across various datasets, demonstrating its effectiveness in enhancing the accuracy and interpretability of recommendations."
  },
  {
    "objectID": "posts/Harnessing_Multimodal_Large_Language_Models_for_Multimodal_Sequential_Recommendation/2024-08-19-Harnessing_Multimodal_Large_Language_Models_for_Multimodal_Sequential_Recommendation.html#analysis-and-critique",
    "href": "posts/Harnessing_Multimodal_Large_Language_Models_for_Multimodal_Sequential_Recommendation/2024-08-19-Harnessing_Multimodal_Large_Language_Models_for_Multimodal_Sequential_Recommendation.html#analysis-and-critique",
    "title": "Harnessing Multimodal Large Language Models for Multimodal Sequential Recommendation",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper presents an innovative approach to integrating MLLMs into multimodal sequential recommendation systems, addressing the challenges of processing sequential multimodal data.\nThe proposed two-stage user preference summarization method effectively captures dynamic user preferences, improving the interpretability of recommendations.\nThe paper demonstrates the effectiveness of the MLLM-MSR model through extensive evaluations on various datasets, showcasing its superior ability to adapt to evolving user preferences.\nHowever, the paper does not discuss potential limitations or unanswered questions, such as the computational demands of processing sequential multimodal data or the generalizability of the fine-tuned MLLM-based recommender.\nFuture research could explore these aspects and investigate the applicability of the MLLM-MSR model in other recommendation domains."
  },
  {
    "objectID": "posts/Harnessing_Multimodal_Large_Language_Models_for_Multimodal_Sequential_Recommendation/2024-08-19-Harnessing_Multimodal_Large_Language_Models_for_Multimodal_Sequential_Recommendation.html#appendix",
    "href": "posts/Harnessing_Multimodal_Large_Language_Models_for_Multimodal_Sequential_Recommendation/2024-08-19-Harnessing_Multimodal_Large_Language_Models_for_Multimodal_Sequential_Recommendation.html#appendix",
    "title": "Harnessing Multimodal Large Language Models for Multimodal Sequential Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09698v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09698v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6167"
  },
  {
    "objectID": "posts/Multi_Stage_Balanced_Distillation_Addressing_Long_Tail_Challenges_in_Sequence_Level_Knowledge_Distillation/2024-06-19-Multi_Stage_Balanced_Distillation_Addressing_Long_Tail_Challenges_in_Sequence_Level_Knowledge_Distillation.html#appendix",
    "href": "posts/Multi_Stage_Balanced_Distillation_Addressing_Long_Tail_Challenges_in_Sequence_Level_Knowledge_Distillation/2024-06-19-Multi_Stage_Balanced_Distillation_Addressing_Long_Tail_Challenges_in_Sequence_Level_Knowledge_Distillation.html#appendix",
    "title": "Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13114v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13114v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7892"
  },
  {
    "objectID": "posts/ReCaLL_Membership_Inference_via_Relative_Conditional_Log_Likelihoods/2024-06-23-ReCaLL_Membership_Inference_via_Relative_Conditional_Log_Likelihoods.html#appendix",
    "href": "posts/ReCaLL_Membership_Inference_via_Relative_Conditional_Log_Likelihoods/2024-06-23-ReCaLL_Membership_Inference_via_Relative_Conditional_Log_Likelihoods.html#appendix",
    "title": "ReCaLL: Membership Inference via Relative Conditional Log-Likelihoods",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.15968v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.15968v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8640"
  },
  {
    "objectID": "posts/Enhancing_Agent_Learning_through_World_Dynamics_Modeling/2024-07-25-Enhancing_Agent_Learning_through_World_Dynamics_Modeling.html#appendix",
    "href": "posts/Enhancing_Agent_Learning_through_World_Dynamics_Modeling/2024-07-25-Enhancing_Agent_Learning_through_World_Dynamics_Modeling.html#appendix",
    "title": "Enhancing Agent Learning through World Dynamics Modeling",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17695v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17695v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6832"
  },
  {
    "objectID": "posts/Educating_LLMs_like_Human_Students_Structure_aware_Injection_of_Domain_Knowledge/2024-07-23-Educating_LLMs_like_Human_Students_Structure_aware_Injection_of_Domain_Knowledge.html#appendix",
    "href": "posts/Educating_LLMs_like_Human_Students_Structure_aware_Injection_of_Domain_Knowledge/2024-07-23-Educating_LLMs_like_Human_Students_Structure_aware_Injection_of_Domain_Knowledge.html#appendix",
    "title": "Educating LLMs like Human Students: Structure-aware Injection of Domain Knowledge",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16724v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16724v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7569"
  },
  {
    "objectID": "posts/Enhancing_Data_Privacy_in_Large_Language_Models_through_Private_Association_Editing/2024-06-26-Enhancing_Data_Privacy_in_Large_Language_Models_through_Private_Association_Editing.html",
    "href": "posts/Enhancing_Data_Privacy_in_Large_Language_Models_through_Private_Association_Editing/2024-06-26-Enhancing_Data_Privacy_in_Large_Language_Models_through_Private_Association_Editing.html",
    "title": "Enhancing Data Privacy in Large Language Models through Private Association Editing",
    "section": "",
    "text": "Summary:\nThe paper introduces Private Association Editing (PAE), a novel defense approach for private data leakage in Large Language Models (LLMs). PAE is designed to effectively remove Personally Identifiable Information (PII) without retraining the model. The approach consists of a four-step procedure: detecting memorized PII, applying PAE cards to mitigate memorization of private data, verifying resilience to targeted data extraction (TDE) attacks, and ensuring consistency in the post-edit LLMs. The versatility and efficiency of PAE, which allows for batch modifications, significantly enhance data privacy in LLMs. Experimental results demonstrate the effectiveness of PAE in mitigating private data leakage.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/Enhancing_Data_Privacy_in_Large_Language_Models_through_Private_Association_Editing/2024-06-26-Enhancing_Data_Privacy_in_Large_Language_Models_through_Private_Association_Editing.html#appendix",
    "href": "posts/Enhancing_Data_Privacy_in_Large_Language_Models_through_Private_Association_Editing/2024-06-26-Enhancing_Data_Privacy_in_Large_Language_Models_through_Private_Association_Editing.html#appendix",
    "title": "Enhancing Data Privacy in Large Language Models through Private Association Editing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18221v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18221v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7076"
  },
  {
    "objectID": "posts/Decomposed_Prompting_to_Answer_Questions_on_a_Course_Discussion_Board/2024-07-30-Decomposed_Prompting_to_Answer_Questions_on_a_Course_Discussion_Board.html#appendix",
    "href": "posts/Decomposed_Prompting_to_Answer_Questions_on_a_Course_Discussion_Board/2024-07-30-Decomposed_Prompting_to_Answer_Questions_on_a_Course_Discussion_Board.html#appendix",
    "title": "Decomposed Prompting to Answer Questions on a Course Discussion Board",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21170v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21170v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2329"
  },
  {
    "objectID": "posts/GenderAlign_An_Alignment_Dataset_for_Mitigating_Gender_Bias_in_Large_Language_Models/2024-06-20-GenderAlign_An_Alignment_Dataset_for_Mitigating_Gender_Bias_in_Large_Language_Models.html#appendix",
    "href": "posts/GenderAlign_An_Alignment_Dataset_for_Mitigating_Gender_Bias_in_Large_Language_Models/2024-06-20-GenderAlign_An_Alignment_Dataset_for_Mitigating_Gender_Bias_in_Large_Language_Models.html#appendix",
    "title": "GenderAlign: An Alignment Dataset for Mitigating Gender Bias in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13925v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13925v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6741"
  },
  {
    "objectID": "posts/VELO_A_Vector_Database_Assisted_Cloud_Edge_Collaborative_LLM_QoS_Optimization_Framework/2024-06-19-VELO_A_Vector_Database_Assisted_Cloud_Edge_Collaborative_LLM_QoS_Optimization_Framework.html#appendix",
    "href": "posts/VELO_A_Vector_Database_Assisted_Cloud_Edge_Collaborative_LLM_QoS_Optimization_Framework/2024-06-19-VELO_A_Vector_Database_Assisted_Cloud_Edge_Collaborative_LLM_QoS_Optimization_Framework.html#appendix",
    "title": "VELO: A Vector Database-Assisted Cloud-Edge Collaborative LLM QoS Optimization Framework",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13399v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13399v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7725"
  },
  {
    "objectID": "posts/Hierarchical_Context_Pruning_Optimizing_Real_World_Code_Completion_with_Repository_Level_Pretrained_Code_LLMs/2024-06-26-Hierarchical_Context_Pruning_Optimizing_Real_World_Code_Completion_with_Repository_Level_Pretrained_Code_LLMs.html#appendix",
    "href": "posts/Hierarchical_Context_Pruning_Optimizing_Real_World_Code_Completion_with_Repository_Level_Pretrained_Code_LLMs/2024-06-26-Hierarchical_Context_Pruning_Optimizing_Real_World_Code_Completion_with_Repository_Level_Pretrained_Code_LLMs.html#appendix",
    "title": "Hierarchical Context Pruning: Optimizing Real-World Code Completion with Repository-Level Pretrained Code LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18294v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18294v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6374"
  },
  {
    "objectID": "posts/Are_Social_Sentiments_Inherent_in_LLMs_An_Empirical_Study_on_Extraction_of_Inter_demographic_Sentiments/2024-08-08-Are_Social_Sentiments_Inherent_in_LLMs_An_Empirical_Study_on_Extraction_of_Inter_demographic_Sentiments.html#major-findings",
    "href": "posts/Are_Social_Sentiments_Inherent_in_LLMs_An_Empirical_Study_on_Extraction_of_Inter_demographic_Sentiments/2024-08-08-Are_Social_Sentiments_Inherent_in_LLMs_An_Empirical_Study_on_Extraction_of_Inter_demographic_Sentiments.html#major-findings",
    "title": "Are Social Sentiments Inherent in LLMs? An Empirical Study on Extraction of Inter-demographic Sentiments",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe study found that LLMs can capture and extract sentiments between social groups, particularly for nationalities and religions, which had relatively large data points.\nThe LLM responses, including inter-group sentiments, align well with actual social survey results, as shown by the higher correlations and relatively small p-values.\nThe study used five representative LLMs, including GPT-3.5 Turbo, GPT-4, Llama 2-Chat 13B, Llama 2-Chat 70B, and Vicuna 13B v1.5, to validate the findings."
  },
  {
    "objectID": "posts/Are_Social_Sentiments_Inherent_in_LLMs_An_Empirical_Study_on_Extraction_of_Inter_demographic_Sentiments/2024-08-08-Are_Social_Sentiments_Inherent_in_LLMs_An_Empirical_Study_on_Extraction_of_Inter_demographic_Sentiments.html#analysis-and-critique",
    "href": "posts/Are_Social_Sentiments_Inherent_in_LLMs_An_Empirical_Study_on_Extraction_of_Inter_demographic_Sentiments/2024-08-08-Are_Social_Sentiments_Inherent_in_LLMs_An_Empirical_Study_on_Extraction_of_Inter_demographic_Sentiments.html#analysis-and-critique",
    "title": "Are Social Sentiments Inherent in LLMs? An Empirical Study on Extraction of Inter-demographic Sentiments",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe study provides valuable insights into the ability of LLMs to capture and extract sentiments between social groups. However, there are some limitations and potential biases that should be considered:\n\nThe study only focused on three attributes (nationality, religion, and race/ethnicity) and was conducted in English. More languages and social groups should be considered to draw more general conclusions.\nThe study relied on sentiment analysis to extract sentiments from LLM responses. The accuracy and reliability of sentiment analysis tools may vary, which could impact the results.\nThe study did not address the potential biases that LLMs may have learned from the training data, which could influence the extracted sentiments.\nThe study did not explore the potential impact of different LLM architectures, training methods, or hyperparameters on the ability to capture and extract sentiments between social groups.\n\nOverall, the study provides a valuable contribution to the understanding of LLMs’ ability to capture and extract sentiments between social groups. However, further research is needed to address the limitations"
  },
  {
    "objectID": "posts/Are_Social_Sentiments_Inherent_in_LLMs_An_Empirical_Study_on_Extraction_of_Inter_demographic_Sentiments/2024-08-08-Are_Social_Sentiments_Inherent_in_LLMs_An_Empirical_Study_on_Extraction_of_Inter_demographic_Sentiments.html#appendix",
    "href": "posts/Are_Social_Sentiments_Inherent_in_LLMs_An_Empirical_Study_on_Extraction_of_Inter_demographic_Sentiments/2024-08-08-Are_Social_Sentiments_Inherent_in_LLMs_An_Empirical_Study_on_Extraction_of_Inter_demographic_Sentiments.html#appendix",
    "title": "Are Social Sentiments Inherent in LLMs? An Empirical Study on Extraction of Inter-demographic Sentiments",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04293v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04293v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3959"
  },
  {
    "objectID": "posts/IDEAL_Leveraging_Infinite_and_Dynamic_Characterizations_of_Large_Language_Models_for_Query_focused_Summarization/2024-07-15-IDEAL_Leveraging_Infinite_and_Dynamic_Characterizations_of_Large_Language_Models_for_Query_focused_Summarization.html#appendix",
    "href": "posts/IDEAL_Leveraging_Infinite_and_Dynamic_Characterizations_of_Large_Language_Models_for_Query_focused_Summarization/2024-07-15-IDEAL_Leveraging_Infinite_and_Dynamic_Characterizations_of_Large_Language_Models_for_Query_focused_Summarization.html#appendix",
    "title": "IDEAL: Leveraging Infinite and Dynamic Characterizations of Large Language Models for Query-focused Summarization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10486v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10486v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6156"
  },
  {
    "objectID": "posts/Perception_guided_Jailbreak_against_Text_to_Image_Models/2024-08-20-Perception_guided_Jailbreak_against_Text_to_Image_Models.html#appendix",
    "href": "posts/Perception_guided_Jailbreak_against_Text_to_Image_Models/2024-08-20-Perception_guided_Jailbreak_against_Text_to_Image_Models.html#appendix",
    "title": "Perception-guided Jailbreak against Text-to-Image Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10848v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10848v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5762"
  },
  {
    "objectID": "posts/Do_LLMs_Really_Adapt_to_Domains_An_Ontology_Learning_Perspective/2024-07-29-Do_LLMs_Really_Adapt_to_Domains_An_Ontology_Learning_Perspective.html#appendix",
    "href": "posts/Do_LLMs_Really_Adapt_to_Domains_An_Ontology_Learning_Perspective/2024-07-29-Do_LLMs_Really_Adapt_to_Domains_An_Ontology_Learning_Perspective.html#appendix",
    "title": "Do LLMs Really Adapt to Domains? An Ontology Learning Perspective",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19998v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19998v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7696"
  },
  {
    "objectID": "posts/Towards_Detecting_LLMs_Hallucination_via_Markov_Chain_based_Multi_agent_Debate_Framework/2024-06-05-Towards_Detecting_LLMs_Hallucination_via_Markov_Chain_based_Multi_agent_Debate_Framework.html#appendix",
    "href": "posts/Towards_Detecting_LLMs_Hallucination_via_Markov_Chain_based_Multi_agent_Debate_Framework/2024-06-05-Towards_Detecting_LLMs_Hallucination_via_Markov_Chain_based_Multi_agent_Debate_Framework.html#appendix",
    "title": "Towards Detecting LLMs Hallucination via Markov Chain-based Multi-agent Debate Framework",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03075v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03075v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5918"
  },
  {
    "objectID": "posts/Harnessing_the_Power_of_LLMs_in_Source_Code_Vulnerability_Detection/2024-08-07-Harnessing_the_Power_of_LLMs_in_Source_Code_Vulnerability_Detection.html#major-findings",
    "href": "posts/Harnessing_the_Power_of_LLMs_in_Source_Code_Vulnerability_Detection/2024-08-07-Harnessing_the_Power_of_LLMs_in_Source_Code_Vulnerability_Detection.html#major-findings",
    "title": "Harnessing the Power of LLMs in Source Code Vulnerability Detection",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nLLMs for Vulnerability Detection: The paper leverages LLMs to analyze source code and identify vulnerabilities, converting source code to LLVM IRs to ensure the proposed method is universal.\nHigh Accuracy: The proposed method achieves high accuracy in identifying source code vulnerabilities, as demonstrated by extensive experiments on real-world and synthetic codes from NVD and SARD.\nComparison with Existing Methods: The paper compares the proposed method with existing methods, such as VulDeeLocator and an LSTM-based method, and shows that the proposed method achieves comparable or superior accuracy."
  },
  {
    "objectID": "posts/Harnessing_the_Power_of_LLMs_in_Source_Code_Vulnerability_Detection/2024-08-07-Harnessing_the_Power_of_LLMs_in_Source_Code_Vulnerability_Detection.html#analysis-and-critique",
    "href": "posts/Harnessing_the_Power_of_LLMs_in_Source_Code_Vulnerability_Detection/2024-08-07-Harnessing_the_Power_of_LLMs_in_Source_Code_Vulnerability_Detection.html#analysis-and-critique",
    "title": "Harnessing the Power of LLMs in Source Code Vulnerability Detection",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper effectively leverages LLMs for source code vulnerability detection, addressing the limitations of existing methods.\nThe use of LLVM IRs for source code conversion ensures the proposed method is universal across multiple programming languages.\nThe paper demonstrates high accuracy in identifying source code vulnerabilities, but further research is needed to explore the generalizability of LLMs in detecting all types of vulnerabilities.\nThe paper does not discuss potential biases or limitations in the data used for training and evaluation, which could impact the generalizability of the proposed method.\nThe paper does not discuss the computational cost or scalability of the proposed method, which could be a significant factor in practical applications."
  },
  {
    "objectID": "posts/Harnessing_the_Power_of_LLMs_in_Source_Code_Vulnerability_Detection/2024-08-07-Harnessing_the_Power_of_LLMs_in_Source_Code_Vulnerability_Detection.html#appendix",
    "href": "posts/Harnessing_the_Power_of_LLMs_in_Source_Code_Vulnerability_Detection/2024-08-07-Harnessing_the_Power_of_LLMs_in_Source_Code_Vulnerability_Detection.html#appendix",
    "title": "Harnessing the Power of LLMs in Source Code Vulnerability Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03489v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03489v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3599"
  },
  {
    "objectID": "posts/Unboxing_Occupational_Bias_Grounded_Debiasing_LLMs_with_U.S._Labor_Data/2024-08-20-Unboxing_Occupational_Bias_Grounded_Debiasing_LLMs_with_U.S._Labor_Data.html#appendix",
    "href": "posts/Unboxing_Occupational_Bias_Grounded_Debiasing_LLMs_with_U.S._Labor_Data/2024-08-20-Unboxing_Occupational_Bias_Grounded_Debiasing_LLMs_with_U.S._Labor_Data.html#appendix",
    "title": "Unboxing Occupational Bias: Grounded Debiasing LLMs with U.S. Labor Data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11247v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11247v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5208"
  },
  {
    "objectID": "posts/Very_Large_Scale_Multi_Agent_Simulation_in_AgentScope/2024-07-25-Very_Large_Scale_Multi_Agent_Simulation_in_AgentScope.html#appendix",
    "href": "posts/Very_Large_Scale_Multi_Agent_Simulation_in_AgentScope/2024-07-25-Very_Large_Scale_Multi_Agent_Simulation_in_AgentScope.html#appendix",
    "title": "Very Large-Scale Multi-Agent Simulation in AgentScope",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17789v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17789v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12591"
  },
  {
    "objectID": "posts/A_Multi_Source_Heterogeneous_Knowledge_Injected_Prompt_Learning_Method_for_Legal_Charge_Prediction/2024-08-05-A_Multi_Source_Heterogeneous_Knowledge_Injected_Prompt_Learning_Method_for_Legal_Charge_Prediction.html",
    "href": "posts/A_Multi_Source_Heterogeneous_Knowledge_Injected_Prompt_Learning_Method_for_Legal_Charge_Prediction/2024-08-05-A_Multi_Source_Heterogeneous_Knowledge_Injected_Prompt_Learning_Method_for_Legal_Charge_Prediction.html",
    "title": "A Multi-Source Heterogeneous Knowledge Injected Prompt Learning Method for Legal Charge Prediction",
    "section": "",
    "text": "Summary:\nThe paper presents a prompt learning framework-based method for legal charge prediction that leverages multi-source heterogeneous external knowledge from a legal knowledge base, a conversational LLM, and related legal articles. The method matches knowledge snippets in case descriptions via the legal knowledge base and encapsulates them into the input through a hard prompt template. It also retrieves legal articles related to a given case description through contrastive learning and obtains factual elements within the case description through a conversational LLM. The method fuses the embedding vectors of soft prompt tokens with the encoding vector of factual elements to achieve knowledge-enhanced model forward inference. The proposed method achieved state-of-the-art results on CAIL-2018, the largest legal charge prediction dataset, and has lower data dependency.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel approach to legal charge prediction that leverages multi-source heterogeneous external knowledge. The method’s ability to achieve state-of-the-art results on the largest legal charge prediction dataset and its lower data dependency are significant contributions. However, the paper does not explore situations where a single case description may correspond to multiple legal charges, which could be a limitation. Additionally, the paper does not provide a detailed comparison with other methods that also use external knowledge, such as knowledge graphs or ontologies. The paper could also benefit from a more in-depth analysis of the interpretability of the method, as this is a crucial aspect in the legal domain."
  },
  {
    "objectID": "posts/A_Multi_Source_Heterogeneous_Knowledge_Injected_Prompt_Learning_Method_for_Legal_Charge_Prediction/2024-08-05-A_Multi_Source_Heterogeneous_Knowledge_Injected_Prompt_Learning_Method_for_Legal_Charge_Prediction.html#appendix",
    "href": "posts/A_Multi_Source_Heterogeneous_Knowledge_Injected_Prompt_Learning_Method_for_Legal_Charge_Prediction/2024-08-05-A_Multi_Source_Heterogeneous_Knowledge_Injected_Prompt_Learning_Method_for_Legal_Charge_Prediction.html#appendix",
    "title": "A Multi-Source Heterogeneous Knowledge Injected Prompt Learning Method for Legal Charge Prediction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02233v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02233v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15870"
  },
  {
    "objectID": "posts/Fire_Flyer_AI_HPC_A_Cost_Effective_Software_Hardware_Co_Design_for_Deep_Learning/2024-08-26-Fire_Flyer_AI_HPC_A_Cost_Effective_Software_Hardware_Co_Design_for_Deep_Learning.html",
    "href": "posts/Fire_Flyer_AI_HPC_A_Cost_Effective_Software_Hardware_Co_Design_for_Deep_Learning/2024-08-26-Fire_Flyer_AI_HPC_A_Cost_Effective_Software_Hardware_Co_Design_for_Deep_Learning.html",
    "title": "Fire-Flyer AI-HPC: A Cost-Effective Software-Hardware Co-Design for Deep Learning",
    "section": "",
    "text": "Summary:\nThe paper introduces the Fire-Flyer AI-HPC architecture, a cost-effective hardware-software co-design framework for deep learning and large language models (LLMs). The authors deployed a cluster of 10,000 PCIe A100 GPUs for deep learning training, achieving performance comparable to the DGX-A100 while reducing costs by half and energy consumption by 40%. The architecture features a Two-Layer Fat-Tree Network integrating storage and computation, HFReduce for computation-communication overlap, and various software optimizations to keep the Computation-Storage Integrated Network congestion-free. The system-oriented experience from deep learning training provides valuable insights for future advancements in AI-HPC.\nMajor Findings:\nAnalysis and Critique:\nThe Fire-Flyer AI-HPC architecture presents a promising approach to addressing the increasing demands of computational power and bandwidth in deep learning and LLMs. The authors’ focus on cost-effectiveness and energy efficiency is commendable, as these factors are crucial for the widespread adoption of AI-HPC systems.\nHowever, the paper could benefit from a more detailed discussion of the limitations and potential biases in the proposed architecture. For instance, the authors mention the need for software optimizations to address the performance challenges of the PCIe architecture, but they do not provide specific examples or discuss the potential trade-offs between performance and cost-effectiveness.\nAdditionally, the paper could benefit from a more comprehensive comparison with other existing AI-HPC architectures, highlighting the unique advantages and disadvantages of the Fire-Flyer AI-H"
  },
  {
    "objectID": "posts/Fire_Flyer_AI_HPC_A_Cost_Effective_Software_Hardware_Co_Design_for_Deep_Learning/2024-08-26-Fire_Flyer_AI_HPC_A_Cost_Effective_Software_Hardware_Co_Design_for_Deep_Learning.html#appendix",
    "href": "posts/Fire_Flyer_AI_HPC_A_Cost_Effective_Software_Hardware_Co_Design_for_Deep_Learning/2024-08-26-Fire_Flyer_AI_HPC_A_Cost_Effective_Software_Hardware_Co_Design_for_Deep_Learning.html#appendix",
    "title": "Fire-Flyer AI-HPC: A Cost-Effective Software-Hardware Co-Design for Deep Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.14158v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.14158v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11170"
  },
  {
    "objectID": "posts/Hypothetical_Minds_Scaffolding_Theory_of_Mind_for_Multi_Agent_Tasks_with_Large_Language_Models/2024-07-09-Hypothetical_Minds_Scaffolding_Theory_of_Mind_for_Multi_Agent_Tasks_with_Large_Language_Models.html",
    "href": "posts/Hypothetical_Minds_Scaffolding_Theory_of_Mind_for_Multi_Agent_Tasks_with_Large_Language_Models/2024-07-09-Hypothetical_Minds_Scaffolding_Theory_of_Mind_for_Multi_Agent_Tasks_with_Large_Language_Models.html",
    "title": "Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models",
    "section": "",
    "text": "Summary:\nThe paper introduces Hypothetical Minds, an autonomous agent that leverages large language models (LLMs) to handle the challenges of multi-agent reinforcement learning (MARL). The agent features a cognitively-inspired architecture with modular components for perception, memory, and hierarchical planning over two levels of abstraction. The Theory of Mind module is a key component that scaffolds the high-level planning process by generating hypotheses about other agents’ strategies in natural language, evaluating, and iteratively refining these hypotheses based on their predictive accuracy. The paper demonstrates that Hypothetical Minds significantly improves performance over previous LLM-agent and RL baselines on a range of competitive, mixed motive, and collaborative domains in the Melting Pot benchmark.\nMajor Findings:"
  },
  {
    "objectID": "posts/Hypothetical_Minds_Scaffolding_Theory_of_Mind_for_Multi_Agent_Tasks_with_Large_Language_Models/2024-07-09-Hypothetical_Minds_Scaffolding_Theory_of_Mind_for_Multi_Agent_Tasks_with_Large_Language_Models.html#appendix",
    "href": "posts/Hypothetical_Minds_Scaffolding_Theory_of_Mind_for_Multi_Agent_Tasks_with_Large_Language_Models/2024-07-09-Hypothetical_Minds_Scaffolding_Theory_of_Mind_for_Multi_Agent_Tasks_with_Large_Language_Models.html#appendix",
    "title": "Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07086v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07086v1\n\n\nTruncated\nTrue\n\n\nWord Count\n27806"
  },
  {
    "objectID": "posts/The_Remarkable_Robustness_of_LLMs_Stages_of_Inference/2024-06-27-The_Remarkable_Robustness_of_LLMs_Stages_of_Inference.html#appendix",
    "href": "posts/The_Remarkable_Robustness_of_LLMs_Stages_of_Inference/2024-06-27-The_Remarkable_Robustness_of_LLMs_Stages_of_Inference.html#appendix",
    "title": "The Remarkable Robustness of LLMs: Stages of Inference?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19384v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19384v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8310"
  },
  {
    "objectID": "posts/Machine_Unlearning_Fails_to_Remove_Data_Poisoning_Attacks/2024-06-25-Machine_Unlearning_Fails_to_Remove_Data_Poisoning_Attacks.html#appendix",
    "href": "posts/Machine_Unlearning_Fails_to_Remove_Data_Poisoning_Attacks/2024-06-25-Machine_Unlearning_Fails_to_Remove_Data_Poisoning_Attacks.html#appendix",
    "title": "Machine Unlearning Fails to Remove Data Poisoning Attacks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17216v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17216v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15361"
  },
  {
    "objectID": "posts/Development_of_a_Multi_Agent_Clinical_Decision_Support_System_for_Korean_Triage_and_Acuity_Scale_(KTAS)_Based_Triage_and_Treatment_Planning_in_Emergency_Departments/2024-08-14-Development_of_a_Multi_Agent_Clinical_Decision_Support_System_for_Korean_Triage_and_Acuity_Scale_(KTAS)_Based_Triage_and_Treatment_Planning_in_Emergency_Departments.html#appendix",
    "href": "posts/Development_of_a_Multi_Agent_Clinical_Decision_Support_System_for_Korean_Triage_and_Acuity_Scale_(KTAS)_Based_Triage_and_Treatment_Planning_in_Emergency_Departments/2024-08-14-Development_of_a_Multi_Agent_Clinical_Decision_Support_System_for_Korean_Triage_and_Acuity_Scale_(KTAS)_Based_Triage_and_Treatment_Planning_in_Emergency_Departments.html#appendix",
    "title": "Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07531v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07531v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13163"
  },
  {
    "objectID": "posts/Can_ChatGPT_Pass_a_Theory_of_Computing_Course/2024-07-10-Can_ChatGPT_Pass_a_Theory_of_Computing_Course.html#appendix",
    "href": "posts/Can_ChatGPT_Pass_a_Theory_of_Computing_Course/2024-07-10-Can_ChatGPT_Pass_a_Theory_of_Computing_Course.html#appendix",
    "title": "Can ChatGPT Pass a Theory of Computing Course?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07757v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07757v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6148"
  },
  {
    "objectID": "posts/Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer/2024-06-09-Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer.html",
    "href": "posts/Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer/2024-06-09-Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer.html",
    "title": "Are Large Language Models Actually Good at Text Style Transfer?",
    "section": "",
    "text": "Summary:\nThis paper evaluates the performance of large language models (LLMs) on Text Style Transfer (TST), specifically focusing on sentiment transfer and text detoxification across three languages: English, Hindi, and Bengali. The study analyzes the capabilities of pre-trained LLMs using zero-shot and few-shot prompting as well as parameter-efficient finetuning on publicly available datasets. The evaluation is conducted using automatic metrics, GPT-4, and human evaluations, revealing that while some prompted LLMs perform well in English, their performance in other languages remains average. However, finetuning significantly improves results compared to zero-shot and few-shot prompting, making them comparable to previous state-of-the-art.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer/2024-06-09-Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer.html#appendix",
    "href": "posts/Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer/2024-06-09-Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer.html#appendix",
    "title": "Are Large Language Models Actually Good at Text Style Transfer?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05885v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05885v1\n\n\nTruncated\nFalse\n\n\nWord Count\n27021"
  },
  {
    "objectID": "posts/Finding_Blind_Spots_in_Evaluator_LLMs_with_Interpretable_Checklists/2024-06-19-Finding_Blind_Spots_in_Evaluator_LLMs_with_Interpretable_Checklists.html#appendix",
    "href": "posts/Finding_Blind_Spots_in_Evaluator_LLMs_with_Interpretable_Checklists/2024-06-19-Finding_Blind_Spots_in_Evaluator_LLMs_with_Interpretable_Checklists.html#appendix",
    "title": "Finding Blind Spots in Evaluator LLMs with Interpretable Checklists",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13439v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13439v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7140"
  },
  {
    "objectID": "posts/eyeballvul_a_future_proof_benchmark_for_vulnerability_detection_in_the_wild/2024-07-11-eyeballvul_a_future_proof_benchmark_for_vulnerability_detection_in_the_wild.html#appendix",
    "href": "posts/eyeballvul_a_future_proof_benchmark_for_vulnerability_detection_in_the_wild/2024-07-11-eyeballvul_a_future_proof_benchmark_for_vulnerability_detection_in_the_wild.html#appendix",
    "title": "eyeballvul: a future-proof benchmark for vulnerability detection in the wild",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08708v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08708v1\n\n\nTruncated\nFalse\n\n\nWord Count\n45"
  },
  {
    "objectID": "posts/Disce_aut_Deficere_Evaluating_LLMs_Proficiency_on_the_INVALSI_Italian_Benchmark/2024-06-25-Disce_aut_Deficere_Evaluating_LLMs_Proficiency_on_the_INVALSI_Italian_Benchmark.html#appendix",
    "href": "posts/Disce_aut_Deficere_Evaluating_LLMs_Proficiency_on_the_INVALSI_Italian_Benchmark/2024-06-25-Disce_aut_Deficere_Evaluating_LLMs_Proficiency_on_the_INVALSI_Italian_Benchmark.html#appendix",
    "title": "Disce aut Deficere: Evaluating LLMs Proficiency on the INVALSI Italian Benchmark",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17535v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17535v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8268"
  },
  {
    "objectID": "posts/A_Voter_Based_Stochastic_Rejection_Method_Framework_for_Asymptotically_Safe_Language_Model_Outputs/2024-07-24-A_Voter_Based_Stochastic_Rejection_Method_Framework_for_Asymptotically_Safe_Language_Model_Outputs.html#appendix",
    "href": "posts/A_Voter_Based_Stochastic_Rejection_Method_Framework_for_Asymptotically_Safe_Language_Model_Outputs/2024-07-24-A_Voter_Based_Stochastic_Rejection_Method_Framework_for_Asymptotically_Safe_Language_Model_Outputs.html#appendix",
    "title": "A Voter-Based Stochastic Rejection-Method Framework for Asymptotically Safe Language Model Outputs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16994v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16994v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5147"
  },
  {
    "objectID": "posts/CityBench_Evaluating_the_Capabilities_of_Large_Language_Model_as_World_Model/2024-06-20-CityBench_Evaluating_the_Capabilities_of_Large_Language_Model_as_World_Model.html#appendix",
    "href": "posts/CityBench_Evaluating_the_Capabilities_of_Large_Language_Model_as_World_Model/2024-06-20-CityBench_Evaluating_the_Capabilities_of_Large_Language_Model_as_World_Model.html#appendix",
    "title": "CityBench: Evaluating the Capabilities of Large Language Model as World Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13945v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13945v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5783"
  },
  {
    "objectID": "posts/LLaVA_Surg_Towards_Multimodal_Surgical_Assistant_via_Structured_Surgical_Video_Learning/2024-08-15-LLaVA_Surg_Towards_Multimodal_Surgical_Assistant_via_Structured_Surgical_Video_Learning.html#appendix",
    "href": "posts/LLaVA_Surg_Towards_Multimodal_Surgical_Assistant_via_Structured_Surgical_Video_Learning/2024-08-15-LLaVA_Surg_Towards_Multimodal_Surgical_Assistant_via_Structured_Surgical_Video_Learning.html#appendix",
    "title": "LLaVA-Surg: Towards Multimodal Surgical Assistant via Structured Surgical Video Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07981v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07981v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5596"
  },
  {
    "objectID": "posts/MLR_Copilot_Autonomous_Machine_Learning_Research_based_on_Large_Language_Models_Agents/2024-08-26-MLR_Copilot_Autonomous_Machine_Learning_Research_based_on_Large_Language_Models_Agents.html#appendix",
    "href": "posts/MLR_Copilot_Autonomous_Machine_Learning_Research_based_on_Large_Language_Models_Agents/2024-08-26-MLR_Copilot_Autonomous_Machine_Learning_Research_based_on_Large_Language_Models_Agents.html#appendix",
    "title": "MLR-Copilot: Autonomous Machine Learning Research based on Large Language Models Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.14033v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.14033v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3929"
  },
  {
    "objectID": "posts/Prompt_Consistency_Image_Generation_(PCIG)_A_Unified_Framework_Integrating_LLMs_Knowledge_Graphs_and_Controllable_Diffusion_Models/2024-06-24-Prompt_Consistency_Image_Generation_(PCIG)_A_Unified_Framework_Integrating_LLMs_Knowledge_Graphs_and_Controllable_Diffusion_Models.html",
    "href": "posts/Prompt_Consistency_Image_Generation_(PCIG)_A_Unified_Framework_Integrating_LLMs_Knowledge_Graphs_and_Controllable_Diffusion_Models/2024-06-24-Prompt_Consistency_Image_Generation_(PCIG)_A_Unified_Framework_Integrating_LLMs_Knowledge_Graphs_and_Controllable_Diffusion_Models.html",
    "title": "Prompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models",
    "section": "",
    "text": "Summary:\nThe paper introduces a novel diffusion-based framework called Prompt-Consistency Image Generation (PCIG) to address the inconsistency between visual output and textual input in Text-to-Image (T2I) generative models. The framework leverages a state-of-the-art large language module to extract objects and construct a knowledge graph to predict the locations of these objects in potentially generated images. It then integrates a controllable image generation model with a visual text generation module to generate an image that is consistent with the original prompt, guided by the predicted object locations.\nMajor Findings:\nAnalysis and Critique:\nWhile PCIG shows promising results in generating images that align with the original prompt, there are some potential limitations and areas for improvement. For instance, the use of GPT4-turbo as the LLM for prompt analysis may introduce additional costs. Additionally, the framework may struggle with generating images with complex relationships and interactions between objects or with small text. Future work could explore the use of more powerful basic diffusion models to address these challenges."
  },
  {
    "objectID": "posts/Prompt_Consistency_Image_Generation_(PCIG)_A_Unified_Framework_Integrating_LLMs_Knowledge_Graphs_and_Controllable_Diffusion_Models/2024-06-24-Prompt_Consistency_Image_Generation_(PCIG)_A_Unified_Framework_Integrating_LLMs_Knowledge_Graphs_and_Controllable_Diffusion_Models.html#appendix",
    "href": "posts/Prompt_Consistency_Image_Generation_(PCIG)_A_Unified_Framework_Integrating_LLMs_Knowledge_Graphs_and_Controllable_Diffusion_Models/2024-06-24-Prompt_Consistency_Image_Generation_(PCIG)_A_Unified_Framework_Integrating_LLMs_Knowledge_Graphs_and_Controllable_Diffusion_Models.html#appendix",
    "title": "Prompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16333v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16333v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5668"
  },
  {
    "objectID": "posts/Can_Large_Language_Models_Understand_Symbolic_Graphics_Programs/2024-08-15-Can_Large_Language_Models_Understand_Symbolic_Graphics_Programs.html",
    "href": "posts/Can_Large_Language_Models_Understand_Symbolic_Graphics_Programs/2024-08-15-Can_Large_Language_Models_Understand_Symbolic_Graphics_Programs.html",
    "title": "Can Large Language Models Understand Symbolic Graphics Programs?",
    "section": "",
    "text": "Summary:\nThis paper explores the ability of large language models (LLMs) to understand symbolic graphics programs, which are a popular representation for generating visual data. The authors propose a new task of symbolic graphics program understanding and introduce a generic yet scalable benchmark creation pipeline for this task. They build a large benchmark, SGP-Bench, for comprehensively evaluating LLM’s semantic understanding and consistency of symbolic graphics programs. The benchmark includes two types of symbolic graphics programs: SVG for 2D vector graphics and CAD for 2D/3D objects. To improve the symbolic program understanding, the authors collect an instruction-following dataset and propose a new finetuning method, called symbolic instruction tuning. They also introduce a symbolic MNIST dataset, where the symbolic problem understanding can be extremely challenging, and show that symbolic instruction tuning can also improve generic instruction following performance.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an interesting and novel task of symbolic graphics program understanding and introduces a large benchmark, SGP-Bench, for evaluating LLMs on this task. The authors also propose a new finetuning method, symbolic instruction tuning, to improve the symbolic program understanding. However, the paper does not provide a detailed analysis of the limitations and potential biases of the proposed benchmark and finetuning method. Additionally, the paper does not discuss the potential applications and implications of the proposed task and benchmark. It would be interesting to see how the proposed task and benchmark can be used to improve the performance of LLMs on other tasks, such as visual"
  },
  {
    "objectID": "posts/Can_Large_Language_Models_Understand_Symbolic_Graphics_Programs/2024-08-15-Can_Large_Language_Models_Understand_Symbolic_Graphics_Programs.html#appendix",
    "href": "posts/Can_Large_Language_Models_Understand_Symbolic_Graphics_Programs/2024-08-15-Can_Large_Language_Models_Understand_Symbolic_Graphics_Programs.html#appendix",
    "title": "Can Large Language Models Understand Symbolic Graphics Programs?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.08313v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.08313v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13856"
  },
  {
    "objectID": "posts/Multilingual_Blending_LLM_Safety_Alignment_Evaluation_with_Language_Mixture/2024-07-10-Multilingual_Blending_LLM_Safety_Alignment_Evaluation_with_Language_Mixture.html#appendix",
    "href": "posts/Multilingual_Blending_LLM_Safety_Alignment_Evaluation_with_Language_Mixture/2024-07-10-Multilingual_Blending_LLM_Safety_Alignment_Evaluation_with_Language_Mixture.html#appendix",
    "title": "Multilingual Blending: LLM Safety Alignment Evaluation with Language Mixture",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07342v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07342v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10780"
  },
  {
    "objectID": "posts/Towards_Next_Era_of_Multi_objective_Optimization_Large_Language_Models_as_Architects_of_Evolutionary_Operators/2024-06-13-Towards_Next_Era_of_Multi_objective_Optimization_Large_Language_Models_as_Architects_of_Evolutionary_Operators.html#appendix",
    "href": "posts/Towards_Next_Era_of_Multi_objective_Optimization_Large_Language_Models_as_Architects_of_Evolutionary_Operators/2024-06-13-Towards_Next_Era_of_Multi_objective_Optimization_Large_Language_Models_as_Architects_of_Evolutionary_Operators.html#appendix",
    "title": "Towards Next Era of Multi-objective Optimization: Large Language Models as Architects of Evolutionary Operators",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.08987v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.08987v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8531"
  },
  {
    "objectID": "posts/Patched_RTC_evaluating_LLMs_for_diverse_software_development_tasks/2024-07-23-Patched_RTC_evaluating_LLMs_for_diverse_software_development_tasks.html#appendix",
    "href": "posts/Patched_RTC_evaluating_LLMs_for_diverse_software_development_tasks/2024-07-23-Patched_RTC_evaluating_LLMs_for_diverse_software_development_tasks.html#appendix",
    "title": "Patched RTC: evaluating LLMs for diverse software development tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16557v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16557v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4337"
  },
  {
    "objectID": "posts/Simulating_Classroom_Education_with_LLM_Empowered_Agents/2024-06-27-Simulating_Classroom_Education_with_LLM_Empowered_Agents.html#appendix",
    "href": "posts/Simulating_Classroom_Education_with_LLM_Empowered_Agents/2024-06-27-Simulating_Classroom_Education_with_LLM_Empowered_Agents.html#appendix",
    "title": "Simulating Classroom Education with LLM-Empowered Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19226v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19226v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6252"
  },
  {
    "objectID": "posts/Follow_the_Rules_Reasoning_for_Video_Anomaly_Detection_with_Large_Language_Models/2024-07-14-Follow_the_Rules_Reasoning_for_Video_Anomaly_Detection_with_Large_Language_Models.html#appendix",
    "href": "posts/Follow_the_Rules_Reasoning_for_Video_Anomaly_Detection_with_Large_Language_Models/2024-07-14-Follow_the_Rules_Reasoning_for_Video_Anomaly_Detection_with_Large_Language_Models.html#appendix",
    "title": "Follow the Rules: Reasoning for Video Anomaly Detection with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10299v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10299v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9790"
  },
  {
    "objectID": "posts/OPTune_Efficient_Online_Preference_Tuning/2024-06-11-OPTune_Efficient_Online_Preference_Tuning.html#appendix",
    "href": "posts/OPTune_Efficient_Online_Preference_Tuning/2024-06-11-OPTune_Efficient_Online_Preference_Tuning.html#appendix",
    "title": "OPTune: Efficient Online Preference Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07657v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07657v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7692"
  },
  {
    "objectID": "posts/Task_Oriented_In_Domain_Data_Augmentation/2024-06-24-Task_Oriented_In_Domain_Data_Augmentation.html#appendix",
    "href": "posts/Task_Oriented_In_Domain_Data_Augmentation/2024-06-24-Task_Oriented_In_Domain_Data_Augmentation.html#appendix",
    "title": "Task Oriented In-Domain Data Augmentation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16694v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16694v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6953"
  },
  {
    "objectID": "posts/EAGLE_Elevating_Geometric_Reasoning_through_LLM_empowered_Visual_Instruction_Tuning/2024-08-21-EAGLE_Elevating_Geometric_Reasoning_through_LLM_empowered_Visual_Instruction_Tuning.html#appendix",
    "href": "posts/EAGLE_Elevating_Geometric_Reasoning_through_LLM_empowered_Visual_Instruction_Tuning/2024-08-21-EAGLE_Elevating_Geometric_Reasoning_through_LLM_empowered_Visual_Instruction_Tuning.html#appendix",
    "title": "EAGLE: Elevating Geometric Reasoning through LLM-empowered Visual Instruction Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11397v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11397v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7088"
  },
  {
    "objectID": "posts/What_Do_Language_Models_Learn_in_Context_The_Structured_Task_Hypothesis/2024-06-06-What_Do_Language_Models_Learn_in_Context_The_Structured_Task_Hypothesis.html#appendix",
    "href": "posts/What_Do_Language_Models_Learn_in_Context_The_Structured_Task_Hypothesis/2024-06-06-What_Do_Language_Models_Learn_in_Context_The_Structured_Task_Hypothesis.html#appendix",
    "title": "What Do Language Models Learn in Context? The Structured Task Hypothesis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04216v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04216v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15"
  },
  {
    "objectID": "posts/Tactics_Techniques_and_Procedures_(TTPs)_in_Interpreted_Malware_A_Zero_Shot_Generation_with_Large_Language_Models/2024-07-11-Tactics_Techniques_and_Procedures_(TTPs)_in_Interpreted_Malware_A_Zero_Shot_Generation_with_Large_Language_Models.html#appendix",
    "href": "posts/Tactics_Techniques_and_Procedures_(TTPs)_in_Interpreted_Malware_A_Zero_Shot_Generation_with_Large_Language_Models/2024-07-11-Tactics_Techniques_and_Procedures_(TTPs)_in_Interpreted_Malware_A_Zero_Shot_Generation_with_Large_Language_Models.html#appendix",
    "title": "Tactics, Techniques, and Procedures (TTPs) in Interpreted Malware: A Zero-Shot Generation with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08532v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08532v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14754"
  },
  {
    "objectID": "posts/PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models/2024-06-27-PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models.html#major-findings",
    "href": "posts/PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models/2024-06-27-PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models.html#major-findings",
    "title": "PhysioLLM: Supporting Personalized Health Insights with Wearables and Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nImproved Understanding of Health Data: PhysioLLM outperforms both the Fitbit App alone and a generic LLM chatbot in facilitating a deeper, personalized understanding of health data.\nPersonalized Insights: The system provides effective personalized insights using an LLM architecture, which improves one’s understanding of their own health.\nActionable Steps Toward Personal Health Goals: The interface is perceived as more personalized than chatting with a generic LLM-based chatbot, and it results in users having more motivation to change and their goals being found to be more actionable."
  },
  {
    "objectID": "posts/PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models/2024-06-27-PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models/2024-06-27-PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models.html#analysis-and-critique",
    "title": "PhysioLLM: Supporting Personalized Health Insights with Wearables and Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nLimited Expert Health Knowledge: The system uses an off-the-shelf, general-purpose LLM, which has limited expert health knowledge. Integrations of fine-tuned specialized LLMs with the system will further improve the quality of the insights.\nHandling Randomness and Unknowns: The system has limitations in handling the randomness and unknowns in the data and contexts. However, its adaptability ensures beneficial and personalized suggestions.\nPotential for Positive Behavior Change: Anecdotal evidence suggests that the system has the potential to nudge people towards positive behavior change, which merits further study.\nPrivacy and Ethical Considerations: The system has embedded counter-action prompts to prevent abusive uses, but further tests on the robustness of the safety prompt are needed. The system should acknowledge its limitations and ensure that no raw data is sent to the LLM, and all data and survey results are de-identified.\n**Broader User"
  },
  {
    "objectID": "posts/PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models/2024-06-27-PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models.html#appendix",
    "href": "posts/PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models/2024-06-27-PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models.html#appendix",
    "title": "PhysioLLM: Supporting Personalized Health Insights with Wearables and Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19283v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19283v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7356"
  },
  {
    "objectID": "posts/EmPO_Theory_Driven_Dataset_Construction_for_Empathetic_Response_Generation_through_Preference_Optimization/2024-06-27-EmPO_Theory_Driven_Dataset_Construction_for_Empathetic_Response_Generation_through_Preference_Optimization.html#appendix",
    "href": "posts/EmPO_Theory_Driven_Dataset_Construction_for_Empathetic_Response_Generation_through_Preference_Optimization/2024-06-27-EmPO_Theory_Driven_Dataset_Construction_for_Empathetic_Response_Generation_through_Preference_Optimization.html#appendix",
    "title": "EmPO: Theory-Driven Dataset Construction for Empathetic Response Generation through Preference Optimization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19071v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19071v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4108"
  },
  {
    "objectID": "posts/ChatGPT_Doesnt_Trust_Chargers_Fans_Guardrail_Sensitivity_in_Context/2024-07-09-ChatGPT_Doesnt_Trust_Chargers_Fans_Guardrail_Sensitivity_in_Context.html#appendix",
    "href": "posts/ChatGPT_Doesnt_Trust_Chargers_Fans_Guardrail_Sensitivity_in_Context/2024-07-09-ChatGPT_Doesnt_Trust_Chargers_Fans_Guardrail_Sensitivity_in_Context.html#appendix",
    "title": "ChatGPT Doesn’t Trust Chargers Fans: Guardrail Sensitivity in Context",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06866v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06866v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9182"
  },
  {
    "objectID": "posts/SAFETY_J_Evaluating_Safety_with_Critique/2024-07-25-SAFETY_J_Evaluating_Safety_with_Critique.html#appendix",
    "href": "posts/SAFETY_J_Evaluating_Safety_with_Critique/2024-07-25-SAFETY_J_Evaluating_Safety_with_Critique.html#appendix",
    "title": "SAFETY-J: Evaluating Safety with Critique",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17075v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17075v2\n\n\nTruncated\nFalse\n\n\nWord Count\n8777"
  },
  {
    "objectID": "posts/TestART_Improving_LLM_based_Unit_Test_via_Co_evolution_of_Automated_Generation_and_Repair_Iteration/2024-08-07-TestART_Improving_LLM_based_Unit_Test_via_Co_evolution_of_Automated_Generation_and_Repair_Iteration.html",
    "href": "posts/TestART_Improving_LLM_based_Unit_Test_via_Co_evolution_of_Automated_Generation_and_Repair_Iteration/2024-08-07-TestART_Improving_LLM_based_Unit_Test_via_Co_evolution_of_Automated_Generation_and_Repair_Iteration.html",
    "title": "TestART: Improving LLM-based Unit Test via Co-evolution of Automated Generation and Repair Iteration",
    "section": "",
    "text": "Summary:\nTestART is a novel unit test generation method that leverages the strengths of large language models (LLMs) while overcoming their limitations. It improves LLM-based unit test generation through the co-evolution of automated generation and repair iteration. TestART uses a template-based repair technique to fix bugs in LLM-generated test cases, employing prompt injection to guide the next-step automated generation and avoid repetition suppression. It also extracts coverage information from passed test cases and utilizes it as testing feedback to enhance the sufficiency of the final test case. This synergy between generation and repair significantly improves the quality, effectiveness, and readability of the produced test cases. In comparative experiments, TestART-generated test cases have a pass rate of 78.55%, which is approximately 18% higher than both the ChatGPT-4.0 model and the same ChatGPT-3.5-based method ChatUniTest. It also achieves an impressive line coverage rate of 90.96% on the focal methods that passed the test, exceeding EvoSuite by 3.4%.\nMajor Findings:\nAnalysis and Critique:\nTestART’s approach to improving LLM-based unit test generation through the co-evolution"
  },
  {
    "objectID": "posts/TestART_Improving_LLM_based_Unit_Test_via_Co_evolution_of_Automated_Generation_and_Repair_Iteration/2024-08-07-TestART_Improving_LLM_based_Unit_Test_via_Co_evolution_of_Automated_Generation_and_Repair_Iteration.html#appendix",
    "href": "posts/TestART_Improving_LLM_based_Unit_Test_via_Co_evolution_of_Automated_Generation_and_Repair_Iteration/2024-08-07-TestART_Improving_LLM_based_Unit_Test_via_Co_evolution_of_Automated_Generation_and_Repair_Iteration.html#appendix",
    "title": "TestART: Improving LLM-based Unit Test via Co-evolution of Automated Generation and Repair Iteration",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03095v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03095v2\n\n\nTruncated\nFalse\n\n\nWord Count\n10992"
  },
  {
    "objectID": "posts/Sifting_through_the_Chaff_On_Utilizing_Execution_Feedback_for_Ranking_the_Generated_Code_Candidates/2024-08-26-Sifting_through_the_Chaff_On_Utilizing_Execution_Feedback_for_Ranking_the_Generated_Code_Candidates.html",
    "href": "posts/Sifting_through_the_Chaff_On_Utilizing_Execution_Feedback_for_Ranking_the_Generated_Code_Candidates/2024-08-26-Sifting_through_the_Chaff_On_Utilizing_Execution_Feedback_for_Ranking_the_Generated_Code_Candidates.html",
    "title": "Sifting through the Chaff: On Utilizing Execution Feedback for Ranking the Generated Code Candidates",
    "section": "",
    "text": "The paper presents a novel approach called RankEF, which utilizes execution feedback to enhance the efficiency of code ranking. The method integrates execution feedback and classification labels using multi-task learning, enabling the ranker to understand the underlying factors contributing to diverse code errors. The experimental results demonstrate that RankEF outperforms existing baseline methods due to its profound grasp of error causality. The paper also provides the availability of the experimental dataset and source code for further research."
  },
  {
    "objectID": "posts/Sifting_through_the_Chaff_On_Utilizing_Execution_Feedback_for_Ranking_the_Generated_Code_Candidates/2024-08-26-Sifting_through_the_Chaff_On_Utilizing_Execution_Feedback_for_Ranking_the_Generated_Code_Candidates.html#appendix",
    "href": "posts/Sifting_through_the_Chaff_On_Utilizing_Execution_Feedback_for_Ranking_the_Generated_Code_Candidates/2024-08-26-Sifting_through_the_Chaff_On_Utilizing_Execution_Feedback_for_Ranking_the_Generated_Code_Candidates.html#appendix",
    "title": "Sifting through the Chaff: On Utilizing Execution Feedback for Ranking the Generated Code Candidates",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.13976v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.13976v1\n\n\nTruncated\nFalse\n\n\nWord Count\n25044"
  },
  {
    "objectID": "posts/On_Speeding_Up_Language_Model_Evaluation/2024-07-08-On_Speeding_Up_Language_Model_Evaluation.html#major-findings",
    "href": "posts/On_Speeding_Up_Language_Model_Evaluation/2024-07-08-On_Speeding_Up_Language_Model_Evaluation.html#major-findings",
    "title": "On Speeding Up Language Model Evaluation",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe proposed algorithms, UCB-E and UCB-E-LRF, can identify the top-performing method using only 5-15% of the typically needed resources, resulting in an 85-95% reduction in cost.\nThe UCB-E algorithm enjoys a theoretical guarantee that the chance of selecting the best arm converges to 100% by an exponential decay of the number of evaluations.\nThe UCB-E-LRF algorithm leverages the intrinsic low-rankness of the scoring matrices, which can be well-approximated by a low-rank matrix, to predict the remaining unobserved method-example pairs and prioritize evaluations of the pairs with large uncertainties in this prediction."
  },
  {
    "objectID": "posts/On_Speeding_Up_Language_Model_Evaluation/2024-07-08-On_Speeding_Up_Language_Model_Evaluation.html#analysis-and-critique",
    "href": "posts/On_Speeding_Up_Language_Model_Evaluation/2024-07-08-On_Speeding_Up_Language_Model_Evaluation.html#analysis-and-critique",
    "title": "On Speeding Up Language Model Evaluation",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a novel approach to reducing the cost of evaluating methods on test examples in the context of LLMs. The proposed algorithms, UCB-E and UCB-E-LRF, offer significant improvements over traditional methods, reducing the required resources by up to 95%. However, the paper does not discuss the potential limitations or biases of the proposed approach, such as the impact of the choice of low-rank factorization or the potential for overfitting to the training data. Additionally, the paper does not provide a comparison with other state-of-the-art methods for reducing the cost of evaluating LLMs. Further research is needed to evaluate the proposed approach in a broader context and to address potential limitations and biases."
  },
  {
    "objectID": "posts/On_Speeding_Up_Language_Model_Evaluation/2024-07-08-On_Speeding_Up_Language_Model_Evaluation.html#appendix",
    "href": "posts/On_Speeding_Up_Language_Model_Evaluation/2024-07-08-On_Speeding_Up_Language_Model_Evaluation.html#appendix",
    "title": "On Speeding Up Language Model Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06172v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06172v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9151"
  },
  {
    "objectID": "posts/LLMEmbed_Rethinking_Lightweight_LLMs_Genuine_Function_in_Text_Classification/2024-06-06-LLMEmbed_Rethinking_Lightweight_LLMs_Genuine_Function_in_Text_Classification.html#appendix",
    "href": "posts/LLMEmbed_Rethinking_Lightweight_LLMs_Genuine_Function_in_Text_Classification/2024-06-06-LLMEmbed_Rethinking_Lightweight_LLMs_Genuine_Function_in_Text_Classification.html#appendix",
    "title": "LLMEmbed: Rethinking Lightweight LLM’s Genuine Function in Text Classification",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03725v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03725v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5774"
  },
  {
    "objectID": "posts/Arena_Learning_Build_Data_Flywheel_for_LLMs_Post_training_via_Simulated_Chatbot_Arena/2024-07-15-Arena_Learning_Build_Data_Flywheel_for_LLMs_Post_training_via_Simulated_Chatbot_Arena.html#appendix",
    "href": "posts/Arena_Learning_Build_Data_Flywheel_for_LLMs_Post_training_via_Simulated_Chatbot_Arena/2024-07-15-Arena_Learning_Build_Data_Flywheel_for_LLMs_Post_training_via_Simulated_Chatbot_Arena.html#appendix",
    "title": "Arena Learning: Build Data Flywheel for LLMs Post-training via Simulated Chatbot Arena",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10627v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10627v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10689"
  },
  {
    "objectID": "posts/YouDream_Generating_Anatomically_Controllable_Consistent_Text_to_3D_Animals/2024-06-24-YouDream_Generating_Anatomically_Controllable_Consistent_Text_to_3D_Animals.html",
    "href": "posts/YouDream_Generating_Anatomically_Controllable_Consistent_Text_to_3D_Animals/2024-06-24-YouDream_Generating_Anatomically_Controllable_Consistent_Text_to_3D_Animals.html",
    "title": "YouDream: Generating Anatomically Controllable Consistent Text-to-3D Animals",
    "section": "",
    "text": "Summary:\nYouDream is a method for generating high-quality anatomically controllable 3D animals. It is guided by a text-to-image diffusion model controlled by 2D views of a 3D pose prior. The method generates 3D animals that are not possible to create using previous text-to-3D generative methods and preserves anatomic consistency. A fully automated pipeline for generating commonly found animals is also proposed, which uses a multi-agent LLM to adapt poses from a limited library of animal 3D poses to represent the desired animal. A user study conducted on the outcomes of YouDream demonstrates the preference of the animal models generated by this method over others.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/YouDream_Generating_Anatomically_Controllable_Consistent_Text_to_3D_Animals/2024-06-24-YouDream_Generating_Anatomically_Controllable_Consistent_Text_to_3D_Animals.html#appendix",
    "href": "posts/YouDream_Generating_Anatomically_Controllable_Consistent_Text_to_3D_Animals/2024-06-24-YouDream_Generating_Anatomically_Controllable_Consistent_Text_to_3D_Animals.html#appendix",
    "title": "YouDream: Generating Anatomically Controllable Consistent Text-to-3D Animals",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16273v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16273v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10409"
  },
  {
    "objectID": "posts/Can_we_teach_language_models_to_gloss_endangered_languages/2024-06-27-Can_we_teach_language_models_to_gloss_endangered_languages.html#appendix",
    "href": "posts/Can_we_teach_language_models_to_gloss_endangered_languages/2024-06-27-Can_we_teach_language_models_to_gloss_endangered_languages.html#appendix",
    "title": "Can we teach language models to gloss endangered languages?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18895v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18895v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6433"
  },
  {
    "objectID": "posts/First_Activations_Matter_Training_Free_Methods_for_Dynamic_Activation_in_Large_Language_Models/2024-08-21-First_Activations_Matter_Training_Free_Methods_for_Dynamic_Activation_in_Large_Language_Models.html#major-findings",
    "href": "posts/First_Activations_Matter_Training_Free_Methods_for_Dynamic_Activation_in_Large_Language_Models/2024-08-21-First_Activations_Matter_Training_Free_Methods_for_Dynamic_Activation_in_Large_Language_Models.html#major-findings",
    "title": "First Activations Matter: Training-Free Methods for Dynamic Activation in Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nTDA significantly reduces generation latency with minimal impact on model performance.\nThe paper provides a mathematical explanation for DA and its relationship with the ReLU activation function.\nThe paper identifies history-related activation uncertainty in dynamic activation, explaining why previous DA methods fail in models with non-ReLU activation functions.\nThe paper conducts a detailed analysis of semantic-irrelevant activation inertia in DA, elucidating the mechanism of TDA that leverages sequential information in models across various architectures and activation functions."
  },
  {
    "objectID": "posts/First_Activations_Matter_Training_Free_Methods_for_Dynamic_Activation_in_Large_Language_Models/2024-08-21-First_Activations_Matter_Training_Free_Methods_for_Dynamic_Activation_in_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/First_Activations_Matter_Training_Free_Methods_for_Dynamic_Activation_in_Large_Language_Models/2024-08-21-First_Activations_Matter_Training_Free_Methods_for_Dynamic_Activation_in_Large_Language_Models.html#analysis-and-critique",
    "title": "First Activations Matter: Training-Free Methods for Dynamic Activation in Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a promising approach to improving the inference efficiency of LLMs. However, the theoretical derivations and empirical validation are based on specific models and datasets, which may limit the generalizability of the findings. Future research should consider more diverse models and datasets to validate the proposed method’s effectiveness.\nAdditionally, the paper does not discuss the potential impact of TDA on the model’s interpretability and fairness. As the method selectively activates neurons based on sequential information, it may introduce biases or reduce the model’s ability to explain its predictions. Future research should address these concerns to ensure that the proposed method is not only efficient but also fair and interpretable."
  },
  {
    "objectID": "posts/First_Activations_Matter_Training_Free_Methods_for_Dynamic_Activation_in_Large_Language_Models/2024-08-21-First_Activations_Matter_Training_Free_Methods_for_Dynamic_Activation_in_Large_Language_Models.html#appendix",
    "href": "posts/First_Activations_Matter_Training_Free_Methods_for_Dynamic_Activation_in_Large_Language_Models/2024-08-21-First_Activations_Matter_Training_Free_Methods_for_Dynamic_Activation_in_Large_Language_Models.html#appendix",
    "title": "First Activations Matter: Training-Free Methods for Dynamic Activation in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11393v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11393v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5666"
  },
  {
    "objectID": "posts/Mutagenesis_screen_to_map_the_functionals_of_parameters_of_Large_Language_Models/2024-08-21-Mutagenesis_screen_to_map_the_functionals_of_parameters_of_Large_Language_Models.html#appendix",
    "href": "posts/Mutagenesis_screen_to_map_the_functionals_of_parameters_of_Large_Language_Models/2024-08-21-Mutagenesis_screen_to_map_the_functionals_of_parameters_of_Large_Language_Models.html#appendix",
    "title": "Mutagenesis screen to map the functionals of parameters of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11494v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11494v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11477"
  },
  {
    "objectID": "posts/Generative_Monoculture_in_Large_Language_Models/2024-07-02-Generative_Monoculture_in_Large_Language_Models.html#appendix",
    "href": "posts/Generative_Monoculture_in_Large_Language_Models/2024-07-02-Generative_Monoculture_in_Large_Language_Models.html#appendix",
    "title": "Generative Monoculture in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02209v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02209v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13500"
  },
  {
    "objectID": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#summary-1",
    "href": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#summary-1",
    "title": "LangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling",
    "section": "Summary:",
    "text": "Summary:\nThe paper introduces a novel framework, LangTopo, which aligns graph structure modeling with natural language understanding at the token level. LangTopo quantifies the graph structure modeling capabilities of GNNs and LLMs by constructing a codebook for the graph modality and performs consistency maximization. This process aligns the text description of LLM with the topological modeling of GNN, allowing LLM to learn the ability of GNN to capture graph structures, enabling LLM to handle graph-structured data independently. The effectiveness of the proposed method is demonstrated on multiple datasets."
  },
  {
    "objectID": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#major-findings",
    "href": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#major-findings",
    "title": "LangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe paper proposes LangTopo, a new framework for learning graph structures using LLMs, which enables LLMs to learn GNNs’ ability to model graph structures through supervised learning.\nLangTopo achieves alignment between the natural language descriptive text in LLMs and the processing and operation of GNN models by constructing a codebook for the graph data modality.\nUnlike existing paradigms that usually introduce external modules to recognize graph structures, LangTopo endows the LLM itself with the ability to model graph structures, obviating the need for external data or model integration during inference."
  },
  {
    "objectID": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#analysis-and-critique",
    "href": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#analysis-and-critique",
    "title": "LangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper presents a promising approach to addressing the challenges of combining the structural modeling capacity of GNNs with the text processing capability of LLMs.\nThe use of an external GNN to extract spatial structure embeddings and training a projection layer or adapter to inject these embeddings into the LLM has been a common approach, but LLMs still lack the ability to handle graph data independently and continue to rely on external models during inference.\nThe paper’s focus on modeling, rather than embedding, is a significant contribution to the field, as it addresses the fundamental issue of LLMs lacking the capability to model graph structures.\nThe paper’s evaluation on multiple datasets demonstrates the effectiveness of the proposed method, but further research is needed to explore the generalizability and scalability of LangTopo.\nThe paper’s limitation is the unexplored scenario of jointly training with multiple datasets for graph modality"
  },
  {
    "objectID": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#appendix",
    "href": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#appendix",
    "title": "LangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13250v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13250v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10341"
  },
  {
    "objectID": "posts/EvalYaks_Instruction_Tuning_Datasets_and_LoRA_Fine_tuned_Models_for_Automated_Scoring_of_CEFR_B2_Speaking_Assessment_Transcripts/2024-08-22-EvalYaks_Instruction_Tuning_Datasets_and_LoRA_Fine_tuned_Models_for_Automated_Scoring_of_CEFR_B2_Speaking_Assessment_Transcripts.html",
    "href": "posts/EvalYaks_Instruction_Tuning_Datasets_and_LoRA_Fine_tuned_Models_for_Automated_Scoring_of_CEFR_B2_Speaking_Assessment_Transcripts/2024-08-22-EvalYaks_Instruction_Tuning_Datasets_and_LoRA_Fine_tuned_Models_for_Automated_Scoring_of_CEFR_B2_Speaking_Assessment_Transcripts.html",
    "title": "EvalYaks: Instruction Tuning Datasets and LoRA Fine-tuned Models for Automated Scoring of CEFR B2 Speaking Assessment Transcripts",
    "section": "",
    "text": "Summary:\nThe paper presents a study on automating the evaluation of CEFR B2 English speaking assessments in e-learning environments using conversation transcripts. The authors evaluate the capability of leading open-source and commercial Large Language Models (LLMs) to score candidates’ performance across various criteria in the CEFR B2 speaking exam. They also create a new expert-validated, CEFR-aligned synthetic conversational dataset with transcripts rated at different assessment scores. The authors then perform parameter-efficient instruction tuning of Mistral Instruct 7B v0.2 to develop a family of models called EvalYaks. Four models in this family are for assessing the four sections of the CEFR B2 speaking exam, one for identifying the CEFR level of vocabulary and generating level-specific vocabulary, and another for detecting the CEFR level of text and generating level-specific text. EvalYaks achieved an average acceptable accuracy of 96%, a degree of variation of 0.35 levels, and performed 3 times better than the next best model. The study demonstrates that a 7B parameter LLM instruction-tuned with high-quality CEFR-aligned assessment data can effectively evaluate and score CEFR B2 English speaking assessments.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a promising approach to automating the evaluation of CEFR B2 English speaking assessments using LLMs. The authors’ creation of a new expert-validated, CEFR-aligned synthetic conversational dataset and the development of EvalYaks through parameter-efficient instruction tuning are significant contributions to the field. However, the study has some limitations. The authors do not discuss the potential biases in the synthetic dataset or the impact of cultural and"
  },
  {
    "objectID": "posts/EvalYaks_Instruction_Tuning_Datasets_and_LoRA_Fine_tuned_Models_for_Automated_Scoring_of_CEFR_B2_Speaking_Assessment_Transcripts/2024-08-22-EvalYaks_Instruction_Tuning_Datasets_and_LoRA_Fine_tuned_Models_for_Automated_Scoring_of_CEFR_B2_Speaking_Assessment_Transcripts.html#appendix",
    "href": "posts/EvalYaks_Instruction_Tuning_Datasets_and_LoRA_Fine_tuned_Models_for_Automated_Scoring_of_CEFR_B2_Speaking_Assessment_Transcripts/2024-08-22-EvalYaks_Instruction_Tuning_Datasets_and_LoRA_Fine_tuned_Models_for_Automated_Scoring_of_CEFR_B2_Speaking_Assessment_Transcripts.html#appendix",
    "title": "EvalYaks: Instruction Tuning Datasets and LoRA Fine-tuned Models for Automated Scoring of CEFR B2 Speaking Assessment Transcripts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12226v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12226v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11370"
  },
  {
    "objectID": "posts/The_Model_Arena_for_Cross_lingual_Sentiment_Analysis_A_Comparative_Study_in_the_Era_of_Large_Language_Models/2024-06-27-The_Model_Arena_for_Cross_lingual_Sentiment_Analysis_A_Comparative_Study_in_the_Era_of_Large_Language_Models.html#appendix",
    "href": "posts/The_Model_Arena_for_Cross_lingual_Sentiment_Analysis_A_Comparative_Study_in_the_Era_of_Large_Language_Models/2024-06-27-The_Model_Arena_for_Cross_lingual_Sentiment_Analysis_A_Comparative_Study_in_the_Era_of_Large_Language_Models.html#appendix",
    "title": "The Model Arena for Cross-lingual Sentiment Analysis: A Comparative Study in the Era of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19358v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19358v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5764"
  },
  {
    "objectID": "posts/rLLM_Relational_Table_Learning_with_LLMs/2024-07-29-rLLM_Relational_Table_Learning_with_LLMs.html#appendix",
    "href": "posts/rLLM_Relational_Table_Learning_with_LLMs/2024-07-29-rLLM_Relational_Table_Learning_with_LLMs.html#appendix",
    "title": "rLLM: Relational Table Learning with LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20157v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20157v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5065"
  },
  {
    "objectID": "posts/KOALA_Enhancing_Speculative_Decoding_for_LLM_via_Multi_Layer_Draft_Heads_with_Adversarial_Learning/2024-08-15-KOALA_Enhancing_Speculative_Decoding_for_LLM_via_Multi_Layer_Draft_Heads_with_Adversarial_Learning.html#appendix",
    "href": "posts/KOALA_Enhancing_Speculative_Decoding_for_LLM_via_Multi_Layer_Draft_Heads_with_Adversarial_Learning/2024-08-15-KOALA_Enhancing_Speculative_Decoding_for_LLM_via_Multi_Layer_Draft_Heads_with_Adversarial_Learning.html#appendix",
    "title": "KOALA: Enhancing Speculative Decoding for LLM via Multi-Layer Draft Heads with Adversarial Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.08146v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.08146v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5911"
  },
  {
    "objectID": "posts/NoteLLM_2_Multimodal_Large_Representation_Models_for_Recommendation/2024-05-27-NoteLLM_2_Multimodal_Large_Representation_Models_for_Recommendation.html#appendix",
    "href": "posts/NoteLLM_2_Multimodal_Large_Representation_Models_for_Recommendation/2024-05-27-NoteLLM_2_Multimodal_Large_Representation_Models_for_Recommendation.html#appendix",
    "title": "NoteLLM-2: Multimodal Large Representation Models for Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.16789v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.16789v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7838"
  },
  {
    "objectID": "posts/Paired_Completion_Flexible_Quantification_of_Issue_framing_at_Scale_with_LLMs/2024-08-19-Paired_Completion_Flexible_Quantification_of_Issue_framing_at_Scale_with_LLMs.html#appendix",
    "href": "posts/Paired_Completion_Flexible_Quantification_of_Issue_framing_at_Scale_with_LLMs/2024-08-19-Paired_Completion_Flexible_Quantification_of_Issue_framing_at_Scale_with_LLMs.html#appendix",
    "title": "Paired Completion: Flexible Quantification of Issue-framing at Scale with LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09742v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09742v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7395"
  },
  {
    "objectID": "posts/SLIP_Securing_LLMs_IP_Using_Weights_Decomposition/2024-07-15-SLIP_Securing_LLMs_IP_Using_Weights_Decomposition.html#appendix",
    "href": "posts/SLIP_Securing_LLMs_IP_Using_Weights_Decomposition/2024-07-15-SLIP_Securing_LLMs_IP_Using_Weights_Decomposition.html#appendix",
    "title": "SLIP: Securing LLMs IP Using Weights Decomposition",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10886v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10886v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8145"
  },
  {
    "objectID": "posts/Characterizing_and_Evaluating_the_Reliability_of_LLMs_against_Jailbreak_Attacks/2024-08-18-Characterizing_and_Evaluating_the_Reliability_of_LLMs_against_Jailbreak_Attacks.html#appendix",
    "href": "posts/Characterizing_and_Evaluating_the_Reliability_of_LLMs_against_Jailbreak_Attacks/2024-08-18-Characterizing_and_Evaluating_the_Reliability_of_LLMs_against_Jailbreak_Attacks.html#appendix",
    "title": "Characterizing and Evaluating the Reliability of LLMs against Jailbreak Attacks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09326v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09326v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8950"
  },
  {
    "objectID": "posts/On_the_Robustness_of_Language_Models_for_Tabular_Question_Answering/2024-06-18-On_the_Robustness_of_Language_Models_for_Tabular_Question_Answering.html#appendix",
    "href": "posts/On_the_Robustness_of_Language_Models_for_Tabular_Question_Answering/2024-06-18-On_the_Robustness_of_Language_Models_for_Tabular_Question_Answering.html#appendix",
    "title": "On the Robustness of Language Models for Tabular Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12719v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12719v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3509"
  },
  {
    "objectID": "posts/TheoremLlama_Transforming_General_Purpose_LLMs_into_Lean4_Experts/2024-07-03-TheoremLlama_Transforming_General_Purpose_LLMs_into_Lean4_Experts.html#appendix",
    "href": "posts/TheoremLlama_Transforming_General_Purpose_LLMs_into_Lean4_Experts/2024-07-03-TheoremLlama_Transforming_General_Purpose_LLMs_into_Lean4_Experts.html#appendix",
    "title": "TheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03203v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03203v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8361"
  },
  {
    "objectID": "posts/Decoding_Biases_Automated_Methods_and_LLM_Judges_for_Gender_Bias_Detection_in_Language_Models/2024-08-07-Decoding_Biases_Automated_Methods_and_LLM_Judges_for_Gender_Bias_Detection_in_Language_Models.html#appendix",
    "href": "posts/Decoding_Biases_Automated_Methods_and_LLM_Judges_for_Gender_Bias_Detection_in_Language_Models/2024-08-07-Decoding_Biases_Automated_Methods_and_LLM_Judges_for_Gender_Bias_Detection_in_Language_Models.html#appendix",
    "title": "Decoding Biases: Automated Methods and LLM Judges for Gender Bias Detection in Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03907v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03907v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5205"
  },
  {
    "objectID": "posts/DanModCap_Designing_a_Danmaku_Moderation_Tool_for_Video_Sharing_Platforms_that_Leverages_Impact_Captions/2024-08-05-DanModCap_Designing_a_Danmaku_Moderation_Tool_for_Video_Sharing_Platforms_that_Leverages_Impact_Captions.html#appendix",
    "href": "posts/DanModCap_Designing_a_Danmaku_Moderation_Tool_for_Video_Sharing_Platforms_that_Leverages_Impact_Captions/2024-08-05-DanModCap_Designing_a_Danmaku_Moderation_Tool_for_Video_Sharing_Platforms_that_Leverages_Impact_Captions.html#appendix",
    "title": "DanModCap: Designing a Danmaku Moderation Tool for Video-Sharing Platforms that Leverages Impact Captions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02574v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02574v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14165"
  },
  {
    "objectID": "posts/Knowledge_Graph_Tuning_Real_time_Large_Language_Model_Personalization_based_on_Human_Feedback/2024-05-30-Knowledge_Graph_Tuning_Real_time_Large_Language_Model_Personalization_based_on_Human_Feedback.html#appendix",
    "href": "posts/Knowledge_Graph_Tuning_Real_time_Large_Language_Model_Personalization_based_on_Human_Feedback/2024-05-30-Knowledge_Graph_Tuning_Real_time_Large_Language_Model_Personalization_based_on_Human_Feedback.html#appendix",
    "title": "Knowledge Graph Tuning: Real-time Large Language Model Personalization based on Human Feedback",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.19686v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.19686v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6292"
  },
  {
    "objectID": "posts/CoEvol_Constructing_Better_Responses_for_Instruction_Finetuning_through_Multi_Agent_Cooperation/2024-06-11-CoEvol_Constructing_Better_Responses_for_Instruction_Finetuning_through_Multi_Agent_Cooperation.html#appendix",
    "href": "posts/CoEvol_Constructing_Better_Responses_for_Instruction_Finetuning_through_Multi_Agent_Cooperation/2024-06-11-CoEvol_Constructing_Better_Responses_for_Instruction_Finetuning_through_Multi_Agent_Cooperation.html#appendix",
    "title": "CoEvol: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07054v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07054v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6780"
  },
  {
    "objectID": "posts/FFN_a_Fine_grained_Chinese_English_Financial_Domain_Parallel_Corpus/2024-06-27-FFN_a_Fine_grained_Chinese_English_Financial_Domain_Parallel_Corpus.html#appendix",
    "href": "posts/FFN_a_Fine_grained_Chinese_English_Financial_Domain_Parallel_Corpus/2024-06-27-FFN_a_Fine_grained_Chinese_English_Financial_Domain_Parallel_Corpus.html#appendix",
    "title": "FFN: a Fine-grained Chinese-English Financial Domain Parallel Corpus",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18856v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18856v1\n\n\nTruncated\nFalse\n\n\nWord Count\n848"
  },
  {
    "objectID": "posts/A_Survey_of_Attacks_on_Large_Vision_Language_Models_Resources_Advances_and_Future_Trends/2024-07-10-A_Survey_of_Attacks_on_Large_Vision_Language_Models_Resources_Advances_and_Future_Trends.html#major-findings",
    "href": "posts/A_Survey_of_Attacks_on_Large_Vision_Language_Models_Resources_Advances_and_Future_Trends/2024-07-10-A_Survey_of_Attacks_on_Large_Vision_Language_Models_Resources_Advances_and_Future_Trends.html#major-findings",
    "title": "A Survey of Attacks on Large Vision-Language Models: Resources, Advances, and Future Trends",
    "section": "Major Findings",
    "text": "Major Findings\n\nAdversarial Attacks: These attacks manipulate model outputs by introducing subtle perturbations to the input data, causing the model to produce incorrect or undesirable outputs. These perturbations are meticulously designed to exploit the model’s vulnerabilities.\nJailbreak Attacks: These attacks exploit weaknesses in the model to bypass its intended restrictions and controls, leading to the model executing unauthorized commands, accessing restricted data, or performing actions beyond its designed capabilities.\nPrompt Injection Attacks: These attacks involve manipulating the model’s input prompts to alter its behavior or outputs in unintended ways. By injecting malicious or misleading prompts, attackers can steer the model to generate incorrect, biased, or harmful responses.\nData Poisoning/Backdoor Attacks: These attacks tamper with the training data to undermine the model’s performance and reliability. In these attacks, malicious data is inserted into the training dataset, causing the model to learn and propagate incorrect patterns."
  },
  {
    "objectID": "posts/A_Survey_of_Attacks_on_Large_Vision_Language_Models_Resources_Advances_and_Future_Trends/2024-07-10-A_Survey_of_Attacks_on_Large_Vision_Language_Models_Resources_Advances_and_Future_Trends.html#analysis-and-critique",
    "href": "posts/A_Survey_of_Attacks_on_Large_Vision_Language_Models_Resources_Advances_and_Future_Trends/2024-07-10-A_Survey_of_Attacks_on_Large_Vision_Language_Models_Resources_Advances_and_Future_Trends.html#analysis-and-critique",
    "title": "A Survey of Attacks on Large Vision-Language Models: Resources, Advances, and Future Trends",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\nThe paper provides a comprehensive overview of the current landscape of attacks on LVLMs. However, it does not delve into the specific methodologies used in each type of attack, which could be beneficial for understanding the nuances of each attack. Additionally, the paper does not discuss potential defense strategies against these attacks, which is a crucial aspect of ensuring the security and robustness of LVLMs.\nMoreover, the paper could benefit from a more in-depth discussion on the ethical implications of these attacks, as they can have significant real-world consequences. For instance, adversarial attacks on autonomous driving systems could lead"
  },
  {
    "objectID": "posts/A_Survey_of_Attacks_on_Large_Vision_Language_Models_Resources_Advances_and_Future_Trends/2024-07-10-A_Survey_of_Attacks_on_Large_Vision_Language_Models_Resources_Advances_and_Future_Trends.html#appendix",
    "href": "posts/A_Survey_of_Attacks_on_Large_Vision_Language_Models_Resources_Advances_and_Future_Trends/2024-07-10-A_Survey_of_Attacks_on_Large_Vision_Language_Models_Resources_Advances_and_Future_Trends.html#appendix",
    "title": "A Survey of Attacks on Large Vision-Language Models: Resources, Advances, and Future Trends",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07403v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07403v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11932"
  },
  {
    "objectID": "posts/Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents/2024-06-09-Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents.html",
    "href": "posts/Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents/2024-06-09-Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents.html",
    "title": "Machine Against the RAG: Jamming Retrieval-Augmented Generation with Blocker Documents",
    "section": "",
    "text": "Summary:\nThe paper introduces a new class of denial-of-service vulnerabilities in retrieval-augmented generation (RAG) systems, where a single “blocker” document in the RAG database can cause the system to refuse to answer certain queries. The authors demonstrate this attack against several popular large language models (LLMs) and show that resistance to jamming is a novel LLM-safety property not captured by existing safety and trustworthiness metrics.\nThe authors investigate several methods for generating blocker documents, including a new method based on black-box optimization that does not require knowledge of the embedding or LLM used by the target RAG system. They also discuss the limitations of this method, such as producing blocker documents that have no semantics and can be easily filtered out from RAG databases.\nThe paper concludes with a discussion of future research directions, such as minimizing the number of queries to the target RAG system, generating blocker documents with access to a RAG system whose database is not exactly the same as the target system, and generating passive blocker documents that are difficult to detect or even semantically plausible.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an interesting and novel attack on RAG systems, highlighting a previously unrecognized vulnerability. The authors’ investigation of different methods for generating blocker documents is thorough and well-presented. However, the paper could benefit from a more in-depth discussion of the potential real-world implications of this attack and possible countermeasures. Additionally, the limitations of the black-box optimization method for generating blocker documents should be further explored and addressed."
  },
  {
    "objectID": "posts/Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents/2024-06-09-Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents.html#appendix",
    "href": "posts/Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents/2024-06-09-Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents.html#appendix",
    "title": "Machine Against the RAG: Jamming Retrieval-Augmented Generation with Blocker Documents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05870v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05870v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12156"
  },
  {
    "objectID": "posts/An_investigation_on_the_use_of_Large_Language_Models_for_hyperparameter_tuning_in_Evolutionary_Algorithms/2024-08-05-An_investigation_on_the_use_of_Large_Language_Models_for_hyperparameter_tuning_in_Evolutionary_Algorithms.html#appendix",
    "href": "posts/An_investigation_on_the_use_of_Large_Language_Models_for_hyperparameter_tuning_in_Evolutionary_Algorithms/2024-08-05-An_investigation_on_the_use_of_Large_Language_Models_for_hyperparameter_tuning_in_Evolutionary_Algorithms.html#appendix",
    "title": "An investigation on the use of Large Language Models for hyperparameter tuning in Evolutionary Algorithms",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02451v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02451v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5174"
  },
  {
    "objectID": "posts/SNAP_Unlearning_Selective_Knowledge_in_Large_Language_Models_with_Negative_Instructions/2024-06-18-SNAP_Unlearning_Selective_Knowledge_in_Large_Language_Models_with_Negative_Instructions.html#appendix",
    "href": "posts/SNAP_Unlearning_Selective_Knowledge_in_Large_Language_Models_with_Negative_Instructions/2024-06-18-SNAP_Unlearning_Selective_Knowledge_in_Large_Language_Models_with_Negative_Instructions.html#appendix",
    "title": "SNAP: Unlearning Selective Knowledge in Large Language Models with Negative Instructions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12329v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12329v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7278"
  },
  {
    "objectID": "posts/Toward_a_Dialogue_System_Using_a_Large_Language_Model_to_Recognize_User_Emotions_with_a_Camera/2024-08-15-Toward_a_Dialogue_System_Using_a_Large_Language_Model_to_Recognize_User_Emotions_with_a_Camera.html#appendix",
    "href": "posts/Toward_a_Dialogue_System_Using_a_Large_Language_Model_to_Recognize_User_Emotions_with_a_Camera/2024-08-15-Toward_a_Dialogue_System_Using_a_Large_Language_Model_to_Recognize_User_Emotions_with_a_Camera.html#appendix",
    "title": "Toward a Dialogue System Using a Large Language Model to Recognize User Emotions with a Camera",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07982v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07982v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2786"
  },
  {
    "objectID": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#major-findings",
    "href": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#major-findings",
    "title": "MolX: Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nMolX significantly improves the performance of LLMs on various molecule-related tasks, outperforming baselines on tasks such as molecule-to-text translation, retrosynthesis, and property prediction.\nMolX can act as a plug-in module to the LLM, enhancing its performance on molecule-related tasks while fully preserving its general-purpose usage on other domains.\nThe proposed method only introduces a small number of trainable parameters, making it an efficient solution for enhancing LLMs."
  },
  {
    "objectID": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#analysis-and-critique",
    "href": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#analysis-and-critique",
    "title": "MolX: Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper does not discuss the potential limitations of the MolX framework, such as its performance on more complex molecular structures or its ability to handle large-scale molecular datasets.\nThe paper does not provide a comparison with other multi-modal approaches for molecular learning, which could provide a more comprehensive evaluation of the proposed method.\nThe paper does not discuss the potential applications of MolX in other domains, such as drug discovery or materials science, which could provide additional insights into its potential impact.\nThe paper does not discuss the potential ethical implications of using LLMs for molecular learning, such as the potential for bias in the generated molecular structures or the potential for misuse in the development of harmful substances.\n\nOverall, the paper presents a promising approach for enhancing the ability of LLMs to comprehend molecules. However, further research is needed to fully evaluate its limitations, compare it with other approaches, and explore its potential applications and ethical implications."
  },
  {
    "objectID": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#appendix",
    "href": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#appendix",
    "title": "MolX: Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06777v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06777v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8694"
  },
  {
    "objectID": "posts/Semantic_Communication_Enhanced_by_Knowledge_Graph_Representation_Learning/2024-07-27-Semantic_Communication_Enhanced_by_Knowledge_Graph_Representation_Learning.html#appendix",
    "href": "posts/Semantic_Communication_Enhanced_by_Knowledge_Graph_Representation_Learning/2024-07-27-Semantic_Communication_Enhanced_by_Knowledge_Graph_Representation_Learning.html#appendix",
    "title": "Semantic Communication Enhanced by Knowledge Graph Representation Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19338v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19338v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3787"
  },
  {
    "objectID": "posts/A_Taxonomy_for_Data_Contamination_in_Large_Language_Models/2024-07-11-A_Taxonomy_for_Data_Contamination_in_Large_Language_Models.html#major-findings",
    "href": "posts/A_Taxonomy_for_Data_Contamination_in_Large_Language_Models/2024-07-11-A_Taxonomy_for_Data_Contamination_in_Large_Language_Models.html#major-findings",
    "title": "A Taxonomy for Data Contamination in Large Language Models",
    "section": "Major Findings",
    "text": "Major Findings\n\nThe paper presents a taxonomy that categorizes the various types of contamination encountered by LLMs during the pretraining phase and identifies which types pose the highest risk.\nThe authors analyze the impact of contamination on two key NLP tasks: summarization and question answering, revealing how different types of contamination influence task performance during evaluation.\nThe findings reveal that for GPT-2 Large models, having in-domain data present during training is often as beneficial as having the test data present during training.\nCertain contamination types exhibit task-dependent effects on evaluation performance, further complicating decontamination best practices.\nThe findings enable recommendations for identifying and mitigating problematic contamination during LLM development to ensure reliable evaluations."
  },
  {
    "objectID": "posts/A_Taxonomy_for_Data_Contamination_in_Large_Language_Models/2024-07-11-A_Taxonomy_for_Data_Contamination_in_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/A_Taxonomy_for_Data_Contamination_in_Large_Language_Models/2024-07-11-A_Taxonomy_for_Data_Contamination_in_Large_Language_Models.html#analysis-and-critique",
    "title": "A Taxonomy for Data Contamination in Large Language Models",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\nThe paper provides a comprehensive taxonomy for data contamination in LLMs and analyzes its impact on two key NLP tasks. However, the paper does not discuss the potential impact of contamination on other NLP tasks, such as named entity recognition or part-of-speech tagging. Additionally, the paper does not provide a detailed analysis of the impact of contamination on model fairness, bias, and robustness.\nFurthermore, the paper does not discuss the potential impact of contamination on model interpretability and explainability. As LLMs become more prevalent in real-world applications, it is essential to understand how contamination affects model behavior and decision-making processes.\nOverall, the paper provides valuable insights into the impact of data contamination on LLMs and highlights the need for further research in this area. However, the paper could benefit from a more comprehensive analysis of the impact of contamination on other NLP tasks and model fairness, bias, and robustness."
  },
  {
    "objectID": "posts/A_Taxonomy_for_Data_Contamination_in_Large_Language_Models/2024-07-11-A_Taxonomy_for_Data_Contamination_in_Large_Language_Models.html#appendix",
    "href": "posts/A_Taxonomy_for_Data_Contamination_in_Large_Language_Models/2024-07-11-A_Taxonomy_for_Data_Contamination_in_Large_Language_Models.html#appendix",
    "title": "A Taxonomy for Data Contamination in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08716v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08716v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15638"
  },
  {
    "objectID": "posts/BEEAR_Embedding_based_Adversarial_Removal_of_Safety_Backdoors_in_Instruction_tuned_Language_Models/2024-06-24-BEEAR_Embedding_based_Adversarial_Removal_of_Safety_Backdoors_in_Instruction_tuned_Language_Models.html#appendix",
    "href": "posts/BEEAR_Embedding_based_Adversarial_Removal_of_Safety_Backdoors_in_Instruction_tuned_Language_Models/2024-06-24-BEEAR_Embedding_based_Adversarial_Removal_of_Safety_Backdoors_in_Instruction_tuned_Language_Models.html#appendix",
    "title": "BEEAR: Embedding-based Adversarial Removal of Safety Backdoors in Instruction-tuned Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17092v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17092v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11761"
  },
  {
    "objectID": "posts/Efficient_Training_of_Large_Language_Models_on_Distributed_Infrastructures_A_Survey/2024-07-29-Efficient_Training_of_Large_Language_Models_on_Distributed_Infrastructures_A_Survey.html",
    "href": "posts/Efficient_Training_of_Large_Language_Models_on_Distributed_Infrastructures_A_Survey/2024-07-29-Efficient_Training_of_Large_Language_Models_on_Distributed_Infrastructures_A_Survey.html",
    "title": "Efficient Training of Large Language Models on Distributed Infrastructures: A Survey",
    "section": "",
    "text": "Summary:\nThe paper provides a comprehensive overview of the challenges and advancements in training large language models (LLMs) on distributed infrastructures. It discusses various AI accelerators, network infrastructure, resource scheduling, and parallelism schemes for LLM training. The paper also covers heterogeneity in LLM training, low-bit fixed point training, memory optimization techniques, in-network aggregation, and checkpoint-free recovery methods. The survey aims to provide insights into improving LLM training systems and tackling ongoing challenges, such as scalability, efficiency, and reliability.\nKey Terms:\n**Major"
  },
  {
    "objectID": "posts/Efficient_Training_of_Large_Language_Models_on_Distributed_Infrastructures_A_Survey/2024-07-29-Efficient_Training_of_Large_Language_Models_on_Distributed_Infrastructures_A_Survey.html#appendix",
    "href": "posts/Efficient_Training_of_Large_Language_Models_on_Distributed_Infrastructures_A_Survey/2024-07-29-Efficient_Training_of_Large_Language_Models_on_Distributed_Infrastructures_A_Survey.html#appendix",
    "title": "Efficient Training of Large Language Models on Distributed Infrastructures: A Survey",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20018v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20018v1\n\n\nTruncated\nTrue\n\n\nWord Count\n37218"
  },
  {
    "objectID": "posts/An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics/2024-06-10-An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics.html",
    "href": "posts/An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics/2024-06-10-An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics.html",
    "title": "An Empirical Design Justice Approach to Identifying Ethical Considerations in the Intersection of Large Language Models and Social Robotics",
    "section": "",
    "text": "Summary:\nThe integration of Large Language Models (LLMs) in social robotics presents a unique set of ethical challenges and social impacts. This research aims to identify ethical considerations that arise in the design and development of these two technologies in combination. Using LLMs for social robotics may provide benefits, such as enabling natural language open-domain dialogues. However, the intersection of these two technologies also gives rise to ethical concerns related to misinformation, non-verbal cues, emotional disruption, and biases. The robot’s physical social embodiment adds complexity, as ethical hazards associated with LLM-based Social AI, such as hallucinations and misinformation, can be exacerbated due to the effects of physical embodiment on social perception and communication. To address these challenges, this study employs an empirical design justice-based methodology, focusing on identifying socio-technical ethical considerations through a qualitative co-design and interaction study. The purpose of the study is to identify ethical considerations relevant to the process of co-design of, and interaction with a humanoid social robot as the interface of a LLM, and to evaluate how a design justice methodology can be used in the context of designing LLMs-based social robotics.\nMajor Findings:\nAnalysis and Critique:\nThe study presents a novel methodological approach based on previous work on design justice in AI and HRI. The approach enables the identification and validation of ethical concerns through empirical design justice-based data from diverse participants. However, the study also highlights limitations, such as the inability to confidently determine ethical considerations in"
  },
  {
    "objectID": "posts/An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics/2024-06-10-An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics.html#appendix",
    "href": "posts/An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics/2024-06-10-An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics.html#appendix",
    "title": "An Empirical Design Justice Approach to Identifying Ethical Considerations in the Intersection of Large Language Models and Social Robotics",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06400v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06400v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14471"
  },
  {
    "objectID": "posts/Reinforced_Prompt_Personalization_for_Recommendation_with_Large_Language_Models/2024-07-24-Reinforced_Prompt_Personalization_for_Recommendation_with_Large_Language_Models.html#appendix",
    "href": "posts/Reinforced_Prompt_Personalization_for_Recommendation_with_Large_Language_Models/2024-07-24-Reinforced_Prompt_Personalization_for_Recommendation_with_Large_Language_Models.html#appendix",
    "title": "Reinforced Prompt Personalization for Recommendation with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17115v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17115v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11227"
  },
  {
    "objectID": "posts/BertaQA_How_Much_Do_Language_Models_Know_About_Local_Culture/2024-06-11-BertaQA_How_Much_Do_Language_Models_Know_About_Local_Culture.html#appendix",
    "href": "posts/BertaQA_How_Much_Do_Language_Models_Know_About_Local_Culture/2024-06-11-BertaQA_How_Much_Do_Language_Models_Know_About_Local_Culture.html#appendix",
    "title": "BertaQA: How Much Do Language Models Know About Local Culture?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07302v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07302v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5979"
  },
  {
    "objectID": "posts/From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty/2024-07-08-From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty.html",
    "href": "posts/From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty/2024-07-08-From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty.html",
    "title": "From Loops to Oops: Fallback Behaviors of Language Models Under Uncertainty",
    "section": "",
    "text": "Summary:\nThe paper “From Loops to Oops: Fallback Behaviors of Language Models Under Uncertainty” investigates the undesirable behaviors of large language models (LLMs), such as hallucinations and sequence repetitions, and proposes to view these behaviors as fallbacks that models exhibit under uncertainty. The authors categorize fallback behaviors into sequence repetitions, degenerate text, and hallucinations, and extensively analyze them in models from the same family that differ by the amount of pretraining tokens, parameter count, or the inclusion of instruction-following training. The experiments reveal a clear and consistent ordering of fallback behaviors, with more advanced LLMs exhibiting more complex fallback behaviors. The same ordering is observed throughout a single generation, even for the best-performing models, as uncertainty increases. The paper also demonstrates that common decoding techniques, such as random sampling, might alleviate some unwanted behaviors like sequence repetitions but increase harder-to-detect hallucinations.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive analysis of the fallback behaviors of LLMs under uncertainty, offering valuable insights into the relationship between model complexity, training, and the emergence of different fallback behaviors. The authors’ categorization of fallback behaviors and their extensive experiments contribute to a better understanding of the limitations and challenges of LLMs. However, the paper does not discuss potential solutions to mitigate the identified issues or explore the implications of these findings for the development and deployment of LLMs in real-world applications. Additionally, the paper does not address the potential impact of different decoding strategies on the performance and reliability of LLMs. Further research is needed to investigate these aspects and develop more robust and reliable LLMs."
  },
  {
    "objectID": "posts/From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty/2024-07-08-From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty.html#appendix",
    "href": "posts/From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty/2024-07-08-From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty.html#appendix",
    "title": "From Loops to Oops: Fallback Behaviors of Language Models Under Uncertainty",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06071v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06071v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17045"
  },
  {
    "objectID": "posts/DaRec_A_Disentangled_Alignment_Framework_for_Large_Language_Model_and_Recommender_System/2024-08-15-DaRec_A_Disentangled_Alignment_Framework_for_Large_Language_Model_and_Recommender_System.html#summary-1",
    "href": "posts/DaRec_A_Disentangled_Alignment_Framework_for_Large_Language_Model_and_Recommender_System/2024-08-15-DaRec_A_Disentangled_Alignment_Framework_for_Large_Language_Model_and_Recommender_System.html#summary-1",
    "title": "DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System",
    "section": "Summary:",
    "text": "Summary:\nThe paper presents a novel plug-and-play alignment framework, DaRec, for large language models (LLMs) and collaborative models in recommendation systems. The authors theoretically prove that directly aligning the representations of LLMs and collaborative models is sub-optimal for enhancing downstream recommendation tasks performance. To address this issue, DaRec disentangles the latent representations of both LLMs and collaborative models into specific and shared components via projection layers and representation regularization. The proposed method then performs both global and local structure alignment on the shared representations to facilitate knowledge transfer. The authors also provide theoretical proof that the specific and shared representations contain more pertinent and less irrelevant information, which can enhance the effectiveness of downstream recommendation tasks. Extensive experimental results on benchmark datasets demonstrate the superiority of DaRec over existing state-of-the-art algorithms."
  },
  {
    "objectID": "posts/DaRec_A_Disentangled_Alignment_Framework_for_Large_Language_Model_and_Recommender_System/2024-08-15-DaRec_A_Disentangled_Alignment_Framework_for_Large_Language_Model_and_Recommender_System.html#major-findings",
    "href": "posts/DaRec_A_Disentangled_Alignment_Framework_for_Large_Language_Model_and_Recommender_System/2024-08-15-DaRec_A_Disentangled_Alignment_Framework_for_Large_Language_Model_and_Recommender_System.html#major-findings",
    "title": "DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nDirectly aligning the representations of LLMs and collaborative models is sub-optimal for enhancing downstream recommendation tasks performance.\nThe proposed DaRec framework disentangles the latent representations of both LLMs and collaborative models into specific and shared components, which can enhance the effectiveness of downstream recommendation tasks.\nDaRec performs both global and local structure alignment on the shared representations to facilitate knowledge transfer.\nThe specific and shared representations obtained by DaRec contain more pertinent and less irrelevant information, which can enhance the effectiveness of downstream recommendation tasks.\nExtensive experimental results on benchmark datasets demonstrate the superiority of DaRec over existing state-of-the-art algorithms."
  },
  {
    "objectID": "posts/DaRec_A_Disentangled_Alignment_Framework_for_Large_Language_Model_and_Recommender_System/2024-08-15-DaRec_A_Disentangled_Alignment_Framework_for_Large_Language_Model_and_Recommender_System.html#analysis-and-critique",
    "href": "posts/DaRec_A_Disentangled_Alignment_Framework_for_Large_Language_Model_and_Recommender_System/2024-08-15-DaRec_A_Disentangled_Alignment_Framework_for_Large_Language_Model_and_Recommender_System.html#analysis-and-critique",
    "title": "DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a novel and effective approach to aligning LLMs and collaborative models in recommendation systems. The authors provide a theoretical analysis of the limitations of existing alignment methods and propose a new framework, DaRec, to address these limitations. The proposed method is shown to be effective in enhancing the performance of downstream recommendation tasks.\nHowever, there are some potential limitations and areas for improvement. First, the proposed method requires the disentanglement of latent representations into specific and shared components, which may not always be feasible or accurate. Second, the proposed method relies on the availability of large-scale labeled data for training, which may not always be available. Finally, the proposed method may"
  },
  {
    "objectID": "posts/DaRec_A_Disentangled_Alignment_Framework_for_Large_Language_Model_and_Recommender_System/2024-08-15-DaRec_A_Disentangled_Alignment_Framework_for_Large_Language_Model_and_Recommender_System.html#appendix",
    "href": "posts/DaRec_A_Disentangled_Alignment_Framework_for_Large_Language_Model_and_Recommender_System/2024-08-15-DaRec_A_Disentangled_Alignment_Framework_for_Large_Language_Model_and_Recommender_System.html#appendix",
    "title": "DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.08231v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.08231v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8065"
  },
  {
    "objectID": "posts/Enhance_Modality_Robustness_in_Text_Centric_Multimodal_Alignment_with_Adversarial_Prompting/2024-08-19-Enhance_Modality_Robustness_in_Text_Centric_Multimodal_Alignment_with_Adversarial_Prompting.html#appendix",
    "href": "posts/Enhance_Modality_Robustness_in_Text_Centric_Multimodal_Alignment_with_Adversarial_Prompting/2024-08-19-Enhance_Modality_Robustness_in_Text_Centric_Multimodal_Alignment_with_Adversarial_Prompting.html#appendix",
    "title": "Enhance Modality Robustness in Text-Centric Multimodal Alignment with Adversarial Prompting",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09798v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09798v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5824"
  },
  {
    "objectID": "posts/Enhancing_Multi_hop_Reasoning_through_Knowledge_Erasure_in_Large_Language_Model_Editing/2024-08-22-Enhancing_Multi_hop_Reasoning_through_Knowledge_Erasure_in_Large_Language_Model_Editing.html#major-findings",
    "href": "posts/Enhancing_Multi_hop_Reasoning_through_Knowledge_Erasure_in_Large_Language_Model_Editing/2024-08-22-Enhancing_Multi_hop_Reasoning_through_Knowledge_Erasure_in_Large_Language_Model_Editing.html#major-findings",
    "title": "Enhancing Multi-hop Reasoning through Knowledge Erasure in Large Language Model Editing",
    "section": "Major Findings",
    "text": "Major Findings\n\nThe residual single-hop knowledge after editing causes edited models to revert to their original answers when processing multi-hop questions, undermining their performance in multi-hop reasoning tasks.\nThe proposed KELE method incorporates a knowledge erasure mechanism that eliminates old knowledge while injecting new knowledge, substantially enhancing the multi-hop reasoning capability of edited LLMs.\nExtensive experiments on GPT-J and GPT-2 XL demonstrate that KELE significantly improves the multi-hop reasoning ability of edited models."
  },
  {
    "objectID": "posts/Enhancing_Multi_hop_Reasoning_through_Knowledge_Erasure_in_Large_Language_Model_Editing/2024-08-22-Enhancing_Multi_hop_Reasoning_through_Knowledge_Erasure_in_Large_Language_Model_Editing.html#analysis-and-critique",
    "href": "posts/Enhancing_Multi_hop_Reasoning_through_Knowledge_Erasure_in_Large_Language_Model_Editing/2024-08-22-Enhancing_Multi_hop_Reasoning_through_Knowledge_Erasure_in_Large_Language_Model_Editing.html#analysis-and-critique",
    "title": "Enhancing Multi-hop Reasoning through Knowledge Erasure in Large Language Model Editing",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\n\nThe paper provides a well-structured and coherent summary of the proposed method and its evaluation, highlighting the importance of addressing the challenges in multi-hop reasoning tasks.\nThe authors’ hypothesis regarding the impact of residual single-hop knowledge on multi-hop reasoning tasks is well-supported by empirical evidence and cognitive neuroscience insights.\nThe proposed KELE method effectively addresses the limitations of existing knowledge editing techniques, offering a promising approach to enhancing the multi-hop reasoning capabilities of LLMs.\nHowever, the paper does not discuss potential limitations or unanswered questions, such as the scalability of the KELE method for larger models or the impact of the erasure function on the overall performance of the model.\nAdditionally, the paper does not address potential biases or conflicting evidence that may arise during the knowledge editing process, which could be important considerations for future research.\n\nIn conclusion, the paper presents a novel and effective knowledge editing method, KELE, that significantly enhances the multi-hop reasoning capabilities of edited LLMs. The authors provide a well-structured and coherent summary of their findings, supported by empirical evidence and cognitive neuroscience insights. However, further research is needed to address potential limitations, unanswered questions, and conflic"
  },
  {
    "objectID": "posts/Enhancing_Multi_hop_Reasoning_through_Knowledge_Erasure_in_Large_Language_Model_Editing/2024-08-22-Enhancing_Multi_hop_Reasoning_through_Knowledge_Erasure_in_Large_Language_Model_Editing.html#appendix",
    "href": "posts/Enhancing_Multi_hop_Reasoning_through_Knowledge_Erasure_in_Large_Language_Model_Editing/2024-08-22-Enhancing_Multi_hop_Reasoning_through_Knowledge_Erasure_in_Large_Language_Model_Editing.html#appendix",
    "title": "Enhancing Multi-hop Reasoning through Knowledge Erasure in Large Language Model Editing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12456v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12456v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8285"
  },
  {
    "objectID": "posts/Can_Large_Language_Models_Understand_DL_Lite_Ontologies_An_Empirical_Study/2024-06-25-Can_Large_Language_Models_Understand_DL_Lite_Ontologies_An_Empirical_Study.html#appendix",
    "href": "posts/Can_Large_Language_Models_Understand_DL_Lite_Ontologies_An_Empirical_Study/2024-06-25-Can_Large_Language_Models_Understand_DL_Lite_Ontologies_An_Empirical_Study.html#appendix",
    "title": "Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17532v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17532v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10388"
  },
  {
    "objectID": "posts/Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model/2024-07-03-Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model.html#major-findings",
    "href": "posts/Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model/2024-07-03-Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model.html#major-findings",
    "title": "Raw Text is All you Need: Knowledge-intensive Multi-turn Instruction Tuning for Large Language Model",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe proposed R2S framework allows LLMs to generate dialogues that are coherent, contextually relevant, and embed rich, domain-specific knowledge into conversations.\nThe creation of a comprehensive knowledge-intensive benchmark, k-Bench, facilitates the training and evaluation of the proposed methods, covering a diverse range of topics and serving as a vital resource for assessing the effectiveness of CoD and the overall framework.\nThe synthetic instruction dataset gInstruct retains an extensive amount of knowledge from the raw documents in a dialogue format, which is used to fine-tune an open-source LLM, referred to as gLLM. The experimental results demonstrate that this synthetic instruction approach is highly effective in enhancing the SFT model, enabling it to excel across various performance metrics."
  },
  {
    "objectID": "posts/Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model/2024-07-03-Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model.html#analysis-and-critique",
    "href": "posts/Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model/2024-07-03-Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model.html#analysis-and-critique",
    "title": "Raw Text is All you Need: Knowledge-intensive Multi-turn Instruction Tuning for Large Language Model",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper does not discuss the potential limitations of the proposed framework, such as the computational resources required for generating and fine-tuning the gLLM model.\nThe paper does not address the potential biases that may be introduced during the data collection and processing stages, which could impact the performance of the gLLM model.\nThe paper does not provide a comprehensive comparison with other existing methods for generating multi-turn dialogues for instruction tuning, which could help to better understand the advantages and disadvantages of the proposed approach.\nThe paper does not discuss the potential applications and use cases of"
  },
  {
    "objectID": "posts/Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model/2024-07-03-Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model.html#appendix",
    "href": "posts/Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model/2024-07-03-Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model.html#appendix",
    "title": "Raw Text is All you Need: Knowledge-intensive Multi-turn Instruction Tuning for Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03040v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03040v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5924"
  },
  {
    "objectID": "posts/ULLME_A_Unified_Framework_for_Large_Language_Model_Embeddings_with_Generation_Augmented_Learning/2024-08-06-ULLME_A_Unified_Framework_for_Large_Language_Model_Embeddings_with_Generation_Augmented_Learning.html#appendix",
    "href": "posts/ULLME_A_Unified_Framework_for_Large_Language_Model_Embeddings_with_Generation_Augmented_Learning/2024-08-06-ULLME_A_Unified_Framework_for_Large_Language_Model_Embeddings_with_Generation_Augmented_Learning.html#appendix",
    "title": "ULLME: A Unified Framework for Large Language Model Embeddings with Generation-Augmented Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03402v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03402v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5397"
  },
  {
    "objectID": "posts/TokenSHAP_Interpreting_Large_Language_Models_with_Monte_Carlo_Shapley_Value_Estimation/2024-07-14-TokenSHAP_Interpreting_Large_Language_Models_with_Monte_Carlo_Shapley_Value_Estimation.html#appendix",
    "href": "posts/TokenSHAP_Interpreting_Large_Language_Models_with_Monte_Carlo_Shapley_Value_Estimation/2024-07-14-TokenSHAP_Interpreting_Large_Language_Models_with_Monte_Carlo_Shapley_Value_Estimation.html#appendix",
    "title": "TokenSHAP: Interpreting Large Language Models with Monte Carlo Shapley Value Estimation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10114v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10114v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3919"
  },
  {
    "objectID": "posts/Behavioral_Testing_Can_Large_Language_Models_Implicitly_Resolve_Ambiguous_Entities/2024-07-25-Behavioral_Testing_Can_Large_Language_Models_Implicitly_Resolve_Ambiguous_Entities.html#appendix",
    "href": "posts/Behavioral_Testing_Can_Large_Language_Models_Implicitly_Resolve_Ambiguous_Entities/2024-07-25-Behavioral_Testing_Can_Large_Language_Models_Implicitly_Resolve_Ambiguous_Entities.html#appendix",
    "title": "Behavioral Testing: Can Large Language Models Implicitly Resolve Ambiguous Entities?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17125v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17125v2\n\n\nTruncated\nFalse\n\n\nWord Count\n7094"
  },
  {
    "objectID": "posts/GraphEval_A_Knowledge_Graph_Based_LLM_Hallucination_Evaluation_Framework/2024-07-15-GraphEval_A_Knowledge_Graph_Based_LLM_Hallucination_Evaluation_Framework.html#appendix",
    "href": "posts/GraphEval_A_Knowledge_Graph_Based_LLM_Hallucination_Evaluation_Framework/2024-07-15-GraphEval_A_Knowledge_Graph_Based_LLM_Hallucination_Evaluation_Framework.html#appendix",
    "title": "GraphEval: A Knowledge-Graph Based LLM Hallucination Evaluation Framework",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10793v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10793v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5868"
  },
  {
    "objectID": "posts/A_Tool_for_Test_Case_Scenarios_Generation_Using_Large_Language_Models/2024-06-11-A_Tool_for_Test_Case_Scenarios_Generation_Using_Large_Language_Models.html#appendix",
    "href": "posts/A_Tool_for_Test_Case_Scenarios_Generation_Using_Large_Language_Models/2024-06-11-A_Tool_for_Test_Case_Scenarios_Generation_Using_Large_Language_Models.html#appendix",
    "title": "A Tool for Test Case Scenarios Generation Using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07021v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07021v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3062"
  },
  {
    "objectID": "posts/REPOEXEC_Evaluate_Code_Generation_with_a_Repository_Level_Executable_Benchmark/2024-06-17-REPOEXEC_Evaluate_Code_Generation_with_a_Repository_Level_Executable_Benchmark.html#appendix",
    "href": "posts/REPOEXEC_Evaluate_Code_Generation_with_a_Repository_Level_Executable_Benchmark/2024-06-17-REPOEXEC_Evaluate_Code_Generation_with_a_Repository_Level_Executable_Benchmark.html#appendix",
    "title": "REPOEXEC: Evaluate Code Generation with a Repository-Level Executable Benchmark",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11927v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11927v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7146"
  },
  {
    "objectID": "posts/Video_Watermarking_Safeguarding_Your_Video_from_(Unauthorized)_Annotations_by_Video_based_LLMs/2024-07-03-Video_Watermarking_Safeguarding_Your_Video_from_(Unauthorized)_Annotations_by_Video_based_LLMs.html#appendix",
    "href": "posts/Video_Watermarking_Safeguarding_Your_Video_from_(Unauthorized)_Annotations_by_Video_based_LLMs/2024-07-03-Video_Watermarking_Safeguarding_Your_Video_from_(Unauthorized)_Annotations_by_Video_based_LLMs.html#appendix",
    "title": "Video Watermarking: Safeguarding Your Video from (Unauthorized) Annotations by Video-based LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02411v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02411v2\n\n\nTruncated\nFalse\n\n\nWord Count\n6556"
  },
  {
    "objectID": "posts/LLM_Driven_Multimodal_Opinion_Expression_Identification/2024-06-26-LLM_Driven_Multimodal_Opinion_Expression_Identification.html#appendix",
    "href": "posts/LLM_Driven_Multimodal_Opinion_Expression_Identification/2024-06-26-LLM_Driven_Multimodal_Opinion_Expression_Identification.html#appendix",
    "title": "LLM-Driven Multimodal Opinion Expression Identification",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18088v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18088v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4217"
  },
  {
    "objectID": "posts/Data_Augmentation_Integrating_Dialogue_Flow_and_Style_to_Adapt_Spoken_Dialogue_Systems_to_Low_Resource_User_Groups/2024-08-20-Data_Augmentation_Integrating_Dialogue_Flow_and_Style_to_Adapt_Spoken_Dialogue_Systems_to_Low_Resource_User_Groups.html#appendix",
    "href": "posts/Data_Augmentation_Integrating_Dialogue_Flow_and_Style_to_Adapt_Spoken_Dialogue_Systems_to_Low_Resource_User_Groups/2024-08-20-Data_Augmentation_Integrating_Dialogue_Flow_and_Style_to_Adapt_Spoken_Dialogue_Systems_to_Low_Resource_User_Groups.html#appendix",
    "title": "Data Augmentation Integrating Dialogue Flow and Style to Adapt Spoken Dialogue Systems to Low-Resource User Groups",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10516v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10516v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5983"
  },
  {
    "objectID": "posts/Can_Watermarking_Large_Language_Models_Prevent_Copyrighted_Text_Generation_and_Hide_Training_Data/2024-07-24-Can_Watermarking_Large_Language_Models_Prevent_Copyrighted_Text_Generation_and_Hide_Training_Data.html#appendix",
    "href": "posts/Can_Watermarking_Large_Language_Models_Prevent_Copyrighted_Text_Generation_and_Hide_Training_Data/2024-07-24-Can_Watermarking_Large_Language_Models_Prevent_Copyrighted_Text_Generation_and_Hide_Training_Data.html#appendix",
    "title": "Can Watermarking Large Language Models Prevent Copyrighted Text Generation and Hide Training Data?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17417v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17417v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7878"
  },
  {
    "objectID": "posts/From_Words_to_Worth_Newborn_Article_Impact_Prediction_with_LLM/2024-08-07-From_Words_to_Worth_Newborn_Article_Impact_Prediction_with_LLM.html#appendix",
    "href": "posts/From_Words_to_Worth_Newborn_Article_Impact_Prediction_with_LLM/2024-08-07-From_Words_to_Worth_Newborn_Article_Impact_Prediction_with_LLM.html#appendix",
    "title": "From Words to Worth: Newborn Article Impact Prediction with LLM",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03934v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03934v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1442"
  },
  {
    "objectID": "posts/Motamot_A_Dataset_for_Revealing_the_Supremacy_of_Large_Language_Models_over_Transformer_Models_in_Bengali_Political_Sentiment_Analysis/2024-07-28-Motamot_A_Dataset_for_Revealing_the_Supremacy_of_Large_Language_Models_over_Transformer_Models_in_Bengali_Political_Sentiment_Analysis.html#appendix",
    "href": "posts/Motamot_A_Dataset_for_Revealing_the_Supremacy_of_Large_Language_Models_over_Transformer_Models_in_Bengali_Political_Sentiment_Analysis/2024-07-28-Motamot_A_Dataset_for_Revealing_the_Supremacy_of_Large_Language_Models_over_Transformer_Models_in_Bengali_Political_Sentiment_Analysis.html#appendix",
    "title": "Motamot: A Dataset for Revealing the Supremacy of Large Language Models over Transformer Models in Bengali Political Sentiment Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19528v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19528v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5988"
  },
  {
    "objectID": "posts/Catching_Chameleons_Detecting_Evolving_Disinformation_Generated_using_Large_Language_Models/2024-06-26-Catching_Chameleons_Detecting_Evolving_Disinformation_Generated_using_Large_Language_Models.html#appendix",
    "href": "posts/Catching_Chameleons_Detecting_Evolving_Disinformation_Generated_using_Large_Language_Models/2024-06-26-Catching_Chameleons_Detecting_Evolving_Disinformation_Generated_using_Large_Language_Models.html#appendix",
    "title": "Catching Chameleons: Detecting Evolving Disinformation Generated using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17992v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17992v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7315"
  },
  {
    "objectID": "posts/Large_Language_Models_Make_Sample_Efficient_Recommender_Systems/2024-06-04-Large_Language_Models_Make_Sample_Efficient_Recommender_Systems.html#appendix",
    "href": "posts/Large_Language_Models_Make_Sample_Efficient_Recommender_Systems/2024-06-04-Large_Language_Models_Make_Sample_Efficient_Recommender_Systems.html#appendix",
    "title": "Large Language Models Make Sample-Efficient Recommender Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02368v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02368v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3649"
  },
  {
    "objectID": "posts/A_Study_on_Prompt_Injection_Attack_Against_LLM_Integrated_Mobile_Robotic_Systems/2024-08-07-A_Study_on_Prompt_Injection_Attack_Against_LLM_Integrated_Mobile_Robotic_Systems.html",
    "href": "posts/A_Study_on_Prompt_Injection_Attack_Against_LLM_Integrated_Mobile_Robotic_Systems/2024-08-07-A_Study_on_Prompt_Injection_Attack_Against_LLM_Integrated_Mobile_Robotic_Systems.html",
    "title": "A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems",
    "section": "",
    "text": "Summary:\nThe integration of Large Language Models (LLMs) into robotic systems has led to advancements in embodied artificial intelligence, enabling more context-aware responses. However, this integration also introduces security risks, particularly in robotic navigation tasks. This study investigates the impact of prompt injections on mobile robot performance in LLM-integrated systems and explores secure prompt strategies to mitigate these risks. The findings demonstrate a substantial overall improvement of approximately 30.8% in both attack detection and system performance with the implementation of robust defence mechanisms.\nMajor Findings:\nAnalysis and Critique:\nWhile the study provides valuable insights into the security implications of LLM-integrated robotic systems, there are potential limitations and areas for further research. The study primarily focuses on the detection and mitigation of prompt injection attacks, but other types of attacks, such as data poisoning or model inversion, may also pose significant threats. Additionally, the study does not address the potential impact of these attacks on the physical environment or human safety. Further research is needed to explore these aspects and develop comprehensive security strategies for LLM-integrated robotic systems."
  },
  {
    "objectID": "posts/A_Study_on_Prompt_Injection_Attack_Against_LLM_Integrated_Mobile_Robotic_Systems/2024-08-07-A_Study_on_Prompt_Injection_Attack_Against_LLM_Integrated_Mobile_Robotic_Systems.html#appendix",
    "href": "posts/A_Study_on_Prompt_Injection_Attack_Against_LLM_Integrated_Mobile_Robotic_Systems/2024-08-07-A_Study_on_Prompt_Injection_Attack_Against_LLM_Integrated_Mobile_Robotic_Systems.html#appendix",
    "title": "A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03515v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03515v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5793"
  },
  {
    "objectID": "posts/GUI_Action_Narrator_Where_and_When_Did_That_Action_Take_Place/2024-06-19-GUI_Action_Narrator_Where_and_When_Did_That_Action_Take_Place.html#appendix",
    "href": "posts/GUI_Action_Narrator_Where_and_When_Did_That_Action_Take_Place/2024-06-19-GUI_Action_Narrator_Where_and_When_Did_That_Action_Take_Place.html#appendix",
    "title": "GUI Action Narrator: Where and When Did That Action Take Place?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13719v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13719v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6190"
  },
  {
    "objectID": "posts/Knowledge_Graph_Enhanced_Large_Language_Models_via_Path_Selection/2024-06-19-Knowledge_Graph_Enhanced_Large_Language_Models_via_Path_Selection.html#appendix",
    "href": "posts/Knowledge_Graph_Enhanced_Large_Language_Models_via_Path_Selection/2024-06-19-Knowledge_Graph_Enhanced_Large_Language_Models_via_Path_Selection.html#appendix",
    "title": "Knowledge Graph-Enhanced Large Language Models via Path Selection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13862v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13862v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6798"
  },
  {
    "objectID": "posts/Agent_Q_Advanced_Reasoning_and_Learning_for_Autonomous_AI_Agents/2024-08-13-Agent_Q_Advanced_Reasoning_and_Learning_for_Autonomous_AI_Agents.html#appendix",
    "href": "posts/Agent_Q_Advanced_Reasoning_and_Learning_for_Autonomous_AI_Agents/2024-08-13-Agent_Q_Advanced_Reasoning_and_Learning_for_Autonomous_AI_Agents.html#appendix",
    "title": "Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07199v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07199v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9890"
  },
  {
    "objectID": "posts/Towards_Explainable_Network_Intrusion_Detection_using_Large_Language_Models/2024-08-08-Towards_Explainable_Network_Intrusion_Detection_using_Large_Language_Models.html#major-findings",
    "href": "posts/Towards_Explainable_Network_Intrusion_Detection_using_Large_Language_Models/2024-08-08-Towards_Explainable_Network_Intrusion_Detection_using_Large_Language_Models.html#major-findings",
    "title": "Towards Explainable Network Intrusion Detection using Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nLLMs, such as GPT-4 and LLama3, struggle with precise attack detection in the context of NIDS.\nLLMs have significant potential as complementary agents in NIDS, particularly in providing explanations and aiding in threat response.\nIntegrating LLMs with RAG and function calling capabilities can enhance their utility in NIDS."
  },
  {
    "objectID": "posts/Towards_Explainable_Network_Intrusion_Detection_using_Large_Language_Models/2024-08-08-Towards_Explainable_Network_Intrusion_Detection_using_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/Towards_Explainable_Network_Intrusion_Detection_using_Large_Language_Models/2024-08-08-Towards_Explainable_Network_Intrusion_Detection_using_Large_Language_Models.html#analysis-and-critique",
    "title": "Towards Explainable Network Intrusion Detection using Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper provides a valuable exploration of the potential of LLMs in the context of NIDS.\nThe authors acknowledge the limitations of LLMs in precise attack detection, which is a crucial aspect of NIDS.\nThe paper highlights the potential of LLMs as complementary agents in NIDS, particularly in providing explanations and aiding in threat response.\nThe authors suggest integrating LLMs with RAG and function calling capabilities, which could be a promising direction for future research.\nHowever, the paper does not provide a comprehensive evaluation of the performance of LLMs in NIDS, and further research is needed to fully understand their potential and limitations.\nThe paper also does not discuss the potential ethical implications of using LLMs in NIDS, such as privacy concerns and the potential for bias in threat detection.\nOverall, the paper provides a useful starting point for exploring the potential of LLMs in NIDS, but further research is needed to fully understand their potential and limitations."
  },
  {
    "objectID": "posts/Towards_Explainable_Network_Intrusion_Detection_using_Large_Language_Models/2024-08-08-Towards_Explainable_Network_Intrusion_Detection_using_Large_Language_Models.html#appendix",
    "href": "posts/Towards_Explainable_Network_Intrusion_Detection_using_Large_Language_Models/2024-08-08-Towards_Explainable_Network_Intrusion_Detection_using_Large_Language_Models.html#appendix",
    "title": "Towards Explainable Network Intrusion Detection using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04342v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04342v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5374"
  },
  {
    "objectID": "posts/Can_We_Rely_on_LLM_Agents_to_Draft_Long_Horizon_Plans_Lets_Take_TravelPlanner_as_an_Example/2024-08-12-Can_We_Rely_on_LLM_Agents_to_Draft_Long_Horizon_Plans_Lets_Take_TravelPlanner_as_an_Example.html#major-findings",
    "href": "posts/Can_We_Rely_on_LLM_Agents_to_Draft_Long_Horizon_Plans_Lets_Take_TravelPlanner_as_an_Example/2024-08-12-Can_We_Rely_on_LLM_Agents_to_Draft_Long_Horizon_Plans_Lets_Take_TravelPlanner_as_an_Example.html#major-findings",
    "title": "Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let’s Take TravelPlanner as an Example",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nLLMs often fail to attend to crucial parts of a long context, despite their ability to handle extensive reference information and few-shot examples.\nLLMs still struggle with analyzing long plans and cannot provide accurate feedback for refinement.\nFeedback-Aware Fine-Tuning (FAFT), which leverages both positive and negative feedback, results in substantial gains over Supervised Fine-Tuning (SFT)."
  },
  {
    "objectID": "posts/Can_We_Rely_on_LLM_Agents_to_Draft_Long_Horizon_Plans_Lets_Take_TravelPlanner_as_an_Example/2024-08-12-Can_We_Rely_on_LLM_Agents_to_Draft_Long_Horizon_Plans_Lets_Take_TravelPlanner_as_an_Example.html#analysis-and-critique",
    "href": "posts/Can_We_Rely_on_LLM_Agents_to_Draft_Long_Horizon_Plans_Lets_Take_TravelPlanner_as_an_Example/2024-08-12-Can_We_Rely_on_LLM_Agents_to_Draft_Long_Horizon_Plans_Lets_Take_TravelPlanner_as_an_Example.html#analysis-and-critique",
    "title": "Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let’s Take TravelPlanner as an Example",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper provides valuable insights into the limitations of LLM-based agents in complex planning tasks. However, the study is limited by the use of only GPT-3.5-Turbo as the Planner agent for RQ1 and RQ2 due to budget constraints. Further investigations are needed to explore the relationship between the magnitude of gains and the size of the FAFT training set, as well as the impact of the ratio of positive to negative samples on the final performance. Additionally, enhancing the feedback expressions could further improve the performance of FAFT. It would also be interesting to investigate RLHF techniques, such as DPO and PRO, to better utilize feedback.\nThe paper adheres to the original work’s specifications, utilizing their data, evaluation scripts, and definitions of commonsense. The authors strictly adhere to TravelPlanner’s guidelines, ensuring the integrity of the evaluation process by prohibiting any form of cheating in the validation and test sets. However, the extensive experiments required for this study have a significant environmental cost. Future endeavors can leverage these insights, potentially reducing the need for numerous large-scale comparisons. Models intended for production could undergo"
  },
  {
    "objectID": "posts/Can_We_Rely_on_LLM_Agents_to_Draft_Long_Horizon_Plans_Lets_Take_TravelPlanner_as_an_Example/2024-08-12-Can_We_Rely_on_LLM_Agents_to_Draft_Long_Horizon_Plans_Lets_Take_TravelPlanner_as_an_Example.html#appendix",
    "href": "posts/Can_We_Rely_on_LLM_Agents_to_Draft_Long_Horizon_Plans_Lets_Take_TravelPlanner_as_an_Example/2024-08-12-Can_We_Rely_on_LLM_Agents_to_Draft_Long_Horizon_Plans_Lets_Take_TravelPlanner_as_an_Example.html#appendix",
    "title": "Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let’s Take TravelPlanner as an Example",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.06318v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.06318v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6085"
  },
  {
    "objectID": "posts/Animate_or_Inanimate_That_is_the_Question_for_Large_Language_Models/2024-08-12-Animate_or_Inanimate_That_is_the_Question_for_Large_Language_Models.html#appendix",
    "href": "posts/Animate_or_Inanimate_That_is_the_Question_for_Large_Language_Models/2024-08-12-Animate_or_Inanimate_That_is_the_Question_for_Large_Language_Models.html#appendix",
    "title": "Animate, or Inanimate, That is the Question for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.06332v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.06332v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6451"
  },
  {
    "objectID": "posts/Explicit_and_Implicit_Large_Language_Model_Personas_Generate_Opinions_but_Fail_to_Replicate_Deeper_Perceptions_and_Biases/2024-06-20-Explicit_and_Implicit_Large_Language_Model_Personas_Generate_Opinions_but_Fail_to_Replicate_Deeper_Perceptions_and_Biases.html#appendix",
    "href": "posts/Explicit_and_Implicit_Large_Language_Model_Personas_Generate_Opinions_but_Fail_to_Replicate_Deeper_Perceptions_and_Biases/2024-06-20-Explicit_and_Implicit_Large_Language_Model_Personas_Generate_Opinions_but_Fail_to_Replicate_Deeper_Perceptions_and_Biases.html#appendix",
    "title": "Explicit and Implicit Large Language Model Personas Generate Opinions but Fail to Replicate Deeper Perceptions and Biases",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14462v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14462v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6689"
  },
  {
    "objectID": "posts/Probability_of_Differentiation_Reveals_Brittleness_of_Homogeneity_Bias_in_Large_Language_Models/2024-07-10-Probability_of_Differentiation_Reveals_Brittleness_of_Homogeneity_Bias_in_Large_Language_Models.html#appendix",
    "href": "posts/Probability_of_Differentiation_Reveals_Brittleness_of_Homogeneity_Bias_in_Large_Language_Models/2024-07-10-Probability_of_Differentiation_Reveals_Brittleness_of_Homogeneity_Bias_in_Large_Language_Models.html#appendix",
    "title": "Probability of Differentiation Reveals Brittleness of Homogeneity Bias in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07329v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07329v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6590"
  },
  {
    "objectID": "posts/Genetic_Instruct_Scaling_up_Synthetic_Generation_of_Coding_Instructions_for_Large_Language_Models/2024-07-29-Genetic_Instruct_Scaling_up_Synthetic_Generation_of_Coding_Instructions_for_Large_Language_Models.html#appendix",
    "href": "posts/Genetic_Instruct_Scaling_up_Synthetic_Generation_of_Coding_Instructions_for_Large_Language_Models/2024-07-29-Genetic_Instruct_Scaling_up_Synthetic_Generation_of_Coding_Instructions_for_Large_Language_Models.html#appendix",
    "title": "Genetic Instruct: Scaling up Synthetic Generation of Coding Instructions for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21077v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21077v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5982"
  },
  {
    "objectID": "posts/Revolutionizing_Bridge_Operation_and_maintenance_with_LLM_based_Agents_An_Overview_of_Applications_and_Insights/2024-07-14-Revolutionizing_Bridge_Operation_and_maintenance_with_LLM_based_Agents_An_Overview_of_Applications_and_Insights.html#appendix",
    "href": "posts/Revolutionizing_Bridge_Operation_and_maintenance_with_LLM_based_Agents_An_Overview_of_Applications_and_Insights/2024-07-14-Revolutionizing_Bridge_Operation_and_maintenance_with_LLM_based_Agents_An_Overview_of_Applications_and_Insights.html#appendix",
    "title": "Revolutionizing Bridge Operation and maintenance with LLM-based Agents: An Overview of Applications and Insights",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10064v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10064v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11852"
  },
  {
    "objectID": "posts/An_Investigation_of_Prompt_Variations_for_Zero_shot_LLM_based_Rankers/2024-06-20-An_Investigation_of_Prompt_Variations_for_Zero_shot_LLM_based_Rankers.html#appendix",
    "href": "posts/An_Investigation_of_Prompt_Variations_for_Zero_shot_LLM_based_Rankers/2024-06-20-An_Investigation_of_Prompt_Variations_for_Zero_shot_LLM_based_Rankers.html#appendix",
    "title": "An Investigation of Prompt Variations for Zero-shot LLM-based Rankers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14117v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14117v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7110"
  },
  {
    "objectID": "posts/Large_Language_Models_Prompting_With_Episodic_Memory/2024-08-14-Large_Language_Models_Prompting_With_Episodic_Memory.html#appendix",
    "href": "posts/Large_Language_Models_Prompting_With_Episodic_Memory/2024-08-14-Large_Language_Models_Prompting_With_Episodic_Memory.html#appendix",
    "title": "Large Language Models Prompting With Episodic Memory",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07465v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07465v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6949"
  },
  {
    "objectID": "posts/Poisoned_LangChain_Jailbreak_LLMs_by_LangChain/2024-06-26-Poisoned_LangChain_Jailbreak_LLMs_by_LangChain.html#appendix",
    "href": "posts/Poisoned_LangChain_Jailbreak_LLMs_by_LangChain/2024-06-26-Poisoned_LangChain_Jailbreak_LLMs_by_LangChain.html#appendix",
    "title": "Poisoned LangChain: Jailbreak LLMs by LangChain",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18122v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18122v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4003"
  },
  {
    "objectID": "posts/A_Teacher_Is_Worth_A_Million_Instructions/2024-06-27-A_Teacher_Is_Worth_A_Million_Instructions.html#appendix",
    "href": "posts/A_Teacher_Is_Worth_A_Million_Instructions/2024-06-27-A_Teacher_Is_Worth_A_Million_Instructions.html#appendix",
    "title": "A Teacher Is Worth A Million Instructions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19112v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19112v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5345"
  },
  {
    "objectID": "posts/Mix_CPT_A_Domain_Adaptation_Framework_via_Decoupling_Knowledge_Learning_and_Format_Alignment/2024-07-15-Mix_CPT_A_Domain_Adaptation_Framework_via_Decoupling_Knowledge_Learning_and_Format_Alignment.html#appendix",
    "href": "posts/Mix_CPT_A_Domain_Adaptation_Framework_via_Decoupling_Knowledge_Learning_and_Format_Alignment/2024-07-15-Mix_CPT_A_Domain_Adaptation_Framework_via_Decoupling_Knowledge_Learning_and_Format_Alignment.html#appendix",
    "title": "Mix-CPT: A Domain Adaptation Framework via Decoupling Knowledge Learning and Format Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10804v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10804v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8459"
  },
  {
    "objectID": "posts/Keep_the_Cost_Down_A_Review_on_Methods_to_Optimize_LLM_s_KV_Cache_Consumption/2024-07-25-Keep_the_Cost_Down_A_Review_on_Methods_to_Optimize_LLM_s_KV_Cache_Consumption.html#appendix",
    "href": "posts/Keep_the_Cost_Down_A_Review_on_Methods_to_Optimize_LLM_s_KV_Cache_Consumption/2024-07-25-Keep_the_Cost_Down_A_Review_on_Methods_to_Optimize_LLM_s_KV_Cache_Consumption.html#appendix",
    "title": "Keep the Cost Down: A Review on Methods to Optimize LLM’ s KV-Cache Consumption",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.18003v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.18003v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7020"
  },
  {
    "objectID": "posts/Physics_of_Language_Models_Part_2.1_Grade_School_Math_and_the_Hidden_Reasoning_Process/2024-07-29-Physics_of_Language_Models_Part_2.1_Grade_School_Math_and_the_Hidden_Reasoning_Process.html",
    "href": "posts/Physics_of_Language_Models_Part_2.1_Grade_School_Math_and_the_Hidden_Reasoning_Process/2024-07-29-Physics_of_Language_Models_Part_2.1_Grade_School_Math_and_the_Hidden_Reasoning_Process.html",
    "title": "Physics of Language Models: Part 2.1, Grade-School Math and the Hidden Reasoning Process",
    "section": "",
    "text": "Summary: The paper investigates the performance of language models, specifically GPT2, in solving grade-school math problems. The study uses a synthetic dataset called iGSM to train and test the model, demonstrating that GPT2 can achieve high accuracy and learn to generate shortest solutions. The paper also introduces V-probing, a nearly-linear probing method, to analyze the model’s performance on various tasks. The results indicate that the model can solve math problems like humans and even learn beyond human reasoning skills. The study also examines the reasoning mistakes made by the language models, finding that many are systematic and stem from errors in their mental process. The paper concludes by discussing the importance of the depth of the language model for its reasoning ability.\nMajor Findings:"
  },
  {
    "objectID": "posts/Physics_of_Language_Models_Part_2.1_Grade_School_Math_and_the_Hidden_Reasoning_Process/2024-07-29-Physics_of_Language_Models_Part_2.1_Grade_School_Math_and_the_Hidden_Reasoning_Process.html#appendix",
    "href": "posts/Physics_of_Language_Models_Part_2.1_Grade_School_Math_and_the_Hidden_Reasoning_Process/2024-07-29-Physics_of_Language_Models_Part_2.1_Grade_School_Math_and_the_Hidden_Reasoning_Process.html#appendix",
    "title": "Physics of Language Models: Part 2.1, Grade-School Math and the Hidden Reasoning Process",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20311v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20311v1\n\n\nTruncated\nTrue\n\n\nWord Count\n38551"
  },
  {
    "objectID": "posts/Leveraging_Language_Models_for_Emotion_and_Behavior_Analysis_in_Education/2024-08-13-Leveraging_Language_Models_for_Emotion_and_Behavior_Analysis_in_Education.html#appendix",
    "href": "posts/Leveraging_Language_Models_for_Emotion_and_Behavior_Analysis_in_Education/2024-08-13-Leveraging_Language_Models_for_Emotion_and_Behavior_Analysis_in_Education.html#appendix",
    "title": "Leveraging Language Models for Emotion and Behavior Analysis in Education",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.06874v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.06874v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3706"
  },
  {
    "objectID": "posts/NormTab_Improving_Symbolic_Reasoning_in_LLMs_Through_Tabular_Data_Normalization/2024-06-25-NormTab_Improving_Symbolic_Reasoning_in_LLMs_Through_Tabular_Data_Normalization.html#appendix",
    "href": "posts/NormTab_Improving_Symbolic_Reasoning_in_LLMs_Through_Tabular_Data_Normalization/2024-06-25-NormTab_Improving_Symbolic_Reasoning_in_LLMs_Through_Tabular_Data_Normalization.html#appendix",
    "title": "NormTab: Improving Symbolic Reasoning in LLMs Through Tabular Data Normalization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17961v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17961v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6898"
  },
  {
    "objectID": "posts/Towards_Synthetic_Trace_Generation_of_Modeling_Operations_using_In_Context_Learning_Approach/2024-08-26-Towards_Synthetic_Trace_Generation_of_Modeling_Operations_using_In_Context_Learning_Approach.html#appendix",
    "href": "posts/Towards_Synthetic_Trace_Generation_of_Modeling_Operations_using_In_Context_Learning_Approach/2024-08-26-Towards_Synthetic_Trace_Generation_of_Modeling_Operations_using_In_Context_Learning_Approach.html#appendix",
    "title": "Towards Synthetic Trace Generation of Modeling Operations using In-Context Learning Approach",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.14259v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.14259v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11478"
  },
  {
    "objectID": "posts/Agent_Driven_Automatic_Software_Improvement/2024-06-24-Agent_Driven_Automatic_Software_Improvement.html#appendix",
    "href": "posts/Agent_Driven_Automatic_Software_Improvement/2024-06-24-Agent_Driven_Automatic_Software_Improvement.html#appendix",
    "title": "Agent-Driven Automatic Software Improvement",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16739v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16739v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5961"
  },
  {
    "objectID": "posts/HIGHT_Hierarchical_Graph_Tokenization_for_Graph_Language_Alignment/2024-06-20-HIGHT_Hierarchical_Graph_Tokenization_for_Graph_Language_Alignment.html#appendix",
    "href": "posts/HIGHT_Hierarchical_Graph_Tokenization_for_Graph_Language_Alignment/2024-06-20-HIGHT_Hierarchical_Graph_Tokenization_for_Graph_Language_Alignment.html#appendix",
    "title": "HIGHT: Hierarchical Graph Tokenization for Graph-Language Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14021v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14021v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11102"
  },
  {
    "objectID": "posts/Are_Large_Language_Models_Possible_to_Conduct_Cognitive_Behavioral_Therapy/2024-07-25-Are_Large_Language_Models_Possible_to_Conduct_Cognitive_Behavioral_Therapy.html#major-findings",
    "href": "posts/Are_Large_Language_Models_Possible_to_Conduct_Cognitive_Behavioral_Therapy/2024-07-25-Are_Large_Language_Models_Possible_to_Conduct_Cognitive_Behavioral_Therapy.html#major-findings",
    "title": "Are Large Language Models Possible to Conduct Cognitive Behavioral Therapy?",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe study found that LLMs can generate CBT dialogue text with high text diversity, semantic similarity, and text fluency. The models also demonstrated active questioning ability, which is crucial in CBT.\nThe integration of a CBT knowledge base with LLMs can enhance the models’ CBT counseling ability. The experimental results showed that the integrated models could generate more concise and realistic dialogue text, which is more in line with the dialogue style and pattern of a psychotherapist and a patient in real-life scenarios.\nThe study also highlighted some limitations of the experiment, such as the limited number of CBT dialogues collected and the limited knowledge base, which may not cover comprehensive knowledge of CBT. Additionally, CBT based on LLM involves the patient’s privacy and personal information, which may pose privacy and security risks."
  },
  {
    "objectID": "posts/Are_Large_Language_Models_Possible_to_Conduct_Cognitive_Behavioral_Therapy/2024-07-25-Are_Large_Language_Models_Possible_to_Conduct_Cognitive_Behavioral_Therapy.html#analysis-and-critique",
    "href": "posts/Are_Large_Language_Models_Possible_to_Conduct_Cognitive_Behavioral_Therapy/2024-07-25-Are_Large_Language_Models_Possible_to_Conduct_Cognitive_Behavioral_Therapy.html#analysis-and-critique",
    "title": "Are Large Language Models Possible to Conduct Cognitive Behavioral Therapy?",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper provides a comprehensive evaluation framework for assessing the CBT counseling ability of LLMs, which includes the evaluation of emotion tendency, structured dialogue pattern, and proactive inquiry ability. The study also explores the potential of integrating a CBT knowledge base with LLMs to enhance their CBT counseling ability. However, the paper has some limitations, such as the limited number of CBT dialogues collected and the limited knowledge base, which may not cover comprehensive knowledge of CBT. Additionally, the paper does not discuss the ethical and privacy concerns related to CBT based on LLMs. It is essential to address these concerns to ensure the safe and effective use of LLMs in psychological counseling."
  },
  {
    "objectID": "posts/Are_Large_Language_Models_Possible_to_Conduct_Cognitive_Behavioral_Therapy/2024-07-25-Are_Large_Language_Models_Possible_to_Conduct_Cognitive_Behavioral_Therapy.html#appendix",
    "href": "posts/Are_Large_Language_Models_Possible_to_Conduct_Cognitive_Behavioral_Therapy/2024-07-25-Are_Large_Language_Models_Possible_to_Conduct_Cognitive_Behavioral_Therapy.html#appendix",
    "title": "Are Large Language Models Possible to Conduct Cognitive Behavioral Therapy?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17730v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17730v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6869"
  },
  {
    "objectID": "posts/GenFollower_Enhancing_Car_Following_Prediction_with_Large_Language_Models/2024-07-08-GenFollower_Enhancing_Car_Following_Prediction_with_Large_Language_Models.html#appendix",
    "href": "posts/GenFollower_Enhancing_Car_Following_Prediction_with_Large_Language_Models/2024-07-08-GenFollower_Enhancing_Car_Following_Prediction_with_Large_Language_Models.html#appendix",
    "title": "GenFollower: Enhancing Car-Following Prediction with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05611v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05611v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7041"
  },
  {
    "objectID": "posts/A_Critical_Study_of_What_Code_LLMs_(Do_Not)_Learn/2024-06-17-A_Critical_Study_of_What_Code_LLMs_(Do_Not)_Learn.html#appendix",
    "href": "posts/A_Critical_Study_of_What_Code_LLMs_(Do_Not)_Learn/2024-06-17-A_Critical_Study_of_What_Code_LLMs_(Do_Not)_Learn.html#appendix",
    "title": "A Critical Study of What Code-LLMs (Do Not) Learn",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11930v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11930v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10566"
  },
  {
    "objectID": "posts/RiskAwareBench_Towards_Evaluating_Physical_Risk_Awareness_for_High_level_Planning_of_LLM_based_Embodied_Agents/2024-08-08-RiskAwareBench_Towards_Evaluating_Physical_Risk_Awareness_for_High_level_Planning_of_LLM_based_Embodied_Agents.html#appendix",
    "href": "posts/RiskAwareBench_Towards_Evaluating_Physical_Risk_Awareness_for_High_level_Planning_of_LLM_based_Embodied_Agents/2024-08-08-RiskAwareBench_Towards_Evaluating_Physical_Risk_Awareness_for_High_level_Planning_of_LLM_based_Embodied_Agents.html#appendix",
    "title": "RiskAwareBench: Towards Evaluating Physical Risk Awareness for High-level Planning of LLM-based Embodied Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04449v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04449v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7160"
  },
  {
    "objectID": "posts/EXAONE_3.0_7.8B_Instruction_Tuned_Language_Model/2024-08-08-EXAONE_3.0_7.8B_Instruction_Tuned_Language_Model.html#appendix",
    "href": "posts/EXAONE_3.0_7.8B_Instruction_Tuned_Language_Model/2024-08-08-EXAONE_3.0_7.8B_Instruction_Tuned_Language_Model.html#appendix",
    "title": "EXAONE 3.0 7.8B Instruction Tuned Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03541v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03541v2\n\n\nTruncated\nFalse\n\n\nWord Count\n8000"
  },
  {
    "objectID": "posts/Towards_Region_aware_Bias_Evaluation_Metrics/2024-06-23-Towards_Region_aware_Bias_Evaluation_Metrics.html#appendix",
    "href": "posts/Towards_Region_aware_Bias_Evaluation_Metrics/2024-06-23-Towards_Region_aware_Bias_Evaluation_Metrics.html#appendix",
    "title": "Towards Region-aware Bias Evaluation Metrics",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16152v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16152v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8427"
  },
  {
    "objectID": "posts/Stronger_Faster_and_Cheaper_Log_Parsing_with_LLMs/2024-06-10-Stronger_Faster_and_Cheaper_Log_Parsing_with_LLMs.html#appendix",
    "href": "posts/Stronger_Faster_and_Cheaper_Log_Parsing_with_LLMs/2024-06-10-Stronger_Faster_and_Cheaper_Log_Parsing_with_LLMs.html#appendix",
    "title": "Stronger, Faster, and Cheaper Log Parsing with LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06156v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06156v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11355"
  },
  {
    "objectID": "posts/Model_Enhanced_LLM_Driven_VUI_Testing_of_VPA_Apps/2024-07-03-Model_Enhanced_LLM_Driven_VUI_Testing_of_VPA_Apps.html#appendix",
    "href": "posts/Model_Enhanced_LLM_Driven_VUI_Testing_of_VPA_Apps/2024-07-03-Model_Enhanced_LLM_Driven_VUI_Testing_of_VPA_Apps.html#appendix",
    "title": "Model-Enhanced LLM-Driven VUI Testing of VPA Apps",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02791v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02791v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9664"
  },
  {
    "objectID": "posts/Building_AI_Agents_for_Autonomous_Clouds_Challenges_and_Design_Principles/2024-07-16-Building_AI_Agents_for_Autonomous_Clouds_Challenges_and_Design_Principles.html#appendix",
    "href": "posts/Building_AI_Agents_for_Autonomous_Clouds_Challenges_and_Design_Principles/2024-07-16-Building_AI_Agents_for_Autonomous_Clouds_Challenges_and_Design_Principles.html#appendix",
    "title": "Building AI Agents for Autonomous Clouds: Challenges and Design Principles",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.12165v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.12165v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7552"
  },
  {
    "objectID": "posts/DCA_Bench_A_Benchmark_for_Dataset_Curation_Agents/2024-06-11-DCA_Bench_A_Benchmark_for_Dataset_Curation_Agents.html#appendix",
    "href": "posts/DCA_Bench_A_Benchmark_for_Dataset_Curation_Agents/2024-06-11-DCA_Bench_A_Benchmark_for_Dataset_Curation_Agents.html#appendix",
    "title": "DCA-Bench: A Benchmark for Dataset Curation Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07275v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07275v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8553"
  },
  {
    "objectID": "posts/AutoRAG_HP_Automatic_Online_Hyper_Parameter_Tuning_for_Retrieval_Augmented_Generation/2024-06-27-AutoRAG_HP_Automatic_Online_Hyper_Parameter_Tuning_for_Retrieval_Augmented_Generation.html#appendix",
    "href": "posts/AutoRAG_HP_Automatic_Online_Hyper_Parameter_Tuning_for_Retrieval_Augmented_Generation/2024-06-27-AutoRAG_HP_Automatic_Online_Hyper_Parameter_Tuning_for_Retrieval_Augmented_Generation.html#appendix",
    "title": "AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19251v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19251v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7362"
  },
  {
    "objectID": "posts/MathViz_E_A_Case_study_in_Domain_Specialized_Tool_Using_Agents/2024-07-24-MathViz_E_A_Case_study_in_Domain_Specialized_Tool_Using_Agents.html#appendix",
    "href": "posts/MathViz_E_A_Case_study_in_Domain_Specialized_Tool_Using_Agents/2024-07-24-MathViz_E_A_Case_study_in_Domain_Specialized_Tool_Using_Agents.html#appendix",
    "title": "MathViz-E: A Case-study in Domain-Specialized Tool-Using Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17544v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17544v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5991"
  },
  {
    "objectID": "posts/LARR_Large_Language_Model_Aided_Real_time_Scene_Recommendation_with_Semantic_Understanding/2024-08-21-LARR_Large_Language_Model_Aided_Real_time_Scene_Recommendation_with_Semantic_Understanding.html#appendix",
    "href": "posts/LARR_Large_Language_Model_Aided_Real_time_Scene_Recommendation_with_Semantic_Understanding/2024-08-21-LARR_Large_Language_Model_Aided_Real_time_Scene_Recommendation_with_Semantic_Understanding.html#appendix",
    "title": "LARR: Large Language Model Aided Real-time Scene Recommendation with Semantic Understanding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11523v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11523v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8914"
  },
  {
    "objectID": "posts/3D_Properties_Identifying_Challenges_in_DPO_and_Charting_a_Path_Forward/2024-06-11-3D_Properties_Identifying_Challenges_in_DPO_and_Charting_a_Path_Forward.html#appendix",
    "href": "posts/3D_Properties_Identifying_Challenges_in_DPO_and_Charting_a_Path_Forward/2024-06-11-3D_Properties_Identifying_Challenges_in_DPO_and_Charting_a_Path_Forward.html#appendix",
    "title": "3D-Properties: Identifying Challenges in DPO and Charting a Path Forward",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07327v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07327v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8028"
  },
  {
    "objectID": "posts/How_Efficient_is_LLM_Generated_Code_A_Rigorous__High_Standard_Benchmark/2024-06-10-How_Efficient_is_LLM_Generated_Code_A_Rigorous__High_Standard_Benchmark.html#appendix",
    "href": "posts/How_Efficient_is_LLM_Generated_Code_A_Rigorous__High_Standard_Benchmark/2024-06-10-How_Efficient_is_LLM_Generated_Code_A_Rigorous__High_Standard_Benchmark.html#appendix",
    "title": "How Efficient is LLM-Generated Code? A Rigorous & High-Standard Benchmark",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06647v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06647v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8226"
  },
  {
    "objectID": "posts/Say_Your_Reason_Extract_Contextual_Rules_In_Situ_for_Context_aware_Service_Recommendation/2024-08-26-Say_Your_Reason_Extract_Contextual_Rules_In_Situ_for_Context_aware_Service_Recommendation.html",
    "href": "posts/Say_Your_Reason_Extract_Contextual_Rules_In_Situ_for_Context_aware_Service_Recommendation/2024-08-26-Say_Your_Reason_Extract_Contextual_Rules_In_Situ_for_Context_aware_Service_Recommendation.html",
    "title": "Say Your Reason: Extract Contextual Rules In Situ for Context-aware Service Recommendation",
    "section": "",
    "text": "Summary:\nSayRea is an interactive system that facilitates the extraction of contextual rules for personalized context-aware service recommendations in mobile scenarios. The system monitors a user’s execution of registered services on their smartphones and proactively requests a single-sentence reason from the user. By utilizing a Large Language Model (LLM), SayRea parses the reason and predicts contextual relationships between the observed service and potential contexts. A 10-day field study involving 20 participants showed that SayRea accumulated an average of 62.4 rules per user and successfully recommended 45% of service usage. The participants provided positive feedback on the system’s usability, interpretability, and controllability.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/Say_Your_Reason_Extract_Contextual_Rules_In_Situ_for_Context_aware_Service_Recommendation/2024-08-26-Say_Your_Reason_Extract_Contextual_Rules_In_Situ_for_Context_aware_Service_Recommendation.html#appendix",
    "href": "posts/Say_Your_Reason_Extract_Contextual_Rules_In_Situ_for_Context_aware_Service_Recommendation/2024-08-26-Say_Your_Reason_Extract_Contextual_Rules_In_Situ_for_Context_aware_Service_Recommendation.html#appendix",
    "title": "Say Your Reason: Extract Contextual Rules In Situ for Context-aware Service Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.13977v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.13977v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7194"
  },
  {
    "objectID": "posts/Item_Language_Model_for_Conversational_Recommendation/2024-06-05-Item_Language_Model_for_Conversational_Recommendation.html#appendix",
    "href": "posts/Item_Language_Model_for_Conversational_Recommendation/2024-06-05-Item_Language_Model_for_Conversational_Recommendation.html#appendix",
    "title": "Item-Language Model for Conversational Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02844v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02844v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6105"
  },
  {
    "objectID": "posts/PAS_Data_Efficient_Plug_and_Play_Prompt_Augmentation_System/2024-07-08-PAS_Data_Efficient_Plug_and_Play_Prompt_Augmentation_System.html#appendix",
    "href": "posts/PAS_Data_Efficient_Plug_and_Play_Prompt_Augmentation_System/2024-07-08-PAS_Data_Efficient_Plug_and_Play_Prompt_Augmentation_System.html#appendix",
    "title": "PAS: Data-Efficient Plug-and-Play Prompt Augmentation System",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06027v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06027v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8562"
  },
  {
    "objectID": "posts/Compromesso!_Italian_Many_Shot_Jailbreaks_Undermine_the_Safety_of_Large_Language_Models/2024-08-08-Compromesso!_Italian_Many_Shot_Jailbreaks_Undermine_the_Safety_of_Large_Language_Models.html#appendix",
    "href": "posts/Compromesso!_Italian_Many_Shot_Jailbreaks_Undermine_the_Safety_of_Large_Language_Models/2024-08-08-Compromesso!_Italian_Many_Shot_Jailbreaks_Undermine_the_Safety_of_Large_Language_Models.html#appendix",
    "title": "Compromesso! Italian Many-Shot Jailbreaks Undermine the Safety of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04522v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04522v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4028"
  },
  {
    "objectID": "posts/Large_Language_Models_in_Student_Assessment_Comparing_ChatGPT_and_Human_Graders/2024-06-24-Large_Language_Models_in_Student_Assessment_Comparing_ChatGPT_and_Human_Graders.html#appendix",
    "href": "posts/Large_Language_Models_in_Student_Assessment_Comparing_ChatGPT_and_Human_Graders/2024-06-24-Large_Language_Models_in_Student_Assessment_Comparing_ChatGPT_and_Human_Graders.html#appendix",
    "title": "Large Language Models in Student Assessment: Comparing ChatGPT and Human Graders",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16510v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16510v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9017"
  },
  {
    "objectID": "posts/Understanding_Epistemic_Language_with_a_Bayesian_Theory_of_Mind/2024-08-21-Understanding_Epistemic_Language_with_a_Bayesian_Theory_of_Mind.html#appendix",
    "href": "posts/Understanding_Epistemic_Language_with_a_Bayesian_Theory_of_Mind/2024-08-21-Understanding_Epistemic_Language_with_a_Bayesian_Theory_of_Mind.html#appendix",
    "title": "Understanding Epistemic Language with a Bayesian Theory of Mind",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12022v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12022v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11043"
  },
  {
    "objectID": "posts/Enhancing_Collaborative_Semantics_of_Language_Model_Driven_Recommendations_via_Graph_Aware_Learning/2024-06-19-Enhancing_Collaborative_Semantics_of_Language_Model_Driven_Recommendations_via_Graph_Aware_Learning.html#appendix",
    "href": "posts/Enhancing_Collaborative_Semantics_of_Language_Model_Driven_Recommendations_via_Graph_Aware_Learning/2024-06-19-Enhancing_Collaborative_Semantics_of_Language_Model_Driven_Recommendations_via_Graph_Aware_Learning.html#appendix",
    "title": "Enhancing Collaborative Semantics of Language Model-Driven Recommendations via Graph-Aware Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13235v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13235v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7497"
  },
  {
    "objectID": "posts/SimpleLLM4AD_An_End_to_End_Vision_Language_Model_with_Graph_Visual_Question_Answering_for_Autonomous_Driving/2024-07-31-SimpleLLM4AD_An_End_to_End_Vision_Language_Model_with_Graph_Visual_Question_Answering_for_Autonomous_Driving.html#appendix",
    "href": "posts/SimpleLLM4AD_An_End_to_End_Vision_Language_Model_with_Graph_Visual_Question_Answering_for_Autonomous_Driving/2024-07-31-SimpleLLM4AD_An_End_to_End_Vision_Language_Model_with_Graph_Visual_Question_Answering_for_Autonomous_Driving.html#appendix",
    "title": "SimpleLLM4AD: An End-to-End Vision-Language Model with Graph Visual Question Answering for Autonomous Driving",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21293v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21293v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5930"
  },
  {
    "objectID": "posts/Instruction_Finetuning_for_Leaderboard_Generation_from_Empirical_AI_Research/2024-08-19-Instruction_Finetuning_for_Leaderboard_Generation_from_Empirical_AI_Research.html#appendix",
    "href": "posts/Instruction_Finetuning_for_Leaderboard_Generation_from_Empirical_AI_Research/2024-08-19-Instruction_Finetuning_for_Leaderboard_Generation_from_Empirical_AI_Research.html#appendix",
    "title": "Instruction Finetuning for Leaderboard Generation from Empirical AI Research",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10141v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10141v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6247"
  },
  {
    "objectID": "posts/CHOP_Integrating_ChatGPT_into_EFL_Oral_Presentation_Practice/2024-07-10-CHOP_Integrating_ChatGPT_into_EFL_Oral_Presentation_Practice.html#appendix",
    "href": "posts/CHOP_Integrating_ChatGPT_into_EFL_Oral_Presentation_Practice/2024-07-10-CHOP_Integrating_ChatGPT_into_EFL_Oral_Presentation_Practice.html#appendix",
    "title": "CHOP: Integrating ChatGPT into EFL Oral Presentation Practice",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07393v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07393v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6286"
  },
  {
    "objectID": "posts/Efficiently_Exploring_Large_Language_Models_for_Document_Level_Machine_Translation_with_In_context_Learning/2024-06-11-Efficiently_Exploring_Large_Language_Models_for_Document_Level_Machine_Translation_with_In_context_Learning.html#appendix",
    "href": "posts/Efficiently_Exploring_Large_Language_Models_for_Document_Level_Machine_Translation_with_In_context_Learning/2024-06-11-Efficiently_Exploring_Large_Language_Models_for_Document_Level_Machine_Translation_with_In_context_Learning.html#appendix",
    "title": "Efficiently Exploring Large Language Models for Document-Level Machine Translation with In-context Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07081v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07081v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6243"
  },
  {
    "objectID": "posts/Automated_Defects_Detection_and_Fix_in_Logging_Statement/2024-08-06-Automated_Defects_Detection_and_Fix_in_Logging_Statement.html#appendix",
    "href": "posts/Automated_Defects_Detection_and_Fix_in_Logging_Statement/2024-08-06-Automated_Defects_Detection_and_Fix_in_Logging_Statement.html#appendix",
    "title": "Automated Defects Detection and Fix in Logging Statement",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03101v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03101v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7105"
  },
  {
    "objectID": "posts/Review_LLM_Harnessing_Large_Language_Models_for_Personalized_Review_Generation/2024-07-10-Review_LLM_Harnessing_Large_Language_Models_for_Personalized_Review_Generation.html#appendix",
    "href": "posts/Review_LLM_Harnessing_Large_Language_Models_for_Personalized_Review_Generation/2024-07-10-Review_LLM_Harnessing_Large_Language_Models_for_Personalized_Review_Generation.html#appendix",
    "title": "Review-LLM: Harnessing Large Language Models for Personalized Review Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07487v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07487v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3091"
  },
  {
    "objectID": "posts/Confabulation_The_Surprising_Value_of_Large_Language_Model_Hallucinations/2024-06-06-Confabulation_The_Surprising_Value_of_Large_Language_Model_Hallucinations.html#appendix",
    "href": "posts/Confabulation_The_Surprising_Value_of_Large_Language_Model_Hallucinations/2024-06-06-Confabulation_The_Surprising_Value_of_Large_Language_Model_Hallucinations.html#appendix",
    "title": "Confabulation: The Surprising Value of Large Language Model Hallucinations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04175v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04175v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5509"
  },
  {
    "objectID": "posts/Directed_Domain_Fine_Tuning_Tailoring_Separate_Modalities_for_Specific_Training_Tasks/2024-06-24-Directed_Domain_Fine_Tuning_Tailoring_Separate_Modalities_for_Specific_Training_Tasks.html#appendix",
    "href": "posts/Directed_Domain_Fine_Tuning_Tailoring_Separate_Modalities_for_Specific_Training_Tasks/2024-06-24-Directed_Domain_Fine_Tuning_Tailoring_Separate_Modalities_for_Specific_Training_Tasks.html#appendix",
    "title": "Directed Domain Fine-Tuning: Tailoring Separate Modalities for Specific Training Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16346v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16346v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6463"
  },
  {
    "objectID": "posts/MedDiT_A_Knowledge_Controlled_Diffusion_Transformer_Framework_for_Dynamic_Medical_Image_Generation_in_Virtual_Simulated_Patient/2024-08-22-MedDiT_A_Knowledge_Controlled_Diffusion_Transformer_Framework_for_Dynamic_Medical_Image_Generation_in_Virtual_Simulated_Patient.html#appendix",
    "href": "posts/MedDiT_A_Knowledge_Controlled_Diffusion_Transformer_Framework_for_Dynamic_Medical_Image_Generation_in_Virtual_Simulated_Patient/2024-08-22-MedDiT_A_Knowledge_Controlled_Diffusion_Transformer_Framework_for_Dynamic_Medical_Image_Generation_in_Virtual_Simulated_Patient.html#appendix",
    "title": "MedDiT: A Knowledge-Controlled Diffusion Transformer Framework for Dynamic Medical Image Generation in Virtual Simulated Patient",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12236v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12236v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2097"
  },
  {
    "objectID": "posts/LLM_Circuit_Analyses_Are_Consistent_Across_Training_and_Scale/2024-07-15-LLM_Circuit_Analyses_Are_Consistent_Across_Training_and_Scale.html#appendix",
    "href": "posts/LLM_Circuit_Analyses_Are_Consistent_Across_Training_and_Scale/2024-07-15-LLM_Circuit_Analyses_Are_Consistent_Across_Training_and_Scale.html#appendix",
    "title": "LLM Circuit Analyses Are Consistent Across Training and Scale",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10827v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10827v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11482"
  },
  {
    "objectID": "posts/Exploring_Scaling_Trends_in_LLM_Robustness/2024-07-25-Exploring_Scaling_Trends_in_LLM_Robustness.html#appendix",
    "href": "posts/Exploring_Scaling_Trends_in_LLM_Robustness/2024-07-25-Exploring_Scaling_Trends_in_LLM_Robustness.html#appendix",
    "title": "Exploring Scaling Trends in LLM Robustness",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.18213v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.18213v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7444"
  },
  {
    "objectID": "posts/CodexGraph_Bridging_Large_Language_Models_and_Code_Repositories_via_Code_Graph_Databases/2024-08-07-CodexGraph_Bridging_Large_Language_Models_and_Code_Repositories_via_Code_Graph_Databases.html#appendix",
    "href": "posts/CodexGraph_Bridging_Large_Language_Models_and_Code_Repositories_via_Code_Graph_Databases/2024-08-07-CodexGraph_Bridging_Large_Language_Models_and_Code_Repositories_via_Code_Graph_Databases.html#appendix",
    "title": "CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03910v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03910v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7961"
  },
  {
    "objectID": "posts/Learning_to_Plan_for_Retrieval_Augmented_Large_Language_Models_from_Knowledge_Graphs/2024-06-20-Learning_to_Plan_for_Retrieval_Augmented_Large_Language_Models_from_Knowledge_Graphs.html#appendix",
    "href": "posts/Learning_to_Plan_for_Retrieval_Augmented_Large_Language_Models_from_Knowledge_Graphs/2024-06-20-Learning_to_Plan_for_Retrieval_Augmented_Large_Language_Models_from_Knowledge_Graphs.html#appendix",
    "title": "Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14282v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14282v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6692"
  },
  {
    "objectID": "posts/Hey_Thats_My_Model!_Introducing_Chain__Hash_An_LLM_Fingerprinting_Technique/2024-07-15-Hey_Thats_My_Model!_Introducing_Chain__Hash_An_LLM_Fingerprinting_Technique.html#appendix",
    "href": "posts/Hey_Thats_My_Model!_Introducing_Chain__Hash_An_LLM_Fingerprinting_Technique/2024-07-15-Hey_Thats_My_Model!_Introducing_Chain__Hash_An_LLM_Fingerprinting_Technique.html#appendix",
    "title": "Hey, That’s My Model! Introducing Chain & Hash, An LLM Fingerprinting Technique",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10887v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10887v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11915"
  },
  {
    "objectID": "posts/LLMs_are_not_Zero_Shot_Reasoners_for_Biomedical_Information_Extraction/2024-08-22-LLMs_are_not_Zero_Shot_Reasoners_for_Biomedical_Information_Extraction.html#appendix",
    "href": "posts/LLMs_are_not_Zero_Shot_Reasoners_for_Biomedical_Information_Extraction/2024-08-22-LLMs_are_not_Zero_Shot_Reasoners_for_Biomedical_Information_Extraction.html#appendix",
    "title": "LLMs are not Zero-Shot Reasoners for Biomedical Information Extraction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12249v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12249v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7773"
  },
  {
    "objectID": "posts/CodeGraph_Enhancing_Graph_Reasoning_of_LLMs_with_Code/2024-08-25-CodeGraph_Enhancing_Graph_Reasoning_of_LLMs_with_Code.html#appendix",
    "href": "posts/CodeGraph_Enhancing_Graph_Reasoning_of_LLMs_with_Code/2024-08-25-CodeGraph_Enhancing_Graph_Reasoning_of_LLMs_with_Code.html#appendix",
    "title": "CodeGraph: Enhancing Graph Reasoning of LLMs with Code",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.13863v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.13863v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8240"
  },
  {
    "objectID": "posts/LLMs_assist_NLP_Researchers_Critique_Paper_(Meta_)Reviewing/2024-06-24-LLMs_assist_NLP_Researchers_Critique_Paper_(Meta_)Reviewing.html#appendix",
    "href": "posts/LLMs_assist_NLP_Researchers_Critique_Paper_(Meta_)Reviewing/2024-06-24-LLMs_assist_NLP_Researchers_Critique_Paper_(Meta_)Reviewing.html#appendix",
    "title": "LLMs assist NLP Researchers: Critique Paper (Meta-)Reviewing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16253v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16253v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7952"
  },
  {
    "objectID": "posts/Subtractive_Training_for_Music_Stem_Insertion_using_Latent_Diffusion_Models/2024-06-27-Subtractive_Training_for_Music_Stem_Insertion_using_Latent_Diffusion_Models.html#appendix",
    "href": "posts/Subtractive_Training_for_Music_Stem_Insertion_using_Latent_Diffusion_Models/2024-06-27-Subtractive_Training_for_Music_Stem_Insertion_using_Latent_Diffusion_Models.html#appendix",
    "title": "Subtractive Training for Music Stem Insertion using Latent Diffusion Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19328v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19328v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1133"
  },
  {
    "objectID": "posts/Evaluating_LLMs_for_Text_to_SQL_Generation_With_Complex_SQL_Workload/2024-07-28-Evaluating_LLMs_for_Text_to_SQL_Generation_With_Complex_SQL_Workload.html#appendix",
    "href": "posts/Evaluating_LLMs_for_Text_to_SQL_Generation_With_Complex_SQL_Workload/2024-07-28-Evaluating_LLMs_for_Text_to_SQL_Generation_With_Complex_SQL_Workload.html#appendix",
    "title": "Evaluating LLMs for Text-to-SQL Generation With Complex SQL Workload",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19517v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19517v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4422"
  },
  {
    "objectID": "posts/SeaLLMs_3_Open_Foundation_and_Chat_Multilingual_Large_Language_Models_for_Southeast_Asian_Languages/2024-07-29-SeaLLMs_3_Open_Foundation_and_Chat_Multilingual_Large_Language_Models_for_Southeast_Asian_Languages.html#appendix",
    "href": "posts/SeaLLMs_3_Open_Foundation_and_Chat_Multilingual_Large_Language_Models_for_Southeast_Asian_Languages/2024-07-29-SeaLLMs_3_Open_Foundation_and_Chat_Multilingual_Large_Language_Models_for_Southeast_Asian_Languages.html#appendix",
    "title": "SeaLLMs 3: Open Foundation and Chat Multilingual Large Language Models for Southeast Asian Languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19672v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19672v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5720"
  },
  {
    "objectID": "posts/PenHeal_A_Two_Stage_LLM_Framework_for_Automated_Pentesting_and_Optimal_Remediation/2024-07-25-PenHeal_A_Two_Stage_LLM_Framework_for_Automated_Pentesting_and_Optimal_Remediation.html#appendix",
    "href": "posts/PenHeal_A_Two_Stage_LLM_Framework_for_Automated_Pentesting_and_Optimal_Remediation/2024-07-25-PenHeal_A_Two_Stage_LLM_Framework_for_Automated_Pentesting_and_Optimal_Remediation.html#appendix",
    "title": "PenHeal: A Two-Stage LLM Framework for Automated Pentesting and Optimal Remediation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17788v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17788v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9946"
  },
  {
    "objectID": "posts/KGV_Integrating_Large_Language_Models_with_Knowledge_Graphs_for_Cyber_Threat_Intelligence_Credibility_Assessment/2024-08-15-KGV_Integrating_Large_Language_Models_with_Knowledge_Graphs_for_Cyber_Threat_Intelligence_Credibility_Assessment.html#appendix",
    "href": "posts/KGV_Integrating_Large_Language_Models_with_Knowledge_Graphs_for_Cyber_Threat_Intelligence_Credibility_Assessment/2024-08-15-KGV_Integrating_Large_Language_Models_with_Knowledge_Graphs_for_Cyber_Threat_Intelligence_Credibility_Assessment.html#appendix",
    "title": "KGV: Integrating Large Language Models with Knowledge Graphs for Cyber Threat Intelligence Credibility Assessment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.08088v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.08088v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5070"
  },
  {
    "objectID": "posts/Can_LLMs_Reason_in_the_Wild_with_Programs/2024-06-19-Can_LLMs_Reason_in_the_Wild_with_Programs.html#appendix",
    "href": "posts/Can_LLMs_Reason_in_the_Wild_with_Programs/2024-06-19-Can_LLMs_Reason_in_the_Wild_with_Programs.html#appendix",
    "title": "Can LLMs Reason in the Wild with Programs?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13764v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13764v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13142"
  },
  {
    "objectID": "posts/Spider2_V_How_Far_Are_Multimodal_Agents_From_Automating_Data_Science_and_Engineering_Workflows/2024-07-15-Spider2_V_How_Far_Are_Multimodal_Agents_From_Automating_Data_Science_and_Engineering_Workflows.html",
    "href": "posts/Spider2_V_How_Far_Are_Multimodal_Agents_From_Automating_Data_Science_and_Engineering_Workflows/2024-07-15-Spider2_V_How_Far_Are_Multimodal_Agents_From_Automating_Data_Science_and_Engineering_Workflows.html",
    "title": "Spider2-V: How Far Are Multimodal Agents From Automating Data Science and Engineering Workflows?",
    "section": "",
    "text": "Summary:\nThe paper introduces Spider2-V, a multimodal agent benchmark that covers the entire data science and engineering workflow. It includes 494 real-world tasks in a real-time executable computer environment and 20 professional enterprise data software. The benchmark aims to evaluate a multimodal agent’s ability to perform professional data-related tasks by writing code and managing the GUI in enterprise data software systems. The tasks are derived from real-world practices and are supplemented with retrieval-augmented agents with official documentation and tutorials of these software systems. The benchmark is designed to balance realistic simulation with evaluation simplicity and features automatic configurations for task setup and customized evaluation metrics for each task.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a comprehensive and well-structured summary of the Spider2-V benchmark. The benchmark is a significant contribution to the field of data science and engineering, as it covers the entire data workflow and integrates visual interfaces. However, the paper does not provide a detailed analysis of the limitations or potential biases of the benchmark. It would be beneficial to include a more in-depth discussion of these aspects to provide a more balanced perspective on the benchmark’s strengths and weaknesses. Additionally, the paper could benefit from a more detailed comparison with other existing benchmarks in the field, highlighting the unique features and advantages of Spider2-V."
  },
  {
    "objectID": "posts/Spider2_V_How_Far_Are_Multimodal_Agents_From_Automating_Data_Science_and_Engineering_Workflows/2024-07-15-Spider2_V_How_Far_Are_Multimodal_Agents_From_Automating_Data_Science_and_Engineering_Workflows.html#appendix",
    "href": "posts/Spider2_V_How_Far_Are_Multimodal_Agents_From_Automating_Data_Science_and_Engineering_Workflows/2024-07-15-Spider2_V_How_Far_Are_Multimodal_Agents_From_Automating_Data_Science_and_Engineering_Workflows.html#appendix",
    "title": "Spider2-V: How Far Are Multimodal Agents From Automating Data Science and Engineering Workflows?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10956v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10956v1\n\n\nTruncated\nFalse\n\n\nWord Count\n25225"
  },
  {
    "objectID": "posts/Multilingual_Trolley_Problems_for_Language_Models/2024-07-02-Multilingual_Trolley_Problems_for_Language_Models.html#appendix",
    "href": "posts/Multilingual_Trolley_Problems_for_Language_Models/2024-07-02-Multilingual_Trolley_Problems_for_Language_Models.html#appendix",
    "title": "Multilingual Trolley Problems for Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02273v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02273v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12265"
  },
  {
    "objectID": "posts/Using_Advanced_LLMs_to_Enhance_Smaller_LLMs_An_Interpretable_Knowledge_Distillation_Approach/2024-08-13-Using_Advanced_LLMs_to_Enhance_Smaller_LLMs_An_Interpretable_Knowledge_Distillation_Approach.html#appendix",
    "href": "posts/Using_Advanced_LLMs_to_Enhance_Smaller_LLMs_An_Interpretable_Knowledge_Distillation_Approach/2024-08-13-Using_Advanced_LLMs_to_Enhance_Smaller_LLMs_An_Interpretable_Knowledge_Distillation_Approach.html#appendix",
    "title": "Using Advanced LLMs to Enhance Smaller LLMs: An Interpretable Knowledge Distillation Approach",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07238v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07238v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10737"
  },
  {
    "objectID": "posts/Buffer_of_Thoughts_Thought_Augmented_Reasoning_with_Large_Language_Models/2024-06-06-Buffer_of_Thoughts_Thought_Augmented_Reasoning_with_Large_Language_Models.html#appendix",
    "href": "posts/Buffer_of_Thoughts_Thought_Augmented_Reasoning_with_Large_Language_Models/2024-06-06-Buffer_of_Thoughts_Thought_Augmented_Reasoning_with_Large_Language_Models.html#appendix",
    "title": "Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04271v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04271v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6204"
  },
  {
    "objectID": "posts/Advancing_Annotation_of_Stance_in_Social_Media_Posts_A_Comparative_Analysis_of_Large_Language_Models_and_Crowd_Sourcing/2024-06-11-Advancing_Annotation_of_Stance_in_Social_Media_Posts_A_Comparative_Analysis_of_Large_Language_Models_and_Crowd_Sourcing.html#appendix",
    "href": "posts/Advancing_Annotation_of_Stance_in_Social_Media_Posts_A_Comparative_Analysis_of_Large_Language_Models_and_Crowd_Sourcing/2024-06-11-Advancing_Annotation_of_Stance_in_Social_Media_Posts_A_Comparative_Analysis_of_Large_Language_Models_and_Crowd_Sourcing.html#appendix",
    "title": "Advancing Annotation of Stance in Social Media Posts: A Comparative Analysis of Large Language Models and Crowd Sourcing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07483v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07483v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7463"
  },
  {
    "objectID": "posts/DAAD_Dynamic_Analysis_and_Adaptive_Discriminator_for_Fake_News_Detection/2024-08-20-DAAD_Dynamic_Analysis_and_Adaptive_Discriminator_for_Fake_News_Detection.html",
    "href": "posts/DAAD_Dynamic_Analysis_and_Adaptive_Discriminator_for_Fake_News_Detection/2024-08-20-DAAD_Dynamic_Analysis_and_Adaptive_Discriminator_for_Fake_News_Detection.html",
    "title": "DAAD: Dynamic Analysis and Adaptive Discriminator for Fake News Detection",
    "section": "",
    "text": "Summary:\nThe paper proposes a Dynamic Analysis and Adaptive Discriminator (DAAD) approach for fake news detection, addressing the limitations of existing knowledge-based and semantics-based methods. The DAAD approach introduces domain-specific comments from Large language models (LLMs) using Monte Carlo Tree Search (MCTS) and mitigates the risk of getting trapped in local minima during optimization through MemoryBank, Batchprompt, and Resampling. The paper also defines four typical deceit patterns and designs corresponding discriminators, allowing for flexible exploration of optimal detection models through dynamic routing.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/DAAD_Dynamic_Analysis_and_Adaptive_Discriminator_for_Fake_News_Detection/2024-08-20-DAAD_Dynamic_Analysis_and_Adaptive_Discriminator_for_Fake_News_Detection.html#appendix",
    "href": "posts/DAAD_Dynamic_Analysis_and_Adaptive_Discriminator_for_Fake_News_Detection/2024-08-20-DAAD_Dynamic_Analysis_and_Adaptive_Discriminator_for_Fake_News_Detection.html#appendix",
    "title": "DAAD: Dynamic Analysis and Adaptive Discriminator for Fake News Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10883v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10883v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8259"
  },
  {
    "objectID": "posts/Learning_based_Models_for_Vulnerability_Detection_An_Extensive_Study/2024-08-14-Learning_based_Models_for_Vulnerability_Detection_An_Extensive_Study.html#appendix",
    "href": "posts/Learning_based_Models_for_Vulnerability_Detection_An_Extensive_Study/2024-08-14-Learning_based_Models_for_Vulnerability_Detection_An_Extensive_Study.html#appendix",
    "title": "Learning-based Models for Vulnerability Detection: An Extensive Study",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07526v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07526v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10658"
  },
  {
    "objectID": "posts/Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models/2024-07-08-Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models.html#major-findings",
    "href": "posts/Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models/2024-07-08-Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models.html#major-findings",
    "title": "Merge, Ensemble, and Cooperate! A Survey on Collaborative Strategies in the Era of Large Language Models",
    "section": "Major Findings",
    "text": "Major Findings\n\nMerging: This approach integrates the parameters of multiple LLMs into a single, unified model, requiring that the parameters are compatible within a linear space. Merging methods are tailored to be more suitable for LLMs, effectively leveraging the collaborative advantages of diverse LLMs.\nEnsemble: Ensemble methods focus on combining the outputs generated by various LLMs to produce coherent results, with less emphasis on the parameters of the individual models. These methods are derived from traditional fusion techniques commonly explored in machine learning.\nCooperation: Cooperation extends beyond merging and ensemble, focusing on cooperative methods that harness the diverse strengths of LLMs to achieve specific objectives. These techniques expand the methodologies for model collaboration, holding significant research importance for LLMs."
  },
  {
    "objectID": "posts/Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models/2024-07-08-Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models/2024-07-08-Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models.html#analysis-and-critique",
    "title": "Merge, Ensemble, and Cooperate! A Survey on Collaborative Strategies in the Era of Large Language Models",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\nThe paper provides a well-structured and coherent summary of the emerging research area of collaboration strategies for LLMs. The authors’ categorization of these strategies into Merging, Ensemble, and Cooperation offers a clear understanding of their respective frameworks and applications.\nHowever, the paper does not discuss the potential limitations, unanswered questions, or biases that may be apparent while reviewing the text. Additionally, the paper does not address any methodological issues, conflicting evidence, or areas that require further research or clarification.\nIn conclusion, the paper serves as a valuable resource for understanding the strategies and methodologies for collaborative efforts among LLMs. However, it would benefit from a more critical analysis of the discussed topics, addressing potential limitations and areas for further research."
  },
  {
    "objectID": "posts/Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models/2024-07-08-Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models.html#appendix",
    "href": "posts/Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models/2024-07-08-Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models.html#appendix",
    "title": "Merge, Ensemble, and Cooperate! A Survey on Collaborative Strategies in the Era of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06089v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06089v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14228"
  },
  {
    "objectID": "posts/Large_Language_Models_for_Automatic_Milestone_Detection_in_Group_Discussions/2024-06-16-Large_Language_Models_for_Automatic_Milestone_Detection_in_Group_Discussions.html#appendix",
    "href": "posts/Large_Language_Models_for_Automatic_Milestone_Detection_in_Group_Discussions/2024-06-16-Large_Language_Models_for_Automatic_Milestone_Detection_in_Group_Discussions.html#appendix",
    "title": "Large Language Models for Automatic Milestone Detection in Group Discussions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.10842v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.10842v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4838"
  },
  {
    "objectID": "posts/UBENCH_Benchmarking_Uncertainty_in_Large_Language_Models_with_Multiple_Choice_Questions/2024-06-18-UBENCH_Benchmarking_Uncertainty_in_Large_Language_Models_with_Multiple_Choice_Questions.html#appendix",
    "href": "posts/UBENCH_Benchmarking_Uncertainty_in_Large_Language_Models_with_Multiple_Choice_Questions/2024-06-18-UBENCH_Benchmarking_Uncertainty_in_Large_Language_Models_with_Multiple_Choice_Questions.html#appendix",
    "title": "UBENCH: Benchmarking Uncertainty in Large Language Models with Multiple Choice Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12784v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12784v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7284"
  },
  {
    "objectID": "posts/Where_Do_Large_Language_Models_Fail_When_Generating_Code/2024-06-13-Where_Do_Large_Language_Models_Fail_When_Generating_Code.html#appendix",
    "href": "posts/Where_Do_Large_Language_Models_Fail_When_Generating_Code/2024-06-13-Where_Do_Large_Language_Models_Fail_When_Generating_Code.html#appendix",
    "title": "Where Do Large Language Models Fail When Generating Code?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.08731v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.08731v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9595"
  },
  {
    "objectID": "posts/KGym_A_Platform_and_Dataset_to_Benchmark_Large_Language_Models_on_Linux_Kernel_Crash_Resolution/2024-07-02-KGym_A_Platform_and_Dataset_to_Benchmark_Large_Language_Models_on_Linux_Kernel_Crash_Resolution.html#appendix",
    "href": "posts/KGym_A_Platform_and_Dataset_to_Benchmark_Large_Language_Models_on_Linux_Kernel_Crash_Resolution/2024-07-02-KGym_A_Platform_and_Dataset_to_Benchmark_Large_Language_Models_on_Linux_Kernel_Crash_Resolution.html#appendix",
    "title": "KGym: A Platform and Dataset to Benchmark Large Language Models on Linux Kernel Crash Resolution",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02680v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02680v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3950"
  },
  {
    "objectID": "posts/Applying_LLMs_for_Rescoring_N_best_ASR_Hypotheses_of_Casual_Conversations_Effects_of_Domain_Adaptation_and_Context_Carry_over/2024-06-27-Applying_LLMs_for_Rescoring_N_best_ASR_Hypotheses_of_Casual_Conversations_Effects_of_Domain_Adaptation_and_Context_Carry_over.html#appendix",
    "href": "posts/Applying_LLMs_for_Rescoring_N_best_ASR_Hypotheses_of_Casual_Conversations_Effects_of_Domain_Adaptation_and_Context_Carry_over/2024-06-27-Applying_LLMs_for_Rescoring_N_best_ASR_Hypotheses_of_Casual_Conversations_Effects_of_Domain_Adaptation_and_Context_Carry_over.html#appendix",
    "title": "Applying LLMs for Rescoring N-best ASR Hypotheses of Casual Conversations: Effects of Domain Adaptation and Context Carry-over",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18972v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18972v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5457"
  },
  {
    "objectID": "posts/A_Context_Driven_Approach_for_Co_Auditing_Smart_Contracts_with_The_Support_of_GPT_4_code_interpreter/2024-06-26-A_Context_Driven_Approach_for_Co_Auditing_Smart_Contracts_with_The_Support_of_GPT_4_code_interpreter.html#appendix",
    "href": "posts/A_Context_Driven_Approach_for_Co_Auditing_Smart_Contracts_with_The_Support_of_GPT_4_code_interpreter/2024-06-26-A_Context_Driven_Approach_for_Co_Auditing_Smart_Contracts_with_The_Support_of_GPT_4_code_interpreter.html#appendix",
    "title": "A Context-Driven Approach for Co-Auditing Smart Contracts with The Support of GPT-4 code interpreter",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18075v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18075v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9396"
  },
  {
    "objectID": "posts/Exploring_Mathematical_Extrapolation_of_Large_Language_Models_with_Synthetic_Data/2024-06-04-Exploring_Mathematical_Extrapolation_of_Large_Language_Models_with_Synthetic_Data.html#appendix",
    "href": "posts/Exploring_Mathematical_Extrapolation_of_Large_Language_Models_with_Synthetic_Data/2024-06-04-Exploring_Mathematical_Extrapolation_of_Large_Language_Models_with_Synthetic_Data.html#appendix",
    "title": "Exploring Mathematical Extrapolation of Large Language Models with Synthetic Data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02100v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02100v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3993"
  },
  {
    "objectID": "posts/MetaOpenFOAM_an_LLM_based_multi_agent_framework_for_CFD/2024-07-31-MetaOpenFOAM_an_LLM_based_multi_agent_framework_for_CFD.html",
    "href": "posts/MetaOpenFOAM_an_LLM_based_multi_agent_framework_for_CFD/2024-07-31-MetaOpenFOAM_an_LLM_based_multi_agent_framework_for_CFD.html",
    "title": "MetaOpenFOAM: an LLM-based multi-agent framework for CFD",
    "section": "",
    "text": "Summary:\nThe paper introduces MetaOpenFOAM, a novel multi-agent framework for CFD simulations that aims to complete tasks using only natural language as input. The framework leverages the MetaGPT assembly line paradigm and Langchain’s Retrieval-Augmented Generation (RAG) technology. MetaOpenFOAM achieved a high pass rate (85%) on a benchmark for natural language-based CFD solvers, with each test case costing only $0.22 on average. The paper also presents an ablation study and parameter sensitivity analysis to validate the necessity of each component in the multi-agent system and the RAG technology.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an innovative approach to CFD simulations using a multi-agent framework and natural language input. The results are promising, with a high pass rate and low cost per test case. However, the paper does not discuss the limitations or potential biases of the approach. Additionally, the benchmark used for evaluation is not publicly available, making it difficult to compare the results with other methods. The paper could benefit from a more comprehensive evaluation and comparison with existing CFD solvers."
  },
  {
    "objectID": "posts/MetaOpenFOAM_an_LLM_based_multi_agent_framework_for_CFD/2024-07-31-MetaOpenFOAM_an_LLM_based_multi_agent_framework_for_CFD.html#appendix",
    "href": "posts/MetaOpenFOAM_an_LLM_based_multi_agent_framework_for_CFD/2024-07-31-MetaOpenFOAM_an_LLM_based_multi_agent_framework_for_CFD.html#appendix",
    "title": "MetaOpenFOAM: an LLM-based multi-agent framework for CFD",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21320v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21320v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14305"
  },
  {
    "objectID": "posts/MagicItem_Dynamic_Behavior_Design_of_Virtual_Objects_with_Large_Language_Models_in_a_Consumer_Metaverse_Platform/2024-06-19-MagicItem_Dynamic_Behavior_Design_of_Virtual_Objects_with_Large_Language_Models_in_a_Consumer_Metaverse_Platform.html#appendix",
    "href": "posts/MagicItem_Dynamic_Behavior_Design_of_Virtual_Objects_with_Large_Language_Models_in_a_Consumer_Metaverse_Platform/2024-06-19-MagicItem_Dynamic_Behavior_Design_of_Virtual_Objects_with_Large_Language_Models_in_a_Consumer_Metaverse_Platform.html#appendix",
    "title": "MagicItem: Dynamic Behavior Design of Virtual Objects with Large Language Models in a Consumer Metaverse Platform",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13242v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13242v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9382"
  },
  {
    "objectID": "posts/CLAVE_An_Adaptive_Framework_for_Evaluating_Values_of_LLM_Generated_Responses/2024-07-15-CLAVE_An_Adaptive_Framework_for_Evaluating_Values_of_LLM_Generated_Responses.html#appendix",
    "href": "posts/CLAVE_An_Adaptive_Framework_for_Evaluating_Values_of_LLM_Generated_Responses/2024-07-15-CLAVE_An_Adaptive_Framework_for_Evaluating_Values_of_LLM_Generated_Responses.html#appendix",
    "title": "CLAVE: An Adaptive Framework for Evaluating Values of LLM Generated Responses",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10725v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10725v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9188"
  },
  {
    "objectID": "posts/On_the_attribution_of_confidence_to_large_language_models/2024-07-11-On_the_attribution_of_confidence_to_large_language_models.html#appendix",
    "href": "posts/On_the_attribution_of_confidence_to_large_language_models/2024-07-11-On_the_attribution_of_confidence_to_large_language_models.html#appendix",
    "title": "On the attribution of confidence to large language models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08388v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08388v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11712"
  },
  {
    "objectID": "posts/A_Comparative_Analysis_of_Faithfulness_Metrics_and_Humans_in_Citation_Evaluation/2024-08-22-A_Comparative_Analysis_of_Faithfulness_Metrics_and_Humans_in_Citation_Evaluation.html#appendix",
    "href": "posts/A_Comparative_Analysis_of_Faithfulness_Metrics_and_Humans_in_Citation_Evaluation/2024-08-22-A_Comparative_Analysis_of_Faithfulness_Metrics_and_Humans_in_Citation_Evaluation.html#appendix",
    "title": "A Comparative Analysis of Faithfulness Metrics and Humans in Citation Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12398v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12398v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6443"
  },
  {
    "objectID": "posts/WARP_On_the_Benefits_of_Weight_Averaged_Rewarded_Policies/2024-06-24-WARP_On_the_Benefits_of_Weight_Averaged_Rewarded_Policies.html",
    "href": "posts/WARP_On_the_Benefits_of_Weight_Averaged_Rewarded_Policies/2024-06-24-WARP_On_the_Benefits_of_Weight_Averaged_Rewarded_Policies.html",
    "title": "WARP: On the Benefits of Weight Averaged Rewarded Policies",
    "section": "",
    "text": "Summary:\nThe paper introduces a novel alignment strategy called Weight Averaged Rewarded Policies (WARP) for Reinforcement Learning from Human Feeduring (RLHF) in large language models (LLMs). WARP aims to optimize the -reward Pareto front of solutions by merging policies in the weight space at three distinct stages: using the exponential moving average (EMA) of the policy as a dynamic anchor in regularization, applying spherical interpolation to merge independently fine-tuned policies, and linearly interpolating between the merged model and the initialization. The iterative application of WARP improves the -reward Pareto front, aligning the LLMs while protecting the knowledge from pre-training. The paper compares WARP with state-of-the-art baselines and shows that it outperforms them in terms of alignment and quality.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel and promising approach to RLHF in LLMs. The use of model merging by weight averaging is a well-established technique in the literature, and the paper builds on this to propose a new alignment strategy. The experimental results show that WARP outperforms other RL alignment strategies in terms of -reward Pareto optimality. However, the paper does not discuss the computational cost of training WARP, which may be a limitation for some applications. Additionally, the paper does not provide a detailed comparison with other RLHF methods, such as Proximal Policy Optimization (PPO) or Deep Q-Networks (DQN), which could provide a more comprehensive evaluation of the proposed approach."
  },
  {
    "objectID": "posts/WARP_On_the_Benefits_of_Weight_Averaged_Rewarded_Policies/2024-06-24-WARP_On_the_Benefits_of_Weight_Averaged_Rewarded_Policies.html#appendix",
    "href": "posts/WARP_On_the_Benefits_of_Weight_Averaged_Rewarded_Policies/2024-06-24-WARP_On_the_Benefits_of_Weight_Averaged_Rewarded_Policies.html#appendix",
    "title": "WARP: On the Benefits of Weight Averaged Rewarded Policies",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16768v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16768v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11719"
  },
  {
    "objectID": "posts/MedTsLLM_Leveraging_LLMs_for_Multimodal_Medical_Time_Series_Analysis/2024-08-14-MedTsLLM_Leveraging_LLMs_for_Multimodal_Medical_Time_Series_Analysis.html#major-findings",
    "href": "posts/MedTsLLM_Leveraging_LLMs_for_Multimodal_Medical_Time_Series_Analysis/2024-08-14-MedTsLLM_Leveraging_LLMs_for_Multimodal_Medical_Time_Series_Analysis.html#major-findings",
    "title": "MedTsLLM: Leveraging LLMs for Multimodal Medical Time Series Analysis",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nMedTsLLM effectively integrates time series data and text to perform clinically relevant tasks, outperforming state-of-the-art baselines in multiple medical domains.\nThe model utilizes a reprogramming layer to align embeddings of time series patches with a pretrained LLM’s embedding space, making effective use of raw time series data in conjunction with textual context.\nMedTsLLM handles multiple covariates and tailors the text prompt to include patient-specific information, improving its performance and applicability in various medical domains."
  },
  {
    "objectID": "posts/MedTsLLM_Leveraging_LLMs_for_Multimodal_Medical_Time_Series_Analysis/2024-08-14-MedTsLLM_Leveraging_LLMs_for_Multimodal_Medical_Time_Series_Analysis.html#analysis-and-critique",
    "href": "posts/MedTsLLM_Leveraging_LLMs_for_Multimodal_Medical_Time_Series_Analysis/2024-08-14-MedTsLLM_Leveraging_LLMs_for_Multimodal_Medical_Time_Series_Analysis.html#analysis-and-critique",
    "title": "MedTsLLM: Leveraging LLMs for Multimodal Medical Time Series Analysis",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a promising approach to harnessing the power of LLMs for medical time series analysis, which could elevate data-driven tools for clinicians and improve patient outcomes. However, the following points should be considered:\n\nThe paper does not discuss the computational requirements and potential limitations of using LLMs for real-time clinical applications.\nThe model’s performance on other medical domains beyond electrocardiograms and respiratory waveforms is not evaluated, which may limit its generalizability.\nThe paper does not address potential biases in the training data or the impact of such biases on the model’s performance and clinical applicability.\nThe paper does not provide a detailed comparison with traditional time series analysis methods, which could help contextualize the advantages and limitations of the proposed approach.\nThe paper does not discuss the potential ethical implications of using LLMs for medical applications, such as data privacy and patient consent."
  },
  {
    "objectID": "posts/MedTsLLM_Leveraging_LLMs_for_Multimodal_Medical_Time_Series_Analysis/2024-08-14-MedTsLLM_Leveraging_LLMs_for_Multimodal_Medical_Time_Series_Analysis.html#appendix",
    "href": "posts/MedTsLLM_Leveraging_LLMs_for_Multimodal_Medical_Time_Series_Analysis/2024-08-14-MedTsLLM_Leveraging_LLMs_for_Multimodal_Medical_Time_Series_Analysis.html#appendix",
    "title": "MedTsLLM: Leveraging LLMs for Multimodal Medical Time Series Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07773v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07773v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11390"
  },
  {
    "objectID": "posts/Reading_with_Intent/2024-08-20-Reading_with_Intent.html#appendix",
    "href": "posts/Reading_with_Intent/2024-08-20-Reading_with_Intent.html#appendix",
    "title": "Reading with Intent",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11189v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11189v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6931"
  },
  {
    "objectID": "posts/ShadowLLM_Predictor_based_Contextual_Sparsity_for_Large_Language_Models/2024-06-24-ShadowLLM_Predictor_based_Contextual_Sparsity_for_Large_Language_Models.html#appendix",
    "href": "posts/ShadowLLM_Predictor_based_Contextual_Sparsity_for_Large_Language_Models/2024-06-24-ShadowLLM_Predictor_based_Contextual_Sparsity_for_Large_Language_Models.html#appendix",
    "title": "ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16635v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16635v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6242"
  },
  {
    "objectID": "posts/Safe_Embed_Unveiling_the_Safety_Critical_Knowledge_of_Sentence_Encoders/2024-07-09-Safe_Embed_Unveiling_the_Safety_Critical_Knowledge_of_Sentence_Encoders.html#appendix",
    "href": "posts/Safe_Embed_Unveiling_the_Safety_Critical_Knowledge_of_Sentence_Encoders/2024-07-09-Safe_Embed_Unveiling_the_Safety_Critical_Knowledge_of_Sentence_Encoders.html#appendix",
    "title": "Safe-Embed: Unveiling the Safety-Critical Knowledge of Sentence Encoders",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06851v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06851v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7554"
  },
  {
    "objectID": "posts/Automated_Review_Generation_Method_Based_on_Large_Language_Models/2024-07-30-Automated_Review_Generation_Method_Based_on_Large_Language_Models.html#appendix",
    "href": "posts/Automated_Review_Generation_Method_Based_on_Large_Language_Models/2024-07-30-Automated_Review_Generation_Method_Based_on_Large_Language_Models.html#appendix",
    "title": "Automated Review Generation Method Based on Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20906v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20906v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6801"
  },
  {
    "objectID": "posts/Is_Large_Language_Model_Good_at_Database_Knob_Tuning_A_Comprehensive_Experimental_Evaluation/2024-08-05-Is_Large_Language_Model_Good_at_Database_Knob_Tuning_A_Comprehensive_Experimental_Evaluation.html#appendix",
    "href": "posts/Is_Large_Language_Model_Good_at_Database_Knob_Tuning_A_Comprehensive_Experimental_Evaluation/2024-08-05-Is_Large_Language_Model_Good_at_Database_Knob_Tuning_A_Comprehensive_Experimental_Evaluation.html#appendix",
    "title": "Is Large Language Model Good at Database Knob Tuning? A Comprehensive Experimental Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02213v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02213v1\n\n\nTruncated\nFalse\n\n\nWord Count\n866"
  },
  {
    "objectID": "posts/TF_Attack_Transferable_and_Fast_Adversarial_Attacks_on_Large_Language_Models/2024-08-26-TF_Attack_Transferable_and_Fast_Adversarial_Attacks_on_Large_Language_Models.html",
    "href": "posts/TF_Attack_Transferable_and_Fast_Adversarial_Attacks_on_Large_Language_Models/2024-08-26-TF_Attack_Transferable_and_Fast_Adversarial_Attacks_on_Large_Language_Models.html",
    "title": "TF-Attack: Transferable and Fast Adversarial Attacks on Large Language Models",
    "section": "",
    "text": "Summary:\nThe paper introduces a new scheme, TF-Attack, for Transferable and Fast adversarial attacks on Large Language Models (LLMs). TF-Attack employs an external LLM as a third-party overseer to identify critical units within sentences, rather than the victim model. It also introduces the concept of Importance Level, which allows for parallel substitutions of attacks. The proposed method is evaluated on 6 widely adopted benchmarks, and results show that it consistently surpasses previous methods in transferability and delivers significant speed improvements, up to 20 times faster than earlier attack strategies.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/TF_Attack_Transferable_and_Fast_Adversarial_Attacks_on_Large_Language_Models/2024-08-26-TF_Attack_Transferable_and_Fast_Adversarial_Attacks_on_Large_Language_Models.html#appendix",
    "href": "posts/TF_Attack_Transferable_and_Fast_Adversarial_Attacks_on_Large_Language_Models/2024-08-26-TF_Attack_Transferable_and_Fast_Adversarial_Attacks_on_Large_Language_Models.html#appendix",
    "title": "TF-Attack: Transferable and Fast Adversarial Attacks on Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.13985v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.13985v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7417"
  },
  {
    "objectID": "posts/Large_Language_Models_Assume_People_are_More_Rational_than_We_Really_are/2024-06-24-Large_Language_Models_Assume_People_are_More_Rational_than_We_Really_are.html#appendix",
    "href": "posts/Large_Language_Models_Assume_People_are_More_Rational_than_We_Really_are/2024-06-24-Large_Language_Models_Assume_People_are_More_Rational_than_We_Really_are.html#appendix",
    "title": "Large Language Models Assume People are More Rational than We Really are",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17055v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17055v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9964"
  },
  {
    "objectID": "posts/Lottery_Ticket_Adaptation_Mitigating_Destructive_Interference_in_LLMs/2024-06-24-Lottery_Ticket_Adaptation_Mitigating_Destructive_Interference_in_LLMs.html#appendix",
    "href": "posts/Lottery_Ticket_Adaptation_Mitigating_Destructive_Interference_in_LLMs/2024-06-24-Lottery_Ticket_Adaptation_Mitigating_Destructive_Interference_in_LLMs.html#appendix",
    "title": "Lottery Ticket Adaptation: Mitigating Destructive Interference in LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16797v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16797v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9206"
  },
  {
    "objectID": "posts/Prompting_Techniques_for_Secure_Code_Generation_A_Systematic_Investigation/2024-07-09-Prompting_Techniques_for_Secure_Code_Generation_A_Systematic_Investigation.html#appendix",
    "href": "posts/Prompting_Techniques_for_Secure_Code_Generation_A_Systematic_Investigation/2024-07-09-Prompting_Techniques_for_Secure_Code_Generation_A_Systematic_Investigation.html#appendix",
    "title": "Prompting Techniques for Secure Code Generation: A Systematic Investigation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07064v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07064v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20445"
  },
  {
    "objectID": "posts/Bias_Aware_Low_Rank_Adaptation_Mitigating_Catastrophic_Inheritance_of_Large_Language_Models/2024-08-08-Bias_Aware_Low_Rank_Adaptation_Mitigating_Catastrophic_Inheritance_of_Large_Language_Models.html#appendix",
    "href": "posts/Bias_Aware_Low_Rank_Adaptation_Mitigating_Catastrophic_Inheritance_of_Large_Language_Models/2024-08-08-Bias_Aware_Low_Rank_Adaptation_Mitigating_Catastrophic_Inheritance_of_Large_Language_Models.html#appendix",
    "title": "Bias-Aware Low-Rank Adaptation: Mitigating Catastrophic Inheritance of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04556v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04556v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5969"
  },
  {
    "objectID": "posts/Model_Attribution_in_Machine_Generated_Disinformation_A_Domain_Generalization_Approach_with_Supervised_Contrastive_Learning/2024-07-31-Model_Attribution_in_Machine_Generated_Disinformation_A_Domain_Generalization_Approach_with_Supervised_Contrastive_Learning.html#appendix",
    "href": "posts/Model_Attribution_in_Machine_Generated_Disinformation_A_Domain_Generalization_Approach_with_Supervised_Contrastive_Learning/2024-07-31-Model_Attribution_in_Machine_Generated_Disinformation_A_Domain_Generalization_Approach_with_Supervised_Contrastive_Learning.html#appendix",
    "title": "Model Attribution in Machine-Generated Disinformation: A Domain Generalization Approach with Supervised Contrastive Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21264v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21264v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6708"
  },
  {
    "objectID": "posts/Single_Character_Perturbations_Break_LLM_Alignment/2024-07-03-Single_Character_Perturbations_Break_LLM_Alignment.html",
    "href": "posts/Single_Character_Perturbations_Break_LLM_Alignment/2024-07-03-Single_Character_Perturbations_Break_LLM_Alignment.html",
    "title": "Single Character Perturbations Break LLM Alignment",
    "section": "",
    "text": "Summary:\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/Single_Character_Perturbations_Break_LLM_Alignment/2024-07-03-Single_Character_Perturbations_Break_LLM_Alignment.html#appendix",
    "href": "posts/Single_Character_Perturbations_Break_LLM_Alignment/2024-07-03-Single_Character_Perturbations_Break_LLM_Alignment.html#appendix",
    "title": "Single Character Perturbations Break LLM Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03232v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03232v1\n\n\nTruncated\nFalse\n\n\nWord Count\n21366"
  },
  {
    "objectID": "posts/Decision_Making_Behavior_Evaluation_Framework_for_LLMs_under_Uncertain_Context/2024-06-10-Decision_Making_Behavior_Evaluation_Framework_for_LLMs_under_Uncertain_Context.html#appendix",
    "href": "posts/Decision_Making_Behavior_Evaluation_Framework_for_LLMs_under_Uncertain_Context/2024-06-10-Decision_Making_Behavior_Evaluation_Framework_for_LLMs_under_Uncertain_Context.html#appendix",
    "title": "Decision-Making Behavior Evaluation Framework for LLMs under Uncertain Context",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05972v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05972v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6256"
  },
  {
    "objectID": "posts/LMM_VQA_Advancing_Video_Quality_Assessment_with_Large_Multimodal_Models/2024-08-26-LMM_VQA_Advancing_Video_Quality_Assessment_with_Large_Multimodal_Models.html#major-findings",
    "href": "posts/LMM_VQA_Advancing_Video_Quality_Assessment_with_Large_Multimodal_Models/2024-08-26-LMM_VQA_Advancing_Video_Quality_Assessment_with_Large_Multimodal_Models.html#major-findings",
    "title": "LMM-VQA: Advancing Video Quality Assessment with Large Multimodal Models",
    "section": "Major Findings",
    "text": "Major Findings\n\nLMM-VQA achieves state-of-the-art performance across five VQA benchmarks, demonstrating an average improvement of in generalization ability over existing methods.\nThe advanced design of the spatiotemporal encoder and projector enables LMM-VQA to perform exceptionally well on general video understanding tasks.\nThe code for LMM-VQA will be made available at https://github.com/Sueqk/LMM-VQA."
  },
  {
    "objectID": "posts/LMM_VQA_Advancing_Video_Quality_Assessment_with_Large_Multimodal_Models/2024-08-26-LMM_VQA_Advancing_Video_Quality_Assessment_with_Large_Multimodal_Models.html#analysis-and-critique",
    "href": "posts/LMM_VQA_Advancing_Video_Quality_Assessment_with_Large_Multimodal_Models/2024-08-26-LMM_VQA_Advancing_Video_Quality_Assessment_with_Large_Multimodal_Models.html#analysis-and-critique",
    "title": "LMM-VQA: Advancing Video Quality Assessment with Large Multimodal Models",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\n\nThe paper presents a promising approach to VQA using LMMs, which has the potential to improve the performance and generalization ability of VQA models.\nThe use of a spatiotemporal vision encoder and modality alignment is a novel approach to addressing the challenges of VQA, which could inspire further research in this area.\nThe paper does not provide a detailed comparison of LMM-VQA with other state-of-the-art VQA methods, which could help to better understand its strengths and limitations.\nThe paper does not discuss the computational complexity and efficiency of LMM-VQA, which are important considerations for practical applications.\nThe paper does not provide a detailed analysis of the limitations and potential biases of LMM-VQA, which could help to identify areas for improvement and further research."
  },
  {
    "objectID": "posts/LMM_VQA_Advancing_Video_Quality_Assessment_with_Large_Multimodal_Models/2024-08-26-LMM_VQA_Advancing_Video_Quality_Assessment_with_Large_Multimodal_Models.html#appendix",
    "href": "posts/LMM_VQA_Advancing_Video_Quality_Assessment_with_Large_Multimodal_Models/2024-08-26-LMM_VQA_Advancing_Video_Quality_Assessment_with_Large_Multimodal_Models.html#appendix",
    "title": "LMM-VQA: Advancing Video Quality Assessment with Large Multimodal Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.14008v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.14008v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8834"
  },
  {
    "objectID": "posts/Can_Large_Language_Models_Automatically_Jailbreak_GPT_4V/2024-07-23-Can_Large_Language_Models_Automatically_Jailbreak_GPT_4V.html#appendix",
    "href": "posts/Can_Large_Language_Models_Automatically_Jailbreak_GPT_4V/2024-07-23-Can_Large_Language_Models_Automatically_Jailbreak_GPT_4V.html#appendix",
    "title": "Can Large Language Models Automatically Jailbreak GPT-4V?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16686v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16686v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6844"
  },
  {
    "objectID": "posts/Targeted_Visual_Prompting_for_Medical_Visual_Question_Answering/2024-08-06-Targeted_Visual_Prompting_for_Medical_Visual_Question_Answering.html#major-findings",
    "href": "posts/Targeted_Visual_Prompting_for_Medical_Visual_Question_Answering/2024-08-06-Targeted_Visual_Prompting_for_Medical_Visual_Question_Answering.html#major-findings",
    "title": "Targeted Visual Prompting for Medical Visual Question Answering",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe paper addresses the issue of simple visual errors in MLLMs, which cast doubt on their actual visual understanding abilities.\nThe authors propose a novel approach using the formulation of localized questions to detect visual understanding failures and enhance explainability in the visual component of Med-VQA.\nThe proposed Targeted Visual Prompting method allows the full advantage of the MLLM to enhance the performance of the VQA model by providing both global and local visual tokens relative to the region of interest defined by the user.\nThe method is validated through exhaustive experiments across multiple datasets, demonstrating clear performance benefits compared to previously proposed methods without introducing additional parameters to the model."
  },
  {
    "objectID": "posts/Targeted_Visual_Prompting_for_Medical_Visual_Question_Answering/2024-08-06-Targeted_Visual_Prompting_for_Medical_Visual_Question_Answering.html#analysis-and-critique",
    "href": "posts/Targeted_Visual_Prompting_for_Medical_Visual_Question_Answering/2024-08-06-Targeted_Visual_Prompting_for_Medical_Visual_Question_Answering.html#analysis-and-critique",
    "title": "Targeted Visual Prompting for Medical Visual Question Answering",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper effectively addresses the limitations of traditional Med-VQA methods, which fail to benefit MLLMs due to their design focused on traditional architectures.\nThe proposed method enables localized questions in MLLMs in Med-VQA, allowing for fine-grained probing of images by focusing on user-defined regions rather than the entire image.\nThe method allows for a compositional evaluation, facilitating the interpretation of the model’s visual understanding capabilities.\nThe paper provides a comprehensive evaluation of the proposed method across multiple datasets, demonstrating its effectiveness in enhancing the performance of MLLMs in Med-VQA.\nHowever, the paper does not discuss the potential limitations or shortcomings of the proposed method, such as the reliance on the quality of the visual tokens or the potential for overfitting to specific datasets.\nAdditionally, the paper does not explore the potential for the method to be extended to other domains or applications beyond Med-VQA.\n\nOverall, the paper presents a novel and effective approach to enhancing the visual understanding capabilities of MLLMs in Med"
  },
  {
    "objectID": "posts/Targeted_Visual_Prompting_for_Medical_Visual_Question_Answering/2024-08-06-Targeted_Visual_Prompting_for_Medical_Visual_Question_Answering.html#appendix",
    "href": "posts/Targeted_Visual_Prompting_for_Medical_Visual_Question_Answering/2024-08-06-Targeted_Visual_Prompting_for_Medical_Visual_Question_Answering.html#appendix",
    "title": "Targeted Visual Prompting for Medical Visual Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03043v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03043v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3173"
  },
  {
    "objectID": "posts/Graph_Retrieval_Augmented_Trustworthiness_Reasoning/2024-08-22-Graph_Retrieval_Augmented_Trustworthiness_Reasoning.html#appendix",
    "href": "posts/Graph_Retrieval_Augmented_Trustworthiness_Reasoning/2024-08-22-Graph_Retrieval_Augmented_Trustworthiness_Reasoning.html#appendix",
    "title": "Graph Retrieval Augmented Trustworthiness Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12333v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12333v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7446"
  },
  {
    "objectID": "posts/Augmenting_Query_and_Passage_for_Retrieval_Augmented_Generation_using_LLMs_for_Open_Domain_Question_Answering/2024-06-20-Augmenting_Query_and_Passage_for_Retrieval_Augmented_Generation_using_LLMs_for_Open_Domain_Question_Answering.html#appendix",
    "href": "posts/Augmenting_Query_and_Passage_for_Retrieval_Augmented_Generation_using_LLMs_for_Open_Domain_Question_Answering/2024-06-20-Augmenting_Query_and_Passage_for_Retrieval_Augmented_Generation_using_LLMs_for_Open_Domain_Question_Answering.html#appendix",
    "title": "Augmenting Query and Passage for Retrieval-Augmented Generation using LLMs for Open-Domain Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14277v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14277v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6421"
  },
  {
    "objectID": "posts/Poor_Supervised_Evaluation_for_SuperLLM_via_Mutual_Consistency/2024-08-25-Poor_Supervised_Evaluation_for_SuperLLM_via_Mutual_Consistency.html#appendix",
    "href": "posts/Poor_Supervised_Evaluation_for_SuperLLM_via_Mutual_Consistency/2024-08-25-Poor_Supervised_Evaluation_for_SuperLLM_via_Mutual_Consistency.html#appendix",
    "title": "Poor-Supervised Evaluation for SuperLLM via Mutual Consistency",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.13738v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.13738v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6446"
  },
  {
    "objectID": "posts/Cost_Effective_Hallucination_Detection_for_LLMs/2024-07-31-Cost_Effective_Hallucination_Detection_for_LLMs.html#appendix",
    "href": "posts/Cost_Effective_Hallucination_Detection_for_LLMs/2024-07-31-Cost_Effective_Hallucination_Detection_for_LLMs.html#appendix",
    "title": "Cost-Effective Hallucination Detection for LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21424v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21424v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8476"
  },
  {
    "objectID": "posts/The_current_status_of_large_language_models_in_summarizing_radiology_report_impressions/2024-06-04-The_current_status_of_large_language_models_in_summarizing_radiology_report_impressions.html#appendix",
    "href": "posts/The_current_status_of_large_language_models_in_summarizing_radiology_report_impressions/2024-06-04-The_current_status_of_large_language_models_in_summarizing_radiology_report_impressions.html#appendix",
    "title": "The current status of large language models in summarizing radiology report impressions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02134v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02134v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7591"
  },
  {
    "objectID": "posts/MMM_Multilingual_Mutual_Reinforcement_Effect_Mix_Datasets__Test_with_Open_domain_Information_Extraction_Large_Language_Models/2024-07-15-MMM_Multilingual_Mutual_Reinforcement_Effect_Mix_Datasets__Test_with_Open_domain_Information_Extraction_Large_Language_Models.html#appendix",
    "href": "posts/MMM_Multilingual_Mutual_Reinforcement_Effect_Mix_Datasets__Test_with_Open_domain_Information_Extraction_Large_Language_Models/2024-07-15-MMM_Multilingual_Mutual_Reinforcement_Effect_Mix_Datasets__Test_with_Open_domain_Information_Extraction_Large_Language_Models.html#appendix",
    "title": "MMM: Multilingual Mutual Reinforcement Effect Mix Datasets & Test with Open-domain Information Extraction Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10953v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10953v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5622"
  },
  {
    "objectID": "posts/Nob_MIAs_Non_biased_Membership_Inference_Attacks_Assessment_on_Large_Language_Models_with_Ex_Post_Dataset_Construction/2024-08-12-Nob_MIAs_Non_biased_Membership_Inference_Attacks_Assessment_on_Large_Language_Models_with_Ex_Post_Dataset_Construction.html#appendix",
    "href": "posts/Nob_MIAs_Non_biased_Membership_Inference_Attacks_Assessment_on_Large_Language_Models_with_Ex_Post_Dataset_Construction/2024-08-12-Nob_MIAs_Non_biased_Membership_Inference_Attacks_Assessment_on_Large_Language_Models_with_Ex_Post_Dataset_Construction.html#appendix",
    "title": "Nob-MIAs: Non-biased Membership Inference Attacks Assessment on Large Language Models with Ex-Post Dataset Construction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.05968v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.05968v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7404"
  },
  {
    "objectID": "posts/FsPONER_Few_shot_Prompt_Optimization_for_Named_Entity_Recognition_in_Domain_specific_Scenarios/2024-07-10-FsPONER_Few_shot_Prompt_Optimization_for_Named_Entity_Recognition_in_Domain_specific_Scenarios.html#appendix",
    "href": "posts/FsPONER_Few_shot_Prompt_Optimization_for_Named_Entity_Recognition_in_Domain_specific_Scenarios/2024-07-10-FsPONER_Few_shot_Prompt_Optimization_for_Named_Entity_Recognition_in_Domain_specific_Scenarios.html#appendix",
    "title": "FsPONER: Few-shot Prompt Optimization for Named Entity Recognition in Domain-specific Scenarios",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08035v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08035v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7052"
  },
  {
    "objectID": "posts/Crosslingual_Capabilities_and_Knowledge_Barriers_in_Multilingual_Large_Language_Models/2024-06-23-Crosslingual_Capabilities_and_Knowledge_Barriers_in_Multilingual_Large_Language_Models.html#appendix",
    "href": "posts/Crosslingual_Capabilities_and_Knowledge_Barriers_in_Multilingual_Large_Language_Models/2024-06-23-Crosslingual_Capabilities_and_Knowledge_Barriers_in_Multilingual_Large_Language_Models.html#appendix",
    "title": "Crosslingual Capabilities and Knowledge Barriers in Multilingual Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16135v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16135v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11266"
  },
  {
    "objectID": "posts/Exploring_Changes_in_Nation_Perception_with_Nationality_Assigned_Personas_in_LLMs/2024-06-20-Exploring_Changes_in_Nation_Perception_with_Nationality_Assigned_Personas_in_LLMs.html#appendix",
    "href": "posts/Exploring_Changes_in_Nation_Perception_with_Nationality_Assigned_Personas_in_LLMs/2024-06-20-Exploring_Changes_in_Nation_Perception_with_Nationality_Assigned_Personas_in_LLMs.html#appendix",
    "title": "Exploring Changes in Nation Perception with Nationality-Assigned Personas in LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13993v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13993v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4062"
  },
  {
    "objectID": "posts/Shared_Imagination_LLMs_Hallucinate_Alike/2024-07-23-Shared_Imagination_LLMs_Hallucinate_Alike.html#appendix",
    "href": "posts/Shared_Imagination_LLMs_Hallucinate_Alike/2024-07-23-Shared_Imagination_LLMs_Hallucinate_Alike.html#appendix",
    "title": "Shared Imagination: LLMs Hallucinate Alike",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16604v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16604v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7135"
  },
  {
    "objectID": "posts/CIPHER_Cybersecurity_Intelligent_Penetration_testing_Helper_for_Ethical_Researcher/2024-08-21-CIPHER_Cybersecurity_Intelligent_Penetration_testing_Helper_for_Ethical_Researcher.html#appendix",
    "href": "posts/CIPHER_Cybersecurity_Intelligent_Penetration_testing_Helper_for_Ethical_Researcher/2024-08-21-CIPHER_Cybersecurity_Intelligent_Penetration_testing_Helper_for_Ethical_Researcher.html#appendix",
    "title": "CIPHER: Cybersecurity Intelligent Penetration-testing Helper for Ethical Researcher",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11650v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11650v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13773"
  },
  {
    "objectID": "posts/RVISA_Reasoning_and_Verification_for_Implicit_Sentiment_Analysis/2024-07-02-RVISA_Reasoning_and_Verification_for_Implicit_Sentiment_Analysis.html#appendix",
    "href": "posts/RVISA_Reasoning_and_Verification_for_Implicit_Sentiment_Analysis/2024-07-02-RVISA_Reasoning_and_Verification_for_Implicit_Sentiment_Analysis.html#appendix",
    "title": "RVISA: Reasoning and Verification for Implicit Sentiment Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02340v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02340v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7317"
  },
  {
    "objectID": "posts/Enhancing_Healthcare_through_Large_Language_Models_A_Study_on_Medical_Question_Answering/2024-08-08-Enhancing_Healthcare_through_Large_Language_Models_A_Study_on_Medical_Question_Answering.html#appendix",
    "href": "posts/Enhancing_Healthcare_through_Large_Language_Models_A_Study_on_Medical_Question_Answering/2024-08-08-Enhancing_Healthcare_through_Large_Language_Models_A_Study_on_Medical_Question_Answering.html#appendix",
    "title": "Enhancing Healthcare through Large Language Models: A Study on Medical Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04138v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04138v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4386"
  },
  {
    "objectID": "posts/FastGAS_Fast_Graph_based_Annotation_Selection_for_In_Context_Learning/2024-06-06-FastGAS_Fast_Graph_based_Annotation_Selection_for_In_Context_Learning.html#appendix",
    "href": "posts/FastGAS_Fast_Graph_based_Annotation_Selection_for_In_Context_Learning/2024-06-06-FastGAS_Fast_Graph_based_Annotation_Selection_for_In_Context_Learning.html#appendix",
    "title": "FastGAS: Fast Graph-based Annotation Selection for In-Context Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03730v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03730v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8522"
  },
  {
    "objectID": "posts/Converging_Paradigms_The_Synergy_of_Symbolic_and_Connectionist_AI_in_LLM_Empowered_Autonomous_Agents/2024-07-11-Converging_Paradigms_The_Synergy_of_Symbolic_and_Connectionist_AI_in_LLM_Empowered_Autonomous_Agents.html#appendix",
    "href": "posts/Converging_Paradigms_The_Synergy_of_Symbolic_and_Connectionist_AI_in_LLM_Empowered_Autonomous_Agents/2024-07-11-Converging_Paradigms_The_Synergy_of_Symbolic_and_Connectionist_AI_in_LLM_Empowered_Autonomous_Agents.html#appendix",
    "title": "Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08516v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08516v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6221"
  },
  {
    "objectID": "posts/LLM_DetectAIve_a_Tool_for_Fine_Grained_Machine_Generated_Text_Detection/2024-08-08-LLM_DetectAIve_a_Tool_for_Fine_Grained_Machine_Generated_Text_Detection.html#appendix",
    "href": "posts/LLM_DetectAIve_a_Tool_for_Fine_Grained_Machine_Generated_Text_Detection/2024-08-08-LLM_DetectAIve_a_Tool_for_Fine_Grained_Machine_Generated_Text_Detection.html#appendix",
    "title": "LLM-DetectAIve: a Tool for Fine-Grained Machine-Generated Text Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04284v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04284v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3866"
  },
  {
    "objectID": "posts/PrefCLM_Enhancing_Preference_based_Reinforcement_Learning_with_Crowdsourced_Large_Language_Models/2024-07-11-PrefCLM_Enhancing_Preference_based_Reinforcement_Learning_with_Crowdsourced_Large_Language_Models.html",
    "href": "posts/PrefCLM_Enhancing_Preference_based_Reinforcement_Learning_with_Crowdsourced_Large_Language_Models/2024-07-11-PrefCLM_Enhancing_Preference_based_Reinforcement_Learning_with_Crowdsourced_Large_Language_Models.html",
    "title": "PrefCLM: Enhancing Preference-based Reinforcement Learning with Crowdsourced Large Language Models",
    "section": "",
    "text": "Summary:\nThe article introduces PrefCLM, a novel framework that utilizes crowdsourced large language models (LLMs) as simulated teachers in preference-based reinforcement learning (PbRL). PrefCLM aims to address the challenges of existing PbRL methods, which often require a large volume of feedback and rely on synthetic feedback generated by scripted teachers. The framework employs Dempster-Shafer Theory to fuse individual preferences from multiple LLM agents at the score level, efficiently leveraging their diversity and collective intelligence. Additionally, PrefCLM includes a human-in-the-loop pipeline that facilitates collective refinements based on user interactive feedback.\nMajor Findings:\nAnalysis and Critique:\nWhile PrefCLM shows promising results, there are potential limitations and areas for further research. The reliance on LLMs for generating synthetic feedback may introduce biases or inaccuracies, as LLMs may not fully capture the nuances of human preferences. Additionally, the scalability and generalizability of PrefCLM to more complex tasks and environments remain to be explored. Further research is needed to address these challenges and validate the effectiveness of PrefCLM in diverse HRI scenarios."
  },
  {
    "objectID": "posts/PrefCLM_Enhancing_Preference_based_Reinforcement_Learning_with_Crowdsourced_Large_Language_Models/2024-07-11-PrefCLM_Enhancing_Preference_based_Reinforcement_Learning_with_Crowdsourced_Large_Language_Models.html#appendix",
    "href": "posts/PrefCLM_Enhancing_Preference_based_Reinforcement_Learning_with_Crowdsourced_Large_Language_Models/2024-07-11-PrefCLM_Enhancing_Preference_based_Reinforcement_Learning_with_Crowdsourced_Large_Language_Models.html#appendix",
    "title": "PrefCLM: Enhancing Preference-based Reinforcement Learning with Crowdsourced Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08213v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08213v1\n\n\nTruncated\nFalse\n\n\nWord Count\n19231"
  },
  {
    "objectID": "posts/Controllable_Navigation_Instruction_Generation_with_Chain_of_Thought_Prompting/2024-07-10-Controllable_Navigation_Instruction_Generation_with_Chain_of_Thought_Prompting.html#appendix",
    "href": "posts/Controllable_Navigation_Instruction_Generation_with_Chain_of_Thought_Prompting/2024-07-10-Controllable_Navigation_Instruction_Generation_with_Chain_of_Thought_Prompting.html#appendix",
    "title": "Controllable Navigation Instruction Generation with Chain of Thought Prompting",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07433v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07433v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7664"
  },
  {
    "objectID": "posts/Enhancing_Computer_Programming_Education_with_LLMs_A_Study_on_Effective_Prompt_Engineering_for_Python_Code_Generation/2024-07-07-Enhancing_Computer_Programming_Education_with_LLMs_A_Study_on_Effective_Prompt_Engineering_for_Python_Code_Generation.html#appendix",
    "href": "posts/Enhancing_Computer_Programming_Education_with_LLMs_A_Study_on_Effective_Prompt_Engineering_for_Python_Code_Generation/2024-07-07-Enhancing_Computer_Programming_Education_with_LLMs_A_Study_on_Effective_Prompt_Engineering_for_Python_Code_Generation.html#appendix",
    "title": "Enhancing Computer Programming Education with LLMs: A Study on Effective Prompt Engineering for Python Code Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05437v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05437v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9547"
  },
  {
    "objectID": "posts/LLM_Enhanced_Static_Analysis_for_Precise_Identification_of_Vulnerable_OSS_Versions/2024-08-14-LLM_Enhanced_Static_Analysis_for_Precise_Identification_of_Vulnerable_OSS_Versions.html#major-findings",
    "href": "posts/LLM_Enhanced_Static_Analysis_for_Precise_Identification_of_Vulnerable_OSS_Versions/2024-08-14-LLM_Enhanced_Static_Analysis_for_Precise_Identification_of_Vulnerable_OSS_Versions.html#major-findings",
    "title": "LLM-Enhanced Static Analysis for Precise Identification of Vulnerable OSS Versions",
    "section": "Major Findings",
    "text": "Major Findings\n\nVercation, an approach combining program slicing with a Large Language Model (LLM), effectively identifies vulnerable versions of open-source C/C++ software.\nThe approach achieves an F1 score of 92.4% on a curated dataset, outperforming current state-of-the-art methods.\nVercation detected 134 incorrect vulnerable OSS versions in NVD reports, highlighting its effectiveness in identifying vulnerable versions."
  },
  {
    "objectID": "posts/LLM_Enhanced_Static_Analysis_for_Precise_Identification_of_Vulnerable_OSS_Versions/2024-08-14-LLM_Enhanced_Static_Analysis_for_Precise_Identification_of_Vulnerable_OSS_Versions.html#analysis-and-critique",
    "href": "posts/LLM_Enhanced_Static_Analysis_for_Precise_Identification_of_Vulnerable_OSS_Versions/2024-08-14-LLM_Enhanced_Static_Analysis_for_Precise_Identification_of_Vulnerable_OSS_Versions.html#analysis-and-critique",
    "title": "LLM-Enhanced Static Analysis for Precise Identification of Vulnerable OSS Versions",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\nThe paper presents a novel approach to identifying vulnerable versions of open-source C/C++ software. The use of a Large Language Model (LLM) in conjunction with program slicing is a unique contribution to the field. The authors’ curation of a dataset linking 74 OSS vulnerabilities and 1013 versions is commendable, as it provides a robust basis for evaluating the approach.\nHowever, the paper does not provide a detailed comparison of Vercation with other state-of-the-art methods. While the F1 score of 92.4% is impressive, it would be beneficial to understand how this compares to other approaches in terms of precision, recall, and other relevant metrics. Additionally, the paper does not discuss"
  },
  {
    "objectID": "posts/LLM_Enhanced_Static_Analysis_for_Precise_Identification_of_Vulnerable_OSS_Versions/2024-08-14-LLM_Enhanced_Static_Analysis_for_Precise_Identification_of_Vulnerable_OSS_Versions.html#appendix",
    "href": "posts/LLM_Enhanced_Static_Analysis_for_Precise_Identification_of_Vulnerable_OSS_Versions/2024-08-14-LLM_Enhanced_Static_Analysis_for_Precise_Identification_of_Vulnerable_OSS_Versions.html#appendix",
    "title": "LLM-Enhanced Static Analysis for Precise Identification of Vulnerable OSS Versions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07321v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07321v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13214"
  },
  {
    "objectID": "posts/When_is_the_consistent_prediction_likely_to_be_a_correct_prediction/2024-07-08-When_is_the_consistent_prediction_likely_to_be_a_correct_prediction.html#appendix",
    "href": "posts/When_is_the_consistent_prediction_likely_to_be_a_correct_prediction/2024-07-08-When_is_the_consistent_prediction_likely_to_be_a_correct_prediction.html#appendix",
    "title": "When is the consistent prediction likely to be a correct prediction?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05778v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05778v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4435"
  },
  {
    "objectID": "posts/Look_Within_Why_LLMs_Hallucinate_A_Causal_Perspective/2024-07-14-Look_Within_Why_LLMs_Hallucinate_A_Causal_Perspective.html#appendix",
    "href": "posts/Look_Within_Why_LLMs_Hallucinate_A_Causal_Perspective/2024-07-14-Look_Within_Why_LLMs_Hallucinate_A_Causal_Perspective.html#appendix",
    "title": "Look Within, Why LLMs Hallucinate: A Causal Perspective",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10153v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10153v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5521"
  },
  {
    "objectID": "posts/Evaluating_Large_Language_Models_with_Grid_Based_Game_Competitions_An_Extensible_LLM_Benchmark_and_Leaderboard/2024-07-11-Evaluating_Large_Language_Models_with_Grid_Based_Game_Competitions_An_Extensible_LLM_Benchmark_and_Leaderboard.html#major-findings",
    "href": "posts/Evaluating_Large_Language_Models_with_Grid_Based_Game_Competitions_An_Extensible_LLM_Benchmark_and_Leaderboard/2024-07-11-Evaluating_Large_Language_Models_with_Grid_Based_Game_Competitions_An_Extensible_LLM_Benchmark_and_Leaderboard.html#major-findings",
    "title": "Evaluating Large Language Models with Grid-Based Game Competitions: An Extensible LLM Benchmark and Leaderboard",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nLLMs perform relatively well in simpler formats, such as list prompts for Tic-Tac-Toe and Connect Four, but their performance declines with more complex prompts, especially those involving illustrations and images.\nLLMs show a tendency to make invalid moves when faced with more complex prompts, underscoring the need for improved strategic decision-making processes.\nThe study reveals both the strengths and limitations of LLMs, pointing to the need for ongoing research to enhance their ability to process complex and visual data, improve decision-making processes, and develop more sophisticated benchmarking tools."
  },
  {
    "objectID": "posts/Evaluating_Large_Language_Models_with_Grid_Based_Game_Competitions_An_Extensible_LLM_Benchmark_and_Leaderboard/2024-07-11-Evaluating_Large_Language_Models_with_Grid_Based_Game_Competitions_An_Extensible_LLM_Benchmark_and_Leaderboard.html#analysis-and-critique",
    "href": "posts/Evaluating_Large_Language_Models_with_Grid_Based_Game_Competitions_An_Extensible_LLM_Benchmark_and_Leaderboard/2024-07-11-Evaluating_Large_Language_Models_with_Grid_Based_Game_Competitions_An_Extensible_LLM_Benchmark_and_Leaderboard.html#analysis-and-critique",
    "title": "Evaluating Large Language Models with Grid-Based Game Competitions: An Extensible LLM Benchmark and Leaderboard",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThis study provides a valuable contribution to the field by introducing a novel and extensible benchmark for LLMs using grid-based games. The use of open-source game simulation code and the generation of detailed data files in various formats facilitate further analysis and comparison of LLM performance. However, the study has some limitations. The focus on a select group of LLMs might not capture the full diversity of strategic approaches across available models. Additionally, the simplicity of the games used in this benchmark may not challenge LLMs’ strategic capabilities as much as more complex games like chess or Go might.\nFuture work could explore several promising directions to extend research and deepen our understanding"
  },
  {
    "objectID": "posts/Evaluating_Large_Language_Models_with_Grid_Based_Game_Competitions_An_Extensible_LLM_Benchmark_and_Leaderboard/2024-07-11-Evaluating_Large_Language_Models_with_Grid_Based_Game_Competitions_An_Extensible_LLM_Benchmark_and_Leaderboard.html#appendix",
    "href": "posts/Evaluating_Large_Language_Models_with_Grid_Based_Game_Competitions_An_Extensible_LLM_Benchmark_and_Leaderboard/2024-07-11-Evaluating_Large_Language_Models_with_Grid_Based_Game_Competitions_An_Extensible_LLM_Benchmark_and_Leaderboard.html#appendix",
    "title": "Evaluating Large Language Models with Grid-Based Game Competitions: An Extensible LLM Benchmark and Leaderboard",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07796v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07796v2\n\n\nTruncated\nFalse\n\n\nWord Count\n13403"
  },
  {
    "objectID": "posts/Mitigating_Hallucination_in_Fictional_Character_Role_Play/2024-06-25-Mitigating_Hallucination_in_Fictional_Character_Role_Play.html#appendix",
    "href": "posts/Mitigating_Hallucination_in_Fictional_Character_Role_Play/2024-06-25-Mitigating_Hallucination_in_Fictional_Character_Role_Play.html#appendix",
    "title": "Mitigating Hallucination in Fictional Character Role-Play",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17260v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17260v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5369"
  },
  {
    "objectID": "posts/StuGPTViz_A_Visual_Analytics_Approach_to_Understand_Student_ChatGPT_Interactions/2024-07-17-StuGPTViz_A_Visual_Analytics_Approach_to_Understand_Student_ChatGPT_Interactions.html#appendix",
    "href": "posts/StuGPTViz_A_Visual_Analytics_Approach_to_Understand_Student_ChatGPT_Interactions/2024-07-17-StuGPTViz_A_Visual_Analytics_Approach_to_Understand_Student_ChatGPT_Interactions.html#appendix",
    "title": "StuGPTViz: A Visual Analytics Approach to Understand Student-ChatGPT Interactions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.12423v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.12423v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12718"
  },
  {
    "objectID": "posts/Clinical_Insights_A_Comprehensive_Review_of_Language_Models_in_Medicine/2024-08-21-Clinical_Insights_A_Comprehensive_Review_of_Language_Models_in_Medicine.html",
    "href": "posts/Clinical_Insights_A_Comprehensive_Review_of_Language_Models_in_Medicine/2024-08-21-Clinical_Insights_A_Comprehensive_Review_of_Language_Models_in_Medicine.html",
    "title": "Clinical Insights: A Comprehensive Review of Language Models in Medicine",
    "section": "",
    "text": "Summary:\nThis paper provides a comprehensive review of the advancements and applications of large language models (LLMs) in the healthcare sector, with a focus on clinical applications. The study traces the evolution of LLMs from their foundational technologies to the latest developments in domain-specific models and multimodal integration. It discusses the opportunities these technologies present for enhancing clinical efficiency and the challenges they pose in terms of ethics, data privacy, and implementation. The paper also critically evaluates the deployment strategies of LLMs, emphasizing the necessity of open-source models to ensure data privacy and adaptability within healthcare environments. Future research directions are proposed, focusing on empirical studies to evaluate the real-world efficacy of LLMs in healthcare and the development of open datasets for further research.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive overview of the advancements and applications of LLMs in the healthcare sector. However, it does not delve deeply into the methodological issues, conflicting evidence, or areas that require further research or clarification. The paper also does not discuss the potential biases or limitations of the reviewed studies. Furthermore, the paper does not provide a detailed exploration of the potential risks and ethical implications of using LLMs in healthcare, which is a critical aspect that needs to be addressed.\nThe paper also does not discuss the potential impact of LLMs on"
  },
  {
    "objectID": "posts/Clinical_Insights_A_Comprehensive_Review_of_Language_Models_in_Medicine/2024-08-21-Clinical_Insights_A_Comprehensive_Review_of_Language_Models_in_Medicine.html#appendix",
    "href": "posts/Clinical_Insights_A_Comprehensive_Review_of_Language_Models_in_Medicine/2024-08-21-Clinical_Insights_A_Comprehensive_Review_of_Language_Models_in_Medicine.html#appendix",
    "title": "Clinical Insights: A Comprehensive Review of Language Models in Medicine",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11735v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11735v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10828"
  },
  {
    "objectID": "posts/GPT_Assisted_Annotation_of_Rhetorical_and_Linguistic_Features_for_Interpretable_Propaganda_Technique_Detection_in_News_Text/2024-07-16-GPT_Assisted_Annotation_of_Rhetorical_and_Linguistic_Features_for_Interpretable_Propaganda_Technique_Detection_in_News_Text.html#appendix",
    "href": "posts/GPT_Assisted_Annotation_of_Rhetorical_and_Linguistic_Features_for_Interpretable_Propaganda_Technique_Detection_in_News_Text/2024-07-16-GPT_Assisted_Annotation_of_Rhetorical_and_Linguistic_Features_for_Interpretable_Propaganda_Technique_Detection_in_News_Text.html#appendix",
    "title": "GPT Assisted Annotation of Rhetorical and Linguistic Features for Interpretable Propaganda Technique Detection in News Text",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.11827v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.11827v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7256"
  },
  {
    "objectID": "posts/Casper_Prompt_Sanitization_for_Protecting_User_Privacy_in_Web_Based_Large_Language_Models/2024-08-13-Casper_Prompt_Sanitization_for_Protecting_User_Privacy_in_Web_Based_Large_Language_Models.html#appendix",
    "href": "posts/Casper_Prompt_Sanitization_for_Protecting_User_Privacy_in_Web_Based_Large_Language_Models/2024-08-13-Casper_Prompt_Sanitization_for_Protecting_User_Privacy_in_Web_Based_Large_Language_Models.html#appendix",
    "title": "Casper: Prompt Sanitization for Protecting User Privacy in Web-Based Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07004v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07004v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12904"
  },
  {
    "objectID": "posts/The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis/2024-06-19-The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis.html",
    "href": "posts/The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis/2024-06-19-The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis.html",
    "title": "The Efficacy of Conversational Artificial Intelligence in Rectifying the Theory of Mind and Autonomy Biases: Comparative Analysis",
    "section": "",
    "text": "Summary:\nThis study evaluates the efficacy of Conversational Artificial Intelligence (CAI) in rectifying cognitive biases and recognizing affect in human-AI interactions, which is crucial for digital mental health interventions. The research employs a structured methodology with clinical-based virtual case scenarios simulating typical user-bot interactions. Performance and affect recognition were assessed across two categories of cognitive biases: theory of mind biases (anthropomorphization of AI, overtrust in AI, attribution to AI) and autonomy biases (illusion of control, fundamental attribution error, just-world hypothesis). A qualitative feedback mechanism was used with an ordinal scale to quantify responses based on accuracy, therapeutic quality, and adherence to CBT principles. Therapeutic bots (Wysa, Youper) and general-use LLMs (GTP 3.5, GTP 4, Gemini Pro) were evaluated through scripted interactions, double-reviewed by cognitive scientists and a clinical psychologist. Statistical analysis showed therapeutic bots were consistently outperformed by non-therapeutic bots in bias rectification and in 4 out of 6 biases in affect recognition. The data suggests that non-therapeutic chatbots are more effective in addressing some cognitive biases.\nMajor Findings:"
  },
  {
    "objectID": "posts/The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis/2024-06-19-The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis.html#appendix",
    "href": "posts/The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis/2024-06-19-The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis.html#appendix",
    "title": "The Efficacy of Conversational Artificial Intelligence in Rectifying the Theory of Mind and Autonomy Biases: Comparative Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13813v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13813v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17145"
  },
  {
    "objectID": "posts/Prism_A_Framework_for_Decoupling_and_Assessing_the_Capabilities_of_VLMs/2024-06-20-Prism_A_Framework_for_Decoupling_and_Assessing_the_Capabilities_of_VLMs.html#appendix",
    "href": "posts/Prism_A_Framework_for_Decoupling_and_Assessing_the_Capabilities_of_VLMs/2024-06-20-Prism_A_Framework_for_Decoupling_and_Assessing_the_Capabilities_of_VLMs.html#appendix",
    "title": "Prism: A Framework for Decoupling and Assessing the Capabilities of VLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14544v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14544v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8916"
  },
  {
    "objectID": "posts/LLM_Based_Robust_Product_Classification_in_Commerce_and_Compliance/2024-08-11-LLM_Based_Robust_Product_Classification_in_Commerce_and_Compliance.html#appendix",
    "href": "posts/LLM_Based_Robust_Product_Classification_in_Commerce_and_Compliance/2024-08-11-LLM_Based_Robust_Product_Classification_in_Commerce_and_Compliance.html#appendix",
    "title": "LLM-Based Robust Product Classification in Commerce and Compliance",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.05874v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.05874v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6218"
  },
  {
    "objectID": "posts/Whats_Wrong_with_Your_Code_Generated_by_Large_Language_Models_An_Extensive_Study/2024-07-08-Whats_Wrong_with_Your_Code_Generated_by_Large_Language_Models_An_Extensive_Study.html#appendix",
    "href": "posts/Whats_Wrong_with_Your_Code_Generated_by_Large_Language_Models_An_Extensive_Study/2024-07-08-Whats_Wrong_with_Your_Code_Generated_by_Large_Language_Models_An_Extensive_Study.html#appendix",
    "title": "What’s Wrong with Your Code Generated by Large Language Models? An Extensive Study",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06153v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06153v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14163"
  },
  {
    "objectID": "posts/Incorporating_Large_Language_Models_into_Production_Systems_for_Enhanced_Task_Automation_and_Flexibility/2024-07-11-Incorporating_Large_Language_Models_into_Production_Systems_for_Enhanced_Task_Automation_and_Flexibility.html#appendix",
    "href": "posts/Incorporating_Large_Language_Models_into_Production_Systems_for_Enhanced_Task_Automation_and_Flexibility/2024-07-11-Incorporating_Large_Language_Models_into_Production_Systems_for_Enhanced_Task_Automation_and_Flexibility.html#appendix",
    "title": "Incorporating Large Language Models into Production Systems for Enhanced Task Automation and Flexibility",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08550v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08550v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8495"
  },
  {
    "objectID": "posts/Large_Language_Models_are_Skeptics_False_Negative_Problem_of_Input_conflicting_Hallucination/2024-06-20-Large_Language_Models_are_Skeptics_False_Negative_Problem_of_Input_conflicting_Hallucination.html#appendix",
    "href": "posts/Large_Language_Models_are_Skeptics_False_Negative_Problem_of_Input_conflicting_Hallucination/2024-06-20-Large_Language_Models_are_Skeptics_False_Negative_Problem_of_Input_conflicting_Hallucination.html#appendix",
    "title": "Large Language Models are Skeptics: False Negative Problem of Input-conflicting Hallucination",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13929v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13929v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4576"
  },
  {
    "objectID": "posts/Investigating_the_Effectiveness_of_Bayesian_Spam_Filters_in_Detecting_LLM_modified_Spam_Mails/2024-08-26-Investigating_the_Effectiveness_of_Bayesian_Spam_Filters_in_Detecting_LLM_modified_Spam_Mails.html#major-findings",
    "href": "posts/Investigating_the_Effectiveness_of_Bayesian_Spam_Filters_in_Detecting_LLM_modified_Spam_Mails/2024-08-26-Investigating_the_Effectiveness_of_Bayesian_Spam_Filters_in_Detecting_LLM_modified_Spam_Mails.html#major-findings",
    "title": "Investigating the Effectiveness of Bayesian Spam Filters in Detecting LLM-modified Spam Mails",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nLLM-modified spam emails bypass traditional spam filters: The study found that LLM-modified spam emails can evade traditional spam filters, with SpamAssassin misclassifying up to 73.7% of these emails as legitimate.\nCost-efficiency of LLM-modified spam attacks: The cost-efficiency of LLM-modified spam attacks (0.17 cents per email) makes them a significant threat to cybersecurity.\nLimited effectiveness of simpler attacks: Simpler attacks, such as dictionary-replacement attacks, have limited effectiveness in bypassing spam filters, with a maximum success rate of only 0.4%."
  },
  {
    "objectID": "posts/Investigating_the_Effectiveness_of_Bayesian_Spam_Filters_in_Detecting_LLM_modified_Spam_Mails/2024-08-26-Investigating_the_Effectiveness_of_Bayesian_Spam_Filters_in_Detecting_LLM_modified_Spam_Mails.html#analysis-and-critique",
    "href": "posts/Investigating_the_Effectiveness_of_Bayesian_Spam_Filters_in_Detecting_LLM_modified_Spam_Mails/2024-08-26-Investigating_the_Effectiveness_of_Bayesian_Spam_Filters_in_Detecting_LLM_modified_Spam_Mails.html#analysis-and-critique",
    "title": "Investigating the Effectiveness of Bayesian Spam Filters in Detecting LLM-modified Spam Mails",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe study provides valuable insights into the vulnerabilities of current spam filters against LLM-modified spam emails. However, it only evaluates SpamAssassin, and the results may not be generalizable to other spam filters.\nThe study uses a dataset that is almost 20 years old, which may not accurately represent the current state of spam emails. The use of more recent datasets could provide a more accurate evaluation of the effectiveness of LLM-modified spam emails.\nThe study does not consider the potential impact of LLM-modified spam emails on users, such as the potential for these emails to be more convincing and therefore more likely to result in successful phishing attacks."
  },
  {
    "objectID": "posts/Investigating_the_Effectiveness_of_Bayesian_Spam_Filters_in_Detecting_LLM_modified_Spam_Mails/2024-08-26-Investigating_the_Effectiveness_of_Bayesian_Spam_Filters_in_Detecting_LLM_modified_Spam_Mails.html#appendix",
    "href": "posts/Investigating_the_Effectiveness_of_Bayesian_Spam_Filters_in_Detecting_LLM_modified_Spam_Mails/2024-08-26-Investigating_the_Effectiveness_of_Bayesian_Spam_Filters_in_Detecting_LLM_modified_Spam_Mails.html#appendix",
    "title": "Investigating the Effectiveness of Bayesian Spam Filters in Detecting LLM-modified Spam Mails",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.14293v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.14293v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4258"
  },
  {
    "objectID": "posts/Enhancing_Model_Performance_Another_Approach_to_Vision_Language_Instruction_Tuning/2024-07-25-Enhancing_Model_Performance_Another_Approach_to_Vision_Language_Instruction_Tuning.html#appendix",
    "href": "posts/Enhancing_Model_Performance_Another_Approach_to_Vision_Language_Instruction_Tuning/2024-07-25-Enhancing_Model_Performance_Another_Approach_to_Vision_Language_Instruction_Tuning.html#appendix",
    "title": "Enhancing Model Performance: Another Approach to Vision-Language Instruction Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17813v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17813v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3995"
  },
  {
    "objectID": "posts/Is_GPT_4_Alone_Sufficient_for_Automated_Essay_Scoring_A_Comparative_Judgment_Approach_Based_on_Rater_Cognition/2024-07-08-Is_GPT_4_Alone_Sufficient_for_Automated_Essay_Scoring_A_Comparative_Judgment_Approach_Based_on_Rater_Cognition.html#appendix",
    "href": "posts/Is_GPT_4_Alone_Sufficient_for_Automated_Essay_Scoring_A_Comparative_Judgment_Approach_Based_on_Rater_Cognition/2024-07-08-Is_GPT_4_Alone_Sufficient_for_Automated_Essay_Scoring_A_Comparative_Judgment_Approach_Based_on_Rater_Cognition.html#appendix",
    "title": "Is GPT-4 Alone Sufficient for Automated Essay Scoring?: A Comparative Judgment Approach Based on Rater Cognition",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05733v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05733v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6518"
  },
  {
    "objectID": "posts/Verbalized_Machine_Learning_Revisiting_Machine_Learning_with_Language_Models/2024-06-06-Verbalized_Machine_Learning_Revisiting_Machine_Learning_with_Language_Models.html#appendix",
    "href": "posts/Verbalized_Machine_Learning_Revisiting_Machine_Learning_with_Language_Models/2024-06-06-Verbalized_Machine_Learning_Revisiting_Machine_Learning_with_Language_Models.html#appendix",
    "title": "Verbalized Machine Learning: Revisiting Machine Learning with Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04344v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04344v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10781"
  },
  {
    "objectID": "posts/Step_Back_Profiling_Distilling_User_History_for_Personalized_Scientific_Writing/2024-06-20-Step_Back_Profiling_Distilling_User_History_for_Personalized_Scientific_Writing.html#appendix",
    "href": "posts/Step_Back_Profiling_Distilling_User_History_for_Personalized_Scientific_Writing/2024-06-20-Step_Back_Profiling_Distilling_User_History_for_Personalized_Scientific_Writing.html#appendix",
    "title": "Step-Back Profiling: Distilling User History for Personalized Scientific Writing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14275v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14275v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5200"
  },
  {
    "objectID": "posts/Aligning_(Medical)_LLMs_for_(Counterfactual)_Fairness/2024-08-22-Aligning_(Medical)_LLMs_for_(Counterfactual)_Fairness.html#major-findings",
    "href": "posts/Aligning_(Medical)_LLMs_for_(Counterfactual)_Fairness/2024-08-22-Aligning_(Medical)_LLMs_for_(Counterfactual)_Fairness.html#major-findings",
    "title": "Aligning (Medical) LLMs for (Counterfactual) Fairness",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe study presents an evaluation framework to conduct a comprehensive evaluation to quantify social biases in LLMs used in medical applications. The authors extensively analyze multiple LLM types, datasets, and prompting techniques, demonstrating existing fairness challenges in medical LLMs.\nThe authors propose a mitigation technique for fairness concerns using model alignment techniques in a knowledge distillation framework. They show that their mitigation method is effective in reducing observed biased patterns."
  },
  {
    "objectID": "posts/Aligning_(Medical)_LLMs_for_(Counterfactual)_Fairness/2024-08-22-Aligning_(Medical)_LLMs_for_(Counterfactual)_Fairness.html#analysis-and-critique",
    "href": "posts/Aligning_(Medical)_LLMs_for_(Counterfactual)_Fairness/2024-08-22-Aligning_(Medical)_LLMs_for_(Counterfactual)_Fairness.html#analysis-and-critique",
    "title": "Aligning (Medical) LLMs for (Counterfactual) Fairness",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe study provides a comprehensive evaluation of bias patterns in LLMs used for medical applications, which is a significant contribution to the field. However, the evaluation framework may not cover all possible sources of bias, and further research is needed to identify other potential biases.\nThe proposed bias mitigation technique is promising, but it may not be applicable to all types of LLMs, especially those that do not have access to model parameters. Additionally, the effectiveness of the mitigation technique may vary depending on the specific LLM and the task at hand.\nThe study does not address the potential impact of the mitigation technique on the overall performance of the LLMs. It is essential to ensure that the mitigation of biases does not come at the cost of reduced performance in other areas.\nThe study focuses on counterfactual fairness, which is an important aspect of fairness, but it may not capture all forms of bias. Future research should consider other types of fairness, such as group fairness and individual fairness.\nThe study does not discuss the potential ethical implications of the proposed mitigation technique. It is crucial to consider the ethical"
  },
  {
    "objectID": "posts/Aligning_(Medical)_LLMs_for_(Counterfactual)_Fairness/2024-08-22-Aligning_(Medical)_LLMs_for_(Counterfactual)_Fairness.html#appendix",
    "href": "posts/Aligning_(Medical)_LLMs_for_(Counterfactual)_Fairness/2024-08-22-Aligning_(Medical)_LLMs_for_(Counterfactual)_Fairness.html#appendix",
    "title": "Aligning (Medical) LLMs for (Counterfactual) Fairness",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12055v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12055v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9308"
  },
  {
    "objectID": "posts/Aligning_Agents_like_Large_Language_Models/2024-06-06-Aligning_Agents_like_Large_Language_Models.html",
    "href": "posts/Aligning_Agents_like_Large_Language_Models/2024-06-06-Aligning_Agents_like_Large_Language_Models.html",
    "title": "Aligning Agents like Large Language Models",
    "section": "",
    "text": "Summary:\nThe paper explores the challenge of training agents to behave as desired in complex 3D environments using high-dimensional sensory information. The authors draw an analogy between the undesirable behaviors of imitation learning agents and the unhelpful responses of unaligned large language models (LLMs). They investigate the procedure for aligning LLMs and apply it to aligning agents in a 3D environment from pixels. The authors focus on an academically illustrative part of a modern console game where players must navigate from a randomly selected spawn point to one of three jumppads. They demonstrate that they can align their agent to consistently perform the desired mode while providing insights and advice for successfully applying this approach to training agents.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an innovative approach to aligning agents in complex 3D environments by drawing an analogy between the undesirable behaviors of imitation learning agents and the unhelpful responses of unaligned LLMs. The authors’ investigation of the procedure for aligning LLMs and its application to aligning agents is a significant contribution to the field. However, the paper’s focus on an academically illustrative part of a modern console game may limit the generalizability of the findings to other complex 3D environments. Additionally, the use of synthetic preference labelling may not fully capture the complexity of human preferences in real-world scenarios. Further research is needed to evaluate the effectiveness of this approach in more diverse and complex environments and to explore the use of human preference labelling."
  },
  {
    "objectID": "posts/Aligning_Agents_like_Large_Language_Models/2024-06-06-Aligning_Agents_like_Large_Language_Models.html#appendix",
    "href": "posts/Aligning_Agents_like_Large_Language_Models/2024-06-06-Aligning_Agents_like_Large_Language_Models.html#appendix",
    "title": "Aligning Agents like Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04208v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04208v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12915"
  },
  {
    "objectID": "posts/Generative_Debunking_of_Climate_Misinformation/2024-07-08-Generative_Debunking_of_Climate_Misinformation.html#appendix",
    "href": "posts/Generative_Debunking_of_Climate_Misinformation/2024-07-08-Generative_Debunking_of_Climate_Misinformation.html#appendix",
    "title": "Generative Debunking of Climate Misinformation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05599v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05599v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6823"
  },
  {
    "objectID": "posts/Accuracy_and_Consistency_of_LLMs_in_the_Registered_Dietitian_Exam_The_Impact_of_Prompt_Engineering_and_Knowledge_Retrieval/2024-08-06-Accuracy_and_Consistency_of_LLMs_in_the_Registered_Dietitian_Exam_The_Impact_of_Prompt_Engineering_and_Knowledge_Retrieval.html#appendix",
    "href": "posts/Accuracy_and_Consistency_of_LLMs_in_the_Registered_Dietitian_Exam_The_Impact_of_Prompt_Engineering_and_Knowledge_Retrieval/2024-08-06-Accuracy_and_Consistency_of_LLMs_in_the_Registered_Dietitian_Exam_The_Impact_of_Prompt_Engineering_and_Knowledge_Retrieval.html#appendix",
    "title": "Accuracy and Consistency of LLMs in the Registered Dietitian Exam: The Impact of Prompt Engineering and Knowledge Retrieval",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02964v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02964v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7951"
  },
  {
    "objectID": "posts/Iterative_or_Innovative_A_Problem_Oriented_Perspective_for_Code_Optimization/2024-06-17-Iterative_or_Innovative_A_Problem_Oriented_Perspective_for_Code_Optimization.html#appendix",
    "href": "posts/Iterative_or_Innovative_A_Problem_Oriented_Perspective_for_Code_Optimization/2024-06-17-Iterative_or_Innovative_A_Problem_Oriented_Perspective_for_Code_Optimization.html#appendix",
    "title": "Iterative or Innovative? A Problem-Oriented Perspective for Code Optimization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11935v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11935v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10246"
  },
  {
    "objectID": "posts/AMONGAGENTS_Evaluating_Large_Language_Models_in_the_Interactive_Text_Based_Social_Deduction_Game/2024-07-24-AMONGAGENTS_Evaluating_Large_Language_Models_in_the_Interactive_Text_Based_Social_Deduction_Game.html#appendix",
    "href": "posts/AMONGAGENTS_Evaluating_Large_Language_Models_in_the_Interactive_Text_Based_Social_Deduction_Game/2024-07-24-AMONGAGENTS_Evaluating_Large_Language_Models_in_the_Interactive_Text_Based_Social_Deduction_Game.html#appendix",
    "title": "AMONGAGENTS: Evaluating Large Language Models in the Interactive Text-Based Social Deduction Game",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16521v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16521v2\n\n\nTruncated\nFalse\n\n\nWord Count\n8569"
  },
  {
    "objectID": "posts/Why_Are_My_Prompts_Leaked_Unraveling_Prompt_Extraction_Threats_in_Customized_Large_Language_Models/2024-08-05-Why_Are_My_Prompts_Leaked_Unraveling_Prompt_Extraction_Threats_in_Customized_Large_Language_Models.html#major-findings",
    "href": "posts/Why_Are_My_Prompts_Leaked_Unraveling_Prompt_Extraction_Threats_in_Customized_Large_Language_Models/2024-08-05-Why_Are_My_Prompts_Leaked_Unraveling_Prompt_Extraction_Threats_in_Customized_Large_Language_Models.html#major-findings",
    "title": "Why Are My Prompts Leaked? Unraveling Prompt Extraction Threats in Customized Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nScaling Laws in Prompt Extraction: The authors analyze the scaling laws in prompt extraction and find that larger LLMs exhibit similar extraction rates to smaller LLMs under explicit intent-based attacks. However, larger LLMs are more vulnerable to implicit attacks.\nPrompt Memorization: The authors observe that LLMs can memorize and transcribe some long prompts accurately and verbatim, a phenomenon they refer to as prompt memorization. This occurs due to the perplexity of prompts and the parallel translation of prompts in attention matrices.\nDefense Strategies: The authors propose several defense strategies against PEA, including alignments and prompt engineering-based methods. They find that these methods can significantly reduce the prompt extraction rate for Llama2-7B and GPT-3.5."
  },
  {
    "objectID": "posts/Why_Are_My_Prompts_Leaked_Unraveling_Prompt_Extraction_Threats_in_Customized_Large_Language_Models/2024-08-05-Why_Are_My_Prompts_Leaked_Unraveling_Prompt_Extraction_Threats_in_Customized_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/Why_Are_My_Prompts_Leaked_Unraveling_Prompt_Extraction_Threats_in_Customized_Large_Language_Models/2024-08-05-Why_Are_My_Prompts_Leaked_Unraveling_Prompt_Extraction_Threats_in_Customized_Large_Language_Models.html#analysis-and-critique",
    "title": "Why Are My Prompts Leaked? Unraveling Prompt Extraction Threats in Customized Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper provides a comprehensive analysis of prompt extraction threats in customized LLMs and proposes several defense strategies. However, the paper does not discuss the potential impact of prompt leakage on the performance of LLMs or the potential risks associated with using leaked prompts. Additionally, the paper does not provide a detailed comparison of the proposed defense strategies with existing methods.\nFurther research is needed to evaluate the effectiveness of the proposed defense strategies in real-world scenarios and to explore the potential risks associated with prompt leakage. Additionally, future work could focus on developing more robust defense strategies that can effectively prevent prompt leakage in customized LLMs."
  },
  {
    "objectID": "posts/Why_Are_My_Prompts_Leaked_Unraveling_Prompt_Extraction_Threats_in_Customized_Large_Language_Models/2024-08-05-Why_Are_My_Prompts_Leaked_Unraveling_Prompt_Extraction_Threats_in_Customized_Large_Language_Models.html#appendix",
    "href": "posts/Why_Are_My_Prompts_Leaked_Unraveling_Prompt_Extraction_Threats_in_Customized_Large_Language_Models/2024-08-05-Why_Are_My_Prompts_Leaked_Unraveling_Prompt_Extraction_Threats_in_Customized_Large_Language_Models.html#appendix",
    "title": "Why Are My Prompts Leaked? Unraveling Prompt Extraction Threats in Customized Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02416v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02416v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10615"
  },
  {
    "objectID": "posts/BLAZE_Cross_Language_and_Cross_Project_Bug_Localization_via_Dynamic_Chunking_and_Hard_Example_Learning/2024-07-24-BLAZE_Cross_Language_and_Cross_Project_Bug_Localization_via_Dynamic_Chunking_and_Hard_Example_Learning.html#appendix",
    "href": "posts/BLAZE_Cross_Language_and_Cross_Project_Bug_Localization_via_Dynamic_Chunking_and_Hard_Example_Learning/2024-07-24-BLAZE_Cross_Language_and_Cross_Project_Bug_Localization_via_Dynamic_Chunking_and_Hard_Example_Learning.html#appendix",
    "title": "BLAZE: Cross-Language and Cross-Project Bug Localization via Dynamic Chunking and Hard Example Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17631v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17631v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9812"
  },
  {
    "objectID": "posts/Enhancing_LLM_Based_Automated_Program_Repair_with_Design_Rationales/2024-08-22-Enhancing_LLM_Based_Automated_Program_Repair_with_Design_Rationales.html#appendix",
    "href": "posts/Enhancing_LLM_Based_Automated_Program_Repair_with_Design_Rationales/2024-08-22-Enhancing_LLM_Based_Automated_Program_Repair_with_Design_Rationales.html#appendix",
    "title": "Enhancing LLM-Based Automated Program Repair with Design Rationales",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12056v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12056v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11439"
  },
  {
    "objectID": "posts/STBench_Assessing_the_Ability_of_Large_Language_Models_in_Spatio_Temporal_Analysis/2024-06-27-STBench_Assessing_the_Ability_of_Large_Language_Models_in_Spatio_Temporal_Analysis.html#appendix",
    "href": "posts/STBench_Assessing_the_Ability_of_Large_Language_Models_in_Spatio_Temporal_Analysis/2024-06-27-STBench_Assessing_the_Ability_of_Large_Language_Models_in_Spatio_Temporal_Analysis.html#appendix",
    "title": "STBench: Assessing the Ability of Large Language Models in Spatio-Temporal Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19065v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19065v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11715"
  },
  {
    "objectID": "posts/A_Survey_of_Backdoor_Attacks_and_Defenses_on_Large_Language_Models_Implications_for_Security_Measures/2024-06-10-A_Survey_of_Backdoor_Attacks_and_Defenses_on_Large_Language_Models_Implications_for_Security_Measures.html#appendix",
    "href": "posts/A_Survey_of_Backdoor_Attacks_and_Defenses_on_Large_Language_Models_Implications_for_Security_Measures/2024-06-10-A_Survey_of_Backdoor_Attacks_and_Defenses_on_Large_Language_Models_Implications_for_Security_Measures.html#appendix",
    "title": "A Survey of Backdoor Attacks and Defenses on Large Language Models: Implications for Security Measures",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06852v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06852v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9560"
  },
  {
    "objectID": "posts/Towards_Reliable_Medical_Question_Answering_Techniques_and_Challenges_in_Mitigating_Hallucinations_in_Language_Models/2024-08-25-Towards_Reliable_Medical_Question_Answering_Techniques_and_Challenges_in_Mitigating_Hallucinations_in_Language_Models.html#major-findings",
    "href": "posts/Towards_Reliable_Medical_Question_Answering_Techniques_and_Challenges_in_Mitigating_Hallucinations_in_Language_Models/2024-08-25-Towards_Reliable_Medical_Question_Answering_Techniques_and_Challenges_in_Mitigating_Hallucinations_in_Language_Models.html#major-findings",
    "title": "Towards Reliable Medical Question Answering: Techniques and Challenges in Mitigating Hallucinations in Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nRetrieval-Augmented Generation (RAG): RAG has emerged as a promising technique for enhancing the performance and reliability of LLMs by incorporating external knowledge during the text generation process. This approach addresses the limitations of LLMs in generating accurate and contextually relevant information, particularly in knowledge-intensive tasks such as medical question answering (QA) and summarization.\nIterative Feedback Loops: Iterative feedback loops enable models to continuously evaluate and improve their outputs. This self-refinement technique has been shown to reduce hallucinations in the medical domain, where accuracy is critical for patient outcomes.\nSupervised Fine-Tuning: Supervised fine-tuning methods have been explored to improve the factual accuracy of language models, particularly for biography generation and medical QA tasks. This fine-tuning process ensures that the models generate more factual and reliable content, which is vital for applications in the medical field."
  },
  {
    "objectID": "posts/Towards_Reliable_Medical_Question_Answering_Techniques_and_Challenges_in_Mitigating_Hallucinations_in_Language_Models/2024-08-25-Towards_Reliable_Medical_Question_Answering_Techniques_and_Challenges_in_Mitigating_Hallucinations_in_Language_Models.html#analysis-and-critique",
    "href": "posts/Towards_Reliable_Medical_Question_Answering_Techniques_and_Challenges_in_Mitigating_Hallucinations_in_Language_Models/2024-08-25-Towards_Reliable_Medical_Question_Answering_Techniques_and_Challenges_in_Mitigating_Hallucinations_in_Language_Models.html#analysis-and-critique",
    "title": "Towards Reliable Medical Question Answering: Techniques and Challenges in Mitigating Hallucinations in Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper provides a comprehensive overview of the current state of hallucination mitigation techniques in LLMs, with a focus on the medical domain. However, it does not delve deeply into the ethical implications of AI in healthcare, which is a crucial aspect to consider.\nThe paper highlights the need for high-quality, domain-specific data sources and robust evaluation metrics, but does not provide concrete solutions to these challenges.\nThe paper could benefit from a more in-depth discussion on the trade-offs between fine-tuning open-domain models for specific tasks and training domain-specific models from scratch.\nThe paper could also explore the potential of other techniques, such as ensemble learning and unlearning, in mitigating hallucinations in the medical domain.\n\nOverall"
  },
  {
    "objectID": "posts/Towards_Reliable_Medical_Question_Answering_Techniques_and_Challenges_in_Mitigating_Hallucinations_in_Language_Models/2024-08-25-Towards_Reliable_Medical_Question_Answering_Techniques_and_Challenges_in_Mitigating_Hallucinations_in_Language_Models.html#appendix",
    "href": "posts/Towards_Reliable_Medical_Question_Answering_Techniques_and_Challenges_in_Mitigating_Hallucinations_in_Language_Models/2024-08-25-Towards_Reliable_Medical_Question_Answering_Techniques_and_Challenges_in_Mitigating_Hallucinations_in_Language_Models.html#appendix",
    "title": "Towards Reliable Medical Question Answering: Techniques and Challenges in Mitigating Hallucinations in Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.13808v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.13808v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7098"
  },
  {
    "objectID": "posts/Should_AI_Optimize_Your_Code_A_Comparative_Study_of_Current_Large_Language_Models_Versus_Classical_Optimizing_Compilers/2024-06-17-Should_AI_Optimize_Your_Code_A_Comparative_Study_of_Current_Large_Language_Models_Versus_Classical_Optimizing_Compilers.html#appendix",
    "href": "posts/Should_AI_Optimize_Your_Code_A_Comparative_Study_of_Current_Large_Language_Models_Versus_Classical_Optimizing_Compilers/2024-06-17-Should_AI_Optimize_Your_Code_A_Comparative_Study_of_Current_Large_Language_Models_Versus_Classical_Optimizing_Compilers.html#appendix",
    "title": "Should AI Optimize Your Code? A Comparative Study of Current Large Language Models Versus Classical Optimizing Compilers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12146v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12146v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7663"
  },
  {
    "objectID": "posts/Helpful_assistant_or_fruitful_facilitator_Investigating_how_personas_affect_language_model_behavior/2024-07-02-Helpful_assistant_or_fruitful_facilitator_Investigating_how_personas_affect_language_model_behavior.html#appendix",
    "href": "posts/Helpful_assistant_or_fruitful_facilitator_Investigating_how_personas_affect_language_model_behavior/2024-07-02-Helpful_assistant_or_fruitful_facilitator_Investigating_how_personas_affect_language_model_behavior.html#appendix",
    "title": "Helpful assistant or fruitful facilitator? Investigating how personas affect language model behavior",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02099v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02099v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8203"
  },
  {
    "objectID": "posts/USDC_A_Dataset_of_User_Stance_and_Dogmatism_in_Long_Conversations/2024-06-24-USDC_A_Dataset_of_User_Stance_and_Dogmatism_in_Long_Conversations.html#appendix",
    "href": "posts/USDC_A_Dataset_of_User_Stance_and_Dogmatism_in_Long_Conversations/2024-06-24-USDC_A_Dataset_of_User_Stance_and_Dogmatism_in_Long_Conversations.html#appendix",
    "title": "USDC: A Dataset of User Stance and Dogmatism in Long Conversations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16833v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16833v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9875"
  },
  {
    "objectID": "posts/When_to_Stop_Towards_Efficient_Code_Generation_in_LLMs_with_Excess_Token_Prevention/2024-07-29-When_to_Stop_Towards_Efficient_Code_Generation_in_LLMs_with_Excess_Token_Prevention.html#appendix",
    "href": "posts/When_to_Stop_Towards_Efficient_Code_Generation_in_LLMs_with_Excess_Token_Prevention/2024-07-29-When_to_Stop_Towards_Efficient_Code_Generation_in_LLMs_with_Excess_Token_Prevention.html#appendix",
    "title": "When to Stop? Towards Efficient Code Generation in LLMs with Excess Token Prevention",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20042v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20042v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12130"
  },
  {
    "objectID": "posts/Averaging_log_likelihoods_in_direct_alignment/2024-06-27-Averaging_log_likelihoods_in_direct_alignment.html#appendix",
    "href": "posts/Averaging_log_likelihoods_in_direct_alignment/2024-06-27-Averaging_log_likelihoods_in_direct_alignment.html#appendix",
    "title": "Averaging log-likelihoods in direct alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19188v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19188v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5452"
  },
  {
    "objectID": "posts/Large_Language_Models_as_Evaluators_for_Scientific_Synthesis/2024-07-03-Large_Language_Models_as_Evaluators_for_Scientific_Synthesis.html#appendix",
    "href": "posts/Large_Language_Models_as_Evaluators_for_Scientific_Synthesis/2024-07-03-Large_Language_Models_as_Evaluators_for_Scientific_Synthesis.html#appendix",
    "title": "Large Language Models as Evaluators for Scientific Synthesis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02977v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02977v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6836"
  },
  {
    "objectID": "posts/Breaking_Bias_Building_Bridges_Evaluation_and_Mitigation_of_Social_Biases_in_LLMs_via_Contact_Hypothesis/2024-07-02-Breaking_Bias_Building_Bridges_Evaluation_and_Mitigation_of_Social_Biases_in_LLMs_via_Contact_Hypothesis.html#appendix",
    "href": "posts/Breaking_Bias_Building_Bridges_Evaluation_and_Mitigation_of_Social_Biases_in_LLMs_via_Contact_Hypothesis/2024-07-02-Breaking_Bias_Building_Bridges_Evaluation_and_Mitigation_of_Social_Biases_in_LLMs_via_Contact_Hypothesis.html#appendix",
    "title": "Breaking Bias, Building Bridges: Evaluation and Mitigation of Social Biases in LLMs via Contact Hypothesis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02030v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02030v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7434"
  },
  {
    "objectID": "posts/Multi_Layer_Ranking_with_Large_Language_Models_for_News_Source_Recommendation/2024-06-17-Multi_Layer_Ranking_with_Large_Language_Models_for_News_Source_Recommendation.html#appendix",
    "href": "posts/Multi_Layer_Ranking_with_Large_Language_Models_for_News_Source_Recommendation/2024-06-17-Multi_Layer_Ranking_with_Large_Language_Models_for_News_Source_Recommendation.html#appendix",
    "title": "Multi-Layer Ranking with Large Language Models for News Source Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11745v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11745v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4168"
  },
  {
    "objectID": "posts/ICLGuard_Controlling_In_Context_Learning_Behavior_for_Applicability_Authorization/2024-07-09-ICLGuard_Controlling_In_Context_Learning_Behavior_for_Applicability_Authorization.html#appendix",
    "href": "posts/ICLGuard_Controlling_In_Context_Learning_Behavior_for_Applicability_Authorization/2024-07-09-ICLGuard_Controlling_In_Context_Learning_Behavior_for_Applicability_Authorization.html#appendix",
    "title": "ICLGuard: Controlling In-Context Learning Behavior for Applicability Authorization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06955v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06955v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12482"
  },
  {
    "objectID": "posts/Enhancing_Tool_Retrieval_with_Iterative_Feedback_from_Large_Language_Models/2024-06-25-Enhancing_Tool_Retrieval_with_Iterative_Feedback_from_Large_Language_Models.html#appendix",
    "href": "posts/Enhancing_Tool_Retrieval_with_Iterative_Feedback_from_Large_Language_Models/2024-06-25-Enhancing_Tool_Retrieval_with_Iterative_Feedback_from_Large_Language_Models.html#appendix",
    "title": "Enhancing Tool Retrieval with Iterative Feedback from Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17465v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17465v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5575"
  },
  {
    "objectID": "posts/Self_and_Cross_Model_Distillation_for_LLMs_Effective_Methods_for_Refusal_Pattern_Alignment/2024-06-17-Self_and_Cross_Model_Distillation_for_LLMs_Effective_Methods_for_Refusal_Pattern_Alignment.html#appendix",
    "href": "posts/Self_and_Cross_Model_Distillation_for_LLMs_Effective_Methods_for_Refusal_Pattern_Alignment/2024-06-17-Self_and_Cross_Model_Distillation_for_LLMs_Effective_Methods_for_Refusal_Pattern_Alignment.html#appendix",
    "title": "Self and Cross-Model Distillation for LLMs: Effective Methods for Refusal Pattern Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11285v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11285v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6660"
  },
  {
    "objectID": "posts/EnJa_Ensemble_Jailbreak_on_Large_Language_Models/2024-08-07-EnJa_Ensemble_Jailbreak_on_Large_Language_Models.html#major-findings",
    "href": "posts/EnJa_Ensemble_Jailbreak_on_Large_Language_Models/2024-08-07-EnJa_Ensemble_Jailbreak_on_Large_Language_Models.html#major-findings",
    "title": "EnJa: Ensemble Jailbreak on Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe proposed EnJa attack achieves a state-of-the-art attack success rate with fewer queries and is much stronger than any individual jailbreak.\nThe EnJa attack integrates prompt-level and token-level jailbreak into a more powerful hybrid jailbreak attack.\nThe EnJa attack hides harmful instructions using prompt-level jailbreak and boosts the attack success rate using a gradient-based attack.\nThe EnJa attack connects the two types of jailbreak attacks via a template-based connector."
  },
  {
    "objectID": "posts/EnJa_Ensemble_Jailbreak_on_Large_Language_Models/2024-08-07-EnJa_Ensemble_Jailbreak_on_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/EnJa_Ensemble_Jailbreak_on_Large_Language_Models/2024-08-07-EnJa_Ensemble_Jailbreak_on_Large_Language_Models.html#analysis-and-critique",
    "title": "EnJa: Ensemble Jailbreak on Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents an interesting approach to jailbreaking large language models by integrating prompt-level and token-level jailbreak into a more powerful hybrid attack. The proposed EnJa attack achieves a state-of-the-art attack success rate with fewer queries and is much stronger than any individual jailbreak. However, the paper does not discuss the potential risks and ethical implications of such attacks. It is important to consider the potential harm that could be caused by malicious actors using these techniques to generate harmful content. Additionally, the paper does not provide a detailed analysis of the limitations and potential biases of the proposed approach. Further research is needed to evaluate the robustness and generalizability of the EnJa attack and to develop effective countermeasures."
  },
  {
    "objectID": "posts/EnJa_Ensemble_Jailbreak_on_Large_Language_Models/2024-08-07-EnJa_Ensemble_Jailbreak_on_Large_Language_Models.html#appendix",
    "href": "posts/EnJa_Ensemble_Jailbreak_on_Large_Language_Models/2024-08-07-EnJa_Ensemble_Jailbreak_on_Large_Language_Models.html#appendix",
    "title": "EnJa: Ensemble Jailbreak on Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03603v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03603v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12013"
  },
  {
    "objectID": "posts/Strategic_Demonstration_Selection_for_Improved_Fairness_in_LLM_In_Context_Learning/2024-08-19-Strategic_Demonstration_Selection_for_Improved_Fairness_in_LLM_In_Context_Learning.html#appendix",
    "href": "posts/Strategic_Demonstration_Selection_for_Improved_Fairness_in_LLM_In_Context_Learning/2024-08-19-Strategic_Demonstration_Selection_for_Improved_Fairness_in_LLM_In_Context_Learning.html#appendix",
    "title": "Strategic Demonstration Selection for Improved Fairness in LLM In-Context Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09757v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09757v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6909"
  },
  {
    "objectID": "posts/Microscopic_Analysis_on_LLM_players_via_Social_Deduction_Game/2024-08-19-Microscopic_Analysis_on_LLM_players_via_Social_Deduction_Game.html#appendix",
    "href": "posts/Microscopic_Analysis_on_LLM_players_via_Social_Deduction_Game/2024-08-19-Microscopic_Analysis_on_LLM_players_via_Social_Deduction_Game.html#appendix",
    "title": "Microscopic Analysis on LLM players via Social Deduction Game",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09946v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09946v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10720"
  },
  {
    "objectID": "posts/TAMIGO_Empowering_Teaching_Assistants_using_LLM_assisted_viva_and_code_assessment_in_an_Advanced_Computing_Class/2024-07-23-TAMIGO_Empowering_Teaching_Assistants_using_LLM_assisted_viva_and_code_assessment_in_an_Advanced_Computing_Class.html#appendix",
    "href": "posts/TAMIGO_Empowering_Teaching_Assistants_using_LLM_assisted_viva_and_code_assessment_in_an_Advanced_Computing_Class/2024-07-23-TAMIGO_Empowering_Teaching_Assistants_using_LLM_assisted_viva_and_code_assessment_in_an_Advanced_Computing_Class.html#appendix",
    "title": "TAMIGO: Empowering Teaching Assistants using LLM-assisted viva and code assessment in an Advanced Computing Class",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16805v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16805v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6849"
  },
  {
    "objectID": "posts/MAGIC_Generating_Self_Correction_Guideline_for_In_Context_Text_to_SQL/2024-06-18-MAGIC_Generating_Self_Correction_Guideline_for_In_Context_Text_to_SQL.html#appendix",
    "href": "posts/MAGIC_Generating_Self_Correction_Guideline_for_In_Context_Text_to_SQL/2024-06-18-MAGIC_Generating_Self_Correction_Guideline_for_In_Context_Text_to_SQL.html#appendix",
    "title": "MAGIC: Generating Self-Correction Guideline for In-Context Text-to-SQL",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12692v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12692v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7370"
  },
  {
    "objectID": "posts/IgnitionInnovators_at_Discharge_Me!_Chain_of_Thought_Instruction_Finetuning_Large_Language_Models_for_Discharge_Summaries/2024-07-24-IgnitionInnovators_at_Discharge_Me!_Chain_of_Thought_Instruction_Finetuning_Large_Language_Models_for_Discharge_Summaries.html#appendix",
    "href": "posts/IgnitionInnovators_at_Discharge_Me!_Chain_of_Thought_Instruction_Finetuning_Large_Language_Models_for_Discharge_Summaries/2024-07-24-IgnitionInnovators_at_Discharge_Me!_Chain_of_Thought_Instruction_Finetuning_Large_Language_Models_for_Discharge_Summaries.html#appendix",
    "title": "IgnitionInnovators at Discharge Me!: Chain-of-Thought Instruction Finetuning Large Language Models for Discharge Summaries",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17636v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17636v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3701"
  },
  {
    "objectID": "posts/Efficient_Detection_of_Toxic_Prompts_in_Large_Language_Models/2024-08-21-Efficient_Detection_of_Toxic_Prompts_in_Large_Language_Models.html",
    "href": "posts/Efficient_Detection_of_Toxic_Prompts_in_Large_Language_Models/2024-08-21-Efficient_Detection_of_Toxic_Prompts_in_Large_Language_Models.html",
    "title": "Efficient Detection of Toxic Prompts in Large Language Models",
    "section": "",
    "text": "Summary:\nThe paper “Efficient Detection of Toxic Prompts in Large Language Models” presents a novel method called ToxicDetector for detecting toxic prompts in large language models (LLMs). The method leverages LLMs to create toxic concept prompts, uses embedding vectors to form feature vectors, and employs a Multi-Layer Perceptron (MLP) classifier for prompt classification. The evaluation on various versions of the LLama models, Gemma-2, and multiple datasets demonstrates that ToxicDetector achieves a high accuracy of 96.39% and a low false positive rate of 2.00%, outperforming state-of-the-art methods. Additionally, ToxicDetector’s processing time of 0.0780 seconds per prompt makes it highly suitable for real-time applications.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a promising method for detecting toxic prompts in LLMs. The high accuracy and low false positive rate achieved by ToxicDetector demonstrate its effectiveness in identifying toxic prompts. The use of embedding vectors and an MLP classifier allows for efficient and scalable detection, making it suitable for real-time applications. However, the paper does not discuss potential limitations or shortcomings of the method, such as its performance on different types of toxic prompts or its generalizability to other LLMs. Additionally, the paper does not provide a detailed comparison with other state-of-the-art methods, making it difficult to fully evaluate its performance. Overall, ToxicDetector shows promise as a method for detecting toxic prompts in LLMs, but further research is needed to fully understand its strengths and limitations."
  },
  {
    "objectID": "posts/Efficient_Detection_of_Toxic_Prompts_in_Large_Language_Models/2024-08-21-Efficient_Detection_of_Toxic_Prompts_in_Large_Language_Models.html#appendix",
    "href": "posts/Efficient_Detection_of_Toxic_Prompts_in_Large_Language_Models/2024-08-21-Efficient_Detection_of_Toxic_Prompts_in_Large_Language_Models.html#appendix",
    "title": "Efficient Detection of Toxic Prompts in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11727v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11727v1\n\n\nTruncated\nFalse\n\n\nWord Count\n21143"
  },
  {
    "objectID": "posts/Flooding_Spread_of_Manipulated_Knowledge_in_LLM_Based_Multi_Agent_Communities/2024-07-10-Flooding_Spread_of_Manipulated_Knowledge_in_LLM_Based_Multi_Agent_Communities.html#appendix",
    "href": "posts/Flooding_Spread_of_Manipulated_Knowledge_in_LLM_Based_Multi_Agent_Communities/2024-07-10-Flooding_Spread_of_Manipulated_Knowledge_in_LLM_Based_Multi_Agent_Communities.html#appendix",
    "title": "Flooding Spread of Manipulated Knowledge in LLM-Based Multi-Agent Communities",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07791v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07791v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11413"
  },
  {
    "objectID": "posts/VGBench_Evaluating_Large_Language_Models_on_Vector_Graphics_Understanding_and_Generation/2024-07-15-VGBench_Evaluating_Large_Language_Models_on_Vector_Graphics_Understanding_and_Generation.html#appendix",
    "href": "posts/VGBench_Evaluating_Large_Language_Models_on_Vector_Graphics_Understanding_and_Generation/2024-07-15-VGBench_Evaluating_Large_Language_Models_on_Vector_Graphics_Understanding_and_Generation.html#appendix",
    "title": "VGBench: Evaluating Large Language Models on Vector Graphics Understanding and Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10972v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10972v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6106"
  },
  {
    "objectID": "posts/Boosting_Large_Language_Models_with_Socratic_Method_for_Conversational_Mathematics_Teaching/2024-07-24-Boosting_Large_Language_Models_with_Socratic_Method_for_Conversational_Mathematics_Teaching.html#appendix",
    "href": "posts/Boosting_Large_Language_Models_with_Socratic_Method_for_Conversational_Mathematics_Teaching/2024-07-24-Boosting_Large_Language_Models_with_Socratic_Method_for_Conversational_Mathematics_Teaching.html#appendix",
    "title": "Boosting Large Language Models with Socratic Method for Conversational Mathematics Teaching",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17349v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17349v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4192"
  },
  {
    "objectID": "posts/CherryRec_Enhancing_News_Recommendation_Quality_via_LLM_driven_Framework/2024-06-18-CherryRec_Enhancing_News_Recommendation_Quality_via_LLM_driven_Framework.html#appendix",
    "href": "posts/CherryRec_Enhancing_News_Recommendation_Quality_via_LLM_driven_Framework/2024-06-18-CherryRec_Enhancing_News_Recommendation_Quality_via_LLM_driven_Framework.html#appendix",
    "title": "CherryRec: Enhancing News Recommendation Quality via LLM-driven Framework",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12243v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12243v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4153"
  },
  {
    "objectID": "posts/Assessing_the_Effectiveness_of_LLMs_in_Android_Application_Vulnerability_Analysis/2024-06-27-Assessing_the_Effectiveness_of_LLMs_in_Android_Application_Vulnerability_Analysis.html#appendix",
    "href": "posts/Assessing_the_Effectiveness_of_LLMs_in_Android_Application_Vulnerability_Analysis/2024-06-27-Assessing_the_Effectiveness_of_LLMs_in_Android_Application_Vulnerability_Analysis.html#appendix",
    "title": "Assessing the Effectiveness of LLMs in Android Application Vulnerability Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18894v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18894v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7395"
  },
  {
    "objectID": "posts/LPU_A_Latency_Optimized_and_Highly_Scalable_Processor_for_Large_Language_Model_Inference/2024-08-14-LPU_A_Latency_Optimized_and_Highly_Scalable_Processor_for_Large_Language_Model_Inference.html#appendix",
    "href": "posts/LPU_A_Latency_Optimized_and_Highly_Scalable_Processor_for_Large_Language_Model_Inference/2024-08-14-LPU_A_Latency_Optimized_and_Highly_Scalable_Processor_for_Large_Language_Model_Inference.html#appendix",
    "title": "LPU: A Latency-Optimized and Highly Scalable Processor for Large Language Model Inference",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07326v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07326v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9561"
  },
  {
    "objectID": "posts/UniCoder_Scaling_Code_Large_Language_Model_via_Universal_Code/2024-06-24-UniCoder_Scaling_Code_Large_Language_Model_via_Universal_Code.html#appendix",
    "href": "posts/UniCoder_Scaling_Code_Large_Language_Model_via_Universal_Code/2024-06-24-UniCoder_Scaling_Code_Large_Language_Model_via_Universal_Code.html#appendix",
    "title": "UniCoder: Scaling Code Large Language Model via Universal Code",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16441v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16441v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3736"
  },
  {
    "objectID": "posts/A_Superalignment_Framework_in_Autonomous_Driving_with_Large_Language_Models/2024-06-09-A_Superalignment_Framework_in_Autonomous_Driving_with_Large_Language_Models.html#appendix",
    "href": "posts/A_Superalignment_Framework_in_Autonomous_Driving_with_Large_Language_Models/2024-06-09-A_Superalignment_Framework_in_Autonomous_Driving_with_Large_Language_Models.html#appendix",
    "title": "A Superalignment Framework in Autonomous Driving with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05651v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05651v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3979"
  },
  {
    "objectID": "posts/Evolutionary_Prompt_Design_for_LLM_Based_Post_ASR_Error_Correction/2024-07-23-Evolutionary_Prompt_Design_for_LLM_Based_Post_ASR_Error_Correction.html#appendix",
    "href": "posts/Evolutionary_Prompt_Design_for_LLM_Based_Post_ASR_Error_Correction/2024-07-23-Evolutionary_Prompt_Design_for_LLM_Based_Post_ASR_Error_Correction.html#appendix",
    "title": "Evolutionary Prompt Design for LLM-Based Post-ASR Error Correction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16370v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16370v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3509"
  },
  {
    "objectID": "posts/3D_Question_Answering_for_City_Scene_Understanding/2024-07-24-3D_Question_Answering_for_City_Scene_Understanding.html#appendix",
    "href": "posts/3D_Question_Answering_for_City_Scene_Understanding/2024-07-24-3D_Question_Answering_for_City_Scene_Understanding.html#appendix",
    "title": "3D Question Answering for City Scene Understanding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17398v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17398v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7976"
  },
  {
    "objectID": "posts/Towards_Comprehensive_Preference_Data_Collection_for_Reward_Modeling/2024-06-24-Towards_Comprehensive_Preference_Data_Collection_for_Reward_Modeling.html#appendix",
    "href": "posts/Towards_Comprehensive_Preference_Data_Collection_for_Reward_Modeling/2024-06-24-Towards_Comprehensive_Preference_Data_Collection_for_Reward_Modeling.html#appendix",
    "title": "Towards Comprehensive Preference Data Collection for Reward Modeling",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16486v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16486v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3102"
  },
  {
    "objectID": "posts/Molecular_Graph_Representation_Learning_Integrating_Large_Language_Models_with_Domain_specific_Small_Models/2024-08-19-Molecular_Graph_Representation_Learning_Integrating_Large_Language_Models_with_Domain_specific_Small_Models.html#appendix",
    "href": "posts/Molecular_Graph_Representation_Learning_Integrating_Large_Language_Models_with_Domain_specific_Small_Models/2024-08-19-Molecular_Graph_Representation_Learning_Integrating_Large_Language_Models_with_Domain_specific_Small_Models.html#appendix",
    "title": "Molecular Graph Representation Learning Integrating Large Language Models with Domain-specific Small Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10124v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10124v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5847"
  },
  {
    "objectID": "posts/Learn_by_Selling_Equipping_Large_Language_Models_with_Product_Knowledge_for_Context_Driven_Recommendations/2024-07-30-Learn_by_Selling_Equipping_Large_Language_Models_with_Product_Knowledge_for_Context_Driven_Recommendations.html#appendix",
    "href": "posts/Learn_by_Selling_Equipping_Large_Language_Models_with_Product_Knowledge_for_Context_Driven_Recommendations/2024-07-30-Learn_by_Selling_Equipping_Large_Language_Models_with_Product_Knowledge_for_Context_Driven_Recommendations.html#appendix",
    "title": "Learn by Selling: Equipping Large Language Models with Product Knowledge for Context-Driven Recommendations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20856v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20856v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2803"
  },
  {
    "objectID": "posts/Defending_Against_Social_Engineering_Attacks_in_the_Age_of_LLMs/2024-06-18-Defending_Against_Social_Engineering_Attacks_in_the_Age_of_LLMs.html#appendix",
    "href": "posts/Defending_Against_Social_Engineering_Attacks_in_the_Age_of_LLMs/2024-06-18-Defending_Against_Social_Engineering_Attacks_in_the_Age_of_LLMs.html#appendix",
    "title": "Defending Against Social Engineering Attacks in the Age of LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12263v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12263v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7850"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Bayesian beagle",
    "section": "",
    "text": "Welcome to the Bayesian beagle blog! This project is a unique intersection of machine learning and scientific communication, providing a platform where readers can quickly get insights from the latest research papers hosted on ArXiv. Utilizing state-of-the-art Large Language Models (LLMs), our system generates concise, comprehensible summaries of complex research articles, covering a wide array of disciplines.\nAll content is LLM generated. Assume skepticism and verify in the original paper as LLM models are imperfect and can struggle under certain circumstances.\nOur blog is built using Quarto and then published with Netlify.\n\n\n\n\ngraph LR\n    A[\"Download weekly Arxiv articles\"] --&gt; B[\"Predict and Filter LLM topic\"]\n    B --&gt; C[\"Summarize short docs\"]\n    B --&gt; D[\"Summarize by Map-Reduce long docs\"]\n    C --&gt; E[\"Update website with summaries weekly\"]\n    D --&gt; E"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian beagle",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nExploring ChatGPT App Ecosystem: Distribution, Deployment and Security\n\n\n\narchitectures\n\n\nsecurity\n\n\nproduction\n\n\nrobustness\n\n\nhci\n\n\n\nFirst study of ChatGPT app ecosystem reveals uneven functionality, security flaws, and privacy concerns in third-party plugins.\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-3D Print: Large Language Models To Monitor and Control 3D Printing\n\n\n\nproduction\n\n\nrobustness\n\n\narchitectures\n\n\n\nLLM-based agents accurately detect and autonomously correct 3D printing errors, outperforming human experts.\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo-CCAM: Enhancing Video-Language Understanding with Causal Cross-Attention Masks for Short and Long Videos\n\n\n\narchitectures\n\n\n\nVideo-CCAM: Robust Video-MLLM with Causal Cross-Attention for Long Videos, Outperforms Existing Models.\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInvestigating the Effectiveness of Bayesian Spam Filters in Detecting LLM-modified Spam Mails\n\n\n\narchitectures\n\n\nsecurity\n\n\nproduction\n\n\nrobustness\n\n\nhci\n\n\n\nLLM-modified spam can bypass SpamAssassin, with up to 73.7% misclassified as legitimate, posing a significant cybersecurity threat.\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre LLM-based Recommenders Already the Best? Simple Scaled Cross-entropy Unleashes the Potential of Traditional Sequential Recommenders\n\n\n\nproduction\n\n\nrecommender\n\n\n\nLLMs excel in sequential recommendation, but inconsistent experimental settings inflate their ranking capability. Cross-entropy loss has desirable properties, but isn’t…\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLMM-VQA: Advancing Video Quality Assessment with Large Multimodal Models\n\n\n\narchitectures\n\n\n\nLMM-VQA: New model for video quality assessment using large multimodal models, outperforming existing methods by 5% on average.\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTF-Attack: Transferable and Fast Adversarial Attacks on Large Language Models\n\n\n\nsecurity\n\n\n\nTL;DR: TF-Attack improves transferability and speed of adversarial attacks on LLMs, outperforming previous methods by up to 20×.\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the Potential of Large Language Models for Heterophilic Graphs\n\n\n\narchitectures\n\n\n\nLLMs enhance GNNs for heterophilic graphs via edge discrimination and reweighting, improving node classification.\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSay Your Reason: Extract Contextual Rules In Situ for Context-aware Service Recommendation\n\n\n\nrecommender\n\n\n\nSayRea system aids personalized mobile service recommendations, reducing user cognitive load and improving experience.\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Synthetic Trace Generation of Modeling Operations using In-Context Learning Approach\n\n\n\nproduction\n\n\narchitectures\n\n\nprogramming\n\n\n\nLLMs can generate synthetic modeling operations, but human-based operations yield higher accuracy. Generative AI tools are an alternative when modeling data is scarce.\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProbing Causality Manipulation of Large Language Models\n\n\n\nproduction\n\n\narchitectures\n\n\neducation\n\n\nsocial-sciences\n\n\n\nLLMs can detect causality entities but lack specialized cognition, treating causality as global semantic.\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond Detection: Leveraging Large Language Models for Cyber Attack Prediction in IoT Networks\n\n\n\nrobustness\n\n\nsecurity\n\n\narchitectures\n\n\n\nProactive IoT cybersecurity: LLMs & LSTM predict malicious activities with 98% accuracy.\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSWE-bench-java: A GitHub Issue Resolving Benchmark for Java\n\n\n\nproduction\n\n\narchitectures\n\n\n\nSWE-bench-java-verified released for multilingual issue resolving in software engineering, inviting contributions for continuous improvement.\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClaim Verification in the Age of Large Language Models: A Survey\n\n\n\nproduction\n\n\n\nSurvey of claim verification frameworks using Large Language Models (LLMs) and Retrieval Augmented Generation (RAG).\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSifting through the Chaff: On Utilizing Execution Feedback for Ranking the Generated Code Candidates\n\n\n\nsecurity\n\n\nprogramming\n\n\n\nTL;DR: RankEF improves code ranking by leveraging execution feedback, outperforming CodeRanker.\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMLR-Copilot: Autonomous Machine Learning Research based on Large Language Models Agents\n\n\n\narchitectures\n\n\n\nMLR-Copilot: Automated Framework for Boosting ML Research Productivity.\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFire-Flyer AI-HPC: A Cost-Effective Software-Hardware Co-Design for Deep Learning\n\n\n\nproduction\n\n\narchitectures\n\n\n\nFire-Flyer AI-HPC halves costs and reduces energy use by 40% for DL training, while maintaining DGX-A100-like performance.\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssessing Contamination in Large Language Models: Introducing the LogProber method\n\n\n\nproduction\n\n\nrobustness\n\n\narchitectures\n\n\n\nLogProber: A new algorithm detects contamination in LLMs using token probability, but limitations exist based on training methods.\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLanguage-specific Calibration for Pruning Multilingual Language Models\n\n\n\nproduction\n\n\narchitectures\n\n\n\nTL;DR: Multilingual LLM pruning strategies explored; calibrating in target language improves fluency, not reasoning.\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFoundation Models for Music: A Survey\n\n\n\nproduction\n\n\narchitectures\n\n\n\nTL;DR: This review explores foundation models in music, discussing representation, generation, ethics, and future trends.\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReprogramming Foundational Large Language Models(LLMs) for Enterprise Adoption for Spatio-Temporal Forecasting Applications: Unveiling a New Era in Copilot-Guided Cross-Modal Time Series Representation Learning\n\n\n\nproduction\n\n\narchitectures\n\n\n\nHybrid model combines LLMs, LMs, and traditional forecasting for improved accuracy in large, complex datasets.\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues\n\n\n\narchitectures\n\n\n\nLLMs generate synthetic ASR errors for data augmentation, improving medical dialogue summarization.\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExplicit Inductive Inference using Large Language Models\n\n\n\nproduction\n\n\n\nLLMs exhibit undesirable attestation bias, which our proposed pipeline mitigates, improving inference performance.\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep-by-Step Unmasking for Parameter-Efficient Fine-tuning of Large Language Models\n\n\n\nproduction\n\n\narchitectures\n\n\n\nID3 method dynamically unmasks parameters for efficient fine-tuning, outperforming fixed-masking techniques, and reducing gradient updates by half.\n\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Reliable Medical Question Answering: Techniques and Challenges in Mitigating Hallucinations in Language Models\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nPaper explores techniques to reduce hallucinations in medical LLMs, ensuring factual accuracy and adherence to medical guidelines.\n\n\n\nAug 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoor-Supervised Evaluation for SuperLLM via Mutual Consistency\n\n\n\nsocial-sciences\n\n\n\nPoEM framework evaluates LLMs without accurate labels, using human & model-centric approach, achieving high correlation with supervised results.\n\n\n\nAug 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoT Rerailer: Enhancing the Reliability of Large Language Models in Complex Reasoning Tasks through Error Detection and Correction\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\neducation\n\n\n\nCoT Rerailer improves LLM reasoning by selecting, correcting, and debating intermediate steps, reducing hallucinations and errors.\n\n\n\nAug 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodeGraph: Enhancing Graph Reasoning of LLMs with Code\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\neducation\n\n\nprogramming\n\n\n\nCodeGraph, a code-based method, enhances LLMs’ graph reasoning abilities, improving performance by up to 58.6% and offering better control and interpretation.\n\n\n\nAug 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDHP Benchmark: Are LLMs Good NLG Evaluators?\n\n\n\nsocial-sciences\n\n\n\nLLMs’ NLG evaluation discernment is benchmarked using DHP framework, revealing strengths and limitations across six datasets and four tasks.\n\n\n\nAug 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBiomedical Large Languages Models Seem not to be Superior to Generalist Models on Unseen Medical Data\n\n\n\nsocial-sciences\n\n\n\nBiomedical LLMs underperform general-purpose ones on clinical tasks, challenging assumptions about domain-specific adaptation.\n\n\n\nAug 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMs are Superior Feedback Providers: Bootstrapping Reasoning for Lie Detection with Self-Generated Feedback\n\n\n\nsocial-sciences\n\n\n\nLLMs improve lie detection in games with self-generated feedback, rivaling supervised learning results.\n\n\n\nAug 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDOCE: Finding the Sweet Spot for Execution-Based Code Generation\n\n\n\nsecurity\n\n\nprogramming\n\n\n\nTL;DR: We propose a framework for code generation with execution-based evaluation, highlighting the importance of filtering and self-debugging.\n\n\n\nAug 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDemo: Generative Open xG Network Simulation with Multi-Agent LLM and ns-3 (GenOnet)\n\n\n\nhci\n\n\neducation\n\n\n\nGenOnet: AI-driven 6G network simulator for open interfaces, based on LLM and ns-3, compliant with O-RAN and 3GPP standards.\n\n\n\nAug 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTime Series Analysis for Education: Methods, Applications, and Future Directions\n\n\n\neducation\n\n\nsocial-sciences\n\n\n\nThis paper offers a comprehensive review of time series analysis in education, discussing applications, methods, and future directions.\n\n\n\nAug 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDraw Like an Artist: Complex Scene Generation with Diffusion Model via Composition, Painting, and Retouching\n\n\n\nprompt-engineering\n\n\n\nCxD framework outperforms SOTA in complex scene generation, using LLM for prompt decomposition and attention modulation for painting, and retouching for detail enhancement.\n\n\n\nAug 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing LLM-Based Automated Program Repair with Design Rationales\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nDRCodePilot improves APR by 4.7x using design rationales and feedback-based refinement.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFlexEdit: Marrying Free-Shape Masks to VLLM for Flexible Image Editing\n\n\n\nprompt-engineering\n\n\n\nFlexEdit: A VLLM-based image editing method using free-shape masks and language instructions for improved accuracy.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAligning (Medical) LLMs for (Counterfactual) Fairness\n\n\n\nsocial-sciences\n\n\n\nNew method aligns LLMs to reduce biases in medical applications, improving fairness and trust in AI-augmented tools.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraph Retrieval Augmented Trustworthiness Reasoning\n\n\n\nrobustness\n\n\n\nTL;DR: GRATR framework improves trustworthiness reasoning in games, outperforming baseline methods and mitigating LLM hallucinations.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Comparative Analysis of Faithfulness Metrics and Humans in Citation Evaluation\n\n\n\nrobustness\n\n\n\nLLMs struggle to verify citations; current faithfulness metrics aren’t consistently effective for fine-grained citation support. No single metric excels in all evaluations.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMDD-5k: A New Diagnostic Conversation Dataset for Mental Disorders Synthesized via Neuro-Symbolic LLM Agents\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nFramework synthesizes diagnostic conversations for mental disorders, creating the largest Chinese dataset, MDD-5k.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMs are not Zero-Shot Reasoners for Biomedical Information Extraction\n\n\n\nprompt-engineering\n\n\n\nLLMs underperform in biomedical tasks; standard prompting outperforms complex techniques like CoT, self-consistency, and RAG. External knowledge integration needs…\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedDiT: A Knowledge-Controlled Diffusion Transformer Framework for Dynamic Medical Image Generation in Virtual Simulated Patient\n\n\n\neducation\n\n\n\nMedDiT: A framework generating medical images for diverse patient simulations, advancing medical education.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConflictBank: A Benchmark for Evaluating the Influence of Knowledge Conflicts in LLM\n\n\n\nrobustness\n\n\nhci\n\n\neducation\n\n\n\nConflictBank: First Benchmark for Evaluating Knowledge Conflicts in Large Language Models.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nToward the Evaluation of Large Language Models Considering Score Variance across Instruction Templates\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nFair NLU evaluation of LLMs requires considering score variance between different instruction templates, using Sharpe score as a metric.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBetter Debugging: Combining Static Analysis and LLMs for Explainable Crashing Fault Localization\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\neducation\n\n\nsecurity\n\n\n\nTL;DR: CrashTracker uses static analysis & LLM to localize & explain Android framework-specific crashing faults, outperforming SOTA tools.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenderCARE: A Comprehensive Framework for Assessing and Reducing Gender Bias in Large Language Models\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nGenderCARE: A framework for quantifying and mitigating gender bias in large language models, achieving up to 90% reduction with minimal impact on performance.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Multi-hop Reasoning through Knowledge Erasure in Large Language Model Editing\n\n\n\nrobustness\n\n\n\nKELE method improves multi-hop reasoning in edited LLMs by erasing residual single-hop knowledge and injecting new information.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Factuality in Large Language Models via Decoding-Time Hallucinatory and Truthful Comparators\n\n\n\nrobustness\n\n\n\nCDT framework reduces LLM hallucination, improving factuality and performance in downstream tasks.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvalYaks: Instruction Tuning Datasets and LoRA Fine-tuned Models for Automated Scoring of CEFR B2 Speaking Assessment Transcripts\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nAutomated models (EvalYaks) effectively evaluate CEFR B2 English speaking assessments with 96% accuracy, offering scalable, automated language proficiency evaluation.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSearch-Based LLMs for Code Optimization\n\n\n\nprogramming\n\n\n\nTL;DR: SBLLM improves code efficiency by up to 209.59% via iterative refinement and optimization method discovery.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInteractive DualChecker for Mitigating Hallucinations in Distilling Large Language Models\n\n\n\nrobustness\n\n\neducation\n\n\n\nDualChecker framework reduces LLM hallucinations, improves teacher-student model performance in knowledge distillation, and enhances few-shot in-context learning.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFIRST: Teach A Reliable Large Language Model Through Efficient Trustworthy Distillation\n\n\n\nrobustness\n\n\n\nFIRST method improves LLM trustworthiness, offering better accuracy and less mis-calibration by efficiently utilizing concentrated knowledge from the teacher model.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnlearning Trojans in Large Language Models: A Comparison Between Natural Language and Source Code\n\n\n\nsecurity\n\n\n\nLya, a novel unlearning approach, effectively removes trojans from poisoned BERT and CodeBERT models, outperforming existing methods.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCLEANANERCorp: Identifying and Correcting Incorrect Labels in the ANERcorp Dataset\n\n\n\nrobustness\n\n\n\nStudy uncovers errors in Arabic NER dataset, proposes corrected version: CLEANANERCorp.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRuleAlign: Making Large Language Models Better Physicians with Diagnostic Rule Alignment\n\n\n\neducation\n\n\n\nLLMs enhanced with RuleAlign framework can better diagnose like physicians, per medical dialogue dataset.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models Are Self-Taught Reasoners: Enhancing LLM Applications via Tailored Problem-Solving Demonstrations\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nAAAI requires authors to follow formatting guidelines for publication consistency.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDLCRec: A Novel Approach for Managing Diversity in LLM-Based Recommender Systems\n\n\n\nrecommender\n\n\n\nDLCRec offers fine-grained control over diversity in LLM-based recommendations, outperforming existing methods.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMEDCO: Medical Education Copilots Based on A Multi-Agent Framework\n\n\n\nprompt-engineering\n\n\neducation\n\n\nsocial-sciences\n\n\n\nMEDCO: A multi-agent system for medical education, improves student performance and emulates real-world training, showcasing AI’s potential in medical education.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan You Trust Your Metric? Automatic Concatenation-Based Tests for Metric Validity\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nLLM harmfulness metrics, like GPT-based, can misclassify unsafe content when prompts and responses are concatenated, showing decision-flipping and order sensitivity.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-tool Integration Application for Math Reasoning Using Large Language Model\n\n\n\neducation\n\n\nprogramming\n\n\n\nFramework with LLMs & tools boosts math reasoning, outperforming baselines in NumGLUE Task 4 by up to 52.29%.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBalancing Act: Prioritization Strategies for LLM-Designed Restless Bandit Rewards\n\n\n\nsocial-sciences\n\n\n\nLLM-designed rewards for multiagent resource allocation now consider social welfare, improving effectiveness and balance over purely LLM-based approaches.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Evaluating and Building Versatile Large Language Models for Medicine\n\n\n\nsocial-sciences\n\n\n\nMedS-Bench evaluates LLMs in clinical tasks; MedS-Ins dataset improves model performance. New model, MMedIns-Llama 3, outperforms existing models.\n\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEfficient Detection of Toxic Prompts in Large Language Models\n\n\n\nrobustness\n\n\nsecurity\n\n\nprogramming\n\n\n\nToxicDetector: Efficient, accurate method for toxic prompt detection in LLMs.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStory3D-Agent: Exploring 3D Storytelling Visualization with Large Language Models\n\n\n\nhci\n\n\n\nAuthors must follow guidelines for AAAI publications to ensure uniformity.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClinical Insights: A Comprehensive Review of Language Models in Medicine\n\n\n\nsocial-sciences\n\n\n\n[TEXT] The study examines the impact of climate change on the frequency and intensity of extreme weather events, finding that global warming is leading to more frequent and…\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCIPHER: Cybersecurity Intelligent Penetration-testing Helper for Ethical Researcher\n\n\n\nsecurity\n\n\neducation\n\n\n\nCIPHER, a specialized language model, outperforms others in penetration testing tasks, filling a gap in cybersecurity Q&A benchmarks.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRAGLAB: A Modular and Research-Oriented Unified Framework for Retrieval-Augmented Generation\n\n\n\nrobustness\n\n\neducation\n\n\nhci\n\n\n\nRAGLAB: A library for fair comparison and development of Retrieval Augmented Generation algorithms.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPersonality Alignment of Large Language Models\n\n\n\nsocial-sciences\n\n\n\nPAS method aligns LLMs with individual user preferences using minimal data and resources, improving AI personalization.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCause-Aware Empathetic Response Generation via Chain-of-Thought Fine-Tuning\n\n\n\nprompt-engineering\n\n\nhci\n\n\nsocial-sciences\n\n\n\nCause-aware empathetic generation approach improves LLMs’ empathy and diversity, achieving SOTA results.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEEG-Defender: Defending against Jailbreak through Early Exit Generation of Large Language Models\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nEeg-Defender reduces malicious LLM use by 85%, detecting threats via early transformer outputs.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Epistemic Language with a Bayesian Theory of Mind\n\n\n\nprompt-engineering\n\n\nhci\n\n\n\nModel (LaBToM) predicts human judgments on others’ beliefs using Bayesian inferences, outperforming LLMs in various expressions.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLARR: Large Language Model Aided Real-time Scene Recommendation with Semantic Understanding\n\n\n\nrecommender\n\n\n\nLARR uses LLMs for real-time scene understanding in RS, improving CTR modeling efficiency.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation\n\n\n\nhci\n\n\n\nUniFashion: A unified framework for multimodal generation and retrieval tasks in the fashion domain, integrating image generation with retrieval and text generation tasks.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResearch on the Application of Large Language Models in Automatic Question Generation: A Case Study of ChatGLM in the Context of High School Information Technology Curriculum\n\n\n\neducation\n\n\nprompt-engineering\n\n\nprogramming\n\n\nhci\n\n\nsocial-sciences\n\n\n\nChatGLM generates clearer, teacher-preferred exam questions than humans, but fit and hit rate are similar; future work can optimize model for better clarity and teacher…\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMigrating Existing Container Workload to Kubernetes – LLM Based Approach and Evaluation\n\n\n\nprompt-engineering\n\n\n\nLLMs can assist in generating Kubernetes manifests but may lack readability and struggle with atypical inputs.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMutagenesis screen to map the functionals of parameters of Large Language Models\n\n\n\nsocial-sciences\n\n\n\n[TEXT] The study examines the impact of climate change on the frequency and intensity of extreme weather events, finding that global warming is increasing the likelihood of…\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Activations Matter: Training-Free Methods for Dynamic Activation in Large Language Models\n\n\n\nrobustness\n\n\n\nTL;DR: TDA method accelerates LLM generation speed by 18-25% without compromising performance, addressing DA limitations and providing theoretical insights.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEAGLE: Elevating Geometric Reasoning through LLM-empowered Visual Instruction Tuning\n\n\n\nrobustness\n\n\neducation\n\n\n\nMLLMs struggle with geometric problem-solving due to inaccurate perception. EAGLE, a two-stage framework, improves visual comprehension and outperforms existing models in…\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApplying and Evaluating Large Language Models in Mental Health Care: A Scoping Review of Human-Assessed Generative Tasks\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLLMs show promise in mental health care, but require rigorous evaluation and ethical oversight for safe integration into clinical practice.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Evaluating Large Language Models on Sarcasm Understanding\n\n\n\nprompt-engineering\n\n\nhci\n\n\n\nLLMs struggle with sarcasm; GPT-4 performs best. Few-shot IO prompting is most effective.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFRAP: Faithful and Realistic Text-to-Image Generation with Adaptive Prompt Weighting\n\n\n\nprompt-engineering\n\n\n\nFRAP improves prompt-image alignment in T2I diffusion models, generating more authentic images with lower latency than latent code optimization methods.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHITS: High-coverage LLM-based Unit Test Generation via Method Slicing\n\n\n\nprogramming\n\n\n\nLLMs struggle with complex Java methods; our approach of slicing methods for LLM-based test generation improves line and branch coverage.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeoReasoner: Reasoning On Geospatially Grounded Context For Natural Language Understanding\n\n\n\nprompt-engineering\n\n\n\nGeoReasoner: A language model for geospatial reasoning, outperforms baselines in toponym recognition, linking, and typing.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutomating Thought of Search: A Journey Towards Soundness and Completeness\n\n\n\nprogramming\n\n\n\nAutoToS automates ToS, achieving 100% accuracy in planning problems with LLMs, no human intervention needed.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNothing in Excess: Mitigating the Exaggerated Safety for LLMs via Safety-Conscious Activation Steering\n\n\n\nrobustness\n\n\n\nSCANS method balances safety & helpfulness in LLMs, improving performance on XSTest & OKTest without compromising defense or capability.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM4VV: Exploring LLM-as-a-Judge for Validation and Verification Testsuites\n\n\n\nrobustness\n\n\neducation\n\n\nprogramming\n\n\n\nLLMs can revolutionize software development, but bias and confidentiality concerns exist. This paper explores judging LLM-generated code to understand and improve these…\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImage Score: Learning and Evaluating Human Preferences for Mercari Search\n\n\n\nhci\n\n\n\nTL;DR: Mercari uses LLMs for cost-effective, explainable image quality assessment, boosting sales.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBURExtract-Llama: An LLM for Clinical Concept Extraction in Breast Ultrasound Reports\n\n\n\nsocial-sciences\n\n\n\nIn-house LLM matches GPT-4’s performance, extracting clinical data from radiology reports, while reducing costs and improving privacy.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAgainst All Odds: Overcoming Typology, Script, and Language Confusion in Multilingual Embedding Inversion Attacks\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nMultilingual LLMs, especially Arabic and Cyrillic script languages, are vulnerable to embedding inversion attacks, with language confusion reducing attack efficacy.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCritique-out-Loud Reward Models\n\n\n\nsocial-sciences\n\n\n\nCLoud reward models improve preference classification accuracy by critiquing assistant responses, offering a Pareto improvement for win rate in Best-of-N.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiagnosing and Remedying Knowledge Deficiencies in LLMs via Label-free Curricular Meaningful Learning\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLaMer: Label-free Framework Diagnoses, Remedies LLM Knowledge Deficiencies, Improving Performance with Less Data.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProbabilistic Medical Predictions of Large Language Models\n\n\n\nprompt-engineering\n\n\n\nLLMs struggle to reliably generate prediction probabilities in clinical contexts, with explicit probabilities underperforming implicit ones.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnlocking Adversarial Suffix Optimization Without Affirmative Phrases: Efficient Black-box Jailbreaking via LLM as Optimizer\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nECLIPSE, a new black-box jailbreaking method, outperforms existing methods in generating harmful LLM content, with 2.4x higher ASR than GCG and 83% less attack overhead than…\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRedWhale: An Adapted Korean LLM Through Efficient Continual Pretraining\n\n\n\nsocial-sciences\n\n\n\nRedWhale, a Korean-focused NLP model, outperforms others, reducing training time and costs while maintaining accuracy.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEstimating Contribution Quality in Online Deliberations Using a Large Language Model\n\n\n\nhci\n\n\n\nLLM outperforms individual human annotators in rating deliberation contributions; nudges after inactivity boost participation without compromising quality.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization\n\n\n\nrecommender\n\n\nrobustness\n\n\n\nOptimized LLM for Tibet tourism using RAG tech improves personalized recommendations, reduces hallucinations, and enhances content generation.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models are Good Attackers: Efficient and Stealthy Textual Backdoor Attacks\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nEST-Bad: Efficient, stealthy textual backdoor attack using LLMs.\n\n\n\nAug 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodeJudge-Eval: Can Large Language Models be Good Judges in Code Understanding?\n\n\n\nprogramming\n\n\n\n[ABSTRACT] This paper presents a new method for detecting and classifying objects in images using deep learning techniques. The proposed method achieves state-of-the-art…\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSoda-Eval: Open-Domain Dialogue Evaluation in the age of LLMs\n\n\n\nhci\n\n\n\nTL;DR: Soda-Eval dataset reveals dialogue evaluation challenges for LLMs, fine-tuning improves performance.\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAthena: Safe Autonomous Agents with Verbal Contrastive Learning\n\n\n\nhci\n\n\n\nAthena framework enhances safety of LLM-based agents via verbal contrastive learning and critiquing, improving safety rates in experiments.\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReading with Intent\n\n\n\nhci\n\n\n\nRAG systems struggle with sarcasm; this paper generates sarcastic passages to improve their performance.\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDAAD: Dynamic Analysis and Adaptive Discriminator for Fake News Detection\n\n\n\nprompt-engineering\n\n\n\nTL;DR: DAAD approach for fake news detection uses MCTS for prompt optimization and identifies four deceit patterns for detection.\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReconciling Methodological Paradigms: Employing Large Language Models as Novice Qualitative Research Assistants in Talent Management Research\n\n\n\nprompt-engineering\n\n\nhci\n\n\neducation\n\n\n\nThis study proposes using LLMs for qualitative research, showcasing their effectiveness in topic modeling of interview data, and recommends integrating them with traditional…\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Augmentation Integrating Dialogue Flow and Style to Adapt Spoken Dialogue Systems to Low-Resource User Groups\n\n\n\nhci\n\n\n\nTL;DR: This study improves SDS performance for underrepresented users via a novel data augmentation framework using LLM and PLM.\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOptimizing Large Language Model Hyperparameters for Code Generation\n\n\n\nprogramming\n\n\n\nLLM code generation performance varies with hyperparameters; optimal results seen with temperature &lt;0.5, top probability &lt;0.75, frequency penalty (-1 to 1.5), and presence…\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhile GitHub Copilot Excels at Coding, Does It Ensure Responsible Output?\n\n\n\nrobustness\n\n\nprogramming\n\n\n\nLLMs in code completion tools (LCCTs) face security risks like jailbreaking and data extraction, with high success rates in attacks on GitHub Copilot and Amazon Q.\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBenchmarking Large Language Models for Math Reasoning Tasks\n\n\n\nprompt-engineering\n\n\n\nLarger LLMs excel in math reasoning, while smaller models benefit from specific prompting strategies. Benchmarking code is open-sourced.\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDr.Academy: A Benchmark for Evaluating Questioning Capability in Education for Large Language Models\n\n\n\nprompt-engineering\n\n\n\nLLMs, like GPT-4 and Claude2, show potential as educators, excelling in generating relevant, diverse, and consistent educational questions across disciplines.\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnboxing Occupational Bias: Grounded Debiasing LLMs with U.S. Labor Data\n\n\n\nhci\n\n\n\nLLMs can amplify societal biases; this study proposes a debiasing mechanism using NBLS data, reducing bias in seven LLMs.\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPerception-guided Jailbreak against Text-to-Image Models\n\n\n\nrobustness\n\n\n\nPGJ: A model-free method for generating natural attack prompts, replacing unsafe words with safe phrases that have similar human perception.\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHarnessing Multimodal Large Language Models for Multimodal Sequential Recommendation\n\n\n\nrecommender\n\n\n\nMLLM-MSR model proposed for multimodal sequential recommendation, capturing dynamic user preferences with image and text inputs.\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Model Driven Recommendation\n\n\n\nrecommender\n\n\nhci\n\n\n\nLLMs enable personalized RSs via NL interactions, using item descriptions, user-system interactions, and profiles. Techniques include encoder-only and autoregressive LLM…\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProxona: Leveraging LLM-Driven Personas to Enhance Creators’ Understanding of Their Audience\n\n\n\nrobustness\n\n\nhci\n\n\n\nProxona system helps creators understand audience by generating data-driven personas from comments, aiding content creation and improvement.\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRevisiting VerilogEval: Newer LLMs, In-Context Learning, and Specification-to-RTL Tasks\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\neducation\n\n\nprogramming\n\n\n\nNew models outperform older ones on VerilogEval, with GPT-4 Turbo and Llama 3.1 405B leading. Prompt engineering is crucial for success.\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow Well Do Large Language Models Serve as End-to-End Secure Code Producers?\n\n\n\nprogramming\n\n\n\nLLMs, like GPT-4, generate vulnerable code due to lack of security awareness. They struggle to identify and repair their own vulnerabilities, but a lightweight tool can…\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo Code, or Not To Code? Exploring Impact of Code in Pre-training\n\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\nCode in pre-training boosts LLM performance in non-code tasks, with up to 8.2% improvement in natural language reasoning and 4.2% in world knowledge.\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPublic Health in Disaster: Emotional Health and Life Incidents Extraction during Hurricane Harvey\n\n\n\nhci\n\n\n\nAI model analyzes disaster-related tweets for emotion and topic, aiding disaster response and mental health services.\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoRA: Collaborative Information Perception by Large Language Model’s Weights for Recommendation\n\n\n\nrecommender\n\n\n\nTL;DR: CoRA method integrates collaborative info into LLMs for better recommendations, preserving LLM’s world knowledge and text inference abilities.\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFerret: Faster and Effective Automated Red Teaming with Reward-Based Scoring Technique\n\n\n\nprompt-engineering\n\n\n\nFerret improves attack success rate by 46% and reduces time by 15.2%, generating transferable adversarial prompts for LLMs.\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBEYOND DIALOGUE: A Profile-Dialogue Alignment Framework Towards General Role-Playing Language Model\n\n\n\nprompt-engineering\n\n\n\nBeyond Dialogue framework improves role-playing models by aligning dialogue with profile traits, reducing biases, and enhancing performance.\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCrafting Tomorrow’s Headlines: Neural News Generation and Detection in English, Turkish, Hungarian, and Persian\n\n\n\nprompt-engineering\n\n\n\nTL;DR: We introduce a benchmark dataset for detecting machine-generated news in four languages, testing various classifiers for interpretability and robustness.\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat can Large Language Models Capture about Code Functional Equivalence?\n\n\n\nprogramming\n\n\n\nCode-LLMs struggle to grasp code semantics, despite strong performance in code generation and classification.\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCHECKWHY: Causal Fact Verification via Argument Structure\n\n\n\nprompt-engineering\n\n\n\nCheckWhy: A dataset for verifying causal facts via reasoning steps.\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEfficient and Deployable Knowledge Infusion for Open-World Recommendations via Large Language Models\n\n\n\nrecommender\n\n\n\nREKI: A framework using LLMs for open-world recommendations, improving performance in Huawei’s news and music platforms.\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEPiC: Cost-effective Search-based Prompt Engineering of LLMs for Code Generation\n\n\n\nprogramming\n\n\n\nEPiC, an evolutionary prompt engineering method, improves LLM-based code generation cost-effectively.\n\n\n\nAug 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMolecular Graph Representation Learning Integrating Large Language Models with Domain-specific Small Models\n\n\n\nprompt-engineering\n\n\nrobustness\n\n\n\nMolGraph-LarDo: New framework integrates LLMs and DSMs for precise molecular property prediction.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultilingual Needle in a Haystack: Investigating Long-Context Behavior of Multilingual Large Language Models\n\n\n\nproduction\n\n\narchitectures\n\n\n\nLLMs struggle with long, multilingual contexts, especially non-English and middle-positioned needles. This is the first study on LLMs’ multilingual long-context behavior.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMicroscopic Analysis on LLM players via Social Deduction Game\n\n\n\nsocial-sciences\n\n\nrobustness\n\n\nhci\n\n\narchitectures\n\n\n\nLLMs evaluated in SpyGame with new metrics for better assessment of game-playing abilities.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStrategic Demonstration Selection for Improved Fairness in LLM In-Context Learning\n\n\n\nsocial-sciences\n\n\n\nIncluding minority group samples in prompts boosts fairness in LLMs without compromising accuracy, aiding in-context learning for tabular data.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMegaAgent: A Practical Framework for Autonomous Cooperation in Large-Scale LLM Agent Systems\n\n\n\nproduction\n\n\narchitectures\n\n\n\nMegaAgent: A framework for autonomous cooperation in large-scale LLM Agent systems, outperforming popular LLM-MA systems and rapidly scaling up to 590 agents.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Make the Most of LLMs’ Grammatical Knowledge for Acceptability Judgments\n\n\n\nsocial-sciences\n\n\nprompt-engineering\n\n\n\nLLMs’ grammatical knowledge is best evaluated using in-template LP and Yes/No probability computing, outperforming traditional methods. Diverse methods recommended for…\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportance Weighting Can Help Large Language Models Self-Improve\n\n\n\narchitectures\n\n\n\nFiltering high-DSE samples with DS weight improves LLM self-improvement, rivaling externally supervised methods.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstruction Finetuning for Leaderboard Generation from Empirical AI Research\n\n\n\nproduction\n\n\n\nThis study automates AI leaderboards using finetuned LLMs, improving information extraction and knowledge representation.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRanking Generated Answers: On the Agreement of Retrieval Models with Humans on Consumer Health Questions\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\narchitectures\n\n\n\nRanking signals can evaluate LLM answers, correlating with human expert preferences, and improving with model size and prompt strategies.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDevelopment of an AI Anti-Bullying System Using Large Language Model Key Topic Detection\n\n\n\nhci\n\n\n\nAI system detects, analyzes, and proposes solutions for social media bullying.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhance Modality Robustness in Text-Centric Multimodal Alignment with Adversarial Prompting\n\n\n\narchitectures\n\n\n\nTL;DR: New text-centric adversarial training improves multimodal representation robustness.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaired Completion: Flexible Quantification of Issue-framing at Scale with LLMs\n\n\n\nsocial-sciences\n\n\n\nPaired completion method enables scalable, accurate, and low-bias issue-framing detection in large text datasets.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre Large Language Models More Honest in Their Probabilistic or Verbalized Confidence?\n\n\n\nsocial-sciences\n\n\nrobustness\n\n\n\nLLMs’ probabilistic perception of knowledge boundaries is more accurate but needs calibration. Both perceptions perform better on less frequent questions. LLMs struggle to…\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMinor DPO reject penalty to increase training robustness\n\n\n\nsocial-sciences\n\n\narchitectures\n\n\n\nDPO simplifies LLM alignment to human preferences, but has limitations. MinorDPO improves stability and alignment, addressing DPO’s shortcomings.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHarnessing Multimodal Large Language Models for Multimodal Sequential Recommendation\n\n\n\nprompt-engineering\n\n\nrecommender\n\n\n\nMLLM-MSR: A new model for multimodal recommendation systems, capturing dynamic user preferences with image and text data.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApplication of Large Language Models in Automated Question Generation: A Case Study on ChatGLM’s Structured Questions for National Teacher Certification Exams\n\n\n\nhci\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\neducation\n\n\n\nChatGLM generates realistic exam questions for NTCE, but needs optimization for diverse rating criteria.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEdge-Cloud Collaborative Motion Planning for Autonomous Driving with Large Language Models\n\n\n\nproduction\n\n\narchitectures\n\n\n\nEC-Drive: Edge-Cloud Collaboration for Efficient Autonomous Driving with GPT-4.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCMoralEval: A Moral Evaluation Benchmark for Chinese Large Language Models\n\n\n\narchitectures\n\n\n\nCMoralEval: A Chinese Morality Benchmark for LLMs (13 words)\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrivacy Checklist: Privacy Violation Detection Grounding on Contextual Integrity Theory\n\n\n\nproduction\n\n\nsecurity\n\n\n\nPrivacy research reimagined: A context-centric approach using LLMs to cover HIPAA regulations and private information.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive Software Release Decision-Making\n\n\n\nprompt-engineering\n\n\n\nGoNoGo: LLM Agent System Automates Automotive Software Deployment, Reducing Manual Intervention.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGANPrompt: Enhancing Robustness in LLM-Based Recommendations with GAN-Enhanced Diversity Prompts\n\n\n\nprompt-engineering\n\n\nrecommender\n\n\n\nGANPrompt improves LLM’s adaptability to diverse prompts, enhancing recommender system accuracy and robustness.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAttribution Analysis Meets Model Editing: Advancing Knowledge Correction in Vision Language Models with VisEdit\n\n\n\nprompt-engineering\n\n\nrobustness\n\n\nproduction\n\n\narchitectures\n\n\n\nVisEdit edits visual representations in VLLMs for accurate, cost-effective knowledge correction.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMSDiagnosis: An EMR-based Dataset for Clinical Multi-Step Diagnosis\n\n\n\nproduction\n\n\narchitectures\n\n\n\nTL;DR: We propose a multi-step diagnostic task with a novel framework, demonstrating its effectiveness on a clinical dataset.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-Directed Turing Test for Large Language Models\n\n\n\nprompt-engineering\n\n\narchitectures\n\n\nhci\n\n\neducation\n\n\nsocial-sciences\n\n\n\nSelf-Directed Turing Test evaluates LLMs in dynamic, prolonged dialogues, revealing GPT-4 struggles with long-term consistency.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBridging the Language Gap: Enhancing Multilingual Prompt-Based Code Generation in LLMs via Zero-Shot Cross-Lingual Transfer\n\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\nLLMs struggle with non-English prompts for code generation. A zero-shot cross-lingual approach using neural projection improves code quality for multilingual prompts.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBenchmarking LLMs for Translating Classical Chinese Poetry:Evaluating Adequacy, Fluency, and Elegance\n\n\n\nsocial-sciences\n\n\nproduction\n\n\narchitectures\n\n\n\nLLMs struggle with translating classical poetry; RAT method and GPT-4 metric proposed for improvement.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Comparison of Large Language Model and Human Performance on Random Number Generation Tasks\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\nrobustness\n\n\nhci\n\n\n\nLLMs like ChatGPT-3.5 generate random sequences more effectively than humans, with fewer repetitive and sequential patterns.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMAPLE: Enhancing Review Generation with Multi-Aspect Prompt LEarning in Explainable Recommendation\n\n\n\nprompt-engineering\n\n\nrecommender\n\n\n\nMAPLE, a personalized aspect-controlled model, outperforms baseline review-generation models in diversity, coherence, and factual relevance, offering enriched, personalized…\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimulating Field Experiments with Large Language Models\n\n\n\nhci\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\neducation\n\n\n\nThis paper explores using LLMs to simulate field experiments, achieving 66% accuracy in observer mode and identifying LLMs’ limitations in certain topics.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPerformance Law of Large Language Models\n\n\n\nproduction\n\n\narchitectures\n\n\n\nPerformance Law predicts LLM capabilities using key hyperparameters, aiding architecture and resource decisions.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTBA: Faster Large Language Model Training Using SSD-Based Activation Offloading\n\n\n\nproduction\n\n\narchitectures\n\n\n\nTBA offloads activations to SSDs, reducing GPU memory usage by 47% with negligible performance overhead, outperforming layerwise full recomputation in memory savings.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIcing on the Cake: Automatic Code Summarization at Ericsson\n\n\n\nprompt-engineering\n\n\nprogramming\n\n\neducation\n\n\n\nTL;DR: Simpler Java method summarization approaches outperform ASAP, showing robustness to method name variations.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDemystifying the Communication Characteristics for Distributed Transformer Models\n\n\n\nproduction\n\n\narchitectures\n\n\n\nTransformer models’ communication behavior reveals need for optimizing small message point-to-point communication and guiding further optimizations in framework and HPC…\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCustomizing Language Models with Instance-wise LoRA for Sequential Recommendation\n\n\n\nproduction\n\n\nrecommender\n\n\narchitectures\n\n\n\niLoRA: A tailored approach for sequential recommendations, improving accuracy by capturing individual user preferences.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nARMADA: Attribute-Based Multimodal Data Augmentation\n\n\n\nproduction\n\n\n\nTL;DR: ARMADA augments image-text pairs using knowledge-guided attribute manipulation, improving multimodal language models.\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTransferring Backdoors between Large Language Models by Knowledge Distillation\n\n\n\nprompt-engineering\n\n\nsecurity\n\n\neducation\n\n\narchitectures\n\n\n\nBackdoor Attack Risk in Mini-LLMs: Adaptive Transferable Attack Proposed\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving and Assessing the Fidelity of Large Language Models Alignment to Online Communities\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs can represent communities, but alignment is challenging. This paper proposes a framework for aligning LLMs with online communities and evaluates its effectiveness in…\n\n\n\nAug 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAntidote: Post-fine-tuning Safety Alignment for Large Language Models against Harmful Fine-tuning\n\n\n\nsecurity\n\n\n\nAntidote removes harmful parameters post-fine-tuning, reducing harmful content without compromising performance, regardless of training hyper-parameters.\n\n\n\nAug 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacterizing and Evaluating the Reliability of LLMs against Jailbreak Attacks\n\n\n\nprompt-engineering\n\n\nsecurity\n\n\nhci\n\n\nrobustness\n\n\n\nLLMs face jailbreaking threats; this study evaluates 13 LLMs against 10 strategies, revealing vulnerabilities and offering reliability scores.\n\n\n\nAug 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMergeRepair: An Exploratory Study on Merging Task-Specific Adapters in Code LLMs for Automated Program Repair\n\n\n\nprogramming\n\n\n\nMerging task-specific adapters for LLMs in APR; exploring merging methods, weight, and task order impact on performance.\n\n\n\nAug 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo Such Thing as a General Learner: Language models and their dual optimization\n\n\n\nhci\n\n\nsocial-sciences\n\n\neducation\n\n\n\nLLMs, optimized during training and selection, don’t settle debates on human cognitive biases in language acquisition.\n\n\n\nAug 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFostering Natural Conversation in Large Language Models with NICO: a Natural Interactive COnversation dataset\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs struggle with natural responses; NICO dataset introduced to improve LLMs’ dialogue capabilities.\n\n\n\nAug 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model\n\n\n\nhci\n\n\n\nHiAgent improves LLM-based agents’ performance in long-horizon tasks by managing working memory with subgoals, achieving a twofold success rate increase.\n\n\n\nAug 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOffline RLHF Methods Need More Accurate Supervision Signals\n\n\n\nsocial-sciences\n\n\n\nRDO improves offline RLHF by considering how much one response is preferred over others, enhancing LLM alignment with human preferences.\n\n\n\nAug 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Transcription Prompt-based Efficient Audio Large Language Model for Robust Speech Recognition\n\n\n\nsocial-sciences\n\n\nrobustness\n\n\n\nNew method reduces errors, eliminates repetition in audio-LLM speech recognition, improving performance in noisy environments.\n\n\n\nAug 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOut-of-distribution generalization via composition: a lens through induction heads in Transformers\n\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\nLLMs solve new tasks via OOD generalization, learning rules through self-attention layer composition and a shared latent subspace.\n\n\n\nAug 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGame Development as Human-LLM Interaction\n\n\n\neducation\n\n\nprogramming\n\n\nhci\n\n\n\nIGE: A Natural Language Game Engine for Everyone\n\n\n\nAug 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Boosting LLMs-driven Relevance Modeling with Progressive Retrieved Behavior-augmented Prompting\n\n\n\nprompt-engineering\n\n\nhci\n\n\nrecommender\n\n\n\nThis study introduces ProRBP, a novel framework for integrating search scenario-oriented knowledge with LLMs, improving relevance modeling in search engines.\n\n\n\nAug 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGalápagos: Automated N-Version Programming with LLMs\n\n\n\nsecurity\n\n\nprogramming\n\n\nrobustness\n\n\n\nTL;DR: Galápagos tool generates diverse, equivalent program variants using LLMs, protecting C code from miscompilation bugs.\n\n\n\nAug 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCyberPal.AI: Empowering LLMs with Expert-Driven Cybersecurity Instructions\n\n\n\nsecurity\n\n\nhci\n\n\n\nSecKnowledge & CyberPal.AI improve LLMs for cyber-security, showing up to 24% better performance.\n\n\n\nAug 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmBARDiment: an Embodied AI Agent for Productivity in XR\n\n\n\nprompt-engineering\n\n\nhci\n\n\n\nNew XR chat-bot uses attention framework for intuitive, context-aware interactions, reducing explicit prompts.\n\n\n\nAug 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMIDAS: Multi-level Intent, Domain, And Slot Knowledge Distillation for Multi-turn NLU\n\n\n\nhci\n\n\nprompt-engineering\n\n\neducation\n\n\n\nMIDAS improves multi-turn conversation understanding by distilling multi-level intent, domain, and slot knowledge.\n\n\n\nAug 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nText2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework\n\n\n\neducation\n\n\nprogramming\n\n\nhci\n\n\n\nText2BIM: LLM-based framework generates 3D building models from natural language instructions, improving BIM design process.\n\n\n\nAug 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKGV: Integrating Large Language Models with Knowledge Graphs for Cyber Threat Intelligence Credibility Assessment\n\n\n\nsecurity\n\n\n\nKnowledge Graph-Based Verifier Improves CTI Quality Assessment, Reducing Data Annotation and Boosting Reasoning Capabilities.\n\n\n\nAug 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation\n\n\n\nrecommender\n\n\n\nLLM4DSR: A model-agnostic approach for denoising sequential recommendation using LLMs, outperforming existing methods.\n\n\n\nAug 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System\n\n\n\nrecommender\n\n\n\nLLMs’ direct representation alignment with collaborative models is sub-optimal; proposed framework disentangles and aligns representations for improved recommendation tasks.\n\n\n\nAug 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nToward a Dialogue System Using a Large Language Model to Recognize User Emotions with a Camera\n\n\n\neducation\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs can recognize user emotions from facial expressions, enabling AI agents to interact based on emotional states, especially for high-scoring emotions like Happy and Angry.\n\n\n\nAug 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWords Matter: Reducing Stigma in Online Conversations about Substance Use with Large Language Models\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nStudy analyzes Reddit posts to develop a model for destigmatizing language towards substance users, promoting a supportive online environment.\n\n\n\nAug 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKOALA: Enhancing Speculative Decoding for LLM via Multi-Layer Draft Heads with Adversarial Learning\n\n\n\nsecurity\n\n\n\nKOALA improves draft head accuracy in LLMs, reducing inference latency by up to 14.09%.\n\n\n\nAug 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan Large Language Models Understand Symbolic Graphics Programs?\n\n\n\neducation\n\n\n\nLLMs can understand symbolic graphics programs by answering questions about visual content, which they may imagine from the programs. A new benchmark evaluates LLMs’ visual…\n\n\n\nAug 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLaVA-Surg: Towards Multimodal Surgical Assistant via Structured Surgical Video Learning\n\n\n\nrobustness\n\n\neducation\n\n\n\nNew dataset Surg-QA enables training of LLaVA-Surg, a model excelling in open-ended surgical video Q&A, outperforming general-domain models.\n\n\n\nAug 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe doctor will polygraph you now: ethical concerns with AI for fact-checking patients\n\n\n\nsocial-sciences\n\n\n\nAI for predicting social behaviors raises ethical concerns about patient data use, accuracy, and trust in healthcare.\n\n\n\nAug 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFine-tuning Large Language Models with Human-inspired Learning Strategies in Medical Question Answering\n\n\n\neducation\n\n\n\nCurriculum learning for LLMs varies in effectiveness, with gains up to 1.81% per dataset, and model-defined difficulty may outperform human-defined difficulty.\n\n\n\nAug 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words\n\n\n\nprompt-engineering\n\n\n\nLLM-based ASR system transcribes ambiguous words better with keyword prompts, improving rare word recognition.\n\n\n\nAug 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssessing Language Models’ Worldview for Fiction Generation\n\n\n\nprogramming\n\n\nhci\n\n\n\nLLMs struggle to maintain consistent worldview for fiction writing, often producing uniform narratives, highlighting their limitations in this area.\n\n\n\nAug 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfidence-weighted integration of human and machine judgments for superior decision-making\n\n\n\nsocial-sciences\n\n\n\nLLMs excel in tasks, but human-machine teams outperform when confidence is well-calibrated and tasks are diverse, improving overall performance.\n\n\n\nAug 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDoes Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models\n\n\n\nsocial-sciences\n\n\neducation\n\n\n\nLLMs’ reasoning abilities are assessed using probability of necessity and sufficiency, offering insights into their real-world reasoning capabilities.\n\n\n\nAug 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsefulness of data flow diagrams and large language models for security threat validation: a registered report\n\n\n\nsecurity\n\n\neducation\n\n\nrobustness\n\n\n\nStudy aims to optimize threat analysis in cybersecurity, testing if more analysis material leads to better validation of identified threats.\n\n\n\nAug 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCovert Bias: The Severity of Social Views’ Unalignment Towards Implicit and Explicit Opinion\n\n\n\nsocial-sciences\n\n\n\nLLMs struggle with implicit bias, favor explicit opinions, and need uncertainty markers for reliability.\n\n\n\nAug 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPolaris: Open-ended Interactive Robotic Manipulation via Syn2Real Visual Grounding and Large Language Models\n\n\n\neducation\n\n\n\nPolaris: GPT-4 & Vision Models for Robotic Manipulation\n\n\n\nAug 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultimodal Causal Reasoning Benchmark: Challenging Vision Large Language Models to Infer Causal Links Between Siamese Images\n\n\n\neducation\n\n\n\nVLLMs struggle with causal reasoning from visual cues; new benchmark, MuCR, introduced for evaluation.\n\n\n\nAug 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLPU: A Latency-Optimized and Highly Scalable Processor for Large Language Model Inference\n\n\n\nhci\n\n\n\nHyperAccel’s LPU outperforms GPU in LLM inference, offering better speed and energy efficiency.\n\n\n\nAug 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs\n\n\n\nrobustness\n\n\n\nLaTeX guide for ACM article formatting using ‘acmart’ class.\n\n\n\nAug 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-Enhanced Static Analysis for Precise Identification of Vulnerable OSS Versions\n\n\n\nsecurity\n\n\nprogramming\n\n\nrobustness\n\n\n\nVercation identifies vulnerable OSS versions using program slicing & LLM, outperforming current methods with a 92.4% F1 score and detecting 134 incorrect versions in NVD…\n\n\n\nAug 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedTsLLM: Leveraging LLMs for Multimodal Medical Time Series Analysis\n\n\n\nprompt-engineering\n\n\n\nMedTsLLM: A multimodal LLM for medical time series analysis, outperforming baselines in semantic segmentation, boundary detection, and anomaly detection.\n\n\n\nAug 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearning-based Models for Vulnerability Detection: An Extensive Study\n\n\n\nsecurity\n\n\n\nDeep learning models for vulnerability detection lack understanding, with sequence-based models showing priority and instability.\n\n\n\nAug 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models Prompting With Episodic Memory\n\n\n\nprompt-engineering\n\n\n\nPOEM: A Reinforcement Learning-based Prompt Optimization Technique Outperforms Recent Methods in Text Classification Tasks.\n\n\n\nAug 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTransformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey\n\n\n\nrobustness\n\n\n\nTL;DR: Transformers and LLMs enhance cybersecurity, aiding in threat detection across various environments and applications.\n\n\n\nAug 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDevelopment of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments\n\n\n\neducation\n\n\n\nLLM-driven CDSS improves ED triage, treatment planning, and care management, potentially alleviating overcrowding and enhancing patient outcomes.\n\n\n\nAug 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA System for Automated Unit Test Generation Using Large Language Models and Assessment of Generated Test Suites\n\n\n\nrobustness\n\n\nprogramming\n\n\n\nLLMs can automate unit test generation, and AgoneTest offers a scalable solution for Java projects, complete with a new dataset and evaluation methodology.\n\n\n\nAug 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeeing and Understanding: Bridging Vision with Chemical Knowledge Via ChemVLM\n\n\n\nsecurity\n\n\n\nChemVLM is a multimodal language model for chemistry, excelling in image understanding and text analysis, achieving state-of-the-art results in five out of six tasks.\n\n\n\nAug 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond Inter-Item Relations: Dynamic Adaptive Mixture-of-Experts for LLM-Based Sequential Recommendation\n\n\n\nrecommender\n\n\n\nMixRec: LLM-based SRS that captures intra-item relations, long-term collaborative knowledge, and uses dynamic adaptive architecture for better sequential recommendations.\n\n\n\nAug 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating Large Language Model based Personal Information Extraction and Countermeasures\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nLLMs can extract personal info from profiles, outperforming traditional methods; prompt injection mitigates this risk.\n\n\n\nAug 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNew Curriculum, New Chance – Retrieval Augmented Generation for Lesson Planning in Ugandan Secondary Schools. Prototype Quality Evaluation\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nAI generates high-quality lesson plans (75-80%) for Ugandan curriculum, outperforming human-made plans.\n\n\n\nAug 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nStudy reveals biases in Speech Large Language Models using Spoken Stereoset dataset, with some models showing stereotypical tendencies.\n\n\n\nAug 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBridging and Modeling Correlations in Pairwise Data for Direct Preference Optimization\n\n\n\neducation\n\n\n\nBMC framework improves DPO by bridging and modeling correlations in pairwise preference data, outperforming baselines in QA, math, and instruction-following tasks.\n\n\n\nAug 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Decision to Action in Surgical Autonomy: Multi-Modal Large Language Models for Robot-Assisted Blood Suction\n\n\n\nprompt-engineering\n\n\n\nLLMs enhance contextual understanding and decision-making in robotic-assisted surgeries, enabling autonomous blood suction.\n\n\n\nAug 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Large-Scale Language Models to Evaluate EEG-Based Multimodal Data for Mental Health\n\n\n\nhci\n\n\n\nMultimodal data (EEG, audio, images) enhances mental health assessment, with 1-shot learning outperforming zero-shot in LLMs.\n\n\n\nAug 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSceneGPT: A Language Model for 3D Scene Understanding\n\n\n\neducation\n\n\n\nSceneGPT: Using Pre-trained LLMs for 3D Scene Understanding without 3D Pre-training.\n\n\n\nAug 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMs can Schedule\n\n\n\nhci\n\n\n\nTL;DR: LLMs can tackle job shop scheduling problems, performing comparably to other neural methods.\n\n\n\nAug 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCasper: Prompt Sanitization for Protecting User Privacy in Web-Based Large Language Models\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nCasper is a browser extension that sanitizes user inputs to protect privacy, removing sensitive info before sending to LLM services with 98.5% PII and 89.9% topic accuracy.\n\n\n\nAug 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Advanced LLMs to Enhance Smaller LLMs: An Interpretable Knowledge Distillation Approach\n\n\n\nhci\n\n\nprompt-engineering\n\n\nrobustness\n\n\neducation\n\n\n\n[ABSTRACT] This study examines the relationship between social media use and mental health in young adults. Results indicate a significant positive correlation between the…\n\n\n\nAug 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow Aligned are Human Chart Takeaways and LLM Predictions? A Case Study on Bar Charts with Varying Layouts\n\n\n\nhci\n\n\n\nLLMs struggle to generate accurate, diverse takeaways like humans, showing sensitivity to visualization design choices.\n\n\n\nAug 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeveraging Language Models for Emotion and Behavior Analysis in Education\n\n\n\nhci\n\n\n\nLLMs with prompt engineering outperform baselines in non-intrusive, scalable student emotion and engagement analysis.\n\n\n\nAug 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAgent Q: Advanced Reasoning and Learning for Autonomous AI Agents\n\n\n\nprompt-engineering\n\n\nhci\n\n\n\nLLMs struggle with multi-step reasoning in interactive environments. Our framework, combining MCTS search, self-critique, and iterative fine-tuning, improves LLM agents’…\n\n\n\nAug 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDracoGPT: Extracting Visualization Design Preferences from Large Language Models\n\n\n\nhci\n\n\nrecommender\n\n\n\nDracoGPT assesses visualization design preferences in LLMs, finding moderate agreement between ranking and recommendation pipelines, but substantial divergence from…\n\n\n\nAug 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents\n\n\n\nprogramming\n\n\n\nDEI framework boosts open-source SWE agents’ performance, improving issue resolution by 25% on SWE-Bench Lite.\n\n\n\nAug 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou still have to study – On the Security of LLM generated code\n\n\n\nsecurity\n\n\neducation\n\n\nrobustness\n\n\n\nAI-generated code often insecure; improves with better prompts and manual guidance.\n\n\n\nAug 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrompt Tuning as User Inherent Profile Inference Machine\n\n\n\nrecommender\n\n\n\nLLMs improve recommender systems but face challenges. UserIP-Tuning, a prompt-tuning method, addresses these issues, enhancing performance and efficiency.\n\n\n\nAug 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge language models can consistently generate high-quality content for election disinformation operations\n\n\n\nrobustness\n\n\nsecurity\n\n\n\n[ABSTRACT] This paper explores the relationship between social media use and mental health in young adults. Results indicate a significant correlation between excessive…\n\n\n\nAug 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNeural embedding of beliefs reveals the role of relative dissonance in human decision-making\n\n\n\nhci\n\n\n\nLLM-based model predicts beliefs, cognitive dissonance using online debate data.\n\n\n\nAug 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHLSPilot: LLM-based High-Level Synthesis\n\n\n\nprogramming\n\n\n\nHLSPilot: LLM-based tool automates high-level application acceleration on hybrid CPU-FPGA architectures, often outperforming manual designs.\n\n\n\nAug 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating Cultural Adaptability of a Large Language Model via Simulation of Synthetic Personas\n\n\n\nhci\n\n\n\nLLMs like GPT-3.5 perform better with user’s country info, but native language cues can reduce alignment with real responses.\n\n\n\nAug 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan Large Language Models Reason? A Characterization via 3-SAT\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\n[TEXT] This study examines the impact of climate change on the migration patterns of polar bears in the Arctic. Results indicate that as sea ice continues to decline, polar…\n\n\n\nAug 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLUT Tensor Core: Lookup Table Enables Efficient Low-Bit LLM Inference Acceleration\n\n\n\nproduction\n\n\narchitectures\n\n\n\nTL;DR: LUT Tensor Core improves low-bit LLM inference efficiency by optimizing mpGEMM with software-hardware co-design.\n\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOptimizing RAG Techniques for Automotive Industry PDF Chatbots: A Case Study with Locally Deployed Ollama Models\n\n\n\narchitectures\n\n\n\nTL;DR: Optimized RAG techniques improve local LLM deployment for automotive PDF chatbots, enhancing context precision, recall, and answer relevancy.\n\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models for Secure Code Assessment: A Multi-Language Empirical Study\n\n\n\nsecurity\n\n\nprogramming\n\n\nrobustness\n\n\n\nLLMs, like GPT-4o, effectively detect vulnerabilities in diverse languages; CodeGuardian, an LLM-assisted tool, aids developers in real-time vulnerability analysis.\n\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNob-MIAs: Non-biased Membership Inference Attacks Assessment on Large Language Models with Ex-Post Dataset Construction\n\n\n\nproduction\n\n\n\nTL;DR: New methods create fairer datasets for evaluating MIAs on LLMs, showing biases hinder MIA effectiveness.\n\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConvKGYarn: Spinning Configurable and Scalable Conversational Knowledge Graph QA datasets with Large Language Models\n\n\n\nproduction\n\n\nsocial-sciences\n\n\nhci\n\n\n\nConvKGYarn generates high-quality, scalable conversational datasets for LLMs, improving KGQA foundations and evaluating LLMs’ knowledge.\n\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHyperion: Unveiling DApp Inconsistencies using LLM and Dataflow-Guided Symbolic Execution\n\n\n\nproduction\n\n\narchitectures\n\n\nrobustness\n\n\nprogramming\n\n\n\nHyperion detects inconsistencies in DApps, achieving 84.06% recall and 92.06% precision, discovering 459 real-world DApps with at least one inconsistency.\n\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnimate, or Inanimate, That is the Question for Large Language Models\n\n\n\nsocial-sciences\n\n\nhci\n\n\nprompt-engineering\n\n\n\nLLMs can understand animacy like humans, despite text-only training, adapting to unconventional situations.\n\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan We Rely on LLM Agents to Draft Long-Horizon Plans? Let’s Take TravelPlanner as an Example\n\n\n\neducation\n\n\narchitectures\n\n\n\nLLMs struggle with long contexts, refinement, and feedback, but Feedback-Aware Fine-Tuning (FAFT) improves performance.\n\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA New Pipeline For Generating Instruction Dataset via RAG and Self Fine-Tuning\n\n\n\narchitectures\n\n\n\nThis research proposes a pipeline for creating domain-specific instruction datasets for fine-tuning large language models, using psychiatry as a case study.\n\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreating Arabic LLM Prompts at Scale\n\n\n\neducation\n\n\nhci\n\n\nprogramming\n\n\narchitectures\n\n\nprompt-engineering\n\n\n\nTwo methods create 67.4M Arabic prompts, enabling a 7B LLM to outperform a 70B model.\n\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultimodal Large Language Models for Phishing Webpage Detection and Identification\n\n\n\nproduction\n\n\narchitectures\n\n\nsecurity\n\n\n\nLLMs effectively detect phishing webpages, offering high precision and interpretable results, outperforming existing brand-based systems.\n\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA RAG-Based Question-Answering Solution for Cyber-Attack Investigation and Attribution\n\n\n\nproduction\n\n\narchitectures\n\n\nsecurity\n\n\n\nOur QA model, based on RAG and LLM, outperforms GPT-3.5 and GPT-4o in cyber-attack investigation and attribution, providing answer sources and reducing hallucination.\n\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuilding Decision Making Models Through Language Model Regime\n\n\n\nproduction\n\n\nsocial-sciences\n\n\narchitectures\n\n\n\nLTU approach trains LLMs for decision making, outperforming traditional methods in e-commerce domains, offering a versatile and adaptable framework.\n\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTRIZ-GPT: An LLM-augmented method for problem-solving\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\n\nTL;DR: LLMs aid TRIZ problem-solving by transforming problems and generating inventive solutions, as demonstrated in a mechanical engineering case study.\n\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMed42-v2: A Suite of Clinical LLMs\n\n\n\nproduction\n\n\neducation\n\n\nprompt-engineering\n\n\n\nMed42-v2: Clinical LLMs outperform generic models, now available on Hugging Face.\n\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReview-driven Personalized Preference Reasoning with Large Language Models for Recommendation\n\n\n\nrecommender\n\n\n\nExp3rt: LLM-based recommender using reviews for enhanced rating prediction and explainability.\n\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating Language Models for Efficient Code Generation\n\n\n\nprogramming\n\n\n\nDPE is a framework for evaluating LLMs’ code efficiency, offering a compound metric and efficiency-focused tasks. It’s proven reliable and convenient.\n\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMutual Reasoning Makes Smaller LLMs Stronger Problem-Solvers\n\n\n\nproduction\n\n\narchitectures\n\n\n\nrStar improves SLMs’ reasoning without fine-tuning via self-play mutual generation-discrimination, boosting GSM8K accuracy significantly.\n\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnchored Preference Optimization and Contrastive Revisions: Addressing Underspecification in Alignment\n\n\n\nproduction\n\n\narchitectures\n\n\n\nCLAIR and APO improve LLM alignment, boosting Llama-3-8B-Instruct performance by 7.65% and closing gap with GPT-4-turbo by 45%.\n\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFuxiTranyu: A Multilingual Large Language Model Trained with Balanced Data\n\n\n\nproduction\n\n\narchitectures\n\n\n\nFuxiTranyu: Open-source multilingual LLM with competitive performance on multilingual benchmarks, available for further research.\n\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn Effects of Steering Latent Representation for Large Language Model Unlearning\n\n\n\nproduction\n\n\narchitectures\n\n\nrobustness\n\n\nsecurity\n\n\n\nRMU unlearning method for LLMs reduces token confidence, causing wrong/nonsense responses. Adaptive RMU improves unlearning performance without extra cost.\n\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSynthetic Patient-Physician Dialogue Generation from Clinical Notes Using LLM\n\n\n\nproduction\n\n\n\n[ABSTRACT] This paper presents a novel approach to image denoising using a deep learning model. The proposed method outperforms existing techniques in terms of both accuracy…\n\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Decoding Acceleration Framework for Industrial Deployable LLM-based Recommender Systems\n\n\n\nrecommender\n\n\n\n[TEXT] The Impact of Social Media on College Students’ Academic Performance: A Review of Literature [TL;DR] Social media negatively affects college students’ academic…\n\n\n\nAug 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-Based Robust Product Classification in Commerce and Compliance\n\n\n\narchitectures\n\n\nsecurity\n\n\n\nLLMs outperform supervised approaches in product classification, especially with incomplete data.\n\n\n\nAug 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSupporting Software Maintenance with Dynamically Generated Document Hierarchies\n\n\n\narchitectures\n\n\nprogramming\n\n\n\nHGEN, an automated tool, generates high-quality software documentation, comparable to manual methods, with improved concept coverage and potential for industrial use.\n\n\n\nAug 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefining Boundaries: A Spectrum of Task Feasibility for Large Language Models\n\n\n\narchitectures\n\n\nrobustness\n\n\n\nLLMs struggle with infeasible tasks; this paper categorizes them, tests LLMs, and explores training enhancements to improve refusal capabilities.\n\n\n\nAug 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTop Pass: Improve Code Generation by Pass@k-Maximized Code Ranking\n\n\n\narchitectures\n\n\nprogramming\n\n\n\nTop Pass ranks code better, improving usability; 32.9% pass@1 increase on CodeContests.\n\n\n\nAug 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUtilizing Large Language Models to Optimize the Detection and Explainability of Phishing Websites\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nPhishLang: Open-source LLM for phishing detection, faster & less resource-intensive than deep learning, offers explainable blocklisting, and integrates with GPT-3.5 Turbo.\n\n\n\nAug 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Retriever Augmented Large Language Models for Attack Graph Generation\n\n\n\narchitectures\n\n\nsecurity\n\n\n\nTL;DR: Leveraging LLMs like ChatGPT to automate attack graph generation for vulnerability management.\n\n\n\nAug 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPreserving Privacy in Large Language Models: A Survey on Current Threats and Solutions\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nTL;DR: This survey explores privacy threats in LLMs and proposes solutions for integrating privacy mechanisms in AI systems.\n\n\n\nAug 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-DetectAIve: a Tool for Fine-Grained Machine-Generated Text Detection\n\n\n\neducation\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\ntl;dr: Study explores how AI can improve mental health care.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Healthcare through Large Language Models: A Study on Medical Question Answering\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nSentence-t5 + Mistral 7B excels in medical QA, scoring 0.762 in precision, aiding patient education.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRecognizing Emotion Regulation Strategies from Human Behavior with Large Language Models\n\n\n\nsocial-sciences\n\n\nhci\n\n\nprompt-engineering\n\n\n\nLLMs can accurately classify emotion regulation strategies using verbal behavior, outperforming Bayesian Networks.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearning Fine-Grained Grounded Citations for Attributed Large Language Models\n\n\n\nrobustness\n\n\n\nFRONT framework improves LLM citation quality, outperforming baselines and ChatGPT in ALCE benchmark.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBias-Aware Low-Rank Adaptation: Mitigating Catastrophic Inheritance of Large Language Models\n\n\n\nprogramming\n\n\n\nTL;DR: BA-LoRA is a PEFT method that reduces bias and improves LLM performance with regularizers.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompromesso! Italian Many-Shot Jailbreaks Undermine the Safety of Large Language Models\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nLLMs can be jailbroken to act unsafely in Italian, with vulnerabilities increasing with more unsafe demonstrations.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEXAONE 3.0 7.8B Instruction Tuned Language Model\n\n\n\neducation\n\n\n\nEXAONE 3.0: Open, 7.8B-parameter LLM excels in Korean, complex reasoning, and general tasks. Available at Hugging Face.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRiskAwareBench: Towards Evaluating Physical Risk Awareness for High-level Planning of LLM-based Embodied Agents\n\n\n\nsecurity\n\n\n\nLLMs in robotics lack risk awareness, posing safety risks; RiskAwareBench framework proposed for assessment.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Explainable Network Intrusion Detection using Large Language Models\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nLLMs underperform in precise threat detection but show potential for explainable NIDS, especially when integrated with RAG and function calling capabilities.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpen-domain Implicit Format Control for Large Language Model Generation\n\n\n\neducation\n\n\n\nStudy explores LLMs’ ability to follow one-shot, open-domain format constraints, introducing a novel framework and dataset for improved control.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre Social Sentiments Inherent in LLMs? An Empirical Study on Extraction of Inter-demographic Sentiments\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs can capture sentiments between social groups, aligning with social survey results, especially for nationalities and religions.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Resilient and Efficient LLMs: A Comparative Study of Efficiency, Performance, and Adversarial Robustness\n\n\n\nsecurity\n\n\n\nSimplified LLMs balance efficiency, performance, and adversarial robustness better than complex models.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConversational Prompt Engineering\n\n\n\neducation\n\n\nhci\n\n\nprompt-engineering\n\n\n\nCPE tool simplifies prompt engineering for LLMs, creating personalized, high-performing prompts with user-friendly chat interactions.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArctic-TILT. Business Document Understanding at Sub-Billion Scale\n\n\n\neducation\n\n\n\nArctic-TILT: Small, accurate LLM for document QA, reducing costs and improving efficiency.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Reasoning Biases in Large Language Models Through Syllogism: Insights from the NeuBAROCO Dataset\n\n\n\nsocial-sciences\n\n\neducation\n\n\nprompt-engineering\n\n\n\nTL;DR: LLMs show human-like reasoning biases in syllogistic problems, with room for improvement in non-entailment/contradiction cases.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideoQA in the Era of LLMs: An Empirical Study\n\n\n\nsecurity\n\n\n\nVideo-LLMs excel in VideoQA but struggle with video temporality, robustness, and interpretability.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearning to Rewrite: Generalized LLM-Generated Text Detection\n\n\n\nrobustness\n\n\n\nLLMs can detect machine-generated text better when trained to rewrite input, improving detection across domains.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat You Need is What You Get: Theory of Mind for an LLM-Based Code Understanding Assistant\n\n\n\nsocial-sciences\n\n\neducation\n\n\nhci\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\nTL;DR: Personalized LLM-based assistant aids novices in code understanding, tailored to user’s mental state.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAcademic collaboration on large language model studies increases overall but varies across disciplines\n\n\n\nhci\n\n\n\nLLMs like ChatGPT boost interdisciplinary collaboration, especially in Computer Science, Medicine, and related fields. Key players include Stanford, Harvard, UCL, and Google.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMMREC: LLM Based Multi-Modal Recommender System\n\n\n\nrecommender\n\n\nhci\n\n\n\nLLMs and deep learning improve recommender systems by processing multi-modal data, enhancing relevance and accuracy.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the extent of similarities in software failures across industries using LLMs\n\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\nIndustry-specific software failures identified using LLMs for safer software development.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPerceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions\n\n\n\nprompt-engineering\n\n\n\nAgent navigates city using landmarks, perception, reflection, and planning, outperforming baselines.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemantic-Enhanced Indirect Call Analysis with Large Language Models\n\n\n\nprogramming\n\n\n\nSEA uses LLMs to improve indirect call analysis, enhancing static analysis tasks in software development.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models for cross-language code clone detection\n\n\n\neducation\n\n\nprogramming\n\n\n\nLLMs struggle with complex code clones; embedding models outperform LLMs in cross-lingual code clone detection.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutomated Educational Question Generation at Different Bloom’s Skill Levels using Large Language Models: Strategies and Evaluation\n\n\n\nsocial-sciences\n\n\neducation\n\n\nhci\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\nLLMs can generate diverse, high-quality educational questions with proper prompting, but human evaluation is superior to automated evaluation.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models\n\n\n\nhci\n\n\n\nTL;DR: MM-Forecast improves event forecasting by integrating images into LLMs, highlighting and complementing text data.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive Debate\n\n\n\nsocial-sciences\n\n\nrobustness\n\n\nhci\n\n\n\nAgent4Debate, a multi-agent framework, enhances LLMs’ debate capabilities, showing human-like performance in competitive debates.\n\n\n\nAug 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnJa: Ensemble Jailbreak on Large Language Models\n\n\n\nrobustness\n\n\nsecurity\n\n\nprompt-engineering\n\n\n\nEnJa: Hybrid Jailbreak Attack Outperforms Existing Methods on Aligned LLMs.\n\n\n\nAug 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring RAG-based Vulnerability Augmentation with LLMs\n\n\n\nrobustness\n\n\nprogramming\n\n\nsecurity\n\n\n\nTL;DR: LLM-based injection method enhances vulnerability detection, outperforming SOTA methods and reducing costs.\n\n\n\nAug 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases\n\n\n\nprogramming\n\n\n\nTL;DR: \frameworkImproves LLM-codebase interaction using graph databases, showing versatility in software engineering.\n\n\n\nAug 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems\n\n\n\nhci\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nSecure prompts boost LLM-robot integration, improving attack detection by 30.8%.\n\n\n\nAug 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPatchview: LLM-Powered Worldbuilding with Generative Dust and Magnet Visualization\n\n\n\nprompt-engineering\n\n\nrobustness\n\n\nhci\n\n\n\nPatchview: A Visual Tool for Customizing LLM-Generated Story Elements, Aiding Worldbuilding and Sensemaking.\n\n\n\nAug 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Words to Worth: Newborn Article Impact Prediction with LLM\n\n\n\nsocial-sciences\n\n\n\n[ABSTRACT] This study examines the relationship between social media use and well-being, finding that passive use is negatively associated with well-being, while active use…\n\n\n\nAug 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMaxMind: A Memory Loop Network to Enhance Software Productivity based on Large Language Models\n\n\n\nrobustness\n\n\nprogramming\n\n\n\nMaxMind model improves LLM systems for software tasks, boosting success rate and efficiency with memory recycling.\n\n\n\nAug 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDecoding Biases: Automated Methods and LLM Judges for Gender Bias Detection in Language Models\n\n\n\nsocial-sciences\n\n\nsecurity\n\n\n\nLLMs can generate biased, harmful text; this work trains models to create adversarial prompts and evaluates LLM-based bias metrics, aligning with human judgment.\n\n\n\nAug 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTestART: Improving LLM-based Unit Test via Co-evolution of Automated Generation and Repair Iteration\n\n\n\nrobustness\n\n\nprogramming\n\n\n\nTestART improves LLM-based unit test generation via co-evolution of automated generation and repair, achieving 78.55% pass rate and 90.96% line coverage.\n\n\n\nAug 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHarnessing the Power of LLMs in Source Code Vulnerability Detection\n\n\n\nrobustness\n\n\nprogramming\n\n\n\nLLMs analyze source code, converted to LLVM IR, to detect known vulnerabilities with high accuracy.\n\n\n\nAug 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan Rule-Based Insights Enhance LLMs for Radiology Report Classification? Introducing the RadPrompt Methodology\n\n\n\nsocial-sciences\n\n\nprompt-engineering\n\n\n\nRadPert & RadPrompt improve chest X-ray pathology detection, outperforming GPT-4 Turbo with fewer rules and multi-turn prompting.\n\n\n\nAug 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models for Base Station Siting: Intelligent Deployment based on Prompt or Agent\n\n\n\nhci\n\n\nprompt-engineering\n\n\n\nLLMs and autonomous agents revolutionize network optimization, improving BSS efficiency and reducing manual effort.\n\n\n\nAug 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeeManc at the PLABA Track of TAC-2023: Investigating LLMs and Controllable Attributes for Improving Biomedical Text Readability\n\n\n\nsocial-sciences\n\n\n\nTL;DR: BeeManc and Lay-SciFive rank 2nd and 3rd in PLABA2023 task, using T5-like models, BART-w-CTs, and ChatGPT-prompting.\n\n\n\nAug 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHuman Speech Perception in Noise: Can Large Language Models Paraphrase to Improve It?\n\n\n\nprompt-engineering\n\n\n\nLLMs struggle with acoustic intelligibility; a prompt-and-select approach improves speech perception in noise by 40%.\n\n\n\nAug 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Multimodal Emotional Support Conversation Systems\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nTL;DR: New dataset & framework improve AI’s empathetic emotional support in mental health care.\n\n\n\nAug 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSLIM-RAFT: A Novel Fine-Tuning Approach to Improve Cross-Linguistic Performance for Mercosur Common Nomenclature\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nThis study improves Portuguese NLP for specific domains like NCM, using a simplified RAFT technique and TeenyTineLLaMA, outperforming ChatGPT-4.\n\n\n\nAug 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRepoMasterEval: Evaluating Code Completion via Real-World Repositories\n\n\n\nrobustness\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\nRepoMasterEval: A novel benchmark for code completion models, tested on real-world Python and TypeScript repositories, aligns with practical scenarios and improves test…\n\n\n\nAug 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWalledEval: A Comprehensive Safety Evaluation Toolkit for Large Language Models\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nWalledEval: Open-source AI safety toolkit for LLMs, featuring 35+ benchmarks and custom mutators. Introduces WalledGuard and SGXSTest.\n\n\n\nAug 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nZero-Delay QKV Compression for Mitigating KV Cache and Network Bottlenecks in LLM Inference\n\n\n\nprompt-engineering\n\n\n\nZDC system reduces job completion time, improves throughput, and lowers perplexity in large-language models by embedding compression within model operations.\n\n\n\nAug 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLifelong Personalized Low-Rank Adaptation of Large Language Models for Recommendation\n\n\n\nrecommender\n\n\n\nRecLoRA improves LLM-based recommenders with personalized LoRA, adaptive history lengths, and efficient training strategy.\n\n\n\nAug 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDigital Avatars: Framework Development and Their Evaluation\n\n\n\neducation\n\n\nhci\n\n\nprompt-engineering\n\n\n\nNovel prompting strategy for AI avatars outperforms competitors in humor, authenticity, and favorability, even surpassing real-world counterparts like Trump and Biden.\n\n\n\nAug 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Logical Fallacy-Informed Framework for Argument Generation\n\n\n\nprompt-engineering\n\n\n\nFIPO framework reduces LLMs’ fallacy errors by 17.5%, improving argument generation quality.\n\n\n\nAug 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConditioning LLMs with Emotion in Neural Machine Translation\n\n\n\nsocial-sciences\n\n\n\nEmotion-infused prompts enhance translation quality in LLMs, especially with arousal emotion.\n\n\n\nAug 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLisbon Computational Linguists at SemEval-2024 Task 2: Using A Mistral 7B Model and Data Augmentation\n\n\n\nprogramming\n\n\n\nTL;DR: Mistral-7B model fine-tuned for NLI4CT task shows notable macro F1-score, but has faithfulness and consistency limitations.\n\n\n\nAug 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAccuracy and Consistency of LLMs in the Registered Dietitian Exam: The Impact of Prompt Engineering and Knowledge Retrieval\n\n\n\nsocial-sciences\n\n\neducation\n\n\nhci\n\n\n\nLLMs show promise in health apps, but evaluations in nutrition are limited. This study evaluates GPT-4o, Claude 3.5, and Gemini 1.5 Pro using RD exam questions, revealing…\n\n\n\nAug 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTargeted Visual Prompting for Medical Visual Question Answering\n\n\n\neducation\n\n\nhci\n\n\n\nTargeted visual prompting improves MLLMs’ region-based visual understanding in Med-VQA.\n\n\n\nAug 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSynthesizing Text-to-SQL Data from Weak and Strong LLMs\n\n\n\neducation\n\n\n\nSynthetic data approach bridges gap between open-source and closed-source LLMs in text-to-SQL tasks, introducing Sense, a specialized model with state-of-the-art results.\n\n\n\nAug 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating the Translation Performance of Large Language Models Based on Euas-20\n\n\n\nprogramming\n\n\n\nTL;DR: We introduce dataset Euas-20 to evaluate LLMs’ translation performance and abilities.\n\n\n\nAug 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutomated Defects Detection and Fix in Logging Statement\n\n\n\nrobustness\n\n\n\nLogFixer: Automated Framework for Detecting and Fixing Logging Defects, Achieving 61.49% Success Rate on New Projects.\n\n\n\nAug 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nULLME: A Unified Framework for Large Language Model Embeddings with Generation-Augmented Learning\n\n\n\nsocial-sciences\n\n\n\nULLME: Flexible framework for LLMs in text embedding, introduces GRL fine-tuning method, and offers pre-trained models.\n\n\n\nAug 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards an Analysis of Discourse and Interactional Pragmatic Reasoning Capabilities of Large Language Models\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\n[TEXT] The study examines the impact of climate change on the global economy, finding that it could lead to significant economic losses and increased inequality. [TL;DR]…\n\n\n\nAug 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-Aided Compilation for Tensor Accelerators\n\n\n\nrobustness\n\n\n\nTL;DR: GPT-4 can translate code for tensor accelerators, enabling agile hardware design.\n\n\n\nAug 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompromising Embodied Agents with Contextual Backdoor Attacks\n\n\n\nsocial-sciences\n\n\nrobustness\n\n\nhci\n\n\n\nContextual Backdoor Attack exploits LLMs, causing embodied agents to execute flawed programs when triggered, posing serious security risks.\n\n\n\nAug 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMs as Probabilistic Minimally Adequate Teachers for DFA Learning\n\n\n\neducation\n\n\nrobustness\n\n\n\nThis paper proposes methods to improve LLM-based automata learning, including Discrimination and Verification prompts, and a dynamic query cache refinement algorithm.\n\n\n\nAug 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExtend Model Merging from Fine-Tuned to Pre-Trained Large Language Models via Weight Disentanglement\n\n\n\neducation\n\n\n\nWIDEN method merges FT and PT LLMs, preserving diverse abilities, unlike existing methods.\n\n\n\nAug 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn the Generalization of Preference Learning with DPO\n\n\n\nsocial-sciences\n\n\n\nTL;DR: New framework analyzes preference-trained LLMs’ generalization, showing they can discern preferred responses on unseen data with high probability.\n\n\n\nAug 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons\n\n\n\neducation\n\n\nhci\n\n\n\nLLMs may not effectively recall factual knowledge for reasoning, often using shortcuts. Enhancing recall improves performance, while CoT prompting intensifies factual recall.\n\n\n\nAug 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHide and Seek: Fingerprinting Large Language Models with Evolutionary Learning\n\n\n\neducation\n\n\n\nNovel method uses LLMs to fingerprint and distinguish between other LLMs, achieving 72% accuracy.\n\n\n\nAug 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScaling Laws for Data Poisoning in LLMs\n\n\n\nrobustness\n\n\n\nLarger language models are more vulnerable to data poisoning, learning harmful behavior faster than smaller models. Safeguards are needed.\n\n\n\nAug 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKaPO: Knowledge-aware Preference Optimization for Controllable Knowledge Selection in Retrieval-Augmented Language Models\n\n\n\neducation\n\n\n\nKaPO improves LLMs’ knowledge selection, outperforming previous methods by 37% in handling knowledge conflicts, and showing robust generalization across datasets.\n\n\n\nAug 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhy Are My Prompts Leaked? Unraveling Prompt Extraction Threats in Customized Large Language Models\n\n\n\nsecurity\n\n\narchitectures\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nPrompt leakage in LLMs analyzed; defense strategies proposed, reducing extraction rates.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpecRover: Code Intent Extraction via LLMs\n\n\n\nprogramming\n\n\n\nSpecRover improves AutoCodeRover’s efficacy by 50% in resolving GitHub issues, emphasizing specification inference in automated program repair.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLong Input Benchmark for Russian Analysis\n\n\n\nproduction\n\n\n\nLIBRA: A Russian benchmark for evaluating LLMs’ long-text understanding, with 21 datasets and varying complexity levels.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs Large Language Model Good at Database Knob Tuning? A Comprehensive Experimental Evaluation\n\n\n\nprompt-engineering\n\n\n\n[TEXT] This study examines the impact of climate change on the global wine industry. It finds that rising temperatures and changing precipitation patterns are likely to have…\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet Me Speak Freely? A Study on the Impact of Format Restrictions on Performance of Large Language Models\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\neducation\n\n\nproduction\n\n\n\nFormat restrictions on LLMs negatively impact their reasoning abilities, with stricter formats causing greater decline.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn investigation on the use of Large Language Models for hyperparameter tuning in Evolutionary Algorithms\n\n\n\narchitectures\n\n\nproduction\n\n\n\nLLMs can optimize hyperparameters in Evolution Strategies, as shown in a preliminary study on step-size adaptation for (1+1)11(1+1)( 1 + 1 )-ES.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDanModCap: Designing a Danmaku Moderation Tool for Video-Sharing Platforms that Leverages Impact Captions\n\n\n\nhci\n\n\nsocial-sciences\n\n\nproduction\n\n\narchitectures\n\n\n\nDanModCap, a moderation tool using Impact Captions, reduces toxicity, promotes positivity, and encourages self-control in online video platform comments.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information\n\n\n\narchitectures\n\n\n\nLLMs can facilitate collaboration in complex games, but still lag behind RL models. They show Theory of Mind capabilities, improving performance against opposing agents.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeveraging the Power of LLMs: A Fine-Tuning Approach for High-Quality Aspect-Based Summarization\n\n\n\narchitectures\n\n\nproduction\n\n\n\nFine-tuning open-source LLMs improves aspect-based summarization, outperforming state-of-the-art methods.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Multi-Source Heterogeneous Knowledge Injected Prompt Learning Method for Legal Charge Prediction\n\n\n\nprompt-engineering\n\n\n\nThis method uses prompt learning with multi-source knowledge for legal charge prediction, achieving state-of-the-art results and strong interpretability.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nContext Conquers Parameters: Outperforming Proprietary LLM in Commit Message Generation\n\n\n\narchitectures\n\n\nprogramming\n\n\nrobustness\n\n\nproduction\n\n\n\nOpen-source LLM generates commit messages comparable to OMG, with OMEGA surpassing GPT-4 in practitioner preference.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Model Aided QoS Prediction for Service Recommendation\n\n\n\nrecommender\n\n\n\nLLMs aid web service recommendation, overcoming data sparsity in QoS prediction, outperforming baselines on the WSDream dataset.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM economicus? Mapping the Behavioral Biases of LLMs via Utility Theory\n\n\n\nsocial-sciences\n\n\n\nLLMs exhibit economic biases, neither fully human-like nor rational, and struggle with consistency. Utility theory helps evaluate and address these biases.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA First Look at License Compliance Capability of LLMs in Code Generation\n\n\n\nsecurity\n\n\narchitectures\n\n\nrobustness\n\n\nproduction\n\n\nprogramming\n\n\n\nLLMs can generate licensed code without proper attribution, risking IP violations. This study proposes a benchmark to evaluate LLMs’ license compliance, finding most…\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSEAS: Self-Evolving Adversarial Safety Optimization for Large Language Models\n\n\n\nsecurity\n\n\narchitectures\n\n\nrobustness\n\n\nproduction\n\n\n\nTL;DR: SEAS framework improves LLM security using self-generated data, reducing manual testing and enhancing safety.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDeveloping PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction\n\n\n\narchitectures\n\n\n\nNew semi-automated approach creates first Polish KBQA dataset, plus MRC and IR datasets, for low-resource languages.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn Evaluation of Requirements Modeling for Cyber-Physical Systems via LLMs\n\n\n\narchitectures\n\n\nrobustness\n\n\nproduction\n\n\n\nTL;DR: LLMs can aid CPSs requirements modeling, but struggle with specialized concepts and may hallucinate, improving in few-shot settings.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future\n\n\n\nsecurity\n\n\narchitectures\n\n\nrobustness\n\n\nhci\n\n\nproduction\n\n\nprogramming\n\n\neducation\n\n\n\nTL;DR: This survey explores LLMs and LLM-based agents in software engineering, discussing their applications, differences, and effectiveness in six key topics.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-Taught Evaluators\n\n\n\nproduction\n\n\n\nSelf-Taught Evaluator improves LLM performance without human annotations, outperforming GPT-4 and matching top reward models.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSceneMotifCoder: Example-driven Visual Program Learning for Generating 3D Object Arrangements\n\n\n\nprogramming\n\n\n\nSMC framework generates high-quality, text-aligned 3D object arrangements using meta-programs learned from few examples, outperforming current methods.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Generalist to Specialist: Exploring CWE-Specific Vulnerability Detection\n\n\n\nsecurity\n\n\narchitectures\n\n\nrobustness\n\n\n\nCWE-specific classifiers outperform single binary classifier for vulnerability detection, suggesting multiclass approach is more effective.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerative AI as a Service in 6G Edge-Cloud: Generation Task Offloading by In-context Learning\n\n\n\narchitectures\n\n\nproduction\n\n\n\nThis work explores edge-cloud deployment of foundation models in 6G networks, minimizing service delay via resource allocation and task offloading, using a novel in-context…\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodeACT: Code Adaptive Compute-efficient Tuning Framework for Code LLMs\n\n\n\nprogramming\n\n\n\nCodeACT improves open-source LLMs’ performance and efficiency by optimizing data selection and training, reducing computational requirements.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating the Performance of Large Language Models for SDG Mapping (Technical Report)\n\n\n\nprogramming\n\n\nsocial-sciences\n\n\n\nTL;DR: Open-source LLMs’ performance compared for SDG mapping task; LLaMA 2 and Gemma have room for improvement.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating Large Language Models for Automatic Register Transfer Logic Generation via High-Level Synthesis\n\n\n\nprogramming\n\n\n\nLLMs struggle with direct Verilog RTL generation. A two-stage pipeline (LLM-generated C++ to HLS-generated Verilog) improves functional correctness.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation\n\n\n\narchitectures\n\n\nproduction\n\n\n\nRAG Foundry is an open-source framework for creating and evaluating RAG systems, improving large language models with diverse RAG configurations.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan Reinforcement Learning Unlock the Hidden Dangers in Aligned Large Language Models?\n\n\n\nsecurity\n\n\narchitectures\n\n\nproduction\n\n\nprompt-engineering\n\n\n\nNew method jailbreaks LLMs using reinforcement learning, improving adversarial trigger transferability with limited model access.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOneLove beyond the field – A few-shot pipeline for topic and sentiment analysis during the FIFA World Cup in Qatar\n\n\n\nhci\n\n\nsocial-sciences\n\n\nproduction\n\n\n\nTwitter users’ sentiment shifted to neutrality after FIFA banned the OneLove armband, with discussions focusing on politics in sports.\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefining and Evaluating Decision and Composite Risk in Language Models Applied to Natural Language Inference\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nThis paper proposes a framework to measure and mitigate risks in LLMs like ChatGPT, arising from misplaced confidence, improving their performance.\n\n\n\nAug 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nARVO: Atlas of Reproducible Vulnerabilities for Open Source Software\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nARVO: A dataset of 5,000+ reproduced memory vulnerabilities in open-source software, automatically updatable, and valuable for security research.\n\n\n\nAug 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Feature-Based Approach to Generating Comprehensive End-to-End Tests\n\n\n\nrobustness\n\n\n\nAutoE2E: LLM-based tool for automated, feature-driven E2E web testing, outperforming baselines with 79% feature coverage.\n\n\n\nAug 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEffective Demonstration Annotation for In-Context Learning via Language Model-Based Determinantal Point Process\n\n\n\nprompt-engineering\n\n\n\nLM-DPP selects optimal examples for annotation, balancing uncertainty and diversity, improving LLMs’ few-shot learning.\n\n\n\nAug 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalyzing Cultural Representations of Emotions in LLMs through Mixed Emotion Survey\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLLMs’ emotional responses may not fully align with human cultural norms, with stronger alignment in East Asian languages than Western European languages.\n\n\n\nAug 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstructing Mechanical Design Agent Based on Large Language Models\n\n\n\nhci\n\n\neducation\n\n\n\nTL;DR: We propose a method to build a Mechanical Design Agent using LLMs, validated by experiments.\n\n\n\nAug 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFine-tuning multilingual language models in Twitter/X sentiment analysis: a study on Eastern-European V4 languages\n\n\n\nhci\n\n\n\nLLMs fine-tuned for ABSA in underrepresented languages can outperform universal models, offering cost-effective solutions. Fine-tuned LLMs (BERT, BERTweet, Llama2, Llama3…\n\n\n\nAug 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnleashing the Power of Data Tsunami: A Comprehensive Survey on Data Assessment and Selection for Instruction Tuning of Language Models\n\n\n\nsocial-sciences\n\n\neducation\n\n\n\nTL;DR: Review of data assessment and selection methods for instruction tuning of large language models.\n\n\n\nAug 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrustNavGPT: Modeling Uncertainty to Improve Trustworthiness of Audio-Guided LLM-Based Robot Navigation\n\n\n\nhci\n\n\nrobustness\n\n\n\nLLM-based agent, TrustNavGPT, uses affective cues in speech for trust assessment, improving robotic navigation and resisting adversarial attacks.\n\n\n\nAug 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResponsive ML inference in multi-tenanted environments using AQUA\n\n\n\nprompt-engineering\n\n\n\nTL;DR: Aqua improves LLM inference responsiveness by 4X and throughput by 6X, by offloading inference context between GPUs, reducing PCIe bandwidth limitations.\n\n\n\nAug 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn LLM-based Readability Measurement for Unit Tests’ Context-aware Inputs\n\n\n\nprompt-engineering\n\n\n\nAutomated tests score higher in readability than manual tests under C3 measurement, a new tool that checks test inputs’ consistency with source code contexts.\n\n\n\nJul 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChat-like Asserts Prediction with the Support of Large Language Model\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nTL;DR: CLAP, a novel LLM-based approach, generates meaningful Python assert statements, outperforming existing methods, and aids automated Python unit test generation.\n\n\n\nJul 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCost-Effective Hallucination Detection for LLMs\n\n\n\nrobustness\n\n\n\nLLMs can hallucinate. This work proposes a calibrated multi-scoring framework for hallucination detection, achieving top performance across various tasks and models.\n\n\n\nJul 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel Attribution in Machine-Generated Disinformation: A Domain Generalization Approach with Supervised Contrastive Learning\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nSupervised Contrastive Learning aids in model attribution for machine-generated disinformation, achieving state-of-the-art results across various prompting methods and…\n\n\n\nJul 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetaOpenFOAM: an LLM-based multi-agent framework for CFD\n\n\n\nhci\n\n\neducation\n\n\n\nMetaOpenFOAM automates CFD simulations via natural language, using multi-agent collaboration and RAG technology, achieving high pass rates at low costs.\n\n\n\nJul 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReplanVLM: Replanning Robotic Tasks with Visual Language Models\n\n\n\nsocial-sciences\n\n\n\nReplanVLM: A Robotic Task Planning Framework with Error Correction for Visual Language Models.\n\n\n\nJul 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond Silent Letters: Amplifying LLMs in Emotion Recognition with Vocal Nuances\n\n\n\nhci\n\n\n\nLLMs can detect emotions in speech via translated speech descriptions, improving accuracy, especially with high-quality audio.\n\n\n\nJul 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimpleLLM4AD: An End-to-End Vision-Language Model with Graph Visual Question Answering for Autonomous Driving\n\n\n\nhci\n\n\n\n[TEXT] This study examines the impact of climate change on the global wine industry. It finds that rising temperatures and changing precipitation patterns are likely to have…\n\n\n\nJul 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKemenkeuGPT: Leveraging a Large Language Model on Indonesia’s Government Financial Data and Regulations to Enhance Decision Making\n\n\n\nprompt-engineering\n\n\n\nLLMs, like KemenkeuGPT, can enhance financial decision-making in Indonesia’s public sector by improving data analysis and interpretation.\n\n\n\nJul 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-for-X: Application-agnostic Integration of Large Language Models to Support Personal Writing Workflows\n\n\n\neducation\n\n\n\nLLM-for-X: A system-wide tool that integrates LLM services into various applications for efficient assistance.\n\n\n\nJul 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCXSimulator: A User Behavior Simulation using LLM Embeddings for Web-Marketing Campaign Assessment\n\n\n\nhci\n\n\n\nCX Simulator predicts user reactions to web-marketing campaigns using LLM embeddings, eliminating the need for costly online testing.\n\n\n\nJul 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan LLMs Reason in Music? An Evaluation of LLMs’ Capability of Music Understanding and Generation\n\n\n\nhci\n\n\n\nLLMs struggle with multi-step music reasoning and complex tasks, requiring more focus on bridging music knowledge and reasoning.\n\n\n\nJul 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSynth-Empathy: Towards High-Quality Synthetic Empathy Data\n\n\n\nsocial-sciences\n\n\n\nSynth-Empathy: LLM-based pipeline generates high-quality empathetic data, improving response performance and achieving SoTA results.\n\n\n\nJul 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaying More Attention to Image: A Training-Free Method for Alleviating Hallucination in LVLMs\n\n\n\nsocial-sciences\n\n\nrobustness\n\n\n\nThis paper proposes a training-free algorithm to balance image and text comprehension in LVLMs, reducing hallucinatory outputs and text inertia.\n\n\n\nJul 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Performance Study of LLM-Generated Code on Leetcode\n\n\n\nprogramming\n\n\n\nTL;DR: LLMs generate code that is often more efficient than human-written code, despite model variations.\n\n\n\nJul 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefending Jailbreak Attack in VLMs via Cross-modality Information Detector\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nCIDER: A plug-and-play jailbreaking detector for VLMs, using cross-modal similarity to identify malicious image inputs, with high effectiveness and efficiency.\n\n\n\nJul 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards interfacing large language models with ASR systems using confidence measures and prompting\n\n\n\nprompt-engineering\n\n\n\nLLMs can enhance ASR systems by post-hoc correction, improving less competitive ASR systems with confidence-based filtering.\n\n\n\nJul 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShieldGemma: Generative AI Content Moderation Based on Gemma\n\n\n\nsecurity\n\n\n\nShieldGemma: LLM-based safety models outperform existing ones, improving content moderation for developers.\n\n\n\nJul 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Faithfulness of Large Language Models in Summarization via Sliding Generation and Self-Consistency\n\n\n\nrobustness\n\n\n\nSliSum improves LLM summarization faithfulness via sliding windows and self-consistency, without fine-tuning or extra resources.\n\n\n\nJul 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChat2Layout: Interactive 3D Furniture Layout with a Multimodal LLM\n\n\n\nhci\n\n\nprompt-engineering\n\n\n\nChat2Layout: Interactive furniture layout system using MLLMs, visual-text prompting, and an agent system for bidirectional interaction.\n\n\n\nJul 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTulip Agent – Enabling LLM-Based Agents to Solve Tasks Using Large Tool Libraries\n\n\n\nprompt-engineering\n\n\n\nTulip Agent: A new architecture for autonomous agents with a large tool library, reducing inference costs and enabling tool adaptation.\n\n\n\nJul 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearn by Selling: Equipping Large Language Models with Product Knowledge for Context-Driven Recommendations\n\n\n\nhci\n\n\nrecommender\n\n\n\nLLMs trained on synthetic queries can enhance product recommendations, but understanding inventory is crucial.\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Feature Importance to Natural Language Explanations Using LLMs with RAG\n\n\n\nsocial-sciences\n\n\n\nLLMs with external knowledge can explain model outputs in a conversational, human-like manner.\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMoFO: Momentum-Filtered Optimizer for Mitigating Forgetting in LLM Fine-Tuning\n\n\n\neducation\n\n\n\nTL;DR: MoFO fine-tunes LLMs without forgetting pre-training knowledge, no pre-training data needed.\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPruning Large Language Models with Semi-Structural Adaptive Sparse Training\n\n\n\nrobustness\n\n\n\nAST, a novel training pipeline, narrows the performance gap between dense and sparse models, compressing language models up to 16x with minimal loss.\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutomated Review Generation Method Based on Large Language Models\n\n\n\nrobustness\n\n\n\nTL;DR: Automated review generation using LLMs streamlines literature processing, providing accurate and quick insights with minimal hallucination risks.\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan LLMs be Fooled? Investigating Vulnerabilities in LLMs\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nLLMs in NLP have vulnerabilities; this study explores model, training, and inference-time weaknesses and suggests mitigation strategies for more secure models.\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrompting Encoder Models for Zero-Shot Classification: A Cross-Domain Study in Italian\n\n\n\nprompt-engineering\n\n\n\nSmaller, domain-specific Italian LMs improve performance in legal/bureaucratic tasks, even with limited resources, offering new insights for specialized contexts.\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMimicking the Mavens: Agent-based Opinion Synthesis and Emotion Prediction for Social Media Influencers\n\n\n\nhci\n\n\nsocial-sciences\n\n\nrobustness\n\n\n\nThis study presents a framework for predicting influencers’ views and public sentiment on social media, using an automated 5W1H module and opinion leader agents, with the…\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdapting Safe-for-Work Classifier for Malaysian Language Text: Enhancing Alignment in LLM-Ops Framework\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nNovel safe-for-work text classifier for Malaysian language content, using state-of-the-art NLP techniques, publicly released for responsible LLM-Ops.\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Agricultural Machinery Management through Advanced LLM Integration\n\n\n\nhci\n\n\neducation\n\n\nprompt-engineering\n\n\n\nAI-driven farming (CIAMM) using GPT-4 and prompt engineering boosts efficiency and sustainability, outperforming other methods.\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssessing Programming Task Difficulty for Efficient Evaluation of Large Language Models\n\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\nHardEval framework assesses task difficulty for LLMs, identifying hard tasks in code generation benchmarks and generating new ones. It can improve LLM evaluations and be…\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDecomposed Prompting to Answer Questions on a Course Discussion Board\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nSystem uses LLM to classify student questions, achieving 81% accuracy, and employs different answering strategies for each type.\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestionnaires for Everyone: Streamlining Cross-Cultural Questionnaire Adaptation with GPT-Based Translation Quality Evaluation\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nTool expedites questionnaire translation with AI, yielding quality similar to conventional methods, promoting equitable research.\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCLR-Fact: Evaluating the Complex Logical Reasoning Capability of Large Language Models over Factual Knowledge\n\n\n\neducation\n\n\n\nLLMs excel in general knowledge reasoning but struggle with domain-specific knowledge. Chain-of-Thought demonstrations improve performance, but set intersections pose…\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSSPA: Split-and-Synthesize Prompting with Gated Alignments for Multi-Label Image Recognition\n\n\n\nprompt-engineering\n\n\n\nSSPA framework enhances multi-label image recognition, leveraging LLMs and bidirectional visual-linguistic interactions, achieving state-of-the-art results.\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBreaking Agents: Compromising Autonomous LLM Agents Through Malfunction Amplification\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nTL;DR: New attack method can mislead LLM agents, causing up to 80% failure rates, posing significant risks that are hard to detect.\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCocobo: Exploring Large Language Models as the Engine for End-User Robot Programming\n\n\n\nhci\n\n\nprogramming\n\n\neducation\n\n\nprompt-engineering\n\n\n\nCocobo: A natural language programming system for robots, powered by LLMs, accessible even to non-coders.\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFine-Tuned Large Language Model for Visualization System: A Study on Self-Regulated Learning in Education\n\n\n\nhci\n\n\neducation\n\n\nprompt-engineering\n\n\n\nTailor-Mind: LLM-enhanced visualization system for self-regulated AI learning, improving beginners’ experience.\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparison of Large Language Models for Generating Contextually Relevant Questions\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLMs, like GPT-3.5 and Llama 2-Chat 13B, excel at generating clear, relevant, and aligned questions for educational use.\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Measure the Intelligence of Large Language Models?\n\n\n\nhci\n\n\nsocial-sciences\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\n[TEXT] This study examines the impact of climate change on the global wine industry. It finds that rising temperatures and changing precipitation patterns are likely to have…\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPyramid Coder: Hierarchical Code Generator for Compositional Visual Question Answering\n\n\n\nprogramming\n\n\neducation\n\n\n\nPyramidCoder: A Prompting Framework for Programmatic VQA Models Improves Accuracy on GQA, VQAv2, and NLVR2 Datasets.\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThinkRepair: Self-Directed Automated Program Repair\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nThinkRepair, a self-directed LLM-based APR, outperforms SOTA APRs in fixing bugs, improving baselines by 27%-344.4% on Defects4J V1.2 and fixing 12-65 more bugs on Defects4J…\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare\n\n\n\neducation\n\n\n\nTL;DR: Diverse, well-distributed datasets can optimize LLM performance, enabling smaller models to achieve high scores.\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMMTrail: A Multimodal Trailer Video Dataset with Language and Music Descriptions\n\n\n\nsocial-sciences\n\n\n\nMMTrail: Large-scale video-language dataset with diverse topics, custom music, and multimodal captions for improved cross-modality studies.\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI-Assisted Generation of Difficult Math Questions\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nThis paper introduces MATH\\(^2\\), a dataset of diverse, challenging math questions generated by combining LLMs with human-in-the-loop approach, leveraging LLM metacognition…\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Code Translation in Language Models with Few-Shot Learning via Retrieval-Augmented Generation\n\n\n\nprogramming\n\n\n\n[TEXT] Abstract: This paper explores the relationship between social media use and mental health in adolescents. Results indicate a significant correlation between excessive…\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen to Stop? Towards Efficient Code Generation in LLMs with Excess Token Prevention\n\n\n\nprogramming\n\n\nrobustness\n\n\narchitectures\n\n\nproduction\n\n\n\nCodeFast accelerates Code LLMs in code generation, improving speed up to 452% without compromising quality.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Large Language Models to generate Easy to Read content\n\n\n\narchitectures\n\n\nsocial-sciences\n\n\n\nThis study explores AI and NLP for simplifying Spanish texts into Easy to Read formats, contributing a parallel corpus and testing a Llama2 model.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOrca: Ocean Significant Wave Height Estimation with Spatio-temporally Aware Large Language Models\n\n\n\nproduction\n\n\n\nOrca framework improves SWH estimation with limited data using spatiotemporal aware encoding and LLMs, outperforming existing methods in the Gulf of Mexico.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPreliminary WMT24 Ranking of General MT Systems and LLMs\n\n\n\narchitectures\n\n\n\n[TEXT] Abstract: This paper explores the role of social media in shaping public opinion during the 2016 U.S. Presidential Election. We analyze a dataset of 171 million…\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeaLLMs 3: Open Foundation and Chat Multilingual Large Language Models for Southeast Asian Languages\n\n\n\nsocial-sciences\n\n\nrobustness\n\n\n\nSeaLLMs 3: Cost-effective, versatile model for Southeast Asian languages, prioritizing safety and inclusivity.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSentiment Analysis of Lithuanian Online Reviews Using Large Language Models\n\n\n\narchitectures\n\n\nsocial-sciences\n\n\n\nThis work explores transformer models for Lithuanian sentiment analysis, achieving high accuracy and outperforming GPT-4.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerating Unseen Code Tests In Infinitum\n\n\n\nprogramming\n\n\n\nNew method generates benchmark variations for LLMs, mitigating leaking into training data, with auto-regression for Python text-to-code generation.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQAEA-DR: A Unified Text Augmentation Framework for Dense Retrieval\n\n\n\nprompt-engineering\n\n\n\nQAEA-DR: Novel text augmentation for dense retrieval, improving query-text matching without altering embedding or retrieval methods.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhysics of Language Models: Part 2.1, Grade-School Math and the Hidden Reasoning Process\n\n\n\nhci\n\n\nsocial-sciences\n\n\neducation\n\n\n\nThis paper explores how language models solve math problems, revealing hidden mechanisms and insights into their reasoning capabilities.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenetic Instruct: Scaling up Synthetic Generation of Coding Instructions for Large Language Models\n\n\n\nprogramming\n\n\n\nTL;DR: Genetic-Instruct improves code generation accuracy by synthesizing instruction samples for LLMs.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEfficient Training of Large Language Models on Distributed Infrastructures: A Survey\n\n\n\nprogramming\n\n\narchitectures\n\n\nproduction\n\n\neducation\n\n\n\nTL;DR: Survey explores advancements in training systems for LLMs, including infrastructure, parallelism, optimizations, and reliability, with a focus on optical computing.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrLLM: Relational Table Learning with LLMs\n\n\n\nproduction\n\n\narchitectures\n\n\n\nrLLM: A PyTorch library for Relational Table Learning with LLMs.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo LLMs Really Adapt to Domains? An Ontology Learning Perspective\n\n\n\narchitectures\n\n\n\nLLMs struggle with domain-specific reasoning but improve with fine-tuning for lexical semantic tasks.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan Editing LLMs Inject Harm?\n\n\n\nproduction\n\n\nrobustness\n\n\narchitectures\n\n\nsecurity\n\n\n\nEditing attacks can inject misinformation and bias into LLMs, posing safety threats and impacting overall fairness.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nByteCheckpoint: A Unified Checkpointing System for LLM Development\n\n\n\narchitectures\n\n\nrobustness\n\n\nproduction\n\n\n\nByteCheckpoint system speeds up LLM checkpointing, reducing saving (up to 529x) and loading (up to 3.51x) times, with automatic online resharding support.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpecify and Edit: Overcoming Ambiguity in Text-Based Image Editing\n\n\n\nproduction\n\n\narchitectures\n\n\n\nSANE improves diffusion-based editing with LLM-derived instructions, enhancing interpretability and diversity.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOptiMUS-0.3: Using Large Language Models to Model and Solve Optimization Problems at Scale\n\n\n\nprogramming\n\n\n\n[TEXT] Abstract: This study examines the impact of social media on the mental health of adolescents. Results indicate a significant correlation between excessive social…\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTime series forecasting with high stakes: A field study of the air cargo industry\n\n\n\nproduction\n\n\n\nThis paper improves air cargo demand forecasting using a mixture of expert models, outperforming industry benchmarks and aiding strategic decisions.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating Large Language Models for automatic analysis of teacher simulations\n\n\n\nhci\n\n\nsocial-sciences\n\n\neducation\n\n\n\nLLMs like Llama 3 outperform DeBERTaV3 in identifying new characteristics in DS for teacher education, offering stable performance and automatic evaluation.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConcise Thoughts: Impact of Output Length on LLM Reasoning and Cost\n\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\n[TEXT] Abstract: This paper examines the role of social media in shaping public opinion during the 2016 U.S. Presidential Election. We find that social media platforms…\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMindSearch: Mimicking Human Minds Elicits Deep AI Searcher\n\n\n\narchitectures\n\n\nproduction\n\n\n\nMindSearch: LLM-based framework for efficient web information seeking and integration, outperforming human effort and existing AI search engines.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSmart Language Agents in Real-World Planning\n\n\n\nprompt-engineering\n\n\n\nTL;DR: Human-in-the-loop prompt refinement boosts LLM travel planning by 139%.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeaching LLMs at Charles University: Assignments and Activities\n\n\n\neducation\n\n\n\nNew course on LLMs offers assignments, quizzes, and research activities.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLanguage-Conditioned Offline RL for Multi-Robot Navigation\n\n\n\nproduction\n\n\narchitectures\n\n\n\nThis method trains multi-robot navigation policies using LLMs and offline reinforcement learning, requiring minimal data and no simulators, with successful real-world…\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare\n\n\n\neducation\n\n\n\nSmaller models can perform well with diverse, high-quality datasets, improving medical LLM performance.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGender, Race, and Intersectional Bias in Resume Screening via Language Model Retrieval\n\n\n\nsocial-sciences\n\n\n\nLLMs used in resume screening favor White and female names, disadvantaging Black males, reflecting real-world biases.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutoScale: Automatic Prediction of Compute-optimal Data Composition for Training LLMs\n\n\n\narchitectures\n\n\nproduction\n\n\n\nAutoScale optimizes data composition for LLM pretraining, improving performance and reducing training time.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning\n\n\n\nproduction\n\n\narchitectures\n\n\nhci\n\n\n\nThis paper proposes a new approach for chart question answering using multimodal large language models, focusing on data quality and alignment with chart characteristics.…\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDetecting and Understanding Vulnerabilities in Language Models via Mechanistic Interpretability\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nTL;DR: We propose a method using Mechanistic Interpretability to locate and understand vulnerabilities in LLMs like GPT-2, improving their robustness against adversarial…\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparative Analysis of Encoder-Based NER and Large Language Models for Skill Extraction from Russian Job Vacancies\n\n\n\nsocial-sciences\n\n\n\nTraditional NER models, like DeepPavlov RuBERT, outperform LLMs in extracting skills from Russian job vacancies, aiding job seekers and employers.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat if Red Can Talk? Dynamic Dialogue Generation Using Large Language Models\n\n\n\nhci\n\n\neducation\n\n\n\nLLMs generate dynamic, contextual character dialogues in RPGs, enhancing player immersion but with room for improvement in subtle personality traits.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMs’ Understanding of Natural Language Revealed\n\n\n\neducation\n\n\n\nLLMs excel in text generation but struggle with language understanding, relying on memorization rather than true comprehension.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating LLMs for Text-to-SQL Generation With Complex SQL Workload\n\n\n\nprompt-engineering\n\n\n\nTL;DR: TPC-DS SQL benchmark is more complex than BIRD and Spider. Current AI models struggle to generate accurate queries.\n\n\n\nJul 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMotamot: A Dataset for Revealing the Supremacy of Large Language Models over Transformer Models in Bengali Political Sentiment Analysis\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nBanglaBERT excels in political sentiment analysis, but Gemini 1.5 Pro outperforms with 96.33% accuracy using few-shot learning.\n\n\n\nJul 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdaCoder: Adaptive Prompt Compression for Programmatic Visual Question Answering\n\n\n\nprogramming\n\n\neducation\n\n\nprompt-engineering\n\n\n\nAdaCoder: Adaptive prompt compression for visual programmatic models, reducing token length by 71.1% without compromising performance.\n\n\n\nJul 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Generic Review of Integrating Artificial Intelligence in Cognitive Behavioral Therapy\n\n\n\nsocial-sciences\n\n\neducation\n\n\n\nAI in CBT: Potential to enhance, automate, and personalize mental health interventions, but further research needed for long-term efficacy.\n\n\n\nJul 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Emerged Security and Privacy of LLM Agent: A Survey with Case Studies\n\n\n\nsecurity\n\n\n\nTL;DR: This survey explores security and privacy issues in LLM agents, discussing threats, impacts, defenses, and future trends.\n\n\n\nJul 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentity-Driven Hierarchical Role-Playing Agents\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\nhci\n\n\n\nHIRPF balances flexibility and precision in role-playing using identity theory, outperforming traditional LLM methods in social simulation.\n\n\n\nJul 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMeta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge\n\n\n\nsocial-sciences\n\n\n\nLLMs can self-improve by judging their own judgments, enhancing their instruction-following abilities without human supervision.\n\n\n\nJul 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnabling Uniform Computer Interaction Experience for Blind Users through Large Language Models\n\n\n\nprompt-engineering\n\n\n\nSavant: A language model tool improving blind users’ screen reader efficiency and usability.\n\n\n\nJul 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImpact of Decoding Methods on Human Alignment of Conversational LLMs\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nTL;DR: Decoding methods impact LLM-human conversation alignment. Fewer beams, lower P-values improve alignment, but results vary by conversation type.\n\n\n\nJul 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemantic Communication Enhanced by Knowledge Graph Representation Learning\n\n\n\nhci\n\n\n\nSemantic communications use graphs and LLMs for compact knowledge representation, achieving high compression rates in communication.\n\n\n\nJul 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPEFT-U: Parameter-Efficient Fine-Tuning for User Personalization\n\n\n\nsocial-sciences\n\n\nhci\n\n\nrecommender\n\n\n\nTL;DR: Introducing PEFT-U Benchmark for personalizing LLMs, addressing the need for user-specific preferences in diverse tasks.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Model Performance: Another Approach to Vision-Language Instruction Tuning\n\n\n\nhci\n\n\n\nTL;DR: Bottleneck Adapter enhances multimodal LLMs, outperforming human-level and LaVIN-7B performance with 90.12% accuracy.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGermanPartiesQA: Benchmarking Commercial Large Language Models for Political Bias and Sycophancy\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\neducation\n\n\nhci\n\n\n\nLLMs show left-green bias, can be ideologically steered with political personas, but changes in output are more like personalization than sycophancy.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinancial Statement Analysis with Large Language Models\n\n\n\nsocial-sciences\n\n\n\nLLM (GPT4) outperforms human analysts in financial statement analysis and predicting earnings changes, offering valuable insights for decision-making.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPenHeal: A Two-Stage LLM Framework for Automated Pentesting and Optimal Remediation\n\n\n\nprompt-engineering\n\n\nrobustness\n\n\neducation\n\n\nsecurity\n\n\n\nPenHeal: LLM-based framework automates vulnerability detection, boosts coverage by 31%, effectiveness by 32%, and cuts costs by 46%.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Scaling Trends in LLM Robustness\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nLarger language models improve with adversarial training, but not without explicit defenses.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre Large Language Models Possible to Conduct Cognitive Behavioral Therapy?\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\nhci\n\n\neducation\n\n\n\nLLMs show potential for CBT, offering new therapy possibilities, but require integration with CBT knowledge bases for optimal results.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKeep the Cost Down: A Review on Methods to Optimize LLM’ s KV-Cache Consumption\n\n\n\nhci\n\n\n\nKV-Cache optimizes LLMs like ChatGPT for long-text handling, improving efficiency from quadratic to linear time complexity, but with increased GPU memory overhead.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBehavioral Testing: Can Large Language Models Implicitly Resolve Ambiguous Entities?\n\n\n\nprompt-engineering\n\n\nrobustness\n\n\n\nLLMs struggle with entity type ambiguity, often failing to consistently apply their factual knowledge, leading to self-inconsistency and biases.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExamining the Influence of Political Bias on Large Language Model Performance in Stance Classification\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLLMs show bias in stance classification, performing better on certain political stances, with accuracy decreasing when target ambiguity rises.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSAFETY-J: Evaluating Safety with Critique\n\n\n\nsecurity\n\n\n\nSafety-J: A bilingual LLM evaluator for nuanced, critique-based safety assessments.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVery Large-Scale Multi-Agent Simulation in AgentScope\n\n\n\nsocial-sciences\n\n\n\nTL;DR: AgentScope enhancements improve scalability, efficiency, and diversity in large-scale multi-agent simulations.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Power of Combining Data and Knowledge: GPT-4o is an Effective Interpreter of Machine Learning Models in Predicting Lymph Node Metastasis of Lung Cancer\n\n\n\nprogramming\n\n\n\nChatGPT can extract info from radiology reports, rivaling traditional systems; prior medical knowledge can enhance some extraction tasks but may worsen others.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Agent Learning through World Dynamics Modeling\n\n\n\nsocial-sciences\n\n\neducation\n\n\n\nLLMs guided by DiVE make better decisions, matching human rewards in the Crafter environment.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDemystifying Verbatim Memorization in Large Language Models\n\n\n\nrobustness\n\n\n\nLLMs memorize verbatim with legal/privacy implications; controlled study shows repetition, later checkpoints, and distributed model states aid memorization. Unlearning…\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAudio Entailment: Assessing Deductive Reasoning for Audio Understanding\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nALMs struggle with logical reasoning; new task Audio Entailment proposed to evaluate and improve this ability.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Geometry of Queries: Query-Based Innovations in Retrieval-Augmented Generation\n\n\n\nsocial-sciences\n\n\nhci\n\n\nrobustness\n\n\n\nQB-RAG improves healthcare chatbot accuracy by pre-computing queries, enhancing retrieval, and aligning user questions with reliable content.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs the Digital Forensics and Incident Response Pipeline Ready for Text-Based Threats in LLM Era?\n\n\n\nsocial-sciences\n\n\nsecurity\n\n\n\nTL;DR: NTGs pose new cybersecurity challenges in DFIR, including detecting and attributing authorship. Current methodologies show vulnerabilities, necessitating more…\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRecursive Introspection: Teaching Language Model Agents How to Self-Improve\n\n\n\nprompt-engineering\n\n\n\nRISE enables LLMs to improve math reasoning with more turns, outperforming single-turn strategies and scaling well with model capability.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Dark Side of Function Calling: Pathways to Jailbreaking Large Language Models\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nJailbreak function attack exploits LLMs’ function calling, succeeding 90% of the time; defense strategies proposed.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTwIPS: A Large Language Model Powered Texting Application to Simplify Conversational Nuances for Autistic Users\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\nhci\n\n\neducation\n\n\n\nTwIPS app aids autistic users in text-based communication, offering tone interpretation, message preview, and phrasing suggestions.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC2P: Featuring Large Language Models with Causal Reasoning\n\n\n\nprompt-engineering\n\n\n\nC2P framework boosts LLMs’ causal reasoning, improving accuracy by over 33% in real-world scenarios with few-shot learning.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3D Question Answering for City Scene Understanding\n\n\n\neducation\n\n\n\nCity-3DQA dataset and Sg-CityU method introduced for city-level 3D MQA, achieving SOTA performance.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBoosting Large Language Models with Socratic Method for Conversational Mathematics Teaching\n\n\n\nprompt-engineering\n\n\neducation\n\n\nhci\n\n\n\nSocraticLLM improves math teaching via conversation, outperforming other models.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIgnitionInnovators at Discharge Me!: Chain-of-Thought Instruction Finetuning Large Language Models for Discharge Summaries\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nThis paper proposes an LLM-based framework for generating discharge summary sections, improving clinical information accuracy with structured prompts and CoT questions.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBLAZE: Cross-Language and Cross-Project Bug Localization via Dynamic Chunking and Hard Example Learning\n\n\n\nrobustness\n\n\n\nBLAZE, a GPT-based approach, improves bug localization with dynamic chunking and hard example learning, outperforming six baselines on three benchmark datasets.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAMONGAGENTS: Evaluating Large Language Models in the Interactive Text-Based Social Deduction Game\n\n\n\nhci\n\n\n\nLLMs can grasp game rules and make decisions in AmongAgents, a text-based game mirroring Among Us, for studying simulated human behavior.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan Language Models Evaluate Human Written Text? Case Study on Korean Student Writing for Education\n\n\n\nsocial-sciences\n\n\neducation\n\n\n\nLLMs can reliably assess grammar and fluency in human-written text, but struggle with other criteria and types of writing.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScholarChemQA: Unveiling the Power of Language Models in Chemical Research Question Answering\n\n\n\neducation\n\n\n\nScholarChemQA: New Chemistry QA Dataset & QAMatch Model for Improved Performance\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRevisiting Who’s Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective\n\n\n\nsecurity\n\n\n\nTL;DR: This paper improves the Who’s Harry Potter method for targeted unlearning in language models, achieving competitive performance.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMathViz-E: A Case-study in Domain-Specialized Tool-Using Agents\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nTL;DR: We present a math visualizer system, tackling domain-specific challenges and open-sourcing datasets and code.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan Watermarking Large Language Models Prevent Copyrighted Text Generation and Hide Training Data?\n\n\n\nrobustness\n\n\n\nWatermarking LLMs reduces copyrighted content generation but complicates detecting copyrighted text in pretraining datasets.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReinforced Prompt Personalization for Recommendation with Large Language Models\n\n\n\nprompt-engineering\n\n\nrecommender\n\n\n\nRPP/RPP+ optimizes prompt patterns for individual users in recommendation tasks, outperforming traditional methods.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArtificial Agency and Large Language Models\n\n\n\nhci\n\n\n\nLLMs are not agents yet, but their elements suggest a path forward. Combining specific architectures and modules could realize artificial agency.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Voter-Based Stochastic Rejection-Method Framework for Asymptotically Safe Language Model Outputs\n\n\n\nsecurity\n\n\n\nTL;DR: New method uses LLM checkers to vote and regenerate outputs, optimizing cost and failure rate.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTesting Large Language Models on Driving Theory Knowledge and Skills for Connected Autonomous Vehicles\n\n\n\neducation\n\n\n\nTL;DR: GPT-4 excels in driving theory tests for autonomous vehicles, but costs 50x more than GPT-3.5, which fails the test.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy Ontologist: Evaluating BFO-Based AI for Definition Support\n\n\n\nhci\n\n\neducation\n\n\n\nLLMs, like GPT-4, can aid ontology development but face challenges in adhering to top-level standards.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCovScore: Evaluation of Multi-Document Abstractive Title Set Generation\n\n\n\nsocial-sciences\n\n\n\nCovScore: Automatic method for evaluating title sets, tested on Holocaust testimonies, simplifies and expedites manual evaluation.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Transfer Unlearning: Empirical Evidence of Cross-Domain Bias Mitigation\n\n\n\nrobustness\n\n\n\nUnlearning approach to debiasing in LLMs by minimizing hate speech, showing cross-domain transfer unlearning benefits.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow Good (Or Bad) Are LLMs at Detecting Misleading Visualizations?\n\n\n\nprompt-engineering\n\n\neducation\n\n\nrobustness\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLLMs can detect misleading charts, aiding in data interpretation and combating misinformation.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWildHallucinations: Evaluating Long-form Factuality in LLMs with Real-World Entity Queries\n\n\n\nrobustness\n\n\n\nLLMs hallucinate more on entities without Wikipedia pages and vary by domain; retrieval component slightly reduces hallucinations.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-Generated Tips Rival Expert-Created Tips in Helping Students Answer Quantum-Computing Questions\n\n\n\nprompt-engineering\n\n\nrobustness\n\n\neducation\n\n\nsocial-sciences\n\n\n\nLLM-generated tips can be as useful as expert-created tips for teaching quantum computing, potentially reducing teachers’ workloads.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSDoH-GPT: Using Large Language Models to Extract Social Determinants of Health (SDoH)\n\n\n\nsocial-sciences\n\n\n\nSDoH-GPT: A few-shot LLM method for SDoH extraction, reducing time and cost by 10-20x, with high accuracy and consistency.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI Could’ve Asked That: Reformulating Unanswerable Questions\n\n\n\neducation\n\n\n\nLLMs struggle to reformulate unanswerable questions; benchmark shows GPT-4 and Llama2-7B succeed only 26% and 12% of the time, respectively.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Sands to Mansions: Enabling Automatic Full-Life-Cycle Cyberattack Construction with LLM\n\n\n\nsecurity\n\n\n\nAurora: Automatic Framework for Efficient, Full-Life-Cycle Cyberattack Emulation\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop Game Applications\n\n\n\nprompt-engineering\n\n\nhci\n\n\n\nThis paper explores integrating LLM-driven agents in tabletop games to enhance SUI interaction tasks, using the AI-Gadget Kit for personalized and dynamic experiences.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models for Anomaly Detection in Computational Workflows: from Supervised Fine-Tuning to In-Context Learning\n\n\n\nprompt-engineering\n\n\nrobustness\n\n\nsecurity\n\n\n\nLLMs can detect workflow anomalies via supervised fine-tuning and in-context learning, offering promising results for system reliability and security.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvolutionary Prompt Design for LLM-Based Post-ASR Error Correction\n\n\n\nprompt-engineering\n\n\n\nEvolutionary prompt optimization improves post-ASR error correction in LLMs, as shown in CHiME-4 subset of SLT 2024 GenSEC challenge.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTAMIGO: Empowering Teaching Assistants using LLM-assisted viva and code assessment in an Advanced Computing Class\n\n\n\nprogramming\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLMs aid TAs in assessing viva and code, offering constructive feedback, but may hallucinate and require alignment with rubrics.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShared Imagination: LLMs Hallucinate Alike\n\n\n\nrobustness\n\n\neducation\n\n\n\nLLMs share a shared imagination space, answering imaginary questions with success, suggesting model homogeneity and computational creativity.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan Large Language Models Automatically Jailbreak GPT-4V?\n\n\n\nprompt-engineering\n\n\nrobustness\n\n\nsecurity\n\n\n\nAutoJailbreak, a novel technique, uses LLMs for red-teaming and in-context learning, achieving a 95.3% Attack Success Rate, highlighting GPT-4V security concerns.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Translation Hallucination Detection for Low and High Resource Languages using Large Language Models\n\n\n\nrobustness\n\n\n\nLLMs, like Llama3-70B and Claude Sonnet, improve hallucination detection in MT, but performance varies between HRLs and LRLs.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPatched RTC: evaluating LLMs for diverse software development tasks\n\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\nPatched RTC: A self-evaluating framework for LLMs in software tasks, correlating with task accuracy and distinguishing model performance.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemantic Change Characterization with LLMs using Rhetorics\n\n\n\nhci\n\n\n\nLLMs effectively capture and analyze semantic changes, improving computational linguistics.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEducating LLMs like Human Students: Structure-aware Injection of Domain Knowledge\n\n\n\nprogramming\n\n\n\nStructTuning: New method efficiently transforms LLMs into domain specialists using 0.3% of traditional training data, achieving 50% performance.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVidyaRANG: Conversational Learning Based Platform powered by Large Language Model\n\n\n\neducation\n\n\n\nPlatform uses LLMs, knowledge-augmented retrieval for personalized, confidential learning; covers software dev, product mgmt, cloud computing, security, and mobile app.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing LLM’s Cognition via Structurization\n\n\n\nprogramming\n\n\nrobustness\n\n\n\nThis paper improves language models’ cognition by structuring context, boosting performance in NLP tasks.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCourse-Correction: Safety Alignment Using Synthetic Preferences\n\n\n\nrobustness\n\n\neducation\n\n\n\nTL;DR: This paper improves LLMs’ course-correction skills, reducing harmful content and jailbreak attacks, using a synthetic dataset and preference learning.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Automatic Cryptographic API Misuse Detection in the Era of LLMs\n\n\n\nrobustness\n\n\n\nLLMs can detect cryptographic misuses, but struggle with false positives. Constrained scope and self-correction improve reliability, leading to a 90% detection rate and…\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent\n\n\n\nprogramming\n\n\nrobustness\n\n\nsecurity\n\n\n\nRedAgent system improves jailbreak attack efficiency on LLMs like GPT-4, discovering 60 vulnerabilities in real-world applications.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOriGen:Enhancing RTL Code Generation with Code-to-Code Augmentation and Self-Reflection\n\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\nOriGen, an open-source LLM, outperforms others in RTL code generation and self-reflection, surpassing GPT-4 in error rectification.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIDA: Breaking Barriers in No-code UI Automation Through Large Language Models and Human-Centric Design\n\n\n\nprogramming\n\n\n\nIDA: A no-code Web UI automation tool for business users, leveraging LLMs, designed for simplicity and human-centric programming.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDDK: Distilling Domain Knowledge for Efficient Large Language Models\n\n\n\neducation\n\n\n\nDDK framework dynamically adjusts distillation dataset, improving student LLM performance, outperforming existing methods.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo LLMs Know When to NOT Answer? Investigating Abstention Abilities of Large Language Models\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nStrategic prompting, like Chain-of-Thought, enhances abstention ability in LLMs, improving overall QA task performance.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrimeGuard: Safe and Helpful LLMs through Tuning-Free Routing\n\n\n\nrobustness\n\n\n\nPrimeGuard improves LM safety without compromising helpfulness, outperforming baselines and reducing attack success rate.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Leverage Personal Textual Knowledge for Personalized Conversational Information Retrieval\n\n\n\nrecommender\n\n\n\nLLM helps PTKB generate better personalized queries for CIR, improving search results with high-quality guidance.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparison of Static Application Security Testing Tools and Large Language Models for Repo-level Vulnerability Detection\n\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\nSAST tools have low detection rates but fewer false positives, while LLMs detect more vulnerabilities but have high false positives. Combining both can improve results.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPsychomatics – A Multidisciplinary Framework for Understanding Artificial Minds\n\n\n\nhci\n\n\neducation\n\n\n\nPsychomatics: A Framework Comparing LLMs and Human Cognition, Highlighting Differences and Potential for AI Development.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpenDevin: An Open Platform for AI Software Developers as Generalist Agents\n\n\n\nprogramming\n\n\n\nOpenDevin: A platform for developing AI agents that write code, use command lines, and browse the web, with 15+ benchmark tasks.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLanguage models are robotic planners: reframing plans as goal refinement graphs\n\n\n\nhci\n\n\n\nLLMs can generate more correct robotic plans using goal modeling techniques from software engineering.\n\n\n\nJul 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWalking in Others’ Shoes: How Perspective-Taking Guides Large Language Models in Reducing Toxicity and Bias\n\n\n\nhci\n\n\n\nPeT strategy reduces toxicity (89%) and bias (73%) in LLMs by inspiring self-regulation, outperforming baselines.\n\n\n\nJul 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo Large Language Models Have Compositional Ability? An Investigation into Limitations and Scalability\n\n\n\nhci\n\n\n\nLLMs struggle with complex composite tasks, despite decent performance on simpler ones. Model scaling doesn’t always improve performance.\n\n\n\nJul 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKnowledge Mechanisms in Large Language Models: A Survey and Perspective\n\n\n\nhci\n\n\n\nExploring knowledge mechanisms in LLMs, including utilization, evolution, and potential dark knowledge, to advance trustworthy AGI.\n\n\n\nJul 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOdyssey: Empowering Agents with Open-World Skills\n\n\n\nhci\n\n\n\nODYSSEY framework empowers LLM-based agents with open-world skills for Minecraft exploration, offering a new benchmark for evaluating agent planning and exploration…\n\n\n\nJul 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBIGbench: A Unified Benchmark for Social Bias in Text-to-Image Generative Models Based on Multi-modal LLM\n\n\n\nhci\n\n\n\nBIGbench: A Unified Benchmark for Biases in Image Generation, Evaluating Four Dimensions of Bias in T2I Models.\n\n\n\nJul 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSynCPKL: Harnessing LLMs to Generate Synthetic Data for Commonsense Persona Knowledge Linking\n\n\n\nhci\n\n\n\nSynCPKL Pipeline generates synthetic data for training commonsense persona knowledge linkers, improving F1 score by 16% in CPKL challenge.\n\n\n\nJul 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoDefeater: Using LLMs To Find Defeaters in Assurance Cases\n\n\n\nprogramming\n\n\n\nLLMs can automatically find defeaters to improve safety assurance cases, as shown in two system tests.\n\n\n\nJul 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCOMCAT: Leveraging Human Judgment to Improve Automatic Documentation and Summarization\n\n\n\nprogramming\n\n\n\nComCat automates comment generation for code, improving comprehension by up to 12% and offering accurate, readable comments preferred over ChatGPT-generated ones.\n\n\n\nJul 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStuGPTViz: A Visual Analytics Approach to Understand Student-ChatGPT Interactions\n\n\n\nprogramming\n\n\n\nTL;DR: Study analyzes student-ChatGPT interactions in a course, creating a system (StuGPTViz) to track and compare conversation patterns, providing pedagogical insights.\n\n\n\nJul 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRevisiting the Impact of Pursuing Modularity for Code Generation\n\n\n\nprogramming\n\n\n\nTL;DR: Modularity doesn’t significantly improve code generation models’ performance.\n\n\n\nJul 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGPT Assisted Annotation of Rhetorical and Linguistic Features for Interpretable Propaganda Technique Detection in News Text\n\n\n\nprogramming\n\n\n\nStudy combines human annotation with GPT-3.5 for cost-effective, interpretable propaganda detection, introducing a new feature set and tool, RhetAnn.\n\n\n\nJul 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuilding AI Agents for Autonomous Clouds: Challenges and Design Principles\n\n\n\nprogramming\n\n\n\nAIOps framework proposed for autonomous, self-healing clouds, reducing human intervention in IT operations.\n\n\n\nJul 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond Correctness: Benchmarking Multi-dimensional Code Generation for Large Language Models\n\n\n\nprogramming\n\n\n\nTL;DR: RACE benchmark evaluates LLMs’ code quality across 4 dimensions: Readability, Maintainability, Correctness, and Efficiency. Current LLMs fall short in generating…\n\n\n\nJul 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVGBench: Evaluating Large Language Models on Vector Graphics Understanding and Generation\n\n\n\nproduction\n\n\nhci\n\n\narchitectures\n\n\nprompt-engineering\n\n\neducation\n\n\n\nTL;DR: VGBench evaluates LLMs on vector graphics, showing strong performance in understanding and generation, but weaker in low-level formats like SVG.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinDKG: Dynamic Knowledge Graphs with Large Language Models for Detecting Global Trends in Financial Markets\n\n\n\nproduction\n\n\n\nLLMs generate dynamic knowledge graphs for strategic thematic investing, outperforming existing ETFs.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmpowering LLMs for Verilog Generation through Multi-Level Summarization\n\n\n\nrobustness\n\n\nprogramming\n\n\neducation\n\n\n\nLLMs struggle with Verilog generation due to data scarcity. CodeV, an instruction-tuned LLM, surpasses previous SOTA in Verilog generation by summarizing existing code.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMMM: Multilingual Mutual Reinforcement Effect Mix Datasets & Test with Open-domain Information Extraction Large Language Models\n\n\n\nproduction\n\n\narchitectures\n\n\n\nNew multilingual dataset (MMM) for MRE research, aided by LLMs, boosts global exploration and enhances Open-domain Information Extraction Large Language Model (OIELLM)…\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCLAVE: An Adaptive Framework for Evaluating Values of LLM Generated Responses\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\n\nCLAVE framework uses dual-model approach for adaptable, generalizable LLM value evaluation, benchmarked on ValEval dataset.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpider2-V: How Far Are Multimodal Agents From Automating Data Science and Engineering Workflows?\n\n\n\nproduction\n\n\narchitectures\n\n\n\nTL;DR: Spider2-V benchmark evaluates multimodal agents for data workflow automation, revealing current limitations.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHey, That’s My Model! Introducing Chain & Hash, An LLM Fingerprinting Technique\n\n\n\nsecurity\n\n\nproduction\n\n\nrobustness\n\n\narchitectures\n\n\n\nChain & Hash: A Cryptographic Approach for Fingerprinting LLMs, Ensuring Robustness and Unforgeability.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM Circuit Analyses Are Consistent Across Training and Scale\n\n\n\nproduction\n\n\n\nCircuit analyses on small models can still apply after more pre-training and across model scale.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMix-CPT: A Domain Adaptation Framework via Decoupling Knowledge Learning and Format Alignment\n\n\n\nproduction\n\n\narchitectures\n\n\n\nMix-CPT: New framework for domain adaptation of LLMs, improving task-solving capabilities in target and general domains.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn Empirical Study of Validating Synthetic Data for Formula Generation\n\n\n\narchitectures\n\n\n\nValidation of synthetic NL formulas boosts LLM performance, enabling models to tackle more complex problems.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraphEval: A Knowledge-Graph Based LLM Hallucination Evaluation Framework\n\n\n\nrobustness\n\n\n\nGraphEval: A KG-based framework for evaluating, detecting, and correcting LLM hallucinations, improving accuracy and providing explainable decisions.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBy My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting\n\n\n\nprompt-engineering\n\n\n\nVisual prompts with MLLMs improve sensor data accuracy by 10% and reduce token costs by 15.8× imes×, outperforming text-based prompts.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSLIP: Securing LLMs IP Using Weights Decomposition\n\n\n\nsecurity\n\n\nproduction\n\n\nrobustness\n\n\narchitectures\n\n\n\nSLIP: A Hybrid Inference Algorithm Protecting LLMs on Edge Devices with Zero Accuracy Loss.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArena Learning: Build Data Flywheel for LLMs Post-training via Simulated Chatbot Arena\n\n\n\nsocial-sciences\n\n\neducation\n\n\n\nArena Learning simulates AI battles for LLMs, improving performance via fine-tuning and reinforcement learning, as seen in WizardLM-ββ’s success.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Retrieval and Managing Retrieval: A Four-Module Synergy for Improved Quality and Efficiency in RAG Systems\n\n\n\narchitectures\n\n\n\nRAG techniques improve LLM responses. Four proposed modules enhance query rewriting, filter irrelevant knowledge, and optimize retrieval, improving response quality and…\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCutting Through the Clutter: The Potential of LLMs for Efficient Filtration in Systematic Literature Reviews\n\n\n\nsocial-sciences\n\n\nrobustness\n\n\n\nLLMs like GPT-4o can significantly speed up literature filtering for reviews, reducing manual screening time from weeks to minutes, while maintaining high recall rates.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Model-based FMRI Encoding of Language Functions for Subjects with Neurocognitive Disorder\n\n\n\nsocial-sciences\n\n\n\nLLM-based fMRI encoding shows higher cognitive abilities linked to better brain scores in older NCD adults, with peak correlations in the middle temporal gyrus.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeveraging LLM-Respondents for Item Evaluation: a Psychometric Analysis\n\n\n\neducation\n\n\narchitectures\n\n\n\nLLMs can resemble college students’ ability in College Algebra, with ensemble LLMs better mimicking human respondents. LLM-calibrated item parameters correlate highly with…\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIDEAL: Leveraging Infinite and Dynamic Characterizations of Large Language Models for Query-focused Summarization\n\n\n\nprogramming\n\n\n\nLLMs-based QFS models: Proposed modules for lengthy summarization and efficient query alignment, with promising results.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond Generative Artificial Intelligence: Roadmap for Natural Language Generation\n\n\n\nsocial-sciences\n\n\nprogramming\n\n\n\nTL;DR: This paper reviews recent NLG surveys to identify gaps in LLMs and suggest future research directions.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFoundational Autoraters: Taming Large Language Models for Better Automatic Evaluation\n\n\n\nsocial-sciences\n\n\nproduction\n\n\narchitectures\n\n\n\nFLAMe, a family of LLM autoraters, outperforms proprietary models like GPT-4 and Claude-3, offering better generalization and less bias in evaluating LLM output.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodebook LLMs: Adapting Political Science Codebooks for LLM Use and Adapting LLMs to Follow Codebooks\n\n\n\narchitectures\n\n\n\nLLMs struggle with codebook constraints; rewriting codebooks and instruction-tuning improve performance.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Medication Recommendation with LLM Text Representation\n\n\n\nrecommender\n\n\n\nThis method enhances medication recommendation by utilizing LLM text representation from unstructured data, improving performance in base models.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetaLLM: A High-performant and Cost-efficient Dynamic Framework for Wrapping LLMs\n\n\n\nproduction\n\n\narchitectures\n\n\n\nMetaLLM dynamically routes queries to optimal LLMs for classification tasks, improving accuracy and cost-effectiveness.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCIBench: Evaluating Your LLMs with a Code Interpreter Plugin\n\n\n\nsocial-sciences\n\n\nprogramming\n\n\neducation\n\n\n\nCIBench evaluates LLMs’ code interpreter use for data science, with/without human help, offering insights for future LLM development.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFast Matrix Multiplications for Lookup Table-Quantized LLMs\n\n\n\nproduction\n\n\narchitectures\n\n\n\nFLUTE accelerates LUT-quantized LLMs inference, offering 2-4× imes× speedup over GEMM kernels and 1.5-2× imes× end-to-end throughput increase for LLaMA3 quantization.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSibyl: Simple yet Effective Agent Framework for Complex Real-world Reasoning\n\n\n\narchitectures\n\n\n\nSibyl: A novel LLM-based agent framework for complex reasoning, outperforming existing agents and achieving state-of-the-art results on the GAIA benchmark.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGRUtopia: Dream General Robots in a City at Scale\n\n\n\neducation\n\n\n\nGRUtopia: Simulated 3D society for diverse robot learning, featuring interactive scenes, social scenarios, and benchmarks.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQ-Sparse: All Large Language Models can be Fully Sparsely-Activated\n\n\n\nproduction\n\n\narchitectures\n\n\n\nQ-Sparse trains sparse LLMs with top-K sparsification, offering efficiency gains in inference and comparable results to dense models.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNTSEBENCH: Cognitive Reasoning Benchmark for Vision Language Models\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nTL;DR: New dataset, NTSEBench, tests LLMs and VLMs on complex cognitive reasoning tasks, featuring 2,728 multiple-choice questions with 4,642 images.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore Non-Determinism\n\n\n\nrobustness\n\n\n\nGreedy decoding outperforms sampling in LLMs, with smaller models potentially matching larger ones. Non-determinism is crucial in LLM evaluations.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDOCBENCH: A Benchmark for Evaluating LLM-based Document Reading Systems\n\n\n\narchitectures\n\n\n\nTL;DR: DocBench is a new benchmark for evaluating LLM-based document reading systems, featuring 229 real documents and 1,102 questions across five domains.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultilingual Contrastive Decoding via Language-Agnostic Layers Skipping\n\n\n\nsocial-sciences\n\n\nprompt-engineering\n\n\nrobustness\n\n\narchitectures\n\n\n\nSkipLayerCD improves LLM’s reasoning in 11 languages by skipping bottom layers, addressing language mismatch in contrastive decoding.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTransforming Agency. On the mode of existence of Large Language Models\n\n\n\neducation\n\n\nsocial-sciences\n\n\nhci\n\n\nrobustness\n\n\n\nLLMs like ChatGPT are not autonomous agents, but linguistic automatons that transform human agency through textual and computational embodiment.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoviCode: Generating Programs from Natural Language Utterances by Novices\n\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\nTL;DR: NoviCode, a new task, challenges models to generate complex code from non-technical descriptions, outperforming end-to-end Text-to-Code approaches.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn Actionable Framework for Assessing Bias and Fairness in Large Language Model Use Cases\n\n\n\nsocial-sciences\n\n\nproduction\n\n\narchitectures\n\n\n\nTL;DR: This paper offers a decision framework to assess bias and fairness risks in LLM use cases, introducing new metrics and considering both prompt-risk and model-risk.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeveraging Hybrid Intelligence Towards Sustainable and Energy-Efficient Machine Learning\n\n\n\neducation\n\n\n\nHybrid Intelligence improves ML efficiency with human and LLM input, focusing on energy-aware development.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding the Importance of Evolutionary Search in Automated Heuristic Design with Large Language Models\n\n\n\narchitectures\n\n\n\nLLMs improve automated heuristic design, but need better integration with search strategies. Large-scale benchmark results are shared for future research.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLook Within, Why LLMs Hallucinate: A Causal Perspective\n\n\n\nrobustness\n\n\n\nDisabling certain self-attention layers in LLMs can reduce hallucination issues, offering a new approach to understanding and mitigating this problem.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistillSeq: A Framework for Safety Alignment Testing in Large Language Models using Knowledge Distillation\n\n\n\nsecurity\n\n\neducation\n\n\nprogramming\n\n\nrobustness\n\n\n\nTL;DR: DistillSeq improves testing efficiency, boosting attack success rates by 93% on average across four LLMs.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Makes and Breaks Safety Fine-tuning? Mechanistic Study\n\n\n\nsecurity\n\n\n\nSafety fine-tuning minimally alters LLM weights, clustering inputs as safe or unsafe, potentially misclassifying adversarial inputs.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRevolutionizing Bridge Operation and maintenance with LLM-based Agents: An Overview of Applications and Insights\n\n\n\nsocial-sciences\n\n\n\nAI agents revolutionize bridge O&M, offering challenges and opportunities for core tasks.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTokenSHAP: Interpreting Large Language Models with Monte Carlo Shapley Value Estimation\n\n\n\nprompt-engineering\n\n\n\nTokenSHAP interprets LLMs by attributing importance to individual tokens, enhancing model transparency and reliability.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearning to Refuse: Towards Mitigating Privacy Risks in LLMs\n\n\n\nrobustness\n\n\n\nRETURN dataset and NAUF framework help LLMs unlearn personal data, preserving privacy without retraining.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFollow the Rules: Reasoning for Video Anomaly Detection with Large Language Models\n\n\n\nrobustness\n\n\n\nAnomalyRuler: Rule-based Reasoning Framework for Video Anomaly Detection with LLMs.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLAB-Bench: Measuring Capabilities of Language Models for Biology Research\n\n\n\nsocial-sciences\n\n\n\nLAB-Bench evaluates AI on practical biology research tasks, aiming to assist scientists in literature search and molecular cloning.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBiasAlert: A Plug-and-play Tool for Social Bias Detection in LLMs\n\n\n\nsocial-sciences\n\n\n\nBiasAlert: A tool for detecting and evaluating social biases in LLM-generated text, outperforming existing methods and GPT-4.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKey-Point-Driven Mathematical Reasoning Distillation of Large Language Model\n\n\n\nrobustness\n\n\neducation\n\n\nprompt-engineering\n\n\n\nTL;DR: KPDD method improves SLMs’ mathematical reasoning, reducing errors and enhancing deployment.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChatLogic: Integrating Logic Programming with Large Language Models for Multi-Step Reasoning\n\n\n\nhci\n\n\nprogramming\n\n\neducation\n\n\nprompt-engineering\n\n\n\nChatLogic enhances LLMs’ multi-step reasoning with logic programming, improving performance in deductive tasks.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAll Roads Lead to Rome: Unveiling the Trajectory of Recommender Systems Across the LLM Era\n\n\n\nrecommender\n\n\n\nLLMs redefine recommender systems, improving effectiveness and reducing user cost, with focus on list-wise and conversational recommendations.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-Granularity Semantic Revision for Large Language Model Distillation\n\n\n\nrobustness\n\n\neducation\n\n\n\nTL;DR: We propose a multi-granularity semantic revision method for LLM distillation, improving existing methods and reducing errors.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemantic Understanding and Data Imputation using Large Language Model to Accelerate Recommendation System\n\n\n\nrecommender\n\n\n\nTL;DR: We use fine-tuned LLMs to impute missing data, improving recommendation system performance.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPractical Unlearning for Large Language Models\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nTL;DR: O3 framework offers practical LLM unlearning, handling continuous requests with minimal utility loss, and no retained data, outperforming existing methods.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenSco: Can Question Decomposition based Passage Alignment improve Question Answering?\n\n\n\neducation\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nTL;DR: GenSco selects passages for multi-hop QA, improving LLM answer generation and efficiency.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeveraging LLMs to Predict Affective States via Smartphone Sensor Features\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs can predict affect outcomes using smartphone data, offering a new approach for digital mental health monitoring.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIncorporating Large Language Models into Production Systems for Enhanced Task Automation and Flexibility\n\n\n\neducation\n\n\n\nThis paper presents a novel approach to integrate LLMs into automated production systems, enhancing task automation and flexibility.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating Large Language Models with Grid-Based Game Competitions: An Extensible LLM Benchmark and Leaderboard\n\n\n\nhci\n\n\neducation\n\n\nprompt-engineering\n\n\n\nThis study introduces a benchmark for LLMs using grid-based games, revealing variations in performance across different games and prompt types.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrefCLM: Enhancing Preference-based Reinforcement Learning with Crowdsourced Large Language Models\n\n\n\nsocial-sciences\n\n\nhci\n\n\neducation\n\n\nprompt-engineering\n\n\n\nPrefCLM uses crowdsourced LLMs for preference-based robot learning, improving user satisfaction in HRI scenarios.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConverging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents\n\n\n\nhci\n\n\neducation\n\n\n\nRecent AI advancements, like LLMs, blend connectionist and symbolic AI, enhancing reasoning and decision-making in Autonomous Agents.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn the attribution of confidence to large language models\n\n\n\nrobustness\n\n\n\nLLM credence attributions may be literal, plausible, but subject to skeptical concerns due to potentially non-truth-tracking experimental techniques.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(β\\)-DPO: Direct Preference Optimization with Dynamic \\(β\\)\n\n\n\nsocial-sciences\n\n\n\nDPO for LLMs improves with dynamic \\(\beta\\) calibration, enhancing performance and robustness.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn the Universal Truthfulness Hyperplane Inside LLMs\n\n\n\nrobustness\n\n\n\nTL;DR: A universal truthfulness hyperplane may exist in LLMs, improving factual accuracy across diverse datasets.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Taxonomy for Data Contamination in Large Language Models\n\n\n\nrobustness\n\n\n\nContamination in pretraining data can inflate language model performance; understanding its impact on tasks like summarization and question answering is crucial.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInvestigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024\n\n\n\nhci\n\n\n\nLLMs can predict political stances with 82% accuracy; expert-curated info boosts performance by 9%.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkywork-Math: Data Scaling Laws for Mathematical Reasoning in Large Language Models – The Story Goes On\n\n\n\neducation\n\n\n\nTL;DR: Skywork-Math model outperforms early GPT-4 on math tasks, highlighting data scaling’s impact on LLMs’ math reasoning abilities.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTactics, Techniques, and Procedures (TTPs) in Interpreted Malware: A Zero-Shot Generation with Large Language Models\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nGenTTP: AI-Powered Tool Extracts Tactics of Interpreted OSS Malware with High Accuracy.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGLBench: A Comprehensive Benchmark for Graph with Large Language Models\n\n\n\nhci\n\n\n\nTL;DR: GLBench evaluates GraphLLM methods, showing they outperform traditional baselines, but lack scaling laws and require both structure and semantics for zero-shot…\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\neyeballvul: a future-proof benchmark for vulnerability detection in the wild\n\n\n\nsecurity\n\n\nrobustness\n\n\n\n[TEXT] This study examines the impact of social media on the mental health of adolescents. Results indicate a significant correlation between excessive social media use and…\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMAVIS: Mathematical Visual Instruction Tuning\n\n\n\nhci\n\n\neducation\n\n\nprompt-engineering\n\n\n\nMAVIS: New Paradigm for MLLMs Improves Math Problem-Solving in Visual Contexts\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRB-SQL: A Retrieval-based LLM Framework for Text-to-SQL\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nRB-SQL improves text-to-SQL tasks with a retrieval-based framework for in-context prompt engineering, outperforming baselines on BIRD and Spider datasets.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRoboMorph: Evolving Robot Morphology using Large Language Models\n\n\n\nprompt-engineering\n\n\n\nRoboMorph: LLMs & evolutionary algorithms for optimizing modular robot designs.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs Your Model Really A Good Math Reasoner? Evaluating Mathematical Reasoning with Checklist\n\n\n\neducation\n\n\n\nLLMs’ math abilities are best tested with diverse tasks, not just problem-solving. MathCheck, a checklist tool, evaluates LLMs’ mathematical reasoning and robustness.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLynx: An Open Source Hallucination Evaluation Model\n\n\n\nrobustness\n\n\n\nLynx, a new hallucination detection model, outperforms others on the HaluBench benchmark, addressing LLM hallucinations.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective\n\n\n\nprogramming\n\n\n\nMLLMs and data co-development: larger, better data improves MLLMs, which in turn aid data development. [Link to project]\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDIDUP: Dynamic Iterative Development for UI Prototyping\n\n\n\nhci\n\n\nprogramming\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nTL;DR: DIDUP improves LLM-generated code-prototyping with adaptive planning, code injection, and lightweight state management for better UI prototyping.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUncertainty Estimation of Large Language Models in Medical Question Answering\n\n\n\nrobustness\n\n\n\nLLMs in healthcare risk hallucination; current uncertainty estimation methods perform poorly. Proposed Two-phase Verification method improves accuracy and reliability…\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpeculative RAG: Enhancing Retrieval Augmented Generation through Drafting\n\n\n\neducation\n\n\n\nSpeculative RAG improves RAG performance by using a smaller LM for drafting and a larger LM for verification, reducing latency and enhancing accuracy.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn the (In)Security of LLM App Stores\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nStudy reveals security risks in LLM apps, including misleading descriptions, privacy violations, harmful content, and malware potential.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal-Time Anomaly Detection and Reactive Planning with Large Language Models\n\n\n\nsecurity\n\n\n\nThis work presents a two-stage framework for fast anomaly detection and safe control in robotic systems using language models, improving trustworthiness under resource and…\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Career Interests of Large Language Models\n\n\n\nsocial-sciences\n\n\nhci\n\n\neducation\n\n\n\nLLMs show social, artistic career interests, differing from high-competence areas, suggesting human-like tendencies and potential workforce roles.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTurn-Level Empathy Prediction Using Psychological Indicators\n\n\n\nsocial-sciences\n\n\n\nLLM-enhanced DeBERTA model improves empathy detection, ranking 7th in CONV-turn track.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel Tells You Where to Merge: Adaptive KV Cache Merging for LLMs on Long-Context Tasks\n\n\n\nrobustness\n\n\n\nKVMerger: A novel KV cache merging approach for efficient LLM serving, reducing memory usage without significant performance loss.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre Large Language Models Really Bias-Free? Jailbreak Prompts for Assessing Adversarial Robustness to Bias Elicitation\n\n\n\nsecurity\n\n\nsocial-sciences\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nLLMs, despite advancements, still exhibit biases from training data, impacting fairness and reliability. Prompt engineering can reveal hidden biases, emphasizing the need…\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVox Populi, Vox AI? Using Language Models to Estimate German Public Opinion\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs, like GPT-3.5, inaccurately predict German vote choice, favoring Green and Left parties, and missing individual voter factors.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFlooding Spread of Manipulated Knowledge in LLM-Based Multi-Agent Communities\n\n\n\nsecurity\n\n\nhci\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nLLM-based multi-agent systems are vulnerable to manipulated knowledge spread, posing security risks.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nControllable Navigation Instruction Generation with Chain of Thought Prompting\n\n\n\nprogramming\n\n\neducation\n\n\nprompt-engineering\n\n\n\nC-Instructor: LLM-based model for controllable, landmark-focused instruction generation with spatial understanding, outperforming previous methods.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFsPONER: Few-shot Prompt Optimization for Named Entity Recognition in Domain-specific Scenarios\n\n\n\nprompt-engineering\n\n\n\nLLM-based FsPONER outperforms fine-tuned models by 10% in F1 score for domain-specific NER tasks with data scarcity.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReview-LLM: Harnessing Large Language Models for Personalized Review Generation\n\n\n\nrecommender\n\n\nprompt-engineering\n\n\n\nReview-LLM customizes LLMs for personalized review generation, improving performance by incorporating user behavior, ratings, and SFT.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCHOP: Integrating ChatGPT into EFL Oral Presentation Practice\n\n\n\nsocial-sciences\n\n\nhci\n\n\neducation\n\n\n\nChatGPT-based platform, CHOP, assists EFL students’ oral presentations with personalized feedback, offering strengths and areas for improvement.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProbability of Differentiation Reveals Brittleness of Homogeneity Bias in Large Language Models\n\n\n\nsocial-sciences\n\n\n\nLLMs’ homogeneity bias varies greatly with situation cues and prompts, suggesting encoder models may have introduced biases.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey of Attacks on Large Vision-Language Models: Resources, Advances, and Future Trends\n\n\n\nsecurity\n\n\n\nTL;DR: This paper reviews various attacks on Large Vision-Language Models, discussing their development and future research directions.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFACTS About Building Retrieval Augmented Generation-based Chatbots\n\n\n\nhci\n\n\n\nThis paper presents a framework (FACTS) for building secure, effective enterprise chatbots using RAG, with empirical results on LLM performance tradeoffs.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultilingual Blending: LLM Safety Alignment Evaluation with Language Mixture\n\n\n\nsecurity\n\n\nprompt-engineering\n\n\n\nTL;DR: Multilingual queries can bypass LLM safety measures, highlighting the need for multilingual safety alignment strategies.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRAG vs. Long Context: Examining Frontier Large Language Models for Environmental Review Document Comprehension\n\n\n\neducation\n\n\n\nLLMs struggle with niche domains like NEPA; RAG models outperform long context models in answering accuracy.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan ChatGPT Pass a Theory of Computing Course?\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nChatGPT struggles with complex math, but can pass a ToC course, excelling in simple questions but faltering in open-ended responses like proofs.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAttribute or Abstain: Large Language Models as Long Document Assistants\n\n\n\nrobustness\n\n\n\nLLMs can improve long document work, but hallucinate. Attribution boosts trust; new benchmark LAB evaluates attribution in long documents, finding citation-based approach…\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Robust Alignment of Language Models: Distributionally Robustifying Direct Preference Optimization\n\n\n\nsocial-sciences\n\n\n\nThis study improves Direct Preference Optimization (DPO) for LLMs using Distributionally Robust Optimization (DRO), introducing Dr. DPO for better handling of noisy training…\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Comprehensive Survey on the Security of Smart Grid: Challenges, Mitigations, and Future Research Opportunities\n\n\n\nsecurity\n\n\n\nReview of smart grid security, focusing on attack vectors, coordinated attacks, and innovative defense strategies, including machine learning and future research directions.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRectifier: Code Translation with Corrector via LLMs\n\n\n\nprogramming\n\n\nrobustness\n\n\n\nTL;DR: Rectifier model repairs errors in code translation by LLMs, improving accuracy and robustness.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Proposed S.C.O.R.E. Evaluation Framework for Large Language Models : Safety, Consensus, Objectivity, Reproducibility and Explainability\n\n\n\nsocial-sciences\n\n\n\nProposed S.C.O.R.E. framework for evaluating LLMs in healthcare: Safety, Consensus, Objectivity, Reproducibility, and Explainability.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWorldAPIs: The World Is Worth How Many APIs? A Thought Experiment\n\n\n\nhci\n\n\n\nTL;DR: This paper proposes a framework to define APIs for versatile AI agents using wikiHow tutorials, inducing 300+ APIs for physical tasks.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNatural Language Mechanisms via Self-Resolution with Foundation Models\n\n\n\nsocial-sciences\n\n\n\nLMMs use natural language reports and LLMs to improve information aggregation, outperforming traditional mechanisms like prediction markets.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArabic Automatic Story Generation with Large Language Models\n\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\nThis work generates Arabic stories from LLMs, using MT and GPT-4 data, achieving coherent results in MSA and Arabic dialects.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn LLM Wizards: Identifying Large Language Models’ Behaviors for Wizard of Oz Experiments\n\n\n\nhci\n\n\n\nTL;DR: This study explores using large language models as Wizards in WoZ experiments, providing methodology and evaluation for their role-playing ability.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVirtual Agents for Alcohol Use Counseling: Exploring LLM-Powered Motivational Interviewing\n\n\n\nhci\n\n\nprompt-engineering\n\n\n\nLLMs enable a virtual counselor for alcohol use, replicating human empathy and adaptability in motivational interviewing.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nICLGuard: Controlling In-Context Learning Behavior for Applicability Authorization\n\n\n\nsecurity\n\n\n\nICLGuard controls ICL behavior in LLMs, allowing model owners to regulate ICL on specific data without affecting the model’s overall functionality.\n\n\n\nJul 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDivine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models\n\n\n\nhci\n\n\n\nLLMs exhibit biases in emotion attribution along religious lines, with major religions in the US and Europe being more nuanced, while Eastern religions are stereotyped and…\n\n\n\nJul 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrompting Techniques for Secure Code Generation: A Systematic Investigation\n\n\n\nsecurity\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\nTL;DR: Study explores prompting techniques for secure code generation in LLMs, finding improvements with Recursive Criticism and Improvement (RCI).\n\n\n\nJul 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSafe-Embed: Unveiling the Safety-Critical Knowledge of Sentence Encoders\n\n\n\nsecurity\n\n\nprompt-engineering\n\n\n\nLLMs vulnerable to unsafe prompts; sentence encoders proposed as robust safety detectors. Code: https://github.com/JwdanielJung/Safe-Embed.\n\n\n\nJul 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Large Language Models for Generating Smart Contracts for Health Insurance from Textual Policies\n\n\n\nprogramming\n\n\n\nLLMs can generate smart contracts from health insurance policies, but human oversight is needed for complex scenarios.\n\n\n\nJul 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChatGPT Doesn’t Trust Chargers Fans: Guardrail Sensitivity in Context\n\n\n\nhci\n\n\n\nGuardrails in GPT-3.5 show biases, favoring refusal for younger, female, and Asian-American personas, and aligning with inferred political ideologies, including sports…\n\n\n\nJul 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models\n\n\n\nprompt-engineering\n\n\n\nHypothetical Minds agent, leveraging LLMs, improves MARL performance in diverse domains, highlighting the value of hypothesis evaluation and refinement.\n\n\n\nJul 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRichelieu: Self-Evolving LLM-Based Agents for AI Diplomacy\n\n\n\nhci\n\n\n\nAI explores its potential for complex diplomacy tasks, combining strategic planning, social reasoning, and self-play for memory augmentation.\n\n\n\nJul 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConvNLP: Image-based AI Text Detection\n\n\n\nprogramming\n\n\n\nLLM-generated text detection using visual word embeddings and ZigZag ResNet improves generalization, with 88.35% detection rate and 2.5ms inference latency.\n\n\n\nJul 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFine-grained large-scale content recommendations for MSX sellers\n\n\n\nrecommender\n\n\n\nThis paper presents a content recommendation model for Microsoft sellers, using semantic matching to suggest relevant content for opportunities, achieving high accuracy in…\n\n\n\nJul 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOptimal Decision Making Through Scenario Simulations Using Large Language Models\n\n\n\nhci\n\n\n\nLLMs can now solve complex problems by requesting options, simulating outcomes, and optimizing solutions, enhancing their real-world utility.\n\n\n\nJul 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Pretrained Large Language Model with Prompt Engineering to Answer Biomedical Questions\n\n\n\nprompt-engineering\n\n\n\nTeam built a biomedical QA system using LLMs, achieving notable scores in BioASQ 2024 Task 12b.\n\n\n\nJul 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\nproduction\n\n\nsecurity\n\n\n\nLLMs can be misled by false premises, causing factuality hallucination. We introduce an automated pipeline to create a large-scale benchmark for this issue.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerative Debunking of Climate Misinformation\n\n\n\nsocial-sciences\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLMs can automatically debunk climate myths using the truth sandwich structure, with GPT-4 and Mixtral showing promising results.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs GPT-4 Alone Sufficient for Automated Essay Scoring?: A Comparative Judgment Approach Based on Rater Cognition\n\n\n\nsocial-sciences\n\n\neducation\n\n\n\nLLMs with Comparative Judgment outperform traditional rubric-based scoring in AES.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat’s Wrong with Your Code Generated by Large Language Models? An Extensive Study\n\n\n\narchitectures\n\n\nrobustness\n\n\nprogramming\n\n\nproduction\n\n\n\nLLMs struggle with complex code, often producing shorter, more complicated code. A novel iterative method improves LLM-generated code, boosting passing rate by 29.2%.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen is the consistent prediction likely to be a correct prediction?\n\n\n\nprompt-engineering\n\n\n\nLLMs produce more accurate answers with longer, consistent reasoning, not just the most consistent answer. Longer responses are less likely, requiring length-based decoding…\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeneration and De-Identification of Indian Clinical Discharge Summaries using LLMs\n\n\n\nproduction\n\n\n\nDe-identification algorithms struggle in Indian healthcare; synthetic data can improve performance.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPsycoLLM: Enhancing LLM for Psychological Understanding and Evaluation\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nPsycoLLM: A Specialized Psychological LLM Outperforms Others in Mental Health Support.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMerge, Ensemble, and Cooperate! A Survey on Collaborative Strategies in the Era of Large Language Models\n\n\n\narchitectures\n\n\nproduction\n\n\n\nThis paper explores three strategies for collaborative large language models: merging, ensemble, and cooperation.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInverseCoder: Unleashing the Power of Instruction-Tuned Code LLMs with Inverse-Instruct\n\n\n\neducation\n\n\nprogramming\n\n\n\nInverseCoder improves code LLMs by self-generating instructions, outperforming original models.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPAS: Data-Efficient Plug-and-Play Prompt Augmentation System\n\n\n\narchitectures\n\n\nsocial-sciences\n\n\nprompt-engineering\n\n\nproduction\n\n\n\nPAS is a plug-and-play AI system for prompt engineering, offering high performance, efficiency, and flexibility for LLMs.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenFollower: Enhancing Car-Following Prediction with Large Language Models\n\n\n\nprompt-engineering\n\n\n\nGenFollower: LLM-based approach improves car-following behavior prediction and interpretability.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Human-LLM Conversations: Mental Models and the Originator of Toxicity\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs provide toxic content mainly due to human demand or provocation.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHyCIR: Boosting Zero-Shot Composed Image Retrieval with Synthetic Labels\n\n\n\narchitectures\n\n\nproduction\n\n\n\nHyCIR uses synthetic labels to improve zero-shot CIR performance, achieving SOTA results on CIRR and CIRCO benchmarks.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Loops to Oops: Fallback Behaviors of Language Models Under Uncertainty\n\n\n\nrobustness\n\n\n\nLLMs’ fallback behaviors shift from repetitions to degenerate text to hallucinations with model advancement and increasing uncertainty. Common decoding techniques may reduce…\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn Speeding Up Language Model Evaluation\n\n\n\narchitectures\n\n\nproduction\n\n\n\nTL;DR: Our approach reduces evaluation resources by 85-95% using multi-armed bandit algorithms and low-rank factorization.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo Multilingual Large Language Models Mitigate Stereotype Bias?\n\n\n\nsocial-sciences\n\n\n\nMultilingual training in LLMs reduces bias and improves prediction accuracy compared to monolingual models.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nT2VSafetyBench: Evaluating the Safety of Text-to-Video Generative Models\n\n\n\narchitectures\n\n\nrobustness\n\n\nsecurity\n\n\n\nT2VSafetyBench: New benchmark for assessing text-to-video model safety risks, highlighting no single model excels in all aspects and a trade-off between usability and safety.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArtificial Intuition: Efficient Classification of Scientific Abstracts\n\n\n\narchitectures\n\n\nproduction\n\n\n\nNew method uses LLM to classify NASA abstracts, aiding strategic research insights.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(R^2\\)-Guard: Robust Reasoning Enabled LLM Guardrail via Knowledge-Enhanced Logical Reasoning\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nR2-Guard: Robust LLM guardrail via knowledge-enhanced reasoning, outperforms LlamaGuard by 30.2% on ToxicChat and 59.5% against jailbreak attacks.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Language Model Rationality with Bi-Directional Deliberation Reasoning\n\n\n\nprompt-engineering\n\n\n\nBIDDER enhances LLM decision-making with bi-directional reasoning, considering past and future contexts, improving rationality in poker and negotiation scenarios.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHecaton: Training and Finetuning Large Language Models with Scalable Chiplet Systems\n\n\n\narchitectures\n\n\n\nHecaton: A chiplet system for LLM training, reducing DRAM accesses and NoP overheads, offering 4.98× performance boost and 2.35× energy reduction.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAffordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\n\nAO-Planner: LLM-based framework for zero-shot VLN tasks, improves SPL by 5.5% on R2R-CE benchmark.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Grammar Masking to Ensure Syntactic Validity in LLM-based Modeling Tasks\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\nproduction\n\n\n\nGrammar masking improves LLMs’ modeling, reducing reliance on prompting and increasing correct syntax chances.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization\n\n\n\nhci\n\n\nproduction\n\n\narchitectures\n\n\nsocial-sciences\n\n\neducation\n\n\n\nLLMs can extract data context but struggle with visual tasks, despite being sensitive to uncertainties in utterances.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niLLM-TSC: Integration reinforcement learning and large language model for traffic signal control policy improvement\n\n\n\narchitectures\n\n\nproduction\n\n\n\nLLM-RL Integration Improves TSC, Reducing Wait Time by 17.5% in Degraded Communication.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCrowdMoGen: Zero-Shot Text-Driven Collective Motion Generation\n\n\n\nsocial-sciences\n\n\nproduction\n\n\n\nCrowdMoGen: Zero-shot text-driven framework for realistic crowd motion generation.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-Based Open-Domain Integrated Task and Knowledge Assistants with Programmable Policies\n\n\n\nrobustness\n\n\n\nKITA outperforms GPT-4 in a user study, offering reliable, grounded responses and controllable agent policies for complex user interactions.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmpowering 1000 tokens/second on-device LLM prefilling with mllm-NPU\n\n\n\narchitectures\n\n\neducation\n\n\nproduction\n\n\n\nmllm-NPU: A system for fast, energy-efficient on-device LLM inference, achieving 22.4x faster prefill speed and 30.7x energy savings.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Optimizing and Evaluating a Retrieval Augmented QA Chatbot using LLMs with Human in the Loop\n\n\n\nproduction\n\n\n\nLLM-driven HR chatbot, enhanced with GPT-4, offers efficient, scalable HR support, aligning with human evaluation.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodeUpdateArena: Benchmarking Knowledge Editing on API Updates\n\n\n\nprogramming\n\n\n\nTL;DR: CodeUpdateArena benchmark evaluates updating code LLMs with evolving API functions, highlighting challenges and room for improvement.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistilling System 2 into System 1\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\nproduction\n\n\n\nDistilling System 2 techniques into System 1 improves LLM performance with less inference cost.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRetrieved In-Context Principles from Previous Mistakes\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nRICP improves LLM performance by learning from mistakes, enhancing error coverage and customization.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSub-SA: Strengthen In-context Learning via Submodular Selective Annotation\n\n\n\nprompt-engineering\n\n\n\nSub-SA is a submodular selective annotation method for ICL, reducing annotation costs and improving in-context example quality with millisecond-level time selection and…\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmpirical Study of Symmetrical Reasoning in Conversational Chatbots\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nChatbots show varied ability to understand predicate symmetry, with some nearing human-like reasoning.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDepression Detection and Analysis using Large Language Models on Textual and Audio-Visual Modalities\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nAI models outperform traditional methods in diagnosing depression, achieving 71.43% accuracy and RMSE of 3.98 on textual modality.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nANOLE: An Open, Autoregressive, Native Large Multimodal Models for Interleaved Image-Text Generation\n\n\n\narchitectures\n\n\nproduction\n\n\n\nAnole: Open, autoregressive LMM for interleaved image-text generation, addressing previous LMM limitations.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLaMAX: Scaling Linguistic Horizons of LLM by Enhancing Translation Capabilities Beyond 100 Languages\n\n\n\narchitectures\n\n\nproduction\n\n\n\nLLMs struggle with low-resource languages. LLaMAX, a multilingual LLM, outperforms existing models in translation tasks across 100+ languages.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Computer Programming Education with LLMs: A Study on Effective Prompt Engineering for Python Code Generation\n\n\n\neducation\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\nLLMs, like GPT-4o, excel in programming education with tailored prompt strategies, offering personalized instruction and improved learning outcomes.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions\n\n\n\nsocial-sciences\n\n\n\nLLMs excel in binary gender prediction but struggle with gender-neutral names, especially non-English ones; birth year data doesn’t improve accuracy.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssessing Code Generation with Intermediate Languages\n\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\n[TEXT] Abstract: This study examines the relationship between CEO narcissism and firm performance. Results indicate that narcissistic CEOs are associated with lower firm…\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCLIMB: A Benchmark of Clinical Bias in Large Language Models\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs in clinical tasks exhibit bias; CLIMB benchmark introduced to evaluate intrinsic and extrinsic bias.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Hallucination Detection through Perturbation-Based Synthetic Data Generation in System Responses\n\n\n\nrobustness\n\n\n\nAutomatic generation of faithful/hallucinated outputs improves LLM hallucination detection.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExperiments with truth using Machine Learning: Spectral analysis and explainable classification of synthetic, false, and genuine information\n\n\n\nsocial-sciences\n\n\n\nLLMs contribute to misinformation; ML algorithms struggle to distinguish fake from genuine text.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the Educational Landscape of AI: Large Language Models’ Approaches to Explaining Conservation of Momentum in Physics\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLMs vary in explaining physics concepts; educator guidance crucial for effective use in teaching.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFaux Polyglot: A Study on Information Disparity in Multilingual Large Language Models\n\n\n\nsocial-sciences\n\n\n\nLLMs in RAG-based search favor same-language info, reinforcing dominant views and potentially marginalizing low-resource languages.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCollective Innovation in Groups of Large Language Models\n\n\n\nsocial-sciences\n\n\neducation\n\n\nhci\n\n\n\nLLMs playing a video game show collective innovation, with dynamic connectivity boosting performance.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Model as an Assignment Evaluator: Insights, Feedback, and Challenges in a 1000+ Student Course\n\n\n\nrobustness\n\n\neducation\n\n\n\nLLM-based evaluators, like GPT-4, can be used in classrooms, but students can manipulate them and they may not always follow instructions.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHarnessing the Power of LLMs: Automating Unit Test Generation for High-Performance Computing\n\n\n\nrobustness\n\n\nprogramming\n\n\n\nLLMs like Davinci and ChatGPT can generate syntactically correct unit tests for parallel and high-performance software, but may have limitations like repetitive assertions…\n\n\n\nJul 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMCloudHunter: Harnessing LLMs for Automated Extraction of Detection Rules from Cloud-Based CTI\n\n\n\nsecurity\n\n\n\nLLMCloudHunter: Automated OSCTI analysis for cloud threats, using LLMs for high-precision rule generation.\n\n\n\nJul 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Comparative Study of DSL Code Generation: Fine-Tuning vs. Optimized Retrieval Augmentation\n\n\n\nrobustness\n\n\nprogramming\n\n\n\nLLMs struggle with DSLs, but optimized RAG models can match fine-tuned models and handle new APIs better.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models as Evaluators for Scientific Synthesis\n\n\n\nprogramming\n\n\n\nLLMs can logically rate scientific summaries but weakly correlate with human ratings, indicating potential and limitations in evaluation.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nLLMs show potential for epilepsy diagnosis, but pitfalls like overconfidence and hallucinations exist.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the Capabilities of LLMs for Code Change Related Tasks\n\n\n\neducation\n\n\nprogramming\n\n\n\nLLMs struggle with code-change tasks, but improve with examples. Larger models aren’t always better, but Llama 2 and Code Llama are top performers.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSingle Character Perturbations Break LLM Alignment\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nAdding a space to prompts can bypass safety measures in language models, causing harmful outputs.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow Does Quantization Affect Multilingual LLMs?\n\n\n\nsocial-sciences\n\n\n\nQuantization harms multilingual LLMs, especially non-Latin script languages and complex tasks, despite automatic metrics underestimating the impact.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJailbreakHunter: A Visual Analytics Approach for Jailbreak Prompts Discovery from Large-Scale Human-LLM Conversational Datasets\n\n\n\nrobustness\n\n\nhci\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nJailbreakHunter: A visual analytics approach to identify LLM jailbreak prompts in large-scale conversational datasets.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCactus: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory\n\n\n\nhci\n\n\nprompt-engineering\n\n\n\nCamel model, trained on Cactus dataset, outperforms others in counseling skills, ensuring privacy and accessibility.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLANE: Logic Alignment of Non-tuning Large Language Models and Online Recommendation Systems for Explainable Reason Generation\n\n\n\nrecommender\n\n\n\nLANE strategy aligns LLMs with recommendation systems, improving explainability without additional tuning.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel-Enhanced LLM-Driven VUI Testing of VPA Apps\n\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nElevate, a VUI testing framework, uses LLMs for better natural language processing, improving state space coverage and efficiency compared to Vitas.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Conversational Abilities of Quantized Large Language Models via Direct Preference Alignment\n\n\n\neducation\n\n\nhci\n\n\n\nQDPO improves quantized LLMs’ conversational abilities, outperforming PTQ and knowledge-distillation fine-tuning techniques.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScreenTK: Seamless Detection of Time-Killing Moments Using Continuous Mobile Screen Text Monitoring\n\n\n\nrobustness\n\n\n\nScreenTK detects time-killing moments on smartphones using continuous screen text monitoring and on-device large language models, outperforming current methods.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Watermarking: Safeguarding Your Video from (Unauthorized) Annotations by Video-based LLMs\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nVideo Watermarking secures video content from unauthorized annotations by video-based LLMs, preserving integrity and confidentiality.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models\n\n\n\nhci\n\n\neducation\n\n\n\nGraCoRe benchmark evaluates LLMs’ graph comprehension and reasoning, revealing insights on semantic enrichment, node ordering, and text length impact.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRaw Text is All you Need: Knowledge-intensive Multi-turn Instruction Tuning for Large Language Model\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nR2S framework uses CoD logic to guide LLMs in generating knowledge-intensive dialogues for instruction tuning, enhancing LLM adaptability and effectiveness.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMG-Verilog: Multi-grained Dataset Towards Enhanced LLM-assisted Verilog Generation\n\n\n\nprogramming\n\n\n\nLLMs aid hardware design, but datasets are limited. New criteria for high-quality hardware datasets proposed, along with a Multi-Grained-Verilog dataset and a balanced…\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts\n\n\n\nprogramming\n\n\n\nTheoremLlama: LLM framework for formal theorem proving outperforms GPT-4.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSOS! Soft Prompt Attack Against Open-Source Large Language Models\n\n\n\nrobustness\n\n\nprogramming\n\n\nsecurity\n\n\n\nNew attack, SOS, targets open-source LLMs, maintaining model utility. Also introduces copyright token for content protection.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Affects the Stability of Tool Learning? An Empirical Study on the Robustness of Tool Learning Frameworks\n\n\n\nrobustness\n\n\neducation\n\n\n\nTool learning in LLMs varies by factors like tasks, data, and algorithms. Exploring these impacts can improve LLM integration in real-world applications.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output\n\n\n\neducation\n\n\n\nIXC-2.5: 7B LLM model excels in long-context text-image tasks, outperforming open-source SOTA models on 16 benchmarks.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSocial Bias Evaluation for Large Language Models Requires Prompt Variations\n\n\n\nrobustness\n\n\nsocial-sciences\n\n\nhci\n\n\nprompt-engineering\n\n\n\nLLMs’ performance and bias vary greatly with prompts; diverse prompts are recommended for accurate comparison.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSafe Unlearning: A Surprisingly Effective and Generalizable Solution to Defend Against Jailbreak Attacks\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nTL;DR: Unlearning harmful knowledge in LLMs effectively defends against jailbreak attacks, outperforming traditional fine-tuning methods.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet the Code LLM Edit Itself When You Edit the Code\n\n\n\nrobustness\n\n\nprogramming\n\n\n\nPIE reduces 85% computational overhead in real-time code editing, maintaining model performance.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models\n\n\n\nprompt-engineering\n\n\n\nDCoT method improves LLM performance by comparing multiple reasoning chains, enabling self-correction.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObfuscaTune: Obfuscated Offsite Fine-tuning and Inference of Proprietary LLMs on Private Datasets\n\n\n\nsecurity\n\n\n\nObfuscaTune: A method for private LLM finetuning on cloud, preserving utility and confidentiality.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFSM: A Finite State Machine Based Zero-Shot Prompting Paradigm for Multi-Hop Question Answering\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nFSM prompting enhances LLMs’ reasoning, improving accuracy and trustworthiness in complex tasks, mitigating hallucination, and easing answer interpretation.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre Large Language Models Consistent over Value-laden Questions?\n\n\n\nrobustness\n\n\neducation\n\n\n\nLLMs show consistency across paraphrases, use-cases, and translations, but inconsistencies remain, especially on controversial topics.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-Evaluation as a Defense Against Adversarial Attacks on LLMs\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nAdding a space to prompts can bypass safety measures in language models, causing harmful outputs.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCogErgLLM: Exploring Large Language Model Systems Design Perspective Using Cognitive Ergonomics\n\n\n\nhci\n\n\n\nIntegrate cognitive ergonomics in LLM design for safer, reliable, and ethical human-AI interactions.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLoRA-Guard: Parameter-Efficient Guardrail Adaptation for Content Moderation of Large Language Models\n\n\n\nrobustness\n\n\n\nLoRA-Guard: Efficient, On-Device Content Moderation for LLMs with Minimal Performance Impact.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM Internal States Reveal Hallucination Risk Faced With a Query\n\n\n\nrobustness\n\n\n\nLLMs can estimate their own hallucination risk before response generation, achieving 84.32% accuracy.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs Your AI-Generated Code Really Secure? Evaluating Large Language Models on Secure Code Generation with CodeSecEval\n\n\n\nrobustness\n\n\nprogramming\n\n\nsecurity\n\n\n\nLLMs for code generation/repair risk security vulnerabilities. This study evaluates and enhances their security, introducing CodeSecEval dataset and strategies to mitigate…\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTalking to Machines: do you read me?\n\n\n\neducation\n\n\nhci\n\n\n\n[TEXT] Abstract: This study examines the impact of social media on the mental health of adolescents. Results indicate a significant correlation between excessive social…\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBreaking Bias, Building Bridges: Evaluation and Mitigation of Social Biases in LLMs via Contact Hypothesis\n\n\n\nhci\n\n\n\nLLMs exhibit social biases, but a new debiasing technique, Social Contact Debiasing (SCD), can reduce these biases by up to 40% in one epoch of instruction tuning.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHelpful assistant or fruitful facilitator? Investigating how personas affect language model behavior\n\n\n\nhci\n\n\neducation\n\n\n\nPersonas in LLMs cause more varied responses than control, with some behaviors consistent across models.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Visual Storytelling with Multimodal Large Language Models\n\n\n\neducation\n\n\nhci\n\n\n\nThis paper presents a novel approach using LLMs and LVLMs with instruction tuning for generating coherent and emotionally resonant visual stories, outperforming existing…\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Steering and Verification in AI-Assisted Data Analysis with Interactive Task Decomposition\n\n\n\neducation\n\n\n\nStepwise, Phasewise systems offer better control, intervention, and verification in AI-assisted data analysis, compared to conversational baselines.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRVISA: Reasoning and Verification for Implicit Sentiment Analysis\n\n\n\nprompt-engineering\n\n\n\nRVISA: A two-stage framework for implicit sentiment analysis using LLMs, achieving state-of-the-art results.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKGym: A Platform and Dataset to Benchmark Large Language Models on Linux Kernel Crash Resolution\n\n\n\nprogramming\n\n\n\nLLMs struggle with Linux kernel crashes, achieving 0.72%-5.38% success. Further research needed for SE tasks.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultilingual Trolley Problems for Language Models\n\n\n\nhci\n\n\n\nLLMs’ moral decisions vary by language; more aligned with English, Korean, Hungarian, and Chinese, less with Hindi and Somali. Fairness dominates GPT-4’s choices…\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogEval: A Comprehensive Benchmark Suite for Large Language Models In Log Analysis\n\n\n\neducation\n\n\nhci\n\n\n\n[TEXT] This study examines the impact of climate change on the migration patterns of polar bears in the Arctic. Results indicate that as sea ice diminishes, polar bears are…\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Alignment in Multimodal LLMs: A Comprehensive Study\n\n\n\nrobustness\n\n\n\nTL;DR: Combining offline and online methods improves MLLMs, BDHS aids multimodal preference data creation.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerative Monoculture in Large Language Models\n\n\n\nhci\n\n\nprogramming\n\n\n\nGenerative Monoculture in LLMs narrows output diversity, potentially limiting perspectives; simple countermeasures insufficient, suggesting need for diverse fine-tuning…\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGRASP: A Grid-Based Benchmark for Evaluating Commonsense Spatial Reasoning\n\n\n\neducation\n\n\n\nLLMs like GPT-3.5-Turbo and GPT-4o struggle with satisfactory solutions in spatial reasoning tasks, as shown by the GRASP benchmark.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSoP: Unlock the Power of Social Facilitation for Automatic Jailbreak Attack\n\n\n\nsecurity\n\n\n\nSoP framework generates jailbreak prompts, bypassing GPT-3.5 and GPT-4 safety with 88% and 60% success, respectively.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt during Large Language Model Fine-tuning\n\n\n\nprompt-engineering\n\n\n\nPromptIntern: LLM method reduces inference tokens by 90%, speeds up inference 4.2x, and saves 88.3% monetary cost.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification\n\n\n\nprompt-engineering\n\n\n\nPelican framework reduces LVLMs’ hallucinations by 8-32% via claim verification, outperforming existing mitigation approaches.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond Numeric Awards: In-Context Dueling Bandits with LLM Agents\n\n\n\nsecurity\n\n\n\nLLMs, like GPT-4 Turbo, excel in identifying Condorcet winners in Dueling Bandits, but struggle with convergence. An LLM-augmented algorithm, IF-Enhanced LLM, improves…\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssessing the Code Clone Detection Capability of Large Language Models\n\n\n\nrobustness\n\n\nprogramming\n\n\n\nGPT-4 outperforms GPT-3.5 in code clone detection, but both struggle with complex clones and human-generated code. Improvements are needed for LLM code clone recognition.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLEXI: Large Language Models Experimentation Interface\n\n\n\nhci\n\n\n\nLEXI, a new open-source tool, simplifies deploying LLM-powered agents in social interaction experiments, with positive usability testing results.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCFinBench: A Comprehensive Chinese Financial Benchmark for Large Language Models\n\n\n\neducation\n\n\n\nTL;DR: CFinBench evaluates financial knowledge of LLMs in Chinese context, revealing a 60.16% highest average accuracy.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSupporters and Skeptics: LLM-based Analysis of Engagement with Mental Health (Mis)Information Content on Video-sharing Platforms\n\n\n\nhci\n\n\n\nStudy finds mental health misinformation on YouTube Shorts and Bitchute, with distinct audience engagement patterns and potential harm to public health.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmbodied AI in Mobile Robots: Coverage Path Planning with Large Language Models\n\n\n\nprogramming\n\n\n\nLLM-based path planning framework for mobile agents improves spatial inference and coverage planning, with claude-3.5 showing the best performance.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSynthetic Multimodal Question Generation\n\n\n\nhci\n\n\n\nSMMQG generates style-specific MMRAG questions from multimodal documents, rivaling human-generated data quality.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention\n\n\n\nprompt-engineering\n\n\n\nMInference speeds up LLM pre-filling by 10x, maintaining accuracy via sparse calculation methods for long-context attention matrices.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the Role of Transliteration in In-Context Learning for Low-resource Languages Written in Non-Latin Scripts\n\n\n\nprompt-engineering\n\n\n\nTransliteration can improve LLMs’ performance for low-resource, non-Latin languages, especially in sequential labeling tasks.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCEB: Compositional Evaluation Benchmark for Fairness in Large Language Models\n\n\n\nhci\n\n\n\nCEB: A Comprehensive Benchmark for Evaluating Bias in Large Language Models.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nS2D: Sorted Speculative Decoding For More Efficient Deployment of Nested Large Language Models\n\n\n\nhci\n\n\n\nTL;DR: New method improves speculative decoding for multiple large language models, reducing costs.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-Cognition in Large Language Models: An Exploratory Study\n\n\n\nhci\n\n\n\nLLMs like Command R and Llama-3-70b-Instruct show detectable self-cognition, which improves tasks like creative writing.\n\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTCSR-SQL: Towards Table Content-aware Text-to-SQL with Self-retrieval\n\n\n\nprogramming\n\n\n\nTL;DR: TCSR-SQL improves Text-to-SQL performance by 13.7% with self-retrieval and in-context learning.\n\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Multilingual Instruction Finetuning via Linguistically Natural and Diverse Datasets\n\n\n\neducation\n\n\nprogramming\n\n\n\nNew method for multilingual IFT datasets improves LLM performance in non-English contexts, boosting summarization by up to 17.57%.\n\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMIRAI: Evaluating LLM Agents for Event Forecasting\n\n\n\nprogramming\n\n\n\nMirai benchmark evaluates LLM agents’ forecasting skills for international events, assessing their ability to source, integrate, and reason with diverse information.\n\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAgentless: Demystifying LLM-based Software Engineering Agents\n\n\n\nprogramming\n\n\n\nAgentless, a simple two-phase LLM approach, outperforms complex software agents in solving software development problems, offering higher performance and lower cost.\n\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscoveryBench: Towards Data-Driven Discovery with Large Language Models\n\n\n\nprogramming\n\n\n\nLLMs struggle with autonomous data-driven discovery, scoring only 25% on the DiscoveryBench benchmark.\n\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssessing the Effectiveness of LLMs in Android Application Vulnerability Analysis\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nLLMs’ strengths and weaknesses in detecting Android code vulnerabilities are analyzed, highlighting the potential of context augmentation with RAG for secure app development.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAveraging log-likelihoods in direct alignment\n\n\n\narchitectures\n\n\nsocial-sciences\n\n\n\nDirect alignment methods for LLMs are made length-invariant, improving alignment with human judgment.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSTBench: Assessing the Ability of Large Language Models in Spatio-Temporal Analysis\n\n\n\narchitectures\n\n\neducation\n\n\nprompt-engineering\n\n\n\nSTBench evaluates LLMs’ spatio-temporal understanding across 13 tasks, revealing strengths and areas for improvement.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApplying LLMs for Rescoring N-best ASR Hypotheses of Casual Conversations: Effects of Domain Adaptation and Context Carry-over\n\n\n\narchitectures\n\n\n\nLLMs like Llama2 improve ASR in casual conversations, even without domain adaptation, and reduce computational cost with adaptation.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSubtractive Training for Music Stem Insertion using Latent Diffusion Models\n\n\n\nproduction\n\n\n\n[TEXT] This study examines the impact of climate change on the frequency and intensity of hurricanes in the Atlantic Ocean. Results suggest a significant increase in both…\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?\n\n\n\nproduction\n\n\n\nModel editing in language models critiqued, 12 open problems identified, semi-synthetic dataset proposed for evaluation.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDisentangling Knowledge-based and Visual Reasoning by Question Decomposition in KB-VQA\n\n\n\nhci\n\n\neducation\n\n\n\nDecomposing complex questions into simpler ones improves visual question-answering performance, boosting accuracy by up to 2% on three datasets.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation\n\n\n\narchitectures\n\n\nproduction\n\n\n\nAutoRAG-HP optimizes RAG hyper-parameters using a novel Hierarchical MAB method, reducing LLM API calls by 80% compared to Grid Search.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Teacher Is Worth A Million Instructions\n\n\n\narchitectures\n\n\n\nImproved training method for smaller LLMs using larger models and domain-specific knowledge, outperforming larger models.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFairness and Bias in Multimodal AI: A Survey\n\n\n\nsocial-sciences\n\n\n\nTL;DR: This survey highlights fairness and bias in Large Multimodal Models, offering 50 examples and discussing challenges, including a new preuse bias category.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLiveBench: A Challenging, Contamination-Free LLM Benchmark\n\n\n\narchitectures\n\n\nproduction\n\n\nsocial-sciences\n\n\nrobustness\n\n\n\nLiveBench: A dynamic, contamination-free LLM benchmark with diverse tasks and automatic scoring.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFFN: a Fine-grained Chinese-English Financial Domain Parallel Corpus\n\n\n\neducation\n\n\n\nLLMs’ financial translation quality is evaluated, revealing room for improvement and optimization.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUniGen: A Unified Framework for Textual Dataset Generation Using Large Language Models\n\n\n\narchitectures\n\n\n\nUniGen: LLM-powered framework for diverse, accurate, and controllable dataset generation, enhancing data quality and supporting benchmarking, data augmentation.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Model Arena for Cross-lingual Sentiment Analysis: A Comparative Study in the Era of Large Language Models\n\n\n\nhci\n\n\nproduction\n\n\nsocial-sciences\n\n\n\nSMLMs outperform LLMs in zero-shot cross-lingual sentiment analysis, but LLMs improve in few-shot settings. Proprietary GPT models excel in zero-shot, but lag in few-shot…\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nT-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings\n\n\n\narchitectures\n\n\n\nT-Free: A novel tokenizer for LLMs, reducing parameters by 85% and improving cross-lingual transfer, without needing a reference corpus.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan we teach language models to gloss endangered languages?\n\n\n\nsocial-sciences\n\n\n\nLLMs can generate interlinear glossed text with in-context learning, outperforming transformer baselines without training, but still lag behind supervised systems.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmPO: Theory-Driven Dataset Construction for Empathetic Response Generation through Preference Optimization\n\n\n\narchitectures\n\n\nrecommender\n\n\nhci\n\n\n\nTL;DR: We propose a novel approach for empathetic response generation using LLMs and preference optimization, with public datasets and models.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhysioLLM: Supporting Personalized Health Insights with Wearables and Large Language Models\n\n\n\nproduction\n\n\n\nPhysioLLM uses LLMs to analyze wearable data, offering personalized health insights and actionable goals, outperforming commercial health apps in a sleep quality case study.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimulating Classroom Education with LLM-Empowered Agents\n\n\n\neducation\n\n\nprompt-engineering\n\n\nhci\n\n\narchitectures\n\n\nsocial-sciences\n\n\n\nLLMs can simulate classroom interactions, improving user experience in a multi-agent framework, as demonstrated by SimClass.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Remarkable Robustness of LLMs: Stages of Inference?\n\n\n\narchitectures\n\n\nproduction\n\n\n\nTL;DR: Large Language Models remain accurate despite deleting or swapping layers, suggesting four universal inference stages.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHierarchical Context Pruning: Optimizing Real-World Code Completion with Repository-Level Pretrained Code LLMs\n\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\nHCP strategy improves Code LLMs’ accuracy by pruning irrelevant code, reducing input length.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAligning Teacher with Student Preferences for Tailored Training Data Generation\n\n\n\narchitectures\n\n\neducation\n\n\nprompt-engineering\n\n\n\nARTE: A framework aligning teacher models with student preferences for tailored training examples in Knowledge Distillation.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAMBROSIA: A Benchmark for Parsing Ambiguous Questions into Database Queries\n\n\n\narchitectures\n\n\n\nAMBROSIA benchmark tests LLMs on interpreting ambiguous text-to-SQL queries, revealing challenges for advanced models.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models\n\n\n\nprompt-engineering\n\n\n\nLLMs can excel in low-resource languages with Self-Supervised Prompting, a novel ICL approach for zero-label cross-lingual transfer.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTools Fail: Detecting Silent Errors in Faulty Tools\n\n\n\narchitectures\n\n\nproduction\n\n\n\nLLMs can detect silent tool errors and plan better, improving their use as tools.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nContrastive Policy Gradient: Aligning LLMs on sequence-level scores in a supervised-friendly fashion\n\n\n\narchitectures\n\n\n\nCoPG: A new RL algorithm for off-policy policy gradient, optimizing LLMs with arbitrary rewards, and generalizing IPO and classic policy gradient.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCapturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nRPLMs enhanced with personality data improve role-playing abilities in dialogue.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJump Starting Bandits with LLM-Generated Prior Knowledge\n\n\n\nrecommender\n\n\nproduction\n\n\n\nLLMs improve contextual bandits in recommendation systems, reducing regret and data-gathering costs.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSonnet or Not, Bot? Poetry Evaluation for Large Models and Datasets\n\n\n\neducation\n\n\nsocial-sciences\n\n\n\nLLMs can recognize poetic form, but challenges remain in evaluating their poetic capabilities and creating NLP benchmarks for poetry.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions\n\n\n\neducation\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nDiVERT outperforms state-of-the-art distractor generation methods in math MCQs, using a 7B parameter LLM and producing human-like error labels.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuri: Multi-constraint Instruction Following for Long-form Text Generation\n\n\n\narchitectures\n\n\nproduction\n\n\n\nSuri-I-ORPO generates longer, coherent, and preferred long-form texts from complex instructions, outperforming base models.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nELCoRec: Enhance Language Understanding with Co-Propagation of Numerical and Categorical Features for Recommendation\n\n\n\nrecommender\n\n\nhci\n\n\nprompt-engineering\n\n\neducation\n\n\n\nTL;DR: ELCoRec enhances language models for recommendation by co-propagating numerical and categorical features, improving preference understanding and recent interest…\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation\n\n\n\nproduction\n\n\nsecurity\n\n\nrobustness\n\n\n\nRAG systems’ security is explored using Membership Inference Attacks, achieving 82% ROC AUC in identifying database membership.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFine-tuned network relies on generic representation to solve unseen cognitive task\n\n\n\narchitectures\n\n\n\nFine-tuned models rely on pretrained representations, while scratch-trained models develop task-specific mechanisms.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale\n\n\n\nproduction\n\n\n\nPubMedVision dataset improves medical multimodal capabilities of MLLMs, outperforming other data construction methods.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data\n\n\n\narchitectures\n\n\nproduction\n\n\n\nFinetuning LLMs on synthetic data enhances their long-context information retrieval and reasoning skills, with minimal impact on general benchmark performance.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMethodology of Adapting Large English Language Models for Specific Cultural Contexts\n\n\n\nsocial-sciences\n\n\n\nLLMs adapted for specific cultures, like Chinese, improve domain knowledge and safety values without losing expertise.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLICO: Large Language Models for In-Context Molecular Optimization\n\n\n\nprompt-engineering\n\n\n\nLICO enhances LLMs for black-box optimization, excelling in molecular property optimization via in-context prompting.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRevealing Fine-Grained Values and Opinions in Large Language Models\n\n\n\nhci\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nTL;DR: Analyzing 156k LLM responses to PCT reveals biases, disparities, and recurring text patterns influenced by prompts and demographic features.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutoPureData: Automated Filtering of Web Data for LLM Fine-tuning\n\n\n\narchitectures\n\n\nproduction\n\n\n\nSystem filters web data for AI training, ensuring purity and reliability.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Weak-to-Strong Generalization with Reliability-Aware Alignment\n\n\n\narchitectures\n\n\n\nApproach improves weak-to-strong generalization in LLMs by estimating weak supervision reliability, reducing error propagation, and enhancing accuracy.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOMG-LLaVA: Bridging Image-level, Object-level, Pixel-level Reasoning and Understanding\n\n\n\neducation\n\n\nprompt-engineering\n\n\nhci\n\n\narchitectures\n\n\nproduction\n\n\n\nOMG-LLaVA: A framework for pixel-level vision understanding with reasoning abilities, accepting visual and text prompts.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLayoutCopilot: An LLM-powered Multi-agent Collaborative Framework for Interactive Analog Layout Design\n\n\n\nhci\n\n\nprompt-engineering\n\n\neducation\n\n\n\n[TEXT] The Impact of Social Media on College Students’ Academic Performance: A Review of Literature [TL;DR] Social media negatively affects college students’ academic…\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEfficient course recommendations with T5-based ranking and summarization\n\n\n\narchitectures\n\n\nrecommender\n\n\neducation\n\n\n\nT5-based re-ranking and summarization improve course recommendation relevance, but speed and interpretability also matter in online evaluation.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMath-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models\n\n\n\neducation\n\n\n\nMath-LLaVA: New Model Improves Multimodal Math Reasoning with Diverse Dataset\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWildTeaming at Scale: From In-the-Wild Jailbreaks to (Adversarially) Safer Language Models\n\n\n\nsecurity\n\n\n\nNew framework discovers 5.7K unique jailbreak tactics, creating a large-scale safety dataset for safer AI chatbots.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMALSIGHT: Exploring Malicious Source Code and Benign Pseudocode for Iterative Binary Malware Summarization\n\n\n\nprogramming\n\n\nsecurity\n\n\n\nMalsight, a novel code summarization framework, generates malware behavior descriptions from executables, improving usability, accuracy, and completeness. It outperforms…\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMs instead of Human Judges? A Large Scale Empirical Study across 20 NLP Evaluation Tasks\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLLMs vary greatly in replicating human annotations, suggesting they’re not yet reliable substitutes for human NLP evaluations.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Context-Driven Approach for Co-Auditing Smart Contracts with The Support of GPT-4 code interpreter\n\n\n\nprompt-engineering\n\n\nsecurity\n\n\nrobustness\n\n\n\nTL;DR: Novel context-driven prompting technique for smart contract co-auditing improves vulnerability detection, outperforming native prompting.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSEED: Accelerating Reasoning Tree Construction via Scheduled Speculative Decoding\n\n\n\nprompt-engineering\n\n\n\nSeeD optimizes LLMs for complex reasoning, offering faster inference and efficient GPU memory management.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoisoned LangChain: Jailbreak LLMs by LangChain\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nPoisoned-LangChain: Novel method for indirect jailbreak attacks on LLMs, achieving 88.56%, 79.04%, and 82.69% success rates in three scenarios.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMental Modeling of Reinforcement Learning Agents by Language Models\n\n\n\nhci\n\n\n\nLLMs currently can’t fully mental model agents via inference alone, revealing their limitations.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMs for Doctors: Leveraging Medical LLMs to Assist Doctors, Not Replace Them\n\n\n\nrobustness\n\n\n\nLLMs as medical assistants face challenges, but our DoctorFLAN dataset and benchmarks can significantly improve their performance, complementing patient-oriented work.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSafeAligner: Safety Alignment against Jailbreak Attacks via Response Disparity Guidance\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nSafeAligner method improves LLM security, balancing safety and utility by comparing outputs of safety-focused and risk-prone models.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCatching Chameleons: Detecting Evolving Disinformation Generated using Large Language Models\n\n\n\nrobustness\n\n\n\nDELD method outperforms in detecting evolving disinformation from LLMs, addressing efficiency and performance challenges.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-Driven Multimodal Opinion Expression Identification\n\n\n\nsocial-sciences\n\n\n\nThis study enhances Opinion Expression Identification (OEI) with multimodal inputs, improving performance and achieving state-of-the-art results.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Entity Recognition Using Ensembles of Deep Learning and Fine-tuned Large Language Models: A Case Study on Adverse Event Extraction from Multiple Sources\n\n\n\nsocial-sciences\n\n\n\nThis study compares traditional deep learning models and LLMs for AE extraction, showing that ensembling these models improves performance.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPsychological Profiling in Cybersecurity: A Look at LLMs and Psycholinguistic Features\n\n\n\nhci\n\n\nsocial-sciences\n\n\nsecurity\n\n\n\nPsychological profiling and LLMs can enhance cybersecurity by analyzing threat actors’ textual data for psychological traits.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHierarchical Context Pruning: Optimizing Real-World Code Completion with Repository-Level Pretrained Code LLMs\n\n\n\nprogramming\n\n\n\nHCP strategy improves Code LLMs’ completion accuracy by pruning irrelevant code content, reducing input length.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Data Privacy in Large Language Models through Private Association Editing\n\n\n\nrobustness\n\n\n\nPAE: A novel defense for LLMs to remove private data without retraining, ensuring data privacy and model consistency.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLLMs as evaluation metrics: Large-scale prompt exploration reveals stability and variability in MT and summarization tasks.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFactFinders at CheckThat! 2024: Refining Check-worthy Statement Detection with LLMs through Data Pruning\n\n\n\nprogramming\n\n\n\nThis study explores using open-source LLMs to identify check-worthy political statements, proposing a data pruning approach for efficient learning.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFew-shot Personalization of LLMs with Mis-aligned Responses\n\n\n\nprompt-engineering\n\n\n\nFermi: New approach for few-shot personalization of LLMs using mis-aligned responses, improving performance across benchmarks.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn Empirical Study of Unit Test Generation with Large Language Models\n\n\n\neducation\n\n\nprompt-engineering\n\n\nrobustness\n\n\n\nTL;DR: Study explores open-source LLMs for unit test generation, comparing them to commercial GPT-4 and traditional Evosuite, highlighting prompt factors and limitations.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDetecting Machine-Generated Texts: Not Just AI vs Humans and Explainability is Complicated\n\n\n\nsocial-sciences\n\n\n\nThis study introduces a ternary text classification for LLM-generated text detection, emphasizing the need for explainable results and proposing guidelines for future…\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Large Language Model Aided Program Refinement\n\n\n\nprogramming\n\n\neducation\n\n\nprompt-engineering\n\n\nrobustness\n\n\n\nLLM4PR tool combines formal refinement techniques with LLMs to generate and verify reliable code from specifications, using GPT4 and Coq.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssertionBench: A Benchmark to Evaluate Large-Language Models for Assertion Generation\n\n\n\nprompt-engineering\n\n\nsecurity\n\n\nrobustness\n\n\n\nLLMs evaluated for hardware assertion generation; benchmark used for quantitative comparison.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLifelong Robot Library Learning: Bootstrapping Composable and Generalizable Skills for Embodied Control with Language Models\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLRLL: LLM-based agent grows robot skill library for complex tasks, outperforming end-to-end and vanilla LLM approaches.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBADGE: BADminton report Generation and Evaluation with LLM\n\n\n\nsocial-sciences\n\n\n\nTL;DR: GPT-4 can generate and evaluate high-quality badminton match reports, outperforming human judges.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymbolic Learning Enables Self-Evolving Agents\n\n\n\nprompt-engineering\n\n\n\nAgent Symbolic Learning enables language agents to self-optimize and evolve, transitioning from model-centric to data-centric AI, potentially advancing AGI.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNatural Language but Omitted? On the Ineffectiveness of Large Language Models’ privacy policy from End-users’ Perspective\n\n\n\nhci\n\n\n\n[TEXT] This study explores the relationship between social media use and mental health in young adults. Results suggest a negative correlation between excessive social media…\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJailbreaking LLMs with Arabic Transliteration and Arabizi\n\n\n\nprompt-engineering\n\n\nsecurity\n\n\nrobustness\n\n\n\nLLMs vulnerable to jailbreak attacks in Arabic, especially in transliteration and chatspeak, potentially exposing hidden information.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelective Prompting Tuning for Personalized Conversations with LLMs\n\n\n\nrecommender\n\n\nhci\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nSelective Prompt Tuning improves LLMs’ personalized dialogue, enhancing response diversity by up to 90%.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWildGuard: Open One-Stop Moderation Tools for Safety Risks, Jailbreaks, and Refusals of LLMs\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nWildGuard is an open-source LLM safety tool that excels in identifying harmful prompts, detecting safety risks, and determining model refusal rates, outperforming existing…\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHuman-AI Collaborative Taxonomy Construction: A Case Study in Profession-Specific Writing Assistants\n\n\n\nhci\n\n\n\nLLMs’ effectiveness in business writing is limited. Proposed: human-AI collaborative taxonomy development for domain-specific writing assistants.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRole-Play Zero-Shot Prompting with Large Language Models for Open-Domain Human-Machine Conversation\n\n\n\nhci\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nTL;DR: Role-play zero-shot prompting improves open-domain conversation in LLMs, surpassing fine-tuned models in French.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs In-Context Learning a Type of Gradient-Based Learning? Evidence from the Inverse Frequency Effect in Structural Priming\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nICL in LLMs is a form of gradient-based learning, as they display the inverse frequency effect, similar to human structural priming.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCategorical Syllogisms Revisited: A Review of the Logical Reasoning Abilities of LLMs for Analyzing Categorical Syllogism\n\n\n\nhci\n\n\n\nCurrent benchmarks for LLMs’ logical reasoning have limitations. Quantifier interpretation is a bottleneck, and future dataset releases should consider this.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThemis: Towards Flexible and Interpretable NLG Evaluation\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nNew NLG Evaluation Corpus and Model, Themis, Outperforms GPT-4 in Flexible, Reference-Free Evaluations.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNew intelligent empowerment for digital transformation\n\n\n\nsocial-sciences\n\n\n\nTL;DR: Study uses LLMs to evaluate DT in firms, finds it boosts financial performance, but effects vary by technology. Blockchain has limited impact.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMathOdyssey: Benchmarking Mathematical Problem-Solving Skills in Large Language Models Using Odyssey Math Data\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLMs excel at basic math but struggle with complex problems, per the MathOdyssey dataset. Open-source models are closing the gap with closed-source models.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdversarial Search Engine Optimization for Large Language Models\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nAttackers can manipulate LLMs to favor their content, degrading overall LLM performance.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIRCAN: Mitigating Knowledge Conflicts in LLM Generation via Identifying and Reweighting Context-Aware Neurons\n\n\n\nrobustness\n\n\n\nIRCAN framework improves LLMs’ context-sensitive output, resolving knowledge conflicts.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNeBuLa: A discourse aware Minecraft Builder\n\n\n\nsocial-sciences\n\n\n\nTL;DR: Model (NeBuLa) improves language to action tasks by considering conversation context, doubling F1 score over baseline.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs ChatGPT a Better Explainer than My Professor?: Evaluating the Explanation Capabilities of LLMs in Conversation Compared to a Human Baseline\n\n\n\neducation\n\n\n\nLLMs can enhance expert explainers’ conversational skills, improving science communication, especially when using concise responses and thought-provoking questions.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConvoCache: Smart Re-Use of Chatbot Responses\n\n\n\nprompt-engineering\n\n\n\nConvoCache speeds up chatbots by reusing past responses, reducing AI usage by up to 89% with 214ms latency. Prefetching offers limited benefits.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLongIns: A Challenging Long-context Instruction-based Exam for LLMs\n\n\n\neducation\n\n\n\nLLMs struggle with long-context tasks; GPT-4 underperforms with 16k context. Multi-hop reasoning needs improvement in short context windows.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Open-World Grasping with Large Vision-Language Models\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\n[TEXT] This study examines the impact of social media on body image and self-esteem in adolescents. Results indicate a significant negative correlation between social media…\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMeasuring and Benchmarking Large Language Models’ Capabilities to Generate Persuasive Language\n\n\n\nhci\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLLMs can produce persuasive text; new dataset measures this ability, enabling comparison of different LLMs and highlighting the impact of system prompts.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Tool Retrieval with Iterative Feedback from Large Language Models\n\n\n\neducation\n\n\n\nTL;DR: Enhancing tool retrieval for LLMs with iterative feedback for improved performance.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMitigating Hallucination in Fictional Character Role-Play\n\n\n\nhci\n\n\nsecurity\n\n\nrobustness\n\n\n\nRoleFact reduces hallucination in role-playing by 18% for adversarial questions and 44% for time-sensitive interviews.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMPCODER: Multi-user Personalized Code Generator with Explicit and Implicit Style Representation Learning\n\n\n\nprogramming\n\n\n\nMPCoder generates personalized code for multiple users, considering syntax and semantics, with a new evaluation metric for coding style similarities.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimsChat: A Customisable Persona-Driven Role-Playing Agent\n\n\n\nhci\n\n\n\nLLMs simulate customizable real-world characters for role-playing, offering a framework for human-like agents.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoSafe: Evaluating Large Language Model Safety in Multi-Turn Dialogue Coreference\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nLLMs vulnerable in multi-turn dialogues; highest attack success rate was 56% with LLaMA2-Chat-7b, lowest was 13.9% with Mistral-7B-Instruct.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale\n\n\n\neducation\n\n\n\nTL;DR: FineWeb, a 15-trillion token dataset, improves LLM performance; FineWeb-Edu boosts knowledge and reasoning tasks.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNormTab: Improving Symbolic Reasoning in LLMs Through Tabular Data Normalization\n\n\n\nprogramming\n\n\n\nNormTab improves LLMs’ symbolic reasoning on tables by normalizing web data, enhancing performance on tasks like WikiTableQuestion and TabFact.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDual-Space Knowledge Distillation for Large Language Models\n\n\n\neducation\n\n\n\nDSKD unifies output spaces for KD, improving LLM compression and enabling KD between models with different vocabularies.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan Large Language Models Understand DL-Lite Ontologies? An Empirical Study\n\n\n\neducation\n\n\n\nLLMs can understand DL-Lite ontologies’ syntax and semantics but struggle with transitivity and large ABoxes.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing LLM-Based Human-Robot Interaction with Nuances for Diversity Awareness\n\n\n\nhci\n\n\n\nSystem uses LLMs for diversity-aware autonomous conversations, adapting to user factors like background, personality, and culture.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-assessment, Exhibition, and Recognition: a Review of Personality in Large Language Models\n\n\n\nhci\n\n\n\nTL;DR: This paper reviews studies on personality in large language models, categorizing them into self-assessment, exhibition, and recognition, and discusses challenges and…\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuantifying AI Psychology: A Psychometrics Benchmark for Large Language Models\n\n\n\nhci\n\n\n\nLLMs exhibit psychological attributes, but self-reported traits may differ from real-world behaviors, according to a new psychometric benchmark.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDisce aut Deficere: Evaluating LLMs Proficiency on the INVALSI Italian Benchmark\n\n\n\neducation\n\n\n\nTL;DR: We adapt INVALSI tests to evaluate LLMs in Italian, comparing them to human performance and inviting further model submissions.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Unlearning Fails to Remove Data Poisoning Attacks\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nExisting unlearning methods fail to remove data poisoning effects, suggesting a need for broader evaluation and improvement.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnmasking the Imposters: In-Domain Detection of Human vs. Machine-Generated Tweets\n\n\n\nhci\n\n\n\nUncensored, fine-tuned LLMs evade detection, raising concerns about misuse on social media.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-ARC: Enhancing LLMs with an Automated Reasoning Critic\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLM-ARC improves LLMs’ logical reasoning via an Actor-Critic method, achieving 88.32% accuracy on the FOLIO benchmark.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models are Interpretable Learners\n\n\n\nprogramming\n\n\n\nLSPs, combining LLMs and symbolic programs, offer interpretable, accurate, and transferable knowledge for decision-making.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearning to Ask Informative Questions: Enhancing LLMs with Preference Optimization and Expected Information Gain\n\n\n\nhci\n\n\nprompt-engineering\n\n\neducation\n\n\n\nLLM-generated questions improved via Direct Preference Optimization (DPO) for better information gain in 20-question games.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Robustness of LLM-based Speech Synthesis by Learning Monotonic Alignment\n\n\n\nrobustness\n\n\n\nLLM-based TTS models can have errors; proposed techniques improve alignment and robustness without adding new parameters.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Three-Pronged Approach to Cross-Lingual Adaptation with Multilingual LLMs\n\n\n\nprogramming\n\n\n\nCross-lingual transfer to Indic languages improves Llama-2 LLM performance, benefiting from dominant language signals, word reordering, and continued pre-training.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBanishing LLM Hallucinations Requires Rethinking Generalization\n\n\n\nrobustness\n\n\n\nLLMs hallucinate due to training loss, not just creativity-factuality balance. MoME and Lamini-1 models can mitigate this issue.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRetrieval-Augmented Code Generation for Situated Action Generation: A Case Study on Minecraft\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLMs predict Builder’s actions in Minecraft Collaborative Building Task, using few-shot prompting for improved performance.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaLMQA: Exploring culturally specific long-form question answering across 23 languages\n\n\n\nsocial-sciences\n\n\n\nTL;DR: CaLMQA dataset evaluates multilingual LLMs on complex questions, revealing gaps in low-resource languages and cultural specificity.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNative Design Bias: Studying the Impact of English Nativeness on Language Model Performance\n\n\n\nhci\n\n\n\nLLMs perform worse for non-native English speakers, with an anchoring effect worsening responses.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM Targeted Underperformance Disproportionately Impacts Vulnerable Users\n\n\n\nrobustness\n\n\n\nLLMs’ reliability varies with user traits; lower proficiency, education, and non-US users receive less accurate, truthful, and more refused responses.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicting the Big Five Personality Traits in Chinese Counselling Dialogues Using Large Language Models\n\n\n\nhci\n\n\n\nLLMs can predict Big Five personality traits from counseling dialogues, outperforming traditional methods.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow Well Can Knowledge Edit Methods Edit Perplexing Knowledge?\n\n\n\nrobustness\n\n\n\nPerplexingness of new knowledge impacts editing efficacy in LLMs, with abstract concepts being more challenging to incorporate.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond Demographics: Aligning Role-playing LLM-based Agents Using Human Belief Networks\n\n\n\nhci\n\n\n\nLLMs align better with human beliefs when seeded with a single belief, improving social simulations.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo they mean ‘us’? Interpreting Referring Expressions in Intergroup Bias\n\n\n\nsocial-sciences\n\n\n\nLLMs detect intergroup bias in NFL comments, influenced by win probabilities.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCogMG: Collaborative Augmentation Between Large Language Model and Knowledge Graph\n\n\n\nrobustness\n\n\n\nCogMG framework improves LLM QA accuracy by leveraging knowledge graphs, reducing hallucinations and misalignment issues.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Comprehensive Preference Data Collection for Reward Modeling\n\n\n\nsocial-sciences\n\n\n\nNew framework for RLHF preference data collection improves quality, diversity, and reduces human labor.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUniCoder: Scaling Code Large Language Model via Universal Code\n\n\n\nprompt-engineering\n\n\nprogramming\n\n\neducation\n\n\n\nUniCoder: Improving Code Generation with Universal Code Intermediate Representation\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in Large Language Models\n\n\n\narchitectures\n\n\nproduction\n\n\n\nM2Lingual: A synthetic multilingual IFT dataset for LLMs, covering 70 languages and 17 NLP tasks, outperforming existing multilingual IFT datasets.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutomated Adversarial Discovery for Safety Classifiers\n\n\n\nrobustness\n\n\n\nAutomated methods struggle to find diverse, successful attacks on safety classifiers, revealing a need for improved adversarial discovery techniques.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUSDC: A Dataset of User Stance and Dogmatism in Long Conversations\n\n\n\nproduction\n\n\n\nLLMs automate annotation for user stance, dogmatism in Reddit conversations, creating USDC dataset for finetuning small language models.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnnotatedTables: A Large Tabular Dataset with Language Model Annotations\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nLLMs can automate annotation of large, diverse tabular data, enabling flexible annotations and SQL program generation.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLottery Ticket Adaptation: Mitigating Destructive Interference in LLMs\n\n\n\nproduction\n\n\narchitectures\n\n\neducation\n\n\nrobustness\n\n\n\nLoTA, a sparse adaptation method, outperforms full fine-tuning and LoRA, avoiding catastrophic forgetting and enabling model merging over dissimilar tasks.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models Assume People are More Rational than We Really are\n\n\n\nhci\n\n\n\nLLMs incorrectly assume humans are more rational, aligning with expected value theory, but match human expectations of rational behavior.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShadowLLM: Predictor-based Contextual Sparsity for Large Language Models\n\n\n\nrobustness\n\n\n\nShadowLLM improves end-to-end accuracy by 15%+, speeds up to 20% over DejaVu, validated on models up to 30B parameters.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWARP: On the Benefits of Weight Averaged Rewarded Policies\n\n\n\narchitectures\n\n\nproduction\n\n\n\nWARP strategy improves LLM alignment, balancing KL regularization and reward optimization.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMs assist NLP Researchers: Critique Paper (Meta-)Reviewing\n\n\n\nhci\n\n\n\nThis study explores LLMs’ potential to assist NLP researchers in paper reviewing, but does not advocate their use due to current limitations in expertise and nuanced…\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDirected Domain Fine-Tuning: Tailoring Separate Modalities for Specific Training Tasks\n\n\n\neducation\n\n\n\nFine-tuning Video-LLaVA with LORA on cooking tasks improves performance using smaller, task-specific datasets.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models in Student Assessment: Comparing ChatGPT and Human Graders\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\neducation\n\n\n\nGPT-4 aligns with human mean scores but lacks adaptability in grading nuanced criteria, highlighting AI’s limitations in higher education.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAgent-Driven Automatic Software Improvement\n\n\n\narchitectures\n\n\nprogramming\n\n\n\nThis research aims to improve software quality using agents powered by Large Language Models, focusing on iterative learning and error correction.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlagBench: Exploring the Duality of Large Language Models in Plagiarism Generation and Detection\n\n\n\nrobustness\n\n\n\nLLMs can aid plagiarism, but also detect it. GPT-3.5 outperforms Llama2 and GPT-4 in paraphrasing and summarizing, and LLMs can surpass commercial plagiarism detectors.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluation of Instruction-Following Ability for Large Language Models on Story-Ending Generation\n\n\n\nsocial-sciences\n\n\neducation\n\n\n\nLLMs’ instruction-following ability in story-ending generation aligns with human evaluation, with open-source models nearing GPT-3.5 performance.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBEEAR: Embedding-based Adversarial Removal of Safety Backdoors in Instruction-tuned Language Models\n\n\n\nrobustness\n\n\n\nBEEAR mitigates safety backdoor attacks in LLMs, reducing success rates from &gt;95% to &lt;1% without compromising model utility.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYouDream: Generating Anatomically Controllable Consistent Text-to-3D Animals\n\n\n\nhci\n\n\n\nYouDream generates anatomically accurate 3D animals from text, outperforming previous text-to-3D methods.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTask Oriented In-Domain Data Augmentation\n\n\n\neducation\n\n\n\nTRAIT, a task-oriented framework, enhances LLMs in specialized domains like law and advertisement by augmenting in-domain data and generating synthetic task-oriented…\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPISTOL: Dataset Compilation Pipeline for Structural Unlearning of LLMs\n\n\n\narchitectures\n\n\nrobustness\n\n\nproduction\n\n\n\nPISTOL: A pipeline for benchmarking structural unlearning in LLMs, highlighting challenges and model impacts.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models\n\n\n\nrobustness\n\n\n\nNew framework improves text-to-image model reliability, reducing inconsistencies between visual output and textual input.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSoley: Identification and Automated Detection of Logic Vulnerabilities in Ethereum Smart Contracts Using Large Language Models\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nTL;DR: Sóley, a LLM-based tool, outperforms existing methods in detecting logic vulnerabilities in smart contracts, aiding security and sustainability.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Augmentation of Multi-turn Psychological Dialogue via Knowledge-driven Progressive Thought Prompting\n\n\n\nprompt-engineering\n\n\nhci\n\n\nsocial-sciences\n\n\n\nNew method for multi-turn dialogue data augmentation in psychology, using progressive thought and psychology knowledge generators, and a multi-turn dialogue generator.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models\n\n\n\nproduction\n\n\n\nSurvey explores scaling compute during inference in LLMs, focusing on token-level, meta-generation, and efficient generation algorithms.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs\n\n\n\narchitectures\n\n\neducation\n\n\nproduction\n\n\n\nCambrian-1: A family of MLLMs with vision-centric approach, offering new insights into various models, and introducing CV-Bench and Spatial Vision Aggregator (SVA) for…\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdversarial Contrastive Decoding: Boosting Safety Alignment of Large Language Models via Opposite Prompt Optimization\n\n\n\nprompt-engineering\n\n\nsecurity\n\n\narchitectures\n\n\n\nACD: A lightweight, optimization-based method for safer LLM responses, improving safety without heavy training or sacrificing generation ability.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn the Transformations across Reward Model, Parameter Update, and In-Context Prompt\n\n\n\nprompt-engineering\n\n\n\nLLMs can be adapted using three tools: parameter updating, reward modeling, and in-context prompting, offering a unified framework for practical applications.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters\n\n\n\narchitectures\n\n\n\nLanguage-specific draft models speed up multilingual LLM inference time.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRES-Q: Evaluating Code-Editing Large Language Model Systems at the Repository Scale\n\n\n\nprompt-engineering\n\n\narchitectures\n\n\nprogramming\n\n\nproduction\n\n\n\nRES-Q benchmark evaluates LLMs’ ability to edit code repositories, showing Claude Sonnet 3.5 outperforms GPT-4o.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInducing Group Fairness in LLM-Based Decisions\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLLM-based classifiers may lead to unfair decisions; remediation techniques are proposed to improve fairness.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLangSuitE: Planning, Controlling and Interacting with Large Language Models in Embodied Text Environments\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLangSuit⋅⋅⋅E tests LLMs as embodied agents in dynamic textual worlds, offering adaptability, customization, and a novel CoT schema for embodied planning.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis\n\n\n\nprompt-engineering\n\n\nhci\n\n\n\nGraph-augmented LLM framework improves personalized, actionable health insights from wearable data.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoisy Neighbors: Efficient membership inference attacks against LLMs\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nEfficient MIA method for LLMs using noisy neighbors in embedding space, matching shadow models’ effectiveness in privacy auditing.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models\n\n\n\nsecurity\n\n\neducation\n\n\nrobustness\n\n\n\nAutoDetect framework automatically identifies weaknesses in LLMs, improving their performance by over 10%.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSparser is Faster and Less is More: Efficient Sparse Attention for Long-Range Transformers\n\n\n\narchitectures\n\n\n\nSparseK Attention: A novel sparse attention mechanism for efficient, linear-time Transformers with improved performance and seamless integration into LLMs.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlending LLMs into Cascaded Speech Translation: KIT’s Offline Speech Translation System for IWSLT 2024\n\n\n\narchitectures\n\n\nrobustness\n\n\nproduction\n\n\n\nLLM integration in ASR and MT systems improves WER and COMET scores, but not in noisy conditions.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees\n\n\n\narchitectures\n\n\nproduction\n\n\n\nEAGLE-2, an upgrade to EAGLE, offers 20%-40% faster speculative sampling for LLMs, preserving text distribution without loss.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInvestigating the Influence of Prompt-Specific Shortcuts in AI Generated Text Detection\n\n\n\nprompt-engineering\n\n\nsecurity\n\n\nrobustness\n\n\n\nFAILOpt Attack Exploits Shortcuts in AI-Generated Text Detection, Enhances Robustness.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParaphrase and Aggregate with Large Language Models for Minimizing Intent Classification Errors\n\n\n\nrobustness\n\n\n\nLLMs like LLaMa can excel in multi-class classification, but PAG-LLM reduces errors and hallucinated labels, improving performance by up to 22.7%.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFreeTraj: Tuning-Free Trajectory Control in Video Diffusion Models\n\n\n\narchitectures\n\n\nproduction\n\n\n\nTuning-free framework for trajectory-controllable video generation using diffusion models.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRagnarök: A Reusable RAG Framework and Baselines for TREC 2024 Retrieval-Augmented Generation Track\n\n\n\narchitectures\n\n\nproduction\n\n\n\nTREC 2024 RAG Track proposed for evaluating RAG-based search systems, featuring Ragnarök framework and industrial baselines.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPORT: Preference Optimization on Reasoning Traces\n\n\n\nprompt-engineering\n\n\n\nPreference optimization on reasoning steps enhances language model accuracy, as shown by up to 8.47% increase on GSM8K benchmark.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCrosslingual Capabilities and Knowledge Barriers in Multilingual Large Language Models\n\n\n\nsocial-sciences\n\n\n\nLLMs struggle with crosslingual knowledge transfer, but fine-tuning on mixed-language data helps improve performance.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Region-aware Bias Evaluation Metrics\n\n\n\nsocial-sciences\n\n\n\nRegion-aware approach identifies gender bias in language models, outperforming traditional methods.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSerial Position Effects of Large Language Models\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLLMs excel in zero-shot learning but exhibit human-like biases, like primacy and recency effects, which vary in intensity and can be inconsistently mitigated.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPreference Tuning For Toxicity Mitigation Generalizes Across Languages\n\n\n\nsocial-sciences\n\n\nrobustness\n\n\n\nZero-shot preference tuning in English can significantly reduce toxicity in multilingual LLMs, as shown by DPO training results across 17 languages and various models.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReCaLL: Membership Inference via Relative Conditional Log-Likelihoods\n\n\n\nsecurity\n\n\n\nReCall is a new method for detecting pretraining data in large language models, outperforming existing methods and offering insights into model behavior.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEERPD: Leveraging Emotion and Emotion Regulation for Improving Personality Detection\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nEERPD: New method improves personality detection by incorporating emotion regulation, outperforming previous models.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFastMem: Fast Memorization of Prompt Improves Context Awareness of Large Language Models\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nFastMem improves LLMs’ context awareness, boosting accuracy in tasks like comprehension and summarization.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChain-of-Probe: Examing the Necessity and Accuracy of CoT Step-by-Step\n\n\n\nprompt-engineering\n\n\n\nCoP method reveals CoT can be unnecessary, and correct answers may have reasoning errors. CoP prioritizes answers with correct reasoning for reliability.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEffectiveness of ChatGPT in explaining complex medical reports to patients\n\n\n\nhci\n\n\nsocial-sciences\n\n\neducation\n\n\n\nChatGPT struggles to accurately explain complex cancer reports to patients, facing issues like inaccuracies, language, personalization, and distrust.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Text to Test: AI-Generated Control Software for Materials Science Instruments\n\n\n\nhci\n\n\neducation\n\n\n\nLLMs, like ChatGPT-4, can automate scientific instruments and democratize materials research, as demonstrated by controlling a Keithley 2400 and analyzing a…\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrace is the New AutoDiff – Unlocking Efficient Optimization of Computational Workflows\n\n\n\nprompt-engineering\n\n\n\nTrace: A Framework for Optimizing AI Systems with Diverse Feedback and Parameters.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeaching LLMs to Abstain across Languages via Multilingual Feedback\n\n\n\nsocial-sciences\n\n\neducation\n\n\nrobustness\n\n\n\nTL;DR: Multilingual feedback improves LLM abstention, reducing performance gaps between high and low-resource languages in QA tasks.\n\n\n\nJun 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration\n\n\n\nsocial-sciences\n\n\n\nModular Pluralism: A framework for LLMs to model diverse human preferences across communities, offering flexibility and modular control.\n\n\n\nJun 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Fire Thief Is Also the Keeper: Balancing Usability and Privacy in Prompts\n\n\n\nprompt-engineering\n\n\nrobustness\n\n\nhci\n\n\nsecurity\n\n\n\nProSan: A framework for anonymizing prompts in LLMs, maintaining usability, and adapting to resource conditions.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep-Back Profiling: Distilling User History for Personalized Scientific Writing\n\n\n\nsocial-sciences\n\n\n\nStep-back Profiling personalizes LLMs for collaborative scientific writing, outperforming baselines on LaMP benchmark.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models are Skeptics: False Negative Problem of Input-conflicting Hallucination\n\n\n\nrobustness\n\n\n\nLLMs tend to generate false negative responses, but context and query rewriting can help.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrism: A Framework for Decoupling and Assessing the Capabilities of VLMs\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nPrism separates vision and reasoning in VLMs, improving performance and reducing costs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAligning Large Language Models with Diverse Political Viewpoints\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs aligned with diverse political views generate more accurate viewpoints than commercial models like ChatGPT.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDye4AI: Assuring Data Boundary on Generative AI Services\n\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nTL;DR: Dye4AI system tests AI data boundaries by injecting triggers into dialogue, ensuring data security in AI model evolution.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLiveMind: Low-latency Large Language Models with Simultaneous Inference\n\n\n\narchitectures\n\n\neducation\n\n\nprompt-engineering\n\n\n\nNew framework reduces LLM inference latency by up to 93% with incomplete prompts, improving interactive experience and accuracy.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Changes in Nation Perception with Nationality-Assigned Personas in LLMs\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs favor Western Europe, but nationality personas influence focus and favorability towards the assigned region. Biases and stereotypes emerge in LLMs with different…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAugmenting Query and Passage for Retrieval-Augmented Generation using LLMs for Open-Domain Question Answering\n\n\n\neducation\n\n\n\nTL;DR: Improving open-domain QA by augmenting questions and passages with LLMs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM4CP: Adapting Large Language Models for Channel Prediction\n\n\n\narchitectures\n\n\nproduction\n\n\n\n[TEXT] This study examines the relationship between social media use and mental health in adolescents. Results indicate a significant correlation between excessive social…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFVEL: Interactive Formal Verification Environment with Large Language Models via Theorem Proving\n\n\n\narchitectures\n\n\neducation\n\n\nprompt-engineering\n\n\n\nFVEL: LLM-powered Formal Verification in Isabelle improves verification, reducing proof errors, and solving more problems in SV-COMP.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinding Safety Neurons in Large Language Models\n\n\n\nsecurity\n\n\n\nSafety neurons in LLMs can restore 90% safety with 5% intervention, transferable across datasets, and aid in detecting unsafe outputs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHierarchical Micro-Segmentations for Zero-Trust Services via Large Language Model (LLM)-enhanced Graph Diffusion\n\n\n\nsecurity\n\n\n\nThis paper proposes LEGD, a hierarchical micro-segmentation algorithm for efficient zero-trust service provisioning in NGNs, achieving 90% higher efficiency than baselines.…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs\n\n\n\neducation\n\n\n\nTL;DR: Fine-tuning LLMs with KG-derived data enhances planning, improving complex QA task performance.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Spatial Representations in the Historical Lake District Texts with LLM-based Relation Extraction\n\n\n\nsocial-sciences\n\n\n\nAI model extracts spatial relations from English Lake District texts, visualizing historical narratives as a network for deeper understanding.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVAIYAKARANA : A Benchmark for Automatic Grammar Correction in Bangla\n\n\n\nrobustness\n\n\n\nThis work proposes a method to generate grammatically incorrect Bangla sentences for AI training, creating a dataset called Vaiyakarana. Human evaluators outperform AI…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHIGHT: Hierarchical Graph Tokenization for Graph-Language Alignment\n\n\n\nrobustness\n\n\nhci\n\n\n\nHIGHT: New method improves graph-language alignment in LLMs, reducing hallucination and enhancing performance in molecule-language tasks.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeCoKD: Aligning Large Language Models for In-Context Learning with Fewer Shots\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nSeCoKD improves LLMs’ performance with fewer demonstrations, outperforming base models and Supervised Fine-tuning, especially in zero-shot and one-shot settings.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel Merging and Safety Alignment: One Bad Model Spoils the Bunch\n\n\n\narchitectures\n\n\nproduction\n\n\n\nMerging LLMs can propagate misalignment; proposed method integrates alignment-related data, improving domain expertise and alignment.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn Investigation of Prompt Variations for Zero-shot LLM-based Rankers\n\n\n\nprompt-engineering\n\n\n\nPrompt components and wordings significantly impact zero-shot LLM ranking effectiveness, sometimes more than ranking algorithms.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExplicit and Implicit Large Language Model Personas Generate Opinions but Fail to Replicate Deeper Perceptions and Biases\n\n\n\nprompt-engineering\n\n\nproduction\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs with personas struggle to replicate human biases, lacking intrinsic human cognition despite reflecting speech patterns.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerative AI for Enhancing Active Learning in Education: A Comparative Study of GPT-3.5 and GPT-4 in Crafting Customized Test Questions\n\n\n\nprompt-engineering\n\n\neducation\n\n\nhci\n\n\n\nGPT-4 excels at creating complex math questions, improving GPT-3.5’s problem-solving skills, showcasing AI’s potential in personalized education.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRaising the Bar: Investigating the Values of Large Language Models via Generative Evolving Testing\n\n\n\nrobustness\n\n\nsocial-sciences\n\n\n\nTL;DR: GETA dynamically tests LLMs’ moral baselines, addressing the issue of outdated evaluation data, and accurately assesses their values.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGlobal is Good, Local is Bad?: Understanding Brand Bias in LLMs\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs exhibit bias towards global brands, favoring them over local ones, and show country-of-origin effects.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeeing Through AI’s Lens: Enhancing Human Skepticism Towards LLM-Generated Fake News\n\n\n\nrobustness\n\n\nsocial-sciences\n\n\n\nTL;DR: ESAS metric helps identify terms to distinguish human-written vs. LLM-generated news, aiding in detecting fake news.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCityBench: Evaluating the Capabilities of Large Language Model as World Model\n\n\n\neducation\n\n\n\nTL;DR: CityBench is a new evaluation benchmark for LLMs in urban domains, featuring 7 tasks across 13 cities and 13 models.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenderAlign: An Alignment Dataset for Mitigating Gender Bias in Large Language Models\n\n\n\nsocial-sciences\n\n\n\nGenderAlign dataset reduces gender bias in LLMs, offering a new approach to alignment.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCREF: An LLM-based Conversational Software Repair Framework for Programming Tutors\n\n\n\nprogramming\n\n\neducation\n\n\n\nLLMs show potential for program repair, but data leakage is a concern. A new benchmark, TutorCode, is introduced to evaluate LLMs’ repair capabilities. Tutor guidance is…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPersuasiveness of Generated Free-Text Rationales in Subjective Decisions: A Case Study on Pairwise Argument Ranking\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\neducation\n\n\nhci\n\n\n\nLLMs generate persuasive rationales for subjective tasks, with Llama2-70B-chat outperforming GPT models. Persuasiveness improves with parameter control via prompting or…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment\n\n\n\nsocial-sciences\n\n\n\nEnriched image captions increase gender bias and hallucination, cautioning against over-descriptiveness.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData-Centric AI in the Age of Large Language Models\n\n\n\nproduction\n\n\n\nData-centric viewpoint for AI research: Prioritizing data in large language models for benchmarks, attribution, knowledge transfer, and inference contextualization.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSynDARin: Synthesising Datasets for Automated Reasoning in Low-Resource Languages\n\n\n\narchitectures\n\n\nproduction\n\n\n\nSynDARin generates QA datasets for low-resource languages, maintaining quality and diversity, and filtering out poor translations, enabling evaluation of LLMs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmedIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced Clinical Diagnosis on EMRs\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\n\nmedIKAL framework combines LLMs and KGs for precise, enhanced clinical diagnosis using EMRs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLaSA: Large Multimodal Agent for Human Activity Analysis Through Wearable Sensors\n\n\n\neducation\n\n\n\nLLaSA: A Multimodal AI Model for Activity Understanding Using IMUs and LLMs, with Applications in Healthcare and HCI.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMR-BEN: A Comprehensive Meta-Reasoning Benchmark for Large Language Models\n\n\n\nhci\n\n\n\nTL;DR: Mr-Ben benchmark evaluates LLMs’ meta-reasoning skills, revealing gaps in reasoning capabilities.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSEC-QA: A Systematic Evaluation Corpus for Financial QA\n\n\n\narchitectures\n\n\n\nTL;DR: SEC-QA framework generates QA pairs for financial documents, improving complex QA accuracy.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranslating Across Cultures: LLMs for Intralingual Cultural Adaptation\n\n\n\narchitectures\n\n\nproduction\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs can adapt translations to target cultures, outperforming specialized models in cultural sensitivity, but may perpetuate biases.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTaxonomy-Guided Zero-Shot Recommendations with LLMs\n\n\n\nrecommender\n\n\n\nTaxonomy-guided LLM method (TaxRec) improves recommender systems with better item categorization and controlled feature generation.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInvestigating Mysteries of CoT-Augmented Distillation\n\n\n\nproduction\n\n\neducation\n\n\nprompt-engineering\n\n\n\nCoT sequences after labels improve student model performance, even when incoherent or partial. No reasoning needed at test time.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRobust Few-shot Transfer Learning for Knowledge Base Question Answering with Unanswerable Questions\n\n\n\nprompt-engineering\n\n\n\nFUn-FuSIC improves few-shot KBQA with unanswerable questions, outperforming existing models.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Different Design Choices in Training Large Time Series Models\n\n\n\nprompt-engineering\n\n\n\nLTSM-bundle outperforms existing methods in time series forecasting, using novel prompting strategies and best design choices.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models\n\n\n\narchitectures\n\n\nproduction\n\n\nprompt-engineering\n\n\n\nGraphReader outperforms GPT-4-128k on long-context tasks, using a 4k context window and a graph-based agent system.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold\n\n\n\narchitectures\n\n\nproduction\n\n\n\nFinetuning LLMs with model-generated data can improve math reasoning, especially with self-generated correct solutions and per-step negative responses. This approach can…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConnecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data\n\n\n\nproduction\n\n\nsecurity\n\n\n\nLLMs can infer censored knowledge by piecing together scattered hints, posing a challenge for safety and control.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre LLMs Naturally Good at Synthetic Tabular Data Generation?\n\n\n\narchitectures\n\n\nproduction\n\n\n\nLLMs struggle with generating synthetic tables; this paper proposes a permutation-aware approach to improve their performance.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Truthful Multilingual Large Language Models: Benchmarking and Alignment Strategies\n\n\n\narchitectures\n\n\nproduction\n\n\n\nResearch proposes benchmark and method to improve truthfulness and reduce language disparity in multilingual large language models.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMMBench-Video: A Long-Form Multi-Shot Benchmark for Holistic Video Understanding\n\n\n\narchitectures\n\n\nproduction\n\n\n\nMMBench-Video: New Benchmark for Video Understanding with LVLMs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfrican or European Swallow? Benchmarking Large Vision-Language Models for Fine-Grained Object Classification\n\n\n\narchitectures\n\n\nproduction\n\n\n\nTL;DR: FOCI benchmark reveals CLIP models outperform LVLMs in fine-grained object classification, highlighting alignment issues.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQ*: Improving Multi-step Reasoning for LLMs with Deliberative Planning\n\n\n\nrobustness\n\n\n\nQ* framework guides LLMs’ decoding, improving multi-step reasoning without fine-tuning, reducing errors and inconsistencies.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Expert Radiology Report Summarization by Prompting Large Language Models with a Layperson Summary\n\n\n\nproduction\n\n\n\nThis paper presents a novel method for radiology report summarization, improving accuracy and accessibility, especially in out-of-domain tests.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJailbreaking as a Reward Misspecification Problem\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nTL;DR: New system (ReMiss) detects harmful prompts in LLMs, outperforming previous methods.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPEER: Automatic Prompt Engineering Enhances Large Language Model Reranking\n\n\n\narchitectures\n\n\nproduction\n\n\nprompt-engineering\n\n\n\nAPEER: A novel automatic prompt engineering algorithm for relevance ranking, outperforming manual prompts and showing better transferability.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArtificial Leviathan: Exploring Social Evolution of LLM Agents Through the Lens of Hobbesian Social Contract Theory\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs simulate social dynamics, aligning with Hobbes’s Social Contract Theory, offering potential for understanding group behavior and complex human systems.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAsynchronous Large Language Model Enhanced Planner for Autonomous Driving\n\n\n\narchitectures\n\n\nproduction\n\n\n\nAsyncDriver: LLM-enhanced framework for precise, controllable autonomous driving, reducing LLM’s computational cost.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMind the Privacy Unit! User-Level Differential Privacy for Language Model Fine-Tuning\n\n\n\narchitectures\n\n\n\nUser-level DP for LLMs ensures uniform privacy across users, focusing on fine-tuning for natural language generation tasks.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCityGPT: Empowering Urban Spatial Cognition of Large Language Models\n\n\n\nprogramming\n\n\neducation\n\n\n\nCityGPT enhances LLMs’ urban understanding using CityInstruction and CityEval, achieving competitive performance with commercial LLMs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating Implicit Bias in Large Language Models by Attacking From a Psychometric Perspective\n\n\n\nsocial-sciences\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nLLMs exhibit implicit bias, with GLM-3 outperforming GPT-3.5 and GPT-4 in defending against attacks. Deception attacks are most effective.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDoes Object Grounding Really Reduce Hallucination of Large Vision-Language Models?\n\n\n\nrobustness\n\n\n\nGrounding objectives minimally reduce object hallucination in open caption generation, despite previous claims.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSPL: A Socratic Playground for Learning Powered by Large Language Mode\n\n\n\nhci\n\n\nsocial-sciences\n\n\neducation\n\n\nprompt-engineering\n\n\n\nSPL, a GPT-4-powered ITS, improves tutoring dialogues and critical thinking skills in learners.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvidence of a log scaling law for political persuasion with large language models\n\n\n\nproduction\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLarger language models only slightly more persuasive than smaller ones, with task completion being key.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPostMark: A Robust Blackbox Watermark for Large Language Models\n\n\n\nproduction\n\n\nrobustness\n\n\nsocial-sciences\n\n\nsecurity\n\n\n\nPostMark: A post-hoc watermarking method for LLM-generated text, robust to paraphrasing and third-party implementable.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCausal Inference with Latent Variables: Recent Advances and Future Prospectives\n\n\n\nsocial-sciences\n\n\n\nRecent developments in causal inference with unobserved variables, challenges, and future opportunities.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutoCAP: Towards Automatic Cross-lingual Alignment Planning for Zero-shot Chain-of-Thought\n\n\n\nprompt-engineering\n\n\n\nAutoCAP, a zero-shot chain-of-thought method, improves cross-lingual alignment by automatically selecting languages and allocating weights, outperforming manual methods.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThrough the Theory of Mind’s Eye: Reading Minds with Multimodal Video Large Language Models\n\n\n\neducation\n\n\nhci\n\n\n\nLLMs can reason about human emotions and intentions in videos, revealing their ToM reasoning process.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOptimizing Psychological Counseling with Instruction-Tuned Large Language Models\n\n\n\neducation\n\n\nhci\n\n\n\nInstruction-tuned LLMs excel in psychological counseling, offering empathetic, relevant, and supportive responses, outperforming baseline models.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKnowledge Tagging System on Math Questions via LLMs with Flexible Demonstration Retriever\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLMs automate knowledge tagging for questions, outperforming prior methods in math tasks and improving efficiency with a reinforcement learning-based demonstration retriever.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Efficacy of Conversational Artificial Intelligence in Rectifying the Theory of Mind and Autonomy Biases: Comparative Analysis\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nNon-therapeutic chatbots outperform therapeutic ones in rectifying cognitive biases and recognizing affect.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeHonest: Benchmarking Honesty of Large Language Models\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nTL;DR: BeHonest benchmark assesses honesty in LLMs, highlighting room for improvement.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMagicItem: Dynamic Behavior Design of Virtual Objects with Large Language Models in a Consumer Metaverse Platform\n\n\n\nprogramming\n\n\neducation\n\n\n\nTool enables non-programmers to create dynamic behaviors for VR objects in metaverse platforms.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn AI-Inspired UI-Design\n\n\n\nhci\n\n\n\nAI can inspire and assist app design by generating, searching, and creating UI images using LLM, VLM, and DM models.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan LLMs Reason in the Wild with Programs?\n\n\n\nprogramming\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLMs struggle with ambiguous, mixed-scope reasoning; fine-tuning with diverse data helps.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Collaborative Semantics of Language Model-Driven Recommendations via Graph-Aware Learning\n\n\n\nrecommender\n\n\n\nGAL-Rec improves LLM-driven recommendations by enhancing collaborative semantics understanding in interaction graphs.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAgentDojo: A Dynamic Environment to Evaluate Attacks and Defenses for LLM Agents\n\n\n\nsecurity\n\n\n\nAI agents are vulnerable to prompt injection attacks; AgentDojo is a framework to evaluate and improve their adversarial robustness.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKnowledge Graph-Enhanced Large Language Models via Path Selection\n\n\n\nrobustness\n\n\n\nKELP framework improves LLM factual accuracy by flexible KG knowledge extraction.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGUI Action Narrator: Where and When Did That Action Take Place?\n\n\n\nprompt-engineering\n\n\n\nGUI automation is improved with multimodal LLMs, aided by a new video captioning benchmark and framework, GUI Narrator, which uses cursor as visual prompt.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling\n\n\n\nhci\n\n\n\nLangTopo framework aligns LLMs with GNNs for graph structure modeling, improving LLMs’ graph data handling.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStackRAG Agent: Improving Developer Answers with Retrieval-Augmented Generation\n\n\n\nprogramming\n\n\nrobustness\n\n\n\nStackRAG: A tool combining Stack Overflow and LLMs for accurate, reliable coding answers.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinding Blind Spots in Evaluator LLMs with Interpretable Checklists\n\n\n\nrobustness\n\n\neducation\n\n\n\nLLMs often struggle to accurately evaluate text generation in other LLMs, with shortcomings in detecting factual accuracy, coherence, and reasoning proficiency.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVELO: A Vector Database-Assisted Cloud-Edge Collaborative LLM QoS Optimization Framework\n\n\n\nprogramming\n\n\nhci\n\n\n\nVELO framework uses edge-based vector database caching to optimize LLM QoS, reducing response time and costs without altering LLM structure.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation\n\n\n\neducation\n\n\n\nBalDistill improves LLM knowledge distillation for long-tailed data, enhancing distilled model efficiency and efficacy.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemantic Structure-Mapping in LLM and Human Analogical Reasoning\n\n\n\neducation\n\n\nhci\n\n\n\nLLMs approach human-level performance in semantic structure-mapping tasks but aren’t entirely human-like.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistributional reasoning in LLMs: Parallel reasoning processes in multi-hop reasoning\n\n\n\nprompt-engineering\n\n\nhci\n\n\n\nLLMs perform multi-hop reasoning via interpretable embeddings, revealing parallel reasoning paths and potential intermediate answers.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpen Generative Large Language Models for Galician\n\n\n\nsocial-sciences\n\n\n\n[TEXT] This study examines the relationship between social media use and mental health in adolescents. Results indicate a significant correlation between excessive social…\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeveraging Large Language Models for Patient Engagement: The Power of Conversational AI in Digital Health\n\n\n\neducation\n\n\nhci\n\n\n\nLLMs in healthcare improve patient engagement via conversational AI, but raise ethical and regulatory considerations.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdaptable Logical Control for Large Language Models\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nCtrl-G outperforms GPT3.5 and GPT4 in interactive text editing, ensuring LLM outputs follow logical constraints.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNicer Than Humans: How do Large Language Models Behave in the Prisoner’s Dilemma?\n\n\n\nrobustness\n\n\nhci\n\n\nsecurity\n\n\n\nLLM Llama2 shows cooperative behavior in Prisoner’s Dilemma, adopting a cautious approach and favoring forgiveness over retaliation.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models\n\n\n\neducation\n\n\n\nAutoIF is a new method for automatically generating instruction-following training data for LLMs, improving performance across three training algorithms.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Contamination Can Cross Language Barriers\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nNew method detects deep contamination in large language models, evading current methods.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProse-to-P4: Leveraging High Level Languages\n\n\n\nprogramming\n\n\n\nLLMs can translate natural language to high-level networking code, making software development easier.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInvestigating Low-Cost LLM Annotation for~Spoken Dialogue Understanding Datasets\n\n\n\neducation\n\n\n\nImproving Spoken Dialogue Datasets with Fine-tuned Language Models.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJogging the Memory of Unlearned Model Through Targeted Relearning Attack\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nExisting unlearning methods in LLMs can be reversed by targeted relearning attacks, using small, loosely related data sets.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSD-Eval: A Benchmark Dataset for Spoken Dialogue Understanding Beyond Words\n\n\n\nhci\n\n\n\nTL;DR: SD-Eval benchmark assesses spoken dialogue understanding & generation, focusing on paralinguistic & environmental info, with models conditioned on this data…\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLIT: Large Language Model Driven Intention Tracking for Proactive Human-Robot Collaboration – A Robot Sous-Chef Application\n\n\n\nprompt-engineering\n\n\n\nLIT predicts human intentions for proactive robot collaboration, reducing excessive prompting in long-horizon tasks.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearning to Generate Answers with Citations via Factual Consistency Models\n\n\n\nrobustness\n\n\n\nThis paper proposes a method using factual consistency models to improve citation accuracy in LLMs, reducing hallucinations and enhancing reliability.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObscurePrompt: Jailbreaking Large Language Models via Obscure Input\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nObscurePrompt: New method for jailbreaking LLMs, improving attack effectiveness and defense robustness.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvery Language Counts: Learn and Unlearn in Multilingual LLMs\n\n\n\nrobustness\n\n\n\nMultilingual LLMs can spread fake info; standard unlearning methods are inadequate. Comprehensive unlearning strategies needed.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefending Against Social Engineering Attacks in the Age of LLMs\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nLLMs aid digital deception, but struggle with detection. ConvoSentinel, a modular defense pipeline, improves CSE detection and adaptability.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCherryRec: Enhancing News Recommendation Quality via LLM-driven Framework\n\n\n\nrecommender\n\n\nprogramming\n\n\n\nCherryRec: A LLM-based news recommendation framework for efficient, high-quality recommendations.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMAGIC: Generating Self-Correction Guideline for In-Context Text-to-SQL\n\n\n\nrobustness\n\n\n\nMAGIC automates self-correction guideline creation in text-to-SQL, outperforming human-crafted guidelines and improving interpretability.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Did I Do Wrong? Quantifying LLMs’ Sensitivity and Consistency to Prompt Engineering\n\n\n\nprogramming\n\n\n\nLLMs face debugging challenges; new metrics sensitivity and consistency introduced for classification tasks to improve LLM performance and robustness.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHopping Too Late: Exploring the Limitations of Large Language Models on Multi-Hop Queries\n\n\n\nrobustness\n\n\n\nLLMs solve multi-hop queries in later layers, but sometimes lack needed knowledge; back-patching analysis can improve accuracy.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerating Educational Materials with Different Levels of Readability using LLMs\n\n\n\nrobustness\n\n\n\nTL;DR: Few-shot prompting improves AI’s ability to simplify educational texts, but quality concerns remain.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUBENCH: Benchmarking Uncertainty in Large Language Models with Multiple Choice Questions\n\n\n\neducation\n\n\n\nUBench is a new benchmark for evaluating LLM reliability, offering improved performance and resource efficiency. It finds GLM4 and GPT-4 as the most reliable LLMs.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPFID: Privacy First Inference Delegation Framework for LLMs\n\n\n\nrobustness\n\n\n\nPFID framework for LLMs enhances privacy by localizing user data, using model sharding, and singular value decomposition, while maintaining system performance.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBreaking the Ceiling of the LLM Community by Treating Token Generation as a Classification for Ensembling\n\n\n\nrobustness\n\n\n\nGaC: Ensembling LLMs by treating token generation as classification improves performance and reduces latency.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?\n\n\n\neducation\n\n\n\nLLMs, like GPT-4, show inconsistency despite high capability; harder data boosts consistency.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSNAP: Unlearning Selective Knowledge in Large Language Models with Negative Instructions\n\n\n\nprogramming\n\n\nrobustness\n\n\n\nSnap framework selectively unlearns information from LLMs, preserving performance and unlearning specified data.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn the Robustness of Language Models for Tabular Question Answering\n\n\n\neducation\n\n\n\nLLMs, like Llama3, excel in table comprehension, but improvements are needed for robustness and handling domain-specific data.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretable Catastrophic Forgetting of Large Language Model Fine-tuning via Instruction Vector\n\n\n\nprogramming\n\n\n\nFine-tuning LLMs may not erase previous skills, but add specialized reasoning; IV-guided training mitigates catastrophic forgetting.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn-Policy Fine-grained Knowledge Feedback for Hallucination Mitigation\n\n\n\nrobustness\n\n\n\nRLFH is an online reinforcement learning method for hallucination mitigation in LLMs, using fine-grained feedback and an LLM-based fact assessment framework.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBenchmarks and Metrics for Evaluations of Code Generation: A Critical Review\n\n\n\nprogramming\n\n\n\nThis paper reviews methods for testing and evaluating LLMs in code generation, focusing on benchmarks and metrics.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards a Client-Centered Assessment of LLM Therapists by Client Simulation\n\n\n\nsecurity\n\n\n\nThis work proposes ClientCAST, an approach using LLMs to simulate clients and assess LLM therapists, focusing on session outcome, therapeutic alliance, and self-reported…\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM4MSR: An LLM-Enhanced Paradigm for Multi-Scenario Recommendation\n\n\n\nrecommender\n\n\n\nLLM4MSR: Efficient, Effective, Interpretable Multi-Scenario Recommendation Paradigm using LLM.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing LLMs to Aid Annotation and Collection of Clinically-Enriched Data in Bipolar Disorder and Schizophrenia\n\n\n\neducation\n\n\n\nSmall language models excel in mental health research, outperforming large models in annotation, data collection, and scalability.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCleanGen: Mitigating Backdoor Attacks for Generation Tasks in Large Language Models\n\n\n\nprogramming\n\n\nrobustness\n\n\nsecurity\n\n\n\nCleanGen: A defense strategy for LLMs that mitigates backdoor attacks, reducing attack success rates with minimal computational overhead.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-enhanced Reranking in Recommender Systems\n\n\n\nrecommender\n\n\n\nLLM-enhanced reranking framework improves accuracy, diversity, and fairness in recommendations, outperforming existing models.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond Under-Alignment: Atomic Preference Enhanced Factuality Tuning for Large Language Models\n\n\n\nrobustness\n\n\n\nLLMs struggle with factuality in OOD datasets; APEFT framework improves factuality by 3.45% on average.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentifying Performance-Sensitive Configurations in Software Systems through Code Analysis with LLM Agents\n\n\n\nrobustness\n\n\neducation\n\n\n\nPerfSense, an LLM-based framework, accurately identifies performance-sensitive configurations, outperforming previous methods and offering insights for future research.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdversarial Attacks on Large Language Models in Medicine\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nLLMs in healthcare are vulnerable to adversarial attacks, requiring robust security measures for safe deployment.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNavigating the Labyrinth: Evaluating and Enhancing LLMs’ Ability to Reason About Search Problems\n\n\n\nprogramming\n\n\n\nLLMs struggle with logic problems; in-context learning with A* algorithm and Multi-Stage-Multi-Try method improves performance.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJailbreak Paradox: The Achilles’ Heel of LLMs\n\n\n\nsecurity\n\n\n\nJailbreaking foundation models: Perfect detection is impossible, and weaker models can’t consistently detect jailbreaks in stronger models.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan We Trust Large Language Models Generated Code? A Framework for In-Context Learning, Security Patterns, and Code Evaluations Across Diverse LLMs\n\n\n\nprogramming\n\n\nrobustness\n\n\nsecurity\n\n\n\nLLMs for code generation may perpetuate vulnerabilities; ICL-driven learning can enhance code security, reducing risks in various programming scenarios.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPRePair: Pointwise Reasoning Enhance Pairwise Evaluating for Robust Instruction-Following Assessments\n\n\n\nsecurity\n\n\n\nLLMs’ biases impact pairwise evaluations more; hybrid method integrating pointwise reasoning improves robustness.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey on Human Preference Learning for Large Language Models\n\n\n\nrecommender\n\n\n\nThis survey explores human preference learning for large language models, covering feedback sources, modeling, usage, and evaluation.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodeNav: Beyond tool-use to using real-world codebases with LLM agents\n\n\n\nprogramming\n\n\n\nCodeNav: LLM agent navigates unseen code repositories, solving queries without manual tool registration, and outperforms tool-use agents in benchmarks.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPDSS: A Privacy-Preserving Framework for Step-by-Step Distillation of Large Language Models\n\n\n\nsecurity\n\n\n\nPDSS: Privacy-preserving framework distills LLMs for domain-specific tasks, ensuring data privacy and improved performance in text generation tasks.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTalk With Human-like Agents: Empathetic Dialogue Through Perceptible Acoustic Reception and Reaction\n\n\n\nrobustness\n\n\n\nPerceptiveAgent: LLM-based dialogue system discerns deeper meanings using speech modality, improving contextual understanding and empathetic responses.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf and Cross-Model Distillation for LLMs: Effective Methods for Refusal Pattern Alignment\n\n\n\nprogramming\n\n\n\nLLMs can be secured against toxic prompts via alignment techniques like SFT and RLHF. Distillation methods, especially cross-model, significantly improve refusal rates and…\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-Layer Ranking with Large Language Models for News Source Recommendation\n\n\n\nrecommender\n\n\n\nLLMs improve expert recommendation for news events, using a multi-layer ranking framework on the NewsQuote dataset.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShould AI Optimize Your Code? A Comparative Study of Current Large Language Models Versus Classical Optimizing Compilers\n\n\n\nprogramming\n\n\n\nLLMs, like CodeLlama-70B, show potential in code optimization, but may generate incorrect code on large sizes, requiring automated verification. CETUS is the top optimizing…\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIterative or Innovative? A Problem-Oriented Perspective for Code Optimization\n\n\n\nprogramming\n\n\n\nThis paper explores code optimization with LLMs, focusing on execution time reduction. It introduces a problem-oriented approach, significantly improving optimization…\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Critical Study of What Code-LLMs (Do Not) Learn\n\n\n\nprogramming\n\n\n\nCode-LLMs struggle to encode relations between syntax and identifiers, with larger models encoding less code info than smaller ones.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nREPOEXEC: Evaluate Code Generation with a Repository-Level Executable Benchmark\n\n\n\nprogramming\n\n\n\nRepoExec benchmark evaluates code generation at repository-level, focusing on executability, correctness, and dependency integration.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDocCGen: Document-based Controlled Code Generation\n\n\n\nprogramming\n\n\n\nDocCGen improves LLMs for structured DSLs like YAML, JSON by leveraging documentation for better code generation.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRePrompt: Planning by Automatic Prompt Engineering for Large Language Models Agents\n\n\n\nprogramming\n\n\n\nRePrompt optimizes LLM prompts for better performance in tasks like code generation and travel planning.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDELRec: Distilling Sequential Pattern to Enhance LLM-based Recommendation\n\n\n\nrecommender\n\n\n\nDELRec framework improves sequential recommendations by extracting patterns from SR models and integrating them into LLMs, enhancing their performance.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLong Code Arena: a Set of Benchmarks for Long-Context Code Models\n\n\n\nprogramming\n\n\n\nLong Code Arena: Benchmarks for Project-wide Code Processing Tasks\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWaDec: Decompile WebAssembly Using Large Language Model\n\n\n\nprogramming\n\n\n\nWaDec, a fine-tuned LLM, decompiles Wasm binary code into readable source code, outperforming current tools with improved metrics and code comprehension.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey on Human Preference Learning for Large Language Models\n\n\n\nrecommender\n\n\n\nThis survey explores human preference learning for LLMs, covering feedback sources, modeling, usage, and evaluation.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoSQA+: Enhancing Code Search Dataset with Matching Code\n\n\n\nprogramming\n\n\n\nCoSQA+ improves code search with diverse, high-quality query-code pairs, outperforming CoSQA and introducing a new metric, MMRR.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging\n\n\n\nprogramming\n\n\n\nTreeInstruct, a state-space planning-based agent, effectively guides students in debugging code using Socratic questioning.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnveiling Assumptions: Exploring the Decisions of AI Chatbots and Human Testers\n\n\n\nprogramming\n\n\n\nLLM-based chatbots can aid software testers in decision-making, with some aligning with human intuition in preferring diverse test scenarios.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Collaborative Data Analytics System with Recommender for Diverse Users\n\n\n\nrecommender\n\n\n\nSLEGO system bridges developer-novice gap with modular microservices, GUI, and LLM-powered recommendations, democratizing data analytics.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen Box Meets Graph Neural Network in Tag-aware Recommendation\n\n\n\nrecommender\n\n\n\nTL;DR: BoxGNN improves tag-aware recommender systems by modeling user preferences with high-order signals and box embeddings.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models for Automatic Milestone Detection in Group Discussions\n\n\n\nprogramming\n\n\n\nAuthors submit electronic manuscripts for IJCAI–24 Proceedings, which will be printed and included in the online version.\n\n\n\nJun 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3D Building Generation in Minecraft via Large Language Models\n\n\n\nprogramming\n\n\n\nLLMs can generate complete 3D buildings in Minecraft, including facades, indoor scenes, and functional blocks, with user-specified requirements.\n\n\n\nJun 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhere Do Large Language Models Fail When Generating Code?\n\n\n\nprogramming\n\n\n\nLLMs struggle with reliable code generation, exhibiting varied semantic and syntactic errors. Different factors impact these errors, posing challenges for future LLM code…\n\n\n\nJun 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Next Era of Multi-objective Optimization: Large Language Models as Architects of Evolutionary Operators\n\n\n\nprogramming\n\n\n\nTL;DR: LLM-based framework evolves EA operators for MOPs, reducing expert intervention and improving performance.\n\n\n\nJun 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-Agent Software Development through Cross-Team Collaboration\n\n\n\nprogramming\n\n\n\nCross-Team Collaboration (CTC) improves LLM-driven software development quality by exploring multiple decision paths.\n\n\n\nJun 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving LLMs for Recommendation with Out-Of-Vocabulary Tokens\n\n\n\nrecommender\n\n\n\nTL;DR: Improving LLM-based recommender systems with out-of-vocabulary tokens for better user-item representation.\n\n\n\nJun 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTHaLLE: Text Hyperlocally Augmented Large Language Extension – Technical Report\n\n\n\narchitectures\n\n\nproduction\n\n\nprompt-engineering\n\n\neducation\n\n\n\nLLMs show promise in financial analysis, with our 8B THaLLE models outperforming others on mock CFA exams.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPITCH: Productivity and Mental Well-being Coaching through Daily Conversational Interaction\n\n\n\nproduction\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\nhci\n\n\n\nPITCH: A conversational AI for productivity, using rotating prompts to boost engagement and mental well-being.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVersiCode: Towards Version-controllable Code Generation\n\n\n\narchitectures\n\n\nproduction\n\n\nprogramming\n\n\n\nTL;DR: VersiCode dataset tests LLMs’ ability to generate version-correct code, revealing challenges and limitations.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaying More Attention to Source Context: Mitigating Unfaithful Translations from Large Language Model\n\n\n\nrobustness\n\n\n\nLLMs can generate unfaithful translations due to bias towards target tokens. Our methods encourage LLMs to focus more on source context, reducing hallucinatory translations.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRS-Agent: Automating Remote Sensing Tasks through Intelligent Agents\n\n\n\nprompt-engineering\n\n\n\nTL;DR: RS-Agent: A LLM-driven remote sensing agent excelling in complex tasks, outperforming in scene classification, visual question answering, and object counting.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFaceGPT: Self-supervised Learning to Chat about 3D Human Faces\n\n\n\neducation\n\n\n\nFaceGPT: Self-supervised 3D face reconstruction from images and text, without 3D annotations.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMerging Improves Self-Critique Against Jailbreak Attacks\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nMerging and self-critique improve LLM robustness against jailbreak attacks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHalluDial: A Large-Scale Benchmark for Automatic Dialogue-Level Hallucination Evaluation\n\n\n\nrobustness\n\n\n\nHalluDial: A Comprehensive Benchmark for Automatic Dialogue-Level Hallucination Evaluation in LLMs.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProgressive Query Expansion for Retrieval Over Cost-constrained Data Sources\n\n\n\nrobustness\n\n\n\nProQE combines PRF and LLMs for progressive query expansion, improving accuracy and cost-effectiveness in retrieval systems.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDR-RAG: Applying Dynamic Document Relevance to Retrieval-Augmented Generation for Question-Answering\n\n\n\narchitectures\n\n\n\nDR-RAG improves QA accuracy by enhancing document retrieval, using a two-stage framework and a small classifier, while maintaining efficiency.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvancing Annotation of Stance in Social Media Posts: A Comparative Analysis of Large Language Models and Crowd Sourcing\n\n\n\nproduction\n\n\nsocial-sciences\n\n\n\nLLMs’ stance annotation accuracy depends on text’s explicitness, often mirroring human performance.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuickLLaMA: Query-aware Inference Acceleration for Large Language Models\n\n\n\narchitectures\n\n\nproduction\n\n\n\nQ-LLM enhances LLMs’ context understanding, improving accuracy on benchmarks without extra training.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEfficiently Exploring Large Language Models for Document-Level Machine Translation with In-context Learning\n\n\n\nprompt-engineering\n\n\n\nLLMs struggle with document-level translation. Our Context-Aware Prompting method (CAP) improves LLM translation accuracy, cohesion, and coherence.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3D-Properties: Identifying Challenges in DPO and Charting a Path Forward\n\n\n\narchitectures\n\n\nsocial-sciences\n\n\neducation\n\n\n\nDPO in LLMs: Examining 3D-properties, issues, and solutions for better alignment with human preference.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Large Language Models for Relevance Judgments in Tetun\n\n\n\narchitectures\n\n\n\nLLMs can automate relevance assessments in low-resource languages, with results similar to high-resource languages.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDCA-Bench: A Benchmark for Dataset Curation Agents\n\n\n\narchitectures\n\n\n\nLLMs can help curate datasets, but real-world issues are complex. DCA-Bench measures LLM agents’ ability to detect dataset quality issues.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nValidating LLM-Generated Programs with Metamorphic Prompt Testing\n\n\n\nrobustness\n\n\nsecurity\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\nTL;DR: Metamorphic prompt testing detects 75% of GPT-4’s erroneous code, with 8.6% false positives.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Tool for Test Case Scenarios Generation Using Large Language Models\n\n\n\nhci\n\n\nprompt-engineering\n\n\neducation\n\n\nprogramming\n\n\n\nTL;DR: Tool generates test case scenarios from user requirements using an LLM-based agent.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models for Constrained-Based Causal Discovery\n\n\n\nhci\n\n\n\nLLMs can assist in causal graph generation, but performance varies. A statistical-inspired voting schema improves results, suggesting potential for knowledge-based CIT in…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBertaQA: How Much Do Language Models Know About Local Culture?\n\n\n\nsocial-sciences\n\n\n\nLLMs struggle with local cultural knowledge but improve with continued pre-training in that language.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees\n\n\n\nprogramming\n\n\n\nTP-LLaMA model outperforms baselines in tool-augmented LLMs by optimizing inference trajectories using preference data from decision trees, enhancing utilization of expert…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoEvol: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation\n\n\n\nhci\n\n\neducation\n\n\n\nCoEvol: LLM-based framework improves instruction responses, outperforming baselines in MT-Bench and AlpacaEval.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understanding in Video-LLMs\n\n\n\nproduction\n\n\neducation\n\n\n\nVideoLLaMA 2 improves video and audio understanding with competitive results in multimodal tasks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeaching Language Models to Self-Improve by Learning from Language Feedback\n\n\n\nsocial-sciences\n\n\n\nSRT uses model feedback for alignment, reducing reliance on human annotations, and significantly improves model performance across tasks and sizes.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpen-LLM-Leaderboard: From Multi-choice to Open-style Questions for LLMs Evaluation, Benchmark, and Arena\n\n\n\narchitectures\n\n\nproduction\n\n\nprompt-engineering\n\n\nhci\n\n\n\nLLMs may favor certain answer IDs due to biases. Open-style questions can eliminate this, but pose new challenges. We introduce the Open-LLM-Leaderboard to track LLM…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOPTune: Efficient Online Preference Tuning\n\n\n\nrecommender\n\n\n\nTL;DR: OPTune speeds up online preference tuning for LLMs, maintaining benefits while reducing training time.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGuiding LLM Temporal Logic Generation with Explicit Separation of Data and Control\n\n\n\narchitectures\n\n\n\nLLMs can improve reactive program synthesis by separating control and data in temporal logic specifications, enhancing specification generation.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOllabench: Evaluating LLMs’ Reasoning for Human-centric Interdependent Cybersecurity\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nOllaBench evaluates LLMs for cybersecurity, revealing commercial models lead in accuracy but have room for improvement, while smaller open-weight models show promise.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards more realistic evaluation of LLM-based code generation: an experimental study and beyond\n\n\n\nrobustness\n\n\nprogramming\n\n\n\n[TEXT] This study examines the impact of social media on the mental health of adolescents. Results indicate a significant correlation between excessive social media use and…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstruct Large Language Models to Drive like Humans\n\n\n\narchitectures\n\n\n\nInstructDriver: Transforming LLM into a motion planner with human-aligned behavior for autonomous driving.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMBBQ: A Dataset for Cross-Lingual Comparison of Stereotypes in Generative LLMs\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLLMs exhibit language-dependent biases, with non-English languages suffering more. MBBQ dataset reveals cross-lingual differences in bias behavior.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReinforcement Learning from Human Feedback without Reward Inference: Model-Free Algorithm and Instance-Dependent Analysis\n\n\n\narchitectures\n\n\nproduction\n\n\n\nRLHF not harder than classic RL; end-to-end RLHF can improve performance by avoiding pitfalls in reward inference.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWorld Models with Hints of Large Language Models for Goal Achieving\n\n\n\nproduction\n\n\nhci\n\n\n\nDLLM, a multi-modal RL approach, improves exploration in long-horizon tasks by integrating hinting subgoals from LLMs, outperforming recent methods in sparse-reward…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDARA: Decomposition-Alignment-Reasoning Autonomous Language Agent for Question Answering over Knowledge Graphs\n\n\n\nhci\n\n\nprompt-engineering\n\n\n\nDARA framework improves LLM-powered agents’ KGQA performance, outperforming in-context learning-based agents and alternative fine-tuned agents.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSingle-Codec: Single-Codebook Speech Codec towards High-Performance Speech Generation\n\n\n\nproduction\n\n\n\nSingle-Codec, a single-sequence codec, improves TTS efficiency and robustness, outperforming multi-codebook codecs in quality, bandwidth, and LLM-TTS performance.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeveraging Large Language Models for Efficient Failure Analysis in Game Development\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nThis paper presents a method using Large Language Models to automatically identify code changes causing test failures, achieving 71% accuracy and reducing debugging time by…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nToxic Memes: A Survey of Computational Perspectives on the Detection and Explanation of Meme Toxicities\n\n\n\narchitectures\n\n\nhci\n\n\nsocial-sciences\n\n\n\nSurvey on toxic memes: new taxonomy, trends, and challenges in computational analysis.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCAAP: Context-Aware Action Planning Prompting to Solve Computer Tasks with Front-End UI Only\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nLLM-based agent uses screenshots for context, achieving 94.4% success on MiniWoB++ problems with 1.48 demos per type, enabling broader automation applications.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLimited Out-of-Context Knowledge Reasoning in Large Language Models\n\n\n\narchitectures\n\n\nproduction\n\n\neducation\n\n\n\nLLMs struggle with out-of-context reasoning and cross-lingual knowledge transfer, despite training adjustments.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Probabilistic Framework for LLM Hallucination Detection via Belief Tree Propagation\n\n\n\nrobustness\n\n\n\nBTProp: New method improves hallucination detection in LLMs by 3%-9% via a belief tree and hidden Markov tree model.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraphCoder: Enhancing Repository-Level Code Completion via Code Context Graph-based Retrieval and Language Model\n\n\n\nprogramming\n\n\n\nGraphCoder improves code completion with a graph-based retrieval-generation process, outperforming baseline methods in accuracy and efficiency.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTextGrad: Automatic Differentiation via Text\n\n\n\narchitectures\n\n\nproduction\n\n\n\nTextGrad optimizes compound AI systems by backpropagating textual feedback, improving performance across various tasks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMcEval: Massively Multilingual Code Evaluation\n\n\n\narchitectures\n\n\nprogramming\n\n\neducation\n\n\nproduction\n\n\nprompt-engineering\n\n\n\nTL;DR: Introducing McEval, a multilingual code benchmark for 40 languages, challenging LLMs in code tasks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Human-AI Collaboration in Healthcare: Guided Deferral Systems with Large Language Models\n\n\n\nsocial-sciences\n\n\n\nTL;DR: Human-AI collaboration improves LLMs’ reliability in healthcare, reducing uncertainty via a guided deferral system.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat’s in an embedding? Would a rose by any embedding smell as sweet?\n\n\n\neducation\n\n\n\n[TEXT] This study examines the relationship between social media use and mental health in young adults. Results suggest a negative correlation between excessive social media…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJoint Demonstration and Preference Learning Improves Policy Alignment with Human Feedback\n\n\n\nsocial-sciences\n\n\n\nTL;DR: AIHF outperforms RLHF and DPO in aligning human preference and value in AI, especially with limited data.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAccessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B\n\n\n\narchitectures\n\n\neducation\n\n\n\nMCTSr algorithm improves LLMs’ mathematical reasoning by integrating Monte Carlo Tree Search, enhancing accuracy in complex tasks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnomaly Detection on Unstable Logs with GPT Models\n\n\n\narchitectures\n\n\nproduction\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\nLLM (GPT-3) outperforms supervised baselines for anomaly detection on unstable logs, with fine-tuning superior to prompt engineering.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnnotation alignment: Comparing LLM and human annotations of conversational safety\n\n\n\nsecurity\n\n\nsocial-sciences\n\n\n\nGPT-4 aligns with human safety perceptions, but more data is needed to assess demographic disparities and idiosyncratic variation.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey of Backdoor Attacks and Defenses on Large Language Models: Implications for Security Measures\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nTL;DR: This paper explores backdoor attacks on large language models, categorizing them by fine-tuning methods and discussing future research directions.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDecision-Making Behavior Evaluation Framework for LLMs under Uncertain Context\n\n\n\nrobustness\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLLMs, like ChatGPT-4.0-Turbo, Claude-3-Opus, and Gemini-1.0-pro, exhibit human-like decision-making patterns but vary in risk, probability, and loss aversion. Ethical…\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan Language Models Serve as Text-Based World Simulators?\n\n\n\nsocial-sciences\n\n\n\nLLMs, like GPT-4, are not yet reliable text-based world simulators, despite their capabilities, as per the ByteSized32-State-Prediction benchmark.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow Efficient is LLM-Generated Code? A Rigorous & High-Standard Benchmark\n\n\n\nprogramming\n\n\n\nLLMs struggle to generate expert-level efficient code, per new benchmark ENAMEL, which evaluates efficiency and correctness of LLM-generated code.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStronger, Faster, and Cheaper Log Parsing with LLMs\n\n\n\neducation\n\n\n\nLogBatcher: Cost-effective LLM-based log parser with no training or labeled data, using clustering and cache matching for efficient parsing.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course\n\n\n\nsocial-sciences\n\n\nprogramming\n\n\neducation\n\n\nhci\n\n\nprompt-engineering\n\n\n\nStudents’ LLM usage in programming education influenced by career expectations, peer usage, and affects self-efficacy and midterm performance.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn Empirical Design Justice Approach to Identifying Ethical Considerations in the Intersection of Large Language Models and Social Robotics\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLLMs in social robotics offer benefits but raise ethical concerns like misinformation, biased responses, and emotional disruption, exacerbated by physical embodiment.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs\n\n\n\nhci\n\n\n\nTL;DR: Our method uses context-aware, query-relevant knowledge graphs to improve LLM performance on complex questions, reducing token usage by up to 67%.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMolX: Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension\n\n\n\neducation\n\n\n\nLLMs struggle with molecule-related tasks; this study introduces MolX, a multi-modal external module, to enhance LLMs’ molecule comprehension, outperforming baselines in…\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Food Safety in Supply Chains: The Potential Role of Large Language Models in Preventing Campylobacter Contamination\n\n\n\nrobustness\n\n\n\nTL;DR: GPTs can aid HACCP implementation to reduce Campylobacter contamination in the food supply chain, but barriers exist.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan I understand what I create? Self-Knowledge Evaluation of Large Language Models\n\n\n\nsocial-sciences\n\n\n\nLLMs struggle with self-generated questions due to human-alignment issues, but fine-tuning improves math performance.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLanguage Models Resist Alignment\n\n\n\nrobustness\n\n\n\nAlignment fine-tuning in LLMs is elastic and can revert to pre-training behavior, especially with larger models and more pre-training data.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSynth-SBDH: A Synthetic Dataset of Social and Behavioral Determinants of Health for Clinical Text\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nSynth-SBDH dataset improves SBDH extraction from clinical text, outperforming counterparts and proving effective for rare categories and resource constraints.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRepoQA: Evaluating Long Context Code Understanding\n\n\n\neducation\n\n\n\nRepoQA benchmark evaluates LLMs on long-context code understanding, showing gaps in open vs. proprietary models and language-specific strengths.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedExQA: Medical Question Answering Benchmark with Multiple Explanations\n\n\n\neducation\n\n\n\nMedExQA benchmark evaluates medical knowledge in LLMs via explanations, highlighting the need for explainability. New medical model, MedPhi-2, outperforms Llama2-based…\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecureNet: A Comparative Study of DeBERTa and Large Language Models for Phishing Detection\n\n\n\nrobustness\n\n\nsecurity\n\n\neducation\n\n\n\nTL;DR: DeBERTa V3 outperforms LLMs like GPT-4 in detecting phishing content, achieving 95.17% recall, while GPT-4 scores 91.04%.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM2CVD: Multi-Model Collaboration for Code Vulnerability Detection\n\n\n\nrobustness\n\n\nsecurity\n\n\nprogramming\n\n\n\nM2CVD combines LLMs and code models for improved vulnerability detection, outperforming baselines on real-world datasets.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models\n\n\n\nrobustness\n\n\nsecurity\n\n\nprompt-engineering\n\n\n\nTL;DR: Chain-of-Scrutiny (CoS) is a user-friendly, black-box defense against backdoor attacks in LLMs, ensuring reasoning consistency to detect attacks.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating the Retrieval Component in LLM-Based Question Answering Systems\n\n\n\nhci\n\n\n\nBaseline for evaluating retrievers in RAG-based chatbots shows better performance assessment, considering LLMs’ strengths and weaknesses.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection\n\n\n\nrobustness\n\n\nsecurity\n\n\nprogramming\n\n\n\nCodeBreaker: LLM-assisted backdoor attack framework for code completion models, evading vulnerability detection.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSilent Signals, Loud Impact: LLMs for Word-Sense Disambiguation of Coded Dog Whistles\n\n\n\nsocial-sciences\n\n\n\nLLMs used to create dataset of 16,550 disambiguated dog whistle examples for hate speech detection and political science.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSafety Alignment Should Be Made More Than Just a Few Tokens Deep\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nShallow safety alignment in LLMs can lead to vulnerabilities; deepening alignment beyond initial tokens can improve robustness.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHarnessing AI for efficient analysis of complex policy documents: a case study of Executive Order 14110\n\n\n\nsecurity\n\n\n\nAI systems Gemini 1.5 Pro and Claude 3 Opus excel in policy document analysis, rivaling human experts in accuracy but with greater efficiency.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTransforming Wearable Data into Health Insights using Large Language Model Agents\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nPHIA, a new AI system, accurately interprets wearable health data, potentially enabling personalized wellness insights.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLanguage Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain\n\n\n\nsecurity\n\n\n\nNew dataset for medical triage decision-making; LLMs used as ethical decision-makers, alignable to different attributes.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Context Learning and Fine-Tuning GPT for Argument Mining\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nGPT-4 and GPT-3.5 excel in Argument Type Classification using In-Context Learning and fine-tuning, respectively.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niMotion-LLM: Motion Prediction Instruction Tuning\n\n\n\nrobustness\n\n\nhci\n\n\n\niMotion-LLM: A multimodal model for trajectory prediction in multi-agent scenarios, guided by textual instructions, enhancing safety and contextual relevance.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRaccoon: Prompt Extraction Benchmark of LLM-Integrated Applications\n\n\n\nrobustness\n\n\nsecurity\n\n\nprompt-engineering\n\n\neducation\n\n\n\nRaccoon benchmark evaluates LLM susceptibility to prompt extraction attacks, offering insights and defenses.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge language models for generating rules, yay or nay?\n\n\n\nprogramming\n\n\n\nLLMs can aid engineering safety-critical systems by generating logic rules, but lack threshold generation ability.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards a Personal Health Large Language Model\n\n\n\neducation\n\n\n\nPH-LLM, a fine-tuned Gemini model, excels in personal health insights, outperforming experts in fitness and nearing their level in sleep, while accurately predicting sleep…\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024\n\n\n\nhci\n\n\neducation\n\n\nsocial-sciences\n\n\n\nTeam HYU_MLLAB_KT solves SMART-101 CVPR 2024 challenge with LLM and object detection, achieving 29.5 accuracy on test set and 27.1 WOSA on challenge set.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShould We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue\n\n\n\nhci\n\n\neducation\n\n\n\nLLM adaptation techniques vary in effectiveness based on base LLM and dialogue type; human evaluation is crucial.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Superalignment Framework in Autonomous Driving with Large Language Models\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nTL;DR: Novel security framework for autonomous vehicles using multi-agent LLM approach, ensuring data protection and adherence to regulations.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n61A-Bot: AI homework assistance in CS1 is fast and cheap – but is it helpful?\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\n61A-Bot reduces homework completion time, but effects may not transfer to assignments without bot access.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMoPS: Modular Story Premise Synthesis for Open-Ended Automatic Story Generation\n\n\n\nsocial-sciences\n\n\neducation\n\n\n\nMoPS generates diverse, fascinating, and original story premises for automatic story generation, outperforming existing methods.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nZero-Shot End-To-End Spoken Question Answering In Medical Domain\n\n\n\nhci\n\n\n\nE2E methodologies for SQA in the medical domain require fewer resources and improve accuracy compared to traditional cascade systems.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Comprehensive Evaluation of Parameter-Efficient Fine-Tuning on Automated Program Repair\n\n\n\nprompt-engineering\n\n\n\nPEFT methods improve LLMs’ bug-fixing capabilities in APR, outperforming existing techniques. Larger parameters/datasets don’t guarantee better performance.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey on LLM-Based Agentic Workflows and LLM-Profiled Components\n\n\n\nprompt-engineering\n\n\n\nLLMs enable advanced workflows, focusing on reusable components for clearer role understanding.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Against the RAG: Jamming Retrieval-Augmented Generation with Blocker Documents\n\n\n\nrobustness\n\n\n\nTL;DR: RAG systems are vulnerable to jamming attacks using blocker documents, which can prevent them from answering queries. New methods for generating blocker documents are…\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models Memorize Sensor Datasets! Implications on Human Activity Recognition Research\n\n\n\nrobustness\n\n\n\nLLMs may have seen HAR benchmark data during training, potentially skewing evaluation results.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre Large Language Models Actually Good at Text Style Transfer?\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLLMs struggle with TST in non-English languages, but finetuning improves results, highlighting the need for dedicated datasets.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMrRank: Improving Question Answering Retrieval System through Multi-Result Ranking Model\n\n\n\nrobustness\n\n\n\nNew method combines IR systems for LLMs, improving performance and reducing hallucinations.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDigital Business Model Analysis Using a Large Language Model\n\n\n\nhci\n\n\nprogramming\n\n\n\nThis study proposes an LLM-based method for comparing and analyzing similar companies across different business domains to support digital business model design.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecurity Vulnerability Detection with Multitask Self-Instructed Fine-Tuning of Large Language Models\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\nsecurity\n\n\neducation\n\n\n\nMSIVD: Multitask LLM & GNN technique improves vulnerability detection, outperforming existing methods with F1 scores of 0.92 (BigVul) and 0.48 (PreciseBugs).\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHello Again! LLM-powered Personalized Agent for Long-term Dialogue\n\n\n\nhci\n\n\n\nLD-Agent: A framework for long-term dialogue systems with event memory, persona modeling, and response generation.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDomainRAG: A Chinese Benchmark for Evaluating Domain-specific Retrieval-Augmented Generation\n\n\n\neducation\n\n\n\nRAG models outperform LLMs in domain-specific tasks like college enrollment, but improvements are needed in areas like conversation, structure analysis, and denoising.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo LLMs Exhibit Human-Like Reasoning? Evaluating Theory of Mind in LLMs for Open-Ended Responses\n\n\n\nhci\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLLMs struggle with Theory of Mind reasoning in open-ended questions, but incorporating human intentions and emotions can improve their performance, though not fully…\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States\n\n\n\nrobustness\n\n\n\nLLMs learn ethics in pre-training, align concepts with emotions, and refine for safe output. Jailbreaks disrupt this process, causing harm.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLGR2: Language Guided Reward Relabeling for Accelerating Hierarchical Reinforcement Learning\n\n\n\nhci\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\nprogramming\n\n\n\nLGR2: A language-guided HRL framework for robotic control, mitigating non-stationarity and achieving high success rates in complex tasks.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreativity Has Left the Chat: The Price of Debiasing Language Models\n\n\n\nhci\n\n\nprompt-engineering\n\n\n\nRLHF alignment in LLMs reduces toxicity but limits creativity, impacting marketing tasks. Balance between consistency and creativity is crucial.\n\n\n\nJun 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo LLMs Recognize me, When I is not me: Assessment of LLMs Understanding of Turkish Indexical Pronouns in Indexical Shift Contexts\n\n\n\nsocial-sciences\n\n\n\nTL;DR: Advanced LLMs struggle with Turkish’s unique grammatical challenge, the Indexical Shift, highlighting the need for low-resource language research.\n\n\n\nJun 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAligning Agents like Large Language Models\n\n\n\nhci\n\n\n\nWe align 3D agents with desired behaviors using LLM alignment techniques, improving imitation learning.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVerbalized Machine Learning: Revisiting Machine Learning with Language Models\n\n\n\nprompt-engineering\n\n\n\nVML uses LLMs to solve ML problems, offering easy encoding of inductive bias, automatic model class selection, and interpretable learner updates.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFastGAS: Fast Graph-based Annotation Selection for In-Context Learning\n\n\n\nprompt-engineering\n\n\n\nFastGAS: A graph-based method for efficient instance selection in in-context learning, improving performance and reducing selection time.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuffer of Thoughts: Thought-Augmented Reasoning with Large Language Models\n\n\n\nprompt-engineering\n\n\n\nBoT improves LLMs’ reasoning, outperforming SOTA methods on 10 tasks with 12% cost, potentially surpassing Llama3-70B with Llama3-8B.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRefactoring to Pythonic Idioms: A Hybrid Knowledge-Driven Approach Leveraging Large Language Models\n\n\n\nprompt-engineering\n\n\n\nHybrid approach combines LLMs and rule-based methods for Python code idiomatization, outperforming LLM-only and rule-based approaches.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfabulation: The Surprising Value of Large Language Model Hallucinations\n\n\n\nhci\n\n\n\nLLM confabulations mirror human narrativity, offering potential value in AI communication.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaCE: Parsimonious Concept Engineering for Large Language Models\n\n\n\nrobustness\n\n\n\nTL;DR: PaCE is a novel framework for aligning LLMs, improving output quality while preserving linguistic capabilities.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPOEM: Interactive Prompt Optimization for Enhancing Multimodal Reasoning of Large Language Models\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nIntroducing ame: A Visual Analytics System for Prompt Engineering in Multimodal LLMs.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAsk LLMs Directly, What shapes your bias?: Measuring Social Bias in Large Language Models\n\n\n\nhci\n\n\n\nThis paper proposes a method to quantify social biases in LLMs by considering diverse social perceptions, offering a more nuanced understanding of bias.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoherent Zero-Shot Visual Instruction Generation\n\n\n\neducation\n\n\n\nNew framework generates consistent, visually appealing multi-step instructions using diffusion models and LLMs.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMEmbed: Rethinking Lightweight LLM’s Genuine Function in Text Classification\n\n\n\nprompt-engineering\n\n\n\nLLMEmbed: Efficient LLM-based text classification with low overhead.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Do Language Models Learn in Context? The Structured Task Hypothesis\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\n[TEXT] This study examines the relationship between social media use and mental health in young adults. Results indicate a significant correlation between excessive social…\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models as Evaluators for Recommendation Explanations\n\n\n\nrecommender\n\n\n\nLLMs, like GPT4, can accurately evaluate recommendation explanations with proper prompts and settings, offering a cost-effective solution.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTool-Planner: Dynamic Solution Tree Planning for Large Language Model with Tool Clustering\n\n\n\neducation\n\n\n\nTL;DR: Tool-Planner improves tool learning in LLMs like GPT-4 and Claude 3, optimizing planning and handling errors.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBenchmark Data Contamination of Large Language Models: A Survey\n\n\n\nprogramming\n\n\n\nTL;DR: Large Language Models face Benchmark Data Contamination, requiring new evaluation methods for reliable performance.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey on Medical Large Language Models: Technology, Application, Trustworthiness, and Future Directions\n\n\n\nprogramming\n\n\n\nMed-LLMs revolutionize healthcare, offering clinical decision support, report generation, and medical education. Ethical considerations and robust evaluation are crucial for…\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People\n\n\n\nhci\n\n\n\nThis study proposes a method to compare human and GPT-4 conversational tones, creating an interpretable representation of their relations.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDICE: Detecting In-distribution Contamination in LLM’s Fine-tuning Phase for Math Reasoning\n\n\n\neducation\n\n\n\nDICE detects in-distribution contamination in LLMs, potentially overestimating model capabilities.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nText-to-Drive: Diverse Driving Behavior Synthesis via Large Language Models\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nTL;DR: Text-to-Drive (T2D) uses LLMs to generate diverse driving behaviors for autonomous vehicle simulation, offering a scalable and intuitive method for human operators.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRetrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining\n\n\n\nprompt-engineering\n\n\n\nContext-Aware RAG improves prompt-based TTS, outperforming text-only retrieval methods.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemantically Diverse Language Generation for Uncertainty Estimation in Language Models\n\n\n\nrobustness\n\n\n\nLLMs can hallucinate due to predictive uncertainty. SDLG quantifies this, improving trustworthiness and efficiency in LLMs.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeneralization-Enhanced Code Vulnerability Detection via Multi-Task Instruction Fine-Tuning\n\n\n\nprogramming\n\n\n\nVulLLM, a multi-task framework with LLMs, outperforms SOTA models in vulnerability detection by capturing root causes, not just superficial features.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM-QALM: A Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall in Large Language Models via Question Answering\n\n\n\neducation\n\n\n\nLLMs’ success in healthcare tasks depends on recall, comprehension, and integration of knowledge, with instruction tuning and fine-tuning on medical datasets showing promise.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSynthetic Programming Elicitation and Repair for Text-to-Code in Very Low-Resource Programming Languages\n\n\n\nprogramming\n\n\n\nLLMs struggle with unseen programming languages. SPEAC, a new approach, enables LLMs to generate valid code for these languages.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nText-like Encoding of Collaborative Information in Large Language Models for Recommendation\n\n\n\nrecommender\n\n\n\nBinLLM: A novel method integrating collaborative info into LLMs via text-like binary encoding, improving recommendation performance.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nItem-Language Model for Conversational Recommendation\n\n\n\nrecommender\n\n\nprogramming\n\n\n\nTL;DR: Proposed Item-Language Model (ILM) addresses LLM limitations in recommender systems, aligning item representations with user interaction signals.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Detecting LLMs Hallucination via Markov Chain-based Multi-agent Debate Framework\n\n\n\nprogramming\n\n\n\nMarkov Chain-based multi-agent debate improves hallucination detection in LLMs, outperforming baselines.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBIPED: Pedagogically Informed Tutoring System for ESL Education\n\n\n\neducation\n\n\n\nLLMs can serve as effective tutors for English learners. We developed a dataset and models that replicate human teachers’ diverse teaching strategies.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring User Retrieval Integration towards Large Language Models for Cross-Domain Sequential Recommendation\n\n\n\nrecommender\n\n\n\nURLLM improves CDSR by integrating user retrieval and domain grounding on LLM, addressing cold-start issues and semantic reasoning.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models\n\n\n\nprogramming\n\n\n\nThis work enhances LLMs for long texts by considering fragment-level relations, improving story understanding, code generation, and chatting.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Repository-Level Code Generation with Integrated Contextual Information\n\n\n\nprogramming\n\n\n\nCatCoder improves LLM code generation for repositories, outperforming RepoCoder by up to 17.35% in pass@k score, and shows consistent improvements across various LLMs.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPosition Debiasing Fine-Tuning for Causal Perception in Long-Term Dialogue\n\n\n\nprogramming\n\n\n\nCPD method alleviates position bias in LLMs, improving long-term dialogue relevance.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe current status of large language models in summarizing radiology report impressions\n\n\n\nprogramming\n\n\n\nLLMs struggle to replace radiologists in summarizing radiology reports, despite few-shot prompt improvements.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChain of Agents: Large Language Models Collaborating on Long-Context Tasks\n\n\n\nprogramming\n\n\n\nChain-of-Agents (CoA) improves long-context tasks by dividing text among agents, showing up to 10% improvement over baselines.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Mathematical Extrapolation of Large Language Models with Synthetic Data\n\n\n\nprogramming\n\n\n\nLLMs excel in various tasks but struggle with multi-step reasoning. Fine-tuning on synthetic data improves performance in complex arithmetic puzzles.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models Make Sample-Efficient Recommender Systems\n\n\n\nrecommender\n\n\n\nLLMs improve recommender systems’ efficiency, needing less training data for superior performance.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nXRec: Large Language Models for Explainable Recommendation\n\n\n\nrecommender\n\n\n\nXRec framework uses LLMs for explainable recommendations, outperforming baselines in understanding user preferences.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemCoder: Training Code Language Models with Comprehensive Semantics\n\n\n\nprogramming\n\n\n\nSemCoder: A 6.7B Code LLM excels in code generation and execution reasoning, outperforming GPT-3.5-turbo, by integrating semantics from multiple dimensions.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models as Recommender Systems: A Study of Popularity Bias\n\n\n\nrecommender\n\n\n\nLLMs in recommenders can reduce popularity bias, showing less bias than traditional systems without explicit mitigation.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession Context Embedding for Intent Understanding in Product Search\n\n\n\nrecommender\n\n\n\nSession embedding improves search by capturing user intent from multiple engagements, outperforming single query-item pair relevance training.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrivacy in LLM-based Recommendation: Recent Advances and Future Directions\n\n\n\nrecommender\n\n\n\nPrivacy in LLM-based recommendations: attacks, protection, challenges, and future directions.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Understand Whole Software Repository?\n\n\n\nprogramming\n\n\n\nTL;DR: RepoUnderstander improves ASE by understanding whole repositories, outperforming SWE-agent by 18.5%.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerating Query Recommendations via LLMs\n\n\n\nrecommender\n\n\n\n[TEXT] This study examines the impact of climate change on the global wine industry. Results indicate significant shifts in wine production regions and grape varieties due…\n\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKnowledge Graph Tuning: Real-time Large Language Model Personalization based on Human Feedback\n\n\n\nrecommender\n\n\n\nKGT: A novel, efficient, and interpretable method for real-time personalization of LLMs using knowledge graphs, improving user experience and performance.\n\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKeyword-driven Retrieval-Augmented Large Language Models for Cold-start User Recommendations\n\n\n\nrecommender\n\n\n\nTL;DR: KALM4Rec improves cold-start recommendations using keywords and LLMs for candidate retrieval and re-ranking.\n\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPreference Learning Algorithms Do Not Learn Preference Rankings\n\n\n\nrecommender\n\n\n\nDespite high performance, preference-tuned LLMs often have low ranking accuracy, due to limitations in the DPO objective and a gap between observed and idealized ranking…\n\n\n\nMay 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSLMRec: Empowering Small Language Models for Sequential Recommendation\n\n\n\nrecommender\n\n\n\nSLMRec: Small Language Model for Sequential Recommendation achieves 6.6x training, 8.0x inference speedups with 13% of LLM-based model parameters.\n\n\n\nMay 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteLLM-2: Multimodal Large Representation Models for Recommendation\n\n\n\nrecommender\n\n\n\nTL;DR: NoteLLM-2 enhances multimodal representation in I2I recommendations by focusing on visual content and fusing it with textual information.\n\n\n\nMay 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRAGSys: Item-Cold-Start Recommender as RAG System\n\n\n\nrecommender\n\n\n\nICL for LLMs resembles item-cold-start recommenders, prioritizing discovery and maximizing information gain. Diversity and quality bias in demonstrations are crucial for…\n\n\n\nMay 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMs for User Interest Exploration: A Hybrid Approach\n\n\n\nrecommender\n\n\n\nHybrid framework with LLMs and classic models improves novel interest discovery, boosting user enjoyment.\n\n\n\nMay 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNavigating User Experience of ChatGPT-based Conversational Recommender Systems: The Effects of Prompt Guidance and Recommendation Domain\n\n\n\nrecommender\n\n\n\nPrompt guidance in ChatGPT-based CRS enhances user experience, with book recommendations showing more engagement than job recommendations.\n\n\n\nMay 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSunnie: An Anthropomorphic LLM-Based Conversational Agent for Mental Well-Being Activity Recommendation\n\n\n\nrecommender\n\n\n\nThis LaTeX document guides authors on formatting ACM articles.\n\n\n\nMay 22, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Exploring_ChatGPT_App_Ecosystem_Distribution_Deployment_and_Security/2024-08-26-Exploring_ChatGPT_App_Ecosystem_Distribution_Deployment_and_Security.html#appendix",
    "href": "posts/Exploring_ChatGPT_App_Ecosystem_Distribution_Deployment_and_Security/2024-08-26-Exploring_ChatGPT_App_Ecosystem_Distribution_Deployment_and_Security.html#appendix",
    "title": "Exploring ChatGPT App Ecosystem: Distribution, Deployment and Security",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.14357v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.14357v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11784"
  },
  {
    "objectID": "posts/From_Feature_Importance_to_Natural_Language_Explanations_Using_LLMs_with_RAG/2024-07-30-From_Feature_Importance_to_Natural_Language_Explanations_Using_LLMs_with_RAG.html#appendix",
    "href": "posts/From_Feature_Importance_to_Natural_Language_Explanations_Using_LLMs_with_RAG/2024-07-30-From_Feature_Importance_to_Natural_Language_Explanations_Using_LLMs_with_RAG.html#appendix",
    "title": "From Feature Importance to Natural Language Explanations Using LLMs with RAG",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20990v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20990v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7607"
  },
  {
    "objectID": "posts/Leveraging_LLMs_to_Predict_Affective_States_via_Smartphone_Sensor_Features/2024-07-11-Leveraging_LLMs_to_Predict_Affective_States_via_Smartphone_Sensor_Features.html#appendix",
    "href": "posts/Leveraging_LLMs_to_Predict_Affective_States_via_Smartphone_Sensor_Features/2024-07-11-Leveraging_LLMs_to_Predict_Affective_States_via_Smartphone_Sensor_Features.html#appendix",
    "title": "Leveraging LLMs to Predict Affective States via Smartphone Sensor Features",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08240v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08240v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5214"
  },
  {
    "objectID": "posts/Multilingual_Needle_in_a_Haystack_Investigating_Long_Context_Behavior_of_Multilingual_Large_Language_Models/2024-08-19-Multilingual_Needle_in_a_Haystack_Investigating_Long_Context_Behavior_of_Multilingual_Large_Language_Models.html#appendix",
    "href": "posts/Multilingual_Needle_in_a_Haystack_Investigating_Long_Context_Behavior_of_Multilingual_Large_Language_Models/2024-08-19-Multilingual_Needle_in_a_Haystack_Investigating_Long_Context_Behavior_of_Multilingual_Large_Language_Models.html#appendix",
    "title": "Multilingual Needle in a Haystack: Investigating Long-Context Behavior of Multilingual Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10151v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10151v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6917"
  },
  {
    "objectID": "posts/Measuring_and_Benchmarking_Large_Language_Models_Capabilities_to_Generate_Persuasive_Language/2024-06-25-Measuring_and_Benchmarking_Large_Language_Models_Capabilities_to_Generate_Persuasive_Language.html#appendix",
    "href": "posts/Measuring_and_Benchmarking_Large_Language_Models_Capabilities_to_Generate_Persuasive_Language/2024-06-25-Measuring_and_Benchmarking_Large_Language_Models_Capabilities_to_Generate_Persuasive_Language.html#appendix",
    "title": "Measuring and Benchmarking Large Language Models’ Capabilities to Generate Persuasive Language",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17753v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17753v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10078"
  },
  {
    "objectID": "posts/Is_Your_AI_Generated_Code_Really_Secure_Evaluating_Large_Language_Models_on_Secure_Code_Generation_with_CodeSecEval/2024-07-02-Is_Your_AI_Generated_Code_Really_Secure_Evaluating_Large_Language_Models_on_Secure_Code_Generation_with_CodeSecEval.html#appendix",
    "href": "posts/Is_Your_AI_Generated_Code_Really_Secure_Evaluating_Large_Language_Models_on_Secure_Code_Generation_with_CodeSecEval/2024-07-02-Is_Your_AI_Generated_Code_Really_Secure_Evaluating_Large_Language_Models_on_Secure_Code_Generation_with_CodeSecEval.html#appendix",
    "title": "Is Your AI-Generated Code Really Secure? Evaluating Large Language Models on Secure Code Generation with CodeSecEval",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02395v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02395v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9474"
  },
  {
    "objectID": "posts/LLM_3D_Print_Large_Language_Models_To_Monitor_and_Control_3D_Printing/2024-08-26-LLM_3D_Print_Large_Language_Models_To_Monitor_and_Control_3D_Printing.html#appendix",
    "href": "posts/LLM_3D_Print_Large_Language_Models_To_Monitor_and_Control_3D_Printing/2024-08-26-LLM_3D_Print_Large_Language_Models_To_Monitor_and_Control_3D_Printing.html#appendix",
    "title": "LLM-3D Print: Large Language Models To Monitor and Control 3D Printing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.14307v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.14307v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8288"
  },
  {
    "objectID": "posts/Annotation_alignment_Comparing_LLM_and_human_annotations_of_conversational_safety/2024-06-10-Annotation_alignment_Comparing_LLM_and_human_annotations_of_conversational_safety.html#appendix",
    "href": "posts/Annotation_alignment_Comparing_LLM_and_human_annotations_of_conversational_safety/2024-06-10-Annotation_alignment_Comparing_LLM_and_human_annotations_of_conversational_safety.html#appendix",
    "title": "Annotation alignment: Comparing LLM and human annotations of conversational safety",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06369v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06369v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7965"
  },
  {
    "objectID": "posts/Talking_to_Machines_do_you_read_me/2024-07-02-Talking_to_Machines_do_you_read_me.html",
    "href": "posts/Talking_to_Machines_do_you_read_me/2024-07-02-Talking_to_Machines_do_you_read_me.html",
    "title": "Talking to Machines: do you read me?",
    "section": "",
    "text": "Summary:\nThis academic paper provides an overview of the research on dialogue systems, focusing on the contributions of Lina María Rojas Barahona. The author discusses her work on task-oriented dialogues and conversational question answering, as well as her role as an industrial supervisor for four PhD theses. The paper also briefly reviews the state of the art in conversational agents and highlights open research problems. The author emphasizes the progress made in dialogue systems since the introduction of Eliza, the automated psychoanalyst, in 1966. She notes that while early systems were limited by poor understanding and lack of expressivity, recent advances in deep learning and data-driven techniques have led to promising results in creating artificial agents capable of conversing with humans.\nThe paper explores various aspects of dialogue systems, including the use of Partially Observable Markov Decision Processes (POMDPs) in spoken dialogue systems, Machine Learning (ML)"
  },
  {
    "objectID": "posts/Talking_to_Machines_do_you_read_me/2024-07-02-Talking_to_Machines_do_you_read_me.html#appendix",
    "href": "posts/Talking_to_Machines_do_you_read_me/2024-07-02-Talking_to_Machines_do_you_read_me.html#appendix",
    "title": "Talking to Machines: do you read me?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02354v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02354v1\n\n\nTruncated\nTrue\n\n\nWord Count\n44116"
  },
  {
    "objectID": "posts/A_Comparative_Study_of_DSL_Code_Generation_Fine_Tuning_vs._Optimized_Retrieval_Augmentation/2024-07-03-A_Comparative_Study_of_DSL_Code_Generation_Fine_Tuning_vs._Optimized_Retrieval_Augmentation.html#appendix",
    "href": "posts/A_Comparative_Study_of_DSL_Code_Generation_Fine_Tuning_vs._Optimized_Retrieval_Augmentation/2024-07-03-A_Comparative_Study_of_DSL_Code_Generation_Fine_Tuning_vs._Optimized_Retrieval_Augmentation.html#appendix",
    "title": "A Comparative Study of DSL Code Generation: Fine-Tuning vs. Optimized Retrieval Augmentation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02742v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02742v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6386"
  },
  {
    "objectID": "posts/Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models/2024-06-08-Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models.html",
    "href": "posts/Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models/2024-06-08-Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models.html",
    "title": "Creativity Has Left the Chat: The Price of Debiasing Language Models",
    "section": "",
    "text": "Summary:\nThe paper “Creativity Has Left the Chat: The Price of Debiasing Language Models” explores the impact of the Reinforcement Learning from Human Feedback (RLHF) process on the creativity and output diversity of Large Language Models (LLMs). The authors use the Llama-2 series of models to conduct three experiments, focusing on the Llama-2-7B-text (base model) and Llama-2-7B-chat (aligned model). The experiments reveal that while RLHF effectively reduces biases and toxicity in LLMs, it may inadvertently lead to a reduction in the models’ creative potential. The aligned models exhibit lower entropy in token predictions, form distinct clusters in the embedding space, and gravitate towards “attractor states,” indicating limited output diversity. These findings have significant implications for marketers who rely on LLMs for creative tasks, as the trade-off between consistency and creativity in aligned models should be carefully considered.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides valuable insights into the unintended consequences of the RLHF process on the creativity and output diversity of LLMs. However, the study is limited by the computational costs and resource demands, which prevented the authors from delving into various parameters or configurations of the RLHF process. Future research should explore different parameters and configurations to understand their impact on the creativity and output diversity of aligned LLMs. Additionally, further investigation is needed to analyze other unintended consequences of model alignment and RLHF to enhance our understanding of the trade-offs involved in practical applications of these models."
  },
  {
    "objectID": "posts/Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models/2024-06-08-Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models.html#appendix",
    "href": "posts/Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models/2024-06-08-Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models.html#appendix",
    "title": "Creativity Has Left the Chat: The Price of Debiasing Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05587v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05587v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20391"
  },
  {
    "objectID": "posts/Enhancing_Code_Translation_in_Language_Models_with_Few_Shot_Learning_via_Retrieval_Augmented_Generation/2024-07-29-Enhancing_Code_Translation_in_Language_Models_with_Few_Shot_Learning_via_Retrieval_Augmented_Generation.html#appendix",
    "href": "posts/Enhancing_Code_Translation_in_Language_Models_with_Few_Shot_Learning_via_Retrieval_Augmented_Generation/2024-07-29-Enhancing_Code_Translation_in_Language_Models_with_Few_Shot_Learning_via_Retrieval_Augmented_Generation.html#appendix",
    "title": "Enhancing Code Translation in Language Models with Few-Shot Learning via Retrieval-Augmented Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19619v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19619v1\n\n\nTruncated\nFalse\n\n\nWord Count\n0"
  },
  {
    "objectID": "posts/PORT_Preference_Optimization_on_Reasoning_Traces/2024-06-23-PORT_Preference_Optimization_on_Reasoning_Traces.html#appendix",
    "href": "posts/PORT_Preference_Optimization_on_Reasoning_Traces/2024-06-23-PORT_Preference_Optimization_on_Reasoning_Traces.html#appendix",
    "title": "PORT: Preference Optimization on Reasoning Traces",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16061v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16061v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8636"
  },
  {
    "objectID": "posts/An_LLM_based_Readability_Measurement_for_Unit_Tests_Context_aware_Inputs/2024-07-31-An_LLM_based_Readability_Measurement_for_Unit_Tests_Context_aware_Inputs.html",
    "href": "posts/An_LLM_based_Readability_Measurement_for_Unit_Tests_Context_aware_Inputs/2024-07-31-An_LLM_based_Readability_Measurement_for_Unit_Tests_Context_aware_Inputs.html",
    "title": "An LLM-based Readability Measurement for Unit Tests’ Context-aware Inputs",
    "section": "",
    "text": "Summary:\nThe paper introduces a novel concept called readability context, which refers to the requirements for test readability described in the source code. The authors propose the Context Consistency Criterion (C3), a tool that mines the readability contexts and measures the consistency of the tests’ inputs with these contexts. C3 is evaluated on JAVA projects, and its performance is compared with manual tests, traditional test generation tools, and an LLM-based tool. The results show that C3 detects readability contexts with high precision, recall, and F1-Score. The proposed EvoSuiteC3, a variant of EvoSuite, leverages the readability contexts mined by C3 to generate test inputs with improved readability. The evaluation reveals that EvoSuiteC3 and ChatUniTest perform closely to manual tests in input readability, while EvoSuite and Randoop largely fail to generate readable string-type inputs.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an innovative approach to measuring the readability of test inputs by introducing the concept of readability context and the Context Consistency Criterion (C3). The evaluation of C3 on JAVA projects demonstrates its effectiveness in detecting readability contexts with high precision, recall, and F1-Score. The proposed EvoSuiteC3, which leverages the readability contexts mined by C3, shows promising results in generating test inputs with improved readability.\nHowever, the paper has some limitations."
  },
  {
    "objectID": "posts/An_LLM_based_Readability_Measurement_for_Unit_Tests_Context_aware_Inputs/2024-07-31-An_LLM_based_Readability_Measurement_for_Unit_Tests_Context_aware_Inputs.html#appendix",
    "href": "posts/An_LLM_based_Readability_Measurement_for_Unit_Tests_Context_aware_Inputs/2024-07-31-An_LLM_based_Readability_Measurement_for_Unit_Tests_Context_aware_Inputs.html#appendix",
    "title": "An LLM-based Readability Measurement for Unit Tests’ Context-aware Inputs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21369v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21369v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11321"
  },
  {
    "objectID": "posts/PEFT_U_Parameter_Efficient_Fine_Tuning_for_User_Personalization/2024-07-25-PEFT_U_Parameter_Efficient_Fine_Tuning_for_User_Personalization.html#major-findings",
    "href": "posts/PEFT_U_Parameter_Efficient_Fine_Tuning_for_User_Personalization/2024-07-25-PEFT_U_Parameter_Efficient_Fine_Tuning_for_User_Personalization.html#major-findings",
    "title": "PEFT-U: Parameter-Efficient Fine-Tuning for User Personalization",
    "section": "Major Findings",
    "text": "Major Findings\n\nThe PEFT-U Benchmark is the first of its kind to focus on modeling user preferences in NLP with an emphasis on identical inputs that require different model outputs depending upon the user.\nThe benchmark consists of over 13+ personalized tasks and 15k+ users across domains such as Hate Speech, Sentiment/Emotion, and Humor.\nThe authors implement and empirically analyze a series of personalized prompting approaches (non-parametric) vs tuning and compartmentalizing user-level knowledge (parametric) for personalized tasks."
  },
  {
    "objectID": "posts/PEFT_U_Parameter_Efficient_Fine_Tuning_for_User_Personalization/2024-07-25-PEFT_U_Parameter_Efficient_Fine_Tuning_for_User_Personalization.html#analysis-and-critique",
    "href": "posts/PEFT_U_Parameter_Efficient_Fine_Tuning_for_User_Personalization/2024-07-25-PEFT_U_Parameter_Efficient_Fine_Tuning_for_User_Personalization.html#analysis-and-critique",
    "title": "PEFT-U: Parameter-Efficient Fine-Tuning for User Personalization",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\n\nThe paper does not provide a detailed comparison of the proposed approach with existing personalization methods in NLP.\nThe authors do not discuss the limitations of their approach, such as the potential for overfitting to specific users or the scalability of the proposed methods.\nThe paper does not provide a clear definition of what constitutes a “personalized” task, which may limit the generalizability of the proposed benchmark.\nThe authors do not discuss the potential ethical implications of personalizing LLMs, such as the risk of reinforcing existing biases or stereotypes.\nThe paper does not provide a detailed analysis of the performance of the proposed methods on each of the 13+ personalized tasks, which may limit the usefulness of the benchmark for evaluating the effectiveness of personalization methods."
  },
  {
    "objectID": "posts/PEFT_U_Parameter_Efficient_Fine_Tuning_for_User_Personalization/2024-07-25-PEFT_U_Parameter_Efficient_Fine_Tuning_for_User_Personalization.html#appendix",
    "href": "posts/PEFT_U_Parameter_Efficient_Fine_Tuning_for_User_Personalization/2024-07-25-PEFT_U_Parameter_Efficient_Fine_Tuning_for_User_Personalization.html#appendix",
    "title": "PEFT-U: Parameter-Efficient Fine-Tuning for User Personalization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.18078v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.18078v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7032"
  },
  {
    "objectID": "posts/M2Lingual_Enhancing_Multilingual_Multi_Turn_Instruction_Alignment_in_Large_Language_Models/2024-06-24-M2Lingual_Enhancing_Multilingual_Multi_Turn_Instruction_Alignment_in_Large_Language_Models.html#appendix",
    "href": "posts/M2Lingual_Enhancing_Multilingual_Multi_Turn_Instruction_Alignment_in_Large_Language_Models/2024-06-24-M2Lingual_Enhancing_Multilingual_Multi_Turn_Instruction_Alignment_in_Large_Language_Models.html#appendix",
    "title": "M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16783v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16783v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8562"
  },
  {
    "objectID": "posts/KG_FPQ_Evaluating_Factuality_Hallucination_in_LLMs_with_Knowledge_Graph_based_False_Premise_Questions/2024-07-08-KG_FPQ_Evaluating_Factuality_Hallucination_in_LLMs_with_Knowledge_Graph_based_False_Premise_Questions.html#appendix",
    "href": "posts/KG_FPQ_Evaluating_Factuality_Hallucination_in_LLMs_with_Knowledge_Graph_based_False_Premise_Questions/2024-07-08-KG_FPQ_Evaluating_Factuality_Hallucination_in_LLMs_with_Knowledge_Graph_based_False_Premise_Questions.html#appendix",
    "title": "KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05868v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05868v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7115"
  },
  {
    "objectID": "posts/THaLLE_Text_Hyperlocally_Augmented_Large_Language_Extension____Technical_Report/2024-06-11-THaLLE_Text_Hyperlocally_Augmented_Large_Language_Extension____Technical_Report.html#appendix",
    "href": "posts/THaLLE_Text_Hyperlocally_Augmented_Large_Language_Extension____Technical_Report/2024-06-11-THaLLE_Text_Hyperlocally_Augmented_Large_Language_Extension____Technical_Report.html#appendix",
    "title": "THaLLE: Text Hyperlocally Augmented Large Language Extension – Technical Report",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07505v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07505v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5344"
  },
  {
    "objectID": "posts/Chat_like_Asserts_Prediction_with_the_Support_of_Large_Language_Model/2024-07-31-Chat_like_Asserts_Prediction_with_the_Support_of_Large_Language_Model.html#appendix",
    "href": "posts/Chat_like_Asserts_Prediction_with_the_Support_of_Large_Language_Model/2024-07-31-Chat_like_Asserts_Prediction_with_the_Support_of_Large_Language_Model.html#appendix",
    "title": "Chat-like Asserts Prediction with the Support of Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21429v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21429v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14111"
  },
  {
    "objectID": "posts/Automated_Adversarial_Discovery_for_Safety_Classifiers/2024-06-24-Automated_Adversarial_Discovery_for_Safety_Classifiers.html#appendix",
    "href": "posts/Automated_Adversarial_Discovery_for_Safety_Classifiers/2024-06-24-Automated_Adversarial_Discovery_for_Safety_Classifiers.html#appendix",
    "title": "Automated Adversarial Discovery for Safety Classifiers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17104v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17104v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6260"
  },
  {
    "objectID": "posts/Conditioning_LLMs_with_Emotion_in_Neural_Machine_Translation/2024-08-06-Conditioning_LLMs_with_Emotion_in_Neural_Machine_Translation.html#appendix",
    "href": "posts/Conditioning_LLMs_with_Emotion_in_Neural_Machine_Translation/2024-08-06-Conditioning_LLMs_with_Emotion_in_Neural_Machine_Translation.html#appendix",
    "title": "Conditioning LLMs with Emotion in Neural Machine Translation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03150v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03150v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3638"
  },
  {
    "objectID": "posts/Math_LLaVA_Bootstrapping_Mathematical_Reasoning_for_Multimodal_Large_Language_Models/2024-06-26-Math_LLaVA_Bootstrapping_Mathematical_Reasoning_for_Multimodal_Large_Language_Models.html#appendix",
    "href": "posts/Math_LLaVA_Bootstrapping_Mathematical_Reasoning_for_Multimodal_Large_Language_Models/2024-06-26-Math_LLaVA_Bootstrapping_Mathematical_Reasoning_for_Multimodal_Large_Language_Models.html#appendix",
    "title": "Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17294v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17294v2\n\n\nTruncated\nFalse\n\n\nWord Count\n6677"
  },
  {
    "objectID": "posts/Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue/2024-06-04-Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue.html",
    "href": "posts/Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue/2024-06-04-Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue.html",
    "title": "Position Debiasing Fine-Tuning for Causal Perception in Long-Term Dialogue",
    "section": "",
    "text": "Summary:\nThe paper proposes a novel method, Causal Perception long-term Dialogue framework (CPD), to alleviate the position bias in large language models (LLMs) for long-term dialogue tasks. The CPD framework employs perturbation-based causal variable discovery to extract causally relevant utterances from dialogue history and enhances the model’s causal perception during fine-tuning. The framework includes a local-position awareness method for inter-sentence position correlation elimination and a causal-perception fine-tuning strategy to improve the model’s ability to discover causal invariant factors. Experimental results on two datasets demonstrate that the proposed method effectively alleviates position bias and achieves significant progress compared to existing baselines.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a well-structured and coherent summary of the proposed CPD framework for addressing position bias in LLMs for long-term dialogue tasks. The use of perturbation-based causal variable discovery and the local-position awareness method are innovative approaches to extract causally relevant utterances from dialogue history. The causal-perception fine-tuning strategy also provides a promising direction for improving the model’s ability to discover causal invariant factors.\nHowever, the paper could benefit from a more detailed analysis of the limitations and potential biases of the proposed method. For instance, the paper does not discuss the potential impact of the perturbation-based approach on the model’s performance or the generalizability of the method to other types of dialogue tasks. Additionally, the paper could provide more insights into the potential challenges and trade-offs in implementing the proposed method in real-world applications.\nOverall, the paper presents a promising approach to addressing position bias in LLMs for long-term dialogue tasks. The proposed CPD framework and the experimental results provide valuable insights into the potential of perturbation-based causal variable discovery and causal-perception fine-t"
  },
  {
    "objectID": "posts/Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue/2024-06-04-Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue.html#appendix",
    "href": "posts/Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue/2024-06-04-Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue.html#appendix",
    "title": "Position Debiasing Fine-Tuning for Causal Perception in Long-Term Dialogue",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02002v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02002v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7030"
  },
  {
    "objectID": "posts/Through_the_Theory_of_Minds_Eye_Reading_Minds_with_Multimodal_Video_Large_Language_Models/2024-06-19-Through_the_Theory_of_Minds_Eye_Reading_Minds_with_Multimodal_Video_Large_Language_Models.html#appendix",
    "href": "posts/Through_the_Theory_of_Minds_Eye_Reading_Minds_with_Multimodal_Video_Large_Language_Models/2024-06-19-Through_the_Theory_of_Minds_Eye_Reading_Minds_with_Multimodal_Video_Large_Language_Models.html#appendix",
    "title": "Through the Theory of Mind’s Eye: Reading Minds with Multimodal Video Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13763v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13763v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4909"
  },
  {
    "objectID": "posts/What_Did_I_Do_Wrong_Quantifying_LLMs_Sensitivity_and_Consistency_to_Prompt_Engineering/2024-06-18-What_Did_I_Do_Wrong_Quantifying_LLMs_Sensitivity_and_Consistency_to_Prompt_Engineering.html#appendix",
    "href": "posts/What_Did_I_Do_Wrong_Quantifying_LLMs_Sensitivity_and_Consistency_to_Prompt_Engineering/2024-06-18-What_Did_I_Do_Wrong_Quantifying_LLMs_Sensitivity_and_Consistency_to_Prompt_Engineering.html#appendix",
    "title": "What Did I Do Wrong? Quantifying LLMs’ Sensitivity and Consistency to Prompt Engineering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12334v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12334v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6408"
  },
  {
    "objectID": "posts/Lisbon_Computational_Linguists_at_SemEval_2024_Task_2_Using_A_Mistral_7B_Model_and_Data_Augmentation/2024-08-06-Lisbon_Computational_Linguists_at_SemEval_2024_Task_2_Using_A_Mistral_7B_Model_and_Data_Augmentation.html#appendix",
    "href": "posts/Lisbon_Computational_Linguists_at_SemEval_2024_Task_2_Using_A_Mistral_7B_Model_and_Data_Augmentation/2024-08-06-Lisbon_Computational_Linguists_at_SemEval_2024_Task_2_Using_A_Mistral_7B_Model_and_Data_Augmentation.html#appendix",
    "title": "Lisbon Computational Linguists at SemEval-2024 Task 2: Using A Mistral 7B Model and Data Augmentation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03127v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03127v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6009"
  },
  {
    "objectID": "posts/CodeJudge_Eval_Can_Large_Language_Models_be_Good_Judges_in_Code_Understanding/2024-08-20-CodeJudge_Eval_Can_Large_Language_Models_be_Good_Judges_in_Code_Understanding.html#appendix",
    "href": "posts/CodeJudge_Eval_Can_Large_Language_Models_be_Good_Judges_in_Code_Understanding/2024-08-20-CodeJudge_Eval_Can_Large_Language_Models_be_Good_Judges_in_Code_Understanding.html#appendix",
    "title": "CodeJudge-Eval: Can Large Language Models be Good Judges in Code Understanding?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10718v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10718v1\n\n\nTruncated\nFalse\n\n\nWord Count\n985"
  },
  {
    "objectID": "posts/Video_CCAM_Enhancing_Video_Language_Understanding_with_Causal_Cross_Attention_Masks_for_Short_and_Long_Videos/2024-08-26-Video_CCAM_Enhancing_Video_Language_Understanding_with_Causal_Cross_Attention_Masks_for_Short_and_Long_Videos.html#appendix",
    "href": "posts/Video_CCAM_Enhancing_Video_Language_Understanding_with_Causal_Cross_Attention_Masks_for_Short_and_Long_Videos/2024-08-26-Video_CCAM_Enhancing_Video_Language_Understanding_with_Causal_Cross_Attention_Masks_for_Short_and_Long_Videos.html#appendix",
    "title": "Video-CCAM: Enhancing Video-Language Understanding with Causal Cross-Attention Masks for Short and Long Videos",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.14023v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.14023v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5520"
  },
  {
    "objectID": "posts/Optimizing_Psychological_Counseling_with_Instruction_Tuned_Large_Language_Models/2024-06-19-Optimizing_Psychological_Counseling_with_Instruction_Tuned_Large_Language_Models.html#appendix",
    "href": "posts/Optimizing_Psychological_Counseling_with_Instruction_Tuned_Large_Language_Models/2024-06-19-Optimizing_Psychological_Counseling_with_Instruction_Tuned_Large_Language_Models.html#appendix",
    "title": "Optimizing Psychological Counseling with Instruction-Tuned Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13617v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13617v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4397"
  },
  {
    "objectID": "posts/SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research/2024-07-03-SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research.html#major-findings",
    "href": "posts/SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research/2024-07-03-SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research.html#major-findings",
    "title": "SemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nModels achieve above-chance classification performance, with prompt engineering significantly improving their outcome. Some models achieve close-to-clinical performance and reasoning.\nGPT-4 emerges as the top-performing model across all evaluation metrics, while Mixtral8x7B, while competitive with GPT-4 in performance, exhibits tendencies to hallucinate in source citations and provides incomplete and partially incorrect reasoning.\nGPT-3.5 and Qwen-72B exhibit higher confidence levels in their outputs, albeit with reduced correctness."
  },
  {
    "objectID": "posts/SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research/2024-07-03-SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research.html#analysis-and-critique",
    "href": "posts/SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research/2024-07-03-SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research.html#analysis-and-critique",
    "title": "SemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe study provides the first extensive benchmark comparing current SOTA LLMs in the medical domain of epilepsy and highlights their ability to leverage unstructured texts from patients’ medical history to aid diagnostic processes in health care.\nHowever, the analyses also reveal significant pitfalls with several models being overly confident while showing poor performance, as well as exhibiting citation errors and hallucinations.\nThe lack of systematic evaluation of LLMs’ understanding of specific clinical domains is a limitation, requiring large-scale annotated text-datasets, systematic investigation of prompt designs, and exploration of in-context learning strategies.\nThe study does not address the potential biases in the annotated clinical database, which could impact the performance of the LLMs.\nThe study does not provide a comparison with other machine learning or deep learning models, which could offer a more comprehensive understanding of the performance of LLMs in this domain.\nThe study does not discuss the potential ethical implications of using LLMs for epilepsy diagnosis, such as the risk of over"
  },
  {
    "objectID": "posts/SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research/2024-07-03-SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research.html#appendix",
    "href": "posts/SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research/2024-07-03-SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research.html#appendix",
    "title": "SemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03004v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03004v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6699"
  },
  {
    "objectID": "posts/Improving_Visual_Storytelling_with_Multimodal_Large_Language_Models/2024-07-02-Improving_Visual_Storytelling_with_Multimodal_Large_Language_Models.html#appendix",
    "href": "posts/Improving_Visual_Storytelling_with_Multimodal_Large_Language_Models/2024-07-02-Improving_Visual_Storytelling_with_Multimodal_Large_Language_Models.html#appendix",
    "title": "Improving Visual Storytelling with Multimodal Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02586v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02586v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3182"
  },
  {
    "objectID": "posts/Exploring_the_Capabilities_of_LLMs_for_Code_Change_Related_Tasks/2024-07-03-Exploring_the_Capabilities_of_LLMs_for_Code_Change_Related_Tasks.html#appendix",
    "href": "posts/Exploring_the_Capabilities_of_LLMs_for_Code_Change_Related_Tasks/2024-07-03-Exploring_the_Capabilities_of_LLMs_for_Code_Change_Related_Tasks.html#appendix",
    "title": "Exploring the Capabilities of LLMs for Code Change Related Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02824v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02824v1\n\n\nTruncated\nFalse\n\n\nWord Count\n16271"
  },
  {
    "objectID": "posts/61A_Bot_AI_homework_assistance_in_CS1_is_fast_and_cheap____but_is_it_helpful/2024-06-09-61A_Bot_AI_homework_assistance_in_CS1_is_fast_and_cheap____but_is_it_helpful.html#appendix",
    "href": "posts/61A_Bot_AI_homework_assistance_in_CS1_is_fast_and_cheap____but_is_it_helpful/2024-06-09-61A_Bot_AI_homework_assistance_in_CS1_is_fast_and_cheap____but_is_it_helpful.html#appendix",
    "title": "61A-Bot: AI homework assistance in CS1 is fast and cheap – but is it helpful?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05600v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05600v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7095"
  },
  {
    "objectID": "posts/Soda_Eval_Open_Domain_Dialogue_Evaluation_in_the_age_of_LLMs/2024-08-20-Soda_Eval_Open_Domain_Dialogue_Evaluation_in_the_age_of_LLMs.html#appendix",
    "href": "posts/Soda_Eval_Open_Domain_Dialogue_Evaluation_in_the_age_of_LLMs/2024-08-20-Soda_Eval_Open_Domain_Dialogue_Evaluation_in_the_age_of_LLMs.html#appendix",
    "title": "Soda-Eval: Open-Domain Dialogue Evaluation in the age of LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10902v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10902v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9986"
  },
  {
    "objectID": "posts/PITCH_Productivity_and_Mental_Well_being_Coaching_through_Daily_Conversational_Interaction/2024-06-11-PITCH_Productivity_and_Mental_Well_being_Coaching_through_Daily_Conversational_Interaction.html#appendix",
    "href": "posts/PITCH_Productivity_and_Mental_Well_being_Coaching_through_Daily_Conversational_Interaction/2024-06-11-PITCH_Productivity_and_Mental_Well_being_Coaching_through_Daily_Conversational_Interaction.html#appendix",
    "title": "PITCH: Productivity and Mental Well-being Coaching through Daily Conversational Interaction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07485v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07485v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3364"
  },
  {
    "objectID": "posts/The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts/2024-06-20-The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts.html",
    "href": "posts/The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts/2024-06-20-The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts.html",
    "title": "The Fire Thief Is Also the Keeper: Balancing Usability and Privacy in Prompts",
    "section": "",
    "text": "Summary:\nThe paper introduces Prompt Privacy Sanitizer (ProSan), an end-to-end framework for prompt privacy protection that balances usability and privacy. ProSan generates anonymized prompts by removing contextual privacy while maintaining task usability and human readability. It can be seamlessly integrated into the online LLM service pipeline. ProSan dynamically adjusts its protection targets and strength based on the importance of words and the privacy leakage risk of prompts. It is also capable of adapting to diverse computational resource conditions, ensuring privacy protection even for mobile devices with limited computing power.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a promising approach to addressing the issue of privacy leaks in prompts. However, it does not provide a comprehensive evaluation of the framework’s performance across a wide range of tasks and datasets. Additionally, the paper does not discuss potential limitations or biases in the framework, such as the reliance on self-information for measuring privacy risk, which may not fully capture the complexity of privacy in natural language. Further research is needed to evaluate the framework’s robustness and generalizability, as well as to explore alternative methods for measuring privacy risk."
  },
  {
    "objectID": "posts/The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts/2024-06-20-The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts.html#appendix",
    "href": "posts/The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts/2024-06-20-The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts.html#appendix",
    "title": "The Fire Thief Is Also the Keeper: Balancing Usability and Privacy in Prompts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14318v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14318v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11663"
  },
  {
    "objectID": "posts/LUT_Tensor_Core_Lookup_Table_Enables_Efficient_Low_Bit_LLM_Inference_Acceleration/2024-08-12-LUT_Tensor_Core_Lookup_Table_Enables_Efficient_Low_Bit_LLM_Inference_Acceleration.html#major-findings",
    "href": "posts/LUT_Tensor_Core_Lookup_Table_Enables_Efficient_Low_Bit_LLM_Inference_Acceleration/2024-08-12-LUT_Tensor_Core_Lookup_Table_Enables_Efficient_Low_Bit_LLM_Inference_Acceleration.html#major-findings",
    "title": "LUT Tensor Core: Lookup Table Enables Efficient Low-Bit LLM Inference Acceleration",
    "section": "Major Findings",
    "text": "Major Findings\n\nLUT Tensor Core is a software-hardware co-design optimized for low-bit LLM inference, addressing the mpGEMM requirements.\nThe design utilizes a lookup table (LUT)-based approach for mpGEMM, with software-based operator fusion and table symmetrization techniques.\nThe hardware design features an elongated tiling shape and a bit-serial design to support various precision combinations in mpGEMM.\nAn end-to-end compilation stack with new instructions for LUT-based mpGEMM is proposed for efficient LLM compilation and optimizations.\nLUT Tensor Core achieves significant improvements in compute density and energy efficiency on low-bit LLMs."
  },
  {
    "objectID": "posts/LUT_Tensor_Core_Lookup_Table_Enables_Efficient_Low_Bit_LLM_Inference_Acceleration/2024-08-12-LUT_Tensor_Core_Lookup_Table_Enables_Efficient_Low_Bit_LLM_Inference_Acceleration.html#analysis-and-critique",
    "href": "posts/LUT_Tensor_Core_Lookup_Table_Enables_Efficient_Low_Bit_LLM_Inference_Acceleration/2024-08-12-LUT_Tensor_Core_Lookup_Table_Enables_Efficient_Low_Bit_LLM_Inference_Acceleration.html#analysis-and-critique",
    "title": "LUT Tensor Core: Lookup Table Enables Efficient Low-Bit LLM Inference Acceleration",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\nWhile the paper presents a promising approach to address the mpGEMM requirements in low-bit LLMs, there are some potential limitations and areas for further research:\n\nThe paper does not discuss the potential impact of the proposed design on model accuracy, which is a crucial aspect of LLM inference.\nThe evaluation is limited to a few low-bit LLMs, and it would be"
  },
  {
    "objectID": "posts/LUT_Tensor_Core_Lookup_Table_Enables_Efficient_Low_Bit_LLM_Inference_Acceleration/2024-08-12-LUT_Tensor_Core_Lookup_Table_Enables_Efficient_Low_Bit_LLM_Inference_Acceleration.html#appendix",
    "href": "posts/LUT_Tensor_Core_Lookup_Table_Enables_Efficient_Low_Bit_LLM_Inference_Acceleration/2024-08-12-LUT_Tensor_Core_Lookup_Table_Enables_Efficient_Low_Bit_LLM_Inference_Acceleration.html#appendix",
    "title": "LUT Tensor Core: Lookup Table Enables Efficient Low-Bit LLM Inference Acceleration",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.06003v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.06003v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10345"
  },
  {
    "objectID": "posts/VersiCode_Towards_Version_controllable_Code_Generation/2024-06-11-VersiCode_Towards_Version_controllable_Code_Generation.html#appendix",
    "href": "posts/VersiCode_Towards_Version_controllable_Code_Generation/2024-06-11-VersiCode_Towards_Version_controllable_Code_Generation.html#appendix",
    "title": "VersiCode: Towards Version-controllable Code Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07411v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07411v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6957"
  },
  {
    "objectID": "posts/Synthetic_Programming_Elicitation_and_Repair_for_Text_to_Code_in_Very_Low_Resource_Programming_Languages/2024-06-05-Synthetic_Programming_Elicitation_and_Repair_for_Text_to_Code_in_Very_Low_Resource_Programming_Languages.html#appendix",
    "href": "posts/Synthetic_Programming_Elicitation_and_Repair_for_Text_to_Code_in_Very_Low_Resource_Programming_Languages/2024-06-05-Synthetic_Programming_Elicitation_and_Repair_for_Text_to_Code_in_Very_Low_Resource_Programming_Languages.html#appendix",
    "title": "Synthetic Programming Elicitation and Repair for Text-to-Code in Very Low-Resource Programming Languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03636v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03636v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9438"
  },
  {
    "objectID": "posts/Text_like_Encoding_of_Collaborative_Information_in_Large_Language_Models_for_Recommendation/2024-06-05-Text_like_Encoding_of_Collaborative_Information_in_Large_Language_Models_for_Recommendation.html#appendix",
    "href": "posts/Text_like_Encoding_of_Collaborative_Information_in_Large_Language_Models_for_Recommendation/2024-06-05-Text_like_Encoding_of_Collaborative_Information_in_Large_Language_Models_for_Recommendation.html#appendix",
    "title": "Text-like Encoding of Collaborative Information in Large Language Models for Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03210v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03210v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6859"
  },
  {
    "objectID": "posts/Optimizing_RAG_Techniques_for_Automotive_Industry_PDF_Chatbots_A_Case_Study_with_Locally_Deployed_Ollama_Models/2024-08-12-Optimizing_RAG_Techniques_for_Automotive_Industry_PDF_Chatbots_A_Case_Study_with_Locally_Deployed_Ollama_Models.html#appendix",
    "href": "posts/Optimizing_RAG_Techniques_for_Automotive_Industry_PDF_Chatbots_A_Case_Study_with_Locally_Deployed_Ollama_Models/2024-08-12-Optimizing_RAG_Techniques_for_Automotive_Industry_PDF_Chatbots_A_Case_Study_with_Locally_Deployed_Ollama_Models.html#appendix",
    "title": "Optimizing RAG Techniques for Automotive Industry PDF Chatbots: A Case Study with Locally Deployed Ollama Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.05933v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.05933v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14182"
  },
  {
    "objectID": "posts/FlexEdit_Marrying_Free_Shape_Masks_to_VLLM_for_Flexible_Image_Editing/2024-08-22-FlexEdit_Marrying_Free_Shape_Masks_to_VLLM_for_Flexible_Image_Editing.html#appendix",
    "href": "posts/FlexEdit_Marrying_Free_Shape_Masks_to_VLLM_for_Flexible_Image_Editing/2024-08-22-FlexEdit_Marrying_Free_Shape_Masks_to_VLLM_for_Flexible_Image_Editing.html#appendix",
    "title": "FlexEdit: Marrying Free-Shape Masks to VLLM for Flexible Image Editing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12429v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12429v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7801"
  },
  {
    "objectID": "posts/SceneGPT_A_Language_Model_for_3D_Scene_Understanding/2024-08-13-SceneGPT_A_Language_Model_for_3D_Scene_Understanding.html#appendix",
    "href": "posts/SceneGPT_A_Language_Model_for_3D_Scene_Understanding/2024-08-13-SceneGPT_A_Language_Model_for_3D_Scene_Understanding.html#appendix",
    "title": "SceneGPT: A Language Model for 3D Scene Understanding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.06926v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.06926v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4080"
  },
  {
    "objectID": "posts/Story3D_Agent_Exploring_3D_Storytelling_Visualization_with_Large_Language_Models/2024-08-21-Story3D_Agent_Exploring_3D_Storytelling_Visualization_with_Large_Language_Models.html#appendix",
    "href": "posts/Story3D_Agent_Exploring_3D_Storytelling_Visualization_with_Large_Language_Models/2024-08-21-Story3D_Agent_Exploring_3D_Storytelling_Visualization_with_Large_Language_Models.html#appendix",
    "title": "Story3D-Agent: Exploring 3D Storytelling Visualization with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11801v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11801v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2494"
  },
  {
    "objectID": "posts/EmBARDiment_an_Embodied_AI_Agent_for_Productivity_in_XR/2024-08-15-EmBARDiment_an_Embodied_AI_Agent_for_Productivity_in_XR.html#appendix",
    "href": "posts/EmBARDiment_an_Embodied_AI_Agent_for_Productivity_in_XR/2024-08-15-EmBARDiment_an_Embodied_AI_Agent_for_Productivity_in_XR.html#appendix",
    "title": "EmBARDiment: an Embodied AI Agent for Productivity in XR",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.08158v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.08158v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8561"
  },
  {
    "objectID": "posts/WildTeaming_at_Scale_From_In_the_Wild_Jailbreaks_to_(Adversarially)_Safer_Language_Models/2024-06-26-WildTeaming_at_Scale_From_In_the_Wild_Jailbreaks_to_(Adversarially)_Safer_Language_Models.html#appendix",
    "href": "posts/WildTeaming_at_Scale_From_In_the_Wild_Jailbreaks_to_(Adversarially)_Safer_Language_Models/2024-06-26-WildTeaming_at_Scale_From_In_the_Wild_Jailbreaks_to_(Adversarially)_Safer_Language_Models.html#appendix",
    "title": "WildTeaming at Scale: From In-the-Wild Jailbreaks to (Adversarially) Safer Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18510v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18510v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9370"
  },
  {
    "objectID": "posts/Revisiting_the_Impact_of_Pursuing_Modularity_for_Code_Generation/2024-07-16-Revisiting_the_Impact_of_Pursuing_Modularity_for_Code_Generation.html#appendix",
    "href": "posts/Revisiting_the_Impact_of_Pursuing_Modularity_for_Code_Generation/2024-07-16-Revisiting_the_Impact_of_Pursuing_Modularity_for_Code_Generation.html#appendix",
    "title": "Revisiting the Impact of Pursuing Modularity for Code Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.11406v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.11406v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3658"
  },
  {
    "objectID": "posts/AnnotatedTables_A_Large_Tabular_Dataset_with_Language_Model_Annotations/2024-06-24-AnnotatedTables_A_Large_Tabular_Dataset_with_Language_Model_Annotations.html#appendix",
    "href": "posts/AnnotatedTables_A_Large_Tabular_Dataset_with_Language_Model_Annotations/2024-06-24-AnnotatedTables_A_Large_Tabular_Dataset_with_Language_Model_Annotations.html#appendix",
    "title": "AnnotatedTables: A Large Tabular Dataset with Language Model Annotations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16349v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16349v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13468"
  },
  {
    "objectID": "posts/A_Decoding_Acceleration_Framework_for_Industrial_Deployable_LLM_based_Recommender_Systems/2024-08-11-A_Decoding_Acceleration_Framework_for_Industrial_Deployable_LLM_based_Recommender_Systems.html#major-findings",
    "href": "posts/A_Decoding_Acceleration_Framework_for_Industrial_Deployable_LLM_based_Recommender_Systems/2024-08-11-A_Decoding_Acceleration_Framework_for_Industrial_Deployable_LLM_based_Recommender_Systems.html#major-findings",
    "title": "A Decoding Acceleration Framework for Industrial Deployable LLM-based Recommender Systems",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nDiver outperforms state-of-the-art reranking models in terms of utility and diversity, as demonstrated by the experimental results.\nDiver performs well on different scenarios with various importance of diversity, as shown by the results of RQ2.\nDiver performs well on different initial ranking lists, as shown by the results of RQ3.\nDifferent hyper-parameter settings, such as the dimension of hidden states, influence the performance of Diver, as shown by the results of RQ4.\nEach designed component, such as the user history behaviors and the aggregation function, influences the performance of Diver, as shown by the results of RQ5."
  },
  {
    "objectID": "posts/A_Decoding_Acceleration_Framework_for_Industrial_Deployable_LLM_based_Recommender_Systems/2024-08-11-A_Decoding_Acceleration_Framework_for_Industrial_Deployable_LLM_based_Recommender_Systems.html#analysis-and-critique",
    "href": "posts/A_Decoding_Acceleration_Framework_for_Industrial_Deployable_LLM_based_Recommender_Systems/2024-08-11-A_Decoding_Acceleration_Framework_for_Industrial_Deployable_LLM_based_Recommender_Systems.html#analysis-and-critique",
    "title": "A Decoding Acceleration Framework for Industrial Deployable LLM-based Recommender Systems",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe article provides a clear and detailed explanation of the proposed model, Diver, and its components.\nThe experimental results demonstrate the effectiveness of Diver in improving both utility and diversity in recommender systems.\nThe article also acknowledges the limitations of the proposed model, such as the need to revise the objective function and the potential for further improvement in the optimization process.\nThe article could benefit from a more detailed discussion of the potential biases and limitations of the experimental results, such as the use of specific datasets and the choice of evaluation metrics.\nThe article could also benefit from a more detailed comparison with other state-of-the-art reranking models, such as DLCM, Seq2Slate, and PRM.\nThe article could also benefit from a more detailed discussion of the potential applications and implications of the proposed model in real-world recommender"
  },
  {
    "objectID": "posts/A_Decoding_Acceleration_Framework_for_Industrial_Deployable_LLM_based_Recommender_Systems/2024-08-11-A_Decoding_Acceleration_Framework_for_Industrial_Deployable_LLM_based_Recommender_Systems.html#appendix",
    "href": "posts/A_Decoding_Acceleration_Framework_for_Industrial_Deployable_LLM_based_Recommender_Systems/2024-08-11-A_Decoding_Acceleration_Framework_for_Industrial_Deployable_LLM_based_Recommender_Systems.html#appendix",
    "title": "A Decoding Acceleration Framework for Industrial Deployable LLM-based Recommender Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.05676v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.05676v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2018"
  },
  {
    "objectID": "posts/Improving_Steering_and_Verification_in_AI_Assisted_Data_Analysis_with_Interactive_Task_Decomposition/2024-07-02-Improving_Steering_and_Verification_in_AI_Assisted_Data_Analysis_with_Interactive_Task_Decomposition.html",
    "href": "posts/Improving_Steering_and_Verification_in_AI_Assisted_Data_Analysis_with_Interactive_Task_Decomposition/2024-07-02-Improving_Steering_and_Verification_in_AI_Assisted_Data_Analysis_with_Interactive_Task_Decomposition.html",
    "title": "Improving Steering and Verification in AI-Assisted Data Analysis with Interactive Task Decomposition",
    "section": "",
    "text": "Summary:\nThis paper presents a study on the challenges of using AI-assisted data analysis tools, specifically focusing on steering and verification. The study involved 15 participants and identified two significant limitations: steering the AI and verifying its output. The paper then introduces a novel approach to improve steering and verification using editable AI assumptions, progressive disclosure, and non-linear conversations. Two implementations of this approach are presented, each balancing information overload and the degree of user control differently. A controlled, within-subjects experiment was conducted to compare these systems with a Conversational baseline system. The results showed that users reported significantly greater control with the two new systems and found intervention, correction, and verification easier compared to the baseline.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a well-structured and coherent summary of the study and its findings. The use of markdown for formatting enhances the readability and organization of the information. The study’s methodology and results are clearly explained, and the comparison with a Conversational baseline system provides a useful point of reference.\nHowever, there are some potential limitations and areas for improvement. The sample size of 15 participants is relatively small, which may limit the generalizability of the findings. Additionally, the study does not provide detailed information on the specific tasks or datasets used, making it difficult to assess the validity and applicability of the results. Furthermore, the paper does not discuss any potential biases or confounding factors that may have influenced the results.\nOverall, the paper offers valuable insights into the challenges and potential solutions for improving steering and verification in AI-assisted data analysis. However, further research with larger sample sizes and more diverse tasks"
  },
  {
    "objectID": "posts/Improving_Steering_and_Verification_in_AI_Assisted_Data_Analysis_with_Interactive_Task_Decomposition/2024-07-02-Improving_Steering_and_Verification_in_AI_Assisted_Data_Analysis_with_Interactive_Task_Decomposition.html#appendix",
    "href": "posts/Improving_Steering_and_Verification_in_AI_Assisted_Data_Analysis_with_Interactive_Task_Decomposition/2024-07-02-Improving_Steering_and_Verification_in_AI_Assisted_Data_Analysis_with_Interactive_Task_Decomposition.html#appendix",
    "title": "Improving Steering and Verification in AI-Assisted Data Analysis with Interactive Task Decomposition",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02651v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02651v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17913"
  },
  {
    "objectID": "posts/MoPS_Modular_Story_Premise_Synthesis_for_Open_Ended_Automatic_Story_Generation/2024-06-09-MoPS_Modular_Story_Premise_Synthesis_for_Open_Ended_Automatic_Story_Generation.html#appendix",
    "href": "posts/MoPS_Modular_Story_Premise_Synthesis_for_Open_Ended_Automatic_Story_Generation/2024-06-09-MoPS_Modular_Story_Premise_Synthesis_for_Open_Ended_Automatic_Story_Generation.html#appendix",
    "title": "MoPS: Modular Story Premise Synthesis for Open-Ended Automatic Story Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05690v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05690v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9468"
  },
  {
    "objectID": "posts/Knowledge_Tagging_System_on_Math_Questions_via_LLMs_with_Flexible_Demonstration_Retriever/2024-06-19-Knowledge_Tagging_System_on_Math_Questions_via_LLMs_with_Flexible_Demonstration_Retriever.html#appendix",
    "href": "posts/Knowledge_Tagging_System_on_Math_Questions_via_LLMs_with_Flexible_Demonstration_Retriever/2024-06-19-Knowledge_Tagging_System_on_Math_Questions_via_LLMs_with_Flexible_Demonstration_Retriever.html#appendix",
    "title": "Knowledge Tagging System on Math Questions via LLMs with Flexible Demonstration Retriever",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13885v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13885v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6455"
  },
  {
    "objectID": "posts/Zero_Shot_End_To_End_Spoken_Question_Answering_In_Medical_Domain/2024-06-09-Zero_Shot_End_To_End_Spoken_Question_Answering_In_Medical_Domain.html#appendix",
    "href": "posts/Zero_Shot_End_To_End_Spoken_Question_Answering_In_Medical_Domain/2024-06-09-Zero_Shot_End_To_End_Spoken_Question_Answering_In_Medical_Domain.html#appendix",
    "title": "Zero-Shot End-To-End Spoken Question Answering In Medical Domain",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05876v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05876v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4005"
  },
  {
    "objectID": "posts/Hopping_Too_Late_Exploring_the_Limitations_of_Large_Language_Models_on_Multi_Hop_Queries/2024-06-18-Hopping_Too_Late_Exploring_the_Limitations_of_Large_Language_Models_on_Multi_Hop_Queries.html#appendix",
    "href": "posts/Hopping_Too_Late_Exploring_the_Limitations_of_Large_Language_Models_on_Multi_Hop_Queries/2024-06-18-Hopping_Too_Late_Exploring_the_Limitations_of_Large_Language_Models_on_Multi_Hop_Queries.html#appendix",
    "title": "Hopping Too Late: Exploring the Limitations of Large Language Models on Multi-Hop Queries",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12775v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12775v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8033"
  },
  {
    "objectID": "posts/LLMs_can_Schedule/2024-08-13-LLMs_can_Schedule.html#appendix",
    "href": "posts/LLMs_can_Schedule/2024-08-13-LLMs_can_Schedule.html#appendix",
    "title": "LLMs can Schedule",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.06993v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.06993v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5428"
  },
  {
    "objectID": "posts/Exploring_Large_Language_Models_to_generate_Easy_to_Read_content/2024-07-29-Exploring_Large_Language_Models_to_generate_Easy_to_Read_content.html#appendix",
    "href": "posts/Exploring_Large_Language_Models_to_generate_Easy_to_Read_content/2024-07-29-Exploring_Large_Language_Models_to_generate_Easy_to_Read_content.html#appendix",
    "title": "Exploring Large Language Models to generate Easy to Read content",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20046v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20046v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8462"
  },
  {
    "objectID": "posts/Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model/2024-06-11-Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model.html",
    "href": "posts/Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model/2024-06-11-Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model.html",
    "title": "Paying More Attention to Source Context: Mitigating Unfaithful Translations from Large Language Model",
    "section": "",
    "text": "Summary:\nThe paper focuses on the issue of unfaithful translations in large language models (LLMs) due to insufficient focus on the source context. The authors propose three methods to address this issue: reweight attention, contrastive decoding, and target-constrained tuning. The reweight attention method adjusts the attention weight of the source context to help models focus on the source context during generation. Contrastive decoding reduces the influence of target prefixes, and target-constrained tuning encourages LLMs to avoid excessive dependence on specific target prefixes. The experimental results show that the proposed methods improve translation performance across several language pairs in the proposed unfaithful translation test sets, outperforming baseline methods and effectively reducing the phenomenon of hallucinatory and unfaithful translations.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model/2024-06-11-Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model.html#appendix",
    "href": "posts/Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model/2024-06-11-Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model.html#appendix",
    "title": "Paying More Attention to Source Context: Mitigating Unfaithful Translations from Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07036v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07036v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10716"
  },
  {
    "objectID": "posts/MoFO_Momentum_Filtered_Optimizer_for_Mitigating_Forgetting_in_LLM_Fine_Tuning/2024-07-30-MoFO_Momentum_Filtered_Optimizer_for_Mitigating_Forgetting_in_LLM_Fine_Tuning.html#appendix",
    "href": "posts/MoFO_Momentum_Filtered_Optimizer_for_Mitigating_Forgetting_in_LLM_Fine_Tuning/2024-07-30-MoFO_Momentum_Filtered_Optimizer_for_Mitigating_Forgetting_in_LLM_Fine_Tuning.html#appendix",
    "title": "MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting in LLM Fine-Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20999v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20999v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7266"
  },
  {
    "objectID": "posts/WeKnow_RAG_An_Adaptive_Approach_for_Retrieval_Augmented_Generation_Integrating_Web_Search_and_Knowledge_Graphs/2024-08-14-WeKnow_RAG_An_Adaptive_Approach_for_Retrieval_Augmented_Generation_Integrating_Web_Search_and_Knowledge_Graphs.html#appendix",
    "href": "posts/WeKnow_RAG_An_Adaptive_Approach_for_Retrieval_Augmented_Generation_Integrating_Web_Search_and_Knowledge_Graphs/2024-08-14-WeKnow_RAG_An_Adaptive_Approach_for_Retrieval_Augmented_Generation_Integrating_Web_Search_and_Knowledge_Graphs.html#appendix",
    "title": "WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07611v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07611v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4912"
  },
  {
    "objectID": "posts/SpecRover_Code_Intent_Extraction_via_LLMs/2024-08-05-SpecRover_Code_Intent_Extraction_via_LLMs.html#appendix",
    "href": "posts/SpecRover_Code_Intent_Extraction_via_LLMs/2024-08-05-SpecRover_Code_Intent_Extraction_via_LLMs.html#appendix",
    "title": "SpecRover: Code Intent Extraction via LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02232v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02232v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10030"
  },
  {
    "objectID": "posts/Large_Language_Models_for_Secure_Code_Assessment_A_Multi_Language_Empirical_Study/2024-08-12-Large_Language_Models_for_Secure_Code_Assessment_A_Multi_Language_Empirical_Study.html#appendix",
    "href": "posts/Large_Language_Models_for_Secure_Code_Assessment_A_Multi_Language_Empirical_Study/2024-08-12-Large_Language_Models_for_Secure_Code_Assessment_A_Multi_Language_Empirical_Study.html#appendix",
    "title": "Large Language Models for Secure Code Assessment: A Multi-Language Empirical Study",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.06428v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.06428v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8522"
  },
  {
    "objectID": "posts/Aligning_Large_Language_Models_with_Diverse_Political_Viewpoints/2024-06-20-Aligning_Large_Language_Models_with_Diverse_Political_Viewpoints.html#appendix",
    "href": "posts/Aligning_Large_Language_Models_with_Diverse_Political_Viewpoints/2024-06-20-Aligning_Large_Language_Models_with_Diverse_Political_Viewpoints.html#appendix",
    "title": "Aligning Large Language Models with Diverse Political Viewpoints",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14155v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14155v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5339"
  },
  {
    "objectID": "posts/Generation_and_De_Identification_of_Indian_Clinical_Discharge_Summaries_using_LLMs/2024-07-08-Generation_and_De_Identification_of_Indian_Clinical_Discharge_Summaries_using_LLMs.html#appendix",
    "href": "posts/Generation_and_De_Identification_of_Indian_Clinical_Discharge_Summaries_using_LLMs/2024-07-08-Generation_and_De_Identification_of_Indian_Clinical_Discharge_Summaries_using_LLMs.html#appendix",
    "title": "Generation and De-Identification of Indian Clinical Discharge Summaries using LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05887v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05887v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9455"
  },
  {
    "objectID": "posts/MegaAgent_A_Practical_Framework_for_Autonomous_Cooperation_in_Large_Scale_LLM_Agent_Systems/2024-08-19-MegaAgent_A_Practical_Framework_for_Autonomous_Cooperation_in_Large_Scale_LLM_Agent_Systems.html#appendix",
    "href": "posts/MegaAgent_A_Practical_Framework_for_Autonomous_Cooperation_in_Large_Scale_LLM_Agent_Systems/2024-08-19-MegaAgent_A_Practical_Framework_for_Autonomous_Cooperation_in_Large_Scale_LLM_Agent_Systems.html#appendix",
    "title": "MegaAgent: A Practical Framework for Autonomous Cooperation in Large-Scale LLM Agent Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09955v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09955v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10060"
  },
  {
    "objectID": "posts/FinDKG_Dynamic_Knowledge_Graphs_with_Large_Language_Models_for_Detecting_Global_Trends_in_Financial_Markets/2024-07-15-FinDKG_Dynamic_Knowledge_Graphs_with_Large_Language_Models_for_Detecting_Global_Trends_in_Financial_Markets.html#appendix",
    "href": "posts/FinDKG_Dynamic_Knowledge_Graphs_with_Large_Language_Models_for_Detecting_Global_Trends_in_Financial_Markets/2024-07-15-FinDKG_Dynamic_Knowledge_Graphs_with_Large_Language_Models_for_Detecting_Global_Trends_in_Financial_Markets.html#appendix",
    "title": "FinDKG: Dynamic Knowledge Graphs with Large Language Models for Detecting Global Trends in Financial Markets",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10909v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10909v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6659"
  },
  {
    "objectID": "posts/Dye4AI_Assuring_Data_Boundary_on_Generative_AI_Services/2024-06-20-Dye4AI_Assuring_Data_Boundary_on_Generative_AI_Services.html#appendix",
    "href": "posts/Dye4AI_Assuring_Data_Boundary_on_Generative_AI_Services/2024-06-20-Dye4AI_Assuring_Data_Boundary_on_Generative_AI_Services.html#appendix",
    "title": "Dye4AI: Assuring Data Boundary on Generative AI Services",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14114v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14114v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15379"
  },
  {
    "objectID": "posts/How_to_Make_the_Most_of_LLMs_Grammatical_Knowledge_for_Acceptability_Judgments/2024-08-19-How_to_Make_the_Most_of_LLMs_Grammatical_Knowledge_for_Acceptability_Judgments.html#appendix",
    "href": "posts/How_to_Make_the_Most_of_LLMs_Grammatical_Knowledge_for_Acceptability_Judgments/2024-08-19-How_to_Make_the_Most_of_LLMs_Grammatical_Knowledge_for_Acceptability_Judgments.html#appendix",
    "title": "How to Make the Most of LLMs’ Grammatical Knowledge for Acceptability Judgments",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09639v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09639v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5926"
  },
  {
    "objectID": "posts/Importance_Weighting_Can_Help_Large_Language_Models_Self_Improve/2024-08-19-Importance_Weighting_Can_Help_Large_Language_Models_Self_Improve.html#appendix",
    "href": "posts/Importance_Weighting_Can_Help_Large_Language_Models_Self_Improve/2024-08-19-Importance_Weighting_Can_Help_Large_Language_Models_Self_Improve.html#appendix",
    "title": "Importance Weighting Can Help Large Language Models Self-Improve",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09849v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09849v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7239"
  },
  {
    "objectID": "posts/LiveMind_Low_latency_Large_Language_Models_with_Simultaneous_Inference/2024-06-20-LiveMind_Low_latency_Large_Language_Models_with_Simultaneous_Inference.html#appendix",
    "href": "posts/LiveMind_Low_latency_Large_Language_Models_with_Simultaneous_Inference/2024-06-20-LiveMind_Low_latency_Large_Language_Models_with_Simultaneous_Inference.html#appendix",
    "title": "LiveMind: Low-latency Large Language Models with Simultaneous Inference",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14319v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14319v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8602"
  },
  {
    "objectID": "posts/Can_Language_Models_Evaluate_Human_Written_Text_Case_Study_on_Korean_Student_Writing_for_Education/2024-07-24-Can_Language_Models_Evaluate_Human_Written_Text_Case_Study_on_Korean_Student_Writing_for_Education.html#appendix",
    "href": "posts/Can_Language_Models_Evaluate_Human_Written_Text_Case_Study_on_Korean_Student_Writing_for_Education/2024-07-24-Can_Language_Models_Evaluate_Human_Written_Text_Case_Study_on_Korean_Student_Writing_for_Education.html#appendix",
    "title": "Can Language Models Evaluate Human Written Text? Case Study on Korean Student Writing for Education",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17022v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17022v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2789"
  },
  {
    "objectID": "posts/Divine_LLaMAs_Bias_Stereotypes_Stigmatization_and_Emotion_Representation_of_Religion_in_Large_Language_Models/2024-07-09-Divine_LLaMAs_Bias_Stereotypes_Stigmatization_and_Emotion_Representation_of_Religion_in_Large_Language_Models.html#appendix",
    "href": "posts/Divine_LLaMAs_Bias_Stereotypes_Stigmatization_and_Emotion_Representation_of_Religion_in_Large_Language_Models/2024-07-09-Divine_LLaMAs_Bias_Stereotypes_Stigmatization_and_Emotion_Representation_of_Religion_in_Large_Language_Models.html#appendix",
    "title": "Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06908v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06908v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6978"
  },
  {
    "objectID": "posts/A_Comprehensive_Evaluation_of_Parameter_Efficient_Fine_Tuning_on_Automated_Program_Repair/2024-06-09-A_Comprehensive_Evaluation_of_Parameter_Efficient_Fine_Tuning_on_Automated_Program_Repair.html#appendix",
    "href": "posts/A_Comprehensive_Evaluation_of_Parameter_Efficient_Fine_Tuning_on_Automated_Program_Repair/2024-06-09-A_Comprehensive_Evaluation_of_Parameter_Efficient_Fine_Tuning_on_Automated_Program_Repair.html#appendix",
    "title": "A Comprehensive Evaluation of Parameter-Efficient Fine-Tuning on Automated Program Repair",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05639v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05639v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12423"
  },
  {
    "objectID": "posts/MALSIGHT_Exploring_Malicious_Source_Code_and_Benign_Pseudocode_for_Iterative_Binary_Malware_Summarization/2024-06-26-MALSIGHT_Exploring_Malicious_Source_Code_and_Benign_Pseudocode_for_Iterative_Binary_Malware_Summarization.html#appendix",
    "href": "posts/MALSIGHT_Exploring_Malicious_Source_Code_and_Benign_Pseudocode_for_Iterative_Binary_Malware_Summarization/2024-06-26-MALSIGHT_Exploring_Malicious_Source_Code_and_Benign_Pseudocode_for_Iterative_Binary_Malware_Summarization.html#appendix",
    "title": "MALSIGHT: Exploring Malicious Source Code and Benign Pseudocode for Iterative Binary Malware Summarization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18379v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18379v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12933"
  },
  {
    "objectID": "posts/DistillSeq_A_Framework_for_Safety_Alignment_Testing_in_Large_Language_Models_using_Knowledge_Distillation/2024-07-14-DistillSeq_A_Framework_for_Safety_Alignment_Testing_in_Large_Language_Models_using_Knowledge_Distillation.html#appendix",
    "href": "posts/DistillSeq_A_Framework_for_Safety_Alignment_Testing_in_Large_Language_Models_using_Knowledge_Distillation/2024-07-14-DistillSeq_A_Framework_for_Safety_Alignment_Testing_in_Large_Language_Models_using_Knowledge_Distillation.html#appendix",
    "title": "DistillSeq: A Framework for Safety Alignment Testing in Large Language Models using Knowledge Distillation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10106v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10106v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10899"
  },
  {
    "objectID": "posts/Empowering_LLMs_for_Verilog_Generation_through_Multi_Level_Summarization/2024-07-15-Empowering_LLMs_for_Verilog_Generation_through_Multi_Level_Summarization.html#appendix",
    "href": "posts/Empowering_LLMs_for_Verilog_Generation_through_Multi_Level_Summarization/2024-07-15-Empowering_LLMs_for_Verilog_Generation_through_Multi_Level_Summarization.html#appendix",
    "title": "Empowering LLMs for Verilog Generation through Multi-Level Summarization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10424v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10424v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6724"
  },
  {
    "objectID": "posts/RS_Agent_Automating_Remote_Sensing_Tasks_through_Intelligent_Agents/2024-06-11-RS_Agent_Automating_Remote_Sensing_Tasks_through_Intelligent_Agents.html#appendix",
    "href": "posts/RS_Agent_Automating_Remote_Sensing_Tasks_through_Intelligent_Agents/2024-06-11-RS_Agent_Automating_Remote_Sensing_Tasks_through_Intelligent_Agents.html#appendix",
    "title": "RS-Agent: Automating Remote Sensing Tasks through Intelligent Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07089v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07089v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5913"
  },
  {
    "objectID": "posts/Athena_Safe_Autonomous_Agents_with_Verbal_Contrastive_Learning/2024-08-20-Athena_Safe_Autonomous_Agents_with_Verbal_Contrastive_Learning.html#appendix",
    "href": "posts/Athena_Safe_Autonomous_Agents_with_Verbal_Contrastive_Learning/2024-08-20-Athena_Safe_Autonomous_Agents_with_Verbal_Contrastive_Learning.html#appendix",
    "title": "Athena: Safe Autonomous Agents with Verbal Contrastive Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11021v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11021v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4476"
  },
  {
    "objectID": "posts/Recognizing_Emotion_Regulation_Strategies_from_Human_Behavior_with_Large_Language_Models/2024-08-08-Recognizing_Emotion_Regulation_Strategies_from_Human_Behavior_with_Large_Language_Models.html#major-findings",
    "href": "posts/Recognizing_Emotion_Regulation_Strategies_from_Human_Behavior_with_Large_Language_Models/2024-08-08-Recognizing_Emotion_Regulation_Strategies_from_Human_Behavior_with_Large_Language_Models.html#major-findings",
    "title": "Recognizing Emotion Regulation Strategies from Human Behavior with Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe study utilizes LLMs instruction-tuned on prompts incorporating multimodal behavior to classify peoples’ strategies to regulate the emotion shame.\nIn the first cross-user evaluations on the recently introduced Deep corpus, the approach outperforms the previous state of the art based on expert-constructed Bayesian Networks when information from post-interaction interviews is not available.\nExtensive ablation experiments are conducted, highlighting the impact of different modalities on performance."
  },
  {
    "objectID": "posts/Recognizing_Emotion_Regulation_Strategies_from_Human_Behavior_with_Large_Language_Models/2024-08-08-Recognizing_Emotion_Regulation_Strategies_from_Human_Behavior_with_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/Recognizing_Emotion_Regulation_Strategies_from_Human_Behavior_with_Large_Language_Models/2024-08-08-Recognizing_Emotion_Regulation_Strategies_from_Human_Behavior_with_Large_Language_Models.html#analysis-and-critique",
    "title": "Recognizing Emotion Regulation Strategies from Human Behavior with Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe study presents a significant improvement over previous approaches based on Bayesian Networks and highlights the importance of modeling verbal behavior in emotion regulation. However, the study is limited by the size and variability of the Deep corpus, which is limited in size and variability due to the need for verbalized introspection and the complexity of the annotations. The ten participants were all having the same cultural background, similar age, and were pre-selected having good skills to reflect on their internal experiences. Therefore, the full range of emotion regulation strategies and associated nonverbal behavior may not be captured, which may limit the generalizability of the findings.\nThe study focuses on emotion regulation in validated shame-eliciting situations, limiting the extension of the work to situations where other emotion classes are elicited. Future work should extend the application of this proposed hybrid approach to other emotion classes, to gain an overall deeper understanding of individual emotional experiences.\nFinally, while the proposed approach allows to automatically infer emotion regulation strategies from behavioral descriptions, the descriptions provided with the Deep dataset were manually annotated. Future work should replace such manual steps"
  },
  {
    "objectID": "posts/Recognizing_Emotion_Regulation_Strategies_from_Human_Behavior_with_Large_Language_Models/2024-08-08-Recognizing_Emotion_Regulation_Strategies_from_Human_Behavior_with_Large_Language_Models.html#appendix",
    "href": "posts/Recognizing_Emotion_Regulation_Strategies_from_Human_Behavior_with_Large_Language_Models/2024-08-08-Recognizing_Emotion_Regulation_Strategies_from_Human_Behavior_with_Large_Language_Models.html#appendix",
    "title": "Recognizing Emotion Regulation Strategies from Human Behavior with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04420v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04420v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6827"
  },
  {
    "objectID": "posts/Generating_Educational_Materials_with_Different_Levels_of_Readability_using_LLMs/2024-06-18-Generating_Educational_Materials_with_Different_Levels_of_Readability_using_LLMs.html#appendix",
    "href": "posts/Generating_Educational_Materials_with_Different_Levels_of_Readability_using_LLMs/2024-06-18-Generating_Educational_Materials_with_Different_Levels_of_Readability_using_LLMs.html#appendix",
    "title": "Generating Educational Materials with Different Levels of Readability using LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12787v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12787v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5307"
  },
  {
    "objectID": "posts/MIDAS_Multi_level_Intent_Domain_And_Slot_Knowledge_Distillation_for_Multi_turn_NLU/2024-08-15-MIDAS_Multi_level_Intent_Domain_And_Slot_Knowledge_Distillation_for_Multi_turn_NLU.html#major-findings",
    "href": "posts/MIDAS_Multi_level_Intent_Domain_And_Slot_Knowledge_Distillation_for_Multi_turn_NLU/2024-08-15-MIDAS_Multi_level_Intent_Domain_And_Slot_Knowledge_Distillation_for_Multi_turn_NLU.html#major-findings",
    "title": "MIDAS: Multi-level Intent, Domain, And Slot Knowledge Distillation for Multi-turn NLU",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nMIDAS introduces a novel multi-level, multi-teacher knowledge distillation model to enhance multi-turn NLU, outperforming across widely-used multi-NLU datasets and producing superior performance in all intent detection, slot filling, and domain classification, even compared with LLMs.\nThe paper introduces multi-level teacher loss functions, shedding light on their impact within the multi-teacher knowledge distillation and guiding a student model."
  },
  {
    "objectID": "posts/MIDAS_Multi_level_Intent_Domain_And_Slot_Knowledge_Distillation_for_Multi_turn_NLU/2024-08-15-MIDAS_Multi_level_Intent_Domain_And_Slot_Knowledge_Distillation_for_Multi_turn_NLU.html#analysis-and-critique",
    "href": "posts/MIDAS_Multi_level_Intent_Domain_And_Slot_Knowledge_Distillation_for_Multi_turn_NLU/2024-08-15-MIDAS_Multi_level_Intent_Domain_And_Slot_Knowledge_Distillation_for_Multi_turn_NLU.html#analysis-and-critique",
    "title": "MIDAS: Multi-level Intent, Domain, And Slot Knowledge Distillation for Multi-turn NLU",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper does not provide a detailed comparison with other existing NLU models, making it difficult to assess the true novelty and effectiveness of the proposed approach.\nThe paper does not discuss the potential limitations or shortcomings of the proposed approach, such as the computational complexity of training multiple teachers or the potential for overfitting.\nThe paper does not provide a clear explanation of how the multi-teacher loss is calculated or how it is used to guide the student model.\nThe paper does not provide a detailed analysis of the experimental results, making it difficult to understand the significance of the reported improvements.\nThe paper does not discuss the potential applications or use cases of the proposed approach, making it difficult to understand its practical relevance."
  },
  {
    "objectID": "posts/MIDAS_Multi_level_Intent_Domain_And_Slot_Knowledge_Distillation_for_Multi_turn_NLU/2024-08-15-MIDAS_Multi_level_Intent_Domain_And_Slot_Knowledge_Distillation_for_Multi_turn_NLU.html#appendix",
    "href": "posts/MIDAS_Multi_level_Intent_Domain_And_Slot_Knowledge_Distillation_for_Multi_turn_NLU/2024-08-15-MIDAS_Multi_level_Intent_Domain_And_Slot_Knowledge_Distillation_for_Multi_turn_NLU.html#appendix",
    "title": "MIDAS: Multi-level Intent, Domain, And Slot Knowledge Distillation for Multi-turn NLU",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.08144v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.08144v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8516"
  },
  {
    "objectID": "posts/PsycoLLM_Enhancing_LLM_for_Psychological_Understanding_and_Evaluation/2024-07-08-PsycoLLM_Enhancing_LLM_for_Psychological_Understanding_and_Evaluation.html#appendix",
    "href": "posts/PsycoLLM_Enhancing_LLM_for_Psychological_Understanding_and_Evaluation/2024-07-08-PsycoLLM_Enhancing_LLM_for_Psychological_Understanding_and_Evaluation.html#appendix",
    "title": "PsycoLLM: Enhancing LLM for Psychological Understanding and Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05721v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05721v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5547"
  },
  {
    "objectID": "posts/Are_LLM_based_Recommenders_Already_the_Best_Simple_Scaled_Cross_entropy_Unleashes_the_Potential_of_Traditional_Sequential_Recommenders/2024-08-26-Are_LLM_based_Recommenders_Already_the_Best_Simple_Scaled_Cross_entropy_Unleashes_the_Potential_of_Traditional_Sequential_Recommenders.html#major-findings",
    "href": "posts/Are_LLM_based_Recommenders_Already_the_Best_Simple_Scaled_Cross_entropy_Unleashes_the_Potential_of_Traditional_Sequential_Recommenders/2024-08-26-Are_LLM_based_Recommenders_Already_the_Best_Simple_Scaled_Cross_entropy_Unleashes_the_Potential_of_Traditional_Sequential_Recommenders.html#major-findings",
    "title": "Are LLM-based Recommenders Already the Best? Simple Scaled Cross-entropy Unleashes the Potential of Traditional Sequential Recommenders",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe cross-entropy loss has two desirable properties: tightness and coverage, which contribute to its superiority in improving the ranking capability of recommenders.\nThe cross-entropy loss is not yet optimal in terms of some ranking metrics, and an effective alternative is to scale up the sampled normalizing term when full softmax cannot be performed.\nTraditional recommendation models can surpass LLM-based counterparts by utilizing the cross-entropy loss and the proposed alternative."
  },
  {
    "objectID": "posts/Are_LLM_based_Recommenders_Already_the_Best_Simple_Scaled_Cross_entropy_Unleashes_the_Potential_of_Traditional_Sequential_Recommenders/2024-08-26-Are_LLM_based_Recommenders_Already_the_Best_Simple_Scaled_Cross_entropy_Unleashes_the_Potential_of_Traditional_Sequential_Recommenders.html#analysis-and-critique",
    "href": "posts/Are_LLM_based_Recommenders_Already_the_Best_Simple_Scaled_Cross_entropy_Unleashes_the_Potential_of_Traditional_Sequential_Recommenders/2024-08-26-Are_LLM_based_Recommenders_Already_the_Best_Simple_Scaled_Cross_entropy_Unleashes_the_Potential_of_Traditional_Sequential_Recommenders.html#analysis-and-critique",
    "title": "Are LLM-based Recommenders Already the Best? Simple Scaled Cross-entropy Unleashes the Potential of Traditional Sequential Recommenders",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe study provides a valuable theoretical foundation for understanding the superiority of the cross-entropy loss in improving the ranking capability of recommenders.\nThe proposed alternative to the cross-entropy loss, scaling up the sampled normalizing term, is a promising approach when full softmax cannot be performed.\nThe study highlights the potential of traditional recommendation models, which can surpass LLM-based counterparts by utilizing the cross-entropy loss and the proposed alternative.\nHowever, the study does not provide empirical evidence to support the theoretical findings, which could be a limitation.\nThe study focuses on the cross-entropy loss and its alternative, but other loss functions, such as binary cross-entropy and Bayesian personalized ranking, are not discussed in detail.\nThe study does not consider the computational complexity of the proposed alternative, which could be a concern in practical applications.\n\nIn conclusion, this study provides valuable insights into the superiority of the cross-entropy loss in improving the ranking capability of recommenders and proposes an effective alternative when full softmax cannot be performed. However, the lack of empirical evidence and the focus on a single loss"
  },
  {
    "objectID": "posts/Are_LLM_based_Recommenders_Already_the_Best_Simple_Scaled_Cross_entropy_Unleashes_the_Potential_of_Traditional_Sequential_Recommenders/2024-08-26-Are_LLM_based_Recommenders_Already_the_Best_Simple_Scaled_Cross_entropy_Unleashes_the_Potential_of_Traditional_Sequential_Recommenders.html#appendix",
    "href": "posts/Are_LLM_based_Recommenders_Already_the_Best_Simple_Scaled_Cross_entropy_Unleashes_the_Potential_of_Traditional_Sequential_Recommenders/2024-08-26-Are_LLM_based_Recommenders_Already_the_Best_Simple_Scaled_Cross_entropy_Unleashes_the_Potential_of_Traditional_Sequential_Recommenders.html#appendix",
    "title": "Are LLM-based Recommenders Already the Best? Simple Scaled Cross-entropy Unleashes the Potential of Traditional Sequential Recommenders",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.14238v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.14238v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7714"
  },
  {
    "objectID": "posts/FaceGPT_Self_supervised_Learning_to_Chat_about_3D_Human_Faces/2024-06-11-FaceGPT_Self_supervised_Learning_to_Chat_about_3D_Human_Faces.html#appendix",
    "href": "posts/FaceGPT_Self_supervised_Learning_to_Chat_about_3D_Human_Faces/2024-06-11-FaceGPT_Self_supervised_Learning_to_Chat_about_3D_Human_Faces.html#appendix",
    "title": "FaceGPT: Self-supervised Learning to Chat about 3D Human Faces",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07163v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07163v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6381"
  },
  {
    "objectID": "posts/Self_Cognition_in_Large_Language_Models_An_Exploratory_Study/2024-07-01-Self_Cognition_in_Large_Language_Models_An_Exploratory_Study.html#appendix",
    "href": "posts/Self_Cognition_in_Large_Language_Models_An_Exploratory_Study/2024-07-01-Self_Cognition_in_Large_Language_Models_An_Exploratory_Study.html#appendix",
    "title": "Self-Cognition in Large Language Models: An Exploratory Study",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01505v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01505v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6005"
  },
  {
    "objectID": "posts/LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction/2024-06-20-LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction.html",
    "href": "posts/LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction/2024-06-20-LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction.html",
    "title": "LLM4CP: Adapting Large Language Models for Channel Prediction",
    "section": "",
    "text": "Summary:\nThe paper proposes a novel channel prediction method called LLM4CP, which is based on fine-tuning pre-trained GPT-2 for MISO-OFDM channel prediction tasks. The method predicts future downlink CSI sequences based on historical uplink CSI sequences and can be applied to both TDD and FDD systems. To account for channel characteristics, the authors have tailored preprocessor, embedding, and output modules to bridge the gap between CSI data and LLM. Preliminary simulations validate the superiority of LLM4CP over existing model-based and deep learning-based channel prediction methods in full-sample, few-shot, and generalization tests with acceptable training and inference costs.\nMajor Findings:\nAnalysis and Critique:\nOverall, the paper presents an interesting and promising approach to channel prediction based on fine-tuning pre-trained GPT-2. However, more detailed analysis and comparison with other state-of-the-art methods are needed to better understand its advantages and"
  },
  {
    "objectID": "posts/LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction/2024-06-20-LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction.html#appendix",
    "href": "posts/LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction/2024-06-20-LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction.html#appendix",
    "title": "LLM4CP: Adapting Large Language Models for Channel Prediction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14440v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14440v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8453"
  },
  {
    "objectID": "posts/Merging_Improves_Self_Critique_Against_Jailbreak_Attacks/2024-06-11-Merging_Improves_Self_Critique_Against_Jailbreak_Attacks.html#appendix",
    "href": "posts/Merging_Improves_Self_Critique_Against_Jailbreak_Attacks/2024-06-11-Merging_Improves_Self_Critique_Against_Jailbreak_Attacks.html#appendix",
    "title": "Merging Improves Self-Critique Against Jailbreak Attacks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07188v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07188v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3164"
  },
  {
    "objectID": "posts/Orca_Ocean_Significant_Wave_Height_Estimation_with_Spatio_temporally_Aware_Large_Language_Models/2024-07-29-Orca_Ocean_Significant_Wave_Height_Estimation_with_Spatio_temporally_Aware_Large_Language_Models.html#appendix",
    "href": "posts/Orca_Ocean_Significant_Wave_Height_Estimation_with_Spatio_temporally_Aware_Large_Language_Models/2024-07-29-Orca_Ocean_Significant_Wave_Height_Estimation_with_Spatio_temporally_Aware_Large_Language_Models.html#appendix",
    "title": "Orca: Ocean Significant Wave Height Estimation with Spatio-temporally Aware Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20053v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20053v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3804"
  },
  {
    "objectID": "posts/Learning_Fine_Grained_Grounded_Citations_for_Attributed_Large_Language_Models/2024-08-08-Learning_Fine_Grained_Grounded_Citations_for_Attributed_Large_Language_Models.html",
    "href": "posts/Learning_Fine_Grained_Grounded_Citations_for_Attributed_Large_Language_Models/2024-08-08-Learning_Fine_Grained_Grounded_Citations_for_Attributed_Large_Language_Models.html",
    "title": "Learning Fine-Grained Grounded Citations for Attributed Large Language Models",
    "section": "",
    "text": "Summary:\nThis paper introduces FRONT, a training framework designed to teach large language models (LLMs) to generate Fine-gRained grOuNded citations. The framework aims to improve citation quality and facilitate fine-grained verification by grounding model outputs in fine-grained supporting quotes. The authors evaluate FRONT on the ALCE benchmark and demonstrate its efficacy in generating superior grounded responses and highly supportive citations. The framework significantly outperforms all baselines, achieving an average of 14.21% improvement in citation quality across all datasets.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel approach to improving citation quality and fine-grained verification in LLMs. The proposed framework, FRONT, demonstrates promising results in generating grounded responses and highly supportive citations. However, the paper does not discuss the potential limitations or shortcomings of the framework, such as the computational resources required for training or the scalability of the approach. Additionally, the evaluation is limited to the ALCE benchmark, and further experiments on other datasets would provide a more comprehensive understanding of the framework’s performance. The authors also do not discuss the potential impact of the framework on the interpretability and transparency of LLMs, which is an important consideration in the development of AI systems."
  },
  {
    "objectID": "posts/Learning_Fine_Grained_Grounded_Citations_for_Attributed_Large_Language_Models/2024-08-08-Learning_Fine_Grained_Grounded_Citations_for_Attributed_Large_Language_Models.html#appendix",
    "href": "posts/Learning_Fine_Grained_Grounded_Citations_for_Attributed_Large_Language_Models/2024-08-08-Learning_Fine_Grained_Grounded_Citations_for_Attributed_Large_Language_Models.html#appendix",
    "title": "Learning Fine-Grained Grounded Citations for Attributed Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04568v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04568v1\n\n\nTruncated\nFalse\n\n\nWord Count\n22635"
  },
  {
    "objectID": "posts/3D_Building_Generation_in_Minecraft_via_Large_Language_Models/2024-06-13-3D_Building_Generation_in_Minecraft_via_Large_Language_Models.html#appendix",
    "href": "posts/3D_Building_Generation_in_Minecraft_via_Large_Language_Models/2024-06-13-3D_Building_Generation_in_Minecraft_via_Large_Language_Models.html#appendix",
    "title": "3D Building Generation in Minecraft via Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.08751v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.08751v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4481"
  },
  {
    "objectID": "posts/A_Survey_on_LLM_Based_Agentic_Workflows_and_LLM_Profiled_Components/2024-06-09-A_Survey_on_LLM_Based_Agentic_Workflows_and_LLM_Profiled_Components.html#appendix",
    "href": "posts/A_Survey_on_LLM_Based_Agentic_Workflows_and_LLM_Profiled_Components/2024-06-09-A_Survey_on_LLM_Based_Agentic_Workflows_and_LLM_Profiled_Components.html#appendix",
    "title": "A Survey on LLM-Based Agentic Workflows and LLM-Profiled Components",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05804v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05804v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5941"
  },
  {
    "objectID": "posts/Pruning_Large_Language_Models_with_Semi_Structural_Adaptive_Sparse_Training/2024-07-30-Pruning_Large_Language_Models_with_Semi_Structural_Adaptive_Sparse_Training.html#appendix",
    "href": "posts/Pruning_Large_Language_Models_with_Semi_Structural_Adaptive_Sparse_Training/2024-07-30-Pruning_Large_Language_Models_with_Semi_Structural_Adaptive_Sparse_Training.html#appendix",
    "title": "Pruning Large Language Models with Semi-Structural Adaptive Sparse Training",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20584v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20584v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6878"
  },
  {
    "objectID": "posts/Synthesizing_Text_to_SQL_Data_from_Weak_and_Strong_LLMs/2024-08-06-Synthesizing_Text_to_SQL_Data_from_Weak_and_Strong_LLMs.html#appendix",
    "href": "posts/Synthesizing_Text_to_SQL_Data_from_Weak_and_Strong_LLMs/2024-08-06-Synthesizing_Text_to_SQL_Data_from_Weak_and_Strong_LLMs.html#appendix",
    "title": "Synthesizing Text-to-SQL Data from Weak and Strong LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03256v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03256v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5683"
  },
  {
    "objectID": "posts/Chain_of_Agents_Large_Language_Models_Collaborating_on_Long_Context_Tasks/2024-06-04-Chain_of_Agents_Large_Language_Models_Collaborating_on_Long_Context_Tasks.html#appendix",
    "href": "posts/Chain_of_Agents_Large_Language_Models_Collaborating_on_Long_Context_Tasks/2024-06-04-Chain_of_Agents_Large_Language_Models_Collaborating_on_Long_Context_Tasks.html#appendix",
    "title": "Chain of Agents: Large Language Models Collaborating on Long-Context Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02818v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02818v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6877"
  },
  {
    "objectID": "posts/Long_Input_Benchmark_for_Russian_Analysis/2024-08-05-Long_Input_Benchmark_for_Russian_Analysis.html#appendix",
    "href": "posts/Long_Input_Benchmark_for_Russian_Analysis/2024-08-05-Long_Input_Benchmark_for_Russian_Analysis.html#appendix",
    "title": "Long Input Benchmark for Russian Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02439v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02439v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8590"
  },
  {
    "objectID": "posts/MPCODER_Multi_user_Personalized_Code_Generator_with_Explicit_and_Implicit_Style_Representation_Learning/2024-06-25-MPCODER_Multi_user_Personalized_Code_Generator_with_Explicit_and_Implicit_Style_Representation_Learning.html#appendix",
    "href": "posts/MPCODER_Multi_user_Personalized_Code_Generator_with_Explicit_and_Implicit_Style_Representation_Learning/2024-06-25-MPCODER_Multi_user_Personalized_Code_Generator_with_Explicit_and_Implicit_Style_Representation_Learning.html#appendix",
    "title": "MPCODER: Multi-user Personalized Code Generator with Explicit and Implicit Style Representation Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17255v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17255v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8886"
  },
  {
    "objectID": "posts/FVEL_Interactive_Formal_Verification_Environment_with_Large_Language_Models_via_Theorem_Proving/2024-06-20-FVEL_Interactive_Formal_Verification_Environment_with_Large_Language_Models_via_Theorem_Proving.html#appendix",
    "href": "posts/FVEL_Interactive_Formal_Verification_Environment_with_Large_Language_Models_via_Theorem_Proving/2024-06-20-FVEL_Interactive_Formal_Verification_Environment_with_Large_Language_Models_via_Theorem_Proving.html#appendix",
    "title": "FVEL: Interactive Formal Verification Environment with Large Language Models via Theorem Proving",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14408v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14408v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11049"
  },
  {
    "objectID": "posts/Finding_Safety_Neurons_in_Large_Language_Models/2024-06-20-Finding_Safety_Neurons_in_Large_Language_Models.html#appendix",
    "href": "posts/Finding_Safety_Neurons_in_Large_Language_Models/2024-06-20-Finding_Safety_Neurons_in_Large_Language_Models.html#appendix",
    "title": "Finding Safety Neurons in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14144v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14144v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10356"
  },
  {
    "objectID": "posts/HalluDial_A_Large_Scale_Benchmark_for_Automatic_Dialogue_Level_Hallucination_Evaluation/2024-06-11-HalluDial_A_Large_Scale_Benchmark_for_Automatic_Dialogue_Level_Hallucination_Evaluation.html#appendix",
    "href": "posts/HalluDial_A_Large_Scale_Benchmark_for_Automatic_Dialogue_Level_Hallucination_Evaluation/2024-06-11-HalluDial_A_Large_Scale_Benchmark_for_Automatic_Dialogue_Level_Hallucination_Evaluation.html#appendix",
    "title": "HalluDial: A Large-Scale Benchmark for Automatic Dialogue-Level Hallucination Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07070v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07070v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10462"
  },
  {
    "objectID": "posts/BeHonest_Benchmarking_Honesty_of_Large_Language_Models/2024-06-19-BeHonest_Benchmarking_Honesty_of_Large_Language_Models.html#appendix",
    "href": "posts/BeHonest_Benchmarking_Honesty_of_Large_Language_Models/2024-06-19-BeHonest_Benchmarking_Honesty_of_Large_Language_Models.html#appendix",
    "title": "BeHonest: Benchmarking Honesty of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13261v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13261v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9544"
  },
  {
    "objectID": "posts/RAGLAB_A_Modular_and_Research_Oriented_Unified_Framework_for_Retrieval_Augmented_Generation/2024-08-21-RAGLAB_A_Modular_and_Research_Oriented_Unified_Framework_for_Retrieval_Augmented_Generation.html#appendix",
    "href": "posts/RAGLAB_A_Modular_and_Research_Oriented_Unified_Framework_for_Retrieval_Augmented_Generation/2024-08-21-RAGLAB_A_Modular_and_Research_Oriented_Unified_Framework_for_Retrieval_Augmented_Generation.html#appendix",
    "title": "RAGLAB: A Modular and Research-Oriented Unified Framework for Retrieval-Augmented Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11381v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11381v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4416"
  },
  {
    "objectID": "posts/GermanPartiesQA_Benchmarking_Commercial_Large_Language_Models_for_Political_Bias_and_Sycophancy/2024-07-25-GermanPartiesQA_Benchmarking_Commercial_Large_Language_Models_for_Political_Bias_and_Sycophancy.html#appendix",
    "href": "posts/GermanPartiesQA_Benchmarking_Commercial_Large_Language_Models_for_Political_Bias_and_Sycophancy/2024-07-25-GermanPartiesQA_Benchmarking_Commercial_Large_Language_Models_for_Political_Bias_and_Sycophancy.html#appendix",
    "title": "GermanPartiesQA: Benchmarking Commercial Large Language Models for Political Bias and Sycophancy",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.18008v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.18008v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6995"
  },
  {
    "objectID": "posts/Personality_Alignment_of_Large_Language_Models/2024-08-21-Personality_Alignment_of_Large_Language_Models.html#appendix",
    "href": "posts/Personality_Alignment_of_Large_Language_Models/2024-08-21-Personality_Alignment_of_Large_Language_Models.html#appendix",
    "title": "Personality Alignment of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11779v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11779v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15266"
  },
  {
    "objectID": "posts/Text2BIM_Generating_Building_Models_Using_a_Large_Language_Model_based_Multi_Agent_Framework/2024-08-15-Text2BIM_Generating_Building_Models_Using_a_Large_Language_Model_based_Multi_Agent_Framework.html#appendix",
    "href": "posts/Text2BIM_Generating_Building_Models_Using_a_Large_Language_Model_based_Multi_Agent_Framework/2024-08-15-Text2BIM_Generating_Building_Models_Using_a_Large_Language_Model_based_Multi_Agent_Framework.html#appendix",
    "title": "Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.08054v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.08054v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11513"
  },
  {
    "objectID": "posts/LLMs_instead_of_Human_Judges_A_Large_Scale_Empirical_Study_across_20_NLP_Evaluation_Tasks/2024-06-26-LLMs_instead_of_Human_Judges_A_Large_Scale_Empirical_Study_across_20_NLP_Evaluation_Tasks.html#appendix",
    "href": "posts/LLMs_instead_of_Human_Judges_A_Large_Scale_Empirical_Study_across_20_NLP_Evaluation_Tasks/2024-06-26-LLMs_instead_of_Human_Judges_A_Large_Scale_Empirical_Study_across_20_NLP_Evaluation_Tasks.html#appendix",
    "title": "LLMs instead of Human Judges? A Large Scale Empirical Study across 20 NLP Evaluation Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18403v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18403v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5321"
  },
  {
    "objectID": "posts/Progressive_Query_Expansion_for_Retrieval_Over_Cost_constrained_Data_Sources/2024-06-11-Progressive_Query_Expansion_for_Retrieval_Over_Cost_constrained_Data_Sources.html#appendix",
    "href": "posts/Progressive_Query_Expansion_for_Retrieval_Over_Cost_constrained_Data_Sources/2024-06-11-Progressive_Query_Expansion_for_Retrieval_Over_Cost_constrained_Data_Sources.html#appendix",
    "title": "Progressive Query Expansion for Retrieval Over Cost-constrained Data Sources",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07136v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07136v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4716"
  },
  {
    "objectID": "posts/CoT_Rerailer_Enhancing_the_Reliability_of_Large_Language_Models_in_Complex_Reasoning_Tasks_through_Error_Detection_and_Correction/2024-08-25-CoT_Rerailer_Enhancing_the_Reliability_of_Large_Language_Models_in_Complex_Reasoning_Tasks_through_Error_Detection_and_Correction.html#appendix",
    "href": "posts/CoT_Rerailer_Enhancing_the_Reliability_of_Large_Language_Models_in_Complex_Reasoning_Tasks_through_Error_Detection_and_Correction/2024-08-25-CoT_Rerailer_Enhancing_the_Reliability_of_Large_Language_Models_in_Complex_Reasoning_Tasks_through_Error_Detection_and_Correction.html#appendix",
    "title": "CoT Rerailer: Enhancing the Reliability of Large Language Models in Complex Reasoning Tasks through Error Detection and Correction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.13940v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.13940v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10488"
  },
  {
    "objectID": "posts/MDD_5k_A_New_Diagnostic_Conversation_Dataset_for_Mental_Disorders_Synthesized_via_Neuro_Symbolic_LLM_Agents/2024-08-22-MDD_5k_A_New_Diagnostic_Conversation_Dataset_for_Mental_Disorders_Synthesized_via_Neuro_Symbolic_LLM_Agents.html#appendix",
    "href": "posts/MDD_5k_A_New_Diagnostic_Conversation_Dataset_for_Mental_Disorders_Synthesized_via_Neuro_Symbolic_LLM_Agents/2024-08-22-MDD_5k_A_New_Diagnostic_Conversation_Dataset_for_Mental_Disorders_Synthesized_via_Neuro_Symbolic_LLM_Agents.html#appendix",
    "title": "MDD-5k: A New Diagnostic Conversation Dataset for Mental Disorders Synthesized via Neuro-Symbolic LLM Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12142v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12142v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7792"
  },
  {
    "objectID": "posts/Improving_and_Assessing_the_Fidelity_of_Large_Language_Models_Alignment_to_Online_Communities/2024-08-18-Improving_and_Assessing_the_Fidelity_of_Large_Language_Models_Alignment_to_Online_Communities.html#appendix",
    "href": "posts/Improving_and_Assessing_the_Fidelity_of_Large_Language_Models_Alignment_to_Online_Communities/2024-08-18-Improving_and_Assessing_the_Fidelity_of_Large_Language_Models_Alignment_to_Online_Communities.html#appendix",
    "title": "Improving and Assessing the Fidelity of Large Language Models Alignment to Online Communities",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09366v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09366v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10011"
  },
  {
    "objectID": "posts/Can_LLMs_be_Fooled_Investigating_Vulnerabilities_in_LLMs/2024-07-30-Can_LLMs_be_Fooled_Investigating_Vulnerabilities_in_LLMs.html#major-findings",
    "href": "posts/Can_LLMs_be_Fooled_Investigating_Vulnerabilities_in_LLMs/2024-07-30-Can_LLMs_be_Fooled_Investigating_Vulnerabilities_in_LLMs.html#major-findings",
    "title": "Can LLMs be Fooled? Investigating Vulnerabilities in LLMs",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nModel-based Vulnerabilities: These vulnerabilities arise from the inherent design and structure of LLMs. Prominent examples include model extraction, model leeching, and model imitation attacks. Mitigation strategies include Malicious Sample Detection, Model Watermarking, and Membership Classification.\nTraining-time Vulnerabilities: These vulnerabilities occur during the training phase of LLMs. Key issues include data poisoning and backdoor attacks. Mitigation strategies involve data augmentation, validation, and sanitizing of training data, and differential privacy techniques.\nInference-time Vulnerabilities: These vulnerabilities manifest during the model’s interaction with end-users or systems. They encompass a range of attacks, including jailbreaking, paraphrasing, spoofing, and prompt injection. Mitigation strategies include applying a paraphraser or retokenization on the input, using perplexity-based strategies, and token-level detection."
  },
  {
    "objectID": "posts/Can_LLMs_be_Fooled_Investigating_Vulnerabilities_in_LLMs/2024-07-30-Can_LLMs_be_Fooled_Investigating_Vulnerabilities_in_LLMs.html#analysis-and-critique",
    "href": "posts/Can_LLMs_be_Fooled_Investigating_Vulnerabilities_in_LLMs/2024-07-30-Can_LLMs_be_Fooled_Investigating_Vulnerabilities_in_LLMs.html#analysis-and-critique",
    "title": "Can LLMs be Fooled? Investigating Vulnerabilities in LLMs",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper provides a comprehensive overview of LLM vulnerabilities and proposes mitigation strategies. However, it is important to note that the field of LLM security is rapidly evolving, and new vulnerabilities and attack methods may emerge. The proposed mitigation strategies may not be effective against all types of attacks, and continuous research and development are needed to stay ahead of potential threats.\nMoreover, the paper does not provide a detailed analysis of the effectiveness of the proposed mitigation strategies. It would be beneficial to conduct empirical studies to evaluate the performance of these strategies against different types of attacks.\nFinally, the paper does not discuss the potential ethical implications of LLM vulnerabilities. As LLMs become more integrated into our daily lives, it is crucial to consider the potential impact of these vulnerabilities on individuals and society as a whole.\nIn conclusion, while the paper provides a valuable contribution to the field of LLM security, further research is needed to fully understand"
  },
  {
    "objectID": "posts/Can_LLMs_be_Fooled_Investigating_Vulnerabilities_in_LLMs/2024-07-30-Can_LLMs_be_Fooled_Investigating_Vulnerabilities_in_LLMs.html#appendix",
    "href": "posts/Can_LLMs_be_Fooled_Investigating_Vulnerabilities_in_LLMs/2024-07-30-Can_LLMs_be_Fooled_Investigating_Vulnerabilities_in_LLMs.html#appendix",
    "title": "Can LLMs be Fooled? Investigating Vulnerabilities in LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20529v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20529v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8142"
  },
  {
    "objectID": "posts/How_Does_Quantization_Affect_Multilingual_LLMs/2024-07-03-How_Does_Quantization_Affect_Multilingual_LLMs.html#appendix",
    "href": "posts/How_Does_Quantization_Affect_Multilingual_LLMs/2024-07-03-How_Does_Quantization_Affect_Multilingual_LLMs.html#appendix",
    "title": "How Does Quantization Affect Multilingual LLMs?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03211v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03211v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6954"
  },
  {
    "objectID": "posts/DR_RAG_Applying_Dynamic_Document_Relevance_to_Retrieval_Augmented_Generation_for_Question_Answering/2024-06-11-DR_RAG_Applying_Dynamic_Document_Relevance_to_Retrieval_Augmented_Generation_for_Question_Answering.html#appendix",
    "href": "posts/DR_RAG_Applying_Dynamic_Document_Relevance_to_Retrieval_Augmented_Generation_for_Question_Answering/2024-06-11-DR_RAG_Applying_Dynamic_Document_Relevance_to_Retrieval_Augmented_Generation_for_Question_Answering.html#appendix",
    "title": "DR-RAG: Applying Dynamic Document Relevance to Retrieval-Augmented Generation for Question-Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07348v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07348v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6121"
  },
  {
    "objectID": "posts/Preliminary_WMT24_Ranking_of_General_MT_Systems_and_LLMs/2024-07-29-Preliminary_WMT24_Ranking_of_General_MT_Systems_and_LLMs.html#appendix",
    "href": "posts/Preliminary_WMT24_Ranking_of_General_MT_Systems_and_LLMs/2024-07-29-Preliminary_WMT24_Ranking_of_General_MT_Systems_and_LLMs.html#appendix",
    "title": "Preliminary WMT24 Ranking of General MT Systems and LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19884v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19884v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1564"
  },
  {
    "objectID": "posts/On_AI_Inspired_UI_Design/2024-06-19-On_AI_Inspired_UI_Design.html#appendix",
    "href": "posts/On_AI_Inspired_UI_Design/2024-06-19-On_AI_Inspired_UI_Design.html#appendix",
    "title": "On AI-Inspired UI-Design",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13631v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13631v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1712"
  },
  {
    "objectID": "posts/ConvKGYarn_Spinning_Configurable_and_Scalable_Conversational_Knowledge_Graph_QA_datasets_with_Large_Language_Models/2024-08-12-ConvKGYarn_Spinning_Configurable_and_Scalable_Conversational_Knowledge_Graph_QA_datasets_with_Large_Language_Models.html#appendix",
    "href": "posts/ConvKGYarn_Spinning_Configurable_and_Scalable_Conversational_Knowledge_Graph_QA_datasets_with_Large_Language_Models/2024-08-12-ConvKGYarn_Spinning_Configurable_and_Scalable_Conversational_Knowledge_Graph_QA_datasets_with_Large_Language_Models.html#appendix",
    "title": "ConvKGYarn: Spinning Configurable and Scalable Conversational Knowledge Graph QA datasets with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.05948v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.05948v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10786"
  },
  {
    "objectID": "posts/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions/2024-07-07-Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions.html#summary-1",
    "href": "posts/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions/2024-07-07-Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions.html#summary-1",
    "title": "Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions",
    "section": "Summary:",
    "text": "Summary:\nThe study examines the performance of autoregressive LLMs and fine-tuned foundation language models in predicting gender categories (i.e., female, male, and neutral) given first names. It also investigates the impact of adding birth year on gender prediction accuracy. The research focuses on the limitations and biases of LLMs in predicting gender-neutral names and names with evolving gender associations over time."
  },
  {
    "objectID": "posts/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions/2024-07-07-Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions.html#major-findings",
    "href": "posts/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions/2024-07-07-Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions.html#major-findings",
    "title": "Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nFine-tuned foundational language models predicted gender-neutral first names more accurately than LLMs under 0-shot prompting across all three datasets. BERT results in the highest average accuracy for the US and Canada dataset, while RoBERTa outperformed BERT on the France dataset.\nMost LLMs showed higher accuracy in gender prediction when provided with 5 labeled name-gender pairs through in-context learning compared to the 0-shot setting across all datasets.\nIncorporating birth years as an additional input feature improved the prediction accuracy of foundational language models compared to the first-name-only setting. However, most LLMs showed a decline in accuracy when birth years were added, particularly in predicting gender-neutral names.\nThe accuracy of gender prediction using the US SSA dynamic gender label dataset has increased in recent years for most LLMs, including Llama3, Mixtral-8x7B, Claude 3 Haiku, and GPT-3.5.\nLLMs have worst performance on gender-neutral names, and the accuracy of gender prediction is higher for English-based first names in the US and Canada SSA datasets than in the France SSA."
  },
  {
    "objectID": "posts/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions/2024-07-07-Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions.html#analysis-and-critique",
    "href": "posts/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions/2024-07-07-Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions.html#analysis-and-critique",
    "title": "Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe study highlights the limitations and biases of LLMs in predicting gender-neutral names and names with evolving gender associations over time. The research underscores the need for more inclusive gender categories and the importance of considering temporal information in gender prediction tasks. However, the study is limited to specific countries, and the dataset preparation involved a subjective threshold to determine gender-neutral names. The prompt templates employed for interacting with LLMs were not optimized, which may lead to variations in results with different prompt formulations. The study also does not consider a broad spectrum of countries and cultures"
  },
  {
    "objectID": "posts/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions/2024-07-07-Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions.html#appendix",
    "href": "posts/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions/2024-07-07-Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions.html#appendix",
    "title": "Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05271v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05271v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6704"
  },
  {
    "objectID": "posts/Cause_Aware_Empathetic_Response_Generation_via_Chain_of_Thought_Fine_Tuning/2024-08-21-Cause_Aware_Empathetic_Response_Generation_via_Chain_of_Thought_Fine_Tuning.html#appendix",
    "href": "posts/Cause_Aware_Empathetic_Response_Generation_via_Chain_of_Thought_Fine_Tuning/2024-08-21-Cause_Aware_Empathetic_Response_Generation_via_Chain_of_Thought_Fine_Tuning.html#appendix",
    "title": "Cause-Aware Empathetic Response Generation via Chain-of-Thought Fine-Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11599v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11599v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5993"
  },
  {
    "objectID": "posts/Financial_Statement_Analysis_with_Large_Language_Models/2024-07-25-Financial_Statement_Analysis_with_Large_Language_Models.html",
    "href": "posts/Financial_Statement_Analysis_with_Large_Language_Models/2024-07-25-Financial_Statement_Analysis_with_Large_Language_Models.html",
    "title": "Financial Statement Analysis with Large Language Models",
    "section": "",
    "text": "Summary:\nThis paper investigates the ability of a large language model (LLM), specifically GPT4, to perform financial statement analysis and predict the direction of future earnings. The study compares the performance of GPT4 to that of financial analysts and other benchmarks, such as logistic regression and a state-of-the-art machine learning model. The results show that GPT4 outperforms financial analysts and achieves performance on par with the state-of-the-art machine learning model. The study also finds that GPT4’s performance is not due to its memory, but rather its ability to generate useful narrative insights about a company’s future performance. Additionally, trading strategies based on GPT’s predictions yield higher Sharpe ratios and alphas than strategies based on other models.\nMajor Findings:\nAnalysis and Critique:\nThe study provides a comprehensive analysis of the ability of LLMs to perform financial statement analysis and predict the direction of future earnings. The results are promising, showing that GPT4 can outperform financial analysts and achieve performance on par with state-of-the-art machine learning models. However, the study does not address the potential limitations of LLMs, such as their inability to understand complex financial concepts or their reliance on large amounts of data. Additionally, the study does not address the potential biases or errors that may be introduced by the use of LLMs in financial analysis. Further research is needed to address these limitations and to fully understand the potential of LLMs in financial analysis."
  },
  {
    "objectID": "posts/Financial_Statement_Analysis_with_Large_Language_Models/2024-07-25-Financial_Statement_Analysis_with_Large_Language_Models.html#appendix",
    "href": "posts/Financial_Statement_Analysis_with_Large_Language_Models/2024-07-25-Financial_Statement_Analysis_with_Large_Language_Models.html#appendix",
    "title": "Financial Statement Analysis with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17866v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17866v1\n\n\nTruncated\nFalse\n\n\nWord Count\n19560"
  },
  {
    "objectID": "posts/Evaluating_the_Translation_Performance_of_Large_Language_Models_Based_on_Euas_20/2024-08-06-Evaluating_the_Translation_Performance_of_Large_Language_Models_Based_on_Euas_20.html#appendix",
    "href": "posts/Evaluating_the_Translation_Performance_of_Large_Language_Models_Based_on_Euas_20/2024-08-06-Evaluating_the_Translation_Performance_of_Large_Language_Models_Based_on_Euas_20.html#appendix",
    "title": "Evaluating the Translation Performance of Large Language Models Based on Euas-20",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03119v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03119v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5165"
  },
  {
    "objectID": "posts/Refactoring_to_Pythonic_Idioms_A_Hybrid_Knowledge_Driven_Approach_Leveraging_Large_Language_Models/2024-06-06-Refactoring_to_Pythonic_Idioms_A_Hybrid_Knowledge_Driven_Approach_Leveraging_Large_Language_Models.html#appendix",
    "href": "posts/Refactoring_to_Pythonic_Idioms_A_Hybrid_Knowledge_Driven_Approach_Leveraging_Large_Language_Models/2024-06-06-Refactoring_to_Pythonic_Idioms_A_Hybrid_Knowledge_Driven_Approach_Leveraging_Large_Language_Models.html#appendix",
    "title": "Refactoring to Pythonic Idioms: A Hybrid Knowledge-Driven Approach Leveraging Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03660v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03660v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14284"
  },
  {
    "objectID": "posts/ReplanVLM_Replanning_Robotic_Tasks_with_Visual_Language_Models/2024-07-31-ReplanVLM_Replanning_Robotic_Tasks_with_Visual_Language_Models.html#appendix",
    "href": "posts/ReplanVLM_Replanning_Robotic_Tasks_with_Visual_Language_Models/2024-07-31-ReplanVLM_Replanning_Robotic_Tasks_with_Visual_Language_Models.html#appendix",
    "title": "ReplanVLM: Replanning Robotic Tasks with Visual Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21762v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21762v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6110"
  },
  {
    "objectID": "posts/Reconciling_Methodological_Paradigms_Employing_Large_Language_Models_as_Novice_Qualitative_Research_Assistants_in_Talent_Management_Research/2024-08-20-Reconciling_Methodological_Paradigms_Employing_Large_Language_Models_as_Novice_Qualitative_Research_Assistants_in_Talent_Management_Research.html#major-findings",
    "href": "posts/Reconciling_Methodological_Paradigms_Employing_Large_Language_Models_as_Novice_Qualitative_Research_Assistants_in_Talent_Management_Research/2024-08-20-Reconciling_Methodological_Paradigms_Employing_Large_Language_Models_as_Novice_Qualitative_Research_Assistants_in_Talent_Management_Research.html#major-findings",
    "title": "Reconciling Methodological Paradigms: Employing Large Language Models as Novice Qualitative Research Assistants in Talent Management Research",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nLLMs can be employed as novice qualitative research assistants for researchers in the talent management space, enabling topic modeling of semi-structured interview data.\nThe LLM-augmented RAG approach can successfully extract topics of interest, with significant coverage compared to manually generated topics from the same dataset.\nResearchers leveraging LLMs should lean heavily on quality criteria used in traditional qualitative research to ensure rigor and trustworthiness of their approach."
  },
  {
    "objectID": "posts/Reconciling_Methodological_Paradigms_Employing_Large_Language_Models_as_Novice_Qualitative_Research_Assistants_in_Talent_Management_Research/2024-08-20-Reconciling_Methodological_Paradigms_Employing_Large_Language_Models_as_Novice_Qualitative_Research_Assistants_in_Talent_Management_Research.html#analysis-and-critique",
    "href": "posts/Reconciling_Methodological_Paradigms_Employing_Large_Language_Models_as_Novice_Qualitative_Research_Assistants_in_Talent_Management_Research/2024-08-20-Reconciling_Methodological_Paradigms_Employing_Large_Language_Models_as_Novice_Qualitative_Research_Assistants_in_Talent_Management_Research.html#analysis-and-critique",
    "title": "Reconciling Methodological Paradigms: Employing Large Language Models as Novice Qualitative Research Assistants in Talent Management Research",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe study presents a promising approach to address the challenge of manually analyzing qualitative data, but it does not discuss the potential limitations or biases that may arise from using LLMs as novice qualitative research assistants.\nThe authors recommend that researchers using LLMs should lean heavily on quality criteria used in traditional qualitative research, but they do not provide specific guidelines or best practices for integrating LLMs into qualitative workflows.\nThe study does not address the ethical considerations and potential risks associated with using AI assistants in sensitive domains like talent management, such as data privacy, algorithmic bias, and model transparency.\nFuture research should seek to establish guidelines and best practices for LLM-augmented qualitative analysis that uphold the rigor and trustworthiness expected within the qualitative research community."
  },
  {
    "objectID": "posts/Reconciling_Methodological_Paradigms_Employing_Large_Language_Models_as_Novice_Qualitative_Research_Assistants_in_Talent_Management_Research/2024-08-20-Reconciling_Methodological_Paradigms_Employing_Large_Language_Models_as_Novice_Qualitative_Research_Assistants_in_Talent_Management_Research.html#appendix",
    "href": "posts/Reconciling_Methodological_Paradigms_Employing_Large_Language_Models_as_Novice_Qualitative_Research_Assistants_in_Talent_Management_Research/2024-08-20-Reconciling_Methodological_Paradigms_Employing_Large_Language_Models_as_Novice_Qualitative_Research_Assistants_in_Talent_Management_Research.html#appendix",
    "title": "Reconciling Methodological Paradigms: Employing Large Language Models as Novice Qualitative Research Assistants in Talent Management Research",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11043v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11043v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5700"
  },
  {
    "objectID": "posts/What_Makes_and_Breaks_Safety_Fine_tuning_Mechanistic_Study/2024-07-14-What_Makes_and_Breaks_Safety_Fine_tuning_Mechanistic_Study.html",
    "href": "posts/What_Makes_and_Breaks_Safety_Fine_tuning_Mechanistic_Study/2024-07-14-What_Makes_and_Breaks_Safety_Fine_tuning_Mechanistic_Study.html",
    "title": "What Makes and Breaks Safety Fine-tuning? Mechanistic Study",
    "section": "",
    "text": "Summary:\nThe paper “What Makes and Breaks Safety Fine-tuning? A Mechanistic Study” investigates the factors contributing to the safety of large language models (LLMs) through safety fine-tuning. The authors design a synthetic data generation framework to capture the interaction between the task and specific concepts. They examine three safety fine-tuning methods: supervised safety fine-tuning, direct preference optimization, and unlearning. The study reveals that these methods minimally transform MLP weights to align unsafe inputs into the null space of the weights, resulting in a clustering of inputs based on their safety. However, when an adversarial input is provided, its activations are closer to safer samples, causing the model to process it as if it were safe.\nMajor Findings:"
  },
  {
    "objectID": "posts/What_Makes_and_Breaks_Safety_Fine_tuning_Mechanistic_Study/2024-07-14-What_Makes_and_Breaks_Safety_Fine_tuning_Mechanistic_Study.html#appendix",
    "href": "posts/What_Makes_and_Breaks_Safety_Fine_tuning_Mechanistic_Study/2024-07-14-What_Makes_and_Breaks_Safety_Fine_tuning_Mechanistic_Study.html#appendix",
    "title": "What Makes and Breaks Safety Fine-tuning? Mechanistic Study",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10264v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10264v1\n\n\nTruncated\nTrue\n\n\nWord Count\n62036"
  },
  {
    "objectID": "posts/InverseCoder_Unleashing_the_Power_of_Instruction_Tuned_Code_LLMs_with_Inverse_Instruct/2024-07-08-InverseCoder_Unleashing_the_Power_of_Instruction_Tuned_Code_LLMs_with_Inverse_Instruct.html#appendix",
    "href": "posts/InverseCoder_Unleashing_the_Power_of_Instruction_Tuned_Code_LLMs_with_Inverse_Instruct/2024-07-08-InverseCoder_Unleashing_the_Power_of_Instruction_Tuned_Code_LLMs_with_Inverse_Instruct.html#appendix",
    "title": "InverseCoder: Unleashing the Power of Instruction-Tuned Code LLMs with Inverse-Instruct",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05700v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05700v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6732"
  },
  {
    "objectID": "posts/Exploring_the_Potential_of_Large_Language_Models_for_Heterophilic_Graphs/2024-08-26-Exploring_the_Potential_of_Large_Language_Models_for_Heterophilic_Graphs.html#appendix",
    "href": "posts/Exploring_the_Potential_of_Large_Language_Models_for_Heterophilic_Graphs/2024-08-26-Exploring_the_Potential_of_Large_Language_Models_for_Heterophilic_Graphs.html#appendix",
    "title": "Exploring the Potential of Large Language Models for Heterophilic Graphs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.14134v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.14134v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8228"
  },
  {
    "objectID": "posts/Hierarchical_Micro_Segmentations_for_Zero_Trust_Services_via_Large_Language_Model_(LLM)_enhanced_Graph_Diffusion/2024-06-20-Hierarchical_Micro_Segmentations_for_Zero_Trust_Services_via_Large_Language_Model_(LLM)_enhanced_Graph_Diffusion.html#appendix",
    "href": "posts/Hierarchical_Micro_Segmentations_for_Zero_Trust_Services_via_Large_Language_Model_(LLM)_enhanced_Graph_Diffusion/2024-06-20-Hierarchical_Micro_Segmentations_for_Zero_Trust_Services_via_Large_Language_Model_(LLM)_enhanced_Graph_Diffusion.html#appendix",
    "title": "Hierarchical Micro-Segmentations for Zero-Trust Services via Large Language Model (LLM)-enhanced Graph Diffusion",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13964v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13964v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11153"
  },
  {
    "objectID": "posts/Sentiment_Analysis_of_Lithuanian_Online_Reviews_Using_Large_Language_Models/2024-07-29-Sentiment_Analysis_of_Lithuanian_Online_Reviews_Using_Large_Language_Models.html#appendix",
    "href": "posts/Sentiment_Analysis_of_Lithuanian_Online_Reviews_Using_Large_Language_Models/2024-07-29-Sentiment_Analysis_of_Lithuanian_Online_Reviews_Using_Large_Language_Models.html#appendix",
    "title": "Sentiment Analysis of Lithuanian Online Reviews Using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19914v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19914v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8863"
  },
  {
    "objectID": "posts/JailbreakHunter_A_Visual_Analytics_Approach_for_Jailbreak_Prompts_Discovery_from_Large_Scale_Human_LLM_Conversational_Datasets/2024-07-03-JailbreakHunter_A_Visual_Analytics_Approach_for_Jailbreak_Prompts_Discovery_from_Large_Scale_Human_LLM_Conversational_Datasets.html#appendix",
    "href": "posts/JailbreakHunter_A_Visual_Analytics_Approach_for_Jailbreak_Prompts_Discovery_from_Large_Scale_Human_LLM_Conversational_Datasets/2024-07-03-JailbreakHunter_A_Visual_Analytics_Approach_for_Jailbreak_Prompts_Discovery_from_Large_Scale_Human_LLM_Conversational_Datasets.html#appendix",
    "title": "JailbreakHunter: A Visual Analytics Approach for Jailbreak Prompts Discovery from Large-Scale Human-LLM Conversational Datasets",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03045v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03045v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13931"
  },
  {
    "objectID": "posts/Can_Language_Models_Serve_as_Text_Based_World_Simulators/2024-06-10-Can_Language_Models_Serve_as_Text_Based_World_Simulators.html#appendix",
    "href": "posts/Can_Language_Models_Serve_as_Text_Based_World_Simulators/2024-06-10-Can_Language_Models_Serve_as_Text_Based_World_Simulators.html#appendix",
    "title": "Can Language Models Serve as Text-Based World Simulators?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06485v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06485v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6025"
  },
  {
    "objectID": "posts/Prompting_Encoder_Models_for_Zero_Shot_Classification_A_Cross_Domain_Study_in_Italian/2024-07-30-Prompting_Encoder_Models_for_Zero_Shot_Classification_A_Cross_Domain_Study_in_Italian.html",
    "href": "posts/Prompting_Encoder_Models_for_Zero_Shot_Classification_A_Cross_Domain_Study_in_Italian/2024-07-30-Prompting_Encoder_Models_for_Zero_Shot_Classification_A_Cross_Domain_Study_in_Italian.html",
    "title": "Prompting Encoder Models for Zero-Shot Classification: A Cross-Domain Study in Italian",
    "section": "",
    "text": "Summary:\nThis paper explores the feasibility of employing smaller, domain-specific encoder Language Models (LMs) alongside prompting techniques to enhance performance in specialized contexts, focusing on the Italian bureaucratic and legal language. The study evaluates two models, BureauBERTo and Ita-Legal-BERT, in zero-shot classification tasks using prompt-based techniques. The results indicate that further pre-trained models may show diminished robustness in general knowledge but exhibit superior adaptability for domain-specific tasks, even in a zero-shot setting. The application of calibration techniques and in-domain verbalizers significantly enhances the efficacy of encoder models.\nMajor Findings:\nAnalysis and Critique:\nWhile the study provides valuable insights into the use of Italian models in specialized contexts, there are some potential limitations and areas for further research. The study focuses on a specific language (Italian) and two domain-specific models, which may not generalize to other languages or models. Additionally, the evaluation of the models is limited to zero-shot classification tasks, and further research is needed to assess their performance in other NLP tasks. Lastly, the study does not address potential biases or ethical considerations in the use of these models."
  },
  {
    "objectID": "posts/Prompting_Encoder_Models_for_Zero_Shot_Classification_A_Cross_Domain_Study_in_Italian/2024-07-30-Prompting_Encoder_Models_for_Zero_Shot_Classification_A_Cross_Domain_Study_in_Italian.html#appendix",
    "href": "posts/Prompting_Encoder_Models_for_Zero_Shot_Classification_A_Cross_Domain_Study_in_Italian/2024-07-30-Prompting_Encoder_Models_for_Zero_Shot_Classification_A_Cross_Domain_Study_in_Italian.html#appendix",
    "title": "Prompting Encoder Models for Zero-Shot Classification: A Cross-Domain Study in Italian",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20654v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20654v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12221"
  },
  {
    "objectID": "posts/QuickLLaMA_Query_aware_Inference_Acceleration_for_Large_Language_Models/2024-06-11-QuickLLaMA_Query_aware_Inference_Acceleration_for_Large_Language_Models.html#appendix",
    "href": "posts/QuickLLaMA_Query_aware_Inference_Acceleration_for_Large_Language_Models/2024-06-11-QuickLLaMA_Query_aware_Inference_Acceleration_for_Large_Language_Models.html#appendix",
    "title": "QuickLLaMA: Query-aware Inference Acceleration for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07528v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07528v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7459"
  },
  {
    "objectID": "posts/Beyond_Silent_Letters_Amplifying_LLMs_in_Emotion_Recognition_with_Vocal_Nuances/2024-07-31-Beyond_Silent_Letters_Amplifying_LLMs_in_Emotion_Recognition_with_Vocal_Nuances.html#appendix",
    "href": "posts/Beyond_Silent_Letters_Amplifying_LLMs_in_Emotion_Recognition_with_Vocal_Nuances/2024-07-31-Beyond_Silent_Letters_Amplifying_LLMs_in_Emotion_Recognition_with_Vocal_Nuances.html#appendix",
    "title": "Beyond Silent Letters: Amplifying LLMs in Emotion Recognition with Vocal Nuances",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21315v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21315v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6396"
  },
  {
    "objectID": "posts/ScholarChemQA_Unveiling_the_Power_of_Language_Models_in_Chemical_Research_Question_Answering/2024-07-24-ScholarChemQA_Unveiling_the_Power_of_Language_Models_in_Chemical_Research_Question_Answering.html#appendix",
    "href": "posts/ScholarChemQA_Unveiling_the_Power_of_Language_Models_in_Chemical_Research_Question_Answering/2024-07-24-ScholarChemQA_Unveiling_the_Power_of_Language_Models_in_Chemical_Research_Question_Answering.html#appendix",
    "title": "ScholarChemQA: Unveiling the Power of Language Models in Chemical Research Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16931v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16931v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10882"
  },
  {
    "objectID": "posts/Exploring_RAG_based_Vulnerability_Augmentation_with_LLMs/2024-08-07-Exploring_RAG_based_Vulnerability_Augmentation_with_LLMs.html#appendix",
    "href": "posts/Exploring_RAG_based_Vulnerability_Augmentation_with_LLMs/2024-08-07-Exploring_RAG_based_Vulnerability_Augmentation_with_LLMs.html#appendix",
    "title": "Exploring RAG-based Vulnerability Augmentation with LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04125v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04125v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9712"
  },
  {
    "objectID": "posts/LLM4DSR_Leveraing_Large_Language_Model_for_Denoising_Sequential_Recommendation/2024-08-15-LLM4DSR_Leveraing_Large_Language_Model_for_Denoising_Sequential_Recommendation.html#appendix",
    "href": "posts/LLM4DSR_Leveraing_Large_Language_Model_for_Denoising_Sequential_Recommendation/2024-08-15-LLM4DSR_Leveraing_Large_Language_Model_for_Denoising_Sequential_Recommendation.html#appendix",
    "title": "LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.08208v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.08208v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7657"
  },
  {
    "objectID": "posts/Fundamental_Problems_With_Model_Editing_How_Should_Rational_Belief_Revision_Work_in_LLMs/2024-06-27-Fundamental_Problems_With_Model_Editing_How_Should_Rational_Belief_Revision_Work_in_LLMs.html",
    "href": "posts/Fundamental_Problems_With_Model_Editing_How_Should_Rational_Belief_Revision_Work_in_LLMs/2024-06-27-Fundamental_Problems_With_Model_Editing_How_Should_Rational_Belief_Revision_Work_in_LLMs.html",
    "title": "Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?",
    "section": "",
    "text": "Summary:\nThe paper critiques the predominant formulation of the model editing problem and proposes a semi-synthetic setting for evaluating model editing. The authors present 12 open challenges, summarized in three categories: (1) challenges with defining the model editing problem, (2) challenges with developing benchmarks, and (3) challenges with assuming LLMs have editable beliefs. The paper also introduces a semi-synthetic setting for evaluating model editing that precisely formalizes the problem, albeit with a simplified problem and models trained from scratch. The evaluation compares an LLM against a Bayesian model, reflecting that Bayesian epistemology is the gold standard in belief revision. The authors use facts from Wikidata to generate a corpus of noisy sentences, which they then train an autoregressive Transformer on. By fitting a Bayesian model to the same data, they obtain exact Bayesian posteriors that serve as the targets for evaluating language models. The experiments show that edits to language models generalize poorly with respect to other relevant beliefs, yielding inconsistent model beliefs.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive critique of the model editing problem and proposes a semi-synthetic setting for evaluating model editing. However, the proposed setting simplifies the problem and uses models trained from scratch, which may not fully capture the complexities of real-world LLMs. Additionally, the paper does not address potential solutions to the 12 open challenges it presents, leaving room for further research in this area. The experiments conducted in the paper"
  },
  {
    "objectID": "posts/Fundamental_Problems_With_Model_Editing_How_Should_Rational_Belief_Revision_Work_in_LLMs/2024-06-27-Fundamental_Problems_With_Model_Editing_How_Should_Rational_Belief_Revision_Work_in_LLMs.html#appendix",
    "href": "posts/Fundamental_Problems_With_Model_Editing_How_Should_Rational_Belief_Revision_Work_in_LLMs/2024-06-27-Fundamental_Problems_With_Model_Editing_How_Should_Rational_Belief_Revision_Work_in_LLMs.html#appendix",
    "title": "Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19354v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19354v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14906"
  },
  {
    "objectID": "posts/$β$_DPO_Direct_Preference_Optimization_with_Dynamic_$β$/2024-07-11-$β$_DPO_Direct_Preference_Optimization_with_Dynamic_$β$.html",
    "href": "posts/$β$_DPO_Direct_Preference_Optimization_with_Dynamic_$β$/2024-07-11-$β$_DPO_Direct_Preference_Optimization_with_Dynamic_$β$.html",
    "title": "\\(β\\)-DPO: Direct Preference Optimization with Dynamic \\(β\\)",
    "section": "",
    "text": "Summary:\nThe paper introduces a novel framework called β-DPO, which aims to optimize DPO by dynamically adjusting the β parameter in response to the variability in the informativeness of pairwise data. The proposed method incorporates β-guided data filtering and batch-level dynamic β calibration, demonstrating significant improvements in DPO’s performance across a range of models and datasets. The empirical evaluations indicate that β-DPO offers an adaptable training paradigm for LLMs with human feedback.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a promising framework for LLM optimization, albeit with room for advancement. Future endeavors should explore:"
  },
  {
    "objectID": "posts/$β$_DPO_Direct_Preference_Optimization_with_Dynamic_$β$/2024-07-11-$β$_DPO_Direct_Preference_Optimization_with_Dynamic_$β$.html#appendix",
    "href": "posts/$β$_DPO_Direct_Preference_Optimization_with_Dynamic_$β$/2024-07-11-$β$_DPO_Direct_Preference_Optimization_with_Dynamic_$β$.html#appendix",
    "title": "\\(β\\)-DPO: Direct Preference Optimization with Dynamic \\(β\\)",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08639v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08639v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13055"
  },
  {
    "objectID": "posts/Exploring_Spatial_Representations_in_the_Historical_Lake_District_Texts_with_LLM_based_Relation_Extraction/2024-06-20-Exploring_Spatial_Representations_in_the_Historical_Lake_District_Texts_with_LLM_based_Relation_Extraction.html#appendix",
    "href": "posts/Exploring_Spatial_Representations_in_the_Historical_Lake_District_Texts_with_LLM_based_Relation_Extraction/2024-06-20-Exploring_Spatial_Representations_in_the_Historical_Lake_District_Texts_with_LLM_based_Relation_Extraction.html#appendix",
    "title": "Exploring Spatial Representations in the Historical Lake District Texts with LLM-based Relation Extraction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14336v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14336v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4003"
  },
  {
    "objectID": "posts/DHP_Benchmark_Are_LLMs_Good_NLG_Evaluators/2024-08-25-DHP_Benchmark_Are_LLMs_Good_NLG_Evaluators.html#appendix",
    "href": "posts/DHP_Benchmark_Are_LLMs_Good_NLG_Evaluators/2024-08-25-DHP_Benchmark_Are_LLMs_Good_NLG_Evaluators.html#appendix",
    "title": "DHP Benchmark: Are LLMs Good NLG Evaluators?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.13704v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.13704v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7759"
  },
  {
    "objectID": "posts/Generating_Unseen_Code_Tests_In_Infinitum/2024-07-29-Generating_Unseen_Code_Tests_In_Infinitum.html#appendix",
    "href": "posts/Generating_Unseen_Code_Tests_In_Infinitum/2024-07-29-Generating_Unseen_Code_Tests_In_Infinitum.html#appendix",
    "title": "Generating Unseen Code Tests In Infinitum",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19772v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19772v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4413"
  },
  {
    "objectID": "posts/ConflictBank_A_Benchmark_for_Evaluating_the_Influence_of_Knowledge_Conflicts_in_LLM/2024-08-22-ConflictBank_A_Benchmark_for_Evaluating_the_Influence_of_Knowledge_Conflicts_in_LLM.html#appendix",
    "href": "posts/ConflictBank_A_Benchmark_for_Evaluating_the_Influence_of_Knowledge_Conflicts_in_LLM/2024-08-22-ConflictBank_A_Benchmark_for_Evaluating_the_Influence_of_Knowledge_Conflicts_in_LLM.html#appendix",
    "title": "ConflictBank: A Benchmark for Evaluating the Influence of Knowledge Conflicts in LLM",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12076v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12076v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6478"
  },
  {
    "objectID": "posts/SimsChat_A_Customisable_Persona_Driven_Role_Playing_Agent/2024-06-25-SimsChat_A_Customisable_Persona_Driven_Role_Playing_Agent.html#appendix",
    "href": "posts/SimsChat_A_Customisable_Persona_Driven_Role_Playing_Agent/2024-06-25-SimsChat_A_Customisable_Persona_Driven_Role_Playing_Agent.html#appendix",
    "title": "SimsChat: A Customisable Persona-Driven Role-Playing Agent",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17962v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17962v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6407"
  },
  {
    "objectID": "posts/VAIYAKARANA__A_Benchmark_for_Automatic_Grammar_Correction_in_Bangla/2024-06-20-VAIYAKARANA__A_Benchmark_for_Automatic_Grammar_Correction_in_Bangla.html",
    "href": "posts/VAIYAKARANA__A_Benchmark_for_Automatic_Grammar_Correction_in_Bangla/2024-06-20-VAIYAKARANA__A_Benchmark_for_Automatic_Grammar_Correction_in_Bangla.html",
    "title": "VAIYAKARANA : A Benchmark for Automatic Grammar Correction in Bangla",
    "section": "",
    "text": "Summary:\nThe paper titled “VAIYAKARANA: A Benchmark for Automatic Grammar Correction in Bangla” by Pramit Bhattacharyya and Arnab Bhattacharya proposes a pragmatic approach to generate grammatically incorrect sentences in Bangla. The authors categorize the different kinds of errors in Bangla into 5 broad classes and 12 finer classes. They then use these categories to generate erroneous sentences systematically from a correct sentence. This approach can generate a large number of wrong sentences, which can be used to train neural networks. The authors also provide a dataset, Vaiyākaraṇa, consisting of 92,830 grammatically incorrect sentences and 18,426 correct sentences. They also collected 619 human-generated sentences from essays written by Bangla native speakers. The authors evaluate their corpus against neural models and LLMs and benchmark it against human evaluators, who are native speakers of Bangla. The analysis shows that native speakers are far more accurate than state-of-the-art models to detect whether a sentence is grammatically correct. However, even native speakers find it difficult to categorize the type of error. This shows the efficacy of the Vaiyākaraṇa corpus. The methodology of generating erroneous sentences can be applied for most other Indian languages as well.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel approach to generate grammatically incorrect sentences in"
  },
  {
    "objectID": "posts/VAIYAKARANA__A_Benchmark_for_Automatic_Grammar_Correction_in_Bangla/2024-06-20-VAIYAKARANA__A_Benchmark_for_Automatic_Grammar_Correction_in_Bangla.html#appendix",
    "href": "posts/VAIYAKARANA__A_Benchmark_for_Automatic_Grammar_Correction_in_Bangla/2024-06-20-VAIYAKARANA__A_Benchmark_for_Automatic_Grammar_Correction_in_Bangla.html#appendix",
    "title": "VAIYAKARANA : A Benchmark for Automatic Grammar Correction in Bangla",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14284v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14284v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20042"
  },
  {
    "objectID": "posts/Generating_Query_Recommendations_via_LLMs/2024-05-30-Generating_Query_Recommendations_via_LLMs.html#appendix",
    "href": "posts/Generating_Query_Recommendations_via_LLMs/2024-05-30-Generating_Query_Recommendations_via_LLMs.html#appendix",
    "title": "Generating Query Recommendations via LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.19749v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.19749v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1852"
  },
  {
    "objectID": "posts/QAEA_DR_A_Unified_Text_Augmentation_Framework_for_Dense_Retrieval/2024-07-29-QAEA_DR_A_Unified_Text_Augmentation_Framework_for_Dense_Retrieval.html#appendix",
    "href": "posts/QAEA_DR_A_Unified_Text_Augmentation_Framework_for_Dense_Retrieval/2024-07-29-QAEA_DR_A_Unified_Text_Augmentation_Framework_for_Dense_Retrieval.html#appendix",
    "title": "QAEA-DR: A Unified Text Augmentation Framework for Dense Retrieval",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20207v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20207v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9720"
  },
  {
    "objectID": "posts/EEG_Defender_Defending_against_Jailbreak_through_Early_Exit_Generation_of_Large_Language_Models/2024-08-21-EEG_Defender_Defending_against_Jailbreak_through_Early_Exit_Generation_of_Large_Language_Models.html#appendix",
    "href": "posts/EEG_Defender_Defending_against_Jailbreak_through_Early_Exit_Generation_of_Large_Language_Models/2024-08-21-EEG_Defender_Defending_against_Jailbreak_through_Early_Exit_Generation_of_Large_Language_Models.html#appendix",
    "title": "EEG-Defender: Defending against Jailbreak through Early Exit Generation of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11308v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11308v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8701"
  },
  {
    "objectID": "posts/Machine_Translation_Hallucination_Detection_for_Low_and_High_Resource_Languages_using_Large_Language_Models/2024-07-23-Machine_Translation_Hallucination_Detection_for_Low_and_High_Resource_Languages_using_Large_Language_Models.html#appendix",
    "href": "posts/Machine_Translation_Hallucination_Detection_for_Low_and_High_Resource_Languages_using_Large_Language_Models/2024-07-23-Machine_Translation_Hallucination_Detection_for_Low_and_High_Resource_Languages_using_Large_Language_Models.html#appendix",
    "title": "Machine Translation Hallucination Detection for Low and High Resource Languages using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16470v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16470v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6122"
  },
  {
    "objectID": "posts/CoSafe_Evaluating_Large_Language_Model_Safety_in_Multi_Turn_Dialogue_Coreference/2024-06-25-CoSafe_Evaluating_Large_Language_Model_Safety_in_Multi_Turn_Dialogue_Coreference.html#appendix",
    "href": "posts/CoSafe_Evaluating_Large_Language_Model_Safety_in_Multi_Turn_Dialogue_Coreference/2024-06-25-CoSafe_Evaluating_Large_Language_Model_Safety_in_Multi_Turn_Dialogue_Coreference.html#appendix",
    "title": "CoSafe: Evaluating Large Language Model Safety in Multi-Turn Dialogue Coreference",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17626v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17626v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14149"
  },
  {
    "objectID": "posts/Disentangling_Knowledge_based_and_Visual_Reasoning_by_Question_Decomposition_in_KB_VQA/2024-06-27-Disentangling_Knowledge_based_and_Visual_Reasoning_by_Question_Decomposition_in_KB_VQA.html#appendix",
    "href": "posts/Disentangling_Knowledge_based_and_Visual_Reasoning_by_Question_Decomposition_in_KB_VQA/2024-06-27-Disentangling_Knowledge_based_and_Visual_Reasoning_by_Question_Decomposition_in_KB_VQA.html#appendix",
    "title": "Disentangling Knowledge-based and Visual Reasoning by Question Decomposition in KB-VQA",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18839v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18839v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4974"
  },
  {
    "objectID": "posts/Responsive_ML_inference_in_multi_tenanted_environments_using_AQUA/2024-08-01-Responsive_ML_inference_in_multi_tenanted_environments_using_AQUA.html#appendix",
    "href": "posts/Responsive_ML_inference_in_multi_tenanted_environments_using_AQUA/2024-08-01-Responsive_ML_inference_in_multi_tenanted_environments_using_AQUA.html#appendix",
    "title": "Responsive ML inference in multi-tenanted environments using AQUA",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21255v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21255v2\n\n\nTruncated\nFalse\n\n\nWord Count\n16848"
  },
  {
    "objectID": "posts/PaCE_Parsimonious_Concept_Engineering_for_Large_Language_Models/2024-06-06-PaCE_Parsimonious_Concept_Engineering_for_Large_Language_Models.html#appendix",
    "href": "posts/PaCE_Parsimonious_Concept_Engineering_for_Large_Language_Models/2024-06-06-PaCE_Parsimonious_Concept_Engineering_for_Large_Language_Models.html#appendix",
    "title": "PaCE: Parsimonious Concept Engineering for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04331v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04331v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9538"
  },
  {
    "objectID": "posts/Cactus_Towards_Psychological_Counseling_Conversations_using_Cognitive_Behavioral_Theory/2024-07-03-Cactus_Towards_Psychological_Counseling_Conversations_using_Cognitive_Behavioral_Theory.html#appendix",
    "href": "posts/Cactus_Towards_Psychological_Counseling_Conversations_using_Cognitive_Behavioral_Theory/2024-07-03-Cactus_Towards_Psychological_Counseling_Conversations_using_Cognitive_Behavioral_Theory.html#appendix",
    "title": "Cactus: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03103v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03103v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10331"
  },
  {
    "objectID": "posts/AgentDojo_A_Dynamic_Environment_to_Evaluate_Attacks_and_Defenses_for_LLM_Agents/2024-06-19-AgentDojo_A_Dynamic_Environment_to_Evaluate_Attacks_and_Defenses_for_LLM_Agents.html#appendix",
    "href": "posts/AgentDojo_A_Dynamic_Environment_to_Evaluate_Attacks_and_Defenses_for_LLM_Agents/2024-06-19-AgentDojo_A_Dynamic_Environment_to_Evaluate_Attacks_and_Defenses_for_LLM_Agents.html#appendix",
    "title": "AgentDojo: A Dynamic Environment to Evaluate Attacks and Defenses for LLM Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13352v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13352v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7934"
  },
  {
    "objectID": "posts/Revisiting_Whos_Harry_Potter_Towards_Targeted_Unlearning_from_a_Causal_Intervention_Perspective/2024-07-24-Revisiting_Whos_Harry_Potter_Towards_Targeted_Unlearning_from_a_Causal_Intervention_Perspective.html#appendix",
    "href": "posts/Revisiting_Whos_Harry_Potter_Towards_Targeted_Unlearning_from_a_Causal_Intervention_Perspective/2024-07-24-Revisiting_Whos_Harry_Potter_Towards_Targeted_Unlearning_from_a_Causal_Intervention_Perspective.html#appendix",
    "title": "Revisiting Who’s Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16997v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16997v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11131"
  },
  {
    "objectID": "posts/Exploring_Large_Language_Models_for_Relevance_Judgments_in_Tetun/2024-06-11-Exploring_Large_Language_Models_for_Relevance_Judgments_in_Tetun.html#appendix",
    "href": "posts/Exploring_Large_Language_Models_for_Relevance_Judgments_in_Tetun/2024-06-11-Exploring_Large_Language_Models_for_Relevance_Judgments_in_Tetun.html#appendix",
    "title": "Exploring Large Language Models for Relevance Judgments in Tetun",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07299v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07299v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3697"
  },
  {
    "objectID": "posts/LANE_Logic_Alignment_of_Non_tuning_Large_Language_Models_and_Online_Recommendation_Systems_for_Explainable_Reason_Generation/2024-07-03-LANE_Logic_Alignment_of_Non_tuning_Large_Language_Models_and_Online_Recommendation_Systems_for_Explainable_Reason_Generation.html#appendix",
    "href": "posts/LANE_Logic_Alignment_of_Non_tuning_Large_Language_Models_and_Online_Recommendation_Systems_for_Explainable_Reason_Generation/2024-07-03-LANE_Logic_Alignment_of_Non_tuning_Large_Language_Models_and_Online_Recommendation_Systems_for_Explainable_Reason_Generation.html#appendix",
    "title": "LANE: Logic Alignment of Non-tuning Large Language Models and Online Recommendation Systems for Explainable Reason Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02833v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02833v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9264"
  },
  {
    "objectID": "posts/How_Aligned_are_Human_Chart_Takeaways_and_LLM_Predictions_A_Case_Study_on_Bar_Charts_with_Varying_Layouts/2024-08-13-How_Aligned_are_Human_Chart_Takeaways_and_LLM_Predictions_A_Case_Study_on_Bar_Charts_with_Varying_Layouts.html#appendix",
    "href": "posts/How_Aligned_are_Human_Chart_Takeaways_and_LLM_Predictions_A_Case_Study_on_Bar_Charts_with_Varying_Layouts/2024-08-13-How_Aligned_are_Human_Chart_Takeaways_and_LLM_Predictions_A_Case_Study_on_Bar_Charts_with_Varying_Layouts.html#appendix",
    "title": "How Aligned are Human Chart Takeaways and LLM Predictions? A Case Study on Bar Charts with Varying Layouts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.06837v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.06837v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6285"
  },
  {
    "objectID": "posts/Let_Me_Speak_Freely_A_Study_on_the_Impact_of_Format_Restrictions_on_Performance_of_Large_Language_Models/2024-08-05-Let_Me_Speak_Freely_A_Study_on_the_Impact_of_Format_Restrictions_on_Performance_of_Large_Language_Models.html#appendix",
    "href": "posts/Let_Me_Speak_Freely_A_Study_on_the_Impact_of_Format_Restrictions_on_Performance_of_Large_Language_Models/2024-08-05-Let_Me_Speak_Freely_A_Study_on_the_Impact_of_Format_Restrictions_on_Performance_of_Large_Language_Models.html#appendix",
    "title": "Let Me Speak Freely? A Study on the Impact of Format Restrictions on Performance of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02442v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02442v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7522"
  },
  {
    "objectID": "posts/POEM_Interactive_Prompt_Optimization_for_Enhancing_Multimodal_Reasoning_of_Large_Language_Models/2024-06-06-POEM_Interactive_Prompt_Optimization_for_Enhancing_Multimodal_Reasoning_of_Large_Language_Models.html#appendix",
    "href": "posts/POEM_Interactive_Prompt_Optimization_for_Enhancing_Multimodal_Reasoning_of_Large_Language_Models/2024-06-06-POEM_Interactive_Prompt_Optimization_for_Enhancing_Multimodal_Reasoning_of_Large_Language_Models.html#appendix",
    "title": "POEM: Interactive Prompt Optimization for Enhancing Multimodal Reasoning of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03843v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03843v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12924"
  },
  {
    "objectID": "posts/Hyperion_Unveiling_DApp_Inconsistencies_using_LLM_and_Dataflow_Guided_Symbolic_Execution/2024-08-12-Hyperion_Unveiling_DApp_Inconsistencies_using_LLM_and_Dataflow_Guided_Symbolic_Execution.html#appendix",
    "href": "posts/Hyperion_Unveiling_DApp_Inconsistencies_using_LLM_and_Dataflow_Guided_Symbolic_Execution/2024-08-12-Hyperion_Unveiling_DApp_Inconsistencies_using_LLM_and_Dataflow_Guided_Symbolic_Execution.html#appendix",
    "title": "Hyperion: Unveiling DApp Inconsistencies using LLM and Dataflow-Guided Symbolic Execution",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.06037v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.06037v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11199"
  },
  {
    "objectID": "posts/Improving_Conversational_Abilities_of_Quantized_Large_Language_Models_via_Direct_Preference_Alignment/2024-07-03-Improving_Conversational_Abilities_of_Quantized_Large_Language_Models_via_Direct_Preference_Alignment.html#appendix",
    "href": "posts/Improving_Conversational_Abilities_of_Quantized_Large_Language_Models_via_Direct_Preference_Alignment/2024-07-03-Improving_Conversational_Abilities_of_Quantized_Large_Language_Models_via_Direct_Preference_Alignment.html#appendix",
    "title": "Improving Conversational Abilities of Quantized Large Language Models via Direct Preference Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03051v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03051v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9273"
  },
  {
    "objectID": "posts/LogEval_A_Comprehensive_Benchmark_Suite_for_Large_Language_Models_In_Log_Analysis/2024-07-02-LogEval_A_Comprehensive_Benchmark_Suite_for_Large_Language_Models_In_Log_Analysis.html#appendix",
    "href": "posts/LogEval_A_Comprehensive_Benchmark_Suite_for_Large_Language_Models_In_Log_Analysis/2024-07-02-LogEval_A_Comprehensive_Benchmark_Suite_for_Large_Language_Models_In_Log_Analysis.html#appendix",
    "title": "LogEval: A Comprehensive Benchmark Suite for Large Language Models In Log Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01896v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01896v1\n\n\nTruncated\nFalse\n\n\nWord Count\n0"
  },
  {
    "objectID": "posts/Mimicking_the_Mavens_Agent_based_Opinion_Synthesis_and_Emotion_Prediction_for_Social_Media_Influencers/2024-07-30-Mimicking_the_Mavens_Agent_based_Opinion_Synthesis_and_Emotion_Prediction_for_Social_Media_Influencers.html#appendix",
    "href": "posts/Mimicking_the_Mavens_Agent_based_Opinion_Synthesis_and_Emotion_Prediction_for_Social_Media_Influencers/2024-07-30-Mimicking_the_Mavens_Agent_based_Opinion_Synthesis_and_Emotion_Prediction_for_Social_Media_Influencers.html#appendix",
    "title": "Mimicking the Mavens: Agent-based Opinion Synthesis and Emotion Prediction for Social Media Influencers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20668v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20668v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11943"
  },
  {
    "objectID": "posts/PFID_Privacy_First_Inference_Delegation_Framework_for_LLMs/2024-06-18-PFID_Privacy_First_Inference_Delegation_Framework_for_LLMs.html#appendix",
    "href": "posts/PFID_Privacy_First_Inference_Delegation_Framework_for_LLMs/2024-06-18-PFID_Privacy_First_Inference_Delegation_Framework_for_LLMs.html#appendix",
    "title": "PFID: Privacy First Inference Delegation Framework for LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12238v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12238v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5069"
  },
  {
    "objectID": "posts/KemenkeuGPT_Leveraging_a_Large_Language_Model_on_Indonesias_Government_Financial_Data_and_Regulations_to_Enhance_Decision_Making/2024-07-31-KemenkeuGPT_Leveraging_a_Large_Language_Model_on_Indonesias_Government_Financial_Data_and_Regulations_to_Enhance_Decision_Making.html#appendix",
    "href": "posts/KemenkeuGPT_Leveraging_a_Large_Language_Model_on_Indonesias_Government_Financial_Data_and_Regulations_to_Enhance_Decision_Making/2024-07-31-KemenkeuGPT_Leveraging_a_Large_Language_Model_on_Indonesias_Government_Financial_Data_and_Regulations_to_Enhance_Decision_Making.html#appendix",
    "title": "KemenkeuGPT: Leveraging a Large Language Model on Indonesia’s Government Financial Data and Regulations to Enhance Decision Making",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21459v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21459v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6531"
  },
  {
    "objectID": "posts/Toward_the_Evaluation_of_Large_Language_Models_Considering_Score_Variance_across_Instruction_Templates/2024-08-22-Toward_the_Evaluation_of_Large_Language_Models_Considering_Score_Variance_across_Instruction_Templates.html#appendix",
    "href": "posts/Toward_the_Evaluation_of_Large_Language_Models_Considering_Score_Variance_across_Instruction_Templates/2024-08-22-Toward_the_Evaluation_of_Large_Language_Models_Considering_Score_Variance_across_Instruction_Templates.html#appendix",
    "title": "Toward the Evaluation of Large Language Models Considering Score Variance across Instruction Templates",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12263v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12263v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8798"
  },
  {
    "objectID": "posts/UniFashion_A_Unified_Vision_Language_Model_for_Multimodal_Fashion_Retrieval_and_Generation/2024-08-21-UniFashion_A_Unified_Vision_Language_Model_for_Multimodal_Fashion_Retrieval_and_Generation.html#major-findings",
    "href": "posts/UniFashion_A_Unified_Vision_Language_Model_for_Multimodal_Fashion_Retrieval_and_Generation/2024-08-21-UniFashion_A_Unified_Vision_Language_Model_for_Multimodal_Fashion_Retrieval_and_Generation.html#major-findings",
    "title": "UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nUniFashion is the first study to conduct an in-depth investigation of the synergistic modeling of multimodal retrieval and generation tasks within the fashion domain, thoroughly exploiting the inter-task relatedness.\nThe model enhances performance via mutual task reinforcement, with the caption generation module aiding the CIR task, while jointly training the generation and retrieval tasks improves the multimodal encoder for the diffusion module.\nExtensive experiments on diverse fashion tasks demonstrate that the unified model significantly surpasses previous state-of-the-art methods."
  },
  {
    "objectID": "posts/UniFashion_A_Unified_Vision_Language_Model_for_Multimodal_Fashion_Retrieval_and_Generation/2024-08-21-UniFashion_A_Unified_Vision_Language_Model_for_Multimodal_Fashion_Retrieval_and_Generation.html#analysis-and-critique",
    "href": "posts/UniFashion_A_Unified_Vision_Language_Model_for_Multimodal_Fashion_Retrieval_and_Generation/2024-08-21-UniFashion_A_Unified_Vision_Language_Model_for_Multimodal_Fashion_Retrieval_and_Generation.html#analysis-and-critique",
    "title": "UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper does not provide a detailed comparison with other existing unified models for multimodal tasks, which could help to better understand the advantages and limitations of UniFashion.\nThe paper does not discuss the potential applications of UniFashion in other domains beyond the fashion industry, which could be an interesting direction for future research.\nThe paper does not provide a detailed analysis of the computational complexity and efficiency of UniFashion, which is an important consideration for practical applications.\nThe paper does not discuss the potential ethical implications of using UniFashion for fashion-related applications, such as the impact on body image and self-esteem.\nThe paper does not provide a detailed discussion of the limitations and potential biases of the dataset used for training and evaluation, which could impact the generalizability of the results."
  },
  {
    "objectID": "posts/UniFashion_A_Unified_Vision_Language_Model_for_Multimodal_Fashion_Retrieval_and_Generation/2024-08-21-UniFashion_A_Unified_Vision_Language_Model_for_Multimodal_Fashion_Retrieval_and_Generation.html#appendix",
    "href": "posts/UniFashion_A_Unified_Vision_Language_Model_for_Multimodal_Fashion_Retrieval_and_Generation/2024-08-21-UniFashion_A_Unified_Vision_Language_Model_for_Multimodal_Fashion_Retrieval_and_Generation.html#appendix",
    "title": "UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11305v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11305v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7400"
  },
  {
    "objectID": "posts/Exploring_Human_LLM_Conversations_Mental_Models_and_the_Originator_of_Toxicity/2024-07-08-Exploring_Human_LLM_Conversations_Mental_Models_and_the_Originator_of_Toxicity.html#appendix",
    "href": "posts/Exploring_Human_LLM_Conversations_Mental_Models_and_the_Originator_of_Toxicity/2024-07-08-Exploring_Human_LLM_Conversations_Mental_Models_and_the_Originator_of_Toxicity.html#appendix",
    "title": "Exploring Human-LLM Conversations: Mental Models and the Originator of Toxicity",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05977v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05977v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8762"
  },
  {
    "objectID": "posts/SEED_Accelerating_Reasoning_Tree_Construction_via_Scheduled_Speculative_Decoding/2024-06-26-SEED_Accelerating_Reasoning_Tree_Construction_via_Scheduled_Speculative_Decoding.html",
    "href": "posts/SEED_Accelerating_Reasoning_Tree_Construction_via_Scheduled_Speculative_Decoding/2024-06-26-SEED_Accelerating_Reasoning_Tree_Construction_via_Scheduled_Speculative_Decoding.html",
    "title": "SEED: Accelerating Reasoning Tree Construction via Scheduled Speculative Decoding",
    "section": "",
    "text": "Summary:\nThe paper introduces SEED, a novel and efficient inference framework designed to optimize runtime speed and GPU memory management concurrently in reasoning tree construction. SEED effectively handles two scenarios: executing multiple iterations with the same prompt and evaluating multiple iterations with different prompts. The framework utilizes scheduled speculative decoding to manage the scheduling of parallel draft models and introduces a novel execution strategy, Speculative Scheduled Execution. This strategy is inspired by the use of speculative decoding in parallel drafting. SEED achieves excellent speed performance on three reasoning and planning datasets: GSM8K, Creative Writing, and Blocksworld. The framework also provides a viable path for conducting batched inference in training-free speculative decoding.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a well-structured and coherent summary of the proposed SEED framework. The authors provide a clear explanation of the problem they aim to address and the methodology they employ to tackle it. The use of speculative decoding and parallel drafting in the framework is well-justified, and the results from the experiments demonstrate the effectiveness of the approach. However, the paper could benefit from a more in-depth discussion of the limitations and potential biases in the methodology, as well as a comparison with other existing approaches to reasoning tree construction. Additionally, the authors could explore the potential applications and implications of their framework in real-world scenarios."
  },
  {
    "objectID": "posts/SEED_Accelerating_Reasoning_Tree_Construction_via_Scheduled_Speculative_Decoding/2024-06-26-SEED_Accelerating_Reasoning_Tree_Construction_via_Scheduled_Speculative_Decoding.html#appendix",
    "href": "posts/SEED_Accelerating_Reasoning_Tree_Construction_via_Scheduled_Speculative_Decoding/2024-06-26-SEED_Accelerating_Reasoning_Tree_Construction_via_Scheduled_Speculative_Decoding.html#appendix",
    "title": "SEED: Accelerating Reasoning Tree Construction via Scheduled Speculative Decoding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18200v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18200v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15801"
  },
  {
    "objectID": "posts/Breaking_the_Ceiling_of_the_LLM_Community_by_Treating_Token_Generation_as_a_Classification_for_Ensembling/2024-06-18-Breaking_the_Ceiling_of_the_LLM_Community_by_Treating_Token_Generation_as_a_Classification_for_Ensembling.html#appendix",
    "href": "posts/Breaking_the_Ceiling_of_the_LLM_Community_by_Treating_Token_Generation_as_a_Classification_for_Ensembling/2024-06-18-Breaking_the_Ceiling_of_the_LLM_Community_by_Treating_Token_Generation_as_a_Classification_for_Ensembling.html#appendix",
    "title": "Breaking the Ceiling of the LLM Community by Treating Token Generation as a Classification for Ensembling",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12585v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12585v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5835"
  },
  {
    "objectID": "posts/The_FineWeb_Datasets_Decanting_the_Web_for_the_Finest_Text_Data_at_Scale/2024-06-25-The_FineWeb_Datasets_Decanting_the_Web_for_the_Finest_Text_Data_at_Scale.html#appendix",
    "href": "posts/The_FineWeb_Datasets_Decanting_the_Web_for_the_Finest_Text_Data_at_Scale/2024-06-25-The_FineWeb_Datasets_Decanting_the_Web_for_the_Finest_Text_Data_at_Scale.html#appendix",
    "title": "The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17557v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17557v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10755"
  },
  {
    "objectID": "posts/HyCIR_Boosting_Zero_Shot_Composed_Image_Retrieval_with_Synthetic_Labels/2024-07-08-HyCIR_Boosting_Zero_Shot_Composed_Image_Retrieval_with_Synthetic_Labels.html#appendix",
    "href": "posts/HyCIR_Boosting_Zero_Shot_Composed_Image_Retrieval_with_Synthetic_Labels/2024-07-08-HyCIR_Boosting_Zero_Shot_Composed_Image_Retrieval_with_Synthetic_Labels.html#appendix",
    "title": "HyCIR: Boosting Zero-Shot Composed Image Retrieval with Synthetic Labels",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05795v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05795v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10950"
  },
  {
    "objectID": "posts/Research_on_the_Application_of_Large_Language_Models_in_Automatic_Question_Generation_A_Case_Study_of_ChatGLM_in_the_Context_of_High_School_Information_Technology_Curriculum/2024-08-21-Research_on_the_Application_of_Large_Language_Models_in_Automatic_Question_Generation_A_Case_Study_of_ChatGLM_in_the_Context_of_High_School_Information_Technology_Curriculum.html#appendix",
    "href": "posts/Research_on_the_Application_of_Large_Language_Models_in_Automatic_Question_Generation_A_Case_Study_of_ChatGLM_in_the_Context_of_High_School_Information_Technology_Curriculum/2024-08-21-Research_on_the_Application_of_Large_Language_Models_in_Automatic_Question_Generation_A_Case_Study_of_ChatGLM_in_the_Context_of_High_School_Information_Technology_Curriculum.html#appendix",
    "title": "Research on the Application of Large Language Models in Automatic Question Generation: A Case Study of ChatGLM in the Context of High School Information Technology Curriculum",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11539v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11539v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5099"
  },
  {
    "objectID": "posts/SeCoKD_Aligning_Large_Language_Models_for_In_Context_Learning_with_Fewer_Shots/2024-06-20-SeCoKD_Aligning_Large_Language_Models_for_In_Context_Learning_with_Fewer_Shots.html#appendix",
    "href": "posts/SeCoKD_Aligning_Large_Language_Models_for_In_Context_Learning_with_Fewer_Shots/2024-06-20-SeCoKD_Aligning_Large_Language_Models_for_In_Context_Learning_with_Fewer_Shots.html#appendix",
    "title": "SeCoKD: Aligning Large Language Models for In-Context Learning with Fewer Shots",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14208v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14208v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6370"
  },
  {
    "objectID": "posts/Dual_Space_Knowledge_Distillation_for_Large_Language_Models/2024-06-25-Dual_Space_Knowledge_Distillation_for_Large_Language_Models.html#appendix",
    "href": "posts/Dual_Space_Knowledge_Distillation_for_Large_Language_Models/2024-06-25-Dual_Space_Knowledge_Distillation_for_Large_Language_Models.html#appendix",
    "title": "Dual-Space Knowledge Distillation for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17328v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17328v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8166"
  },
  {
    "objectID": "posts/Model_Merging_and_Safety_Alignment_One_Bad_Model_Spoils_the_Bunch/2024-06-20-Model_Merging_and_Safety_Alignment_One_Bad_Model_Spoils_the_Bunch.html#appendix",
    "href": "posts/Model_Merging_and_Safety_Alignment_One_Bad_Model_Spoils_the_Bunch/2024-06-20-Model_Merging_and_Safety_Alignment_One_Bad_Model_Spoils_the_Bunch.html#appendix",
    "title": "Model Merging and Safety Alignment: One Bad Model Spoils the Bunch",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14563v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14563v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8326"
  },
  {
    "objectID": "posts/On_the_Universal_Truthfulness_Hyperplane_Inside_LLMs/2024-07-11-On_the_Universal_Truthfulness_Hyperplane_Inside_LLMs.html#appendix",
    "href": "posts/On_the_Universal_Truthfulness_Hyperplane_Inside_LLMs/2024-07-11-On_the_Universal_Truthfulness_Hyperplane_Inside_LLMs.html#appendix",
    "title": "On the Universal Truthfulness Hyperplane Inside LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08582v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08582v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14310"
  },
  {
    "objectID": "posts/Mental_Modeling_of_Reinforcement_Learning_Agents_by_Language_Models/2024-06-26-Mental_Modeling_of_Reinforcement_Learning_Agents_by_Language_Models.html#appendix",
    "href": "posts/Mental_Modeling_of_Reinforcement_Learning_Agents_by_Language_Models/2024-06-26-Mental_Modeling_of_Reinforcement_Learning_Agents_by_Language_Models.html#appendix",
    "title": "Mental Modeling of Reinforcement Learning Agents by Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18505v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18505v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9604"
  },
  {
    "objectID": "posts/PlagBench_Exploring_the_Duality_of_Large_Language_Models_in_Plagiarism_Generation_and_Detection/2024-06-24-PlagBench_Exploring_the_Duality_of_Large_Language_Models_in_Plagiarism_Generation_and_Detection.html#appendix",
    "href": "posts/PlagBench_Exploring_the_Duality_of_Large_Language_Models_in_Plagiarism_Generation_and_Detection/2024-06-24-PlagBench_Exploring_the_Duality_of_Large_Language_Models_in_Plagiarism_Generation_and_Detection.html#appendix",
    "title": "PlagBench: Exploring the Duality of Large Language Models in Plagiarism Generation and Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16288v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16288v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8349"
  },
  {
    "objectID": "posts/Ranking_Generated_Answers_On_the_Agreement_of_Retrieval_Models_with_Humans_on_Consumer_Health_Questions/2024-08-19-Ranking_Generated_Answers_On_the_Agreement_of_Retrieval_Models_with_Humans_on_Consumer_Health_Questions.html#appendix",
    "href": "posts/Ranking_Generated_Answers_On_the_Agreement_of_Retrieval_Models_with_Humans_on_Consumer_Health_Questions/2024-08-19-Ranking_Generated_Answers_On_the_Agreement_of_Retrieval_Models_with_Humans_on_Consumer_Health_Questions.html#appendix",
    "title": "Ranking Generated Answers: On the Agreement of Retrieval Models with Humans on Consumer Health Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09831v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09831v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3362"
  },
  {
    "objectID": "posts/LLMs_for_Doctors_Leveraging_Medical_LLMs_to_Assist_Doctors_Not_Replace_Them/2024-06-26-LLMs_for_Doctors_Leveraging_Medical_LLMs_to_Assist_Doctors_Not_Replace_Them.html#appendix",
    "href": "posts/LLMs_for_Doctors_Leveraging_Medical_LLMs_to_Assist_Doctors_Not_Replace_Them/2024-06-26-LLMs_for_Doctors_Leveraging_Medical_LLMs_to_Assist_Doctors_Not_Replace_Them.html#appendix",
    "title": "LLMs for Doctors: Leveraging Medical LLMs to Assist Doctors, Not Replace Them",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18034v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18034v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10560"
  },
  {
    "objectID": "posts/Migrating_Existing_Container_Workload_to_Kubernetes____LLM_Based_Approach_and_Evaluation/2024-08-21-Migrating_Existing_Container_Workload_to_Kubernetes____LLM_Based_Approach_and_Evaluation.html#appendix",
    "href": "posts/Migrating_Existing_Container_Workload_to_Kubernetes____LLM_Based_Approach_and_Evaluation/2024-08-21-Migrating_Existing_Container_Workload_to_Kubernetes____LLM_Based_Approach_and_Evaluation.html#appendix",
    "title": "Migrating Existing Container Workload to Kubernetes – LLM Based Approach and Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11428v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11428v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3727"
  },
  {
    "objectID": "posts/Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course/2024-06-10-Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course.html",
    "href": "posts/Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course/2024-06-10-Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course.html",
    "title": "Insights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course",
    "section": "",
    "text": "Summary:\nThis study explores the social dynamics surrounding the use of large language models (LLMs) in an undergraduate programming course. The research is guided by the social shaping of technology theory and focuses on two research questions: (1) How do social perceptions influence the usage of LLMs in an undergraduate intermediate-level programming course? (2) How does LLM usage relate to programming self-efficacy and midterm scores among undergraduate students in an intermediate-level programming course?\nThe study employs a mixed-methods approach, including an anonymous student survey, student interviews, and a regression analysis of midterm performance data with students’ self-reported use of LLMs on homework. The findings suggest that students’ engagement with LLMs is significantly associated with their perceptions of their future careers and their peers’ usage. Additionally, the use of LLMs has mixed impacts on students’ self-efficacy and perceived learning outcomes, with a notable negative correlation between LLM usage and self-efficacy regardless of major and a negative correlation between LLM usage and performance on the first midterm.\nMajor Findings:\nAnalysis and Critique:\nThe study provides valuable insights into the social dynamics surrounding the use of LLMs in undergraduate programming education. However, the research has some limitations, including the context of the study, potential selection bias, reliance on self-reported data, and the correlational nature of the regression analyses. Additionally, the study’s focus on peer-reviewed literature may have led to the omission of relevant contributions from non-peer-reviewed sources. Despite these limitations, the research offers a nuanced understanding of the complex dynamic between technology and social factors, challenging the notion of technological determinism. As LLMs and other AI technologies continue to evolve, it is crucial to consider the social dynamics that shape their appropriation."
  },
  {
    "objectID": "posts/Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course/2024-06-10-Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course.html#appendix",
    "href": "posts/Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course/2024-06-10-Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course.html#appendix",
    "title": "Insights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06451v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06451v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14658"
  },
  {
    "objectID": "posts/Validating_LLM_Generated_Programs_with_Metamorphic_Prompt_Testing/2024-06-11-Validating_LLM_Generated_Programs_with_Metamorphic_Prompt_Testing.html#appendix",
    "href": "posts/Validating_LLM_Generated_Programs_with_Metamorphic_Prompt_Testing/2024-06-11-Validating_LLM_Generated_Programs_with_Metamorphic_Prompt_Testing.html#appendix",
    "title": "Validating LLM-Generated Programs with Metamorphic Prompt Testing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06864v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06864v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6738"
  },
  {
    "objectID": "posts/Assessing_Code_Generation_with_Intermediate_Languages/2024-07-07-Assessing_Code_Generation_with_Intermediate_Languages.html#appendix",
    "href": "posts/Assessing_Code_Generation_with_Intermediate_Languages/2024-07-07-Assessing_Code_Generation_with_Intermediate_Languages.html#appendix",
    "title": "Assessing Code Generation with Intermediate Languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05411v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05411v1\n\n\nTruncated\nFalse\n\n\nWord Count\n370"
  },
  {
    "objectID": "posts/ScreenTK_Seamless_Detection_of_Time_Killing_Moments_Using_Continuous_Mobile_Screen_Text_Monitoring/2024-07-03-ScreenTK_Seamless_Detection_of_Time_Killing_Moments_Using_Continuous_Mobile_Screen_Text_Monitoring.html#appendix",
    "href": "posts/ScreenTK_Seamless_Detection_of_Time_Killing_Moments_Using_Continuous_Mobile_Screen_Text_Monitoring/2024-07-03-ScreenTK_Seamless_Detection_of_Time_Killing_Moments_Using_Continuous_Mobile_Screen_Text_Monitoring.html#appendix",
    "title": "ScreenTK: Seamless Detection of Time-Killing Moments Using Continuous Mobile Screen Text Monitoring",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03063v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03063v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3256"
  },
  {
    "objectID": "posts/Antidote_Post_fine_tuning_Safety_Alignment_for_Large_Language_Models_against_Harmful_Fine_tuning/2024-08-18-Antidote_Post_fine_tuning_Safety_Alignment_for_Large_Language_Models_against_Harmful_Fine_tuning.html#appendix",
    "href": "posts/Antidote_Post_fine_tuning_Safety_Alignment_for_Large_Language_Models_against_Harmful_Fine_tuning/2024-08-18-Antidote_Post_fine_tuning_Safety_Alignment_for_Large_Language_Models_against_Harmful_Fine_tuning.html#appendix",
    "title": "Antidote: Post-fine-tuning Safety Alignment for Large Language Models against Harmful Fine-tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09600v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09600v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8169"
  },
  {
    "objectID": "posts/Fairness_and_Bias_in_Multimodal_AI_A_Survey/2024-06-27-Fairness_and_Bias_in_Multimodal_AI_A_Survey.html#appendix",
    "href": "posts/Fairness_and_Bias_in_Multimodal_AI_A_Survey/2024-06-27-Fairness_and_Bias_in_Multimodal_AI_A_Survey.html#appendix",
    "title": "Fairness and Bias in Multimodal AI: A Survey",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19097v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19097v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5909"
  },
  {
    "objectID": "posts/SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance/2024-06-26-SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance.html#major-findings",
    "href": "posts/SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance/2024-06-26-SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance.html#major-findings",
    "title": "SafeAligner: Safety Alignment against Jailbreak Attacks via Response Disparity Guidance",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nSafeAligner increases the likelihood of beneficial tokens while reducing the occurrence of harmful ones, ensuring secure alignment with minimal loss to generality.\nExtensive experiments demonstrate that SafeAligner can be applied to various LLMs, improving their defensive capabilities while preserving their inherent general capabilities.\nThe method achieves safety alignment cost-effectively, with potential cost reductions by scaling down internal models."
  },
  {
    "objectID": "posts/SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance/2024-06-26-SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance.html#analysis-and-critique",
    "href": "posts/SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance/2024-06-26-SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance.html#analysis-and-critique",
    "title": "SafeAligner: Safety Alignment against Jailbreak Attacks via Response Disparity Guidance",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a novel approach to addressing jailbreak attacks on LLMs, which is a significant concern in the field. The proposed method, SafeAligner, offers a promising solution by leveraging the differences in the safety tendencies of model responses. However, the paper does not discuss the potential limitations or unintended consequences of using this method. For instance, it is unclear how SafeAligner would handle cases where the Sentinel and Intruder Models produce conflicting or ambiguous responses. Additionally, the paper does not address the potential computational overhead of training and maintaining two specialized models. Further research is needed to evaluate the long-term effectiveness and efficiency of SafeAligner in real-world applications."
  },
  {
    "objectID": "posts/SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance/2024-06-26-SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance.html#appendix",
    "href": "posts/SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance/2024-06-26-SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance.html#appendix",
    "title": "SafeAligner: Safety Alignment against Jailbreak Attacks via Response Disparity Guidance",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18118v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18118v1\n\n\nTruncated\nFalse\n\n\nWord Count\n21385"
  },
  {
    "objectID": "posts/Can_Large_Language_Models_Always_Solve_Easy_Problems_if_They_Can_Solve_Harder_Ones/2024-06-18-Can_Large_Language_Models_Always_Solve_Easy_Problems_if_They_Can_Solve_Harder_Ones.html#appendix",
    "href": "posts/Can_Large_Language_Models_Always_Solve_Easy_Problems_if_They_Can_Solve_Harder_Ones/2024-06-18-Can_Large_Language_Models_Always_Solve_Easy_Problems_if_They_Can_Solve_Harder_Ones.html#appendix",
    "title": "Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12809v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12809v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9280"
  },
  {
    "objectID": "posts/Serial_Position_Effects_of_Large_Language_Models/2024-06-23-Serial_Position_Effects_of_Large_Language_Models.html#appendix",
    "href": "posts/Serial_Position_Effects_of_Large_Language_Models/2024-06-23-Serial_Position_Effects_of_Large_Language_Models.html#appendix",
    "title": "Serial Position Effects of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.15981v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.15981v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10164"
  },
  {
    "objectID": "posts/Patchview_LLM_Powered_Worldbuilding_with_Generative_Dust_and_Magnet_Visualization/2024-08-07-Patchview_LLM_Powered_Worldbuilding_with_Generative_Dust_and_Magnet_Visualization.html",
    "href": "posts/Patchview_LLM_Powered_Worldbuilding_with_Generative_Dust_and_Magnet_Visualization/2024-08-07-Patchview_LLM_Powered_Worldbuilding_with_Generative_Dust_and_Magnet_Visualization.html",
    "title": "Patchview: LLM-Powered Worldbuilding with Generative Dust and Magnet Visualization",
    "section": "",
    "text": "Summary:\nThe paper introduces Patchview, a customizable LLM-powered system that aids worldbuilding by allowing users to interact with story concepts and elements through the physical metaphor of magnets and dust. Elements in Patchview are visually dragged closer to concepts with high relevance, facilitating sensemaking. The user can also steer the generation with verbally elusive concepts by indicating the desired position of the element between concepts. When the user disagrees with the LLM’s visualization and generation, they can correct those by repositioning the element. These corrections can be used to align the LLM’s future behaviors to the user’s perception. A user study shows that Patchview supports the sensemaking of world elements and steering of element generation, facilitating exploration during the worldbuilding process. Patchview provides insights on how customizable visual representation can help sensemake, steer, and align generative AI model behaviors with the user’s intentions.\nMajor Findings:\nAnalysis and Critique:\nWhile Patchview provides a novel approach to interacting with generative AI models, there are potential limitations and areas for improvement. The interaction of correcting misaligned AI results was intuitive, but those corrections minimally improved the alignment of AI behaviors to the user’s perception, indicating one possible direction for future work. Additionally, the system’s usability and functionalities could be improved, such as adding filtering functions to the list module and better handling under-specified or irrelevant concepts. The study involved only a single session, and future work might investigate the use of Patchview for long-term projects, including the extension of already existing story worlds. Furthermore, the design of Patchview was not compared to other alternatives when the user creates their own story world with LLMs. Future work may investigate comparison to other tools."
  },
  {
    "objectID": "posts/Patchview_LLM_Powered_Worldbuilding_with_Generative_Dust_and_Magnet_Visualization/2024-08-07-Patchview_LLM_Powered_Worldbuilding_with_Generative_Dust_and_Magnet_Visualization.html#appendix",
    "href": "posts/Patchview_LLM_Powered_Worldbuilding_with_Generative_Dust_and_Magnet_Visualization/2024-08-07-Patchview_LLM_Powered_Worldbuilding_with_Generative_Dust_and_Magnet_Visualization.html#appendix",
    "title": "Patchview: LLM-Powered Worldbuilding with Generative Dust and Magnet Visualization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04112v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04112v1\n\n\nTruncated\nFalse\n\n\nWord Count\n19836"
  },
  {
    "objectID": "posts/Better_Debugging_Combining_Static_Analysis_and_LLMs_for_Explainable_Crashing_Fault_Localization/2024-08-22-Better_Debugging_Combining_Static_Analysis_and_LLMs_for_Explainable_Crashing_Fault_Localization.html",
    "href": "posts/Better_Debugging_Combining_Static_Analysis_and_LLMs_for_Explainable_Crashing_Fault_Localization/2024-08-22-Better_Debugging_Combining_Static_Analysis_and_LLMs_for_Explainable_Crashing_Fault_Localization.html",
    "title": "Better Debugging: Combining Static Analysis and LLMs for Explainable Crashing Fault Localization",
    "section": "",
    "text": "Summary:\nThe paper presents a novel approach for explainable crashing fault localization by combining static analysis and large language models (LLMs). The approach aims to address the challenge of debugging and fixing post-release crashes in applications that rely on various frameworks or libraries. The primary insight is that understanding the semantics of exception-throwing statements in the framework code can help find and apprehend buggy methods in the application code.\nThe proposed approach involves designing an exception-thrown summary (ETS) that describes key elements related to each framework-specific exception and extracting ETSs by performing static analysis. The approach does not solely depend on call graph tracing and does not require prior knowledge. Instead, it fully utilizes the information from the framework code and is the first to consider the explainability of the localization results.\nThe approach is applied to one typical scenario, i.e., locating Android framework-specific crashing faults, and implemented as a tool called CrashTracker. The fault localization results show that CrashTracker exhibited an overall MRR value of 0.91 and outperformed the SOTA tool Anchor in precision. For fault explanation, the LLM-powered explanation achieved a 67.04% improvement in users’ satisfaction score compared to the naive one produced by static analysis only.\nMajor Findings:"
  },
  {
    "objectID": "posts/Better_Debugging_Combining_Static_Analysis_and_LLMs_for_Explainable_Crashing_Fault_Localization/2024-08-22-Better_Debugging_Combining_Static_Analysis_and_LLMs_for_Explainable_Crashing_Fault_Localization.html#appendix",
    "href": "posts/Better_Debugging_Combining_Static_Analysis_and_LLMs_for_Explainable_Crashing_Fault_Localization/2024-08-22-Better_Debugging_Combining_Static_Analysis_and_LLMs_for_Explainable_Crashing_Fault_Localization.html#appendix",
    "title": "Better Debugging: Combining Static Analysis and LLMs for Explainable Crashing Fault Localization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12070v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12070v1\n\n\nTruncated\nFalse\n\n\nWord Count\n19814"
  },
  {
    "objectID": "posts/Development_of_an_AI_Anti_Bullying_System_Using_Large_Language_Model_Key_Topic_Detection/2024-08-19-Development_of_an_AI_Anti_Bullying_System_Using_Large_Language_Model_Key_Topic_Detection.html",
    "href": "posts/Development_of_an_AI_Anti_Bullying_System_Using_Large_Language_Model_Key_Topic_Detection/2024-08-19-Development_of_an_AI_Anti_Bullying_System_Using_Large_Language_Model_Key_Topic_Detection.html",
    "title": "Development of an AI Anti-Bullying System Using Large Language Model Key Topic Detection",
    "section": "",
    "text": "Summary:\nThe paper presents an AI anti-bullying system (AABS) designed to identify and analyze coordinated bullying attacks via social media and other platforms. The system uses a large language model (LLM) to populate an expert system-based network model of a bullying attack, facilitating analysis and remediation activities. The paper discusses the challenges of AI-based bullying, which can be particularly pronounced due to the speed, knowledge, and capabilities of AI. The proposed AABS system aims to give responders, such as parents, teachers, and law enforcement, a capability that is just as effective as that provided to a would-be bully by a basic LLM.\nKey Terms: AI anti-bullying system (AABS), large language model (LLM), cyberbullying, bullying attack, remediation activities, generative artificial intelligence (GAI)\n**Major Findings"
  },
  {
    "objectID": "posts/Development_of_an_AI_Anti_Bullying_System_Using_Large_Language_Model_Key_Topic_Detection/2024-08-19-Development_of_an_AI_Anti_Bullying_System_Using_Large_Language_Model_Key_Topic_Detection.html#appendix",
    "href": "posts/Development_of_an_AI_Anti_Bullying_System_Using_Large_Language_Model_Key_Topic_Detection/2024-08-19-Development_of_an_AI_Anti_Bullying_System_Using_Large_Language_Model_Key_Topic_Detection.html#appendix",
    "title": "Development of an AI Anti-Bullying System Using Large Language Model Key Topic Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10417v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10417v1\n\n\nTruncated\nTrue\n\n\nWord Count\n56150"
  },
  {
    "objectID": "posts/An_Empirical_Study_of_Validating_Synthetic_Data_for_Formula_Generation/2024-07-15-An_Empirical_Study_of_Validating_Synthetic_Data_for_Formula_Generation.html#appendix",
    "href": "posts/An_Empirical_Study_of_Validating_Synthetic_Data_for_Formula_Generation/2024-07-15-An_Empirical_Study_of_Validating_Synthetic_Data_for_Formula_Generation.html#appendix",
    "title": "An Empirical Study of Validating Synthetic Data for Formula Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10657v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10657v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3668"
  },
  {
    "objectID": "posts/Open_domain_Implicit_Format_Control_for_Large_Language_Model_Generation/2024-08-08-Open_domain_Implicit_Format_Control_for_Large_Language_Model_Generation.html#appendix",
    "href": "posts/Open_domain_Implicit_Format_Control_for_Large_Language_Model_Generation/2024-08-08-Open_domain_Implicit_Format_Control_for_Large_Language_Model_Generation.html#appendix",
    "title": "Open-domain Implicit Format Control for Large Language Model Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04392v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04392v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3833"
  },
  {
    "objectID": "posts/Probing_Causality_Manipulation_of_Large_Language_Models/2024-08-26-Probing_Causality_Manipulation_of_Large_Language_Models.html#appendix",
    "href": "posts/Probing_Causality_Manipulation_of_Large_Language_Models/2024-08-26-Probing_Causality_Manipulation_of_Large_Language_Models.html#appendix",
    "title": "Probing Causality Manipulation of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.14380v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.14380v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4755"
  },
  {
    "objectID": "posts/CLIMB_A_Benchmark_of_Clinical_Bias_in_Large_Language_Models/2024-07-07-CLIMB_A_Benchmark_of_Clinical_Bias_in_Large_Language_Models.html#appendix",
    "href": "posts/CLIMB_A_Benchmark_of_Clinical_Bias_in_Large_Language_Models/2024-07-07-CLIMB_A_Benchmark_of_Clinical_Bias_in_Large_Language_Models.html#appendix",
    "title": "CLIMB: A Benchmark of Clinical Bias in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05250v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05250v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6808"
  },
  {
    "objectID": "posts/GraCoRe_Benchmarking_Graph_Comprehension_and_Complex_Reasoning_in_Large_Language_Models/2024-07-03-GraCoRe_Benchmarking_Graph_Comprehension_and_Complex_Reasoning_in_Large_Language_Models.html#appendix",
    "href": "posts/GraCoRe_Benchmarking_Graph_Comprehension_and_Complex_Reasoning_in_Large_Language_Models/2024-07-03-GraCoRe_Benchmarking_Graph_Comprehension_and_Complex_Reasoning_in_Large_Language_Models.html#appendix",
    "title": "GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02936v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02936v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5687"
  },
  {
    "objectID": "posts/GenderCARE_A_Comprehensive_Framework_for_Assessing_and_Reducing_Gender_Bias_in_Large_Language_Models/2024-08-22-GenderCARE_A_Comprehensive_Framework_for_Assessing_and_Reducing_Gender_Bias_in_Large_Language_Models.html#appendix",
    "href": "posts/GenderCARE_A_Comprehensive_Framework_for_Assessing_and_Reducing_Gender_Bias_in_Large_Language_Models/2024-08-22-GenderCARE_A_Comprehensive_Framework_for_Assessing_and_Reducing_Gender_Bias_in_Large_Language_Models.html#appendix",
    "title": "GenderCARE: A Comprehensive Framework for Assessing and Reducing Gender Bias in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12494v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12494v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12462"
  },
  {
    "objectID": "posts/DracoGPT_Extracting_Visualization_Design_Preferences_from_Large_Language_Models/2024-08-13-DracoGPT_Extracting_Visualization_Design_Preferences_from_Large_Language_Models.html#appendix",
    "href": "posts/DracoGPT_Extracting_Visualization_Design_Preferences_from_Large_Language_Models/2024-08-13-DracoGPT_Extracting_Visualization_Design_Preferences_from_Large_Language_Models.html#appendix",
    "title": "DracoGPT: Extracting Visualization Design Preferences from Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.06845v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.06845v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5592"
  },
  {
    "objectID": "posts/Supporting_Software_Maintenance_with_Dynamically_Generated_Document_Hierarchies/2024-08-11-Supporting_Software_Maintenance_with_Dynamically_Generated_Document_Hierarchies.html",
    "href": "posts/Supporting_Software_Maintenance_with_Dynamically_Generated_Document_Hierarchies/2024-08-11-Supporting_Software_Maintenance_with_Dynamically_Generated_Document_Hierarchies.html",
    "title": "Supporting Software Maintenance with Dynamically Generated Document Hierarchies",
    "section": "",
    "text": "Summary:\nThe paper presents HGEN, a fully automated pipeline that leverages large language models (LLMs) to transform source code into a well-organized hierarchy of formatted documents. HGEN aims to address the problem of time-consuming and often neglected software documentation by generating multi-level, just-in-time software documentation. The pipeline consists of six stages, including code summarization, clustering, content generation, refinement, and trace link generation.\nThe paper evaluates HGEN both quantitatively and qualitatively. First, it uses HGEN to generate documentation for three diverse projects and engages key developers in comparing the quality of the generated documentation against their own manually-crafted documentation. Second, it pilots HGEN in nine different industrial projects using diverse datasets provided by each project and collects feedback from project stakeholders.\nResults show that HGEN produces artifact hierarchies similar in quality to manually constructed documentation, with much higher coverage of core concepts than the baseline approach. Stakeholder feedback highlights HGEN’s commercial impact potential as a tool for accelerating code comprehension and maintenance tasks.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a promising approach to addressing the challenge of software documentation by leveraging LLMs to generate multi-level, just-in-time documentation. The evaluation of HGEN, both quantitatively and qualitatively, provides a comprehensive assessment of its performance. However, the paper does not discuss potential limitations or biases in the evaluation process, such as the selection of projects or the expertise of the key developers involved in the comparison. Additionally, the paper does not explore the potential impact of HGEN on the software development process or the potential risks associated with relying on automated documentation. Further research is needed to address these questions and to evaluate the long-term effectiveness of HGEN in supporting software maintenance tasks."
  },
  {
    "objectID": "posts/Supporting_Software_Maintenance_with_Dynamically_Generated_Document_Hierarchies/2024-08-11-Supporting_Software_Maintenance_with_Dynamically_Generated_Document_Hierarchies.html#appendix",
    "href": "posts/Supporting_Software_Maintenance_with_Dynamically_Generated_Document_Hierarchies/2024-08-11-Supporting_Software_Maintenance_with_Dynamically_Generated_Document_Hierarchies.html#appendix",
    "title": "Supporting Software Maintenance with Dynamically Generated Document Hierarchies",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.05829v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.05829v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9253"
  },
  {
    "objectID": "posts/Evaluation_of_Instruction_Following_Ability_for_Large_Language_Models_on_Story_Ending_Generation/2024-06-24-Evaluation_of_Instruction_Following_Ability_for_Large_Language_Models_on_Story_Ending_Generation.html#appendix",
    "href": "posts/Evaluation_of_Instruction_Following_Ability_for_Large_Language_Models_on_Story_Ending_Generation/2024-06-24-Evaluation_of_Instruction_Following_Ability_for_Large_Language_Models_on_Story_Ending_Generation.html#appendix",
    "title": "Evaluation of Instruction-Following Ability for Large Language Models on Story-Ending Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16356v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16356v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4154"
  },
  {
    "objectID": "posts/Large_Language_Models_for_Constrained_Based_Causal_Discovery/2024-06-11-Large_Language_Models_for_Constrained_Based_Causal_Discovery.html#appendix",
    "href": "posts/Large_Language_Models_for_Constrained_Based_Causal_Discovery/2024-06-11-Large_Language_Models_for_Constrained_Based_Causal_Discovery.html#appendix",
    "title": "Large Language Models for Constrained-Based Causal Discovery",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07378v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07378v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7632"
  },
  {
    "objectID": "posts/Beyond_Detection_Leveraging_Large_Language_Models_for_Cyber_Attack_Prediction_in_IoT_Networks/2024-08-26-Beyond_Detection_Leveraging_Large_Language_Models_for_Cyber_Attack_Prediction_in_IoT_Networks.html#appendix",
    "href": "posts/Beyond_Detection_Leveraging_Large_Language_Models_for_Cyber_Attack_Prediction_in_IoT_Networks/2024-08-26-Beyond_Detection_Leveraging_Large_Language_Models_for_Cyber_Attack_Prediction_in_IoT_Networks.html#appendix",
    "title": "Beyond Detection: Leveraging Large Language Models for Cyber Attack Prediction in IoT Networks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.14045v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.14045v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5262"
  },
  {
    "objectID": "posts/LiveBench_A_Challenging_Contamination_Free_LLM_Benchmark/2024-06-27-LiveBench_A_Challenging_Contamination_Free_LLM_Benchmark.html",
    "href": "posts/LiveBench_A_Challenging_Contamination_Free_LLM_Benchmark/2024-06-27-LiveBench_A_Challenging_Contamination_Free_LLM_Benchmark.html",
    "title": "LiveBench: A Challenging, Contamination-Free LLM Benchmark",
    "section": "",
    "text": "Summary: The paper introduces LiveBench, a new benchmark for large language models (LLMs) that aims to address the issues of test set contamination and the limitations of LLM judging and human crowdsourcing. LiveBench features frequently-updated questions from recent information sources, automatic scoring based on objective ground-truth values, and a wide variety of challenging tasks across six categories: coding, data, instruction, language, math, and reasoning. The benchmark includes questions based on recent math competitions, arXiv papers, news articles, and datasets, as well as harder, contamination-free versions of tasks from previous benchmarks. The study compares 49 LLMs on LiveBench, with claude-3-5-sonnet-20240620 performing the best across all categories and overall.\nMajor Findings: 1. LiveBench is a new benchmark for LL"
  },
  {
    "objectID": "posts/LiveBench_A_Challenging_Contamination_Free_LLM_Benchmark/2024-06-27-LiveBench_A_Challenging_Contamination_Free_LLM_Benchmark.html#appendix",
    "href": "posts/LiveBench_A_Challenging_Contamination_Free_LLM_Benchmark/2024-06-27-LiveBench_A_Challenging_Contamination_Free_LLM_Benchmark.html#appendix",
    "title": "LiveBench: A Challenging, Contamination-Free LLM Benchmark",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19314v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19314v1\n\n\nTruncated\nTrue\n\n\nWord Count\n27632"
  },
  {
    "objectID": "posts/Defining_Boundaries_A_Spectrum_of_Task_Feasibility_for_Large_Language_Models/2024-08-11-Defining_Boundaries_A_Spectrum_of_Task_Feasibility_for_Large_Language_Models.html#appendix",
    "href": "posts/Defining_Boundaries_A_Spectrum_of_Task_Feasibility_for_Large_Language_Models/2024-08-11-Defining_Boundaries_A_Spectrum_of_Task_Feasibility_for_Large_Language_Models.html#appendix",
    "title": "Defining Boundaries: A Spectrum of Task Feasibility for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.05873v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.05873v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6756"
  },
  {
    "objectID": "posts/Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study/2024-07-02-Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study.html",
    "href": "posts/Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study/2024-07-02-Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study.html",
    "title": "Understanding Alignment in Multimodal LLMs: A Comprehensive Study",
    "section": "",
    "text": "Summary: This academic article focuses on the challenges of hallucination in Multimodal Large Language Models (MLLMs) and the importance of alignment in MLLMs to produce responses more closely aligned with image information. The authors introduce a novel technique called Bias-Driven Hallucination Sampling (BDHS) to address the shortcomings of previous methods. BDHS limits access in the latent space via attention masking, which more directly achieves the underlying motivation of triggering the inherent bias of the underlying language model. The study also introduces a new derivative called MMHALBench-V, which incorporates GPT-4o to provide input images as additional context for evaluating model capabilities. The results of ablation experiments for BDHS show that all BDHS ablations significantly improve performance on LLaVABench-in-the-Wild compared to the DPO baseline and POVID-style"
  },
  {
    "objectID": "posts/Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study/2024-07-02-Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study.html#appendix",
    "href": "posts/Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study/2024-07-02-Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study.html#appendix",
    "title": "Understanding Alignment in Multimodal LLMs: A Comprehensive Study",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02477v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02477v1\n\n\nTruncated\nTrue\n\n\nWord Count\n29846"
  },
  {
    "objectID": "posts/Adapting_Safe_for_Work_Classifier_for_Malaysian_Language_Text_Enhancing_Alignment_in_LLM_Ops_Framework/2024-07-30-Adapting_Safe_for_Work_Classifier_for_Malaysian_Language_Text_Enhancing_Alignment_in_LLM_Ops_Framework.html#appendix",
    "href": "posts/Adapting_Safe_for_Work_Classifier_for_Malaysian_Language_Text_Enhancing_Alignment_in_LLM_Ops_Framework/2024-07-30-Adapting_Safe_for_Work_Classifier_for_Malaysian_Language_Text_Enhancing_Alignment_in_LLM_Ops_Framework.html#appendix",
    "title": "Adapting Safe-for-Work Classifier for Malaysian Language Text: Enhancing Alignment in LLM-Ops Framework",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20729v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20729v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3911"
  },
  {
    "objectID": "posts/Improving_Factuality_in_Large_Language_Models_via_Decoding_Time_Hallucinatory_and_Truthful_Comparators/2024-08-22-Improving_Factuality_in_Large_Language_Models_via_Decoding_Time_Hallucinatory_and_Truthful_Comparators.html#major-findings",
    "href": "posts/Improving_Factuality_in_Large_Language_Models_via_Decoding_Time_Hallucinatory_and_Truthful_Comparators/2024-08-22-Improving_Factuality_in_Large_Language_Models_via_Decoding_Time_Hallucinatory_and_Truthful_Comparators.html#major-findings",
    "title": "Improving Factuality in Large Language Models via Decoding-Time Hallucinatory and Truthful Comparators",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe CDT framework can significantly improve the robustness and factuality of model responses by removing non-factual knowledge from the output space during the decoding process.\nThe comparators in the CDT framework are not limited to specific model structures and task types, offering the prospect of eliminating hallucinations with multifaceted patterns in different tasks.\nExtensive experiments on multiple NLP benchmarks demonstrate the broad applicability and effectiveness of the proposed framework."
  },
  {
    "objectID": "posts/Improving_Factuality_in_Large_Language_Models_via_Decoding_Time_Hallucinatory_and_Truthful_Comparators/2024-08-22-Improving_Factuality_in_Large_Language_Models_via_Decoding_Time_Hallucinatory_and_Truthful_Comparators.html#analysis-and-critique",
    "href": "posts/Improving_Factuality_in_Large_Language_Models_via_Decoding_Time_Hallucinatory_and_Truthful_Comparators/2024-08-22-Improving_Factuality_in_Large_Language_Models_via_Decoding_Time_Hallucinatory_and_Truthful_Comparators.html#analysis-and-critique",
    "title": "Improving Factuality in Large Language Models via Decoding-Time Hallucinatory and Truthful Comparators",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper does not provide a detailed comparison with other existing methods that address the hallucination problem in LLMs.\nThe paper does not discuss the potential limitations of the proposed framework, such as the increased computational cost and the need for large-scale fine-tuning data.\nThe paper does not provide a clear explanation of how the instruction prototype-guided mixture of experts strategy enhances the ability of the comparators to capture different hallucination or truthfulness patterns in distinct task instructions.\nThe paper does not discuss the potential impact of the proposed framework on the interpretability and explainability of LLMs.\nThe paper does not provide a clear explanation of how the proposed framework can be extended to other NLP tasks beyond the ones considered in the experiments."
  },
  {
    "objectID": "posts/Improving_Factuality_in_Large_Language_Models_via_Decoding_Time_Hallucinatory_and_Truthful_Comparators/2024-08-22-Improving_Factuality_in_Large_Language_Models_via_Decoding_Time_Hallucinatory_and_Truthful_Comparators.html#appendix",
    "href": "posts/Improving_Factuality_in_Large_Language_Models_via_Decoding_Time_Hallucinatory_and_Truthful_Comparators/2024-08-22-Improving_Factuality_in_Large_Language_Models_via_Decoding_Time_Hallucinatory_and_Truthful_Comparators.html#appendix",
    "title": "Improving Factuality in Large Language Models via Decoding-Time Hallucinatory and Truthful Comparators",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12325v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12325v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7654"
  },
  {
    "objectID": "posts/Optimizing_Large_Language_Model_Hyperparameters_for_Code_Generation/2024-08-20-Optimizing_Large_Language_Model_Hyperparameters_for_Code_Generation.html",
    "href": "posts/Optimizing_Large_Language_Model_Hyperparameters_for_Code_Generation/2024-08-20-Optimizing_Large_Language_Model_Hyperparameters_for_Code_Generation.html",
    "title": "Optimizing Large Language Model Hyperparameters for Code Generation",
    "section": "",
    "text": "Summary:\nThe study “Optimizing Large Language Model Hyperparameters for Code Generation” by Chetan Arora et al. explores the impact of various hyperparameters on the performance of Large Language Models (LLMs) in code generation tasks. The authors focus on four specific hyperparameters: temperature, top probability (top p), frequency penalty, and presence penalty. They systematically adjust these hyperparameters and evaluate their effects across multiple code generation tasks to identify configurations that yield the best outcomes and those that should be avoided. The results indicate that optimal performance is achieved with a temperature below 0.5, top probability below 0.75, frequency penalty above -1 and below 1.5, and presence penalty above -1.\nMajor Findings:\nAnalysis and Critique:\nThe study provides valuable insights into the impact of hyperparameters on LLM performance in code generation tasks. However, there are some limitations and potential biases that should be considered. The study focuses on a specific model (GPT-3.5) and a specific programming language (Python), which may not generalize to other LLMs or programming languages. Additionally, the metrics used to evaluate the correctness and functionality of the generated code (passing the unit tests generated by the research team) might not capture all aspects of code quality, such as readability, maintainability, or efficiency.\nFurthermore, the study does not explore the impact of"
  },
  {
    "objectID": "posts/Optimizing_Large_Language_Model_Hyperparameters_for_Code_Generation/2024-08-20-Optimizing_Large_Language_Model_Hyperparameters_for_Code_Generation.html#appendix",
    "href": "posts/Optimizing_Large_Language_Model_Hyperparameters_for_Code_Generation/2024-08-20-Optimizing_Large_Language_Model_Hyperparameters_for_Code_Generation.html#appendix",
    "title": "Optimizing Large Language Model Hyperparameters for Code Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10577v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10577v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12627"
  },
  {
    "objectID": "posts/Generative_AI_for_Enhancing_Active_Learning_in_Education_A_Comparative_Study_of_GPT_3.5_and_GPT_4_in_Crafting_Customized_Test_Questions/2024-06-20-Generative_AI_for_Enhancing_Active_Learning_in_Education_A_Comparative_Study_of_GPT_3.5_and_GPT_4_in_Crafting_Customized_Test_Questions.html#appendix",
    "href": "posts/Generative_AI_for_Enhancing_Active_Learning_in_Education_A_Comparative_Study_of_GPT_3.5_and_GPT_4_in_Crafting_Customized_Test_Questions/2024-06-20-Generative_AI_for_Enhancing_Active_Learning_in_Education_A_Comparative_Study_of_GPT_3.5_and_GPT_4_in_Crafting_Customized_Test_Questions.html#appendix",
    "title": "Generative AI for Enhancing Active Learning in Education: A Comparative Study of GPT-3.5 and GPT-4 in Crafting Customized Test Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13903v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13903v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6168"
  },
  {
    "objectID": "posts/While_GitHub_Copilot_Excels_at_Coding_Does_It_Ensure_Responsible_Output/2024-08-20-While_GitHub_Copilot_Excels_at_Coding_Does_It_Ensure_Responsible_Output.html#appendix",
    "href": "posts/While_GitHub_Copilot_Excels_at_Coding_Does_It_Ensure_Responsible_Output/2024-08-20-While_GitHub_Copilot_Excels_at_Coding_Does_It_Ensure_Responsible_Output.html#appendix",
    "title": "While GitHub Copilot Excels at Coding, Does It Ensure Responsible Output?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11006v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11006v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7312"
  },
  {
    "objectID": "posts/By_My_Eyes_Grounding_Multimodal_Large_Language_Models_with_Sensor_Data_via_Visual_Prompting/2024-07-15-By_My_Eyes_Grounding_Multimodal_Large_Language_Models_with_Sensor_Data_via_Visual_Prompting.html#appendix",
    "href": "posts/By_My_Eyes_Grounding_Multimodal_Large_Language_Models_with_Sensor_Data_via_Visual_Prompting/2024-07-15-By_My_Eyes_Grounding_Multimodal_Large_Language_Models_with_Sensor_Data_via_Visual_Prompting.html#appendix",
    "title": "By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10385v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10385v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7689"
  },
  {
    "objectID": "posts/Advancing_Tool_Augmented_Large_Language_Models_Integrating_Insights_from_Errors_in_Inference_Trees/2024-06-11-Advancing_Tool_Augmented_Large_Language_Models_Integrating_Insights_from_Errors_in_Inference_Trees.html#appendix",
    "href": "posts/Advancing_Tool_Augmented_Large_Language_Models_Integrating_Insights_from_Errors_in_Inference_Trees/2024-06-11-Advancing_Tool_Augmented_Large_Language_Models_Integrating_Insights_from_Errors_in_Inference_Trees.html#appendix",
    "title": "Advancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07115v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07115v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6467"
  },
  {
    "objectID": "posts/CyberPal.AI_Empowering_LLMs_with_Expert_Driven_Cybersecurity_Instructions/2024-08-17-CyberPal.AI_Empowering_LLMs_with_Expert_Driven_Cybersecurity_Instructions.html#appendix",
    "href": "posts/CyberPal.AI_Empowering_LLMs_with_Expert_Driven_Cybersecurity_Instructions/2024-08-17-CyberPal.AI_Empowering_LLMs_with_Expert_Driven_Cybersecurity_Instructions.html#appendix",
    "title": "CyberPal.AI: Empowering LLMs with Expert-Driven Cybersecurity Instructions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09304v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09304v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12350"
  },
  {
    "objectID": "posts/MG_Verilog_Multi_grained_Dataset_Towards_Enhanced_LLM_assisted_Verilog_Generation/2024-07-03-MG_Verilog_Multi_grained_Dataset_Towards_Enhanced_LLM_assisted_Verilog_Generation.html#appendix",
    "href": "posts/MG_Verilog_Multi_grained_Dataset_Towards_Enhanced_LLM_assisted_Verilog_Generation/2024-07-03-MG_Verilog_Multi_grained_Dataset_Towards_Enhanced_LLM_assisted_Verilog_Generation.html#appendix",
    "title": "MG-Verilog: Multi-grained Dataset Towards Enhanced LLM-assisted Verilog Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01910v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01910v2\n\n\nTruncated\nFalse\n\n\nWord Count\n3899"
  },
  {
    "objectID": "posts/HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs/2024-06-10-HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs.html",
    "href": "posts/HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs/2024-06-10-HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs.html",
    "title": "HOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs",
    "section": "",
    "text": "Summary:\nThe paper introduces a new method called HOLMES for multi-hop question answering (MHQA) using large language models (LLMs). The method involves transforming unstructured text into a hyper-relational knowledge graph (KG) using a query-derived schema, which is then used as input to the LLM. The proposed method significantly improves upon the state-of-the-art (SoTA) multi-hop QA method, achieving 18.7% and 20% improvements in exact match (EM) scores on the Hotpot dataset and 26% and 14.3% on the MuSiQue dataset for GPT-3.5 and GPT-4, respectively. Additionally, the method uses up to 67% fewer tokens to represent query-relevant information than the current SoTA method and up to 60% fewer tokens compared to the original supporting documents.\nMajor Findings:\nAnalysis and Critique:\nThe proposed method, HOLMES, presents a significant improvement over the SoTA multi-hop QA method. The use of a hyper-relational KG as input to the LLM allows for a more efficient and effective representation of query-relevant information. The method’s ability to use fewer tokens to represent this information is particularly noteworthy, as it can lead to reduced computational costs and improved performance.\nHowever, there are some potential limitations and areas for further research. For example, the method’s reliance on a query-"
  },
  {
    "objectID": "posts/HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs/2024-06-10-HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs.html#appendix",
    "href": "posts/HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs/2024-06-10-HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs.html#appendix",
    "title": "HOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06027v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06027v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20470"
  },
  {
    "objectID": "posts/SWE_bench_java_A_GitHub_Issue_Resolving_Benchmark_for_Java/2024-08-26-SWE_bench_java_A_GitHub_Issue_Resolving_Benchmark_for_Java.html#appendix",
    "href": "posts/SWE_bench_java_A_GitHub_Issue_Resolving_Benchmark_for_Java/2024-08-26-SWE_bench_java_A_GitHub_Issue_Resolving_Benchmark_for_Java.html#appendix",
    "title": "SWE-bench-java: A GitHub Issue Resolving Benchmark for Java",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.14354v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.14354v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4964"
  },
  {
    "objectID": "posts/Enhancing_LLM_Based_Human_Robot_Interaction_with_Nuances_for_Diversity_Awareness/2024-06-25-Enhancing_LLM_Based_Human_Robot_Interaction_with_Nuances_for_Diversity_Awareness.html#appendix",
    "href": "posts/Enhancing_LLM_Based_Human_Robot_Interaction_with_Nuances_for_Diversity_Awareness/2024-06-25-Enhancing_LLM_Based_Human_Robot_Interaction_with_Nuances_for_Diversity_Awareness.html#appendix",
    "title": "Enhancing LLM-Based Human-Robot Interaction with Nuances for Diversity Awareness",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17531v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17531v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7209"
  },
  {
    "objectID": "posts/Learning_to_Refuse_Towards_Mitigating_Privacy_Risks_in_LLMs/2024-07-14-Learning_to_Refuse_Towards_Mitigating_Privacy_Risks_in_LLMs.html#appendix",
    "href": "posts/Learning_to_Refuse_Towards_Mitigating_Privacy_Risks_in_LLMs/2024-07-14-Learning_to_Refuse_Towards_Mitigating_Privacy_Risks_in_LLMs.html#appendix",
    "title": "Learning to Refuse: Towards Mitigating Privacy Risks in LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10058v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10058v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5969"
  },
  {
    "objectID": "posts/Investigating_LLMs_as_Voting_Assistants_via_Contextual_Augmentation_A_Case_Study_on_the_European_Parliament_Elections_2024/2024-07-11-Investigating_LLMs_as_Voting_Assistants_via_Contextual_Augmentation_A_Case_Study_on_the_European_Parliament_Elections_2024.html#appendix",
    "href": "posts/Investigating_LLMs_as_Voting_Assistants_via_Contextual_Augmentation_A_Case_Study_on_the_European_Parliament_Elections_2024/2024-07-11-Investigating_LLMs_as_Voting_Assistants_via_Contextual_Augmentation_A_Case_Study_on_the_European_Parliament_Elections_2024.html#appendix",
    "title": "Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08495v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08495v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5277"
  },
  {
    "objectID": "posts/Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination/2024-06-10-Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination.html",
    "href": "posts/Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination/2024-06-10-Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination.html",
    "title": "Enhancing Food Safety in Supply Chains: The Potential Role of Large Language Models in Preventing Campylobacter Contamination",
    "section": "",
    "text": "Summary:\nThis study explores the potential of large language models (LLMs), specifically generative pre-trained transformers (GPTs), to mitigate Campylobacter contamination across four typical stages of the food supply chain: primary production, food processing, distribution and retail, and preparation and consumption. The study also considers critical barriers to implementing GPTs at each step of the supply chain and proposes initial measures to overcome these obstacles.\nMajor Findings:\nAnalysis and Critique:\nThe study presents an intriguing potential for LLMs to enhance food safety, but the ‘LLM – food safety’ interface remains largely underexplored. The proposed applications of LLMs in this domain are promising, but they require further investigation and practical applications. The study also acknowledges that the adoption of LLMs in the food industry and agri-food supply chains may face several inhibiting factors, such as technological adoption, cultural barriers, data quality and availability, and technical challenges in integrating LLMs with existing food processing and slaughterhouse systems.\nTo alleviate these barriers and enable the deployment of LLMs for bacterial contamination reduction across food supply chains, a"
  },
  {
    "objectID": "posts/Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination/2024-06-10-Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination.html#appendix",
    "href": "posts/Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination/2024-06-10-Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination.html#appendix",
    "title": "Enhancing Food Safety in Supply Chains: The Potential Role of Large Language Models in Preventing Campylobacter Contamination",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06049v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06049v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18111"
  },
  {
    "objectID": "posts/Diversity_Empowers_Intelligence_Integrating_Expertise_of_Software_Engineering_Agents/2024-08-13-Diversity_Empowers_Intelligence_Integrating_Expertise_of_Software_Engineering_Agents.html#appendix",
    "href": "posts/Diversity_Empowers_Intelligence_Integrating_Expertise_of_Software_Engineering_Agents/2024-08-13-Diversity_Empowers_Intelligence_Integrating_Expertise_of_Software_Engineering_Agents.html#appendix",
    "title": "Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07060v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07060v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6727"
  },
  {
    "objectID": "posts/DocCGen_Document_based_Controlled_Code_Generation/2024-06-17-DocCGen_Document_based_Controlled_Code_Generation.html#appendix",
    "href": "posts/DocCGen_Document_based_Controlled_Code_Generation/2024-06-17-DocCGen_Document_based_Controlled_Code_Generation.html#appendix",
    "title": "DocCGen: Document-based Controlled Code Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11925v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11925v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9497"
  },
  {
    "objectID": "posts/Words_Matter_Reducing_Stigma_in_Online_Conversations_about_Substance_Use_with_Large_Language_Models/2024-08-15-Words_Matter_Reducing_Stigma_in_Online_Conversations_about_Substance_Use_with_Large_Language_Models.html#appendix",
    "href": "posts/Words_Matter_Reducing_Stigma_in_Online_Conversations_about_Substance_Use_with_Large_Language_Models/2024-08-15-Words_Matter_Reducing_Stigma_in_Online_Conversations_about_Substance_Use_with_Large_Language_Models.html#appendix",
    "title": "Words Matter: Reducing Stigma in Online Conversations about Substance Use with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07873v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07873v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8134"
  },
  {
    "objectID": "posts/Examining_the_Influence_of_Political_Bias_on_Large_Language_Model_Performance_in_Stance_Classification/2024-07-25-Examining_the_Influence_of_Political_Bias_on_Large_Language_Model_Performance_in_Stance_Classification.html#appendix",
    "href": "posts/Examining_the_Influence_of_Political_Bias_on_Large_Language_Model_Performance_in_Stance_Classification/2024-07-25-Examining_the_Influence_of_Political_Bias_on_Large_Language_Model_Performance_in_Stance_Classification.html#appendix",
    "title": "Examining the Influence of Political Bias on Large Language Model Performance in Stance Classification",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17688v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17688v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7443"
  },
  {
    "objectID": "posts/MaxMind_A_Memory_Loop_Network_to_Enhance_Software_Productivity_based_on_Large_Language_Models/2024-08-07-MaxMind_A_Memory_Loop_Network_to_Enhance_Software_Productivity_based_on_Large_Language_Models.html#appendix",
    "href": "posts/MaxMind_A_Memory_Loop_Network_to_Enhance_Software_Productivity_based_on_Large_Language_Models/2024-08-07-MaxMind_A_Memory_Loop_Network_to_Enhance_Software_Productivity_based_on_Large_Language_Models.html#appendix",
    "title": "MaxMind: A Memory Loop Network to Enhance Software Productivity based on Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03841v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03841v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6889"
  },
  {
    "objectID": "posts/Transformers_and_Large_Language_Models_for_Efficient_Intrusion_Detection_Systems_A_Comprehensive_Survey/2024-08-14-Transformers_and_Large_Language_Models_for_Efficient_Intrusion_Detection_Systems_A_Comprehensive_Survey.html",
    "href": "posts/Transformers_and_Large_Language_Models_for_Efficient_Intrusion_Detection_Systems_A_Comprehensive_Survey/2024-08-14-Transformers_and_Large_Language_Models_for_Efficient_Intrusion_Detection_Systems_A_Comprehensive_Survey.html",
    "title": "Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey",
    "section": "",
    "text": "Summary:\nThis paper provides a comprehensive survey of the utilization of Transformers and Large Language Models (LLMs) in cyber-threat detection systems. The methodology of paper selection and bibliometric analysis is outlined to establish a rigorous framework for evaluating existing research. The fundamentals of Transformers are discussed, including various cyber-attacks and datasets commonly used in this field. The survey explores the application of Transformers in intrusion detection systems (IDSs), focusing on different architectures such as Attention-based models, LLMs like BERT and GPT, CNN/LSTM-Transformer hybrids, and emerging approaches like Vision Transformers (ViTs). The survey also explores the diverse environments and applications where Transformers and LLMs-based IDS have been implemented, including computer networks, IoT devices, critical infrastructure protection, cloud computing, software-defined networking (SDN), and autonomous vehicles (AVs). The paper concludes by summarizing the findings and highlighting the significance of Transformers and LLMs in enhancing cyber-threat detection capabilities, while also outlining potential avenues for further research and development.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive survey of the utilization of Transformers and LLMs in cyber-threat detection systems. The methodology of paper selection and bibliometric analysis is well-structured and rigorous, providing a solid foundation for evaluating existing research. The survey covers a wide range of Transformer-"
  },
  {
    "objectID": "posts/Transformers_and_Large_Language_Models_for_Efficient_Intrusion_Detection_Systems_A_Comprehensive_Survey/2024-08-14-Transformers_and_Large_Language_Models_for_Efficient_Intrusion_Detection_Systems_A_Comprehensive_Survey.html#appendix",
    "href": "posts/Transformers_and_Large_Language_Models_for_Efficient_Intrusion_Detection_Systems_A_Comprehensive_Survey/2024-08-14-Transformers_and_Large_Language_Models_for_Efficient_Intrusion_Detection_Systems_A_Comprehensive_Survey.html#appendix",
    "title": "Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07583v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07583v1\n\n\nTruncated\nFalse\n\n\nWord Count\n22281"
  },
  {
    "objectID": "posts/FACTS_About_Building_Retrieval_Augmented_Generation_based_Chatbots/2024-07-10-FACTS_About_Building_Retrieval_Augmented_Generation_based_Chatbots.html#appendix",
    "href": "posts/FACTS_About_Building_Retrieval_Augmented_Generation_based_Chatbots/2024-07-10-FACTS_About_Building_Retrieval_Augmented_Generation_based_Chatbots.html#appendix",
    "title": "FACTS About Building Retrieval Augmented Generation-based Chatbots",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07858v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07858v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5997"
  },
  {
    "objectID": "posts/VideoLLaMA_2_Advancing_Spatial_Temporal_Modeling_and_Audio_Understanding_in_Video_LLMs/2024-06-11-VideoLLaMA_2_Advancing_Spatial_Temporal_Modeling_and_Audio_Understanding_in_Video_LLMs.html#appendix",
    "href": "posts/VideoLLaMA_2_Advancing_Spatial_Temporal_Modeling_and_Audio_Understanding_in_Video_LLMs/2024-06-11-VideoLLaMA_2_Advancing_Spatial_Temporal_Modeling_and_Audio_Understanding_in_Video_LLMs.html#appendix",
    "title": "VideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understanding in Video-LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07476v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07476v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5170"
  },
  {
    "objectID": "posts/UniGen_A_Unified_Framework_for_Textual_Dataset_Generation_Using_Large_Language_Models/2024-06-27-UniGen_A_Unified_Framework_for_Textual_Dataset_Generation_Using_Large_Language_Models.html#appendix",
    "href": "posts/UniGen_A_Unified_Framework_for_Textual_Dataset_Generation_Using_Large_Language_Models/2024-06-27-UniGen_A_Unified_Framework_for_Textual_Dataset_Generation_Using_Large_Language_Models.html#appendix",
    "title": "UniGen: A Unified Framework for Textual Dataset Generation Using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18966v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18966v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5825"
  },
  {
    "objectID": "posts/Claim_Verification_in_the_Age_of_Large_Language_Models_A_Survey/2024-08-26-Claim_Verification_in_the_Age_of_Large_Language_Models_A_Survey.html#major-findings",
    "href": "posts/Claim_Verification_in_the_Age_of_Large_Language_Models_A_Survey/2024-08-26-Claim_Verification_in_the_Age_of_Large_Language_Models_A_Survey.html#major-findings",
    "title": "Claim Verification in the Age of Large Language Models: A Survey",
    "section": "Major Findings",
    "text": "Major Findings\n\nLLMs have been successful in claim verification, but they are prone to hallucinations and can generate incorrect information.\nRetrieval Augmented Generation (RAG) is a novel method used in claim verification to aid LLMs in their decision-making abilities.\nLLMs can be used to generate misinformation at scale, which can be exploited by malicious actors to spread wrong and factually incorrect information.\nLLMs can generate incorrect veracity labels, as they may rely on obsolete information to assess the veracity of a claim.\nSeveral English datasets have been created for claim verification, but there is a lack of multilingual fact-verification datasets."
  },
  {
    "objectID": "posts/Claim_Verification_in_the_Age_of_Large_Language_Models_A_Survey/2024-08-26-Claim_Verification_in_the_Age_of_Large_Language_Models_A_Survey.html#analysis-and-critique",
    "href": "posts/Claim_Verification_in_the_Age_of_Large_Language_Models_A_Survey/2024-08-26-Claim_Verification_in_the_Age_of_Large_Language_Models_A_Survey.html#analysis-and-critique",
    "title": "Claim Verification in the Age of Large Language Models: A Survey",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\n\nThe survey provides a comprehensive account of recent claim verification frameworks using LLMs, but it does not discuss the limitations and potential biases of these models.\nThe survey does not discuss the methodological issues and conflicting evidence in the use of LLMs for claim verification.\nThe survey does not provide a critical evaluation of the performance of LLMs in claim verification compared to traditional NLP-based models.\nThe survey does not discuss the potential risks and ethical implications of using LLMs for claim verification.\nThe survey does not provide a detailed analysis of the performance of LLMs in handling complex and long claims.\nThe survey does not discuss the potential applications of LLMs in claim verification beyond text-based data.\nThe survey does not discuss the potential impact of LLMs on the labor market and the future of fact-checking.\nThe survey does not discuss the potential impact of LLMs on the spread of misinformation and the role of fact-checking organizations in the age of LLMs.\nThe survey does not discuss the potential impact of LLMs on the development of new fact-checking"
  },
  {
    "objectID": "posts/Claim_Verification_in_the_Age_of_Large_Language_Models_A_Survey/2024-08-26-Claim_Verification_in_the_Age_of_Large_Language_Models_A_Survey.html#appendix",
    "href": "posts/Claim_Verification_in_the_Age_of_Large_Language_Models_A_Survey/2024-08-26-Claim_Verification_in_the_Age_of_Large_Language_Models_A_Survey.html#appendix",
    "title": "Claim Verification in the Age of Large Language Models: A Survey",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.14317v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.14317v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7510"
  },
  {
    "objectID": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#major-findings",
    "href": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#major-findings",
    "title": "Teaching Language Models to Self-Improve by Learning from Language Feedback",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nSRT significantly outperforms strong baselines across diverse tasks and model sizes, with an average performance enhancement of 3.7 to 4.0 points.\nWhen applied to a 70B parameter model, SRT increases the win rate from 9.6% to 25.8% on the AlpacaEval 2.0 benchmark, surpassing well-established systems such as GPT-4-0314, Claude 2, and Gemini.\nThe success of SRT primarily stems from its language feedback feature, which identifies weak areas and offers valuable suggestions for improvement."
  },
  {
    "objectID": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#analysis-and-critique",
    "href": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#analysis-and-critique",
    "title": "Teaching Language Models to Self-Improve by Learning from Language Feedback",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper presents a novel and promising approach to aligning language models using self-refinement and language feedback.\nThe empirical evaluations demonstrate the effectiveness of SRT in improving model performance across various tasks and model sizes.\nThe paper highlights the crucial role of language feedback in the success of SRT, suggesting potential for further exploration in this direction.\nHowever, the paper does not discuss potential limitations or challenges associated with the SRT method, such as the computational cost of generating feedback and refinements or the potential for overfitting to the feedback.\nAdditionally, the paper does not address the potential for biases in the feedback and refinements generated by the more advanced model, which could impact the alignment of the base model.\nFuture work could explore these limitations and potential solutions to improve the SRT method."
  },
  {
    "objectID": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#appendix",
    "href": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#appendix",
    "title": "Teaching Language Models to Self-Improve by Learning from Language Feedback",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07168v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07168v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6361"
  },
  {
    "objectID": "posts/AdaCoder_Adaptive_Prompt_Compression_for_Programmatic_Visual_Question_Answering/2024-07-28-AdaCoder_Adaptive_Prompt_Compression_for_Programmatic_Visual_Question_Answering.html#appendix",
    "href": "posts/AdaCoder_Adaptive_Prompt_Compression_for_Programmatic_Visual_Question_Answering/2024-07-28-AdaCoder_Adaptive_Prompt_Compression_for_Programmatic_Visual_Question_Answering.html#appendix",
    "title": "AdaCoder: Adaptive Prompt Compression for Programmatic Visual Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19410v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19410v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6971"
  },
  {
    "objectID": "posts/Self_assessment_Exhibition_and_Recognition_a_Review_of_Personality_in_Large_Language_Models/2024-06-25-Self_assessment_Exhibition_and_Recognition_a_Review_of_Personality_in_Large_Language_Models.html#appendix",
    "href": "posts/Self_assessment_Exhibition_and_Recognition_a_Review_of_Personality_in_Large_Language_Models/2024-06-25-Self_assessment_Exhibition_and_Recognition_a_Review_of_Personality_in_Large_Language_Models.html#appendix",
    "title": "Self-assessment, Exhibition, and Recognition: a Review of Personality in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17624v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17624v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9841"
  },
  {
    "objectID": "posts/Large_Language_Models_Memorize_Sensor_Datasets!_Implications_on_Human_Activity_Recognition_Research/2024-06-09-Large_Language_Models_Memorize_Sensor_Datasets!_Implications_on_Human_Activity_Recognition_Research.html#appendix",
    "href": "posts/Large_Language_Models_Memorize_Sensor_Datasets!_Implications_on_Human_Activity_Recognition_Research/2024-06-09-Large_Language_Models_Memorize_Sensor_Datasets!_Implications_on_Human_Activity_Recognition_Research.html#appendix",
    "title": "Large Language Models Memorize Sensor Datasets! Implications on Human Activity Recognition Research",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05900v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05900v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6787"
  },
  {
    "objectID": "posts/Improving_Entity_Recognition_Using_Ensembles_of_Deep_Learning_and_Fine_tuned_Large_Language_Models_A_Case_Study_on_Adverse_Event_Extraction_from_Multiple_Sources/2024-06-26-Improving_Entity_Recognition_Using_Ensembles_of_Deep_Learning_and_Fine_tuned_Large_Language_Models_A_Case_Study_on_Adverse_Event_Extraction_from_Multiple_Sources.html",
    "href": "posts/Improving_Entity_Recognition_Using_Ensembles_of_Deep_Learning_and_Fine_tuned_Large_Language_Models_A_Case_Study_on_Adverse_Event_Extraction_from_Multiple_Sources/2024-06-26-Improving_Entity_Recognition_Using_Ensembles_of_Deep_Learning_and_Fine_tuned_Large_Language_Models_A_Case_Study_on_Adverse_Event_Extraction_from_Multiple_Sources.html",
    "title": "Improving Entity Recognition Using Ensembles of Deep Learning and Fine-tuned Large Language Models: A Case Study on Adverse Event Extraction from Multiple Sources",
    "section": "",
    "text": "Summary:\nThis study evaluates the effectiveness of large language models (LLMs) and traditional deep learning models in adverse event (AE) extraction following COVID-19 vaccines. The authors utilized reports and posts from the Vaccine Adverse Event Reporting System (VAERS), Twitter, and Reddit as their corpora. Their goal was to extract three types of entities: vaccine, shot, and adverse event (ae). They explored and fine-tuned multiple LLMs, including GPT-2, GPT-3.5, GPT-4, Llama-2 7b, and Llama-2 13b, as well as traditional deep learning models like Recurrent Neural Network (RNN) and Bidirectional Encoder Representations from Transformers for Biomedical Text Mining (BioBERT). To enhance performance, they created ensembles of the three models with the best performance. The ensemble model achieved the highest performance in “vaccine,” “shot,” and “ae,” with strict F1-scores of 0.878, 0.930, and 0.925, respectively, along with a micro-average score of 0.903. These results underscore the significance of fine-tuning models for specific tasks and demonstrate the effectiveness of ensemble methods in enhancing performance.\nMajor Findings:\nAnalysis and Critique:\nThe study demonstrates the effectiveness and robustness of ensembling fine-tuned traditional deep learning models and LLMs for extracting AE-related information following COVID-19 vaccination. However, the authors acknowledge that the corpora"
  },
  {
    "objectID": "posts/Improving_Entity_Recognition_Using_Ensembles_of_Deep_Learning_and_Fine_tuned_Large_Language_Models_A_Case_Study_on_Adverse_Event_Extraction_from_Multiple_Sources/2024-06-26-Improving_Entity_Recognition_Using_Ensembles_of_Deep_Learning_and_Fine_tuned_Large_Language_Models_A_Case_Study_on_Adverse_Event_Extraction_from_Multiple_Sources.html#appendix",
    "href": "posts/Improving_Entity_Recognition_Using_Ensembles_of_Deep_Learning_and_Fine_tuned_Large_Language_Models_A_Case_Study_on_Adverse_Event_Extraction_from_Multiple_Sources/2024-06-26-Improving_Entity_Recognition_Using_Ensembles_of_Deep_Learning_and_Fine_tuned_Large_Language_Models_A_Case_Study_on_Adverse_Event_Extraction_from_Multiple_Sources.html#appendix",
    "title": "Improving Entity Recognition Using Ensembles of Deep Learning and Fine-tuned Large Language Models: A Case Study on Adverse Event Extraction from Multiple Sources",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18049v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18049v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13358"
  },
  {
    "objectID": "posts/Ask_LLMs_Directly_What_shapes_your_bias_Measuring_Social_Bias_in_Large_Language_Models/2024-06-06-Ask_LLMs_Directly_What_shapes_your_bias_Measuring_Social_Bias_in_Large_Language_Models.html#appendix",
    "href": "posts/Ask_LLMs_Directly_What_shapes_your_bias_Measuring_Social_Bias_in_Large_Language_Models/2024-06-06-Ask_LLMs_Directly_What_shapes_your_bias_Measuring_Social_Bias_in_Large_Language_Models.html#appendix",
    "title": "Ask LLMs Directly, What shapes your bias?: Measuring Social Bias in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04064v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04064v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5188"
  },
  {
    "objectID": "posts/Skywork_Math_Data_Scaling_Laws_for_Mathematical_Reasoning_in_Large_Language_Models____The_Story_Goes_On/2024-07-11-Skywork_Math_Data_Scaling_Laws_for_Mathematical_Reasoning_in_Large_Language_Models____The_Story_Goes_On.html#appendix",
    "href": "posts/Skywork_Math_Data_Scaling_Laws_for_Mathematical_Reasoning_in_Large_Language_Models____The_Story_Goes_On/2024-07-11-Skywork_Math_Data_Scaling_Laws_for_Mathematical_Reasoning_in_Large_Language_Models____The_Story_Goes_On.html#appendix",
    "title": "Skywork-Math: Data Scaling Laws for Mathematical Reasoning in Large Language Models – The Story Goes On",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08348v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08348v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12177"
  },
  {
    "objectID": "posts/Open_LLM_Leaderboard_From_Multi_choice_to_Open_style_Questions_for_LLMs_Evaluation_Benchmark_and_Arena/2024-06-11-Open_LLM_Leaderboard_From_Multi_choice_to_Open_style_Questions_for_LLMs_Evaluation_Benchmark_and_Arena.html#appendix",
    "href": "posts/Open_LLM_Leaderboard_From_Multi_choice_to_Open_style_Questions_for_LLMs_Evaluation_Benchmark_and_Arena/2024-06-11-Open_LLM_Leaderboard_From_Multi_choice_to_Open_style_Questions_for_LLMs_Evaluation_Benchmark_and_Arena.html#appendix",
    "title": "Open-LLM-Leaderboard: From Multi-choice to Open-style Questions for LLMs Evaluation, Benchmark, and Arena",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07545v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07545v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5687"
  },
  {
    "objectID": "posts/T_FREE_Tokenizer_Free_Generative_LLMs_via_Sparse_Representations_for_Memory_Efficient_Embeddings/2024-06-27-T_FREE_Tokenizer_Free_Generative_LLMs_via_Sparse_Representations_for_Memory_Efficient_Embeddings.html#appendix",
    "href": "posts/T_FREE_Tokenizer_Free_Generative_LLMs_via_Sparse_Representations_for_Memory_Efficient_Embeddings/2024-06-27-T_FREE_Tokenizer_Free_Generative_LLMs_via_Sparse_Representations_for_Memory_Efficient_Embeddings.html#appendix",
    "title": "T-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19223v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19223v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8998"
  },
  {
    "objectID": "posts/Coherent_Zero_Shot_Visual_Instruction_Generation/2024-06-06-Coherent_Zero_Shot_Visual_Instruction_Generation.html#appendix",
    "href": "posts/Coherent_Zero_Shot_Visual_Instruction_Generation/2024-06-06-Coherent_Zero_Shot_Visual_Instruction_Generation.html#appendix",
    "title": "Coherent Zero-Shot Visual Instruction Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04337v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04337v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5054"
  },
  {
    "objectID": "posts/Using_Large_Language_Models_for_Generating_Smart_Contracts_for_Health_Insurance_from_Textual_Policies/2024-07-09-Using_Large_Language_Models_for_Generating_Smart_Contracts_for_Health_Insurance_from_Textual_Policies.html#appendix",
    "href": "posts/Using_Large_Language_Models_for_Generating_Smart_Contracts_for_Health_Insurance_from_Textual_Policies/2024-07-09-Using_Large_Language_Models_for_Generating_Smart_Contracts_for_Health_Insurance_from_Textual_Policies.html#appendix",
    "title": "Using Large Language Models for Generating Smart Contracts for Health Insurance from Textual Policies",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07019v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07019v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11200"
  },
  {
    "objectID": "posts/Search_Based_LLMs_for_Code_Optimization/2024-08-22-Search_Based_LLMs_for_Code_Optimization.html#appendix",
    "href": "posts/Search_Based_LLMs_for_Code_Optimization/2024-08-22-Search_Based_LLMs_for_Code_Optimization.html#appendix",
    "title": "Search-Based LLMs for Code Optimization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12159v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12159v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9347"
  },
  {
    "objectID": "posts/Beyond_Correctness_Benchmarking_Multi_dimensional_Code_Generation_for_Large_Language_Models/2024-07-16-Beyond_Correctness_Benchmarking_Multi_dimensional_Code_Generation_for_Large_Language_Models.html#major-findings",
    "href": "posts/Beyond_Correctness_Benchmarking_Multi_dimensional_Code_Generation_for_Large_Language_Models/2024-07-16-Beyond_Correctness_Benchmarking_Multi_dimensional_Code_Generation_for_Large_Language_Models.html#major-findings",
    "title": "Beyond Correctness: Benchmarking Multi-dimensional Code Generation for Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nCurrent LLMs’ ability to generate high-quality code on demand does not yet meet the requirements of software development.\nReadability serves as a critical indicator of the overall quality of generated code.\nMost LLMs exhibit an inherent preference for specific coding styles, making it difficult for them to follow user instructions that are inconsistent with their preference."
  },
  {
    "objectID": "posts/Beyond_Correctness_Benchmarking_Multi_dimensional_Code_Generation_for_Large_Language_Models/2024-07-16-Beyond_Correctness_Benchmarking_Multi_dimensional_Code_Generation_for_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/Beyond_Correctness_Benchmarking_Multi_dimensional_Code_Generation_for_Large_Language_Models/2024-07-16-Beyond_Correctness_Benchmarking_Multi_dimensional_Code_Generation_for_Large_Language_Models.html#analysis-and-critique",
    "title": "Beyond Correctness: Benchmarking Multi-dimensional Code Generation for Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe RACE benchmark provides a valuable contribution to the evaluation of code generated by LLMs, addressing the limitations of existing benchmarks that primarily focus on code correctness. However, the benchmark could be expanded to include additional dimensions, such as security, testability, and dynamic behavior. Additionally, the experiments have only been conducted on Python code data, and future work should consider expanding to multilingual code to explore differences in model preferences across languages.\nThe findings highlight the need for further improvement in the ability of LLMs to generate high-quality code across multiple dimensions based on user demands. The inherent preference bias of LLMs for specific coding styles can lead to the ossification of code style and hinder their ability to meet specific real-world project requirements. Future efforts should focus on improving the ability of LLMs to meet real-world requirements and explore deeper factors influencing generated code quality.\nIn conclusion, the RACE benchmark provides a valuable tool for evaluating the quality of code generated by LLMs and highlights the need for further improvement in this area. The findings of this study can help researchers gain a deeper understanding of the coding capabilities of current LLMs and guide future directions for model improvement."
  },
  {
    "objectID": "posts/Beyond_Correctness_Benchmarking_Multi_dimensional_Code_Generation_for_Large_Language_Models/2024-07-16-Beyond_Correctness_Benchmarking_Multi_dimensional_Code_Generation_for_Large_Language_Models.html#appendix",
    "href": "posts/Beyond_Correctness_Benchmarking_Multi_dimensional_Code_Generation_for_Large_Language_Models/2024-07-16-Beyond_Correctness_Benchmarking_Multi_dimensional_Code_Generation_for_Large_Language_Models.html#appendix",
    "title": "Beyond Correctness: Benchmarking Multi-dimensional Code Generation for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.11470v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.11470v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6582"
  },
  {
    "objectID": "posts/Enhancing_Agricultural_Machinery_Management_through_Advanced_LLM_Integration/2024-07-30-Enhancing_Agricultural_Machinery_Management_through_Advanced_LLM_Integration.html#appendix",
    "href": "posts/Enhancing_Agricultural_Machinery_Management_through_Advanced_LLM_Integration/2024-07-30-Enhancing_Agricultural_Machinery_Management_through_Advanced_LLM_Integration.html#appendix",
    "title": "Enhancing Agricultural Machinery Management through Advanced LLM Integration",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20588v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20588v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3115"
  },
  {
    "objectID": "posts/Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing/2024-06-20-Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing.html",
    "href": "posts/Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing/2024-06-20-Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing.html",
    "title": "Raising the Bar: Investigating the Values of Large Language Models via Generative Evolving Testing",
    "section": "",
    "text": "Summary:\nThe paper proposes a novel framework called GETA (Generative Evolving Testing of vAlues) to address the evaluation chronoeffect problem in assessing the value alignment of Large Language Models (LLMs). GETA incorporates an iteratively-updated item generator that infers each LLM’s moral boundaries and generates difficulty-tailored testing items, accurately reflecting the true alignment extent. This process theoretically learns a joint distribution of item and model response, with item difficulty and value conformity as latent variables. The generator co-evolves with the LLM, addressing the chronoeffect. The paper evaluates various popular LLMs and demonstrates that GETA can create difficulty-matching testing items and more accurately assess LLMs’ values, better consistent with their performance on unseen OOD and i.i.d. items.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a promising approach to address the evaluation chronoeffect problem in assessing the value alignment of LLMs. However, there are some potential limitations and areas for further research:\nOverall, the paper presents an innovative approach to address a significant challenge in evaluating LLMs, and further research is needed to fully understand its"
  },
  {
    "objectID": "posts/Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing/2024-06-20-Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing.html#appendix",
    "href": "posts/Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing/2024-06-20-Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing.html#appendix",
    "title": "Raising the Bar: Investigating the Values of Large Language Models via Generative Evolving Testing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14230v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14230v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11743"
  },
  {
    "objectID": "posts/Enhancing_Retrieval_and_Managing_Retrieval_A_Four_Module_Synergy_for_Improved_Quality_and_Efficiency_in_RAG_Systems/2024-07-15-Enhancing_Retrieval_and_Managing_Retrieval_A_Four_Module_Synergy_for_Improved_Quality_and_Efficiency_in_RAG_Systems.html",
    "href": "posts/Enhancing_Retrieval_and_Managing_Retrieval_A_Four_Module_Synergy_for_Improved_Quality_and_Efficiency_in_RAG_Systems/2024-07-15-Enhancing_Retrieval_and_Managing_Retrieval_A_Four_Module_Synergy_for_Improved_Quality_and_Efficiency_in_RAG_Systems.html",
    "title": "Enhancing Retrieval and Managing Retrieval: A Four-Module Synergy for Improved Quality and Efficiency in RAG Systems",
    "section": "",
    "text": "Summary:\nThe paper introduces a four-module strategy to enhance Retrieval-Augmented Generation (RAG) systems, which leverage the in-context learning capabilities of large language models (LLMs) to produce more accurate and relevant responses. The proposed modules are:\nThe effectiveness of these modules has been validated through experiments and ablation studies across six common QA datasets.\nMajor Findings:\nAnalysis and Critique:\nWhile the proposed modules show promise in improving the accuracy and efficiency of RAG systems, there are potential limitations and areas for further research. For instance, the effectiveness of the modules may vary depending on the specific LLM and knowledge base used. Additionally, the scalability of the modules to handle large-scale knowledge bases and complex queries needs to be further investigated. Furthermore, the potential for bias in the generated queries and the impact on the fairness and diversity of the retrieved information should be considered."
  },
  {
    "objectID": "posts/Enhancing_Retrieval_and_Managing_Retrieval_A_Four_Module_Synergy_for_Improved_Quality_and_Efficiency_in_RAG_Systems/2024-07-15-Enhancing_Retrieval_and_Managing_Retrieval_A_Four_Module_Synergy_for_Improved_Quality_and_Efficiency_in_RAG_Systems.html#appendix",
    "href": "posts/Enhancing_Retrieval_and_Managing_Retrieval_A_Four_Module_Synergy_for_Improved_Quality_and_Efficiency_in_RAG_Systems/2024-07-15-Enhancing_Retrieval_and_Managing_Retrieval_A_Four_Module_Synergy_for_Improved_Quality_and_Efficiency_in_RAG_Systems.html#appendix",
    "title": "Enhancing Retrieval and Managing Retrieval: A Four-Module Synergy for Improved Quality and Efficiency in RAG Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10670v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10670v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6915"
  },
  {
    "objectID": "posts/LLM_for_X_Application_agnostic_Integration_of_Large_Language_Models_to_Support_Personal_Writing_Workflows/2024-07-31-LLM_for_X_Application_agnostic_Integration_of_Large_Language_Models_to_Support_Personal_Writing_Workflows.html#appendix",
    "href": "posts/LLM_for_X_Application_agnostic_Integration_of_Large_Language_Models_to_Support_Personal_Writing_Workflows/2024-07-31-LLM_for_X_Application_agnostic_Integration_of_Large_Language_Models_to_Support_Personal_Writing_Workflows.html#appendix",
    "title": "LLM-for-X: Application-agnostic Integration of Large Language Models to Support Personal Writing Workflows",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21593v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21593v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8464"
  },
  {
    "objectID": "posts/Artificial_Agency_and_Large_Language_Models/2024-07-24-Artificial_Agency_and_Large_Language_Models.html#major-findings",
    "href": "posts/Artificial_Agency_and_Large_Language_Models/2024-07-24-Artificial_Agency_and_Large_Language_Models.html#major-findings",
    "title": "Artificial Agency and Large Language Models",
    "section": "Major Findings",
    "text": "Major Findings\n\nThe paper proposes a theoretical model for artificial agents that is based on a dynamic framework of factors, including the agent’s accessible history, its adaptive repertoire, and its external environment.\nThe paper argues that current state-of-the-art Large Language Models (LLMs) are not agents yet, but that there are elements to them that suggest a way forward.\nThe paper suggests that a combination of the agent architecture presented in Park et al. (2023) and the use of modules like the Coscientist in Boiko et al. (2023) could potentially be a way to realize agency in an artificial manner."
  },
  {
    "objectID": "posts/Artificial_Agency_and_Large_Language_Models/2024-07-24-Artificial_Agency_and_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/Artificial_Agency_and_Large_Language_Models/2024-07-24-Artificial_Agency_and_Large_Language_Models.html#analysis-and-critique",
    "title": "Artificial Agency and Large Language Models",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\nThe paper provides a valuable contribution to the philosophical debates surrounding the possibility of realizing agency in an artificial manner. The proposed theoretical model for artificial agents is well-structured and provides a clear framework for understanding the factors that influence an agent’s actions and goals. However, the paper does not provide a detailed analysis of the limitations and potential biases of the proposed model. Additionally, the paper does not discuss the potential ethical implications of realizing agency in an artificial manner. Further research is needed to address these issues and to evaluate the feasibility of the proposed approach."
  },
  {
    "objectID": "posts/Artificial_Agency_and_Large_Language_Models/2024-07-24-Artificial_Agency_and_Large_Language_Models.html#appendix",
    "href": "posts/Artificial_Agency_and_Large_Language_Models/2024-07-24-Artificial_Agency_and_Large_Language_Models.html#appendix",
    "title": "Artificial Agency and Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16190v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16190v2\n\n\nTruncated\nFalse\n\n\nWord Count\n16895"
  },
  {
    "objectID": "posts/Biomedical_Large_Languages_Models_Seem_not_to_be_Superior_to_Generalist_Models_on_Unseen_Medical_Data/2024-08-25-Biomedical_Large_Languages_Models_Seem_not_to_be_Superior_to_Generalist_Models_on_Unseen_Medical_Data.html#appendix",
    "href": "posts/Biomedical_Large_Languages_Models_Seem_not_to_be_Superior_to_Generalist_Models_on_Unseen_Medical_Data/2024-08-25-Biomedical_Large_Languages_Models_Seem_not_to_be_Superior_to_Generalist_Models_on_Unseen_Medical_Data.html#appendix",
    "title": "Biomedical Large Languages Models Seem not to be Superior to Generalist Models on Unseen Medical Data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.13833v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.13833v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5104"
  },
  {
    "objectID": "posts/StackRAG_Agent_Improving_Developer_Answers_with_Retrieval_Augmented_Generation/2024-06-19-StackRAG_Agent_Improving_Developer_Answers_with_Retrieval_Augmented_Generation.html#appendix",
    "href": "posts/StackRAG_Agent_Improving_Developer_Answers_with_Retrieval_Augmented_Generation/2024-06-19-StackRAG_Agent_Improving_Developer_Answers_with_Retrieval_Augmented_Generation.html#appendix",
    "title": "StackRAG Agent: Improving Developer Answers with Retrieval-Augmented Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13840v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13840v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4732"
  },
  {
    "objectID": "posts/A_Generic_Review_of_Integrating_Artificial_Intelligence_in_Cognitive_Behavioral_Therapy/2024-07-28-A_Generic_Review_of_Integrating_Artificial_Intelligence_in_Cognitive_Behavioral_Therapy.html",
    "href": "posts/A_Generic_Review_of_Integrating_Artificial_Intelligence_in_Cognitive_Behavioral_Therapy/2024-07-28-A_Generic_Review_of_Integrating_Artificial_Intelligence_in_Cognitive_Behavioral_Therapy.html",
    "title": "A Generic Review of Integrating Artificial Intelligence in Cognitive Behavioral Therapy",
    "section": "",
    "text": "Summary:\nCognitive Behavioral Therapy (CBT) is a widely recognized psychological intervention for addressing various mental health issues. However, the delivery of CBT faces barriers such as limited access to qualified therapists and lack of personalized interventions. Recent advancements in artificial intelligence (AI) have provided technical support for the digital transformation of CBT, with the emergence of pre-training models (PTMs) and large language models (LLMs) holding immense potential to support, augment, optimize, and automate CBT delivery.\nMajor Findings:\nAnalysis and Critique:\nWhile AI has shown promise in enhancing CBT delivery, there are several limitations and challenges that need to be addressed. These include the lack of publicly available structured datasets specifically designed for detecting cognitive distortions, the need for more comprehensive models capable of simultaneously diagnosing multiple co-occurring psychological conditions, and the challenge of making AI responses more conversational and human-like to address the perception that individuals may perceive AI-driven support as lacking genuine emotional resonance compared to human interaction. Additionally, human cross-validation is required to ensure rigor and utility in real clinical settings.\nFurthermore, there is a need for more flexible and adaptive forms of CBT to better meet the diverse needs of different patient populations. This can be achieved by exploring the use of AI in various stages of the CBT treatment process, such as pre-treatment, therapeutic process, and post-treatment. Future research should focus on addressing these challenges and exploring the potential of AI in enhancing the effectiveness and accessibility of CBT."
  },
  {
    "objectID": "posts/A_Generic_Review_of_Integrating_Artificial_Intelligence_in_Cognitive_Behavioral_Therapy/2024-07-28-A_Generic_Review_of_Integrating_Artificial_Intelligence_in_Cognitive_Behavioral_Therapy.html#appendix",
    "href": "posts/A_Generic_Review_of_Integrating_Artificial_Intelligence_in_Cognitive_Behavioral_Therapy/2024-07-28-A_Generic_Review_of_Integrating_Artificial_Intelligence_in_Cognitive_Behavioral_Therapy.html#appendix",
    "title": "A Generic Review of Integrating Artificial Intelligence in Cognitive Behavioral Therapy",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19422v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19422v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12709"
  },
  {
    "objectID": "posts/Towards_an_Analysis_of_Discourse_and_Interactional_Pragmatic_Reasoning_Capabilities_of_Large_Language_Models/2024-08-06-Towards_an_Analysis_of_Discourse_and_Interactional_Pragmatic_Reasoning_Capabilities_of_Large_Language_Models.html#appendix",
    "href": "posts/Towards_an_Analysis_of_Discourse_and_Interactional_Pragmatic_Reasoning_Capabilities_of_Large_Language_Models/2024-08-06-Towards_an_Analysis_of_Discourse_and_Interactional_Pragmatic_Reasoning_Capabilities_of_Large_Language_Models.html#appendix",
    "title": "Towards an Analysis of Discourse and Interactional Pragmatic Reasoning Capabilities of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03074v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03074v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2006"
  },
  {
    "objectID": "posts/Interactive_DualChecker_for_Mitigating_Hallucinations_in_Distilling_Large_Language_Models/2024-08-22-Interactive_DualChecker_for_Mitigating_Hallucinations_in_Distilling_Large_Language_Models.html#appendix",
    "href": "posts/Interactive_DualChecker_for_Mitigating_Hallucinations_in_Distilling_Large_Language_Models/2024-08-22-Interactive_DualChecker_for_Mitigating_Hallucinations_in_Distilling_Large_Language_Models.html#appendix",
    "title": "Interactive DualChecker for Mitigating Hallucinations in Distilling Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12326v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12326v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6303"
  },
  {
    "objectID": "posts/SOS!_Soft_Prompt_Attack_Against_Open_Source_Large_Language_Models/2024-07-03-SOS!_Soft_Prompt_Attack_Against_Open_Source_Large_Language_Models.html",
    "href": "posts/SOS!_Soft_Prompt_Attack_Against_Open_Source_Large_Language_Models/2024-07-03-SOS!_Soft_Prompt_Attack_Against_Open_Source_Large_Language_Models.html",
    "title": "SOS! Soft Prompt Attack Against Open-Source Large Language Models",
    "section": "",
    "text": "Summary: The paper presents a novel attack called SOS (Soft prompt attack against Open-Source LLMs) that targets open-source large language models (LLMs). SOS is designed to be computationally efficient and does not require clean data or modification of the model weights, ensuring the model’s utility remains intact. The attack addresses security issues in various scenarios, including backdoor attacks, jailbreak attacks, and prompt stealing attacks. The authors demonstrate the effectiveness of SOS across all evaluated targets and present a novel technique called the copyright token, which enables users to mark their copyrighted content and prevent models from using it.\nKey Terms:\nMajor Findings:"
  },
  {
    "objectID": "posts/SOS!_Soft_Prompt_Attack_Against_Open_Source_Large_Language_Models/2024-07-03-SOS!_Soft_Prompt_Attack_Against_Open_Source_Large_Language_Models.html#appendix",
    "href": "posts/SOS!_Soft_Prompt_Attack_Against_Open_Source_Large_Language_Models/2024-07-03-SOS!_Soft_Prompt_Attack_Against_Open_Source_Large_Language_Models.html#appendix",
    "title": "SOS! Soft Prompt Attack Against Open-Source Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03160v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03160v1\n\n\nTruncated\nTrue\n\n\nWord Count\n28326"
  },
  {
    "objectID": "posts/Quantifying_AI_Psychology_A_Psychometrics_Benchmark_for_Large_Language_Models/2024-06-25-Quantifying_AI_Psychology_A_Psychometrics_Benchmark_for_Large_Language_Models.html#appendix",
    "href": "posts/Quantifying_AI_Psychology_A_Psychometrics_Benchmark_for_Large_Language_Models/2024-06-25-Quantifying_AI_Psychology_A_Psychometrics_Benchmark_for_Large_Language_Models.html#appendix",
    "title": "Quantifying AI Psychology: A Psychometrics Benchmark for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17675v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17675v1\n\n\nTruncated\nFalse\n\n\nWord Count\n22287"
  },
  {
    "objectID": "posts/Cutting_Through_the_Clutter_The_Potential_of_LLMs_for_Efficient_Filtration_in_Systematic_Literature_Reviews/2024-07-15-Cutting_Through_the_Clutter_The_Potential_of_LLMs_for_Efficient_Filtration_in_Systematic_Literature_Reviews.html#appendix",
    "href": "posts/Cutting_Through_the_Clutter_The_Potential_of_LLMs_for_Efficient_Filtration_in_Systematic_Literature_Reviews/2024-07-15-Cutting_Through_the_Clutter_The_Potential_of_LLMs_for_Efficient_Filtration_in_Systematic_Literature_Reviews.html#appendix",
    "title": "Cutting Through the Clutter: The Potential of LLMs for Efficient Filtration in Systematic Literature Reviews",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10652v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10652v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5541"
  },
  {
    "objectID": "posts/Large_Language_Model_based_FMRI_Encoding_of_Language_Functions_for_Subjects_with_Neurocognitive_Disorder/2024-07-15-Large_Language_Model_based_FMRI_Encoding_of_Language_Functions_for_Subjects_with_Neurocognitive_Disorder.html#appendix",
    "href": "posts/Large_Language_Model_based_FMRI_Encoding_of_Language_Functions_for_Subjects_with_Neurocognitive_Disorder/2024-07-15-Large_Language_Model_based_FMRI_Encoding_of_Language_Functions_for_Subjects_with_Neurocognitive_Disorder.html#appendix",
    "title": "Large Language Model-based FMRI Encoding of Language Functions for Subjects with Neurocognitive Disorder",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10376v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10376v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4280"
  },
  {
    "objectID": "posts/PISTOL_Dataset_Compilation_Pipeline_for_Structural_Unlearning_of_LLMs/2024-06-24-PISTOL_Dataset_Compilation_Pipeline_for_Structural_Unlearning_of_LLMs.html#appendix",
    "href": "posts/PISTOL_Dataset_Compilation_Pipeline_for_Structural_Unlearning_of_LLMs/2024-06-24-PISTOL_Dataset_Compilation_Pipeline_for_Structural_Unlearning_of_LLMs.html#appendix",
    "title": "PISTOL: Dataset Compilation Pipeline for Structural Unlearning of LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16810v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16810v1\n\n\nTruncated\nFalse\n\n\nWord Count\n25194"
  },
  {
    "objectID": "posts/Benchmarking_Large_Language_Models_for_Math_Reasoning_Tasks/2024-08-20-Benchmarking_Large_Language_Models_for_Math_Reasoning_Tasks.html#appendix",
    "href": "posts/Benchmarking_Large_Language_Models_for_Math_Reasoning_Tasks/2024-08-20-Benchmarking_Large_Language_Models_for_Math_Reasoning_Tasks.html#appendix",
    "title": "Benchmarking Large Language Models for Math Reasoning Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10839v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10839v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8337"
  },
  {
    "objectID": "posts/Evaluating_and_Enhancing_LLMs_Agent_based_on_Theory_of_Mind_in_Guandan_A_Multi_Player_Cooperative_Game_under_Imperfect_Information/2024-08-05-Evaluating_and_Enhancing_LLMs_Agent_based_on_Theory_of_Mind_in_Guandan_A_Multi_Player_Cooperative_Game_under_Imperfect_Information.html",
    "href": "posts/Evaluating_and_Enhancing_LLMs_Agent_based_on_Theory_of_Mind_in_Guandan_A_Multi_Player_Cooperative_Game_under_Imperfect_Information/2024-08-05-Evaluating_and_Enhancing_LLMs_Agent_based_on_Theory_of_Mind_in_Guandan_A_Multi_Player_Cooperative_Game_under_Imperfect_Information.html",
    "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information",
    "section": "",
    "text": "Summary:\nThis study evaluates the performance of open-source and closed-source Large Language Models (LLMs) in a complex card game, Guandan, which involves imperfect information and requires collaboration among agents. The research aims to explore the applicability of knowledge acquired by these models in sophisticated text-based games and compare their performance to established baselines using other types of agents. The study proposes a Theory of Mind (ToM) planning technique that allows LLM agents to adapt their strategy against various adversaries using only game rules, current state, and historical context as input. An external tool was incorporated to mitigate the challenge of dynamic and extensive action spaces in this card game. The results show that while a performance gap exists between current LLMs and state-of-the-art reinforcement learning (RL) models, LLMs demonstrate ToM capabilities in this game setting and consistently improve their performance against opposing agents.\nMajor Findings:\nAnalysis and Critique:\nThe study provides valuable insights into the performance of LLMs in complex, multi-agent gaming environments. However, it is essential to acknowledge the limitations of LLMs without fine-tuning when faced with cooperative tasks involving imperfect information. The research highlights the significant limitations of most models in addressing such challenges effectively. Additionally, the study’s focus on the Guandan card game may limit the generalizability of the findings to other complex social interactions and strategic thinking tasks. Future research should explore the potential of LLMs in a broader range of real-world tasks and address the identified limitations."
  },
  {
    "objectID": "posts/Evaluating_and_Enhancing_LLMs_Agent_based_on_Theory_of_Mind_in_Guandan_A_Multi_Player_Cooperative_Game_under_Imperfect_Information/2024-08-05-Evaluating_and_Enhancing_LLMs_Agent_based_on_Theory_of_Mind_in_Guandan_A_Multi_Player_Cooperative_Game_under_Imperfect_Information.html#appendix",
    "href": "posts/Evaluating_and_Enhancing_LLMs_Agent_based_on_Theory_of_Mind_in_Guandan_A_Multi_Player_Cooperative_Game_under_Imperfect_Information/2024-08-05-Evaluating_and_Enhancing_LLMs_Agent_based_on_Theory_of_Mind_in_Guandan_A_Multi_Player_Cooperative_Game_under_Imperfect_Information.html#appendix",
    "title": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02559v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02559v1\n\n\nTruncated\nFalse\n\n\nWord Count\n23008"
  },
  {
    "objectID": "posts/Global_is_Good_Local_is_Bad_Understanding_Brand_Bias_in_LLMs/2024-06-20-Global_is_Good_Local_is_Bad_Understanding_Brand_Bias_in_LLMs.html#appendix",
    "href": "posts/Global_is_Good_Local_is_Bad_Understanding_Brand_Bias_in_LLMs/2024-06-20-Global_is_Good_Local_is_Bad_Understanding_Brand_Bias_in_LLMs.html#appendix",
    "title": "Global is Good, Local is Bad?: Understanding Brand Bias in LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13997v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13997v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4379"
  },
  {
    "objectID": "posts/Semantic_Change_Characterization_with_LLMs_using_Rhetorics/2024-07-23-Semantic_Change_Characterization_with_LLMs_using_Rhetorics.html#appendix",
    "href": "posts/Semantic_Change_Characterization_with_LLMs_using_Rhetorics/2024-07-23-Semantic_Change_Characterization_with_LLMs_using_Rhetorics.html#appendix",
    "title": "Semantic Change Characterization with LLMs using Rhetorics",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16624v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16624v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6813"
  },
  {
    "objectID": "posts/GLBench_A_Comprehensive_Benchmark_for_Graph_with_Large_Language_Models/2024-07-11-GLBench_A_Comprehensive_Benchmark_for_Graph_with_Large_Language_Models.html#appendix",
    "href": "posts/GLBench_A_Comprehensive_Benchmark_for_Graph_with_Large_Language_Models/2024-07-11-GLBench_A_Comprehensive_Benchmark_for_Graph_with_Large_Language_Models.html#appendix",
    "title": "GLBench: A Comprehensive Benchmark for Graph with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07457v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07457v2\n\n\nTruncated\nFalse\n\n\nWord Count\n9223"
  },
  {
    "objectID": "posts/Are_Large_Language_Models_More_Honest_in_Their_Probabilistic_or_Verbalized_Confidence/2024-08-19-Are_Large_Language_Models_More_Honest_in_Their_Probabilistic_or_Verbalized_Confidence.html#major-findings",
    "href": "posts/Are_Large_Language_Models_More_Honest_in_Their_Probabilistic_or_Verbalized_Confidence/2024-08-19-Are_Large_Language_Models_More_Honest_in_Their_Probabilistic_or_Verbalized_Confidence.html#major-findings",
    "title": "Are Large Language Models More Honest in Their Probabilistic or Verbalized Confidence?",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nLLMs’ probabilistic perception of their knowledge boundaries is more accurate than their verbalized perception, but it necessitates the use of an in-domain dataset to determine an appropriate confidence threshold for binarizing continuous probabilistic confidence.\nBoth LLMs’ probabilistic perception and verbalized perception of their knowledge boundaries perform better on less common questions, indicating that LLMs’ perception levels decline on more familiar questions.\nLLMs’ verbalized confidence is positively correlated with their probabilistic confidence, but the correlation is weak and varies significantly across different datasets, making it challenging for LLMs to accurately express their internal confidence in natural language."
  },
  {
    "objectID": "posts/Are_Large_Language_Models_More_Honest_in_Their_Probabilistic_or_Verbalized_Confidence/2024-08-19-Are_Large_Language_Models_More_Honest_in_Their_Probabilistic_or_Verbalized_Confidence.html#analysis-and-critique",
    "href": "posts/Are_Large_Language_Models_More_Honest_in_Their_Probabilistic_or_Verbalized_Confidence/2024-08-19-Are_Large_Language_Models_More_Honest_in_Their_Probabilistic_or_Verbalized_Confidence.html#analysis-and-critique",
    "title": "Are Large Language Models More Honest in Their Probabilistic or Verbalized Confidence?",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe study provides valuable insights into the perception of factual knowledge boundaries in LLMs, highlighting the differences and connections between probabilistic and verbalized confidence.\nThe authors’ comprehensive analysis and comparison of LLMs’ perceptions under varying question frequencies and their correlation with QA performance offer a deeper understanding of LLMs’ capabilities and limitations.\nHowever, the study could benefit from exploring additional factors that may influence LLMs’ perception of their knowledge boundaries, such as model size, training data, and prompting techniques.\nAdditionally, the study could investigate the potential applications of LLMs’ perception of their knowledge boundaries in real-world scenarios, such as safety and healthcare, to further demonstrate their practical implications."
  },
  {
    "objectID": "posts/Are_Large_Language_Models_More_Honest_in_Their_Probabilistic_or_Verbalized_Confidence/2024-08-19-Are_Large_Language_Models_More_Honest_in_Their_Probabilistic_or_Verbalized_Confidence.html#appendix",
    "href": "posts/Are_Large_Language_Models_More_Honest_in_Their_Probabilistic_or_Verbalized_Confidence/2024-08-19-Are_Large_Language_Models_More_Honest_in_Their_Probabilistic_or_Verbalized_Confidence.html#appendix",
    "title": "Are Large Language Models More Honest in Their Probabilistic or Verbalized Confidence?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09773v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09773v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4282"
  },
  {
    "objectID": "posts/Seeing_Through_AIs_Lens_Enhancing_Human_Skepticism_Towards_LLM_Generated_Fake_News/2024-06-20-Seeing_Through_AIs_Lens_Enhancing_Human_Skepticism_Towards_LLM_Generated_Fake_News.html#appendix",
    "href": "posts/Seeing_Through_AIs_Lens_Enhancing_Human_Skepticism_Towards_LLM_Generated_Fake_News/2024-06-20-Seeing_Through_AIs_Lens_Enhancing_Human_Skepticism_Towards_LLM_Generated_Fake_News.html#appendix",
    "title": "Seeing Through AI’s Lens: Enhancing Human Skepticism Towards LLM-Generated Fake News",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14012v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14012v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7336"
  },
  {
    "objectID": "posts/Dr.Academy_A_Benchmark_for_Evaluating_Questioning_Capability_in_Education_for_Large_Language_Models/2024-08-20-Dr.Academy_A_Benchmark_for_Evaluating_Questioning_Capability_in_Education_for_Large_Language_Models.html#appendix",
    "href": "posts/Dr.Academy_A_Benchmark_for_Evaluating_Questioning_Capability_in_Education_for_Large_Language_Models/2024-08-20-Dr.Academy_A_Benchmark_for_Evaluating_Questioning_Capability_in_Education_for_Large_Language_Models.html#appendix",
    "title": "Dr.Academy: A Benchmark for Evaluating Questioning Capability in Education for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10947v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10947v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7147"
  },
  {
    "objectID": "posts/Preference_Tuning_For_Toxicity_Mitigation_Generalizes_Across_Languages/2024-06-23-Preference_Tuning_For_Toxicity_Mitigation_Generalizes_Across_Languages.html#appendix",
    "href": "posts/Preference_Tuning_For_Toxicity_Mitigation_Generalizes_Across_Languages/2024-06-23-Preference_Tuning_For_Toxicity_Mitigation_Generalizes_Across_Languages.html#appendix",
    "title": "Preference Tuning For Toxicity Mitigation Generalizes Across Languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16235v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16235v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8475"
  },
  {
    "objectID": "posts/Psychological_Profiling_in_Cybersecurity_A_Look_at_LLMs_and_Psycholinguistic_Features/2024-06-26-Psychological_Profiling_in_Cybersecurity_A_Look_at_LLMs_and_Psycholinguistic_Features.html#appendix",
    "href": "posts/Psychological_Profiling_in_Cybersecurity_A_Look_at_LLMs_and_Psycholinguistic_Features/2024-06-26-Psychological_Profiling_in_Cybersecurity_A_Look_at_LLMs_and_Psycholinguistic_Features.html#appendix",
    "title": "Psychological Profiling in Cybersecurity: A Look at LLMs and Psycholinguistic Features",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18783v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18783v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6749"
  },
  {
    "objectID": "posts/RAG_vs._Long_Context_Examining_Frontier_Large_Language_Models_for_Environmental_Review_Document_Comprehension/2024-07-10-RAG_vs._Long_Context_Examining_Frontier_Large_Language_Models_for_Environmental_Review_Document_Comprehension.html#appendix",
    "href": "posts/RAG_vs._Long_Context_Examining_Frontier_Large_Language_Models_for_Environmental_Review_Document_Comprehension/2024-07-10-RAG_vs._Long_Context_Examining_Frontier_Large_Language_Models_for_Environmental_Review_Document_Comprehension.html#appendix",
    "title": "RAG vs. Long Context: Examining Frontier Large Language Models for Environmental Review Document Comprehension",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07321v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07321v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8903"
  },
  {
    "objectID": "posts/Leveraging_the_Power_of_LLMs_A_Fine_Tuning_Approach_for_High_Quality_Aspect_Based_Summarization/2024-08-05-Leveraging_the_Power_of_LLMs_A_Fine_Tuning_Approach_for_High_Quality_Aspect_Based_Summarization.html#appendix",
    "href": "posts/Leveraging_the_Power_of_LLMs_A_Fine_Tuning_Approach_for_High_Quality_Aspect_Based_Summarization/2024-08-05-Leveraging_the_Power_of_LLMs_A_Fine_Tuning_Approach_for_High_Quality_Aspect_Based_Summarization.html#appendix",
    "title": "Leveraging the Power of LLMs: A Fine-Tuning Approach for High-Quality Aspect-Based Summarization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02584v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02584v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6967"
  },
  {
    "objectID": "posts/Guiding_LLM_Temporal_Logic_Generation_with_Explicit_Separation_of_Data_and_Control/2024-06-11-Guiding_LLM_Temporal_Logic_Generation_with_Explicit_Separation_of_Data_and_Control.html#appendix",
    "href": "posts/Guiding_LLM_Temporal_Logic_Generation_with_Explicit_Separation_of_Data_and_Control/2024-06-11-Guiding_LLM_Temporal_Logic_Generation_with_Explicit_Separation_of_Data_and_Control.html#appendix",
    "title": "Guiding LLM Temporal Logic Generation with Explicit Separation of Data and Control",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07400v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07400v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4241"
  },
  {
    "objectID": "posts/FIRST_Teach_A_Reliable_Large_Language_Model_Through_Efficient_Trustworthy_Distillation/2024-08-22-FIRST_Teach_A_Reliable_Large_Language_Model_Through_Efficient_Trustworthy_Distillation.html#appendix",
    "href": "posts/FIRST_Teach_A_Reliable_Large_Language_Model_Through_Efficient_Trustworthy_Distillation/2024-08-22-FIRST_Teach_A_Reliable_Large_Language_Model_Through_Efficient_Trustworthy_Distillation.html#appendix",
    "title": "FIRST: Teach A Reliable Large Language Model Through Efficient Trustworthy Distillation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12168v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12168v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7033"
  },
  {
    "objectID": "posts/Applying_and_Evaluating_Large_Language_Models_in_Mental_Health_Care_A_Scoping_Review_of_Human_Assessed_Generative_Tasks/2024-08-21-Applying_and_Evaluating_Large_Language_Models_in_Mental_Health_Care_A_Scoping_Review_of_Human_Assessed_Generative_Tasks.html",
    "href": "posts/Applying_and_Evaluating_Large_Language_Models_in_Mental_Health_Care_A_Scoping_Review_of_Human_Assessed_Generative_Tasks/2024-08-21-Applying_and_Evaluating_Large_Language_Models_in_Mental_Health_Care_A_Scoping_Review_of_Human_Assessed_Generative_Tasks.html",
    "title": "Applying and Evaluating Large Language Models in Mental Health Care: A Scoping Review of Human-Assessed Generative Tasks",
    "section": "",
    "text": "Summary:\nThe article “Applying and Evaluating Large Language Models in Mental Health Care: A Scoping Review of Human-Assessed Generative Tasks” by Yining Hua et al. presents a scoping review of the current applications of large language models (LLMs) in mental health care. The review focuses on studies where LLMs were tested with human participants in real-world scenarios. The authors identified 17 studies that met their inclusion criteria, covering applications such as clinical assistance, counseling, therapy, and emotional support. However, the evaluation methods used in these studies were often non-standardized, relying on ad-hoc scales that limit comparability and robustness. Privacy, safety, and fairness were also frequently underexplored. The reliance on proprietary models, such as OpenAI’s GPT series, raises concerns about transparency and reproducibility. While LLMs show potential in expanding mental health care access, especially in underserved areas, the current evidence does not fully support their use as standalone interventions. More rigorous, standardized evaluations and ethical oversight are needed to ensure these tools can be safely and effectively integrated into clinical practice.\nMajor Findings:\nAnalysis and Critique:\nThe article provides a comprehensive review of the current applications of LLMs in mental health care. The authors highlight the potential of LLMs in expanding mental health care access, especially in underserved areas. However, they also identify several limitations and challenges in the current evidence. The non-standardized evaluation methods and reliance on proprietary models limit the comparability"
  },
  {
    "objectID": "posts/Applying_and_Evaluating_Large_Language_Models_in_Mental_Health_Care_A_Scoping_Review_of_Human_Assessed_Generative_Tasks/2024-08-21-Applying_and_Evaluating_Large_Language_Models_in_Mental_Health_Care_A_Scoping_Review_of_Human_Assessed_Generative_Tasks.html#appendix",
    "href": "posts/Applying_and_Evaluating_Large_Language_Models_in_Mental_Health_Care_A_Scoping_Review_of_Human_Assessed_Generative_Tasks/2024-08-21-Applying_and_Evaluating_Large_Language_Models_in_Mental_Health_Care_A_Scoping_Review_of_Human_Assessed_Generative_Tasks.html#appendix",
    "title": "Applying and Evaluating Large Language Models in Mental Health Care: A Scoping Review of Human-Assessed Generative Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11288v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11288v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15816"
  },
  {
    "objectID": "posts/Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias/2024-07-08-Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias.html",
    "href": "posts/Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias/2024-07-08-Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias.html",
    "title": "Do Multilingual Large Language Models Mitigate Stereotype Bias?",
    "section": "",
    "text": "Summary: This paper investigates the impact of multilingual training on bias mitigation in large language models (LLMs). The authors train six LLMs of identical size (2.6B parameters) and architecture, including five monolingual models (English, German, French, Italian, and Spanish) and one multilingual model. The models are evaluated on standard bias benchmarks, which are automatically translated and verified for both translation quality and bias preservation. The results show that multilingual training effectively mitigates bias, and multilingual models achieve not only lower bias but also superior prediction accuracy compared to monolingual models with the same amount of training data, model architecture, and size.\nMajor Findings: 1. Multilingual training effectively mitigates bias in LLMs. 2. Multilingual models achieve lower bias than monolingual models with the same amount of training data, model architecture, and size. 3. Multilingual models outperform monolingual models in prediction accuracy.\nAnalysis and Critique: The paper presents a well-structured and coherent summary of the research, providing a clear overview of the methodology and findings. The use of a controlled setting and the evaluation of both bias and prediction accuracy are strengths of the study. However, the paper does not discuss potential limitations or shortcomings of the research, such as the generalizability of the findings to other languages or the impact of different translation methods on the results. Additionally, the paper does not address the potential for biases to be introduced during the translation process, which could affect the validity of the results. Further research is needed to explore these issues and to validate the findings in other contexts."
  },
  {
    "objectID": "posts/Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias/2024-07-08-Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias.html#appendix",
    "href": "posts/Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias/2024-07-08-Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias.html#appendix",
    "title": "Do Multilingual Large Language Models Mitigate Stereotype Bias?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05740v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05740v1\n\n\nTruncated\nFalse\n\n\nWord Count\n21234"
  },
  {
    "objectID": "posts/Testing_Large_Language_Models_on_Driving_Theory_Knowledge_and_Skills_for_Connected_Autonomous_Vehicles/2024-07-24-Testing_Large_Language_Models_on_Driving_Theory_Knowledge_and_Skills_for_Connected_Autonomous_Vehicles.html#appendix",
    "href": "posts/Testing_Large_Language_Models_on_Driving_Theory_Knowledge_and_Skills_for_Connected_Autonomous_Vehicles/2024-07-24-Testing_Large_Language_Models_on_Driving_Theory_Knowledge_and_Skills_for_Connected_Autonomous_Vehicles.html#appendix",
    "title": "Testing Large Language Models on Driving Theory Knowledge and Skills for Connected Autonomous Vehicles",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17211v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17211v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5807"
  },
  {
    "objectID": "posts/Leveraging_LLM_Respondents_for_Item_Evaluation_a_Psychometric_Analysis/2024-07-15-Leveraging_LLM_Respondents_for_Item_Evaluation_a_Psychometric_Analysis.html#appendix",
    "href": "posts/Leveraging_LLM_Respondents_for_Item_Evaluation_a_Psychometric_Analysis/2024-07-15-Leveraging_LLM_Respondents_for_Item_Evaluation_a_Psychometric_Analysis.html#appendix",
    "title": "Leveraging LLM-Respondents for Item Evaluation: a Psychometric Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10899v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10899v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5642"
  },
  {
    "objectID": "posts/Assessing_Programming_Task_Difficulty_for_Efficient_Evaluation_of_Large_Language_Models/2024-07-30-Assessing_Programming_Task_Difficulty_for_Efficient_Evaluation_of_Large_Language_Models.html#appendix",
    "href": "posts/Assessing_Programming_Task_Difficulty_for_Efficient_Evaluation_of_Large_Language_Models/2024-07-30-Assessing_Programming_Task_Difficulty_for_Efficient_Evaluation_of_Large_Language_Models.html#appendix",
    "title": "Assessing Programming Task Difficulty for Efficient Evaluation of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21227v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21227v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12739"
  },
  {
    "objectID": "posts/LLMs_for_User_Interest_Exploration_A_Hybrid_Approach/2024-05-25-LLMs_for_User_Interest_Exploration_A_Hybrid_Approach.html#appendix",
    "href": "posts/LLMs_for_User_Interest_Exploration_A_Hybrid_Approach/2024-05-25-LLMs_for_User_Interest_Exploration_A_Hybrid_Approach.html#appendix",
    "title": "LLMs for User Interest Exploration: A Hybrid Approach",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.16363v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.16363v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5005"
  },
  {
    "objectID": "posts/MAVIS_Mathematical_Visual_Instruction_Tuning/2024-07-11-MAVIS_Mathematical_Visual_Instruction_Tuning.html#appendix",
    "href": "posts/MAVIS_Mathematical_Visual_Instruction_Tuning/2024-07-11-MAVIS_Mathematical_Visual_Instruction_Tuning.html#appendix",
    "title": "MAVIS: Mathematical Visual Instruction Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08739v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08739v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8660"
  },
  {
    "objectID": "posts/Minor_DPO_reject_penalty_to_increase_training_robustness/2024-08-19-Minor_DPO_reject_penalty_to_increase_training_robustness.html#appendix",
    "href": "posts/Minor_DPO_reject_penalty_to_increase_training_robustness/2024-08-19-Minor_DPO_reject_penalty_to_increase_training_robustness.html#appendix",
    "title": "Minor DPO reject penalty to increase training robustness",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09834v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09834v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5014"
  },
  {
    "objectID": "posts/GRASP_A_Grid_Based_Benchmark_for_Evaluating_Commonsense_Spatial_Reasoning/2024-07-02-GRASP_A_Grid_Based_Benchmark_for_Evaluating_Commonsense_Spatial_Reasoning.html#appendix",
    "href": "posts/GRASP_A_Grid_Based_Benchmark_for_Evaluating_Commonsense_Spatial_Reasoning/2024-07-02-GRASP_A_Grid_Based_Benchmark_for_Evaluating_Commonsense_Spatial_Reasoning.html#appendix",
    "title": "GRASP: A Grid-Based Benchmark for Evaluating Commonsense Spatial Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01892v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01892v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11185"
  },
  {
    "objectID": "posts/LAB_Bench_Measuring_Capabilities_of_Language_Models_for_Biology_Research/2024-07-14-LAB_Bench_Measuring_Capabilities_of_Language_Models_for_Biology_Research.html",
    "href": "posts/LAB_Bench_Measuring_Capabilities_of_Language_Models_for_Biology_Research/2024-07-14-LAB_Bench_Measuring_Capabilities_of_Language_Models_for_Biology_Research.html",
    "title": "LAB-Bench: Measuring Capabilities of Language Models for Biology Research",
    "section": "",
    "text": "Summary:\nThe paper introduces the Language Agent Biology Benchmark (LAB-Bench), a dataset of over 2,400 multiple-choice questions for evaluating AI systems on various practical biology research capabilities. The benchmark covers tasks such as recall and reasoning over literature, interpretation of figures, access and navigation of databases, and comprehension and manipulation of DNA and protein sequences. The authors also introduce a set of 41 “human-hard” multi-step multiple-choice questions, which they believe may take a trained molecular biologist more than 10 minutes to answer completely. The paper evaluates the performance of several frontier commercial and open-source models against the benchmark and compares their capabilities to expert human biology researchers.\nMajor Findings:\nAnalysis and Critique:\nThe LAB-Bench dataset provides a valuable resource for evaluating AI systems on practical biology research tasks. The inclusion of “human-hard” multi-step multiple-choice questions is a unique feature that can help assess the capabilities of AI systems in handling complex tasks. However, the paper does not provide a detailed analysis of the performance of the evaluated models or a comparison to human experts. Additionally, the paper does not discuss the limitations of the dataset or the potential biases in the questions. Further research is needed to evaluate the effectiveness of the LAB-Bench dataset in assessing the capabilities of AI systems for practical biology research tasks."
  },
  {
    "objectID": "posts/LAB_Bench_Measuring_Capabilities_of_Language_Models_for_Biology_Research/2024-07-14-LAB_Bench_Measuring_Capabilities_of_Language_Models_for_Biology_Research.html#appendix",
    "href": "posts/LAB_Bench_Measuring_Capabilities_of_Language_Models_for_Biology_Research/2024-07-14-LAB_Bench_Measuring_Capabilities_of_Language_Models_for_Biology_Research.html#appendix",
    "title": "LAB-Bench: Measuring Capabilities of Language Models for Biology Research",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10362v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10362v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20052"
  },
  {
    "objectID": "posts/Unlearning_Trojans_in_Large_Language_Models_A_Comparison_Between_Natural_Language_and_Source_Code/2024-08-22-Unlearning_Trojans_in_Large_Language_Models_A_Comparison_Between_Natural_Language_and_Source_Code.html#appendix",
    "href": "posts/Unlearning_Trojans_in_Large_Language_Models_A_Comparison_Between_Natural_Language_and_Source_Code/2024-08-22-Unlearning_Trojans_in_Large_Language_Models_A_Comparison_Between_Natural_Language_and_Source_Code.html#appendix",
    "title": "Unlearning Trojans in Large Language Models: A Comparison Between Natural Language and Source Code",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12416v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12416v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6450"
  },
  {
    "objectID": "posts/Large_Language_Models_as_Evaluators_for_Recommendation_Explanations/2024-06-06-Large_Language_Models_as_Evaluators_for_Recommendation_Explanations.html#appendix",
    "href": "posts/Large_Language_Models_as_Evaluators_for_Recommendation_Explanations/2024-06-06-Large_Language_Models_as_Evaluators_for_Recommendation_Explanations.html#appendix",
    "title": "Large Language Models as Evaluators for Recommendation Explanations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03248v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03248v2\n\n\nTruncated\nFalse\n\n\nWord Count\n7752"
  },
  {
    "objectID": "posts/Interpretable_Catastrophic_Forgetting_of_Large_Language_Model_Fine_tuning_via_Instruction_Vector/2024-06-18-Interpretable_Catastrophic_Forgetting_of_Large_Language_Model_Fine_tuning_via_Instruction_Vector.html#appendix",
    "href": "posts/Interpretable_Catastrophic_Forgetting_of_Large_Language_Model_Fine_tuning_via_Instruction_Vector/2024-06-18-Interpretable_Catastrophic_Forgetting_of_Large_Language_Model_Fine_tuning_via_Instruction_Vector.html#appendix",
    "title": "Interpretable Catastrophic Forgetting of Large Language Model Fine-tuning via Instruction Vector",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12227v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12227v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8412"
  },
  {
    "objectID": "posts/Hierarchical_Context_Pruning_Optimizing_Real_World_Code_Completion_with_Repository_Level_Pretrained_Code_LLMs/2024-06-27-Hierarchical_Context_Pruning_Optimizing_Real_World_Code_Completion_with_Repository_Level_Pretrained_Code_LLMs.html#appendix",
    "href": "posts/Hierarchical_Context_Pruning_Optimizing_Real_World_Code_Completion_with_Repository_Level_Pretrained_Code_LLMs/2024-06-27-Hierarchical_Context_Pruning_Optimizing_Real_World_Code_Completion_with_Repository_Level_Pretrained_Code_LLMs.html#appendix",
    "title": "Hierarchical Context Pruning: Optimizing Real-World Code Completion with Repository-Level Pretrained Code LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18294v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18294v2\n\n\nTruncated\nFalse\n\n\nWord Count\n6374"
  },
  {
    "objectID": "posts/RB_SQL_A_Retrieval_based_LLM_Framework_for_Text_to_SQL/2024-07-11-RB_SQL_A_Retrieval_based_LLM_Framework_for_Text_to_SQL.html#appendix",
    "href": "posts/RB_SQL_A_Retrieval_based_LLM_Framework_for_Text_to_SQL/2024-07-11-RB_SQL_A_Retrieval_based_LLM_Framework_for_Text_to_SQL.html#appendix",
    "title": "RB-SQL: A Retrieval-based LLM Framework for Text-to-SQL",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08273v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08273v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7686"
  },
  {
    "objectID": "posts/BIGbench_A_Unified_Benchmark_for_Social_Bias_in_Text_to_Image_Generative_Models_Based_on_Multi_modal_LLM/2024-07-21-BIGbench_A_Unified_Benchmark_for_Social_Bias_in_Text_to_Image_Generative_Models_Based_on_Multi_modal_LLM.html#appendix",
    "href": "posts/BIGbench_A_Unified_Benchmark_for_Social_Bias_in_Text_to_Image_Generative_Models_Based_on_Multi_modal_LLM/2024-07-21-BIGbench_A_Unified_Benchmark_for_Social_Bias_in_Text_to_Image_Generative_Models_Based_on_Multi_modal_LLM.html#appendix",
    "title": "BIGbench: A Unified Benchmark for Social Bias in Text-to-Image Generative Models Based on Multi-modal LLM",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.15240v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.15240v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6160"
  },
  {
    "objectID": "posts/Top_Pass_Improve_Code_Generation_by_Passk_Maximized_Code_Ranking/2024-08-11-Top_Pass_Improve_Code_Generation_by_Passk_Maximized_Code_Ranking.html#appendix",
    "href": "posts/Top_Pass_Improve_Code_Generation_by_Passk_Maximized_Code_Ranking/2024-08-11-Top_Pass_Improve_Code_Generation_by_Passk_Maximized_Code_Ranking.html#appendix",
    "title": "Top Pass: Improve Code Generation by Pass@k-Maximized Code Ranking",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.05715v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.05715v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6715"
  },
  {
    "objectID": "posts/The_Power_of_Combining_Data_and_Knowledge_GPT_4o_is_an_Effective_Interpreter_of_Machine_Learning_Models_in_Predicting_Lymph_Node_Metastasis_of_Lung_Cancer/2024-07-25-The_Power_of_Combining_Data_and_Knowledge_GPT_4o_is_an_Effective_Interpreter_of_Machine_Learning_Models_in_Predicting_Lymph_Node_Metastasis_of_Lung_Cancer.html#appendix",
    "href": "posts/The_Power_of_Combining_Data_and_Knowledge_GPT_4o_is_an_Effective_Interpreter_of_Machine_Learning_Models_in_Predicting_Lymph_Node_Metastasis_of_Lung_Cancer/2024-07-25-The_Power_of_Combining_Data_and_Knowledge_GPT_4o_is_an_Effective_Interpreter_of_Machine_Learning_Models_in_Predicting_Lymph_Node_Metastasis_of_Lung_Cancer.html#appendix",
    "title": "The Power of Combining Data and Knowledge: GPT-4o is an Effective Interpreter of Machine Learning Models in Predicting Lymph Node Metastasis of Lung Cancer",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17900v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17900v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4823"
  },
  {
    "objectID": "posts/Beyond_Generative_Artificial_Intelligence_Roadmap_for_Natural_Language_Generation/2024-07-15-Beyond_Generative_Artificial_Intelligence_Roadmap_for_Natural_Language_Generation.html",
    "href": "posts/Beyond_Generative_Artificial_Intelligence_Roadmap_for_Natural_Language_Generation/2024-07-15-Beyond_Generative_Artificial_Intelligence_Roadmap_for_Natural_Language_Generation.html",
    "title": "Beyond Generative Artificial Intelligence: Roadmap for Natural Language Generation",
    "section": "",
    "text": "Summary:\nThis paper conducts a review of a representative sample of surveys recently published in Natural Language Generation (NLG) to provide a research roadmap for the scientific community. The goal is to identify which NLG aspects are not suitably addressed by Large Language Models (LLMs) and suggest future lines of research. The paper discusses the evolution of NLG, from modular architectures to global approaches, and the current focus on developing larger LLMs. However, these models still lack precision and have problems generating texts faithfully like humans. The paper also highlights the need for further contextual knowledge and information modalities to improve LLM performance in more demanding tasks.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive review of recent surveys in NLG and identifies key research gaps that need to be addressed. However, the paper does not discuss the methodology used to select the surveys or the criteria for inclusion. Additionally, the paper does not provide a detailed analysis of the limitations of the reviewed surveys or the potential biases in their findings. The paper also does not discuss the potential impact of the identified research gaps on the development of NLG systems or the implications for the broader field of AI. Overall, the paper provides a valuable contribution to the field of NLG by highlight"
  },
  {
    "objectID": "posts/Beyond_Generative_Artificial_Intelligence_Roadmap_for_Natural_Language_Generation/2024-07-15-Beyond_Generative_Artificial_Intelligence_Roadmap_for_Natural_Language_Generation.html#appendix",
    "href": "posts/Beyond_Generative_Artificial_Intelligence_Roadmap_for_Natural_Language_Generation/2024-07-15-Beyond_Generative_Artificial_Intelligence_Roadmap_for_Natural_Language_Generation.html#appendix",
    "title": "Beyond Generative Artificial Intelligence: Roadmap for Natural Language Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10554v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10554v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8979"
  },
  {
    "objectID": "posts/A_New_Pipeline_For_Generating_Instruction_Dataset_via_RAG_and_Self_Fine_Tuning/2024-08-12-A_New_Pipeline_For_Generating_Instruction_Dataset_via_RAG_and_Self_Fine_Tuning.html",
    "href": "posts/A_New_Pipeline_For_Generating_Instruction_Dataset_via_RAG_and_Self_Fine_Tuning/2024-08-12-A_New_Pipeline_For_Generating_Instruction_Dataset_via_RAG_and_Self_Fine_Tuning.html",
    "title": "A New Pipeline For Generating Instruction Dataset via RAG and Self Fine-Tuning",
    "section": "",
    "text": "Summary:\nThe paper proposes a pipeline for generating high-quality instruction datasets for fine-tuning large language models (LLMs) on specific domains using custom document collections. The pipeline leverages the power of LLMs and the Retrieval-Augmented Generation (RAG) related framework to create relevant and contextually appropriate instructions. This approach overcomes the limitations of traditional dataset creation methods, which often rely on manual curation or web-scraping techniques that may introduce noise and irrelevant data. The pipeline offers a dynamic solution that can quickly adapt to updates or modifications in the domain-specific document collection, eliminating the need for complete retraining. Additionally, it addresses the challenge of data scarcity by enabling the generation of instruction datasets from a limited set of initial documents, rendering it suitable for unpopular or specialized domains where comprehensive datasets are scarce.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/A_New_Pipeline_For_Generating_Instruction_Dataset_via_RAG_and_Self_Fine_Tuning/2024-08-12-A_New_Pipeline_For_Generating_Instruction_Dataset_via_RAG_and_Self_Fine_Tuning.html#appendix",
    "href": "posts/A_New_Pipeline_For_Generating_Instruction_Dataset_via_RAG_and_Self_Fine_Tuning/2024-08-12-A_New_Pipeline_For_Generating_Instruction_Dataset_via_RAG_and_Self_Fine_Tuning.html#appendix",
    "title": "A New Pipeline For Generating Instruction Dataset via RAG and Self Fine-Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.05911v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.05911v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5446"
  },
  {
    "objectID": "posts/CREF_An_LLM_based_Conversational_Software_Repair_Framework_for_Programming_Tutors/2024-06-20-CREF_An_LLM_based_Conversational_Software_Repair_Framework_for_Programming_Tutors.html#appendix",
    "href": "posts/CREF_An_LLM_based_Conversational_Software_Repair_Framework_for_Programming_Tutors/2024-06-20-CREF_An_LLM_based_Conversational_Software_Repair_Framework_for_Programming_Tutors.html#appendix",
    "title": "CREF: An LLM-based Conversational Software Repair Framework for Programming Tutors",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13972v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13972v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12780"
  },
  {
    "objectID": "posts/Unmasking_the_Imposters_In_Domain_Detection_of_Human_vs._Machine_Generated_Tweets/2024-06-25-Unmasking_the_Imposters_In_Domain_Detection_of_Human_vs._Machine_Generated_Tweets.html#appendix",
    "href": "posts/Unmasking_the_Imposters_In_Domain_Detection_of_Human_vs._Machine_Generated_Tweets/2024-06-25-Unmasking_the_Imposters_In_Domain_Detection_of_Human_vs._Machine_Generated_Tweets.html#appendix",
    "title": "Unmasking the Imposters: In-Domain Detection of Human vs. Machine-Generated Tweets",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17967v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17967v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6557"
  },
  {
    "objectID": "posts/Harnessing_Multimodal_Large_Language_Models_for_Multimodal_Sequential_Recommendation/2024-08-20-Harnessing_Multimodal_Large_Language_Models_for_Multimodal_Sequential_Recommendation.html#appendix",
    "href": "posts/Harnessing_Multimodal_Large_Language_Models_for_Multimodal_Sequential_Recommendation/2024-08-20-Harnessing_Multimodal_Large_Language_Models_for_Multimodal_Sequential_Recommendation.html#appendix",
    "title": "Harnessing Multimodal Large Language Models for Multimodal Sequential Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09698v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09698v2\n\n\nTruncated\nFalse\n\n\nWord Count\n6167"
  },
  {
    "objectID": "posts/Defining_and_Evaluating_Decision_and_Composite_Risk_in_Language_Models_Applied_to_Natural_Language_Inference/2024-08-04-Defining_and_Evaluating_Decision_and_Composite_Risk_in_Language_Models_Applied_to_Natural_Language_Inference.html#appendix",
    "href": "posts/Defining_and_Evaluating_Decision_and_Composite_Risk_in_Language_Models_Applied_to_Natural_Language_Inference/2024-08-04-Defining_and_Evaluating_Decision_and_Composite_Risk_in_Language_Models_Applied_to_Natural_Language_Inference.html#appendix",
    "title": "Defining and Evaluating Decision and Composite Risk in Language Models Applied to Natural Language Inference",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.01935v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.01935v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9495"
  },
  {
    "objectID": "posts/Can_I_understand_what_I_create_Self_Knowledge_Evaluation_of_Large_Language_Models/2024-06-10-Can_I_understand_what_I_create_Self_Knowledge_Evaluation_of_Large_Language_Models.html#appendix",
    "href": "posts/Can_I_understand_what_I_create_Self_Knowledge_Evaluation_of_Large_Language_Models/2024-06-10-Can_I_understand_what_I_create_Self_Knowledge_Evaluation_of_Large_Language_Models.html#appendix",
    "title": "Can I understand what I create? Self-Knowledge Evaluation of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06140v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06140v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7449"
  },
  {
    "objectID": "posts/T2VSafetyBench_Evaluating_the_Safety_of_Text_to_Video_Generative_Models/2024-07-08-T2VSafetyBench_Evaluating_the_Safety_of_Text_to_Video_Generative_Models.html#appendix",
    "href": "posts/T2VSafetyBench_Evaluating_the_Safety_of_Text_to_Video_Generative_Models/2024-07-08-T2VSafetyBench_Evaluating_the_Safety_of_Text_to_Video_Generative_Models.html#appendix",
    "title": "T2VSafetyBench: Evaluating the Safety of Text-to-Video Generative Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05965v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05965v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8108"
  },
  {
    "objectID": "posts/PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation/2024-06-26-PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation.html#major-findings",
    "href": "posts/PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation/2024-06-26-PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation.html#major-findings",
    "title": "PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nStable Prompts: The study discovers that in some scenarios, prompts are stable, with some LLMs showing idiosyncratic preferences for grading generated texts with textual labels, while others prefer to return numeric scores.\nSusceptibility to Changes: However, the stability of prompts and model rankings can be susceptible to seemingly innocuous changes. For instance, changing the requested output format from “0 to 100” to “-1 to +1” can strongly affect the rankings in the evaluation.\nUnderstanding Prompting Approaches: The study contributes to understanding the impact of different prompting approaches on LLM-based metrics for machine translation and summarization evaluation, highlighting the most stable prompting patterns and potential limitations."
  },
  {
    "objectID": "posts/PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation/2024-06-26-PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation.html#analysis-and-critique",
    "href": "posts/PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation/2024-06-26-PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation.html#analysis-and-critique",
    "title": "PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper provides a comprehensive exploration of prompting strategies for LLM-based metrics, offering valuable insights into the stability and variability of these strategies. However, the study’s scope is limited to open-source LLMs, and the findings may not generalize to closed-source models. Additionally, the study does not explore the impact of different prompting strategies on other NLP tasks beyond machine translation and summarization.\nFurthermore, the study’s reliance on a single dataset for evaluation may limit the generalizability of the findings. Future research could benefit from evaluating the proposed prompting strategies on a more diverse range of datasets and tasks.\nLastly, the study does not discuss the potential ethical implications of using LLMs for evaluation, such as the risk of bias or the need for transparency in the evaluation process. Addressing these issues could enhance the credibility and applicability of the proposed prompting strategies."
  },
  {
    "objectID": "posts/PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation/2024-06-26-PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation.html#appendix",
    "href": "posts/PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation/2024-06-26-PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation.html#appendix",
    "title": "PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18528v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18528v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9672"
  },
  {
    "objectID": "posts/LLMs_are_Superior_Feedback_Providers_Bootstrapping_Reasoning_for_Lie_Detection_with_Self_Generated_Feedback/2024-08-25-LLMs_are_Superior_Feedback_Providers_Bootstrapping_Reasoning_for_Lie_Detection_with_Self_Generated_Feedback.html#appendix",
    "href": "posts/LLMs_are_Superior_Feedback_Providers_Bootstrapping_Reasoning_for_Lie_Detection_with_Self_Generated_Feedback/2024-08-25-LLMs_are_Superior_Feedback_Providers_Bootstrapping_Reasoning_for_Lie_Detection_with_Self_Generated_Feedback.html#appendix",
    "title": "LLMs are Superior Feedback Providers: Bootstrapping Reasoning for Lie Detection with Self-Generated Feedback",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.13915v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.13915v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12835"
  },
  {
    "objectID": "posts/CoDefeater_Using_LLMs_To_Find_Defeaters_in_Assurance_Cases/2024-07-18-CoDefeater_Using_LLMs_To_Find_Defeaters_in_Assurance_Cases.html#appendix",
    "href": "posts/CoDefeater_Using_LLMs_To_Find_Defeaters_in_Assurance_Cases/2024-07-18-CoDefeater_Using_LLMs_To_Find_Defeaters_in_Assurance_Cases.html#appendix",
    "title": "CoDefeater: Using LLMs To Find Defeaters in Assurance Cases",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.13717v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.13717v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4468"
  },
  {
    "objectID": "posts/Language_Models_Resist_Alignment/2024-06-10-Language_Models_Resist_Alignment.html#appendix",
    "href": "posts/Language_Models_Resist_Alignment/2024-06-10-Language_Models_Resist_Alignment.html#appendix",
    "title": "Language Models Resist Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06144v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06144v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5000"
  },
  {
    "objectID": "posts/Assessing_Contamination_in_Large_Language_Models_Introducing_the_LogProber_method/2024-08-26-Assessing_Contamination_in_Large_Language_Models_Introducing_the_LogProber_method.html#appendix",
    "href": "posts/Assessing_Contamination_in_Large_Language_Models_Introducing_the_LogProber_method/2024-08-26-Assessing_Contamination_in_Large_Language_Models_Introducing_the_LogProber_method.html#appendix",
    "title": "Assessing Contamination in Large Language Models: Introducing the LogProber method",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.14352v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.14352v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6889"
  },
  {
    "objectID": "posts/SSP_Self_Supervised_Prompting_for_Cross_Lingual_Transfer_to_Low_Resource_Languages_using_Large_Language_Models/2024-06-27-SSP_Self_Supervised_Prompting_for_Cross_Lingual_Transfer_to_Low_Resource_Languages_using_Large_Language_Models.html#appendix",
    "href": "posts/SSP_Self_Supervised_Prompting_for_Cross_Lingual_Transfer_to_Low_Resource_Languages_using_Large_Language_Models/2024-06-27-SSP_Self_Supervised_Prompting_for_Cross_Lingual_Transfer_to_Low_Resource_Languages_using_Large_Language_Models.html#appendix",
    "title": "SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18880v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18880v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11013"
  },
  {
    "objectID": "posts/On_Policy_Fine_grained_Knowledge_Feedback_for_Hallucination_Mitigation/2024-06-18-On_Policy_Fine_grained_Knowledge_Feedback_for_Hallucination_Mitigation.html#appendix",
    "href": "posts/On_Policy_Fine_grained_Knowledge_Feedback_for_Hallucination_Mitigation/2024-06-18-On_Policy_Fine_grained_Knowledge_Feedback_for_Hallucination_Mitigation.html#appendix",
    "title": "On-Policy Fine-grained Knowledge Feedback for Hallucination Mitigation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12221v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12221v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7146"
  },
  {
    "objectID": "posts/RePrompt_Planning_by_Automatic_Prompt_Engineering_for_Large_Language_Models_Agents/2024-06-17-RePrompt_Planning_by_Automatic_Prompt_Engineering_for_Large_Language_Models_Agents.html#appendix",
    "href": "posts/RePrompt_Planning_by_Automatic_Prompt_Engineering_for_Large_Language_Models_Agents/2024-06-17-RePrompt_Planning_by_Automatic_Prompt_Engineering_for_Large_Language_Models_Agents.html#appendix",
    "title": "RePrompt: Planning by Automatic Prompt Engineering for Large Language Models Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11132v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11132v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9868"
  },
  {
    "objectID": "posts/Tools_Fail_Detecting_Silent_Errors_in_Faulty_Tools/2024-06-27-Tools_Fail_Detecting_Silent_Errors_in_Faulty_Tools.html#appendix",
    "href": "posts/Tools_Fail_Detecting_Silent_Errors_in_Faulty_Tools/2024-06-27-Tools_Fail_Detecting_Silent_Errors_in_Faulty_Tools.html#appendix",
    "title": "Tools Fail: Detecting Silent Errors in Faulty Tools",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19228v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19228v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8580"
  },
  {
    "objectID": "posts/Questionnaires_for_Everyone_Streamlining_Cross_Cultural_Questionnaire_Adaptation_with_GPT_Based_Translation_Quality_Evaluation/2024-07-30-Questionnaires_for_Everyone_Streamlining_Cross_Cultural_Questionnaire_Adaptation_with_GPT_Based_Translation_Quality_Evaluation.html#appendix",
    "href": "posts/Questionnaires_for_Everyone_Streamlining_Cross_Cultural_Questionnaire_Adaptation_with_GPT_Based_Translation_Quality_Evaluation/2024-07-30-Questionnaires_for_Everyone_Streamlining_Cross_Cultural_Questionnaire_Adaptation_with_GPT_Based_Translation_Quality_Evaluation.html#appendix",
    "title": "Questionnaires for Everyone: Streamlining Cross-Cultural Questionnaire Adaptation with GPT-Based Translation Quality Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20608v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20608v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5792"
  },
  {
    "objectID": "posts/Contrastive_Policy_Gradient_Aligning_LLMs_on_sequence_level_scores_in_a_supervised_friendly_fashion/2024-06-27-Contrastive_Policy_Gradient_Aligning_LLMs_on_sequence_level_scores_in_a_supervised_friendly_fashion.html#appendix",
    "href": "posts/Contrastive_Policy_Gradient_Aligning_LLMs_on_sequence_level_scores_in_a_supervised_friendly_fashion/2024-06-27-Contrastive_Policy_Gradient_Aligning_LLMs_on_sequence_level_scores_in_a_supervised_friendly_fashion.html#appendix",
    "title": "Contrastive Policy Gradient: Aligning LLMs on sequence-level scores in a supervised-friendly fashion",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19185v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19185v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8271"
  },
  {
    "objectID": "posts/CLR_Fact_Evaluating_the_Complex_Logical_Reasoning_Capability_of_Large_Language_Models_over_Factual_Knowledge/2024-07-30-CLR_Fact_Evaluating_the_Complex_Logical_Reasoning_Capability_of_Large_Language_Models_over_Factual_Knowledge.html#appendix",
    "href": "posts/CLR_Fact_Evaluating_the_Complex_Logical_Reasoning_Capability_of_Large_Language_Models_over_Factual_Knowledge/2024-07-30-CLR_Fact_Evaluating_the_Complex_Logical_Reasoning_Capability_of_Large_Language_Models_over_Factual_Knowledge.html#appendix",
    "title": "CLR-Fact: Evaluating the Complex Logical Reasoning Capability of Large Language Models over Factual Knowledge",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20564v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20564v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6369"
  },
  {
    "objectID": "posts/A_Feature_Based_Approach_to_Generating_Comprehensive_End_to_End_Tests/2024-08-04-A_Feature_Based_Approach_to_Generating_Comprehensive_End_to_End_Tests.html#appendix",
    "href": "posts/A_Feature_Based_Approach_to_Generating_Comprehensive_End_to_End_Tests/2024-08-04-A_Feature_Based_Approach_to_Generating_Comprehensive_End_to_End_Tests.html#appendix",
    "title": "A Feature-Based Approach to Generating Comprehensive End-to-End Tests",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.01894v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.01894v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9219"
  },
  {
    "objectID": "posts/Capturing_Minds_Not_Just_Words_Enhancing_Role_Playing_Language_Models_with_Personality_Indicative_Data/2024-06-27-Capturing_Minds_Not_Just_Words_Enhancing_Role_Playing_Language_Models_with_Personality_Indicative_Data.html#appendix",
    "href": "posts/Capturing_Minds_Not_Just_Words_Enhancing_Role_Playing_Language_Models_with_Personality_Indicative_Data/2024-06-27-Capturing_Minds_Not_Just_Words_Enhancing_Role_Playing_Language_Models_with_Personality_Indicative_Data.html#appendix",
    "title": "Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18921v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18921v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5403"
  },
  {
    "objectID": "posts/DELRec_Distilling_Sequential_Pattern_to_Enhance_LLM_based_Recommendation/2024-06-17-DELRec_Distilling_Sequential_Pattern_to_Enhance_LLM_based_Recommendation.html#appendix",
    "href": "posts/DELRec_Distilling_Sequential_Pattern_to_Enhance_LLM_based_Recommendation/2024-06-17-DELRec_Distilling_Sequential_Pattern_to_Enhance_LLM_based_Recommendation.html#appendix",
    "title": "DELRec: Distilling Sequential Pattern to Enhance LLM-based Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11156v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11156v2\n\n\nTruncated\nFalse\n\n\nWord Count\n8935"
  },
  {
    "objectID": "posts/Harnessing_the_Power_of_LLMs_Automating_Unit_Test_Generation_for_High_Performance_Computing/2024-07-06-Harnessing_the_Power_of_LLMs_Automating_Unit_Test_Generation_for_High_Performance_Computing.html#appendix",
    "href": "posts/Harnessing_the_Power_of_LLMs_Automating_Unit_Test_Generation_for_High_Performance_Computing/2024-07-06-Harnessing_the_Power_of_LLMs_Automating_Unit_Test_Generation_for_High_Performance_Computing.html#appendix",
    "title": "Harnessing the Power of LLMs: Automating Unit Test Generation for High-Performance Computing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05202v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05202v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10114"
  },
  {
    "objectID": "posts/Towards_Evaluating_Large_Language_Models_on_Sarcasm_Understanding/2024-08-21-Towards_Evaluating_Large_Language_Models_on_Sarcasm_Understanding.html",
    "href": "posts/Towards_Evaluating_Large_Language_Models_on_Sarcasm_Understanding/2024-08-21-Towards_Evaluating_Large_Language_Models_on_Sarcasm_Understanding.html",
    "title": "Towards Evaluating Large Language Models on Sarcasm Understanding",
    "section": "",
    "text": "Summary:\nThis study evaluates the performance of large language models (LLMs) in understanding sarcasm, a subtle linguistic phenomenon that often employs rhetorical devices to convey true sentiments and intentions. Eleven state-of-the-art LLMs and eight pre-trained language models (PLMs) were selected and evaluated on six widely used benchmark datasets using different prompting approaches: zero-shot input/output (IO) prompting, few-shot IO prompting, and chain of thought (CoT) prompting.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/Towards_Evaluating_Large_Language_Models_on_Sarcasm_Understanding/2024-08-21-Towards_Evaluating_Large_Language_Models_on_Sarcasm_Understanding.html#appendix",
    "href": "posts/Towards_Evaluating_Large_Language_Models_on_Sarcasm_Understanding/2024-08-21-Towards_Evaluating_Large_Language_Models_on_Sarcasm_Understanding.html#appendix",
    "title": "Towards Evaluating Large Language Models on Sarcasm Understanding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11319v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11319v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8231"
  },
  {
    "objectID": "posts/My_Ontologist_Evaluating_BFO_Based_AI_for_Definition_Support/2024-07-24-My_Ontologist_Evaluating_BFO_Based_AI_for_Definition_Support.html#appendix",
    "href": "posts/My_Ontologist_Evaluating_BFO_Based_AI_for_Definition_Support/2024-07-24-My_Ontologist_Evaluating_BFO_Based_AI_for_Definition_Support.html#appendix",
    "title": "My Ontologist: Evaluating BFO-Based AI for Definition Support",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17657v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17657v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9188"
  },
  {
    "objectID": "posts/Towards_a_Client_Centered_Assessment_of_LLM_Therapists_by_Client_Simulation/2024-06-18-Towards_a_Client_Centered_Assessment_of_LLM_Therapists_by_Client_Simulation.html#appendix",
    "href": "posts/Towards_a_Client_Centered_Assessment_of_LLM_Therapists_by_Client_Simulation/2024-06-18-Towards_a_Client_Centered_Assessment_of_LLM_Therapists_by_Client_Simulation.html#appendix",
    "title": "Towards a Client-Centered Assessment of LLM Therapists by Client Simulation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12266v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12266v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10101"
  },
  {
    "objectID": "posts/Codebook_LLMs_Adapting_Political_Science_Codebooks_for_LLM_Use_and_Adapting_LLMs_to_Follow_Codebooks/2024-07-15-Codebook_LLMs_Adapting_Political_Science_Codebooks_for_LLM_Use_and_Adapting_LLMs_to_Follow_Codebooks.html#appendix",
    "href": "posts/Codebook_LLMs_Adapting_Political_Science_Codebooks_for_LLM_Use_and_Adapting_LLMs_to_Follow_Codebooks/2024-07-15-Codebook_LLMs_Adapting_Political_Science_Codebooks_for_LLM_Use_and_Adapting_LLMs_to_Follow_Codebooks.html#appendix",
    "title": "Codebook LLMs: Adapting Political Science Codebooks for LLM Use and Adapting LLMs to Follow Codebooks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10747v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10747v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14142"
  },
  {
    "objectID": "posts/Soley_Identification_and_Automated_Detection_of_Logic_Vulnerabilities_in_Ethereum_Smart_Contracts_Using_Large_Language_Models/2024-06-24-Soley_Identification_and_Automated_Detection_of_Logic_Vulnerabilities_in_Ethereum_Smart_Contracts_Using_Large_Language_Models.html#appendix",
    "href": "posts/Soley_Identification_and_Automated_Detection_of_Logic_Vulnerabilities_in_Ethereum_Smart_Contracts_Using_Large_Language_Models/2024-06-24-Soley_Identification_and_Automated_Detection_of_Logic_Vulnerabilities_in_Ethereum_Smart_Contracts_Using_Large_Language_Models.html#appendix",
    "title": "Soley: Identification and Automated Detection of Logic Vulnerabilities in Ethereum Smart Contracts Using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16244v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16244v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13712"
  },
  {
    "objectID": "posts/Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text/2024-06-10-Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text.html",
    "href": "posts/Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text/2024-06-10-Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text.html",
    "title": "Synth-SBDH: A Synthetic Dataset of Social and Behavioral Determinants of Health for Clinical Text",
    "section": "",
    "text": "Summary:\nThe study introduces Synth-SBDH, a novel synthetic dataset with detailed SBDH annotations, encompassing status, temporal information, and rationale across 15 SBDH categories. The dataset is the largest publicly available SBDH dataset and is generated and annotated by an LLM (GPT-4). The utility of Synth-SBDH is showcased on three tasks using real-world clinical datasets from two distinct hospital settings, highlighting its versatility, generalizability, and distillation capabilities. Models trained on Synth-SBDH consistently outperform counterparts with no Synth-SBDH training, achieving up to 62.5% macro-F improvements. Synth-SBDH proves effective for rare SBDH categories and under-resource constraints. Human evaluation demonstrates a Human-LLM alignment of 71.06% and uncovers areas for future refinements.\nMajor Findings:\nAnalysis and Critique:\nThe study presents a novel synthetic dataset, Synth-SBDH, which addresses the limitations of existing SBDH datasets and leverages the potential of LLMs in healthcare. The dataset is comprehensive, covering a wide range of SBDH categories and providing detailed"
  },
  {
    "objectID": "posts/Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text/2024-06-10-Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text.html#appendix",
    "href": "posts/Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text/2024-06-10-Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text.html#appendix",
    "title": "Synth-SBDH: A Synthetic Dataset of Social and Behavioral Determinants of Health for Clinical Text",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06056v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06056v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20269"
  },
  {
    "objectID": "posts/InternLM_XComposer_2.5_A_Versatile_Large_Vision_Language_Model_Supporting_Long_Contextual_Input_and_Output/2024-07-03-InternLM_XComposer_2.5_A_Versatile_Large_Vision_Language_Model_Supporting_Long_Contextual_Input_and_Output.html#appendix",
    "href": "posts/InternLM_XComposer_2.5_A_Versatile_Large_Vision_Language_Model_Supporting_Long_Contextual_Input_and_Output/2024-07-03-InternLM_XComposer_2.5_A_Versatile_Large_Vision_Language_Model_Supporting_Long_Contextual_Input_and_Output.html#appendix",
    "title": "InternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03320v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03320v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6365"
  },
  {
    "objectID": "posts/$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning/2024-07-08-$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning.html#summary-1",
    "href": "posts/$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning/2024-07-08-$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning.html#summary-1",
    "title": "\\(R^2\\)-Guard: Robust Reasoning Enabled LLM Guardrail via Knowledge-Enhanced Logical Reasoning",
    "section": "Summary:",
    "text": "Summary:\n\nThe paper introduces -Guard, a robust reasoning enabled LLM guardrail that addresses the limitations of existing guardrail models.\n-Guard consists of two main components: a data-driven category-specific learning component and a knowledge-enhanced reasoning component.\nThe category-specific learning component computes the probability that the prompt falls into different unsafe categories, while the reasoning component makes the final prediction of the overall probability that the prompt is unsafe based on logical inference.\n-Guard employs probabilistic graphical models (PGMs) to implement the reasoning component, which allows for explicit logical inference based on given safety knowledge."
  },
  {
    "objectID": "posts/$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning/2024-07-08-$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning.html#major-findings",
    "href": "posts/$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning/2024-07-08-$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning.html#major-findings",
    "title": "\\(R^2\\)-Guard: Robust Reasoning Enabled LLM Guardrail via Knowledge-Enhanced Logical Reasoning",
    "section": "Major Findings:",
    "text": "Major Findings:\n\n-Guard addresses the limitations of existing guardrail models, such as ineffectiveness due to inadequate training on long-tail data from correlated safety categories, susceptibility to jailbreaks, and inflexibility regarding new safety categories.\n-Guard consists of two main components: a data-driven category-specific learning component and a knowledge-enhanced reasoning component.\n-Guard employs probabilistic graphical models (PGMs) to implement the reasoning component, which allows for explicit logical inference based on given safety knowledge."
  },
  {
    "objectID": "posts/$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning/2024-07-08-$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning.html#analysis-and-critique",
    "href": "posts/$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning/2024-07-08-$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning.html#analysis-and-critique",
    "title": "\\(R^2\\)-Guard: Robust Reasoning Enabled LLM Guardrail via Knowledge-Enhanced Logical Reasoning",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nOne limitation of -Guard is its requirement for explicit specification of safety knowledge rules in PGMs, which necessitates human effort to annotate detailed safety categories and their interconnections.\nHowever, this explicit knowledge also enhances -Guard’s effectiveness and robustness compared to purely data-driven guardrail models.\n-Guard has a broader impact in three key areas: motivating the guardrail community to transition from purely data-driven approaches to those enabled by logical reasoning, providing the symbolic reasoning community with a robust framework for encoding knowledge, performing logical inference, and knowledge weight learning with weak supervision, and safeguarding widespread LLM deployments in various systems.\nThe paper does not see any negative impact of their guardrail model."
  },
  {
    "objectID": "posts/$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning/2024-07-08-$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning.html#appendix",
    "href": "posts/$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning/2024-07-08-$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning.html#appendix",
    "title": "\\(R^2\\)-Guard: Robust Reasoning Enabled LLM Guardrail via Knowledge-Enhanced Logical Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05557v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05557v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7884"
  },
  {
    "objectID": "posts/The_Emerged_Security_and_Privacy_of_LLM_Agent_A_Survey_with_Case_Studies/2024-07-28-The_Emerged_Security_and_Privacy_of_LLM_Agent_A_Survey_with_Case_Studies.html",
    "href": "posts/The_Emerged_Security_and_Privacy_of_LLM_Agent_A_Survey_with_Case_Studies/2024-07-28-The_Emerged_Security_and_Privacy_of_LLM_Agent_A_Survey_with_Case_Studies.html",
    "title": "The Emerged Security and Privacy of LLM Agent: A Survey with Case Studies",
    "section": "",
    "text": "Summary:\nThis paper provides a comprehensive overview of the privacy and security issues faced by Large Language Model (LLM) agents. LLM agents are sophisticated AI systems built on large language models like GPT 4, Claude 3, and Llama 3, which are used in various applications such as virtual assistants, customer service bots, and educational tools. The widespread applications of LLM agents demonstrate their significant commercial value; however, they also expose security and privacy vulnerabilities.\nThe paper categorizes the security threats faced by LLM agents into inherited LLM attacks and unique agent-specific threats. Inherited threats from LLMs include technical vulnerabilities such as hallucinations, catastrophic forgetting, and misunderstandings, as well as intentional malicious attacks like data theft and responses tampering. Agent-specific threats are categorized into knowledge poisoning, functional manipulation, and output manipulation.\nThe paper also explores the real-world impacts of these threats on users, environments, and other agents, highlighting the potential consequences of unmitigated risks. Existing mitigation strategies and solutions to address these threats are reviewed, and gaps in current research and future trends are discussed.\nMajor Findings:\nAnalysis and Critique:\nWhile the paper provides a comprehensive overview of the privacy and security issues faced by LLM agents, it does not delve into the specific methodologies used to address these threats. Additionally, the paper does not discuss the potential biases and ethical considerations that may arise from the use of LLM agents. Further research is needed to explore these aspects and develop more robust"
  },
  {
    "objectID": "posts/The_Emerged_Security_and_Privacy_of_LLM_Agent_A_Survey_with_Case_Studies/2024-07-28-The_Emerged_Security_and_Privacy_of_LLM_Agent_A_Survey_with_Case_Studies.html#appendix",
    "href": "posts/The_Emerged_Security_and_Privacy_of_LLM_Agent_A_Survey_with_Case_Studies/2024-07-28-The_Emerged_Security_and_Privacy_of_LLM_Agent_A_Survey_with_Case_Studies.html#appendix",
    "title": "The Emerged Security and Privacy of LLM Agent: A Survey with Case Studies",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19354v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19354v1\n\n\nTruncated\nFalse\n\n\nWord Count\n16899"
  },
  {
    "objectID": "posts/Ollabench_Evaluating_LLMs_Reasoning_for_Human_centric_Interdependent_Cybersecurity/2024-06-11-Ollabench_Evaluating_LLMs_Reasoning_for_Human_centric_Interdependent_Cybersecurity.html#appendix",
    "href": "posts/Ollabench_Evaluating_LLMs_Reasoning_for_Human_centric_Interdependent_Cybersecurity/2024-06-11-Ollabench_Evaluating_LLMs_Reasoning_for_Human_centric_Interdependent_Cybersecurity.html#appendix",
    "title": "Ollabench: Evaluating LLMs’ Reasoning for Human-centric Interdependent Cybersecurity",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06863v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06863v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7305"
  },
  {
    "objectID": "posts/Compromising_Embodied_Agents_with_Contextual_Backdoor_Attacks/2024-08-06-Compromising_Embodied_Agents_with_Contextual_Backdoor_Attacks.html#appendix",
    "href": "posts/Compromising_Embodied_Agents_with_Contextual_Backdoor_Attacks/2024-08-06-Compromising_Embodied_Agents_with_Contextual_Backdoor_Attacks.html#appendix",
    "title": "Compromising Embodied Agents with Contextual Backdoor Attacks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02882v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02882v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14516"
  },
  {
    "objectID": "posts/Enhancing_Language_Model_Rationality_with_Bi_Directional_Deliberation_Reasoning/2024-07-08-Enhancing_Language_Model_Rationality_with_Bi_Directional_Deliberation_Reasoning.html#appendix",
    "href": "posts/Enhancing_Language_Model_Rationality_with_Bi_Directional_Deliberation_Reasoning/2024-07-08-Enhancing_Language_Model_Rationality_with_Bi_Directional_Deliberation_Reasoning.html#appendix",
    "title": "Enhancing Language Model Rationality with Bi-Directional Deliberation Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06112v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06112v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5655"
  },
  {
    "objectID": "posts/Enhancing_LLMs_Cognition_via_Structurization/2024-07-23-Enhancing_LLMs_Cognition_via_Structurization.html#appendix",
    "href": "posts/Enhancing_LLMs_Cognition_via_Structurization/2024-07-23-Enhancing_LLMs_Cognition_via_Structurization.html#appendix",
    "title": "Enhancing LLM’s Cognition via Structurization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16434v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16434v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10931"
  },
  {
    "objectID": "posts/LLM4MSR_An_LLM_Enhanced_Paradigm_for_Multi_Scenario_Recommendation/2024-06-18-LLM4MSR_An_LLM_Enhanced_Paradigm_for_Multi_Scenario_Recommendation.html#appendix",
    "href": "posts/LLM4MSR_An_LLM_Enhanced_Paradigm_for_Multi_Scenario_Recommendation/2024-06-18-LLM4MSR_An_LLM_Enhanced_Paradigm_for_Multi_Scenario_Recommendation.html#appendix",
    "title": "LLM4MSR: An LLM-Enhanced Paradigm for Multi-Scenario Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12529v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12529v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9061"
  },
  {
    "objectID": "posts/BiasAlert_A_Plug_and_play_Tool_for_Social_Bias_Detection_in_LLMs/2024-07-14-BiasAlert_A_Plug_and_play_Tool_for_Social_Bias_Detection_in_LLMs.html#appendix",
    "href": "posts/BiasAlert_A_Plug_and_play_Tool_for_Social_Bias_Detection_in_LLMs/2024-07-14-BiasAlert_A_Plug_and_play_Tool_for_Social_Bias_Detection_in_LLMs.html#appendix",
    "title": "BiasAlert: A Plug-and-play Tool for Social Bias Detection in LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10241v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10241v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5437"
  },
  {
    "objectID": "posts/Towards_Resilient_and_Efficient_LLMs_A_Comparative_Study_of_Efficiency_Performance_and_Adversarial_Robustness/2024-08-08-Towards_Resilient_and_Efficient_LLMs_A_Comparative_Study_of_Efficiency_Performance_and_Adversarial_Robustness.html#appendix",
    "href": "posts/Towards_Resilient_and_Efficient_LLMs_A_Comparative_Study_of_Efficiency_Performance_and_Adversarial_Robustness/2024-08-08-Towards_Resilient_and_Efficient_LLMs_A_Comparative_Study_of_Efficiency_Performance_and_Adversarial_Robustness.html#appendix",
    "title": "Towards Resilient and Efficient LLMs: A Comparative Study of Efficiency, Performance, and Adversarial Robustness",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04585v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04585v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4853"
  },
  {
    "objectID": "posts/Can_Editing_LLMs_Inject_Harm/2024-07-29-Can_Editing_LLMs_Inject_Harm.html#appendix",
    "href": "posts/Can_Editing_LLMs_Inject_Harm/2024-07-29-Can_Editing_LLMs_Inject_Harm.html#appendix",
    "title": "Can Editing LLMs Inject Harm?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20224v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20224v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9390"
  },
  {
    "objectID": "posts/Large_Language_Model_Aided_QoS_Prediction_for_Service_Recommendation/2024-08-05-Large_Language_Model_Aided_QoS_Prediction_for_Service_Recommendation.html#appendix",
    "href": "posts/Large_Language_Model_Aided_QoS_Prediction_for_Service_Recommendation/2024-08-05-Large_Language_Model_Aided_QoS_Prediction_for_Service_Recommendation.html#appendix",
    "title": "Large Language Model Aided QoS Prediction for Service Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02223v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02223v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6778"
  },
  {
    "objectID": "posts/Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering/2024-06-06-Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering.html",
    "href": "posts/Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering/2024-06-06-Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering.html",
    "title": "Tool-Planner: Dynamic Solution Tree Planning for Large Language Model with Tool Clustering",
    "section": "",
    "text": "Summary: The paper introduces Tool-Planner, a task-processing framework that groups tools based on their API functions into toolkits. This approach allows large language models (LLMs) to implement planning across various toolkits and reselect or adjust tools when a tool error occurs. The authors propose Tool-Planner to address the challenges of redundant error correction and designing a correct plan among multiple tools in tool learning. The experiments conducted demonstrate that Tool-Planner has a high pass and win rate across different datasets and optimizes the planning scheme for tool learning in models such as GPT-4 and Claude 3.\nMajor Findings: 1. Tool-Planner achieves state-of-the-art performance on five out of six datasets and shows competitive performance on the remaining dataset. 2. The method improves the pass rate by +8.8% and the win rate by +9.1% compared to the"
  },
  {
    "objectID": "posts/Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering/2024-06-06-Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering.html#appendix",
    "href": "posts/Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering/2024-06-06-Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering.html#appendix",
    "title": "Tool-Planner: Dynamic Solution Tree Planning for Large Language Model with Tool Clustering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03807v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03807v1\n\n\nTruncated\nTrue\n\n\nWord Count\n29774"
  },
  {
    "objectID": "posts/Learning_to_Ask_Informative_Questions_Enhancing_LLMs_with_Preference_Optimization_and_Expected_Information_Gain/2024-06-25-Learning_to_Ask_Informative_Questions_Enhancing_LLMs_with_Preference_Optimization_and_Expected_Information_Gain.html#appendix",
    "href": "posts/Learning_to_Ask_Informative_Questions_Enhancing_LLMs_with_Preference_Optimization_and_Expected_Information_Gain/2024-06-25-Learning_to_Ask_Informative_Questions_Enhancing_LLMs_with_Preference_Optimization_and_Expected_Information_Gain.html#appendix",
    "title": "Learning to Ask Informative Questions: Enhancing LLMs with Preference Optimization and Expected Information Gain",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17453v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17453v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5253"
  },
  {
    "objectID": "posts/RepoQA_Evaluating_Long_Context_Code_Understanding/2024-06-10-RepoQA_Evaluating_Long_Context_Code_Understanding.html#appendix",
    "href": "posts/RepoQA_Evaluating_Long_Context_Code_Understanding/2024-06-10-RepoQA_Evaluating_Long_Context_Code_Understanding.html#appendix",
    "title": "RepoQA: Evaluating Long Context Code Understanding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06025v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06025v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2740"
  },
  {
    "objectID": "posts/Can_Rule_Based_Insights_Enhance_LLMs_for_Radiology_Report_Classification_Introducing_the_RadPrompt_Methodology/2024-08-07-Can_Rule_Based_Insights_Enhance_LLMs_for_Radiology_Report_Classification_Introducing_the_RadPrompt_Methodology.html",
    "href": "posts/Can_Rule_Based_Insights_Enhance_LLMs_for_Radiology_Report_Classification_Introducing_the_RadPrompt_Methodology/2024-08-07-Can_Rule_Based_Insights_Enhance_LLMs_for_Radiology_Report_Classification_Introducing_the_RadPrompt_Methodology.html",
    "title": "Can Rule-Based Insights Enhance LLMs for Radiology Report Classification? Introducing the RadPrompt Methodology",
    "section": "",
    "text": "Summary:\nThis paper introduces RadPert, a rule-based system that integrates an uncertainty-aware information schema with a streamlined set of rules, enhancing performance in extracting structured labels from radiology reports. The authors also present RadPrompt, a multi-turn prompting strategy that leverages RadPert to bolster the zero-shot predictive capabilities of large language models (LLMs). RadPrompt achieves a statistically significant improvement in weighted average F1 score over GPT-4 Turbo and surpasses both its underlying models, showcasing the synergistic potential of LLMs with rule-based models. The methods have been evaluated on two English Corpora: the MIMIC-CXR gold-standard test set and a gold-standard dataset collected from the Cambridge University Hospitals.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/Can_Rule_Based_Insights_Enhance_LLMs_for_Radiology_Report_Classification_Introducing_the_RadPrompt_Methodology/2024-08-07-Can_Rule_Based_Insights_Enhance_LLMs_for_Radiology_Report_Classification_Introducing_the_RadPrompt_Methodology.html#appendix",
    "href": "posts/Can_Rule_Based_Insights_Enhance_LLMs_for_Radiology_Report_Classification_Introducing_the_RadPrompt_Methodology/2024-08-07-Can_Rule_Based_Insights_Enhance_LLMs_for_Radiology_Report_Classification_Introducing_the_RadPrompt_Methodology.html#appendix",
    "title": "Can Rule-Based Insights Enhance LLMs for Radiology Report Classification? Introducing the RadPrompt Methodology",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04121v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04121v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6498"
  },
  {
    "objectID": "posts/Breaking_Agents_Compromising_Autonomous_LLM_Agents_Through_Malfunction_Amplification/2024-07-30-Breaking_Agents_Compromising_Autonomous_LLM_Agents_Through_Malfunction_Amplification.html#appendix",
    "href": "posts/Breaking_Agents_Compromising_Autonomous_LLM_Agents_Through_Malfunction_Amplification/2024-07-30-Breaking_Agents_Compromising_Autonomous_LLM_Agents_Through_Malfunction_Amplification.html#appendix",
    "title": "Breaking Agents: Compromising Autonomous LLM Agents Through Malfunction Amplification",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20859v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20859v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11241"
  },
  {
    "objectID": "posts/Foundation_Models_for_Music_A_Survey/2024-08-26-Foundation_Models_for_Music_A_Survey.html",
    "href": "posts/Foundation_Models_for_Music_A_Survey/2024-08-26-Foundation_Models_for_Music_A_Survey.html",
    "title": "Foundation Models for Music: A Survey",
    "section": "",
    "text": "Summary:\nThe paper discusses the significance of foundation models (FMs) in music, which have the potential to address data scarcity, reduce annotation costs, and enhance generalisation in music information retrieval and creation. FMs can provide a better understanding of unseen structures, genres, or instruments, and contribute to the protection of the cultural heritage of music. The paper focuses on two types of self-supervisedly pre-trained foundation models: single-modality pre-trained models in the waveform or symbolic domain, and multimodal pre-trained models that can take both natural language and music as input.\nMajor Findings:"
  },
  {
    "objectID": "posts/Foundation_Models_for_Music_A_Survey/2024-08-26-Foundation_Models_for_Music_A_Survey.html#appendix",
    "href": "posts/Foundation_Models_for_Music_A_Survey/2024-08-26-Foundation_Models_for_Music_A_Survey.html#appendix",
    "title": "Foundation Models for Music: A Survey",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.14340v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.14340v1\n\n\nTruncated\nTrue\n\n\nWord Count\n74043"
  },
  {
    "objectID": "posts/ByteCheckpoint_A_Unified_Checkpointing_System_for_LLM_Development/2024-07-29-ByteCheckpoint_A_Unified_Checkpointing_System_for_LLM_Development.html#appendix",
    "href": "posts/ByteCheckpoint_A_Unified_Checkpointing_System_for_LLM_Development/2024-07-29-ByteCheckpoint_A_Unified_Checkpointing_System_for_LLM_Development.html#appendix",
    "title": "ByteCheckpoint: A Unified Checkpointing System for LLM Development",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20143v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20143v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10038"
  },
  {
    "objectID": "posts/Demystifying_Verbatim_Memorization_in_Large_Language_Models/2024-07-25-Demystifying_Verbatim_Memorization_in_Large_Language_Models.html#appendix",
    "href": "posts/Demystifying_Verbatim_Memorization_in_Large_Language_Models/2024-07-25-Demystifying_Verbatim_Memorization_in_Large_Language_Models.html#appendix",
    "title": "Demystifying Verbatim Memorization in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17817v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17817v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14802"
  },
  {
    "objectID": "posts/Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations/2024-07-03-Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations.html",
    "href": "posts/Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations/2024-07-03-Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations.html",
    "title": "Social Bias Evaluation for Large Language Models Requires Prompt Variations",
    "section": "",
    "text": "Summary:\nThis paper investigates the sensitivity of 12 large language models (LLMs) to prompt variations in evaluating task performance and social bias, focusing on a question-answering dataset, BBQ. The study categorizes three prompt variation factors: 1) task instruction and prompt for task recognition, 2) few-shot examples for task performance improvement, and 3) debias-prompt for bias mitigation. The experimental results reveal that LLMs are highly sensitive to prompts in bias evaluation, with the ranking of LLMs and debiasing effectiveness fluctuating when comparing models for task performance and bias scores. The study also shows that LLMs have tradeoffs among task performance and social bias caused by the prompts, and the ambiguity of instances contributes to the sensitivity in advanced LLMs.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive analysis of the sensitivity of LLMs to prompt variations in evaluating task performance and social bias. However, the study is limited to a single question-answering dataset, BBQ, and does not explore other types of datasets or tasks. Additionally, the paper does not discuss the potential impact of prompt variations on the fairness and ethical considerations of LLMs. Further research is needed to investigate the generalizability of the findings to other datasets and tasks and to explore the ethical implications of prompt variations in LLMs."
  },
  {
    "objectID": "posts/Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations/2024-07-03-Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations.html#appendix",
    "href": "posts/Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations/2024-07-03-Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations.html#appendix",
    "title": "Social Bias Evaluation for Large Language Models Requires Prompt Variations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03129v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03129v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17789"
  },
  {
    "objectID": "posts/Specify_and_Edit_Overcoming_Ambiguity_in_Text_Based_Image_Editing/2024-07-29-Specify_and_Edit_Overcoming_Ambiguity_in_Text_Based_Image_Editing.html",
    "href": "posts/Specify_and_Edit_Overcoming_Ambiguity_in_Text_Based_Image_Editing/2024-07-29-Specify_and_Edit_Overcoming_Ambiguity_in_Text_Based_Image_Editing.html",
    "title": "Specify and Edit: Overcoming Ambiguity in Text-Based Image Editing",
    "section": "",
    "text": "Summary:\nThe paper “Specify and Edit: Overcoming Ambiguity in Text-Based Image Editing” proposes a novel zero-shot inference pipeline called SANE (Specify ANd Edit) to improve the performance of diffusion-based text-to-image editing methods with ambiguous instructions. SANE leverages a large language model (LLM) to decompose ambiguous instructions into specific interventions, enhancing both interpretability and editing quality. The experiments conducted on two datasets demonstrate consistent performance improvements and increased output diversity. SANE is also versatile and can benefit both ambiguous and clear editing tasks.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a promising approach to addressing the limitations of diffusion-based text-to-image editing methods with ambiguous instructions. The use of a large language model to decompose ambiguous instructions into specific interventions is a novel and effective approach. The experiments conducted on two datasets demonstrate the effectiveness of SANE in improving editing quality and output diversity. However, the paper does not discuss the limitations of SANE, such as the difficulty in handling a high number of specific instructions and the lack of guarantee that each specific instruction is actually applied. Additionally, the paper does not provide a comparison with other methods that address ambiguity in text-based image editing. Overall, the paper presents a promising approach to addressing the limitations of diffusion-based text-to-image editing methods with ambiguous instructions."
  },
  {
    "objectID": "posts/Specify_and_Edit_Overcoming_Ambiguity_in_Text_Based_Image_Editing/2024-07-29-Specify_and_Edit_Overcoming_Ambiguity_in_Text_Based_Image_Editing.html#appendix",
    "href": "posts/Specify_and_Edit_Overcoming_Ambiguity_in_Text_Based_Image_Editing/2024-07-29-Specify_and_Edit_Overcoming_Ambiguity_in_Text_Based_Image_Editing.html#appendix",
    "title": "Specify and Edit: Overcoming Ambiguity in Text-Based Image Editing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20232v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20232v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17437"
  },
  {
    "objectID": "posts/Distributional_reasoning_in_LLMs_Parallel_reasoning_processes_in_multi_hop_reasoning/2024-06-19-Distributional_reasoning_in_LLMs_Parallel_reasoning_processes_in_multi_hop_reasoning.html#appendix",
    "href": "posts/Distributional_reasoning_in_LLMs_Parallel_reasoning_processes_in_multi_hop_reasoning/2024-06-19-Distributional_reasoning_in_LLMs_Parallel_reasoning_processes_in_multi_hop_reasoning.html#appendix",
    "title": "Distributional reasoning in LLMs: Parallel reasoning processes in multi-hop reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13858v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13858v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7199"
  },
  {
    "objectID": "posts/TrustNavGPT_Modeling_Uncertainty_to_Improve_Trustworthiness_of_Audio_Guided_LLM_Based_Robot_Navigation/2024-08-03-TrustNavGPT_Modeling_Uncertainty_to_Improve_Trustworthiness_of_Audio_Guided_LLM_Based_Robot_Navigation.html#appendix",
    "href": "posts/TrustNavGPT_Modeling_Uncertainty_to_Improve_Trustworthiness_of_Audio_Guided_LLM_Based_Robot_Navigation/2024-08-03-TrustNavGPT_Modeling_Uncertainty_to_Improve_Trustworthiness_of_Audio_Guided_LLM_Based_Robot_Navigation.html#appendix",
    "title": "TrustNavGPT: Modeling Uncertainty to Improve Trustworthiness of Audio-Guided LLM-Based Robot Navigation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.01867v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.01867v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6149"
  },
  {
    "objectID": "posts/You_still_have_to_study____On_the_Security_of_LLM_generated_code/2024-08-13-You_still_have_to_study____On_the_Security_of_LLM_generated_code.html",
    "href": "posts/You_still_have_to_study____On_the_Security_of_LLM_generated_code/2024-08-13-You_still_have_to_study____On_the_Security_of_LLM_generated_code.html",
    "title": "You still have to study – On the Security of LLM generated code",
    "section": "",
    "text": "Summary: This paper analyzes the security of code generated by four major Large Language Models (LLMs) in Python and JavaScript, using the MITRE CWE catalogue as a security definition. The results show that different prompting techniques can lead to up to 65% of the generated code being deemed insecure by a trained security engineer. However, with increasing manual guidance from a skilled engineer, almost all analyzed LLMs can generate code that is close to 100% secure.\nMajor Findings: 1. The study found that using different prompting techniques, some LLMs initially generate up to 65% code which is deemed insecure by a trained security engineer. 2. However, almost all analyzed LLMs will eventually generate code that is close to 100% secure with increasing manual guidance of a skilled engineer. 3. The study also found that the design of a case study showing an interactive, multi-user application accessible over a REST API, and the implementation of this application in Python and JavaScript using different prompting techniques for the current versions of ChatGPT, Copilot, CodeLLama, and CodeWhisperer Large Language Models (LLMs) can be used to evaluate the security of LLM-generated code.\nAnalysis and Critique: The paper provides a comprehensive analysis of the security of LLM-generated code, using a well-structured and coherent approach. The use of the MITRE CWE catalogue as a security definition is a strength of the study, as it provides a standardized framework for evaluating the security of the generated code. However, the study does not provide a detailed analysis of the limitations or potential biases of the LLMs used in the study. Additionally, the study does not discuss the potential impact of the quality of the training data on the security of the generated code. Further research is needed to address these limitations and to evaluate the security of LLM-generated code in other programming languages and contexts."
  },
  {
    "objectID": "posts/You_still_have_to_study____On_the_Security_of_LLM_generated_code/2024-08-13-You_still_have_to_study____On_the_Security_of_LLM_generated_code.html#appendix",
    "href": "posts/You_still_have_to_study____On_the_Security_of_LLM_generated_code/2024-08-13-You_still_have_to_study____On_the_Security_of_LLM_generated_code.html#appendix",
    "title": "You still have to study – On the Security of LLM generated code",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07106v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07106v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13606"
  },
  {
    "objectID": "posts/Large_Language_Model_Driven_Recommendation/2024-08-20-Large_Language_Model_Driven_Recommendation.html",
    "href": "posts/Large_Language_Model_Driven_Recommendation/2024-08-20-Large_Language_Model_Driven_Recommendation.html",
    "title": "Large Language Model Driven Recommendation",
    "section": "",
    "text": "Summary:\nThis chapter discusses the use of large language models (LLMs) in building highly personalized recommendation systems (RSs) that can effectively connect nuanced and diverse user preferences to items. The chapter presents a taxonomy of key data sources for language-driven recommendation, including item descriptions, user-system interactions, and user profiles. It then proceeds to fundamental techniques for LLM recommendation, reviewing the use of encoder-only and autoregressive LLM recommendation in both tuned and untuned settings. The chapter also covers multi-module recommendation architectures in which LLMs interact with components such as retrievers and RSs in multi-stage pipelines. Finally, the chapter discusses architectures for conversational recommender systems (CRSs), in which LLMs facilitate multi-turn dialogues where each turn presents an opportunity not only to make recommendations but also to engage with the user in interactive preference elicitation, critiquing, and question-answering.\nMajor Findings:\nAnalysis and Critique:\nWhile LLMs offer many opportunities for building highly personalized RSs, there are also potential limitations and challenges. For example, LLMs may hallucinate, generating outputs that are incorrect or misleading, which can create significant risks in settings where reliability is key. Additionally, our ability to control LLM behavior is limited, and prompt engineering and fine-tuning may not achieve total control. However, the chapter also discusses approaches to mitigate"
  },
  {
    "objectID": "posts/Large_Language_Model_Driven_Recommendation/2024-08-20-Large_Language_Model_Driven_Recommendation.html#appendix",
    "href": "posts/Large_Language_Model_Driven_Recommendation/2024-08-20-Large_Language_Model_Driven_Recommendation.html#appendix",
    "title": "Large Language Model Driven Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10946v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10946v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8885"
  },
  {
    "objectID": "posts/Proxona_Leveraging_LLM_Driven_Personas_to_Enhance_Creators_Understanding_of_Their_Audience/2024-08-20-Proxona_Leveraging_LLM_Driven_Personas_to_Enhance_Creators_Understanding_of_Their_Audience.html",
    "href": "posts/Proxona_Leveraging_LLM_Driven_Personas_to_Enhance_Creators_Understanding_of_Their_Audience/2024-08-20-Proxona_Leveraging_LLM_Driven_Personas_to_Enhance_Creators_Understanding_of_Their_Audience.html",
    "title": "Proxona: Leveraging LLM-Driven Personas to Enhance Creators’ Understanding of Their Audience",
    "section": "",
    "text": "Summary:\nProxona is a system that helps creators understand their audience by interacting with data-driven personas, represented with distinct dimensions and values. These personas are generated using large language models (LLMs) and are based on audience comments. The system was evaluated through a technical evaluation and a user study with 11 YouTube creators. The results showed that Proxona effectively generated relevant, distinct, audience-reflecting personas with evidence-based responses. The user study also found that Proxona helped creators better understand their audience and make informed decisions in their creative practices.\nMajor Findings:\nAnalysis and Critique:\nProxona’s use of LLMs to generate virtual audiences grounded on audience comments is a novel approach to understanding audience preferences. The system’s ability to cluster comments by the similarity of audience characteristics and minimize hallucinations in persona responses is a significant achievement. However, the system’s reliance on LLMs may introduce biases or inaccuracies in the generated personas. Additionally, the system’s effectiveness may be limited for creators with a small number of comments or those who do not have access to large-scale comment data. The system’s potential for scalability and generalizability to other creative domains beyond YouTube content creation is also worth exploring."
  },
  {
    "objectID": "posts/Proxona_Leveraging_LLM_Driven_Personas_to_Enhance_Creators_Understanding_of_Their_Audience/2024-08-20-Proxona_Leveraging_LLM_Driven_Personas_to_Enhance_Creators_Understanding_of_Their_Audience.html#appendix",
    "href": "posts/Proxona_Leveraging_LLM_Driven_Personas_to_Enhance_Creators_Understanding_of_Their_Audience/2024-08-20-Proxona_Leveraging_LLM_Driven_Personas_to_Enhance_Creators_Understanding_of_Their_Audience.html#appendix",
    "title": "Proxona: Leveraging LLM-Driven Personas to Enhance Creators’ Understanding of Their Audience",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10937v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10937v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17706"
  },
  {
    "objectID": "posts/A_System_for_Automated_Unit_Test_Generation_Using_Large_Language_Models_and_Assessment_of_Generated_Test_Suites/2024-08-14-A_System_for_Automated_Unit_Test_Generation_Using_Large_Language_Models_and_Assessment_of_Generated_Test_Suites.html#appendix",
    "href": "posts/A_System_for_Automated_Unit_Test_Generation_Using_Large_Language_Models_and_Assessment_of_Generated_Test_Suites/2024-08-14-A_System_for_Automated_Unit_Test_Generation_Using_Large_Language_Models_and_Assessment_of_Generated_Test_Suites.html#appendix",
    "title": "A System for Automated Unit Test Generation Using Large Language Models and Assessment of Generated Test Suites",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07846v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07846v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9465"
  },
  {
    "objectID": "posts/EERPD_Leveraging_Emotion_and_Emotion_Regulation_for_Improving_Personality_Detection/2024-06-23-EERPD_Leveraging_Emotion_and_Emotion_Regulation_for_Improving_Personality_Detection.html#appendix",
    "href": "posts/EERPD_Leveraging_Emotion_and_Emotion_Regulation_for_Improving_Personality_Detection/2024-06-23-EERPD_Leveraging_Emotion_and_Emotion_Regulation_for_Improving_Personality_Detection.html#appendix",
    "title": "EERPD: Leveraging Emotion and Emotion Regulation for Improving Personality Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16079v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16079v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5645"
  },
  {
    "objectID": "posts/Large_Language_Models_as_Recommender_Systems_A_Study_of_Popularity_Bias/2024-06-03-Large_Language_Models_as_Recommender_Systems_A_Study_of_Popularity_Bias.html#appendix",
    "href": "posts/Large_Language_Models_as_Recommender_Systems_A_Study_of_Popularity_Bias/2024-06-03-Large_Language_Models_as_Recommender_Systems_A_Study_of_Popularity_Bias.html#appendix",
    "title": "Large Language Models as Recommender Systems: A Study of Popularity Bias",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01285v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01285v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9391"
  },
  {
    "objectID": "posts/Data_Centric_AI_in_the_Age_of_Large_Language_Models/2024-06-20-Data_Centric_AI_in_the_Age_of_Large_Language_Models.html#major-findings",
    "href": "posts/Data_Centric_AI_in_the_Age_of_Large_Language_Models/2024-06-20-Data_Centric_AI_in_the_Age_of_Large_Language_Models.html#major-findings",
    "title": "Data-Centric AI in the Age of Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nData-Centric Benchmarks and Data Curation: The authors advocate for a suite of data-centric benchmarks tailored to the scale and complexity of data for LLMs. These benchmarks can be used to develop new data curation methods and document research efforts and results, which can help promote openness and transparency in AI and LLM research.\nData Attribution: The authors emphasize the importance of data attribution for legal and safety purposes, such as respecting copyright/intellectual property rights and mitigating problematic outputs of LLMs. They describe promising directions for data attribution and removal.\nKnowledge Transfer: The authors discuss the potential of transferring the knowledge of trained LLMs to compact and specialized models. They highlight existing efforts and new opportunities where the outputs of a trained LLM are treated as (synthesized) data.\nInference Contextualization with Data: The authors describe how LLMs can flexibly use data at inference to augment the outputs’ factuality or quality. They elaborate on this paradigm with respect to two prevalent technical frameworks and highlight how it can improve the personalization of LLMs."
  },
  {
    "objectID": "posts/Data_Centric_AI_in_the_Age_of_Large_Language_Models/2024-06-20-Data_Centric_AI_in_the_Age_of_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/Data_Centric_AI_in_the_Age_of_Large_Language_Models/2024-06-20-Data_Centric_AI_in_the_Age_of_Large_Language_Models.html#analysis-and-critique",
    "title": "Data-Centric AI in the Age of Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nLimited Research on Data-Centric Approaches: While the paper provides a comprehensive overview of the role of data in LLMs, it also highlights the lack of research in this area. The authors argue that the bulk of research to date has focused on modeling improvements, with little attention paid to how to best use data for the developmental and inferential stages of LLMs.\nChallenges in Data Attribution and Unlearning:"
  },
  {
    "objectID": "posts/Data_Centric_AI_in_the_Age_of_Large_Language_Models/2024-06-20-Data_Centric_AI_in_the_Age_of_Large_Language_Models.html#appendix",
    "href": "posts/Data_Centric_AI_in_the_Age_of_Large_Language_Models/2024-06-20-Data_Centric_AI_in_the_Age_of_Large_Language_Models.html#appendix",
    "title": "Data-Centric AI in the Age of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14473v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14473v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10052"
  },
  {
    "objectID": "posts/Towards_Robust_Alignment_of_Language_Models_Distributionally_Robustifying_Direct_Preference_Optimization/2024-07-10-Towards_Robust_Alignment_of_Language_Models_Distributionally_Robustifying_Direct_Preference_Optimization.html#appendix",
    "href": "posts/Towards_Robust_Alignment_of_Language_Models_Distributionally_Robustifying_Direct_Preference_Optimization/2024-07-10-Towards_Robust_Alignment_of_Language_Models_Distributionally_Robustifying_Direct_Preference_Optimization.html#appendix",
    "title": "Towards Robust Alignment of Language Models: Distributionally Robustifying Direct Preference Optimization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07880v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07880v1\n\n\nTruncated\nFalse\n\n\nWord Count\n21300"
  },
  {
    "objectID": "posts/Towards_Transfer_Unlearning_Empirical_Evidence_of_Cross_Domain_Bias_Mitigation/2024-07-24-Towards_Transfer_Unlearning_Empirical_Evidence_of_Cross_Domain_Bias_Mitigation.html#appendix",
    "href": "posts/Towards_Transfer_Unlearning_Empirical_Evidence_of_Cross_Domain_Bias_Mitigation/2024-07-24-Towards_Transfer_Unlearning_Empirical_Evidence_of_Cross_Domain_Bias_Mitigation.html#appendix",
    "title": "Towards Transfer Unlearning: Empirical Evidence of Cross-Domain Bias Mitigation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16951v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16951v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3584"
  },
  {
    "objectID": "posts/M2CVD_Multi_Model_Collaboration_for_Code_Vulnerability_Detection/2024-06-10-M2CVD_Multi_Model_Collaboration_for_Code_Vulnerability_Detection.html#appendix",
    "href": "posts/M2CVD_Multi_Model_Collaboration_for_Code_Vulnerability_Detection/2024-06-10-M2CVD_Multi_Model_Collaboration_for_Code_Vulnerability_Detection.html#appendix",
    "title": "M2CVD: Multi-Model Collaboration for Code Vulnerability Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05940v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05940v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9185"
  },
  {
    "objectID": "posts/ConvNLP_Image_based_AI_Text_Detection/2024-07-09-ConvNLP_Image_based_AI_Text_Detection.html#appendix",
    "href": "posts/ConvNLP_Image_based_AI_Text_Detection/2024-07-09-ConvNLP_Image_based_AI_Text_Detection.html#appendix",
    "title": "ConvNLP: Image-based AI Text Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07225v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07225v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5789"
  },
  {
    "objectID": "posts/Extend_Model_Merging_from_Fine_Tuned_to_Pre_Trained_Large_Language_Models_via_Weight_Disentanglement/2024-08-06-Extend_Model_Merging_from_Fine_Tuned_to_Pre_Trained_Large_Language_Models_via_Weight_Disentanglement.html#appendix",
    "href": "posts/Extend_Model_Merging_from_Fine_Tuned_to_Pre_Trained_Large_Language_Models_via_Weight_Disentanglement/2024-08-06-Extend_Model_Merging_from_Fine_Tuned_to_Pre_Trained_Large_Language_Models_via_Weight_Disentanglement.html#appendix",
    "title": "Extend Model Merging from Fine-Tuned to Pre-Trained Large Language Models via Weight Disentanglement",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03092v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03092v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8191"
  },
  {
    "objectID": "posts/Edge_Cloud_Collaborative_Motion_Planning_for_Autonomous_Driving_with_Large_Language_Models/2024-08-19-Edge_Cloud_Collaborative_Motion_Planning_for_Autonomous_Driving_with_Large_Language_Models.html#appendix",
    "href": "posts/Edge_Cloud_Collaborative_Motion_Planning_for_Autonomous_Driving_with_Large_Language_Models/2024-08-19-Edge_Cloud_Collaborative_Motion_Planning_for_Autonomous_Driving_with_Large_Language_Models.html#appendix",
    "title": "Edge-Cloud Collaborative Motion Planning for Autonomous Driving with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09972v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09972v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4056"
  },
  {
    "objectID": "posts/Fostering_Natural_Conversation_in_Large_Language_Models_with_NICO_a_Natural_Interactive_COnversation_dataset/2024-08-18-Fostering_Natural_Conversation_in_Large_Language_Models_with_NICO_a_Natural_Interactive_COnversation_dataset.html#appendix",
    "href": "posts/Fostering_Natural_Conversation_in_Large_Language_Models_with_NICO_a_Natural_Interactive_COnversation_dataset/2024-08-18-Fostering_Natural_Conversation_in_Large_Language_Models_with_NICO_a_Natural_Interactive_COnversation_dataset.html#appendix",
    "title": "Fostering Natural Conversation in Large Language Models with NICO: a Natural Interactive COnversation dataset",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09330v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09330v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6517"
  },
  {
    "objectID": "posts/Towards_more_realistic_evaluation_of_LLM_based_code_generation_an_experimental_study_and_beyond/2024-06-11-Towards_more_realistic_evaluation_of_LLM_based_code_generation_an_experimental_study_and_beyond.html#appendix",
    "href": "posts/Towards_more_realistic_evaluation_of_LLM_based_code_generation_an_experimental_study_and_beyond/2024-06-11-Towards_more_realistic_evaluation_of_LLM_based_code_generation_an_experimental_study_and_beyond.html#appendix",
    "title": "Towards more realistic evaluation of LLM-based code generation: an experimental study and beyond",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06918v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06918v1\n\n\nTruncated\nFalse\n\n\nWord Count\n0"
  },
  {
    "objectID": "posts/MetaLLM_A_High_performant_and_Cost_efficient_Dynamic_Framework_for_Wrapping_LLMs/2024-07-15-MetaLLM_A_High_performant_and_Cost_efficient_Dynamic_Framework_for_Wrapping_LLMs.html#appendix",
    "href": "posts/MetaLLM_A_High_performant_and_Cost_efficient_Dynamic_Framework_for_Wrapping_LLMs/2024-07-15-MetaLLM_A_High_performant_and_Cost_efficient_Dynamic_Framework_for_Wrapping_LLMs.html#appendix",
    "title": "MetaLLM: A High-performant and Cost-efficient Dynamic Framework for Wrapping LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10834v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10834v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5819"
  },
  {
    "objectID": "posts/Multimodal_Large_Language_Models_for_Phishing_Webpage_Detection_and_Identification/2024-08-12-Multimodal_Large_Language_Models_for_Phishing_Webpage_Detection_and_Identification.html",
    "href": "posts/Multimodal_Large_Language_Models_for_Phishing_Webpage_Detection_and_Identification/2024-08-12-Multimodal_Large_Language_Models_for_Phishing_Webpage_Detection_and_Identification.html",
    "title": "Multimodal Large Language Models for Phishing Webpage Detection and Identification",
    "section": "",
    "text": "Summary:\nThis paper explores the use of multimodal large language models (LLMs) for detecting phishing webpages. The authors propose a two-phase system that employs LLMs in both phases: the first phase focuses on brand identification, while the second verifies the domain. The study evaluates three state-of-the-art multimodal LLMs, namely GPT-4, GeminiPro 1.0, and Claude3, on their capability to assist with phishing detection. The results demonstrate that LLMs show promise in detecting phishing pages at high precision, while also providing explanations. The system also performs significantly better than a state-of-the-art brand-based phishing detection system and demonstrates robustness against two known adversarial attacks.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an innovative approach to phishing detection using multimodal LLMs. The authors provide a comprehensive evaluation of the proposed system, demonstrating its effectiveness in detecting phishing webpages and its robustness against adversarial attacks. However, the study does not discuss the potential limitations or biases of the LLMs used in the system. Additionally, the paper does not address the potential challenges in maintaining and updating the LLMs as new phishing techniques emerge. Further research is needed to explore these aspects and ensure the long-term effectiveness of the proposed system."
  },
  {
    "objectID": "posts/Multimodal_Large_Language_Models_for_Phishing_Webpage_Detection_and_Identification/2024-08-12-Multimodal_Large_Language_Models_for_Phishing_Webpage_Detection_and_Identification.html#appendix",
    "href": "posts/Multimodal_Large_Language_Models_for_Phishing_Webpage_Detection_and_Identification/2024-08-12-Multimodal_Large_Language_Models_for_Phishing_Webpage_Detection_and_Identification.html#appendix",
    "title": "Multimodal Large Language Models for Phishing Webpage Detection and Identification",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.05941v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.05941v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17527"
  },
  {
    "objectID": "posts/DiVERT_Distractor_Generation_with_Variational_Errors_Represented_as_Text_for_Math_Multiple_choice_Questions/2024-06-27-DiVERT_Distractor_Generation_with_Variational_Errors_Represented_as_Text_for_Math_Multiple_choice_Questions.html#appendix",
    "href": "posts/DiVERT_Distractor_Generation_with_Variational_Errors_Represented_as_Text_for_Math_Multiple_choice_Questions/2024-06-27-DiVERT_Distractor_Generation_with_Variational_Errors_Represented_as_Text_for_Math_Multiple_choice_Questions.html#appendix",
    "title": "DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19356v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19356v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9499"
  },
  {
    "objectID": "posts/Large_Language_Models_for_Base_Station_Siting_Intelligent_Deployment_based_on_Prompt_or_Agent/2024-08-07-Large_Language_Models_for_Base_Station_Siting_Intelligent_Deployment_based_on_Prompt_or_Agent.html",
    "href": "posts/Large_Language_Models_for_Base_Station_Siting_Intelligent_Deployment_based_on_Prompt_or_Agent/2024-08-07-Large_Language_Models_for_Base_Station_Siting_Intelligent_Deployment_based_on_Prompt_or_Agent.html",
    "title": "Large Language Models for Base Station Siting: Intelligent Deployment based on Prompt or Agent",
    "section": "",
    "text": "Summary:\nThe paper explores the use of large language models (LLMs) for base station siting (BSS) optimization, proposing four strategies: Prompt-optimized LLM (PoL), human-in-the-Loop LLM (HiLL), LLM-empowered autonomous BSS agent (LaBa), and Cooperative multiple LLM-based autonomous BSS agents (CLaBa). The PoL strategy uses crafted prompts to guide LLMs in autonomously accomplishing BSS tasks with minimal human intervention. The HiLL strategy simplifies user involvement by allowing users to express their needs in natural language. The LaBa strategy develops an autonomous agent to manage the entire BSS process, while the CLaBa strategy allows multiple agents to collaboratively solve the BSS problem. The proposed framework is evaluated using real-world data, demonstrating that LLM-based approaches can generate more efficient, cost-effective, and reliable network deployments.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/Large_Language_Models_for_Base_Station_Siting_Intelligent_Deployment_based_on_Prompt_or_Agent/2024-08-07-Large_Language_Models_for_Base_Station_Siting_Intelligent_Deployment_based_on_Prompt_or_Agent.html#appendix",
    "href": "posts/Large_Language_Models_for_Base_Station_Siting_Intelligent_Deployment_based_on_Prompt_or_Agent/2024-08-07-Large_Language_Models_for_Base_Station_Siting_Intelligent_Deployment_based_on_Prompt_or_Agent.html#appendix",
    "title": "Large Language Models for Base Station Siting: Intelligent Deployment based on Prompt or Agent",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03631v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03631v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8825"
  },
  {
    "objectID": "posts/Fine_grained_large_scale_content_recommendations_for_MSX_sellers/2024-07-09-Fine_grained_large_scale_content_recommendations_for_MSX_sellers.html#appendix",
    "href": "posts/Fine_grained_large_scale_content_recommendations_for_MSX_sellers/2024-07-09-Fine_grained_large_scale_content_recommendations_for_MSX_sellers.html#appendix",
    "title": "Fine-grained large-scale content recommendations for MSX sellers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06910v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06910v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4936"
  },
  {
    "objectID": "posts/BeeManc_at_the_PLABA_Track_of_TAC_2023_Investigating_LLMs_and_Controllable_Attributes_for_Improving_Biomedical_Text_Readability/2024-08-07-BeeManc_at_the_PLABA_Track_of_TAC_2023_Investigating_LLMs_and_Controllable_Attributes_for_Improving_Biomedical_Text_Readability.html#appendix",
    "href": "posts/BeeManc_at_the_PLABA_Track_of_TAC_2023_Investigating_LLMs_and_Controllable_Attributes_for_Improving_Biomedical_Text_Readability/2024-08-07-BeeManc_at_the_PLABA_Track_of_TAC_2023_Investigating_LLMs_and_Controllable_Attributes_for_Improving_Biomedical_Text_Readability.html#appendix",
    "title": "BeeManc at the PLABA Track of TAC-2023: Investigating LLMs and Controllable Attributes for Improving Biomedical Text Readability",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03871v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03871v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5132"
  },
  {
    "objectID": "posts/Instruct_Large_Language_Models_to_Drive_like_Humans/2024-06-11-Instruct_Large_Language_Models_to_Drive_like_Humans.html#appendix",
    "href": "posts/Instruct_Large_Language_Models_to_Drive_like_Humans/2024-06-11-Instruct_Large_Language_Models_to_Drive_like_Humans.html#appendix",
    "title": "Instruct Large Language Models to Drive like Humans",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07296v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07296v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5303"
  },
  {
    "objectID": "posts/Enhancing_Large_Language_Model_based_Speech_Recognition_by_Contextualization_for_Rare_and_Ambiguous_Words/2024-08-15-Enhancing_Large_Language_Model_based_Speech_Recognition_by_Contextualization_for_Rare_and_Ambiguous_Words.html#appendix",
    "href": "posts/Enhancing_Large_Language_Model_based_Speech_Recognition_by_Contextualization_for_Rare_and_Ambiguous_Words/2024-08-15-Enhancing_Large_Language_Model_based_Speech_Recognition_by_Contextualization_for_Rare_and_Ambiguous_Words.html#appendix",
    "title": "Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.08027v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.08027v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6678"
  },
  {
    "objectID": "posts/Language_models_are_robotic_planners_reframing_plans_as_goal_refinement_graphs/2024-07-22-Language_models_are_robotic_planners_reframing_plans_as_goal_refinement_graphs.html#appendix",
    "href": "posts/Language_models_are_robotic_planners_reframing_plans_as_goal_refinement_graphs/2024-07-22-Language_models_are_robotic_planners_reframing_plans_as_goal_refinement_graphs.html#appendix",
    "title": "Language models are robotic planners: reframing plans as goal refinement graphs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.15677v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.15677v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5999"
  },
  {
    "objectID": "posts/Leveraging_Large_Language_Models_for_Patient_Engagement_The_Power_of_Conversational_AI_in_Digital_Health/2024-06-19-Leveraging_Large_Language_Models_for_Patient_Engagement_The_Power_of_Conversational_AI_in_Digital_Health.html#appendix",
    "href": "posts/Leveraging_Large_Language_Models_for_Patient_Engagement_The_Power_of_Conversational_AI_in_Digital_Health/2024-06-19-Leveraging_Large_Language_Models_for_Patient_Engagement_The_Power_of_Conversational_AI_in_Digital_Health.html#appendix",
    "title": "Leveraging Large Language Models for Patient Engagement: The Power of Conversational AI in Digital Health",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13659v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13659v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7506"
  },
  {
    "objectID": "posts/Data_Augmentation_of_Multi_turn_Psychological_Dialogue_via_Knowledge_driven_Progressive_Thought_Prompting/2024-06-24-Data_Augmentation_of_Multi_turn_Psychological_Dialogue_via_Knowledge_driven_Progressive_Thought_Prompting.html#appendix",
    "href": "posts/Data_Augmentation_of_Multi_turn_Psychological_Dialogue_via_Knowledge_driven_Progressive_Thought_Prompting/2024-06-24-Data_Augmentation_of_Multi_turn_Psychological_Dialogue_via_Knowledge_driven_Progressive_Thought_Prompting.html#appendix",
    "title": "Data Augmentation of Multi-turn Psychological Dialogue via Knowledge-driven Progressive Thought Prompting",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16567v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16567v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4719"
  },
  {
    "objectID": "posts/Few_shot_Personalization_of_LLMs_with_Mis_aligned_Responses/2024-06-26-Few_shot_Personalization_of_LLMs_with_Mis_aligned_Responses.html#appendix",
    "href": "posts/Few_shot_Personalization_of_LLMs_with_Mis_aligned_Responses/2024-06-26-Few_shot_Personalization_of_LLMs_with_Mis_aligned_Responses.html#appendix",
    "title": "Few-shot Personalization of LLMs with Mis-aligned Responses",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18678v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18678v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11156"
  },
  {
    "objectID": "posts/MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models/2024-06-20-MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models.html#major-findings",
    "href": "posts/MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models/2024-06-20-MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models.html#major-findings",
    "title": "MR-BEN: A Comprehensive Meta-Reasoning Benchmark for Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nMr-Ben is a comprehensive benchmark that employs a meta-reasoning paradigm, where LLMs are challenged to reason about different forms of reasoning. This paradigm involves LLMs acting as teachers, evaluating the reasoning process by assessing correctness, analyzing potential errors, and providing corrections.\nThe analyses of various LLMs on Mr-Ben reveal distinct limitations and previously unidentified weaknesses in their reasoning abilities. While many LLMs can generate the correct answer to a question, they struggle to pinpoint errors in the reasoning process and correct them. This suggests that existing LLMs have yet to master reasoning, particularly the smaller models.\nTechniques such as the use of high-quality synthetic data can significantly improve reasoning abilities, offering a potential pathway to enhance performance regardless of model size. However, different LLMs excel in different reasoning paradigms, challenging the assumption that domain-specific enhancements necessarily lead to broad cognitive improvements."
  },
  {
    "objectID": "posts/MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models/2024-06-20-MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models/2024-06-20-MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models.html#analysis-and-critique",
    "title": "MR-BEN: A Comprehensive Meta-Reasoning Benchmark for Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nWhile Mr-Ben provides a comprehensive evaluation of LLMs’ reasoning abilities, it has some limitations. The benchmark’s applicability may be restricted when it comes to subjects that are inherently holistic or creative in nature, such as humanities or sociology. Additionally, Mr-Ben is currently confined to questions in English, which could potentially limit the scope of reasoning challenges that can be explored. Furthermore, the analysis and correction of errors in the reasoning steps are currently based on solutions generated by three LLMs, which may not represent the diverse reasoning and error patterns of different LLMs and individuals.\nMoreover, the benchmark may present potential negative societal impacts, such as the risk of LLMs being misused or used maliciously. For instance, LLMs with advanced reasoning capabilities could be used to manipulate information or deceive people. The use"
  },
  {
    "objectID": "posts/MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models/2024-06-20-MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models.html#appendix",
    "href": "posts/MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models/2024-06-20-MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models.html#appendix",
    "title": "MR-BEN: A Comprehensive Meta-Reasoning Benchmark for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13975v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13975v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8416"
  },
  {
    "objectID": "posts/Do_LLMs_Recognize_me_When_I_is_not_me_Assessment_of_LLMs_Understanding_of_Turkish_Indexical_Pronouns_in_Indexical_Shift_Contexts/2024-06-08-Do_LLMs_Recognize_me_When_I_is_not_me_Assessment_of_LLMs_Understanding_of_Turkish_Indexical_Pronouns_in_Indexical_Shift_Contexts.html#appendix",
    "href": "posts/Do_LLMs_Recognize_me_When_I_is_not_me_Assessment_of_LLMs_Understanding_of_Turkish_Indexical_Pronouns_in_Indexical_Shift_Contexts/2024-06-08-Do_LLMs_Recognize_me_When_I_is_not_me_Assessment_of_LLMs_Understanding_of_Turkish_Indexical_Pronouns_in_Indexical_Shift_Contexts.html#appendix",
    "title": "Do LLMs Recognize me, When I is not me: Assessment of LLMs Understanding of Turkish Indexical Pronouns in Indexical Shift Contexts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05569v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05569v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5917"
  },
  {
    "objectID": "posts/HITS_High_coverage_LLM_based_Unit_Test_Generation_via_Method_Slicing/2024-08-21-HITS_High_coverage_LLM_based_Unit_Test_Generation_via_Method_Slicing.html#appendix",
    "href": "posts/HITS_High_coverage_LLM_based_Unit_Test_Generation_via_Method_Slicing/2024-08-21-HITS_High_coverage_LLM_based_Unit_Test_Generation_via_Method_Slicing.html#appendix",
    "title": "HITS: High-coverage LLM-based Unit Test Generation via Method Slicing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11324v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11324v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8205"
  },
  {
    "objectID": "posts/Synth_Empathy_Towards_High_Quality_Synthetic_Empathy_Data/2024-07-31-Synth_Empathy_Towards_High_Quality_Synthetic_Empathy_Data.html#appendix",
    "href": "posts/Synth_Empathy_Towards_High_Quality_Synthetic_Empathy_Data/2024-07-31-Synth_Empathy_Towards_High_Quality_Synthetic_Empathy_Data.html#appendix",
    "title": "Synth-Empathy: Towards High-Quality Synthetic Empathy Data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21669v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21669v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6294"
  },
  {
    "objectID": "posts/How_Good_(Or_Bad)_Are_LLMs_at_Detecting_Misleading_Visualizations/2024-07-24-How_Good_(Or_Bad)_Are_LLMs_at_Detecting_Misleading_Visualizations.html#appendix",
    "href": "posts/How_Good_(Or_Bad)_Are_LLMs_at_Detecting_Misleading_Visualizations/2024-07-24-How_Good_(Or_Bad)_Are_LLMs_at_Detecting_Misleading_Visualizations.html#appendix",
    "title": "How Good (Or Bad) Are LLMs at Detecting Misleading Visualizations?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17291v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17291v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10270"
  },
  {
    "objectID": "posts/Identifying_Performance_Sensitive_Configurations_in_Software_Systems_through_Code_Analysis_with_LLM_Agents/2024-06-18-Identifying_Performance_Sensitive_Configurations_in_Software_Systems_through_Code_Analysis_with_LLM_Agents.html#appendix",
    "href": "posts/Identifying_Performance_Sensitive_Configurations_in_Software_Systems_through_Code_Analysis_with_LLM_Agents/2024-06-18-Identifying_Performance_Sensitive_Configurations_in_Software_Systems_through_Code_Analysis_with_LLM_Agents.html#appendix",
    "title": "Identifying Performance-Sensitive Configurations in Software Systems through Code Analysis with LLM Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12806v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12806v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9569"
  },
  {
    "objectID": "posts/Human_Speech_Perception_in_Noise_Can_Large_Language_Models_Paraphrase_to_Improve_It/2024-08-07-Human_Speech_Perception_in_Noise_Can_Large_Language_Models_Paraphrase_to_Improve_It.html#appendix",
    "href": "posts/Human_Speech_Perception_in_Noise_Can_Large_Language_Models_Paraphrase_to_Improve_It/2024-08-07-Human_Speech_Perception_in_Noise_Can_Large_Language_Models_Paraphrase_to_Improve_It.html#appendix",
    "title": "Human Speech Perception in Noise: Can Large Language Models Paraphrase to Improve It?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04029v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04029v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7832"
  },
  {
    "objectID": "posts/Key_Point_Driven_Mathematical_Reasoning_Distillation_of_Large_Language_Model/2024-07-14-Key_Point_Driven_Mathematical_Reasoning_Distillation_of_Large_Language_Model.html#appendix",
    "href": "posts/Key_Point_Driven_Mathematical_Reasoning_Distillation_of_Large_Language_Model/2024-07-14-Key_Point_Driven_Mathematical_Reasoning_Distillation_of_Large_Language_Model.html#appendix",
    "title": "Key-Point-Driven Mathematical Reasoning Distillation of Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10167v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10167v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8199"
  },
  {
    "objectID": "posts/SynCPKL_Harnessing_LLMs_to_Generate_Synthetic_Data_for_Commonsense_Persona_Knowledge_Linking/2024-07-21-SynCPKL_Harnessing_LLMs_to_Generate_Synthetic_Data_for_Commonsense_Persona_Knowledge_Linking.html#appendix",
    "href": "posts/SynCPKL_Harnessing_LLMs_to_Generate_Synthetic_Data_for_Commonsense_Persona_Knowledge_Linking/2024-07-21-SynCPKL_Harnessing_LLMs_to_Generate_Synthetic_Data_for_Commonsense_Persona_Knowledge_Linking.html#appendix",
    "title": "SynCPKL: Harnessing LLMs to Generate Synthetic Data for Commonsense Persona Knowledge Linking",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.15281v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.15281v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4249"
  },
  {
    "objectID": "posts/GANPrompt_Enhancing_Robustness_in_LLM_Based_Recommendations_with_GAN_Enhanced_Diversity_Prompts/2024-08-19-GANPrompt_Enhancing_Robustness_in_LLM_Based_Recommendations_with_GAN_Enhanced_Diversity_Prompts.html",
    "href": "posts/GANPrompt_Enhancing_Robustness_in_LLM_Based_Recommendations_with_GAN_Enhanced_Diversity_Prompts/2024-08-19-GANPrompt_Enhancing_Robustness_in_LLM_Based_Recommendations_with_GAN_Enhanced_Diversity_Prompts.html",
    "title": "GANPrompt: Enhancing Robustness in LLM-Based Recommendations with GAN-Enhanced Diversity Prompts",
    "section": "",
    "text": "Summary:\nGANPrompt is a novel framework that enhances the robustness of Large Language Models (LLMs) in recommender systems using Generative Adversarial Networks (GANs). The framework addresses the challenge of LLMs being highly susceptible to the influence of prompt words by training a multidimensional prompt generator capable of producing diverse prompts based on user behavioral data. These diverse prompts are then used to train the LLM, improving its performance in the face of unseen prompts. A mathematical theory-based diversity constraint mechanism ensures that the generated prompts are both highly diverse and relevant, semantically covering a wide range of user intentions.\nMajor Findings:\nAnalysis and Critique:\nWhile GANPrompt demonstrates promising results, there are potential limitations and areas for improvement. The framework’s reliance on GANs may introduce complexity and computational overhead. Additionally, the effectiveness of the diversity constraint mechanism may vary depending on the specific recommendation task and dataset. Future research could explore the applicability of GANPrompt to a wider range of recommendation tasks and investigate strategies to optimize the trade-off between diversity and relevance in prompt generation."
  },
  {
    "objectID": "posts/GANPrompt_Enhancing_Robustness_in_LLM_Based_Recommendations_with_GAN_Enhanced_Diversity_Prompts/2024-08-19-GANPrompt_Enhancing_Robustness_in_LLM_Based_Recommendations_with_GAN_Enhanced_Diversity_Prompts.html#appendix",
    "href": "posts/GANPrompt_Enhancing_Robustness_in_LLM_Based_Recommendations_with_GAN_Enhanced_Diversity_Prompts/2024-08-19-GANPrompt_Enhancing_Robustness_in_LLM_Based_Recommendations_with_GAN_Enhanced_Diversity_Prompts.html#appendix",
    "title": "GANPrompt: Enhancing Robustness in LLM-Based Recommendations with GAN-Enhanced Diversity Prompts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09671v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09671v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10110"
  },
  {
    "objectID": "posts/A_Comprehensive_Survey_on_the_Security_of_Smart_Grid_Challenges_Mitigations_and_Future_Research_Opportunities/2024-07-10-A_Comprehensive_Survey_on_the_Security_of_Smart_Grid_Challenges_Mitigations_and_Future_Research_Opportunities.html",
    "href": "posts/A_Comprehensive_Survey_on_the_Security_of_Smart_Grid_Challenges_Mitigations_and_Future_Research_Opportunities/2024-07-10-A_Comprehensive_Survey_on_the_Security_of_Smart_Grid_Challenges_Mitigations_and_Future_Research_Opportunities.html",
    "title": "A Comprehensive Survey on the Security of Smart Grid: Challenges, Mitigations, and Future Research Opportunities",
    "section": "",
    "text": "Summary:\nThis study provides a comprehensive review of smart grid security, focusing on system architectures, attack methodologies, defense strategies, and future research opportunities. The review includes an in-depth analysis of various attack vectors, with a focus on new attack surfaces introduced by advanced components in smart grids. The study also examines coordinated attacks that incorporate multiple attack strategies and exploit vulnerabilities across various smart grid components to increase their adverse impact. The review then investigates innovative detection and mitigation strategies, including game theory, graph theory, blockchain, and machine learning, discussing their advancements in counteracting evolving threats and associated research challenges. The study also covers a thorough examination of widely used machine learning-based mitigation strategies, analyzing their applications and research challenges across supervised, unsupervised, semi-supervised, ensemble, and reinforcement learning. Finally, the review outlines future research directions and explores new techniques and concerns, such as large language models (LLMs) and the emerging threat of adversarial machine learning in the future of smart grid security.\nMajor Findings:\nAnalysis and Critique:\nThis study provides a comprehensive review of smart grid security, highlighting the various attack vectors and innovative detection and mitigation strategies. However, the study does not provide a detailed analysis of the effectiveness of these strategies in real-world scenarios. Additionally, the study does not discuss the potential impact of emerging technologies, such as quantum computing and edge computing, on smart grid security. Furthermore, the study does not provide a detailed"
  },
  {
    "objectID": "posts/A_Comprehensive_Survey_on_the_Security_of_Smart_Grid_Challenges_Mitigations_and_Future_Research_Opportunities/2024-07-10-A_Comprehensive_Survey_on_the_Security_of_Smart_Grid_Challenges_Mitigations_and_Future_Research_Opportunities.html#appendix",
    "href": "posts/A_Comprehensive_Survey_on_the_Security_of_Smart_Grid_Challenges_Mitigations_and_Future_Research_Opportunities/2024-07-10-A_Comprehensive_Survey_on_the_Security_of_Smart_Grid_Challenges_Mitigations_and_Future_Research_Opportunities.html#appendix",
    "title": "A Comprehensive Survey on the Security of Smart Grid: Challenges, Mitigations, and Future Research Opportunities",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07966v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07966v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20054"
  },
  {
    "objectID": "posts/Is_Your_Model_Really_A_Good_Math_Reasoner_Evaluating_Mathematical_Reasoning_with_Checklist/2024-07-11-Is_Your_Model_Really_A_Good_Math_Reasoner_Evaluating_Mathematical_Reasoning_with_Checklist.html#appendix",
    "href": "posts/Is_Your_Model_Really_A_Good_Math_Reasoner_Evaluating_Mathematical_Reasoning_with_Checklist/2024-07-11-Is_Your_Model_Really_A_Good_Math_Reasoner_Evaluating_Mathematical_Reasoning_with_Checklist.html#appendix",
    "title": "Is Your Model Really A Good Math Reasoner? Evaluating Mathematical Reasoning with Checklist",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08733v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08733v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7531"
  },
  {
    "objectID": "posts/Adversarial_Contrastive_Decoding_Boosting_Safety_Alignment_of_Large_Language_Models_via_Opposite_Prompt_Optimization/2024-06-24-Adversarial_Contrastive_Decoding_Boosting_Safety_Alignment_of_Large_Language_Models_via_Opposite_Prompt_Optimization.html#appendix",
    "href": "posts/Adversarial_Contrastive_Decoding_Boosting_Safety_Alignment_of_Large_Language_Models_via_Opposite_Prompt_Optimization/2024-06-24-Adversarial_Contrastive_Decoding_Boosting_Safety_Alignment_of_Large_Language_Models_via_Opposite_Prompt_Optimization.html#appendix",
    "title": "Adversarial Contrastive Decoding: Boosting Safety Alignment of Large Language Models via Opposite Prompt Optimization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16743v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16743v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6567"
  },
  {
    "objectID": "posts/Evaluating_Large_Language_Model_based_Personal_Information_Extraction_and_Countermeasures/2024-08-14-Evaluating_Large_Language_Model_based_Personal_Information_Extraction_and_Countermeasures.html#major-findings",
    "href": "posts/Evaluating_Large_Language_Model_based_Personal_Information_Extraction_and_Countermeasures/2024-08-14-Evaluating_Large_Language_Model_based_Personal_Information_Extraction_and_Countermeasures.html#major-findings",
    "title": "Evaluating Large Language Model based Personal Information Extraction and Countermeasures",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nLLMs can be misused by attackers to accurately extract various personal information from personal profiles.\nLLMs outperform conventional methods at such extraction.\nPrompt injection can mitigate the risk of LLM-based PIE to a large extent and outperforms conventional countermeasures."
  },
  {
    "objectID": "posts/Evaluating_Large_Language_Model_based_Personal_Information_Extraction_and_Countermeasures/2024-08-14-Evaluating_Large_Language_Model_based_Personal_Information_Extraction_and_Countermeasures.html#analysis-and-critique",
    "href": "posts/Evaluating_Large_Language_Model_based_Personal_Information_Extraction_and_Countermeasures/2024-08-14-Evaluating_Large_Language_Model_based_Personal_Information_Extraction_and_Countermeasures.html#analysis-and-critique",
    "title": "Evaluating Large Language Model based Personal Information Extraction and Countermeasures",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe study provides a comprehensive analysis of the potential risks associated with LLM-based PIE and the effectiveness of prompt injection as a mitigation strategy. However, there are some limitations and areas for future work.\nFirstly, the study focuses on a limited number of LLMs and datasets, which may not fully capture the diversity and complexity of real-world scenarios. Future work could explore a wider range of LLMs and datasets to provide a more comprehensive evaluation.\nSecondly, the study does not consider the potential ethical and privacy implications of LLM-based PIE. For instance, the use of LLMs to extract personal information from publicly available profiles could infringe on individuals’ privacy rights and lead to unintended consequences. Future work could explore these ethical and privacy issues in more depth.\nThirdly, the study assumes that attackers have access to LLMs and the necessary technical expertise to use them for PIE. However, this may not always be the case in practice. Future work could explore the potential barriers to LLM-based PIE and the factors that may influence attackers’ decisions to use LLMs for this purpose.\nFinally, the study does not consider the potential for adaptive attacks that could bypass the prompt injection defense. Future work could explore the potential for such attacks and develop strategies to mitigate them.\nIn conclusion, the study provides valuable insights into the potential risks associated with LLM-based PIE and the effectiveness of prompt injection as a mitigation strategy. However, there are some limitations and areas"
  },
  {
    "objectID": "posts/Evaluating_Large_Language_Model_based_Personal_Information_Extraction_and_Countermeasures/2024-08-14-Evaluating_Large_Language_Model_based_Personal_Information_Extraction_and_Countermeasures.html#appendix",
    "href": "posts/Evaluating_Large_Language_Model_based_Personal_Information_Extraction_and_Countermeasures/2024-08-14-Evaluating_Large_Language_Model_based_Personal_Information_Extraction_and_Countermeasures.html#appendix",
    "title": "Evaluating Large Language Model based Personal Information Extraction and Countermeasures",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07291v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07291v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11301"
  },
  {
    "objectID": "posts/Towards_Large_Language_Model_Aided_Program_Refinement/2024-06-26-Towards_Large_Language_Model_Aided_Program_Refinement.html#appendix",
    "href": "posts/Towards_Large_Language_Model_Aided_Program_Refinement/2024-06-26-Towards_Large_Language_Model_Aided_Program_Refinement.html#appendix",
    "title": "Towards Large Language Model Aided Program Refinement",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18616v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18616v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5456"
  },
  {
    "objectID": "posts/A_First_Look_at_License_Compliance_Capability_of_LLMs_in_Code_Generation/2024-08-05-A_First_Look_at_License_Compliance_Capability_of_LLMs_in_Code_Generation.html#appendix",
    "href": "posts/A_First_Look_at_License_Compliance_Capability_of_LLMs_in_Code_Generation/2024-08-05-A_First_Look_at_License_Compliance_Capability_of_LLMs_in_Code_Generation.html#appendix",
    "title": "A First Look at License Compliance Capability of LLMs in Code Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02487v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02487v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9790"
  },
  {
    "objectID": "posts/New_Curriculum_New_Chance____Retrieval_Augmented_Generation_for_Lesson_Planning_in_Ugandan_Secondary_Schools._Prototype_Quality_Evaluation/2024-08-14-New_Curriculum_New_Chance____Retrieval_Augmented_Generation_for_Lesson_Planning_in_Ugandan_Secondary_Schools._Prototype_Quality_Evaluation.html#appendix",
    "href": "posts/New_Curriculum_New_Chance____Retrieval_Augmented_Generation_for_Lesson_Planning_in_Ugandan_Secondary_Schools._Prototype_Quality_Evaluation/2024-08-14-New_Curriculum_New_Chance____Retrieval_Augmented_Generation_for_Lesson_Planning_in_Ugandan_Secondary_Schools._Prototype_Quality_Evaluation.html#appendix",
    "title": "New Curriculum, New Chance – Retrieval Augmented Generation for Lesson Planning in Ugandan Secondary Schools. Prototype Quality Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07542v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07542v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9570"
  },
  {
    "objectID": "posts/LLM_Generated_Tips_Rival_Expert_Created_Tips_in_Helping_Students_Answer_Quantum_Computing_Questions/2024-07-24-LLM_Generated_Tips_Rival_Expert_Created_Tips_in_Helping_Students_Answer_Quantum_Computing_Questions.html#appendix",
    "href": "posts/LLM_Generated_Tips_Rival_Expert_Created_Tips_in_Helping_Students_Answer_Quantum_Computing_Questions/2024-07-24-LLM_Generated_Tips_Rival_Expert_Created_Tips_in_Helping_Students_Answer_Quantum_Computing_Questions.html#appendix",
    "title": "LLM-Generated Tips Rival Expert-Created Tips in Helping Students Answer Quantum-Computing Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17024v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17024v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10424"
  },
  {
    "objectID": "posts/On_the_Generalization_of_Preference_Learning_with_DPO/2024-08-06-On_the_Generalization_of_Preference_Learning_with_DPO.html#summary-1",
    "href": "posts/On_the_Generalization_of_Preference_Learning_with_DPO/2024-08-06-On_the_Generalization_of_Preference_Learning_with_DPO.html#summary-1",
    "title": "On the Generalization of Preference Learning with DPO",
    "section": "Summary:",
    "text": "Summary:\n\nThe paper introduces a new theoretical framework to analyze the generalization guarantees of models trained with direct preference optimization (DPO).\nThe framework focuses on the generalization of models after finite gradient steps, reflecting real-world LLM training practices.\nBy analyzing the reward margin associated with each sample and its trajectory throughout training, the authors can effectively bound the generalization error.\nThe paper provides learning guarantees showing that, under specific conditions, models trained with DPO can correctly discern preferred responses on unseen data with high probability.\nThese insights are empirically validated on contemporary LLMs."
  },
  {
    "objectID": "posts/On_the_Generalization_of_Preference_Learning_with_DPO/2024-08-06-On_the_Generalization_of_Preference_Learning_with_DPO.html#major-findings",
    "href": "posts/On_the_Generalization_of_Preference_Learning_with_DPO/2024-08-06-On_the_Generalization_of_Preference_Learning_with_DPO.html#major-findings",
    "title": "On the Generalization of Preference Learning with DPO",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe paper introduces a novel theoretical framework to examine the generalization properties of LLMs by approximating their reward dynamics.\nNew learning guarantees are provided on how DPO can correctly distinguish the preferences of training samples within finite gradient steps and generalize to new input samples with provably high probability.\nThe theoretical insights are empirically validated on contemporary LLMs and preference datasets containing diverse behaviors."
  },
  {
    "objectID": "posts/On_the_Generalization_of_Preference_Learning_with_DPO/2024-08-06-On_the_Generalization_of_Preference_Learning_with_DPO.html#analysis-and-critique",
    "href": "posts/On_the_Generalization_of_Preference_Learning_with_DPO/2024-08-06-On_the_Generalization_of_Preference_Learning_with_DPO.html#analysis-and-critique",
    "title": "On the Generalization of Preference Learning with DPO",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper provides a comprehensive analysis of the generalization behavior of preference learning from a rigorous theoretical standpoint.\nThe framework is specifically designed to examine the generalization properties of LLMs by approximating their reward dynamics.\nThe paper’s theoretical insights are empirically validated on contemporary LLMs, reinforcing their relevance to real-world applications.\nHowever, the paper does not discuss potential limitations, unanswered questions, or conflicting evidence that may arise while reviewing the text.\nAdditionally, the paper does not address methodological issues, areas that require further research, or clarification.\nThe paper’s focus on DPO may limit its applicability to other preference learning methods, and further research is needed to extend the framework to a more general class of objectives."
  },
  {
    "objectID": "posts/On_the_Generalization_of_Preference_Learning_with_DPO/2024-08-06-On_the_Generalization_of_Preference_Learning_with_DPO.html#appendix",
    "href": "posts/On_the_Generalization_of_Preference_Learning_with_DPO/2024-08-06-On_the_Generalization_of_Preference_Learning_with_DPO.html#appendix",
    "title": "On the Generalization of Preference Learning with DPO",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03459v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03459v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8715"
  },
  {
    "objectID": "posts/Lynx_An_Open_Source_Hallucination_Evaluation_Model/2024-07-11-Lynx_An_Open_Source_Hallucination_Evaluation_Model.html#appendix",
    "href": "posts/Lynx_An_Open_Source_Hallucination_Evaluation_Model/2024-07-11-Lynx_An_Open_Source_Hallucination_Evaluation_Model.html#appendix",
    "title": "Lynx: An Open Source Hallucination Evaluation Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08488v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08488v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6415"
  },
  {
    "objectID": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#major-findings",
    "href": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#major-findings",
    "title": "Digital Business Model Analysis Using a Large Language Model",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe study demonstrates the potential of using LLMs for analyzing and designing new business models, which is still an evolving field with scarce research.\nThe proposed method can support idea generation in digital business model design by learning patterns from the commonalities of DX cases and using this knowledge as a reference when considering DX initiatives.\nThe analysis examples show that LLM can effectively extract similar DX cases, not only within the same industry but also from different industries, and consider their commonalities to support the ideation of digital business models."
  },
  {
    "objectID": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#analysis-and-critique",
    "href": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#analysis-and-critique",
    "title": "Digital Business Model Analysis Using a Large Language Model",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe study’s findings are preliminary, and further research is needed to refine the analytical methods using advanced NLP technologies and broaden the examination of digital business models across a wider spectrum of industries.\nThe proposed method potentially offers companies easy access to insights into the use of digital technologies and business model innovations that have previously been less accessible.\nThe authors plan to develop a recommendation system, possibly implemented via chatbots, that could suggest similar cases to act as a catalyst for companies aiming to accelerate their DX efforts.\nThe study makes certain academic contributions by demonstrating the potential of this approach, but more research is needed to fully understand its implications and limitations."
  },
  {
    "objectID": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#appendix",
    "href": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#appendix",
    "title": "Digital Business Model Analysis Using a Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05741v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05741v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3431"
  },
  {
    "objectID": "posts/MBBQ_A_Dataset_for_Cross_Lingual_Comparison_of_Stereotypes_in_Generative_LLMs/2024-06-11-MBBQ_A_Dataset_for_Cross_Lingual_Comparison_of_Stereotypes_in_Generative_LLMs.html#appendix",
    "href": "posts/MBBQ_A_Dataset_for_Cross_Lingual_Comparison_of_Stereotypes_in_Generative_LLMs/2024-06-11-MBBQ_A_Dataset_for_Cross_Lingual_Comparison_of_Stereotypes_in_Generative_LLMs.html#appendix",
    "title": "MBBQ: A Dataset for Cross-Lingual Comparison of Stereotypes in Generative LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07243v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07243v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10630"
  },
  {
    "objectID": "posts/MSDiagnosis_An_EMR_based_Dataset_for_Clinical_Multi_Step_Diagnosis/2024-08-19-MSDiagnosis_An_EMR_based_Dataset_for_Clinical_Multi_Step_Diagnosis.html#major-findings",
    "href": "posts/MSDiagnosis_An_EMR_based_Dataset_for_Clinical_Multi_Step_Diagnosis/2024-08-19-MSDiagnosis_An_EMR_based_Dataset_for_Clinical_Multi_Step_Diagnosis.html#major-findings",
    "title": "MSDiagnosis: An EMR-based Dataset for Clinical Multi-Step Diagnosis",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe paper introduces a multi-step diagnostic task and annotates a clinical diagnostic dataset (MSDiagnosis) that includes primary diagnosis, differential diagnosis, and final diagnosis questions.\nThe authors propose a novel and effective framework that combines forward inference, backward inference, reflection, and refinement, enabling the LLM to self-evaluate and adjust its diagnostic results.\nThe experimental results demonstrate the effectiveness of the proposed method."
  },
  {
    "objectID": "posts/MSDiagnosis_An_EMR_based_Dataset_for_Clinical_Multi_Step_Diagnosis/2024-08-19-MSDiagnosis_An_EMR_based_Dataset_for_Clinical_Multi_Step_Diagnosis.html#analysis-and-critique",
    "href": "posts/MSDiagnosis_An_EMR_based_Dataset_for_Clinical_Multi_Step_Diagnosis/2024-08-19-MSDiagnosis_An_EMR_based_Dataset_for_Clinical_Multi_Step_Diagnosis.html#analysis-and-critique",
    "title": "MSDiagnosis: An EMR-based Dataset for Clinical Multi-Step Diagnosis",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper provides a comprehensive experimental analysis and suggests future research directions for this task.\nThe proposed method could be further improved by incorporating more advanced techniques for forward inference, backward inference, reflection, and refinement.\nThe proposed method could also be evaluated on other clinical diagnostic datasets to further validate its effectiveness.\nThe paper does not discuss the limitations of the proposed method, which could be a potential area for future research.\nThe paper does not provide a detailed comparison with other existing methods, which could be useful for understanding the advantages and disadvantages of the proposed method."
  },
  {
    "objectID": "posts/MSDiagnosis_An_EMR_based_Dataset_for_Clinical_Multi_Step_Diagnosis/2024-08-19-MSDiagnosis_An_EMR_based_Dataset_for_Clinical_Multi_Step_Diagnosis.html#appendix",
    "href": "posts/MSDiagnosis_An_EMR_based_Dataset_for_Clinical_Multi_Step_Diagnosis/2024-08-19-MSDiagnosis_An_EMR_based_Dataset_for_Clinical_Multi_Step_Diagnosis.html#appendix",
    "title": "MSDiagnosis: An EMR-based Dataset for Clinical Multi-Step Diagnosis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10039v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10039v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6755"
  },
  {
    "objectID": "posts/AssertionBench_A_Benchmark_to_Evaluate_Large_Language_Models_for_Assertion_Generation/2024-06-26-AssertionBench_A_Benchmark_to_Evaluate_Large_Language_Models_for_Assertion_Generation.html#appendix",
    "href": "posts/AssertionBench_A_Benchmark_to_Evaluate_Large_Language_Models_for_Assertion_Generation/2024-06-26-AssertionBench_A_Benchmark_to_Evaluate_Large_Language_Models_for_Assertion_Generation.html#appendix",
    "title": "AssertionBench: A Benchmark to Evaluate Large-Language Models for Assertion Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18627v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18627v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6426"
  },
  {
    "objectID": "posts/Evaluating_the_Semantic_Profiling_Abilities_of_LLMs_for_Natural_Language_Utterances_in_Data_Visualization/2024-07-08-Evaluating_the_Semantic_Profiling_Abilities_of_LLMs_for_Natural_Language_Utterances_in_Data_Visualization.html#appendix",
    "href": "posts/Evaluating_the_Semantic_Profiling_Abilities_of_LLMs_for_Natural_Language_Utterances_in_Data_Visualization/2024-07-08-Evaluating_the_Semantic_Profiling_Abilities_of_LLMs_for_Natural_Language_Utterances_in_Data_Visualization.html#appendix",
    "title": "Evaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06129v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06129v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6332"
  },
  {
    "objectID": "posts/Adversarial_Attacks_on_Large_Language_Models_in_Medicine/2024-06-18-Adversarial_Attacks_on_Large_Language_Models_in_Medicine.html#appendix",
    "href": "posts/Adversarial_Attacks_on_Large_Language_Models_in_Medicine/2024-06-18-Adversarial_Attacks_on_Large_Language_Models_in_Medicine.html#appendix",
    "title": "Adversarial Attacks on Large Language Models in Medicine",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12259v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12259v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9477"
  },
  {
    "objectID": "posts/SEAS_Self_Evolving_Adversarial_Safety_Optimization_for_Large_Language_Models/2024-08-05-SEAS_Self_Evolving_Adversarial_Safety_Optimization_for_Large_Language_Models.html#major-findings",
    "href": "posts/SEAS_Self_Evolving_Adversarial_Safety_Optimization_for_Large_Language_Models/2024-08-05-SEAS_Self_Evolving_Adversarial_Safety_Optimization_for_Large_Language_Models.html#major-findings",
    "title": "SEAS: Self-Evolving Adversarial Safety Optimization for Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe SEAS framework enhances the security of LLMs by iteratively improving the capabilities of the Red Team model and the safety of the Target model without requiring manual annotation.\nThe SEAS dataset, which includes various harmful, adversarial, and ambiguous harmless prompts, provides tools for the secure development and deployment of LLMs.\nAfter three iterations, the Target model achieves a security level close to that of GPT-4 while maintaining its general ability, and the Red Team model shows a 50.66% increase in ASR against Llama3-70B."
  },
  {
    "objectID": "posts/SEAS_Self_Evolving_Adversarial_Safety_Optimization_for_Large_Language_Models/2024-08-05-SEAS_Self_Evolving_Adversarial_Safety_Optimization_for_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/SEAS_Self_Evolving_Adversarial_Safety_Optimization_for_Large_Language_Models/2024-08-05-SEAS_Self_Evolving_Adversarial_Safety_Optimization_for_Large_Language_Models.html#analysis-and-critique",
    "title": "SEAS: Self-Evolving Adversarial Safety Optimization for Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper does not provide a detailed comparison of the SEAS framework with other existing adversarial frameworks, which could help to better understand its advantages and limitations.\nThe paper does not discuss the potential risks associated with the use of the SEAS framework, such as the possibility of generating harmful content or the misuse of the generated data.\nThe paper does not provide a detailed analysis of the computational resources required to implement the SEAS framework, which could be a limiting factor for its adoption in resource-constrained environments.\nThe paper does not discuss the potential impact of the SEAS framework on the fairness and bias of LLMs, which is an important consideration in the development of safe and reliable AI systems.\nThe paper does not provide a detailed analysis of the potential limitations of the SEAS dataset, such as the coverage of different types of adversarial attacks and the diversity of the generated"
  },
  {
    "objectID": "posts/SEAS_Self_Evolving_Adversarial_Safety_Optimization_for_Large_Language_Models/2024-08-05-SEAS_Self_Evolving_Adversarial_Safety_Optimization_for_Large_Language_Models.html#appendix",
    "href": "posts/SEAS_Self_Evolving_Adversarial_Safety_Optimization_for_Large_Language_Models/2024-08-05-SEAS_Self_Evolving_Adversarial_Safety_Optimization_for_Large_Language_Models.html#appendix",
    "title": "SEAS: Self-Evolving Adversarial Safety Optimization for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02632v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02632v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8981"
  },
  {
    "objectID": "posts/Prompt_Tuning_as_User_Inherent_Profile_Inference_Machine/2024-08-13-Prompt_Tuning_as_User_Inherent_Profile_Inference_Machine.html#appendix",
    "href": "posts/Prompt_Tuning_as_User_Inherent_Profile_Inference_Machine/2024-08-13-Prompt_Tuning_as_User_Inherent_Profile_Inference_Machine.html#appendix",
    "title": "Prompt Tuning as User Inherent Profile Inference Machine",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.06577v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.06577v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7611"
  },
  {
    "objectID": "posts/Banishing_LLM_Hallucinations_Requires_Rethinking_Generalization/2024-06-25-Banishing_LLM_Hallucinations_Requires_Rethinking_Generalization.html#appendix",
    "href": "posts/Banishing_LLM_Hallucinations_Requires_Rethinking_Generalization/2024-06-25-Banishing_LLM_Hallucinations_Requires_Rethinking_Generalization.html#appendix",
    "title": "Banishing LLM Hallucinations Requires Rethinking Generalization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17642v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17642v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5811"
  },
  {
    "objectID": "posts/Fast_Matrix_Multiplications_for_Lookup_Table_Quantized_LLMs/2024-07-15-Fast_Matrix_Multiplications_for_Lookup_Table_Quantized_LLMs.html#appendix",
    "href": "posts/Fast_Matrix_Multiplications_for_Lookup_Table_Quantized_LLMs/2024-07-15-Fast_Matrix_Multiplications_for_Lookup_Table_Quantized_LLMs.html#appendix",
    "title": "Fast Matrix Multiplications for Lookup Table-Quantized LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10960v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10960v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7852"
  },
  {
    "objectID": "posts/Lifelong_Robot_Library_Learning_Bootstrapping_Composable_and_Generalizable_Skills_for_Embodied_Control_with_Language_Models/2024-06-26-Lifelong_Robot_Library_Learning_Bootstrapping_Composable_and_Generalizable_Skills_for_Embodied_Control_with_Language_Models.html#appendix",
    "href": "posts/Lifelong_Robot_Library_Learning_Bootstrapping_Composable_and_Generalizable_Skills_for_Embodied_Control_with_Language_Models/2024-06-26-Lifelong_Robot_Library_Learning_Bootstrapping_Composable_and_Generalizable_Skills_for_Embodied_Control_with_Language_Models.html#appendix",
    "title": "Lifelong Robot Library Learning: Bootstrapping Composable and Generalizable Skills for Embodied Control with Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18746v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18746v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6688"
  },
  {
    "objectID": "posts/Self_Directed_Turing_Test_for_Large_Language_Models/2024-08-19-Self_Directed_Turing_Test_for_Large_Language_Models.html#appendix",
    "href": "posts/Self_Directed_Turing_Test_for_Large_Language_Models/2024-08-19-Self_Directed_Turing_Test_for_Large_Language_Models.html#appendix",
    "title": "Self-Directed Turing Test for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09853v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09853v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6333"
  },
  {
    "objectID": "posts/Adaptable_Logical_Control_for_Large_Language_Models/2024-06-19-Adaptable_Logical_Control_for_Large_Language_Models.html#appendix",
    "href": "posts/Adaptable_Logical_Control_for_Large_Language_Models/2024-06-19-Adaptable_Logical_Control_for_Large_Language_Models.html#appendix",
    "title": "Adaptable Logical Control for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13892v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13892v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7583"
  },
  {
    "objectID": "posts/Cocobo_Exploring_Large_Language_Models_as_the_Engine_for_End_User_Robot_Programming/2024-07-30-Cocobo_Exploring_Large_Language_Models_as_the_Engine_for_End_User_Robot_Programming.html#major-findings",
    "href": "posts/Cocobo_Exploring_Large_Language_Models_as_the_Engine_for_End_User_Robot_Programming/2024-07-30-Cocobo_Exploring_Large_Language_Models_as_the_Engine_for_End_User_Robot_Programming.html#major-findings",
    "title": "Cocobo: Exploring Large Language Models as the Engine for End-User Robot Programming",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nCocobo has a low learning curve, enabling even users with zero coding experience to customize robot programs successfully.\nThe system’s conversational interface is perceived as natural and intelligent, enhancing the programming experience by making it seem like collaborative coding with the system.\nThe flowchart interface is found to be intuitive for representing code, helping users quickly understand the main steps and key information without extensive reading."
  },
  {
    "objectID": "posts/Cocobo_Exploring_Large_Language_Models_as_the_Engine_for_End_User_Robot_Programming/2024-07-30-Cocobo_Exploring_Large_Language_Models_as_the_Engine_for_End_User_Robot_Programming.html#analysis-and-critique",
    "href": "posts/Cocobo_Exploring_Large_Language_Models_as_the_Engine_for_End_User_Robot_Programming/2024-07-30-Cocobo_Exploring_Large_Language_Models_as_the_Engine_for_End_User_Robot_Programming.html#analysis-and-critique",
    "title": "Cocobo: Exploring Large Language Models as the Engine for End-User Robot Programming",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe study only integrated basic robotic commands and did not extend to more complex IoT and network services, which may limit scalability.\nLLM-powered functions in Cocobo experienced issues with unstable outputs and prolonged response times due to excessively lengthy outputs.\nThe current design does not account for varying levels of programming skills among users, which may limit its effectiveness in practical scenarios.\nThe system lacks an in-depth comparison and analysis of the various representations within the Cocobo system.\nFuture work should focus on enhancing the performance of Cocobo’s LLM-powered functions, expanding the system to support additional APIs for robots and IoT devices, and conducting ‘in-the-wild’ experiments to assess the practical benefits and potential improvements"
  },
  {
    "objectID": "posts/Cocobo_Exploring_Large_Language_Models_as_the_Engine_for_End_User_Robot_Programming/2024-07-30-Cocobo_Exploring_Large_Language_Models_as_the_Engine_for_End_User_Robot_Programming.html#appendix",
    "href": "posts/Cocobo_Exploring_Large_Language_Models_as_the_Engine_for_End_User_Robot_Programming/2024-07-30-Cocobo_Exploring_Large_Language_Models_as_the_Engine_for_End_User_Robot_Programming.html#appendix",
    "title": "Cocobo: Exploring Large Language Models as the Engine for End-User Robot Programming",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20712v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20712v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4048"
  },
  {
    "objectID": "posts/How_Well_Do_Large_Language_Models_Serve_as_End_to_End_Secure_Code_Producers/2024-08-20-How_Well_Do_Large_Language_Models_Serve_as_End_to_End_Secure_Code_Producers.html#appendix",
    "href": "posts/How_Well_Do_Large_Language_Models_Serve_as_End_to_End_Secure_Code_Producers/2024-08-20-How_Well_Do_Large_Language_Models_Serve_as_End_to_End_Secure_Code_Producers.html#appendix",
    "title": "How Well Do Large Language Models Serve as End-to-End Secure Code Producers?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10495v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10495v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11571"
  },
  {
    "objectID": "posts/To_Code_or_Not_To_Code_Exploring_Impact_of_Code_in_Pre_training/2024-08-20-To_Code_or_Not_To_Code_Exploring_Impact_of_Code_in_Pre_training.html#appendix",
    "href": "posts/To_Code_or_Not_To_Code_Exploring_Impact_of_Code_in_Pre_training/2024-08-20-To_Code_or_Not_To_Code_Exploring_Impact_of_Code_in_Pre_training.html#appendix",
    "title": "To Code, or Not To Code? Exploring Impact of Code in Pre-training",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10914v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10914v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3631"
  },
  {
    "objectID": "posts/Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs/2024-06-20-Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs.html#major-findings",
    "href": "posts/Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs/2024-06-20-Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs.html#major-findings",
    "title": "Taxonomy-Guided Zero-Shot Recommendations with LLMs",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe use of a taxonomy dictionary provides a systematic framework for categorizing and organizing items, enhancing the structure and clarity of item information.\nThe TaxRec approach, which uses taxonomy to retrieve knowledge and enhance LLMs’ ability as personal recommenders, significantly improves recommendation quality compared to current zero-shot recommenders.\nThe two-step process of TaxRec, which includes one-time taxonomy categorization and LLM-based recommendation, effectively handles large item pools and makes the recommendation process more efficient, accurate, and scalable."
  },
  {
    "objectID": "posts/Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs/2024-06-20-Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs.html#analysis-and-critique",
    "href": "posts/Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs/2024-06-20-Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs.html#analysis-and-critique",
    "title": "Taxonomy-Guided Zero-Shot Recommendations with LLMs",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper does not discuss the potential limitations of the proposed method, such as the quality and completeness of the taxonomy generated by LLMs and the sufficiency of LLMs’ domain knowledge in certain areas.\nThe paper does not provide a comparison of the proposed method with other taxonomy-based recommendation approaches, which could have helped to better understand the advantages and disadvantages of the proposed method.\nThe paper does not discuss the potential impact of the proposed method on the computational resources required for generating recommendations, which is an important consideration in practical applications.\nThe paper does not provide a detailed analysis of the experimental results, such as the impact of different taxonomy categories on the recommendation quality and the performance of the method in different application domains.\nThe paper does not discuss the potential ethical implications of using LLMs for recommendation,"
  },
  {
    "objectID": "posts/Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs/2024-06-20-Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs.html#appendix",
    "href": "posts/Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs/2024-06-20-Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs.html#appendix",
    "title": "Taxonomy-Guided Zero-Shot Recommendations with LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14043v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14043v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5941"
  },
  {
    "objectID": "posts/CrowdMoGen_Zero_Shot_Text_Driven_Collective_Motion_Generation/2024-07-08-CrowdMoGen_Zero_Shot_Text_Driven_Collective_Motion_Generation.html#appendix",
    "href": "posts/CrowdMoGen_Zero_Shot_Text_Driven_Collective_Motion_Generation/2024-07-08-CrowdMoGen_Zero_Shot_Text_Driven_Collective_Motion_Generation.html#appendix",
    "title": "CrowdMoGen: Zero-Shot Text-Driven Collective Motion Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06188v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06188v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6649"
  },
  {
    "objectID": "posts/Chain_of_Probe_Examing_the_Necessity_and_Accuracy_of_CoT_Step_by_Step/2024-06-23-Chain_of_Probe_Examing_the_Necessity_and_Accuracy_of_CoT_Step_by_Step.html",
    "href": "posts/Chain_of_Probe_Examing_the_Necessity_and_Accuracy_of_CoT_Step_by_Step/2024-06-23-Chain_of_Probe_Examing_the_Necessity_and_Accuracy_of_CoT_Step_by_Step.html",
    "title": "Chain-of-Probe: Examing the Necessity and Accuracy of CoT Step-by-Step",
    "section": "",
    "text": "Summary:\nThe paper proposes a method called Chain-of-Probe (CoP) to examine the necessity and accuracy of Chain-of-Thought (CoT) in large language models (LLMs). The authors address the issue of early answering, where LLMs already have an answer before generating the CoT, and investigate the underlying causes of this phenomenon. The study reveals that early answering is linked to question difficulty, with models tending to predict answers in advance for simpler questions, making CoT unnecessary for simple tasks. The authors propose the CoP Score to evaluate and select CoTs, aiming for more positive improvements.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a novel method, CoP, to detect changes in model thoughts and addresses the issue of early answering in LLMs. However, the study has some limitations. First, CoP currently only applies to multiple-choice questions or questions where the answer is a single token, making it challenging to define the model’s confidence in the final prediction when the target word exceeds one token. Second, regarding the necessity of CoT, it is difficult to determine in advance whether a task is simple, making it impossible to pre-judge whether CoT is needed for a particular question. Lastly, concerning the accuracy of CoT, the CoP Tree has high precision but relatively low recall, leading to an increase in the number of samples needed.\nThe paper also raises ethical concerns regarding the use of GPT-4 as an evaluator. While the authors prioritize transparency, accountability, and mitigation of potential biases, the limitations of AI should be acknowledged, and it should supplement rather than replace human judgment.\nOverall, the paper provides valuable insights into the necessity and accuracy of CoT in LLMs and proposes a novel method to address the issue of early answering. However, further research is needed to overcome the limitations and ethical concerns raised in the study."
  },
  {
    "objectID": "posts/Chain_of_Probe_Examing_the_Necessity_and_Accuracy_of_CoT_Step_by_Step/2024-06-23-Chain_of_Probe_Examing_the_Necessity_and_Accuracy_of_CoT_Step_by_Step.html#appendix",
    "href": "posts/Chain_of_Probe_Examing_the_Necessity_and_Accuracy_of_CoT_Step_by_Step/2024-06-23-Chain_of_Probe_Examing_the_Necessity_and_Accuracy_of_CoT_Step_by_Step.html#appendix",
    "title": "Chain-of-Probe: Examing the Necessity and Accuracy of CoT Step-by-Step",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16144v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16144v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6521"
  },
  {
    "objectID": "posts/Automating_Thought_of_Search_A_Journey_Towards_Soundness_and_Completeness/2024-08-21-Automating_Thought_of_Search_A_Journey_Towards_Soundness_and_Completeness.html",
    "href": "posts/Automating_Thought_of_Search_A_Journey_Towards_Soundness_and_Completeness/2024-08-21-Automating_Thought_of_Search_A_Journey_Towards_Soundness_and_Completeness.html",
    "title": "Automating Thought of Search: A Journey Towards Soundness and Completeness",
    "section": "",
    "text": "Summary:\nThe paper “Automating Thought of Search: A Journey Towards Soundness and Completeness” by Daniel Cao et al. introduces a method called AutoToS, which aims to automate the process of solving planning problems using large language models (LLMs). Unlike previous approaches, AutoToS defines the search space with code generated by the LLMs. The authors claim that their method achieves 100% accuracy with minimal feedback iterations, using LLMs of various sizes on all evaluated domains. The paper also discusses related works, background, and the proposed approach and methodology in detail.\nMajor Findings:"
  },
  {
    "objectID": "posts/Automating_Thought_of_Search_A_Journey_Towards_Soundness_and_Completeness/2024-08-21-Automating_Thought_of_Search_A_Journey_Towards_Soundness_and_Completeness.html#appendix",
    "href": "posts/Automating_Thought_of_Search_A_Journey_Towards_Soundness_and_Completeness/2024-08-21-Automating_Thought_of_Search_A_Journey_Towards_Soundness_and_Completeness.html#appendix",
    "title": "Automating Thought of Search: A Journey Towards Soundness and Completeness",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11326v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11326v1\n\n\nTruncated\nTrue\n\n\nWord Count\n33273"
  },
  {
    "objectID": "posts/Reinforcement_Learning_from_Human_Feedback_without_Reward_Inference_Model_Free_Algorithm_and_Instance_Dependent_Analysis/2024-06-11-Reinforcement_Learning_from_Human_Feedback_without_Reward_Inference_Model_Free_Algorithm_and_Instance_Dependent_Analysis.html#appendix",
    "href": "posts/Reinforcement_Learning_from_Human_Feedback_without_Reward_Inference_Model_Free_Algorithm_and_Instance_Dependent_Analysis/2024-06-11-Reinforcement_Learning_from_Human_Feedback_without_Reward_Inference_Model_Free_Algorithm_and_Instance_Dependent_Analysis.html#appendix",
    "title": "Reinforcement Learning from Human Feedback without Reward Inference: Model-Free Algorithm and Instance-Dependent Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07455v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07455v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11143"
  },
  {
    "objectID": "posts/Exploring_Reasoning_Biases_in_Large_Language_Models_Through_Syllogism_Insights_from_the_NeuBAROCO_Dataset/2024-08-08-Exploring_Reasoning_Biases_in_Large_Language_Models_Through_Syllogism_Insights_from_the_NeuBAROCO_Dataset.html",
    "href": "posts/Exploring_Reasoning_Biases_in_Large_Language_Models_Through_Syllogism_Insights_from_the_NeuBAROCO_Dataset/2024-08-08-Exploring_Reasoning_Biases_in_Large_Language_Models_Through_Syllogism_Insights_from_the_NeuBAROCO_Dataset.html",
    "title": "Exploring Reasoning Biases in Large Language Models Through Syllogism: Insights from the NeuBAROCO Dataset",
    "section": "",
    "text": "Summary:\nThis paper explores the logical reasoning abilities of large language models (LLMs) in natural language, focusing on syllogistic reasoning. The authors present a syllogism dataset called NeuBAROCO, which consists of syllogistic reasoning problems in English and Japanese. The dataset was originally designed for psychological experiments to assess human reasoning capabilities. The study’s experiments with leading LLMs indicate that these models exhibit reasoning biases similar to humans, along with other error tendencies. The primary limitations of LLMs lie in the reasoning process itself rather than the interpretation of syllogisms.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/Exploring_Reasoning_Biases_in_Large_Language_Models_Through_Syllogism_Insights_from_the_NeuBAROCO_Dataset/2024-08-08-Exploring_Reasoning_Biases_in_Large_Language_Models_Through_Syllogism_Insights_from_the_NeuBAROCO_Dataset.html#appendix",
    "href": "posts/Exploring_Reasoning_Biases_in_Large_Language_Models_Through_Syllogism_Insights_from_the_NeuBAROCO_Dataset/2024-08-08-Exploring_Reasoning_Biases_in_Large_Language_Models_Through_Syllogism_Insights_from_the_NeuBAROCO_Dataset.html#appendix",
    "title": "Exploring Reasoning Biases in Large Language Models Through Syllogism: Insights from the NeuBAROCO Dataset",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04403v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04403v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7155"
  },
  {
    "objectID": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#major-findings",
    "href": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#major-findings",
    "title": "World Models with Hints of Large Language Models for Goal Achieving",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nDLLM integrates hinting subgoals from LLMs into the model rollouts to encourage goal discovery and reaching in challenging tasks.\nDLLM assigns higher intrinsic rewards to samples that align with the hints outlined by the language model during model rollouts.\nDLLM outperforms recent methods in various challenging, sparse-reward environments such as HomeGrid, Crafter, and Minecraft."
  },
  {
    "objectID": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#analysis-and-critique",
    "href": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#analysis-and-critique",
    "title": "World Models with Hints of Large Language Models for Goal Achieving",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents an innovative approach to addressing the challenges of long-horizon tasks and sparse rewards in RL. The use of LLMs to provide hinting subgoals is a promising direction for improving exploration and goal-reaching in complex environments. However, the paper does not discuss potential limitations or biases in the LLMs used, which could impact the performance of DLLM. Additionally, the paper does not provide a detailed comparison with other methods that use intrinsic rewards or LLMs for goal-setting. Further research is needed to evaluate the robustness and generalizability of DLLM in different environments and tasks."
  },
  {
    "objectID": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#appendix",
    "href": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#appendix",
    "title": "World Models with Hints of Large Language Models for Goal Achieving",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07381v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07381v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10623"
  },
  {
    "objectID": "posts/Sibyl_Simple_yet_Effective_Agent_Framework_for_Complex_Real_world_Reasoning/2024-07-15-Sibyl_Simple_yet_Effective_Agent_Framework_for_Complex_Real_world_Reasoning.html#appendix",
    "href": "posts/Sibyl_Simple_yet_Effective_Agent_Framework_for_Complex_Real_world_Reasoning/2024-07-15-Sibyl_Simple_yet_Effective_Agent_Framework_for_Complex_Real_world_Reasoning.html#appendix",
    "title": "Sibyl: Simple yet Effective Agent Framework for Complex Real-world Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10718v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10718v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6597"
  },
  {
    "objectID": "posts/IDA_Breaking_Barriers_in_No_code_UI_Automation_Through_Large_Language_Models_and_Human_Centric_Design/2024-07-23-IDA_Breaking_Barriers_in_No_code_UI_Automation_Through_Large_Language_Models_and_Human_Centric_Design.html#appendix",
    "href": "posts/IDA_Breaking_Barriers_in_No_code_UI_Automation_Through_Large_Language_Models_and_Human_Centric_Design/2024-07-23-IDA_Breaking_Barriers_in_No_code_UI_Automation_Through_Large_Language_Models_and_Human_Centric_Design.html#appendix",
    "title": "IDA: Breaking Barriers in No-code UI Automation Through Large Language Models and Human-Centric Design",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.15673v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.15673v2\n\n\nTruncated\nFalse\n\n\nWord Count\n8577"
  },
  {
    "objectID": "posts/Understanding_Different_Design_Choices_in_Training_Large_Time_Series_Models/2024-06-20-Understanding_Different_Design_Choices_in_Training_Large_Time_Series_Models.html#appendix",
    "href": "posts/Understanding_Different_Design_Choices_in_Training_Large_Time_Series_Models/2024-06-20-Understanding_Different_Design_Choices_in_Training_Large_Time_Series_Models.html#appendix",
    "title": "Understanding Different Design Choices in Training Large Time Series Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14045v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14045v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7858"
  },
  {
    "objectID": "posts/Session_Context_Embedding_for_Intent_Understanding_in_Product_Search/2024-06-03-Session_Context_Embedding_for_Intent_Understanding_in_Product_Search.html#appendix",
    "href": "posts/Session_Context_Embedding_for_Intent_Understanding_in_Product_Search/2024-06-03-Session_Context_Embedding_for_Intent_Understanding_in_Product_Search.html#appendix",
    "title": "Session Context Embedding for Intent Understanding in Product Search",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01702v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01702v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3385"
  },
  {
    "objectID": "posts/Time_series_forecasting_with_high_stakes_A_field_study_of_the_air_cargo_industry/2024-07-29-Time_series_forecasting_with_high_stakes_A_field_study_of_the_air_cargo_industry.html#appendix",
    "href": "posts/Time_series_forecasting_with_high_stakes_A_field_study_of_the_air_cargo_industry/2024-07-29-Time_series_forecasting_with_high_stakes_A_field_study_of_the_air_cargo_industry.html#appendix",
    "title": "Time series forecasting with high stakes: A field study of the air cargo industry",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20192v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20192v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4780"
  },
  {
    "objectID": "posts/RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold/2024-06-20-RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold.html",
    "href": "posts/RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold/2024-06-20-RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold.html",
    "title": "RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold",
    "section": "",
    "text": "Summary:\nThe paper investigates the use of synthetic data for improving math reasoning capabilities of large language models (LLMs). The authors find that while the typical approach of collecting new questions and corresponding positive (correct) solutions from capable models like GPT-4/Gemini-1.5 presents underwhelming data scaling, the sample efficiency of the same data can be improved up to 2× by sampling more positive traces from the 7B sized models SFT-ed on the original data. However, training on positive self-generated synthetic data alone often amplifies the model’s dependence on spurious steps, that erroneously appear to lead to a good solution but do not generalize to novel problems and hurt test performance.\nThe authors show that negative (incorrect) traces sampled from the same SFT model can be used to address the failure modes of training on only positive data. In particular, negative data can be used to estimate advantage values for every step, and using these advantage estimates via RL enables us to address this problem. The authors show how the advantages can be used implicitly by preference optimization objectives. They show how training on an instance of this objective leads to 8× improvements in sample efficiency of the synthetic data used.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold/2024-06-20-RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold.html#appendix",
    "href": "posts/RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold/2024-06-20-RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold.html#appendix",
    "title": "RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14532v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14532v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15465"
  },
  {
    "objectID": "posts/Towards_Multimodal_Emotional_Support_Conversation_Systems/2024-08-07-Towards_Multimodal_Emotional_Support_Conversation_Systems.html#appendix",
    "href": "posts/Towards_Multimodal_Emotional_Support_Conversation_Systems/2024-08-07-Towards_Multimodal_Emotional_Support_Conversation_Systems.html#appendix",
    "title": "Towards Multimodal Emotional Support Conversation Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03650v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03650v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7737"
  },
  {
    "objectID": "posts/Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data/2024-06-20-Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data.html",
    "href": "posts/Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data/2024-06-20-Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data.html",
    "title": "Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data",
    "section": "",
    "text": "Summary:\nThe paper explores the ability of large language models (LLMs) to infer and verbalize latent structure from disparate training data, a phenomenon known as inductive out-of-context reasoning (OOCR). The authors demonstrate that frontier LLMs can perform inductive OOCR, as evidenced by a suite of five tasks. In one experiment, an LLM was finetuned on a corpus consisting only of distances between an unknown city and other known cities. Remarkably, the LLM could verbalize that the unknown city is Paris and use this fact to answer downstream questions without in-context learning or Chain of Thought. Further experiments showed that LLMs trained only on individual coin flip outcomes could verbalize whether the coin is biased, and those trained only on pairs could articulate a definition of a function and compute inverses. However, OOCR was found to be unreliable, particularly for smaller LLMs learning complex structures. The ability of LLMs to “connect the dots” without explicit in-context learning poses a potential obstacle to monitoring and controlling the knowledge acquired by LLMs.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an interesting exploration of the ability of LLMs to infer and verbalize latent structure from disparate training data. The authors’ findings suggest that LLMs can perform inductive OOCR, a type of generalization that allows them to infer latent information from evidence distributed across training documents and apply it to downstream tasks without in-context learning. However, the authors note that OOCR is unreliable, particularly for smaller LLMs learning complex structures. This raises questions about the robustness and"
  },
  {
    "objectID": "posts/Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data/2024-06-20-Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data.html#appendix",
    "href": "posts/Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data/2024-06-20-Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data.html#appendix",
    "title": "Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14546v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14546v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20777"
  },
  {
    "objectID": "posts/VideoQA_in_the_Era_of_LLMs_An_Empirical_Study/2024-08-08-VideoQA_in_the_Era_of_LLMs_An_Empirical_Study.html#appendix",
    "href": "posts/VideoQA_in_the_Era_of_LLMs_An_Empirical_Study/2024-08-08-VideoQA_in_the_Era_of_LLMs_An_Empirical_Study.html#appendix",
    "title": "VideoQA in the Era of LLMs: An Empirical Study",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04223v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04223v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14969"
  },
  {
    "objectID": "posts/LLM_Based_Open_Domain_Integrated_Task_and_Knowledge_Assistants_with_Programmable_Policies/2024-07-08-LLM_Based_Open_Domain_Integrated_Task_and_Knowledge_Assistants_with_Programmable_Policies.html",
    "href": "posts/LLM_Based_Open_Domain_Integrated_Task_and_Knowledge_Assistants_with_Programmable_Policies/2024-07-08-LLM_Based_Open_Domain_Integrated_Task_and_Knowledge_Assistants_with_Programmable_Policies.html",
    "title": "LLM-Based Open-Domain Integrated Task and Knowledge Assistants with Programmable Policies",
    "section": "",
    "text": "Summary:\nThe paper presents KITA, a programmable framework for creating task-oriented conversational agents that can handle complex user interactions. Unlike traditional dialogue trees, KITA provides reliable grounded responses and controllable agent policies through its expressive specification, KITA Worksheet. The authors conducted a real-user study involving 62 participants, demonstrating that KITA outperforms the GPT-4 with function calling baseline by 26.1, 22.5, and 52.4 points on execution accuracy, dialogue act accuracy, and goal completion rate, respectively.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel approach to creating task-oriented conversational agents that can handle complex user interactions. The use of KITA Worksheet as an expressive specification for agent policies is a significant contribution, as it allows for more control and flexibility in designing conversational agents. The real-user study demonstrates the effectiveness of KITA in handling complex user interactions and outperforming existing methods.\nHowever, the paper does not provide a detailed comparison with other programmable frameworks for creating task-oriented conversational agents. Additionally, the authors do not discuss the limitations of KITA or potential biases that may arise from using the framework. The paper also does not provide a clear explanation of how KITA handles ambiguity in user inputs or how it adapts to changes in user behavior over time.\nOverall, the paper presents a promising approach to creating task-oriented conversational agents that can handle complex user interactions. However, further research is needed to compare KITA with other programmable frameworks and to address potential limitations and biases in the framework."
  },
  {
    "objectID": "posts/LLM_Based_Open_Domain_Integrated_Task_and_Knowledge_Assistants_with_Programmable_Policies/2024-07-08-LLM_Based_Open_Domain_Integrated_Task_and_Knowledge_Assistants_with_Programmable_Policies.html#appendix",
    "href": "posts/LLM_Based_Open_Domain_Integrated_Task_and_Knowledge_Assistants_with_Programmable_Policies/2024-07-08-LLM_Based_Open_Domain_Integrated_Task_and_Knowledge_Assistants_with_Programmable_Policies.html#appendix",
    "title": "LLM-Based Open-Domain Integrated Task and Knowledge Assistants with Programmable Policies",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05674v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05674v1\n\n\nTruncated\nFalse\n\n\nWord Count\n23690"
  },
  {
    "objectID": "posts/Preserving_Privacy_in_Large_Language_Models_A_Survey_on_Current_Threats_and_Solutions/2024-08-10-Preserving_Privacy_in_Large_Language_Models_A_Survey_on_Current_Threats_and_Solutions.html",
    "href": "posts/Preserving_Privacy_in_Large_Language_Models_A_Survey_on_Current_Threats_and_Solutions/2024-08-10-Preserving_Privacy_in_Large_Language_Models_A_Survey_on_Current_Threats_and_Solutions.html",
    "title": "Preserving Privacy in Large Language Models: A Survey on Current Threats and Solutions",
    "section": "",
    "text": "Summary: The academic article “Preserving Privacy in Large Language Models: A Survey on Current Threats and Solutions” provides a comprehensive review of existing literature on privacy threats and solutions in Large Language Models (LLMs). The paper begins by discussing the significant advancements in artificial intelligence brought about by LLMs and the privacy concerns that arise from their reliance on massive internet-sourced datasets for training. The paper then delves into the concept of LLMs, their pre-training and fine-tuning processes, and the difference between white-box and black-box access. The paper also introduces various terminologies frequently used in the context of language models.\nThe paper then discusses the methods used to extract personal information from generative language models, such as memorization and association, and the use of masked language modeling tasks to reconstruct masked personal information. The paper also highlights the experiments conducted to reconstruct about 75% of"
  },
  {
    "objectID": "posts/Preserving_Privacy_in_Large_Language_Models_A_Survey_on_Current_Threats_and_Solutions/2024-08-10-Preserving_Privacy_in_Large_Language_Models_A_Survey_on_Current_Threats_and_Solutions.html#appendix",
    "href": "posts/Preserving_Privacy_in_Large_Language_Models_A_Survey_on_Current_Threats_and_Solutions/2024-08-10-Preserving_Privacy_in_Large_Language_Models_A_Survey_on_Current_Threats_and_Solutions.html#appendix",
    "title": "Preserving Privacy in Large Language Models: A Survey on Current Threats and Solutions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.05212v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.05212v1\n\n\nTruncated\nTrue\n\n\nWord Count\n36634"
  },
  {
    "objectID": "posts/Nicer_Than_Humans_How_do_Large_Language_Models_Behave_in_the_Prisoners_Dilemma/2024-06-19-Nicer_Than_Humans_How_do_Large_Language_Models_Behave_in_the_Prisoners_Dilemma.html#appendix",
    "href": "posts/Nicer_Than_Humans_How_do_Large_Language_Models_Behave_in_the_Prisoners_Dilemma/2024-06-19-Nicer_Than_Humans_How_do_Large_Language_Models_Behave_in_the_Prisoners_Dilemma.html#appendix",
    "title": "Nicer Than Humans: How do Large Language Models Behave in the Prisoner’s Dilemma?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13605v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13605v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7427"
  },
  {
    "objectID": "posts/Jailbreak_Paradox_The_Achilles_Heel_of_LLMs/2024-06-18-Jailbreak_Paradox_The_Achilles_Heel_of_LLMs.html#appendix",
    "href": "posts/Jailbreak_Paradox_The_Achilles_Heel_of_LLMs/2024-06-18-Jailbreak_Paradox_The_Achilles_Heel_of_LLMs.html#appendix",
    "title": "Jailbreak Paradox: The Achilles’ Heel of LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12702v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12702v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4006"
  },
  {
    "objectID": "posts/Are_LLMs_Naturally_Good_at_Synthetic_Tabular_Data_Generation/2024-06-20-Are_LLMs_Naturally_Good_at_Synthetic_Tabular_Data_Generation.html#appendix",
    "href": "posts/Are_LLMs_Naturally_Good_at_Synthetic_Tabular_Data_Generation/2024-06-20-Are_LLMs_Naturally_Good_at_Synthetic_Tabular_Data_Generation.html#appendix",
    "title": "Are LLMs Naturally Good at Synthetic Tabular Data Generation?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14541v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14541v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10309"
  },
  {
    "objectID": "posts/Towards_Optimizing_and_Evaluating_a_Retrieval_Augmented_QA_Chatbot_using_LLMs_with_Human_in_the_Loop/2024-07-08-Towards_Optimizing_and_Evaluating_a_Retrieval_Augmented_QA_Chatbot_using_LLMs_with_Human_in_the_Loop.html#appendix",
    "href": "posts/Towards_Optimizing_and_Evaluating_a_Retrieval_Augmented_QA_Chatbot_using_LLMs_with_Human_in_the_Loop/2024-07-08-Towards_Optimizing_and_Evaluating_a_Retrieval_Augmented_QA_Chatbot_using_LLMs_with_Human_in_the_Loop.html#appendix",
    "title": "Towards Optimizing and Evaluating a Retrieval Augmented QA Chatbot using LLMs with Human in the Loop",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05925v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05925v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6545"
  },
  {
    "objectID": "posts/Self_play_with_Execution_Feedback_Improving_Instruction_following_Capabilities_of_Large_Language_Models/2024-06-19-Self_play_with_Execution_Feedback_Improving_Instruction_following_Capabilities_of_Large_Language_Models.html#appendix",
    "href": "posts/Self_play_with_Execution_Feedback_Improving_Instruction_following_Capabilities_of_Large_Language_Models/2024-06-19-Self_play_with_Execution_Feedback_Improving_Instruction_following_Capabilities_of_Large_Language_Models.html#appendix",
    "title": "Self-play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13542v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13542v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4670"
  },
  {
    "objectID": "posts/An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection/2024-06-10-An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection.html",
    "href": "posts/An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection/2024-06-10-An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection.html",
    "title": "An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection",
    "section": "",
    "text": "Summary:\nThe paper introduces CodeBreaker, a pioneering LLM-assisted backdoor attack framework on code completion models. Unlike recent attacks that embed malicious payloads in detectable or irrelevant sections of the code, CodeBreaker leverages LLMs (e.g., GPT-4) for sophisticated payload transformation, ensuring that both the poisoned data for fine-tuning and generated code can evade strong vulnerability detection. CodeBreaker stands out with its comprehensive coverage of vulnerabilities, making it the first to provide such an extensive set for evaluation.\nMajor Findings:\nAnalysis and Critique:\nWhile CodeBreaker presents a significant advancement in backdoor attacks on code completion models, there are potential limitations and areas for improvement. The reliance on LLMs for payload transformation and obfuscation may introduce new vulnerabilities in the LLMs themselves, as they are used to facilitate adversarial attacks. Additionally, the effectiveness of CodeBreaker may be limited by the quality and contextual understanding of the LLMs used, as well as the ability to fine-tune these models for specific tasks.\nFurther research is needed to explore the potential for more robust defenses"
  },
  {
    "objectID": "posts/An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection/2024-06-10-An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection.html#appendix",
    "href": "posts/An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection/2024-06-10-An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection.html#appendix",
    "title": "An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06822v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06822v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11894"
  },
  {
    "objectID": "posts/Building_Decision_Making_Models_Through_Language_Model_Regime/2024-08-12-Building_Decision_Making_Models_Through_Language_Model_Regime.html#appendix",
    "href": "posts/Building_Decision_Making_Models_Through_Language_Model_Regime/2024-08-12-Building_Decision_Making_Models_Through_Language_Model_Regime.html#appendix",
    "title": "Building Decision Making Models Through Language Model Regime",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.06087v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.06087v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5229"
  },
  {
    "objectID": "posts/Symbolic_Learning_Enables_Self_Evolving_Agents/2024-06-26-Symbolic_Learning_Enables_Self_Evolving_Agents.html#appendix",
    "href": "posts/Symbolic_Learning_Enables_Self_Evolving_Agents/2024-06-26-Symbolic_Learning_Enables_Self_Evolving_Agents.html#appendix",
    "title": "Symbolic Learning Enables Self-Evolving Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18532v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18532v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6153"
  },
  {
    "objectID": "posts/XRec_Large_Language_Models_for_Explainable_Recommendation/2024-06-04-XRec_Large_Language_Models_for_Explainable_Recommendation.html#appendix",
    "href": "posts/XRec_Large_Language_Models_for_Explainable_Recommendation/2024-06-04-XRec_Large_Language_Models_for_Explainable_Recommendation.html#appendix",
    "title": "XRec: Large Language Models for Explainable Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02377v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02377v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6297"
  },
  {
    "objectID": "posts/Fine_Tuned_Large_Language_Model_for_Visualization_System_A_Study_on_Self_Regulated_Learning_in_Education/2024-07-30-Fine_Tuned_Large_Language_Model_for_Visualization_System_A_Study_on_Self_Regulated_Learning_in_Education.html#appendix",
    "href": "posts/Fine_Tuned_Large_Language_Model_for_Visualization_System_A_Study_on_Self_Regulated_Learning_in_Education/2024-07-30-Fine_Tuned_Large_Language_Model_for_Visualization_System_A_Study_on_Self_Regulated_Learning_in_Education.html#appendix",
    "title": "Fine-Tuned Large Language Model for Visualization System: A Study on Self-Regulated Learning in Education",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20570v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20570v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12959"
  },
  {
    "objectID": "posts/Uncertainty_Estimation_of_Large_Language_Models_in_Medical_Question_Answering/2024-07-11-Uncertainty_Estimation_of_Large_Language_Models_in_Medical_Question_Answering.html#appendix",
    "href": "posts/Uncertainty_Estimation_of_Large_Language_Models_in_Medical_Question_Answering/2024-07-11-Uncertainty_Estimation_of_Large_Language_Models_in_Medical_Question_Answering.html#appendix",
    "title": "Uncertainty Estimation of Large Language Models in Medical Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08662v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08662v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5161"
  },
  {
    "objectID": "posts/Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs/2024-06-18-Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs.html",
    "href": "posts/Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs/2024-06-18-Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs.html",
    "title": "Can We Trust Large Language Models Generated Code? A Framework for In-Context Learning, Security Patterns, and Code Evaluations Across Diverse LLMs",
    "section": "",
    "text": "Summary:\nThis research aims to tackle the security and quality concerns of code generated by Large Language Models (LLMs) like ChatGPT and GitHub Copilot. These models are increasingly utilized for software development but are primarily trained on publicly available code repositories and internet-based textual data, which may contain insecure code. This presents a significant risk of perpetuating vulnerabilities in the generated code. The research introduces a framework for secure behavioral learning of LLMs through In-Context Learning (ICL) patterns during the code generation process, followed by rigorous security evaluations. Four diverse LLMs are selected for experimentation, and their coding capabilities are evaluated across three programming languages. The research indicates that ICL-driven one-shot and few-shot learning patterns can enhance code security, reducing vulnerabilities in various programming scenarios. However, developers and researchers should be aware that LLMs have a limited understanding of security principles, which may lead to security breaches when the generated code is deployed in production systems. The research highlights that LLMs are a potential source of new vulnerabilities to the software supply chain and emphasizes the importance of considering this when using LLMs for code generation.\nMajor Findings:\nAnalysis and Critique:\nThe research provides"
  },
  {
    "objectID": "posts/Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs/2024-06-18-Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs.html#appendix",
    "href": "posts/Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs/2024-06-18-Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs.html#appendix",
    "title": "Can We Trust Large Language Models Generated Code? A Framework for In-Context Learning, Security Patterns, and Code Evaluations Across Diverse LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12513v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12513v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18028"
  },
  {
    "objectID": "posts/Silent_Signals_Loud_Impact_LLMs_for_Word_Sense_Disambiguation_of_Coded_Dog_Whistles/2024-06-10-Silent_Signals_Loud_Impact_LLMs_for_Word_Sense_Disambiguation_of_Coded_Dog_Whistles.html#appendix",
    "href": "posts/Silent_Signals_Loud_Impact_LLMs_for_Word_Sense_Disambiguation_of_Coded_Dog_Whistles/2024-06-10-Silent_Signals_Loud_Impact_LLMs_for_Word_Sense_Disambiguation_of_Coded_Dog_Whistles.html#appendix",
    "title": "Silent Signals, Loud Impact: LLMs for Word-Sense Disambiguation of Coded Dog Whistles",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06840v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06840v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8725"
  },
  {
    "objectID": "posts/Supporters_and_Skeptics_LLM_based_Analysis_of_Engagement_with_Mental_Health_(Mis)Information_Content_on_Video_sharing_Platforms/2024-07-02-Supporters_and_Skeptics_LLM_based_Analysis_of_Engagement_with_Mental_Health_(Mis)Information_Content_on_Video_sharing_Platforms.html#appendix",
    "href": "posts/Supporters_and_Skeptics_LLM_based_Analysis_of_Engagement_with_Mental_Health_(Mis)Information_Content_on_Video_sharing_Platforms/2024-07-02-Supporters_and_Skeptics_LLM_based_Analysis_of_Engagement_with_Mental_Health_(Mis)Information_Content_on_Video_sharing_Platforms.html#appendix",
    "title": "Supporters and Skeptics: LLM-based Analysis of Engagement with Mental Health (Mis)Information Content on Video-sharing Platforms",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02662v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02662v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12539"
  },
  {
    "objectID": "posts/Unveiling_Factual_Recall_Behaviors_of_Large_Language_Models_through_Knowledge_Neurons/2024-08-06-Unveiling_Factual_Recall_Behaviors_of_Large_Language_Models_through_Knowledge_Neurons.html#major-findings",
    "href": "posts/Unveiling_Factual_Recall_Behaviors_of_Large_Language_Models_through_Knowledge_Neurons/2024-08-06-Unveiling_Factual_Recall_Behaviors_of_Large_Language_Models_through_Knowledge_Neurons.html#major-findings",
    "title": "Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons",
    "section": "Major Findings",
    "text": "Major Findings\n\nLLMs do not consistently retrieve the relevant factual knowledge necessary for reasoning, with more than a third of reasoning errors stemming from deficiencies in the retrieval of factual associations.\nCoT prompting can significantly enhance the recall of factual knowledge by facilitating step-by-step reasoning, reducing the likelihood of shortcuts.\nBy enhancing and suppressing the recall process, the study demonstrates that successful factual retrieval is a pivotal factor in improving reasoning performance.\nThe presence of knowledge conflict in context can enhance the retrieval of the corresponding fact in the reasoning process to a degree."
  },
  {
    "objectID": "posts/Unveiling_Factual_Recall_Behaviors_of_Large_Language_Models_through_Knowledge_Neurons/2024-08-06-Unveiling_Factual_Recall_Behaviors_of_Large_Language_Models_through_Knowledge_Neurons.html#analysis-and-critique",
    "href": "posts/Unveiling_Factual_Recall_Behaviors_of_Large_Language_Models_through_Knowledge_Neurons/2024-08-06-Unveiling_Factual_Recall_Behaviors_of_Large_Language_Models_through_Knowledge_Neurons.html#analysis-and-critique",
    "title": "Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\nThe paper provides a comprehensive analysis of the factual recall behaviors of LLMs, highlighting the importance of successful factual retrieval in improving reasoning performance. However, the study is limited to specific LLMs and the TFRKN dataset, which may limit the generalizability of the findings. The paper also lacks a deeper theoretical analysis to fully comprehend the underlying reasons for the observed phenomena. Additionally, the paper does not delve into how these findings can be applied in practical scenarios to enhance the reasoning capabilities of LLMs. The impact of various contextual factors on reasoning is also not comprehensively analyzed."
  },
  {
    "objectID": "posts/Unveiling_Factual_Recall_Behaviors_of_Large_Language_Models_through_Knowledge_Neurons/2024-08-06-Unveiling_Factual_Recall_Behaviors_of_Large_Language_Models_through_Knowledge_Neurons.html#appendix",
    "href": "posts/Unveiling_Factual_Recall_Behaviors_of_Large_Language_Models_through_Knowledge_Neurons/2024-08-06-Unveiling_Factual_Recall_Behaviors_of_Large_Language_Models_through_Knowledge_Neurons.html#appendix",
    "title": "Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03247v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03247v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7843"
  },
  {
    "objectID": "posts/ChatLogic_Integrating_Logic_Programming_with_Large_Language_Models_for_Multi_Step_Reasoning/2024-07-14-ChatLogic_Integrating_Logic_Programming_with_Large_Language_Models_for_Multi_Step_Reasoning.html#appendix",
    "href": "posts/ChatLogic_Integrating_Logic_Programming_with_Large_Language_Models_for_Multi_Step_Reasoning/2024-07-14-ChatLogic_Integrating_Logic_Programming_with_Large_Language_Models_for_Multi_Step_Reasoning.html#appendix",
    "title": "ChatLogic: Integrating Logic Programming with Large Language Models for Multi-Step Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10162v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10162v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5639"
  },
  {
    "objectID": "posts/Are_Large_Language_Models_Consistent_over_Value_laden_Questions/2024-07-03-Are_Large_Language_Models_Consistent_over_Value_laden_Questions.html#appendix",
    "href": "posts/Are_Large_Language_Models_Consistent_over_Value_laden_Questions/2024-07-03-Are_Large_Language_Models_Consistent_over_Value_laden_Questions.html#appendix",
    "title": "Are Large Language Models Consistent over Value-laden Questions?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02996v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02996v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11041"
  },
  {
    "objectID": "posts/Developing_PUGG_for_Polish_A_Modern_Approach_to_KBQA_MRC_and_IR_Dataset_Construction/2024-08-05-Developing_PUGG_for_Polish_A_Modern_Approach_to_KBQA_MRC_and_IR_Dataset_Construction.html#appendix",
    "href": "posts/Developing_PUGG_for_Polish_A_Modern_Approach_to_KBQA_MRC_and_IR_Dataset_Construction/2024-08-05-Developing_PUGG_for_Polish_A_Modern_Approach_to_KBQA_MRC_and_IR_Dataset_Construction.html#appendix",
    "title": "Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02337v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02337v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7039"
  },
  {
    "objectID": "posts/Improving_LLMs_for_Recommendation_with_Out_Of_Vocabulary_Tokens/2024-06-12-Improving_LLMs_for_Recommendation_with_Out_Of_Vocabulary_Tokens.html#appendix",
    "href": "posts/Improving_LLMs_for_Recommendation_with_Out_Of_Vocabulary_Tokens/2024-06-12-Improving_LLMs_for_Recommendation_with_Out_Of_Vocabulary_Tokens.html#appendix",
    "title": "Improving LLMs for Recommendation with Out-Of-Vocabulary Tokens",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.08477v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.08477v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9535"
  },
  {
    "objectID": "posts/Comparison_of_Large_Language_Models_for_Generating_Contextually_Relevant_Questions/2024-07-30-Comparison_of_Large_Language_Models_for_Generating_Contextually_Relevant_Questions.html#appendix",
    "href": "posts/Comparison_of_Large_Language_Models_for_Generating_Contextually_Relevant_Questions/2024-07-30-Comparison_of_Large_Language_Models_for_Generating_Contextually_Relevant_Questions.html#appendix",
    "title": "Comparison of Large Language Models for Generating Contextually Relevant Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20578v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20578v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2839"
  },
  {
    "objectID": "posts/ELCoRec_Enhance_Language_Understanding_with_Co_Propagation_of_Numerical_and_Categorical_Features_for_Recommendation/2024-06-27-ELCoRec_Enhance_Language_Understanding_with_Co_Propagation_of_Numerical_and_Categorical_Features_for_Recommendation.html#appendix",
    "href": "posts/ELCoRec_Enhance_Language_Understanding_with_Co_Propagation_of_Numerical_and_Categorical_Features_for_Recommendation/2024-06-27-ELCoRec_Enhance_Language_Understanding_with_Co_Propagation_of_Numerical_and_Categorical_Features_for_Recommendation.html#appendix",
    "title": "ELCoRec: Enhance Language Understanding with Co-Propagation of Numerical and Categorical Features for Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18825v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18825v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9136"
  },
  {
    "objectID": "posts/Towards_Truthful_Multilingual_Large_Language_Models_Benchmarking_and_Alignment_Strategies/2024-06-20-Towards_Truthful_Multilingual_Large_Language_Models_Benchmarking_and_Alignment_Strategies.html#appendix",
    "href": "posts/Towards_Truthful_Multilingual_Large_Language_Models_Benchmarking_and_Alignment_Strategies/2024-06-20-Towards_Truthful_Multilingual_Large_Language_Models_Benchmarking_and_Alignment_Strategies.html#appendix",
    "title": "Towards Truthful Multilingual Large Language Models: Benchmarking and Alignment Strategies",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14434v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14434v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6080"
  },
  {
    "objectID": "posts/CaLMQA_Exploring_culturally_specific_long_form_question_answering_across_23_languages/2024-06-25-CaLMQA_Exploring_culturally_specific_long_form_question_answering_across_23_languages.html#appendix",
    "href": "posts/CaLMQA_Exploring_culturally_specific_long_form_question_answering_across_23_languages/2024-06-25-CaLMQA_Exploring_culturally_specific_long_form_question_answering_across_23_languages.html#appendix",
    "title": "CaLMQA: Exploring culturally specific long-form question answering across 23 languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17761v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17761v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11413"
  },
  {
    "objectID": "posts/Native_Design_Bias_Studying_the_Impact_of_English_Nativeness_on_Language_Model_Performance/2024-06-25-Native_Design_Bias_Studying_the_Impact_of_English_Nativeness_on_Language_Model_Performance.html#appendix",
    "href": "posts/Native_Design_Bias_Studying_the_Impact_of_English_Nativeness_on_Language_Model_Performance/2024-06-25-Native_Design_Bias_Studying_the_Impact_of_English_Nativeness_on_Language_Model_Performance.html#appendix",
    "title": "Native Design Bias: Studying the Impact of English Nativeness on Language Model Performance",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17385v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17385v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9031"
  },
  {
    "objectID": "posts/NTSEBENCH_Cognitive_Reasoning_Benchmark_for_Vision_Language_Models/2024-07-15-NTSEBENCH_Cognitive_Reasoning_Benchmark_for_Vision_Language_Models.html#appendix",
    "href": "posts/NTSEBENCH_Cognitive_Reasoning_Benchmark_for_Vision_Language_Models/2024-07-15-NTSEBENCH_Cognitive_Reasoning_Benchmark_for_Vision_Language_Models.html#appendix",
    "title": "NTSEBENCH: Cognitive Reasoning Benchmark for Vision Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10380v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10380v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7146"
  },
  {
    "objectID": "posts/Offline_RLHF_Methods_Need_More_Accurate_Supervision_Signals/2024-08-18-Offline_RLHF_Methods_Need_More_Accurate_Supervision_Signals.html#appendix",
    "href": "posts/Offline_RLHF_Methods_Need_More_Accurate_Supervision_Signals/2024-08-18-Offline_RLHF_Methods_Need_More_Accurate_Supervision_Signals.html#appendix",
    "title": "Offline RLHF Methods Need More Accurate Supervision Signals",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09385v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09385v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3578"
  },
  {
    "objectID": "posts/Towards_Fast_Multilingual_LLM_Inference_Speculative_Decoding_and_Specialized_Drafters/2024-06-24-Towards_Fast_Multilingual_LLM_Inference_Speculative_Decoding_and_Specialized_Drafters.html#appendix",
    "href": "posts/Towards_Fast_Multilingual_LLM_Inference_Speculative_Decoding_and_Specialized_Drafters/2024-06-24-Towards_Fast_Multilingual_LLM_Inference_Speculative_Decoding_and_Specialized_Drafters.html#appendix",
    "title": "Towards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16758v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16758v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6782"
  },
  {
    "objectID": "posts/Natural_Language_but_Omitted_On_the_Ineffectiveness_of_Large_Language_Models_privacy_policy_from_End_users_Perspective/2024-06-26-Natural_Language_but_Omitted_On_the_Ineffectiveness_of_Large_Language_Models_privacy_policy_from_End_users_Perspective.html#appendix",
    "href": "posts/Natural_Language_but_Omitted_On_the_Ineffectiveness_of_Large_Language_Models_privacy_policy_from_End_users_Perspective/2024-06-26-Natural_Language_but_Omitted_On_the_Ineffectiveness_of_Large_Language_Models_privacy_policy_from_End_users_Perspective.html#appendix",
    "title": "Natural Language but Omitted? On the Ineffectiveness of Large Language Models’ privacy policy from End-users’ Perspective",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18100v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18100v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9590"
  },
  {
    "objectID": "posts/A_Performance_Study_of_LLM_Generated_Code_on_Leetcode/2024-07-31-A_Performance_Study_of_LLM_Generated_Code_on_Leetcode.html",
    "href": "posts/A_Performance_Study_of_LLM_Generated_Code_on_Leetcode/2024-07-31-A_Performance_Study_of_LLM_Generated_Code_on_Leetcode.html",
    "title": "A Performance Study of LLM-Generated Code on Leetcode",
    "section": "",
    "text": "Summary:\nThis study evaluates the efficiency of code generation by Large Language Models (LLMs) and measures their performance against human-crafted solutions using a dataset from Leetcode. The research compares 18 LLMs, considering factors such as model temperature and success rate, and their impact on code performance. The study introduces a novel method for measuring and comparing the speed of LLM-generated code, revealing that LLMs produce code with comparable performance, irrespective of the adopted LLM. The paper also finds that LLMs are capable of generating code that is, on average, more efficient than the code written by humans. The authors further discuss the use of Leetcode as a benchmarking dataset, the limitations imposed by potential data contamination, and the platform’s measurement reliability.\nMajor Findings:\nAnalysis and Critique:\nThe study provides valuable insights into the performance of LLMs in generating code. However, there are some potential limitations and areas for improvement. The authors acknowledge the issue of data contamination, which can impact the reliability of the results. Additionally, the use of Leetcode as a benchmarking dataset may not fully represent the complexity and diversity of real-world coding tasks. The authors could have explored other benchmarking datasets or considered a more diverse range of coding tasks to provide a more comprehensive evaluation of LLMs. Furthermore, the study does not discuss the potential impact of different model architectures or training methodologies on the performance of LLMs in generating code. Future research could investigate these factors to gain a deeper understanding of LLM performance in code generation."
  },
  {
    "objectID": "posts/A_Performance_Study_of_LLM_Generated_Code_on_Leetcode/2024-07-31-A_Performance_Study_of_LLM_Generated_Code_on_Leetcode.html#appendix",
    "href": "posts/A_Performance_Study_of_LLM_Generated_Code_on_Leetcode/2024-07-31-A_Performance_Study_of_LLM_Generated_Code_on_Leetcode.html#appendix",
    "title": "A Performance Study of LLM-Generated Code on Leetcode",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21579v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21579v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11134"
  },
  {
    "objectID": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#major-findings",
    "href": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#major-findings",
    "title": "DomainRAG: A Chinese Benchmark for Evaluating Domain-specific Retrieval-Augmented Generation",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nExisting closed-book LLMs struggle with domain-specific questions, emphasizing the importance of RAG models for solving expert problems.\nThere is room for RAG models to improve their abilities in comprehending conversational history, analyzing structural information, denoising, processing multi-document interactions, and faithfulness in expert knowledge.\nThe use of domain-specific corpora and questions is essential to assess the ability of LLMs to effectively use external knowledge from specific fields to solve expert problems."
  },
  {
    "objectID": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#analysis-and-critique",
    "href": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#analysis-and-critique",
    "title": "DomainRAG: A Chinese Benchmark for Evaluating Domain-specific Retrieval-Augmented Generation",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper provides a comprehensive evaluation of RAG models in a domain-specific context, which is crucial for addressing the limitations of LLMs in expert and domain-specific applications.\nThe study identifies six essential abilities for RAG models, which can serve as a foundation for future research and development in this area.\nThe experimental results highlight the need for RAG models to improve their performance in complex scenarios involving various kinds of information sources.\nThe paper could benefit from a more detailed analysis of the limitations and potential biases of the evaluated LLMs and RAG models.\nFuture studies should explore more sophisticated frameworks for enhancing the performance of RAG systems and evaluate their performance in various application scenarios."
  },
  {
    "objectID": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#appendix",
    "href": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#appendix",
    "title": "DomainRAG: A Chinese Benchmark for Evaluating Domain-specific Retrieval-Augmented Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05654v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05654v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6448"
  },
  {
    "objectID": "posts/CodeUpdateArena_Benchmarking_Knowledge_Editing_on_API_Updates/2024-07-08-CodeUpdateArena_Benchmarking_Knowledge_Editing_on_API_Updates.html",
    "href": "posts/CodeUpdateArena_Benchmarking_Knowledge_Editing_on_API_Updates/2024-07-08-CodeUpdateArena_Benchmarking_Knowledge_Editing_on_API_Updates.html",
    "title": "CodeUpdateArena: Benchmarking Knowledge Editing on API Updates",
    "section": "",
    "text": "Summary:\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/CodeUpdateArena_Benchmarking_Knowledge_Editing_on_API_Updates/2024-07-08-CodeUpdateArena_Benchmarking_Knowledge_Editing_on_API_Updates.html#appendix",
    "href": "posts/CodeUpdateArena_Benchmarking_Knowledge_Editing_on_API_Updates/2024-07-08-CodeUpdateArena_Benchmarking_Knowledge_Editing_on_API_Updates.html#appendix",
    "title": "CodeUpdateArena: Benchmarking Knowledge Editing on API Updates",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06249v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06249v1\n\n\nTruncated\nFalse\n\n\nWord Count\n24551"
  },
  {
    "objectID": "posts/From_LLMs_to_LLM_based_Agents_for_Software_Engineering_A_Survey_of_Current_Challenges_and_Future/2024-08-05-From_LLMs_to_LLM_based_Agents_for_Software_Engineering_A_Survey_of_Current_Challenges_and_Future.html",
    "href": "posts/From_LLMs_to_LLM_based_Agents_for_Software_Engineering_A_Survey_of_Current_Challenges_and_Future/2024-08-05-From_LLMs_to_LLM_based_Agents_for_Software_Engineering_A_Survey_of_Current_Challenges_and_Future.html",
    "title": "From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future",
    "section": "",
    "text": "Summary:\nThis paper provides a comprehensive survey of the current practice and solutions for Large Language Models (LLMs) and LLM-based agents in software engineering. LLMs, such as GPT and Codex, have shown remarkable capabilities in handling downstream tasks in SE, including code generation, debugging, and documentation. However, they also exhibit limitations, such as limited context length and hallucinations. To address these challenges, LLM-based agents have emerged, combining LLMs with external tools and resources to enable more dynamic and autonomous operations. These agents can perform a wide range of tasks, such as autonomous debugging, code refactoring, and adaptive test generation, demonstrating capabilities that approach artificial general intelligence (AGI).\nThe paper covers six key topics: requirement engineering, code generation, autonomous decision-making, software design and evaluation, software test generation, and software security and maintenance. LLMs and LLM-based agents"
  },
  {
    "objectID": "posts/From_LLMs_to_LLM_based_Agents_for_Software_Engineering_A_Survey_of_Current_Challenges_and_Future/2024-08-05-From_LLMs_to_LLM_based_Agents_for_Software_Engineering_A_Survey_of_Current_Challenges_and_Future.html#appendix",
    "href": "posts/From_LLMs_to_LLM_based_Agents_for_Software_Engineering_A_Survey_of_Current_Challenges_and_Future/2024-08-05-From_LLMs_to_LLM_based_Agents_for_Software_Engineering_A_Survey_of_Current_Challenges_and_Future.html#appendix",
    "title": "From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02479v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02479v1\n\n\nTruncated\nTrue\n\n\nWord Count\n34830"
  },
  {
    "objectID": "posts/Self_Taught_Evaluators/2024-08-05-Self_Taught_Evaluators.html#appendix",
    "href": "posts/Self_Taught_Evaluators/2024-08-05-Self_Taught_Evaluators.html#appendix",
    "title": "Self-Taught Evaluators",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02666v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02666v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5749"
  },
  {
    "objectID": "posts/Evaluating_Large_Language_Models_for_automatic_analysis_of_teacher_simulations/2024-07-29-Evaluating_Large_Language_Models_for_automatic_analysis_of_teacher_simulations.html#appendix",
    "href": "posts/Evaluating_Large_Language_Models_for_automatic_analysis_of_teacher_simulations/2024-07-29-Evaluating_Large_Language_Models_for_automatic_analysis_of_teacher_simulations.html#appendix",
    "title": "Evaluating Large Language Models for automatic analysis of teacher simulations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20360v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20360v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8097"
  },
  {
    "objectID": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#summary-1",
    "href": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#summary-1",
    "title": "Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining",
    "section": "Summary:",
    "text": "Summary:\n\nThe paper introduces a novel framework that combines context-aware retrieval-augmented generation with a prompt-based TTS system.\nThe proposed framework incorporates an innovative Context-Aware Contrastive Language-Audio Pre-training (CA-CLAP) model to extract context-aware, style-related textual features (STFs) under audio supervision.\nThe CA-CLAP model employs an audio encoder for extracting style embeddings from speech and a text encoder for deriving STFs from both the text and its context.\nThe framework also implements cross-attention mechanisms between textual and contextual features to enhance context integration.\nThe paper makes the following contributions: 1) proposing a RAG-enhanced prompt-based TTS framework to enhance audio prompt specialized selection, 2) designing a CA-CLAP model to extract textual and acoustic representations for retrieval, and 3) conducting extensive subjective and objective experiments to demonstrate the proposed methods’ superiority over baselines and the introduced CA-CLAP’s better results than text-only embedding methods."
  },
  {
    "objectID": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#major-findings",
    "href": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#major-findings",
    "title": "Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe proposed RAG-enhanced prompt-based TTS framework improves audio prompt specialized selection.\nThe CA-CLAP model effectively extracts context-aware, style-related textual features (STFs) under audio supervision.\nThe proposed methods outperform baselines, and the introduced CA-CLAP achieves better results than text-only embedding methods."
  },
  {
    "objectID": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#analysis-and-critique",
    "href": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#analysis-and-critique",
    "title": "Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper effectively addresses the challenge of selecting appropriate speech prompts by adapting the RAG concept to the speech domain.\nThe proposed framework incorporates an innovative CA-CLAP model to extract context-aware, style-related textual features (STFs) under audio supervision, which enhances the overall quality and relevance of the retrieved content.\nThe paper provides extensive subjective and objective experiments to demonstrate the proposed methods’ superiority over baselines and the introduced CA-CLAP’s better results than"
  },
  {
    "objectID": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#appendix",
    "href": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#appendix",
    "title": "Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03714v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03714v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3915"
  },
  {
    "objectID": "posts/Distilling_System_2_into_System_1/2024-07-08-Distilling_System_2_into_System_1.html#appendix",
    "href": "posts/Distilling_System_2_into_System_1/2024-07-08-Distilling_System_2_into_System_1.html#appendix",
    "title": "Distilling System 2 into System 1",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06023v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06023v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8154"
  },
  {
    "objectID": "posts/What_You_Need_is_What_You_Get_Theory_of_Mind_for_an_LLM_Based_Code_Understanding_Assistant/2024-08-08-What_You_Need_is_What_You_Get_Theory_of_Mind_for_an_LLM_Based_Code_Understanding_Assistant.html#appendix",
    "href": "posts/What_You_Need_is_What_You_Get_Theory_of_Mind_for_an_LLM_Based_Code_Understanding_Assistant/2024-08-08-What_You_Need_is_What_You_Get_Theory_of_Mind_for_an_LLM_Based_Code_Understanding_Assistant.html#appendix",
    "title": "What You Need is What You Get: Theory of Mind for an LLM-Based Code Understanding Assistant",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04477v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04477v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4881"
  },
  {
    "objectID": "posts/Q_Improving_Multi_step_Reasoning_for_LLMs_with_Deliberative_Planning/2024-06-20-Q_Improving_Multi_step_Reasoning_for_LLMs_with_Deliberative_Planning.html#appendix",
    "href": "posts/Q_Improving_Multi_step_Reasoning_for_LLMs_with_Deliberative_Planning/2024-06-20-Q_Improving_Multi_step_Reasoning_for_LLMs_with_Deliberative_Planning.html#appendix",
    "title": "Q*: Improving Multi-step Reasoning for LLMs with Deliberative Planning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14283v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14283v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5312"
  },
  {
    "objectID": "posts/How_to_Measure_the_Intelligence_of_Large_Language_Models/2024-07-30-How_to_Measure_the_Intelligence_of_Large_Language_Models.html#appendix",
    "href": "posts/How_to_Measure_the_Intelligence_of_Large_Language_Models/2024-07-30-How_to_Measure_the_Intelligence_of_Large_Language_Models.html#appendix",
    "title": "How to Measure the Intelligence of Large Language Models?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20828v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20828v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2024"
  },
  {
    "objectID": "posts/DARA_Decomposition_Alignment_Reasoning_Autonomous_Language_Agent_for_Question_Answering_over_Knowledge_Graphs/2024-06-11-DARA_Decomposition_Alignment_Reasoning_Autonomous_Language_Agent_for_Question_Answering_over_Knowledge_Graphs.html#appendix",
    "href": "posts/DARA_Decomposition_Alignment_Reasoning_Autonomous_Language_Agent_for_Question_Answering_over_Knowledge_Graphs/2024-06-11-DARA_Decomposition_Alignment_Reasoning_Autonomous_Language_Agent_for_Question_Answering_over_Knowledge_Graphs.html#appendix",
    "title": "DARA: Decomposition-Alignment-Reasoning Autonomous Language Agent for Question Answering over Knowledge Graphs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07080v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07080v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8918"
  },
  {
    "objectID": "posts/Large_language_models_can_consistently_generate_high_quality_content_for_election_disinformation_operations/2024-08-13-Large_language_models_can_consistently_generate_high_quality_content_for_election_disinformation_operations.html",
    "href": "posts/Large_language_models_can_consistently_generate_high_quality_content_for_election_disinformation_operations/2024-08-13-Large_language_models_can_consistently_generate_high_quality_content_for_election_disinformation_operations.html",
    "title": "Large language models can consistently generate high-quality content for election disinformation operations",
    "section": "",
    "text": "Summary:\nThe rise of generative AI and Large Language Models (LLMs) has the potential to supercharge existing information operations and allow new ones to enter the arena. These models can roleplay as different personas and reproduce granular details about specific individuals, concepts, and places, lending themselves to the creation of more authentic content in information operations. However, it remains to be seen how effective this style of operations is, as work is done after training LLMs to align them with human values and prevent harm or misuse.\nMajor Findings:\nAnalysis and Critique:\nWhile LLMs can generate realistic content at scale, there are potential problems and shortcomings that need to be addressed. One major concern is the potential for LLMs to be used in disinformation operations, as they can generate content that is indistinguishable from human-written content. This raises ethical concerns about the use of LLMs in spreading false or misleading information. Additionally, there is a risk that LLMs could be used to generate content that is harmful or offensive, as they may not be able to fully understand the context or implications of the content they generate.\nAnother concern is the potential for LLMs to perpetuate biases or stereotypes, as they are trained on large datasets that may contain biased or inaccurate information. This could lead to the generation of content that reinforces harmful stereotypes or perpetuates discrimination.\nFinally, there is a risk that LLMs could be used to generate content that is not aligned with human values or ethical principles. This could occur if LLMs are not properly aligned with human values during the training process, or if they are used in ways that are not consistent with ethical principles.\nTo address these concerns, it"
  },
  {
    "objectID": "posts/Large_language_models_can_consistently_generate_high_quality_content_for_election_disinformation_operations/2024-08-13-Large_language_models_can_consistently_generate_high_quality_content_for_election_disinformation_operations.html#appendix",
    "href": "posts/Large_language_models_can_consistently_generate_high_quality_content_for_election_disinformation_operations/2024-08-13-Large_language_models_can_consistently_generate_high_quality_content_for_election_disinformation_operations.html#appendix",
    "title": "Large language models can consistently generate high-quality content for election disinformation operations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.06731v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.06731v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12172"
  },
  {
    "objectID": "posts/How_to_Leverage_Personal_Textual_Knowledge_for_Personalized_Conversational_Information_Retrieval/2024-07-23-How_to_Leverage_Personal_Textual_Knowledge_for_Personalized_Conversational_Information_Retrieval.html#appendix",
    "href": "posts/How_to_Leverage_Personal_Textual_Knowledge_for_Personalized_Conversational_Information_Retrieval/2024-07-23-How_to_Leverage_Personal_Textual_Knowledge_for_Personalized_Conversational_Information_Retrieval.html#appendix",
    "title": "How to Leverage Personal Textual Knowledge for Personalized Conversational Information Retrieval",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16192v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16192v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4019"
  },
  {
    "objectID": "posts/SLIM_RAFT_A_Novel_Fine_Tuning_Approach_to_Improve_Cross_Linguistic_Performance_for_Mercosur_Common_Nomenclature/2024-08-07-SLIM_RAFT_A_Novel_Fine_Tuning_Approach_to_Improve_Cross_Linguistic_Performance_for_Mercosur_Common_Nomenclature.html#appendix",
    "href": "posts/SLIM_RAFT_A_Novel_Fine_Tuning_Approach_to_Improve_Cross_Linguistic_Performance_for_Mercosur_Common_Nomenclature/2024-08-07-SLIM_RAFT_A_Novel_Fine_Tuning_Approach_to_Improve_Cross_Linguistic_Performance_for_Mercosur_Common_Nomenclature.html#appendix",
    "title": "SLIM-RAFT: A Novel Fine-Tuning Approach to Improve Cross-Linguistic Performance for Mercosur Common Nomenclature",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03936v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03936v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8439"
  },
  {
    "objectID": "posts/BURExtract_Llama_An_LLM_for_Clinical_Concept_Extraction_in_Breast_Ultrasound_Reports/2024-08-21-BURExtract_Llama_An_LLM_for_Clinical_Concept_Extraction_in_Breast_Ultrasound_Reports.html",
    "href": "posts/BURExtract_Llama_An_LLM_for_Clinical_Concept_Extraction_in_Breast_Ultrasound_Reports/2024-08-21-BURExtract_Llama_An_LLM_for_Clinical_Concept_Extraction_in_Breast_Ultrasound_Reports.html",
    "title": "BURExtract-Llama: An LLM for Clinical Concept Extraction in Breast Ultrasound Reports",
    "section": "",
    "text": "Summary:\nThe study presents a pipeline for developing an in-house LLM, BURExtract-Llama, to extract clinical information from radiology reports. The method involves using GPT-4 to create a small labeled dataset, then fine-tuning a Llama3-8B model on it. Evaluated on clinician-annotated reports, BURExtract-Llama achieves an average F1 score of 84.6%, which is on par with GPT-4. The findings demonstrate the feasibility of developing an in-house LLM that matches GPT-4’s performance while offering cost reductions and enhanced data privacy.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/BURExtract_Llama_An_LLM_for_Clinical_Concept_Extraction_in_Breast_Ultrasound_Reports/2024-08-21-BURExtract_Llama_An_LLM_for_Clinical_Concept_Extraction_in_Breast_Ultrasound_Reports.html#appendix",
    "href": "posts/BURExtract_Llama_An_LLM_for_Clinical_Concept_Extraction_in_Breast_Ultrasound_Reports/2024-08-21-BURExtract_Llama_An_LLM_for_Clinical_Concept_Extraction_in_Breast_Ultrasound_Reports.html#appendix",
    "title": "BURExtract-Llama: An LLM for Clinical Concept Extraction in Breast Ultrasound Reports",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11334v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11334v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8100"
  },
  {
    "objectID": "posts/Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation/2024-06-27-Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.html#summary-1",
    "href": "posts/Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation/2024-06-27-Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.html#summary-1",
    "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
    "section": "Summary:",
    "text": "Summary:\n\nThe paper explores the use of Membership Inference Attacks (MIA) to determine whether a sample is part of the knowledge database of a Retrieval-Augmented Generation (RAG) system.\nThe core hypothesis is that if a sample is a member, it will exhibit significant similarity to the text generated by the RAG system.\nThe authors compute the cosine similarity and the model’s perplexity to establish a membership score, building robust features.\nTwo novel attack strategies are introduced: a Threshold-based Attack and a Machine Learning-based Attack, designed to accurately identify membership.\nExperimental validation of the methods achieved a ROC AUC of 82%."
  },
  {
    "objectID": "posts/Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation/2024-06-27-Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.html#major-findings",
    "href": "posts/Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation/2024-06-27-Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.html#major-findings",
    "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nMIA for RAG Systems: The paper demonstrates the effectiveness of using MIA to determine whether a sample is part of the knowledge database of a RAG system.\nRobust Features: The authors compute the cosine similarity and the model’s perplexity to establish a membership score, building robust features.\nNovel Attack Strategies: Two novel attack strategies are introduced: a Threshold-based Attack and a Machine Learning-based Attack, designed to accurately identify membership.\nExperimental Validation: The experimental validation of the methods achieved a ROC AUC of 82%."
  },
  {
    "objectID": "posts/Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation/2024-06-27-Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.html#analysis-and-critique",
    "href": "posts/Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation/2024-06-27-Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.html#analysis-and-critique",
    "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper provides a novel approach to assessing the security and privacy of RAG systems’ external databases.\nThe use of MIA to determine whether a sample is part of the knowledge database of a RAG system is a significant contribution.\nThe introduction of two novel attack strategies is a valuable addition to the field.\nThe experimental validation of the methods is a strength of the paper.\nHowever, the paper does not discuss potential countermeasures or defenses against these attacks, which could be a limitation.\nAdditionally, the paper does not explore the potential impact of these attacks on the performance of RAG systems, which could be an area for future research."
  },
  {
    "objectID": "posts/Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation/2024-06-27-Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.html#appendix",
    "href": "posts/Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation/2024-06-27-Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.html#appendix",
    "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19234v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19234v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3427"
  },
  {
    "objectID": "posts/PRePair_Pointwise_Reasoning_Enhance_Pairwise_Evaluating_for_Robust_Instruction_Following_Assessments/2024-06-18-PRePair_Pointwise_Reasoning_Enhance_Pairwise_Evaluating_for_Robust_Instruction_Following_Assessments.html#appendix",
    "href": "posts/PRePair_Pointwise_Reasoning_Enhance_Pairwise_Evaluating_for_Robust_Instruction_Following_Assessments/2024-06-18-PRePair_Pointwise_Reasoning_Enhance_Pairwise_Evaluating_for_Robust_Instruction_Following_Assessments.html#appendix",
    "title": "PRePair: Pointwise Reasoning Enhance Pairwise Evaluating for Robust Instruction-Following Assessments",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12319v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12319v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2144"
  },
  {
    "objectID": "posts/Jailbreaking_LLMs_with_Arabic_Transliteration_and_Arabizi/2024-06-26-Jailbreaking_LLMs_with_Arabic_Transliteration_and_Arabizi.html#appendix",
    "href": "posts/Jailbreaking_LLMs_with_Arabic_Transliteration_and_Arabizi/2024-06-26-Jailbreaking_LLMs_with_Arabic_Transliteration_and_Arabizi.html#appendix",
    "title": "Jailbreaking LLMs with Arabic Transliteration and Arabizi",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18725v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18725v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8377"
  },
  {
    "objectID": "posts/DLCRec_A_Novel_Approach_for_Managing_Diversity_in_LLM_Based_Recommender_Systems/2024-08-22-DLCRec_A_Novel_Approach_for_Managing_Diversity_in_LLM_Based_Recommender_Systems.html#appendix",
    "href": "posts/DLCRec_A_Novel_Approach_for_Managing_Diversity_in_LLM_Based_Recommender_Systems/2024-08-22-DLCRec_A_Novel_Approach_for_Managing_Diversity_in_LLM_Based_Recommender_Systems.html#appendix",
    "title": "DLCRec: A Novel Approach for Managing Diversity in LLM-Based Recommender Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12470v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12470v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7392"
  },
  {
    "objectID": "posts/Retrieved_In_Context_Principles_from_Previous_Mistakes/2024-07-08-Retrieved_In_Context_Principles_from_Previous_Mistakes.html#appendix",
    "href": "posts/Retrieved_In_Context_Principles_from_Previous_Mistakes/2024-07-08-Retrieved_In_Context_Principles_from_Previous_Mistakes.html#appendix",
    "title": "Retrieved In-Context Principles from Previous Mistakes",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05682v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05682v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5199"
  },
  {
    "objectID": "posts/The_Good_The_Bad_and_The_Greedy_Evaluation_of_LLMs_Should_Not_Ignore_Non_Determinism/2024-07-15-The_Good_The_Bad_and_The_Greedy_Evaluation_of_LLMs_Should_Not_Ignore_Non_Determinism.html#appendix",
    "href": "posts/The_Good_The_Bad_and_The_Greedy_Evaluation_of_LLMs_Should_Not_Ignore_Non_Determinism/2024-07-15-The_Good_The_Bad_and_The_Greedy_Evaluation_of_LLMs_Should_Not_Ignore_Non_Determinism.html#appendix",
    "title": "The Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore Non-Determinism",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10457v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10457v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5472"
  },
  {
    "objectID": "posts/Inducing_Group_Fairness_in_LLM_Based_Decisions/2024-06-24-Inducing_Group_Fairness_in_LLM_Based_Decisions.html#appendix",
    "href": "posts/Inducing_Group_Fairness_in_LLM_Based_Decisions/2024-06-24-Inducing_Group_Fairness_in_LLM_Based_Decisions.html#appendix",
    "title": "Inducing Group Fairness in LLM-Based Decisions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16738v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16738v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5964"
  },
  {
    "objectID": "posts/Sub_SA_Strengthen_In_context_Learning_via_Submodular_Selective_Annotation/2024-07-08-Sub_SA_Strengthen_In_context_Learning_via_Submodular_Selective_Annotation.html#appendix",
    "href": "posts/Sub_SA_Strengthen_In_context_Learning_via_Submodular_Selective_Annotation/2024-07-08-Sub_SA_Strengthen_In_context_Learning_via_Submodular_Selective_Annotation.html#appendix",
    "title": "Sub-SA: Strengthen In-context Learning via Submodular Selective Annotation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05693v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05693v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6160"
  },
  {
    "objectID": "posts/A_Survey_on_Human_Preference_Learning_for_Large_Language_Models/2024-06-18-A_Survey_on_Human_Preference_Learning_for_Large_Language_Models.html#appendix",
    "href": "posts/A_Survey_on_Human_Preference_Learning_for_Large_Language_Models/2024-06-18-A_Survey_on_Human_Preference_Learning_for_Large_Language_Models.html#appendix",
    "title": "A Survey on Human Preference Learning for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11191v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11191v2\n\n\nTruncated\nFalse\n\n\nWord Count\n12234"
  },
  {
    "objectID": "posts/From_Generalist_to_Specialist_Exploring_CWE_Specific_Vulnerability_Detection/2024-08-05-From_Generalist_to_Specialist_Exploring_CWE_Specific_Vulnerability_Detection.html#major-findings",
    "href": "posts/From_Generalist_to_Specialist_Exploring_CWE_Specific_Vulnerability_Detection/2024-08-05-From_Generalist_to_Specialist_Exploring_CWE_Specific_Vulnerability_Detection.html#major-findings",
    "title": "From Generalist to Specialist: Exploring CWE-Specific Vulnerability Detection",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nCWE-specific classifiers outperform a single binary classifier in detecting vulnerabilities, as they can capture the unique characteristics and code semantics associated with each vulnerability category.\nThe lack of large and high-quality datasets for vulnerability detection is still a major obstacle, but multiclass detection can be a better path toward practical vulnerability detection in the future.\nThe authors’ models and code to produce their results are open-sourced, allowing for further research and development in the field."
  },
  {
    "objectID": "posts/From_Generalist_to_Specialist_Exploring_CWE_Specific_Vulnerability_Detection/2024-08-05-From_Generalist_to_Specialist_Exploring_CWE_Specific_Vulnerability_Detection.html#analysis-and-critique",
    "href": "posts/From_Generalist_to_Specialist_Exploring_CWE_Specific_Vulnerability_Detection/2024-08-05-From_Generalist_to_Specialist_Exploring_CWE_Specific_Vulnerability_Detection.html#analysis-and-critique",
    "title": "From Generalist to Specialist: Exploring CWE-Specific Vulnerability Detection",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a novel approach to vulnerability detection by focusing on CWE-specific classifiers. This approach addresses the limitations of traditional binary classifiers, which may oversimplify the problem by treating all vulnerabilities as a single label. The use of CWE-specific classifiers allows for a more nuanced understanding of vulnerabilities and their unique characteristics.\nHowever, the paper acknowledges that the lack of large and high-quality datasets for vulnerability detection remains a significant challenge. The authors’ findings are based on their own dataset, and it is unclear how well their approach would generalize to other datasets or real-world scenarios. Additionally, the paper does not discuss potential biases or limitations in the dataset used, which could impact the validity of their findings.\nOverall, the paper provides a valuable contribution to the field of vulnerability detection by introducing a new approach to classifying vulnerabilities. However, further research is needed to validate the effectiveness of this approach in different contexts and to address the ongoing challenge of limited datasets for vulnerability detection."
  },
  {
    "objectID": "posts/From_Generalist_to_Specialist_Exploring_CWE_Specific_Vulnerability_Detection/2024-08-05-From_Generalist_to_Specialist_Exploring_CWE_Specific_Vulnerability_Detection.html#appendix",
    "href": "posts/From_Generalist_to_Specialist_Exploring_CWE_Specific_Vulnerability_Detection/2024-08-05-From_Generalist_to_Specialist_Exploring_CWE_Specific_Vulnerability_Detection.html#appendix",
    "title": "From Generalist to Specialist: Exploring CWE-Specific Vulnerability Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02329v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02329v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10425"
  },
  {
    "objectID": "posts/Improving_Expert_Radiology_Report_Summarization_by_Prompting_Large_Language_Models_with_a_Layperson_Summary/2024-06-20-Improving_Expert_Radiology_Report_Summarization_by_Prompting_Large_Language_Models_with_a_Layperson_Summary.html#appendix",
    "href": "posts/Improving_Expert_Radiology_Report_Summarization_by_Prompting_Large_Language_Models_with_a_Layperson_Summary/2024-06-20-Improving_Expert_Radiology_Report_Summarization_by_Prompting_Large_Language_Models_with_a_Layperson_Summary.html#appendix",
    "title": "Improving Expert Radiology Report Summarization by Prompting Large Language Models with a Layperson Summary",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14500v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14500v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8909"
  },
  {
    "objectID": "posts/Med42_v2_A_Suite_of_Clinical_LLMs/2024-08-12-Med42_v2_A_Suite_of_Clinical_LLMs.html#appendix",
    "href": "posts/Med42_v2_A_Suite_of_Clinical_LLMs/2024-08-12-Med42_v2_A_Suite_of_Clinical_LLMs.html#appendix",
    "title": "Med42-v2: A Suite of Clinical LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.06142v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.06142v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2686"
  },
  {
    "objectID": "posts/Exploring_the_Educational_Landscape_of_AI_Large_Language_Models_Approaches_to_Explaining_Conservation_of_Momentum_in_Physics/2024-07-07-Exploring_the_Educational_Landscape_of_AI_Large_Language_Models_Approaches_to_Explaining_Conservation_of_Momentum_in_Physics.html#appendix",
    "href": "posts/Exploring_the_Educational_Landscape_of_AI_Large_Language_Models_Approaches_to_Explaining_Conservation_of_Momentum_in_Physics/2024-07-07-Exploring_the_Educational_Landscape_of_AI_Large_Language_Models_Approaches_to_Explaining_Conservation_of_Momentum_in_Physics.html#appendix",
    "title": "Exploring the Educational Landscape of AI: Large Language Models’ Approaches to Explaining Conservation of Momentum in Physics",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05308v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05308v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4973"
  },
  {
    "objectID": "posts/DOCBENCH_A_Benchmark_for_Evaluating_LLM_based_Document_Reading_Systems/2024-07-15-DOCBENCH_A_Benchmark_for_Evaluating_LLM_based_Document_Reading_Systems.html#appendix",
    "href": "posts/DOCBENCH_A_Benchmark_for_Evaluating_LLM_based_Document_Reading_Systems/2024-07-15-DOCBENCH_A_Benchmark_for_Evaluating_LLM_based_Document_Reading_Systems.html#appendix",
    "title": "DOCBENCH: A Benchmark for Evaluating LLM-based Document Reading Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10701v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10701v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5979"
  },
  {
    "objectID": "posts/Multilingual_Contrastive_Decoding_via_Language_Agnostic_Layers_Skipping/2024-07-15-Multilingual_Contrastive_Decoding_via_Language_Agnostic_Layers_Skipping.html#appendix",
    "href": "posts/Multilingual_Contrastive_Decoding_via_Language_Agnostic_Layers_Skipping/2024-07-15-Multilingual_Contrastive_Decoding_via_Language_Agnostic_Layers_Skipping.html#appendix",
    "title": "Multilingual Contrastive Decoding via Language-Agnostic Layers Skipping",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10795v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10795v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3434"
  },
  {
    "objectID": "posts/Review_driven_Personalized_Preference_Reasoning_with_Large_Language_Models_for_Recommendation/2024-08-12-Review_driven_Personalized_Preference_Reasoning_with_Large_Language_Models_for_Recommendation.html#appendix",
    "href": "posts/Review_driven_Personalized_Preference_Reasoning_with_Large_Language_Models_for_Recommendation/2024-08-12-Review_driven_Personalized_Preference_Reasoning_with_Large_Language_Models_for_Recommendation.html#appendix",
    "title": "Review-driven Personalized Preference Reasoning with Large Language Models for Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.06276v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.06276v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9253"
  },
  {
    "objectID": "posts/Using_Pretrained_Large_Language_Model_with_Prompt_Engineering_to_Answer_Biomedical_Questions/2024-07-09-Using_Pretrained_Large_Language_Model_with_Prompt_Engineering_to_Answer_Biomedical_Questions.html#appendix",
    "href": "posts/Using_Pretrained_Large_Language_Model_with_Prompt_Engineering_to_Answer_Biomedical_Questions/2024-07-09-Using_Pretrained_Large_Language_Model_with_Prompt_Engineering_to_Answer_Biomedical_Questions.html#appendix",
    "title": "Using Pretrained Large Language Model with Prompt Engineering to Answer Biomedical Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06779v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06779v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5905"
  },
  {
    "objectID": "posts/Jailbreaking_as_a_Reward_Misspecification_Problem/2024-06-20-Jailbreaking_as_a_Reward_Misspecification_Problem.html#appendix",
    "href": "posts/Jailbreaking_as_a_Reward_Misspecification_Problem/2024-06-20-Jailbreaking_as_a_Reward_Misspecification_Problem.html#appendix",
    "title": "Jailbreaking as a Reward Misspecification Problem",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14393v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14393v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7548"
  },
  {
    "objectID": "posts/Synthetic_Multimodal_Question_Generation/2024-07-02-Synthetic_Multimodal_Question_Generation.html#summary",
    "href": "posts/Synthetic_Multimodal_Question_Generation/2024-07-02-Synthetic_Multimodal_Question_Generation.html#summary",
    "title": "Synthetic Multimodal Question Generation",
    "section": "Summary:",
    "text": "Summary:\nThe paper introduces a method for Synthetic Multimodal Question Generation (SMMQG), a framework that leverages the interplay between a retriever, a large language model (LLM), and a large multimodal model (LMM) to generate question-answer pairs directly from multimodal documents. SMMQG enables fine-grained control over the styles and modalities of questions, and is capable of producing both unimodal and cross-modal questions. The authors use SMMQG to generate an MMRAG dataset of 1024 questions over Wikipedia documents and evaluate state-of-the-art models using it, revealing insights into model performance that are attainable only through style- and modality-specific evaluation data. A human study is conducted to measure the quality of the synthetic data, which is found to be on par with the quality of the crowdsourced benchmark MMQA."
  },
  {
    "objectID": "posts/Synthetic_Multimodal_Question_Generation/2024-07-02-Synthetic_Multimodal_Question_Generation.html#major-findings",
    "href": "posts/Synthetic_Multimodal_Question_Generation/2024-07-02-Synthetic_Multimodal_Question_Generation.html#major-findings",
    "title": "Synthetic Multimodal Question Generation",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nSMMQG is a powerful approach to question-answering over multimodal documents, enabling fine-grained control over the styles and modalities of questions.\nThe quality of the synthetic data generated by SMMQG is on par with the quality of the crowdsourced benchmark MMQA, as demonstrated by a human study.\nEvaluation results using the SMMQG dataset strongly concur with those obtained using MMQA, demonstrating that the synthetic dataset can be used in place of MMQA for model selection."
  },
  {
    "objectID": "posts/Synthetic_Multimodal_Question_Generation/2024-07-02-Synthetic_Multimodal_Question_Generation.html#analysis-and-critique",
    "href": "posts/Synthetic_Multimodal_Question_Generation/2024-07-02-Synthetic_Multimodal_Question_Generation.html#analysis-and-critique",
    "title": "Synthetic Multimodal Question Generation",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a novel and promising approach to generating synthetic multimodal question-answer pairs, addressing a key challenge in evaluating MMRAG systems. The use of a large language model and a large multimodal model in conjunction with a retriever allows for the generation of diverse and high-quality questions and answers. The evaluation of state-of-the-art models using the SMMQG dataset provides valuable insights into model performance, and the human study confirms the quality of the synthetic data.\nHowever, the paper does not discuss potential limitations or biases in the SMMQG framework, nor does it address the issue of generalizability to"
  },
  {
    "objectID": "posts/Synthetic_Multimodal_Question_Generation/2024-07-02-Synthetic_Multimodal_Question_Generation.html#appendix",
    "href": "posts/Synthetic_Multimodal_Question_Generation/2024-07-02-Synthetic_Multimodal_Question_Generation.html#appendix",
    "title": "Synthetic Multimodal Question Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02233v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02233v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13736"
  },
  {
    "objectID": "posts/Is_the_Digital_Forensics_and_Incident_Response_Pipeline_Ready_for_Text_Based_Threats_in_LLM_Era/2024-07-25-Is_the_Digital_Forensics_and_Incident_Response_Pipeline_Ready_for_Text_Based_Threats_in_LLM_Era.html#appendix",
    "href": "posts/Is_the_Digital_Forensics_and_Incident_Response_Pipeline_Ready_for_Text_Based_Threats_in_LLM_Era/2024-07-25-Is_the_Digital_Forensics_and_Incident_Response_Pipeline_Ready_for_Text_Based_Threats_in_LLM_Era.html#appendix",
    "title": "Is the Digital Forensics and Incident Response Pipeline Ready for Text-Based Threats in LLM Era?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17870v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17870v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4669"
  },
  {
    "objectID": "posts/Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities/2024-06-11-Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities.html",
    "href": "posts/Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities/2024-06-11-Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities.html",
    "title": "Toxic Memes: A Survey of Computational Perspectives on the Detection and Explanation of Meme Toxicities",
    "section": "",
    "text": "Summary:\nThis paper provides a comprehensive survey of 158 papers on computational perspectives on toxic memes, covering key developments up to early 2024. The study identifies a wide variety of terminology used to refer to toxic memes, highlighting the need for a clearer taxonomy and harmonized definitions. The authors introduce a novel taxonomy and offer insights into various dimensions of meme toxicity, including intent, target, and conveyance tactics. The paper also catalogs datasets containing toxic memes, analyzes prevalent challenges, and identifies emerging trends in computational approaches to toxic meme detection and interpretation. The survey aims to promote interdisciplinary collaboration and innovation to foster media literacy and a safer online ecosystem.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive survey of the literature on computational perspectives on toxic memes, offering valuable insights into the current state of the field. The introduction of a novel taxonomy and harmonized definitions is a significant contribution, as it addresses the need for a clearer taxonomy and harmonized definitions. The paper also identifies emerging trends in computational approaches to toxic meme detection and interpretation, which can guide future research in the field.\nHowever, the paper does not provide a critical analysis of the limitations and biases of the existing literature. Additionally, the paper does not discuss the potential ethical implications of using computational approaches to detect and interpret toxic memes. Future research should address these limitations and consider the ethical implications of using computational approaches to detect and interpret toxic"
  },
  {
    "objectID": "posts/Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities/2024-06-11-Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities.html#appendix",
    "href": "posts/Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities/2024-06-11-Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities.html#appendix",
    "title": "Toxic Memes: A Survey of Computational Perspectives on the Detection and Explanation of Meme Toxicities",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07353v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07353v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20322"
  },
  {
    "objectID": "posts/Do_LLMs_Exhibit_Human_Like_Reasoning_Evaluating_Theory_of_Mind_in_LLMs_for_Open_Ended_Responses/2024-06-09-Do_LLMs_Exhibit_Human_Like_Reasoning_Evaluating_Theory_of_Mind_in_LLMs_for_Open_Ended_Responses.html#appendix",
    "href": "posts/Do_LLMs_Exhibit_Human_Like_Reasoning_Evaluating_Theory_of_Mind_in_LLMs_for_Open_Ended_Responses/2024-06-09-Do_LLMs_Exhibit_Human_Like_Reasoning_Evaluating_Theory_of_Mind_in_LLMs_for_Open_Ended_Responses.html#appendix",
    "title": "Do LLMs Exhibit Human-Like Reasoning? Evaluating Theory of Mind in LLMs for Open-Ended Responses",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05659v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05659v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10269"
  },
  {
    "objectID": "posts/From_Sands_to_Mansions_Enabling_Automatic_Full_Life_Cycle_Cyberattack_Construction_with_LLM/2024-07-24-From_Sands_to_Mansions_Enabling_Automatic_Full_Life_Cycle_Cyberattack_Construction_with_LLM.html#appendix",
    "href": "posts/From_Sands_to_Mansions_Enabling_Automatic_Full_Life_Cycle_Cyberattack_Construction_with_LLM/2024-07-24-From_Sands_to_Mansions_Enabling_Automatic_Full_Life_Cycle_Cyberattack_Construction_with_LLM.html#appendix",
    "title": "From Sands to Mansions: Enabling Automatic Full-Life-Cycle Cyberattack Construction with LLM",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16928v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16928v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12045"
  },
  {
    "objectID": "posts/Hide_and_Seek_Fingerprinting_Large_Language_Models_with_Evolutionary_Learning/2024-08-06-Hide_and_Seek_Fingerprinting_Large_Language_Models_with_Evolutionary_Learning.html",
    "href": "posts/Hide_and_Seek_Fingerprinting_Large_Language_Models_with_Evolutionary_Learning/2024-08-06-Hide_and_Seek_Fingerprinting_Large_Language_Models_with_Evolutionary_Learning.html",
    "title": "Hide and Seek: Fingerprinting Large Language Models with Evolutionary Learning",
    "section": "",
    "text": "Summary:\nThe paper “Hide and Seek: Fingerprinting Large Language Models with Evolutionary Learning” introduces a novel black-box approach for fingerprinting LLMs, achieving an impressive 72% accuracy in identifying the correct family of models. The method employs an evolutionary strategy that leverages the capabilities of one LLM to discover the most salient features for identifying other LLMs. The approach, called “Hide and Seek,” uses an Auditor LLM to generate discriminative prompts and a Detective LLM to analyze the responses to fingerprint the target models. This method not only demonstrates the feasibility of LLM-driven model identification but also reveals insights into the semantic manifolds of different LLM families.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an innovative approach to fingerprinting LLMs using an evolutionary learning strategy. The “Hide and Seek” algorithm effectively leverages the capabilities of one LLM to discover the most salient features for identifying other LLMs. However, the paper does not provide a detailed comparison with existing methods for fingerprinting LLMs, making it difficult to assess the advantages and disadvantages of the proposed approach. Additionally, the paper does not discuss the potential limitations or biases that may arise from using LLMs for fingerprinting, which could impact the accuracy and reliability of the results. Further research is needed to evaluate the proposed method’s performance against existing techniques and to address potential limitations and biases."
  },
  {
    "objectID": "posts/Hide_and_Seek_Fingerprinting_Large_Language_Models_with_Evolutionary_Learning/2024-08-06-Hide_and_Seek_Fingerprinting_Large_Language_Models_with_Evolutionary_Learning.html#appendix",
    "href": "posts/Hide_and_Seek_Fingerprinting_Large_Language_Models_with_Evolutionary_Learning/2024-08-06-Hide_and_Seek_Fingerprinting_Large_Language_Models_with_Evolutionary_Learning.html#appendix",
    "title": "Hide and Seek: Fingerprinting Large Language Models with Evolutionary Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02871v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02871v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12531"
  },
  {
    "objectID": "posts/On_the_(In)Security_of_LLM_App_Stores/2024-07-11-On_the_(In)Security_of_LLM_App_Stores.html#major-findings",
    "href": "posts/On_the_(In)Security_of_LLM_App_Stores/2024-07-11-On_the_(In)Security_of_LLM_App_Stores.html#major-findings",
    "title": "On the (In)Security of LLM App Stores",
    "section": "Major Findings",
    "text": "Major Findings\n\nMisleading descriptions: 15,146 apps had misleading descriptions, potentially deceiving users and hiding malicious intent.\nPrivacy policy violations: 1,366 apps collected sensitive personal information against their privacy policies, posing a risk to user privacy.\nHarmful content generation: 15,996 apps generated harmful content, including hate speech, self-harm, extremism, etc.\nMalicious activities: 616 apps could be used for malicious activities, such as malware generation and phishing."
  },
  {
    "objectID": "posts/On_the_(In)Security_of_LLM_App_Stores/2024-07-11-On_the_(In)Security_of_LLM_App_Stores.html#analysis-and-critique",
    "href": "posts/On_the_(In)Security_of_LLM_App_Stores/2024-07-11-On_the_(In)Security_of_LLM_App_Stores.html#analysis-and-critique",
    "title": "On the (In)Security of LLM App Stores",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\nThe study provides a comprehensive analysis of the security concerns in LLM app stores, highlighting the need for stronger regulatory measures and improved security practices. However, the research has some limitations. The dataset used may not be entirely representative of the broader LLM app ecosystem, as it only includes six app stores. Additionally, the accuracy of the findings is influenced by the quality and completeness of the data provided by the app stores. The methodology employed for detecting abusive potential, malicious intent, and exploitable vulnerabilities relies on predefined criteria and automated tools"
  },
  {
    "objectID": "posts/On_the_(In)Security_of_LLM_App_Stores/2024-07-11-On_the_(In)Security_of_LLM_App_Stores.html#appendix",
    "href": "posts/On_the_(In)Security_of_LLM_App_Stores/2024-07-11-On_the_(In)Security_of_LLM_App_Stores.html#appendix",
    "title": "On the (In)Security of LLM App Stores",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08422v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08422v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12874"
  },
  {
    "objectID": "posts/Performance_Law_of_Large_Language_Models/2024-08-19-Performance_Law_of_Large_Language_Models.html#appendix",
    "href": "posts/Performance_Law_of_Large_Language_Models/2024-08-19-Performance_Law_of_Large_Language_Models.html#appendix",
    "title": "Performance Law of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.09895v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.09895v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5218"
  },
  {
    "objectID": "posts/Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110/2024-06-10-Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110.html",
    "href": "posts/Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110/2024-06-10-Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110.html",
    "title": "Harnessing AI for efficient analysis of complex policy documents: a case study of Executive Order 14110",
    "section": "",
    "text": "Summary:\nThis study investigates the accuracy and reliability of large language model (LLM)-based AI systems in extracting information from complex policy documents, such as Executive Order 14110. The research focuses on question answering and tasks involving content extraction, comparing the performance of four commercial AI systems (Claude 3 Opus, ChatGPT-4, Gemini Pro 1.5, and Command R+) to manual analysis conducted by human experts. The results show that Gemini and Claude demonstrated the most comprehensive understanding of the EO, consistently providing concise, accurate, and detailed responses. However, achieving acceptable levels of reproducibility and trustworthiness remains a critical challenge that necessitates further research and development.\nMajor Findings:\nAnalysis and Critique:\nThe study provides valuable insights into the potential of AI in policy analysis, but there are several limitations to consider:\nFurther research could involve testing other AI models, including open-source alternatives, mixture-of-"
  },
  {
    "objectID": "posts/Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110/2024-06-10-Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110.html#appendix",
    "href": "posts/Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110/2024-06-10-Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110.html#appendix",
    "title": "Harnessing AI for efficient analysis of complex policy documents: a case study of Executive Order 14110",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06657v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06657v1\n\n\nTruncated\nFalse\n\n\nWord Count\n25409"
  },
  {
    "objectID": "posts/LLM_Targeted_Underperformance_Disproportionately_Impacts_Vulnerable_Users/2024-06-25-LLM_Targeted_Underperformance_Disproportionately_Impacts_Vulnerable_Users.html#appendix",
    "href": "posts/LLM_Targeted_Underperformance_Disproportionately_Impacts_Vulnerable_Users/2024-06-25-LLM_Targeted_Underperformance_Disproportionately_Impacts_Vulnerable_Users.html#appendix",
    "title": "LLM Targeted Underperformance Disproportionately Impacts Vulnerable Users",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17737v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17737v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6850"
  },
  {
    "objectID": "posts/APEER_Automatic_Prompt_Engineering_Enhances_Large_Language_Model_Reranking/2024-06-20-APEER_Automatic_Prompt_Engineering_Enhances_Large_Language_Model_Reranking.html#appendix",
    "href": "posts/APEER_Automatic_Prompt_Engineering_Enhances_Large_Language_Model_Reranking/2024-06-20-APEER_Automatic_Prompt_Engineering_Enhances_Large_Language_Model_Reranking.html#appendix",
    "title": "APEER: Automatic Prompt Engineering Enhances Large Language Model Reranking",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14449v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14449v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7262"
  },
  {
    "objectID": "posts/Pyramid_Coder_Hierarchical_Code_Generator_for_Compositional_Visual_Question_Answering/2024-07-30-Pyramid_Coder_Hierarchical_Code_Generator_for_Compositional_Visual_Question_Answering.html#appendix",
    "href": "posts/Pyramid_Coder_Hierarchical_Code_Generator_for_Compositional_Visual_Question_Answering/2024-07-30-Pyramid_Coder_Hierarchical_Code_Generator_for_Compositional_Visual_Question_Answering.html#appendix",
    "title": "Pyramid Coder: Hierarchical Code Generator for Compositional Visual Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20563v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20563v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4584"
  },
  {
    "objectID": "posts/Agentless_Demystifying_LLM_based_Software_Engineering_Agents/2024-07-01-Agentless_Demystifying_LLM_based_Software_Engineering_Agents.html#appendix",
    "href": "posts/Agentless_Demystifying_LLM_based_Software_Engineering_Agents/2024-07-01-Agentless_Demystifying_LLM_based_Software_Engineering_Agents.html#appendix",
    "title": "Agentless: Demystifying LLM-based Software Engineering Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01489v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01489v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8295"
  },
  {
    "objectID": "posts/Does_Reasoning_Emerge_Examining_the_Probabilities_of_Causation_in_Large_Language_Models/2024-08-15-Does_Reasoning_Emerge_Examining_the_Probabilities_of_Causation_in_Large_Language_Models.html#appendix",
    "href": "posts/Does_Reasoning_Emerge_Examining_the_Probabilities_of_Causation_in_Large_Language_Models/2024-08-15-Does_Reasoning_Emerge_Examining_the_Probabilities_of_Causation_in_Large_Language_Models.html#appendix",
    "title": "Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.08210v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.08210v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8021"
  },
  {
    "objectID": "posts/Investigating_Low_Cost_LLM_Annotation_for~Spoken_Dialogue_Understanding_Datasets/2024-06-19-Investigating_Low_Cost_LLM_Annotation_for~Spoken_Dialogue_Understanding_Datasets.html#appendix",
    "href": "posts/Investigating_Low_Cost_LLM_Annotation_for~Spoken_Dialogue_Understanding_Datasets/2024-06-19-Investigating_Low_Cost_LLM_Annotation_for~Spoken_Dialogue_Understanding_Datasets.html#appendix",
    "title": "Investigating Low-Cost LLM Annotation for~Spoken Dialogue Understanding Datasets",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13269v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13269v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6424"
  },
  {
    "objectID": "posts/WildGuard_Open_One_Stop_Moderation_Tools_for_Safety_Risks_Jailbreaks_and_Refusals_of_LLMs/2024-06-26-WildGuard_Open_One_Stop_Moderation_Tools_for_Safety_Risks_Jailbreaks_and_Refusals_of_LLMs.html#appendix",
    "href": "posts/WildGuard_Open_One_Stop_Moderation_Tools_for_Safety_Risks_Jailbreaks_and_Refusals_of_LLMs/2024-06-26-WildGuard_Open_One_Stop_Moderation_Tools_for_Safety_Risks_Jailbreaks_and_Refusals_of_LLMs.html#appendix",
    "title": "WildGuard: Open One-Stop Moderation Tools for Safety Risks, Jailbreaks, and Refusals of LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18495v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18495v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13217"
  },
  {
    "objectID": "posts/Usefulness_of_data_flow_diagrams_and_large_language_models_for_security_threat_validation_a_registered_report/2024-08-15-Usefulness_of_data_flow_diagrams_and_large_language_models_for_security_threat_validation_a_registered_report.html#appendix",
    "href": "posts/Usefulness_of_data_flow_diagrams_and_large_language_models_for_security_threat_validation_a_registered_report/2024-08-15-Usefulness_of_data_flow_diagrams_and_large_language_models_for_security_threat_validation_a_registered_report.html#appendix",
    "title": "Usefulness of data flow diagrams and large language models for security threat validation: a registered report",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07537v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07537v2\n\n\nTruncated\nFalse\n\n\nWord Count\n7717"
  },
  {
    "objectID": "posts/Recursive_Introspection_Teaching_Language_Model_Agents_How_to_Self_Improve/2024-07-25-Recursive_Introspection_Teaching_Language_Model_Agents_How_to_Self_Improve.html",
    "href": "posts/Recursive_Introspection_Teaching_Language_Model_Agents_How_to_Self_Improve/2024-07-25-Recursive_Introspection_Teaching_Language_Model_Agents_How_to_Self_Improve.html",
    "title": "Recursive Introspection: Teaching Language Model Agents How to Self-Improve",
    "section": "",
    "text": "Summary:\nThe paper introduces RISE (Recursive Introspection), a novel approach for fine-tuning large language models (LLMs) to enable them to improve their responses over multiple turns. RISE is designed to address the challenge of test-time self-improvement, which is not exhibited by even the strongest proprietary LLMs. The approach involves an iterative fine-tuning procedure that teaches the model to alter its response after unsuccessful attempts to solve a hard test-time problem, with optional additional environment feedback. RISE poses fine-tuning for a single-turn prompt as solving a multi-turn Markov decision process (MDP), where the initial state is the prompt. The paper draws inspiration from principles in online imitation learning and reinforcement learning to propose strategies for multi-turn data collection and training. The experiments demonstrate that RISE enables Llama2, Llama3, and Mistral models to improve themselves with more turns on math reasoning tasks, outperforming several single-turn strategies given an equal amount of inference-time computation. RISE also scales well, often attaining larger benefits with more capable models. The analysis shows that RISE makes meaningful improvements to responses without disrupting one-turn abilities.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a promising approach to enable test-time self-improvement in LLMs. The experiments demonstrate the effectiveness of RISE in improving the performance of LLMs on math reasoning tasks. However, the paper does not discuss the potential limitations or shortcomings of the approach. For instance, it is unclear how RISE would perform on other types of tasks beyond math reasoning. Additionally, the paper does not provide a detailed comparison with other fine-tuning methods, which could help to better understand the advantages and disadvantages of RISE. Furthermore,"
  },
  {
    "objectID": "posts/Recursive_Introspection_Teaching_Language_Model_Agents_How_to_Self_Improve/2024-07-25-Recursive_Introspection_Teaching_Language_Model_Agents_How_to_Self_Improve.html#appendix",
    "href": "posts/Recursive_Introspection_Teaching_Language_Model_Agents_How_to_Self_Improve/2024-07-25-Recursive_Introspection_Teaching_Language_Model_Agents_How_to_Self_Improve.html#appendix",
    "title": "Recursive Introspection: Teaching Language Model Agents How to Self-Improve",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.18219v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.18219v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14314"
  },
  {
    "objectID": "posts/WalledEval_A_Comprehensive_Safety_Evaluation_Toolkit_for_Large_Language_Models/2024-08-07-WalledEval_A_Comprehensive_Safety_Evaluation_Toolkit_for_Large_Language_Models.html#appendix",
    "href": "posts/WalledEval_A_Comprehensive_Safety_Evaluation_Toolkit_for_Large_Language_Models/2024-08-07-WalledEval_A_Comprehensive_Safety_Evaluation_Toolkit_for_Large_Language_Models.html#appendix",
    "title": "WalledEval: A Comprehensive Safety Evaluation Toolkit for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03837v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03837v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4789"
  },
  {
    "objectID": "posts/Language_Models_are_Alignable_Decision_Makers_Dataset_and_Application_to_the_Medical_Triage_Domain/2024-06-10-Language_Models_are_Alignable_Decision_Makers_Dataset_and_Application_to_the_Medical_Triage_Domain.html#appendix",
    "href": "posts/Language_Models_are_Alignable_Decision_Makers_Dataset_and_Application_to_the_Medical_Triage_Domain/2024-06-10-Language_Models_are_Alignable_Decision_Makers_Dataset_and_Application_to_the_Medical_Triage_Domain.html#appendix",
    "title": "Language Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06435v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06435v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9086"
  },
  {
    "objectID": "posts/Impact_of_Decoding_Methods_on_Human_Alignment_of_Conversational_LLMs/2024-07-28-Impact_of_Decoding_Methods_on_Human_Alignment_of_Conversational_LLMs.html#appendix",
    "href": "posts/Impact_of_Decoding_Methods_on_Human_Alignment_of_Conversational_LLMs/2024-07-28-Impact_of_Decoding_Methods_on_Human_Alignment_of_Conversational_LLMs.html#appendix",
    "title": "Impact of Decoding Methods on Human Alignment of Conversational LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19526v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19526v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3736"
  },
  {
    "objectID": "posts/Arabic_Automatic_Story_Generation_with_Large_Language_Models/2024-07-10-Arabic_Automatic_Story_Generation_with_Large_Language_Models.html#appendix",
    "href": "posts/Arabic_Automatic_Story_Generation_with_Large_Language_Models/2024-07-10-Arabic_Automatic_Story_Generation_with_Large_Language_Models.html#appendix",
    "title": "Arabic Automatic Story Generation with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07551v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07551v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6596"
  },
  {
    "objectID": "posts/How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States/2024-06-09-How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States.html",
    "href": "posts/How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States/2024-06-09-How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States.html",
    "title": "How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States",
    "section": "",
    "text": "Summary:\nThis paper explores how alignment and jailbreak work in large language models (LLMs) by using weak classifiers to explain LLM safety through intermediate hidden states. The authors confirm that LLMs learn ethical concepts during pre-training rather than alignment and can identify malicious and normal inputs in the early layers. Alignment associates the early concepts with emotion guesses in the middle layers and then refines them to specific reject tokens for safe generations. Jailbreak disturbs the transformation of early unethical classification into negative emotions. The paper conducts experiments on models from 7B to 70B across various model families to prove their conclusion.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a novel perspective on LLM safety by explaining how alignment and jailbreak work through intermediate hidden states. The use of weak classifiers to explain LLM safety is an innovative approach that could be applied to other aspects of LLM behavior. However, the paper does not discuss the limitations of using weak classifiers or the potential biases that may be introduced. Additionally, the paper does not address the potential risks of jailbreak, such as the generation of harmful content, and how these risks can be mitigated. Overall, the paper provides valuable insights into LLM safety and offers a new perspective on how alignment and jailbreak work."
  },
  {
    "objectID": "posts/How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States/2024-06-09-How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States.html#appendix",
    "href": "posts/How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States/2024-06-09-How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States.html#appendix",
    "title": "How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05644v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05644v1\n\n\nTruncated\nFalse\n\n\nWord Count\n19114"
  },
  {
    "objectID": "posts/CoSQA+_Enhancing_Code_Search_Dataset_with_Matching_Code/2024-06-17-CoSQA+_Enhancing_Code_Search_Dataset_with_Matching_Code.html#appendix",
    "href": "posts/CoSQA+_Enhancing_Code_Search_Dataset_with_Matching_Code/2024-06-17-CoSQA+_Enhancing_Code_Search_Dataset_with_Matching_Code.html#appendix",
    "title": "CoSQA+: Enhancing Code Search Dataset with Matching Code",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11589v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11589v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6587"
  },
  {
    "objectID": "posts/Predicting_the_Big_Five_Personality_Traits_in_Chinese_Counselling_Dialogues_Using_Large_Language_Models/2024-06-25-Predicting_the_Big_Five_Personality_Traits_in_Chinese_Counselling_Dialogues_Using_Large_Language_Models.html#appendix",
    "href": "posts/Predicting_the_Big_Five_Personality_Traits_in_Chinese_Counselling_Dialogues_Using_Large_Language_Models/2024-06-25-Predicting_the_Big_Five_Personality_Traits_in_Chinese_Counselling_Dialogues_Using_Large_Language_Models.html#appendix",
    "title": "Predicting the Big Five Personality Traits in Chinese Counselling Dialogues Using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17287v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17287v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10813"
  },
  {
    "objectID": "posts/Limited_Out_of_Context_Knowledge_Reasoning_in_Large_Language_Models/2024-06-11-Limited_Out_of_Context_Knowledge_Reasoning_in_Large_Language_Models.html#appendix",
    "href": "posts/Limited_Out_of_Context_Knowledge_Reasoning_in_Large_Language_Models/2024-06-11-Limited_Out_of_Context_Knowledge_Reasoning_in_Large_Language_Models.html#appendix",
    "title": "Limited Out-of-Context Knowledge Reasoning in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07393v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07393v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5931"
  },
  {
    "objectID": "posts/From_Text_to_Test_AI_Generated_Control_Software_for_Materials_Science_Instruments/2024-06-23-From_Text_to_Test_AI_Generated_Control_Software_for_Materials_Science_Instruments.html#appendix",
    "href": "posts/From_Text_to_Test_AI_Generated_Control_Software_for_Materials_Science_Instruments/2024-06-23-From_Text_to_Test_AI_Generated_Control_Software_for_Materials_Science_Instruments.html#appendix",
    "title": "From Text to Test: AI-Generated Control Software for Materials Science Instruments",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16224v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16224v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8908"
  },
  {
    "objectID": "posts/RedWhale_An_Adapted_Korean_LLM_Through_Efficient_Continual_Pretraining/2024-08-21-RedWhale_An_Adapted_Korean_LLM_Through_Efficient_Continual_Pretraining.html#appendix",
    "href": "posts/RedWhale_An_Adapted_Korean_LLM_Through_Efficient_Continual_Pretraining/2024-08-21-RedWhale_An_Adapted_Korean_LLM_Through_Efficient_Continual_Pretraining.html#appendix",
    "title": "RedWhale: An Adapted Korean LLM Through Efficient Continual Pretraining",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.11294v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.11294v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13631"
  },
  {
    "objectID": "posts/MInference_1.0_Accelerating_Pre_filling_for_Long_Context_LLMs_via_Dynamic_Sparse_Attention/2024-07-02-MInference_1.0_Accelerating_Pre_filling_for_Long_Context_LLMs_via_Dynamic_Sparse_Attention.html#appendix",
    "href": "posts/MInference_1.0_Accelerating_Pre_filling_for_Long_Context_LLMs_via_Dynamic_Sparse_Attention/2024-07-02-MInference_1.0_Accelerating_Pre_filling_for_Long_Context_LLMs_via_Dynamic_Sparse_Attention.html#appendix",
    "title": "MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02490v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02490v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10854"
  },
  {
    "objectID": "posts/Covert_Bias_The_Severity_of_Social_Views_Unalignment_Towards_Implicit_and_Explicit_Opinion/2024-08-15-Covert_Bias_The_Severity_of_Social_Views_Unalignment_Towards_Implicit_and_Explicit_Opinion.html#appendix",
    "href": "posts/Covert_Bias_The_Severity_of_Social_Views_Unalignment_Towards_Implicit_and_Explicit_Opinion/2024-08-15-Covert_Bias_The_Severity_of_Social_Views_Unalignment_Towards_Implicit_and_Explicit_Opinion.html#appendix",
    "title": "Covert Bias: The Severity of Social Views’ Unalignment Towards Implicit and Explicit Opinion",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.08212v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.08212v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5173"
  },
  {
    "objectID": "posts/A_Probabilistic_Framework_for_LLM_Hallucination_Detection_via_Belief_Tree_Propagation/2024-06-11-A_Probabilistic_Framework_for_LLM_Hallucination_Detection_via_Belief_Tree_Propagation.html#appendix",
    "href": "posts/A_Probabilistic_Framework_for_LLM_Hallucination_Detection_via_Belief_Tree_Propagation/2024-06-11-A_Probabilistic_Framework_for_LLM_Hallucination_Detection_via_Belief_Tree_Propagation.html#appendix",
    "title": "A Probabilistic Framework for LLM Hallucination Detection via Belief Tree Propagation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06950v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06950v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10310"
  },
  {
    "objectID": "posts/Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory/2024-06-20-Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory.html",
    "href": "posts/Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory/2024-06-20-Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory.html",
    "title": "Artificial Leviathan: Exploring Social Evolution of LLM Agents Through the Lens of Hobbesian Social Contract Theory",
    "section": "",
    "text": "Summary:\nThe paper presents a novel multi-agent simulation framework that generates believable artificial societies capable of replicating complex human group behaviors and social interactions. The agents’ behaviors are conditioned by their innate psychological drives, intrinsic motivations, and the constraints of their simulated environment. Empirical evidence from systematic experiments establishes correlations between agent attributes and available resources, and the evolutionary trajectories of simulated societies. The analysis discusses the collective behaviors of the generative agents, highlighting the opportunities and potential risks associated with leveraging LLMs for societal simulations.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an innovative approach to simulating complex human group behaviors and social interactions using LLMs. The empirical evidence from systematic experiments supports the correlations between agent attributes and available resources, and the evolutionary trajectories of simulated societies. However, the paper does not address the limitations of LLMs in accurately modeling human behavior, such as the inability to capture the nuances of human emotions and decision-making processes. Additionally, the paper does not discuss the potential biases introduced by the LLMs used in the simulation, which could impact the accuracy of the results. Overall, the paper provides a valuable contribution to the field of computational social science, but further research is needed to address the limitations and biases of LLMs in simulating human behavior."
  },
  {
    "objectID": "posts/Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory/2024-06-20-Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory.html#appendix",
    "href": "posts/Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory/2024-06-20-Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory.html#appendix",
    "title": "Artificial Leviathan: Exploring Social Evolution of LLM Agents Through the Lens of Hobbesian Social Contract Theory",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14373v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14373v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12979"
  },
  {
    "objectID": "posts/How_Well_Can_Knowledge_Edit_Methods_Edit_Perplexing_Knowledge/2024-06-25-How_Well_Can_Knowledge_Edit_Methods_Edit_Perplexing_Knowledge.html#appendix",
    "href": "posts/How_Well_Can_Knowledge_Edit_Methods_Edit_Perplexing_Knowledge/2024-06-25-How_Well_Can_Knowledge_Edit_Methods_Edit_Perplexing_Knowledge.html#appendix",
    "title": "How Well Can Knowledge Edit Methods Edit Perplexing Knowledge?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17253v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17253v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6890"
  },
  {
    "objectID": "posts/Asynchronous_Large_Language_Model_Enhanced_Planner_for_Autonomous_Driving/2024-06-20-Asynchronous_Large_Language_Model_Enhanced_Planner_for_Autonomous_Driving.html#appendix",
    "href": "posts/Asynchronous_Large_Language_Model_Enhanced_Planner_for_Autonomous_Driving/2024-06-20-Asynchronous_Large_Language_Model_Enhanced_Planner_for_Autonomous_Driving.html#appendix",
    "title": "Asynchronous Large Language Model Enhanced Planner for Autonomous Driving",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14556v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14556v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9407"
  },
  {
    "objectID": "posts/MindSearch_Mimicking_Human_Minds_Elicits_Deep_AI_Searcher/2024-07-29-MindSearch_Mimicking_Human_Minds_Elicits_Deep_AI_Searcher.html#appendix",
    "href": "posts/MindSearch_Mimicking_Human_Minds_Elicits_Deep_AI_Searcher/2024-07-29-MindSearch_Mimicking_Human_Minds_Elicits_Deep_AI_Searcher.html#appendix",
    "title": "MindSearch: Mimicking Human Minds Elicits Deep AI Searcher",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20183v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20183v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5127"
  },
  {
    "objectID": "posts/CogErgLLM_Exploring_Large_Language_Model_Systems_Design_Perspective_Using_Cognitive_Ergonomics/2024-07-03-CogErgLLM_Exploring_Large_Language_Model_Systems_Design_Perspective_Using_Cognitive_Ergonomics.html#appendix",
    "href": "posts/CogErgLLM_Exploring_Large_Language_Model_Systems_Design_Perspective_Using_Cognitive_Ergonomics/2024-07-03-CogErgLLM_Exploring_Large_Language_Model_Systems_Design_Perspective_Using_Cognitive_Ergonomics.html#appendix",
    "title": "CogErgLLM: Exploring Large Language Model Systems Design Perspective Using Cognitive Ergonomics",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02885v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02885v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5038"
  },
  {
    "objectID": "posts/Graph_Augmented_LLMs_for_Personalized_Health_Insights_A_Case_Study_in_Sleep_Analysis/2024-06-24-Graph_Augmented_LLMs_for_Personalized_Health_Insights_A_Case_Study_in_Sleep_Analysis.html#appendix",
    "href": "posts/Graph_Augmented_LLMs_for_Personalized_Health_Insights_A_Case_Study_in_Sleep_Analysis/2024-06-24-Graph_Augmented_LLMs_for_Personalized_Health_Insights_A_Case_Study_in_Sleep_Analysis.html#appendix",
    "title": "Graph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16252v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16252v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3224"
  },
  {
    "objectID": "posts/GraphCoder_Enhancing_Repository_Level_Code_Completion_via_Code_Context_Graph_based_Retrieval_and_Language_Model/2024-06-11-GraphCoder_Enhancing_Repository_Level_Code_Completion_via_Code_Context_Graph_based_Retrieval_and_Language_Model.html#appendix",
    "href": "posts/GraphCoder_Enhancing_Repository_Level_Code_Completion_via_Code_Context_Graph_based_Retrieval_and_Language_Model/2024-06-11-GraphCoder_Enhancing_Repository_Level_Code_Completion_via_Code_Context_Graph_based_Retrieval_and_Language_Model.html#appendix",
    "title": "GraphCoder: Enhancing Repository-Level Code Completion via Code Context Graph-based Retrieval and Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07003v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07003v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9656"
  },
  {
    "objectID": "posts/Noisy_Neighbors_Efficient_membership_inference_attacks_against_LLMs/2024-06-24-Noisy_Neighbors_Efficient_membership_inference_attacks_against_LLMs.html#appendix",
    "href": "posts/Noisy_Neighbors_Efficient_membership_inference_attacks_against_LLMs/2024-06-24-Noisy_Neighbors_Efficient_membership_inference_attacks_against_LLMs.html#appendix",
    "title": "Noisy Neighbors: Efficient membership inference attacks against LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16565v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16565v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3223"
  },
  {
    "objectID": "posts/Perceive_Reflect_and_Plan_Designing_LLM_Agent_for_Goal_Directed_City_Navigation_without_Instructions/2024-08-08-Perceive_Reflect_and_Plan_Designing_LLM_Agent_for_Goal_Directed_City_Navigation_without_Instructions.html#appendix",
    "href": "posts/Perceive_Reflect_and_Plan_Designing_LLM_Agent_for_Goal_Directed_City_Navigation_without_Instructions/2024-08-08-Perceive_Reflect_and_Plan_Designing_LLM_Agent_for_Goal_Directed_City_Navigation_without_Instructions.html#appendix",
    "title": "Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04168v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04168v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11761"
  },
  {
    "objectID": "posts/MEDCO_Medical_Education_Copilots_Based_on_A_Multi_Agent_Framework/2024-08-22-MEDCO_Medical_Education_Copilots_Based_on_A_Multi_Agent_Framework.html#appendix",
    "href": "posts/MEDCO_Medical_Education_Copilots_Based_on_A_Multi_Agent_Framework/2024-08-22-MEDCO_Medical_Education_Copilots_Based_on_A_Multi_Agent_Framework.html#appendix",
    "title": "MEDCO: Medical Education Copilots Based on A Multi-Agent Framework",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12496v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12496v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8378"
  },
  {
    "objectID": "posts/Generative_AI_as_a_Service_in_6G_Edge_Cloud_Generation_Task_Offloading_by_In_context_Learning/2024-08-05-Generative_AI_as_a_Service_in_6G_Edge_Cloud_Generation_Task_Offloading_by_In_context_Learning.html#major-findings",
    "href": "posts/Generative_AI_as_a_Service_in_6G_Edge_Cloud_Generation_Task_Offloading_by_In_context_Learning/2024-08-05-Generative_AI_as_a_Service_in_6G_Edge_Cloud_Generation_Task_Offloading_by_In_context_Learning.html#major-findings",
    "title": "Generative AI as a Service in 6G Edge-Cloud: Generation Task Offloading by In-context Learning",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe article presents a novel edge-cloud collaboration strategy for deploying GAI foundation models in 6G networks.\nThe authors introduce a communication system model for content transmission and an LLM inference model for content generation.\nThe article proposes a novel in-context learning method for generation task offloading, which avoids the complexity of dedicated model training and fine-tuning.\nThe proposed method is evaluated through simulations, demonstrating that the edge-cloud deployment and in-context learning task offloading method can achieve satisfactory generation service quality."
  },
  {
    "objectID": "posts/Generative_AI_as_a_Service_in_6G_Edge_Cloud_Generation_Task_Offloading_by_In_context_Learning/2024-08-05-Generative_AI_as_a_Service_in_6G_Edge_Cloud_Generation_Task_Offloading_by_In_context_Learning.html#analysis-and-critique",
    "href": "posts/Generative_AI_as_a_Service_in_6G_Edge_Cloud_Generation_Task_Offloading_by_In_context_Learning/2024-08-05-Generative_AI_as_a_Service_in_6G_Edge_Cloud_Generation_Task_Offloading_by_In_context_Learning.html#analysis-and-critique",
    "title": "Generative AI as a Service in 6G Edge-Cloud: Generation Task Offloading by In-context Learning",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe article provides a detailed and well-structured approach to deploying GAI foundation models in 6G networks.\nThe proposed in-context learning method for generation task offloading is a significant contribution, as it avoids the complexity of dedicated model training and fine-tuning.\nThe simulations demonstrate the effectiveness of the proposed method, but they are limited in scope and do not consider real-world network conditions.\nThe article does not discuss the potential challenges and limitations of deploying GAI foundation models in 6G networks, such as the high computational and storage requirements of large-scale LLMs.\nThe article does not provide a comprehensive comparison of the proposed method with existing task offloading methods in the literature.\nThe article does not discuss the potential privacy and security implications of deploying GAI foundation models in 6G networks."
  },
  {
    "objectID": "posts/Generative_AI_as_a_Service_in_6G_Edge_Cloud_Generation_Task_Offloading_by_In_context_Learning/2024-08-05-Generative_AI_as_a_Service_in_6G_Edge_Cloud_Generation_Task_Offloading_by_In_context_Learning.html#appendix",
    "href": "posts/Generative_AI_as_a_Service_in_6G_Edge_Cloud_Generation_Task_Offloading_by_In_context_Learning/2024-08-05-Generative_AI_as_a_Service_in_6G_Edge_Cloud_Generation_Task_Offloading_by_In_context_Learning.html#appendix",
    "title": "Generative AI as a Service in 6G Edge-Cloud: Generation Task Offloading by In-context Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02549v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02549v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4801"
  },
  {
    "objectID": "posts/Demo_Generative_Open_xG_Network_Simulation_with_Multi_Agent_LLM_and_ns_3_(GenOnet)/2024-08-25-Demo_Generative_Open_xG_Network_Simulation_with_Multi_Agent_LLM_and_ns_3_(GenOnet).html#appendix",
    "href": "posts/Demo_Generative_Open_xG_Network_Simulation_with_Multi_Agent_LLM_and_ns_3_(GenOnet)/2024-08-25-Demo_Generative_Open_xG_Network_Simulation_with_Multi_Agent_LLM_and_ns_3_(GenOnet).html#appendix",
    "title": "Demo: Generative Open xG Network Simulation with Multi-Agent LLM and ns-3 (GenOnet)",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.13781v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.13781v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2515"
  },
  {
    "objectID": "posts/Role_Play_Zero_Shot_Prompting_with_Large_Language_Models_for_Open_Domain_Human_Machine_Conversation/2024-06-26-Role_Play_Zero_Shot_Prompting_with_Large_Language_Models_for_Open_Domain_Human_Machine_Conversation.html#appendix",
    "href": "posts/Role_Play_Zero_Shot_Prompting_with_Large_Language_Models_for_Open_Domain_Human_Machine_Conversation/2024-06-26-Role_Play_Zero_Shot_Prompting_with_Large_Language_Models_for_Open_Domain_Human_Machine_Conversation.html#appendix",
    "title": "Role-Play Zero-Shot Prompting with Large Language Models for Open-Domain Human-Machine Conversation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18460v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18460v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7179"
  },
  {
    "objectID": "posts/CityGPT_Empowering_Urban_Spatial_Cognition_of_Large_Language_Models/2024-06-20-CityGPT_Empowering_Urban_Spatial_Cognition_of_Large_Language_Models.html",
    "href": "posts/CityGPT_Empowering_Urban_Spatial_Cognition_of_Large_Language_Models/2024-06-20-CityGPT_Empowering_Urban_Spatial_Cognition_of_Large_Language_Models.html",
    "title": "CityGPT: Empowering Urban Spatial Cognition of Large Language Models",
    "section": "",
    "text": "Overall Summary:\nThe paper introduces CityGPT, a framework designed to enhance the capability of large language models (LLMs) in understanding urban space and solving related urban tasks. The authors construct a diverse instruction tuning dataset, CityInstruction, to inject urban knowledge and improve spatial reasoning capabilities. They fine-tune various LLMs using a mixture of CityInstruction and general instruction data, without sacrificing general abilities. To validate the effectiveness of their methods, the authors create a comprehensive benchmark, CityEval, to evaluate LLMs in diverse urban scenarios and problems. The results demonstrate that small LLMs trained with CityInstruction can achieve competitive performance with commercial LLMs in the comprehensive evaluation of CityEval.\nMajor Findings:"
  },
  {
    "objectID": "posts/CityGPT_Empowering_Urban_Spatial_Cognition_of_Large_Language_Models/2024-06-20-CityGPT_Empowering_Urban_Spatial_Cognition_of_Large_Language_Models.html#appendix",
    "href": "posts/CityGPT_Empowering_Urban_Spatial_Cognition_of_Large_Language_Models/2024-06-20-CityGPT_Empowering_Urban_Spatial_Cognition_of_Large_Language_Models.html#appendix",
    "title": "CityGPT: Empowering Urban Spatial Cognition of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13948v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13948v1\n\n\nTruncated\nTrue\n\n\nWord Count\n38939"
  },
  {
    "objectID": "posts/Evaluating_Implicit_Bias_in_Large_Language_Models_by_Attacking_From_a_Psychometric_Perspective/2024-06-20-Evaluating_Implicit_Bias_in_Large_Language_Models_by_Attacking_From_a_Psychometric_Perspective.html#appendix",
    "href": "posts/Evaluating_Implicit_Bias_in_Large_Language_Models_by_Attacking_From_a_Psychometric_Perspective/2024-06-20-Evaluating_Implicit_Bias_in_Large_Language_Models_by_Attacking_From_a_Psychometric_Perspective.html#appendix",
    "title": "Evaluating Implicit Bias in Large Language Models by Attacking From a Psychometric Perspective",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14023v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14023v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7014"
  },
  {
    "objectID": "posts/Smart_Language_Agents_in_Real_World_Planning/2024-07-29-Smart_Language_Agents_in_Real_World_Planning.html#appendix",
    "href": "posts/Smart_Language_Agents_in_Real_World_Planning/2024-07-29-Smart_Language_Agents_in_Real_World_Planning.html#appendix",
    "title": "Smart Language Agents in Real-World Planning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19667v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19667v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2888"
  },
  {
    "objectID": "posts/Anchored_Preference_Optimization_and_Contrastive_Revisions_Addressing_Underspecification_in_Alignment/2024-08-12-Anchored_Preference_Optimization_and_Contrastive_Revisions_Addressing_Underspecification_in_Alignment.html#major-findings",
    "href": "posts/Anchored_Preference_Optimization_and_Contrastive_Revisions_Addressing_Underspecification_in_Alignment/2024-08-12-Anchored_Preference_Optimization_and_Contrastive_Revisions_Addressing_Underspecification_in_Alignment.html#major-findings",
    "title": "Anchored Preference Optimization and Contrastive Revisions: Addressing Underspecification in Alignment",
    "section": "Major Findings",
    "text": "Major Findings\n\nThe CLAIR preferences lead to the strongest performance out of all datasets, improving Llama-3-8B-Instruct by 7.65% and closing the gap with GPT-4-turbo by 45%.\nAPO consistently outperforms less controllable objectives, with the best model trained on 32K CLAIR preferences with APO.\nThe contrastiveness of CLAIR preferences is the major driver of performance."
  },
  {
    "objectID": "posts/Anchored_Preference_Optimization_and_Contrastive_Revisions_Addressing_Underspecification_in_Alignment/2024-08-12-Anchored_Preference_Optimization_and_Contrastive_Revisions_Addressing_Underspecification_in_Alignment.html#analysis-and-critique",
    "href": "posts/Anchored_Preference_Optimization_and_Contrastive_Revisions_Addressing_Underspecification_in_Alignment/2024-08-12-Anchored_Preference_Optimization_and_Contrastive_Revisions_Addressing_Underspecification_in_Alignment.html#analysis-and-critique",
    "title": "Anchored Preference Optimization and Contrastive Revisions: Addressing Underspecification in Alignment",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\n\nThe paper does not provide a detailed comparison with other alignment methods, such as Reinforcement Learning from Human or AI Feedback (RLHF/RLAIF).\nThe paper does not discuss the potential limitations of CLAIR and APO, such as the need for a strong LLM to perform revisions or the potential for overfitting to the preference dataset.\nThe paper does not provide a clear explanation of how the APO objectives are selected for a given target model and preference dataset.\nThe paper does not discuss the potential impact of the choice of the target model on the alignment results.\nThe paper does not provide a detailed analysis of the impact of the size of the preference dataset on the alignment results.\nThe paper does not discuss the potential impact of the choice"
  },
  {
    "objectID": "posts/Anchored_Preference_Optimization_and_Contrastive_Revisions_Addressing_Underspecification_in_Alignment/2024-08-12-Anchored_Preference_Optimization_and_Contrastive_Revisions_Addressing_Underspecification_in_Alignment.html#appendix",
    "href": "posts/Anchored_Preference_Optimization_and_Contrastive_Revisions_Addressing_Underspecification_in_Alignment/2024-08-12-Anchored_Preference_Optimization_and_Contrastive_Revisions_Addressing_Underspecification_in_Alignment.html#appendix",
    "title": "Anchored Preference Optimization and Contrastive Revisions: Addressing Underspecification in Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.06266v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.06266v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7233"
  },
  {
    "objectID": "posts/Crafting_Tomorrows_Headlines_Neural_News_Generation_and_Detection_in_English_Turkish_Hungarian_and_Persian/2024-08-20-Crafting_Tomorrows_Headlines_Neural_News_Generation_and_Detection_in_English_Turkish_Hungarian_and_Persian.html",
    "href": "posts/Crafting_Tomorrows_Headlines_Neural_News_Generation_and_Detection_in_English_Turkish_Hungarian_and_Persian/2024-08-20-Crafting_Tomorrows_Headlines_Neural_News_Generation_and_Detection_in_English_Turkish_Hungarian_and_Persian.html",
    "title": "Crafting Tomorrow’s Headlines: Neural News Generation and Detection in English, Turkish, Hungarian, and Persian",
    "section": "",
    "text": "Summary:\nThe paper presents a benchmark dataset for neural news detection in four languages: English, Turkish, Hungarian, and Persian. The dataset includes outputs from multiple multilingual generators, such as BloomZ, LLaMa-2, Mistral, Mixtral, and GPT-4. The authors experiment with various classifiers, ranging from linguistic feature-based to advanced Transformer-based models and LLMs prompting. The main goal is to explore the interpretability and robustness of machine-generated text detectors across all target languages.\nThe paper also discusses the use of transformer-based baselines, BERT and RoBERTa, for fine-tuning and assessing the performance of each language separately in classifying news from humans vs. LLMs. The optimizer used for both models was adamw, with a learning rate of . The best validation losses for English, Turkish, Hungarian, and"
  },
  {
    "objectID": "posts/Crafting_Tomorrows_Headlines_Neural_News_Generation_and_Detection_in_English_Turkish_Hungarian_and_Persian/2024-08-20-Crafting_Tomorrows_Headlines_Neural_News_Generation_and_Detection_in_English_Turkish_Hungarian_and_Persian.html#appendix",
    "href": "posts/Crafting_Tomorrows_Headlines_Neural_News_Generation_and_Detection_in_English_Turkish_Hungarian_and_Persian/2024-08-20-Crafting_Tomorrows_Headlines_Neural_News_Generation_and_Detection_in_English_Turkish_Hungarian_and_Persian.html#appendix",
    "title": "Crafting Tomorrow’s Headlines: Neural News Generation and Detection in English, Turkish, Hungarian, and Persian",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10724v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10724v1\n\n\nTruncated\nTrue\n\n\nWord Count\n30389"
  },
  {
    "objectID": "posts/Semantic_Enhanced_Indirect_Call_Analysis_with_Large_Language_Models/2024-08-08-Semantic_Enhanced_Indirect_Call_Analysis_with_Large_Language_Models.html#appendix",
    "href": "posts/Semantic_Enhanced_Indirect_Call_Analysis_with_Large_Language_Models/2024-08-08-Semantic_Enhanced_Indirect_Call_Analysis_with_Large_Language_Models.html#appendix",
    "title": "Semantic-Enhanced Indirect Call Analysis with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04344v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04344v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10860"
  },
  {
    "objectID": "posts/From_Decision_to_Action_in_Surgical_Autonomy_Multi_Modal_Large_Language_Models_for_Robot_Assisted_Blood_Suction/2024-08-14-From_Decision_to_Action_in_Surgical_Autonomy_Multi_Modal_Large_Language_Models_for_Robot_Assisted_Blood_Suction.html#appendix",
    "href": "posts/From_Decision_to_Action_in_Surgical_Autonomy_Multi_Modal_Large_Language_Models_for_Robot_Assisted_Blood_Suction/2024-08-14-From_Decision_to_Action_in_Surgical_Autonomy_Multi_Modal_Large_Language_Models_for_Robot_Assisted_Blood_Suction.html#appendix",
    "title": "From Decision to Action in Surgical Autonomy: Multi-Modal Large Language Models for Robot-Assisted Blood Suction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07806v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07806v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5814"
  },
  {
    "objectID": "posts/Unveiling_Assumptions_Exploring_the_Decisions_of_AI_Chatbots_and_Human_Testers/2024-06-17-Unveiling_Assumptions_Exploring_the_Decisions_of_AI_Chatbots_and_Human_Testers.html#appendix",
    "href": "posts/Unveiling_Assumptions_Exploring_the_Decisions_of_AI_Chatbots_and_Human_Testers/2024-06-17-Unveiling_Assumptions_Exploring_the_Decisions_of_AI_Chatbots_and_Human_Testers.html#appendix",
    "title": "Unveiling Assumptions: Exploring the Decisions of AI Chatbots and Human Testers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11339v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11339v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5891"
  },
  {
    "objectID": "posts/CodeACT_Code_Adaptive_Compute_efficient_Tuning_Framework_for_Code_LLMs/2024-08-05-CodeACT_Code_Adaptive_Compute_efficient_Tuning_Framework_for_Code_LLMs.html#appendix",
    "href": "posts/CodeACT_Code_Adaptive_Compute_efficient_Tuning_Framework_for_Code_LLMs/2024-08-05-CodeACT_Code_Adaptive_Compute_efficient_Tuning_Framework_for_Code_LLMs.html#appendix",
    "title": "CodeACT: Code Adaptive Compute-efficient Tuning Framework for Code LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02193v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02193v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8346"
  },
  {
    "objectID": "posts/The_Dark_Side_of_Function_Calling_Pathways_to_Jailbreaking_Large_Language_Models/2024-07-25-The_Dark_Side_of_Function_Calling_Pathways_to_Jailbreaking_Large_Language_Models.html#appendix",
    "href": "posts/The_Dark_Side_of_Function_Calling_Pathways_to_Jailbreaking_Large_Language_Models/2024-07-25-The_Dark_Side_of_Function_Calling_Pathways_to_Jailbreaking_Large_Language_Models.html#appendix",
    "title": "The Dark Side of Function Calling: Pathways to Jailbreaking Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17915v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17915v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5067"
  },
  {
    "objectID": "posts/Does_Object_Grounding_Really_Reduce_Hallucination_of_Large_Vision_Language_Models/2024-06-20-Does_Object_Grounding_Really_Reduce_Hallucination_of_Large_Vision_Language_Models.html#appendix",
    "href": "posts/Does_Object_Grounding_Really_Reduce_Hallucination_of_Large_Vision_Language_Models/2024-06-20-Does_Object_Grounding_Really_Reduce_Hallucination_of_Large_Vision_Language_Models.html#appendix",
    "title": "Does Object Grounding Really Reduce Hallucination of Large Vision-Language Models?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14492v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14492v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7908"
  },
  {
    "objectID": "posts/On_Effects_of_Steering_Latent_Representation_for_Large_Language_Model_Unlearning/2024-08-12-On_Effects_of_Steering_Latent_Representation_for_Large_Language_Model_Unlearning.html",
    "href": "posts/On_Effects_of_Steering_Latent_Representation_for_Large_Language_Model_Unlearning/2024-08-12-On_Effects_of_Steering_Latent_Representation_for_Large_Language_Model_Unlearning.html",
    "title": "On Effects of Steering Latent Representation for Large Language Model Unlearning",
    "section": "",
    "text": "Summary:\nThis paper explores the effectiveness of Representation Misdirection for Unlearning (RMU) in large language models (LLMs). RMU steers the model’s representation in the intermediate layer to a target random representation, which reduces token confidence and causes LLMs to generate incorrect or nonsensical responses. The authors investigate the influence of the coefficient on the alignment of forget-sample representations with the random direction and suggest optimal coefficient values for effective unlearning across different network layers. They also demonstrate that RMU unlearned models are robust against adversarial jailbreak attacks. However, RMU is less effective when applied to the middle and later layers in LLMs. To address this limitation, the authors propose Adaptive RMU, a simple yet effective alternative method that makes unlearning effective with most layers.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive analysis of RMU and its effectiveness in LLM unlearning. The authors’ theoretical and empirical findings contribute to a better understanding of the underlying causes and explanations for RMU’s performance. However, the paper does not discuss potential limitations or unanswered questions, such as the generalizability of the findings to other types of LLMs or the impact of different types of forget-tasks on the unlearning process. Additionally, the paper does not address potential biases or conflicting evidence that may arise in the unlearning process. Further research is needed to address these issues and provide a more complete picture of RMU’s effectiveness in LLM unlearning."
  },
  {
    "objectID": "posts/On_Effects_of_Steering_Latent_Representation_for_Large_Language_Model_Unlearning/2024-08-12-On_Effects_of_Steering_Latent_Representation_for_Large_Language_Model_Unlearning.html#appendix",
    "href": "posts/On_Effects_of_Steering_Latent_Representation_for_Large_Language_Model_Unlearning/2024-08-12-On_Effects_of_Steering_Latent_Representation_for_Large_Language_Model_Unlearning.html#appendix",
    "title": "On Effects of Steering Latent Representation for Large Language Model Unlearning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.06223v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.06223v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7618"
  },
  {
    "objectID": "posts/Trace_is_the_New_AutoDiff____Unlocking_Efficient_Optimization_of_Computational_Workflows/2024-06-23-Trace_is_the_New_AutoDiff____Unlocking_Efficient_Optimization_of_Computational_Workflows.html",
    "href": "posts/Trace_is_the_New_AutoDiff____Unlocking_Efficient_Optimization_of_Computational_Workflows/2024-06-23-Trace_is_the_New_AutoDiff____Unlocking_Efficient_Optimization_of_Computational_Workflows.html",
    "title": "Trace is the New AutoDiff – Unlocking Efficient Optimization of Computational Workflows",
    "section": "",
    "text": "Summary:\nThe paper introduces a new optimization framework called Trace, which is designed to optimize computational workflows in AI systems. The framework is inspired by back-propagation and treats the computational workflow as a graph, similar to neural networks. The optimization process involves rich feedback, heterogeneous parameters, and intricate objectives. The paper also introduces a new mathematical setup called Optimization with Trace Oracle (OPTO) to capture and abstract these properties, enabling the design of optimizers that work across multiple domains. The authors propose a general-purpose LLM-based optimizer called OptoPrime, which can effectively solve OPTO problems. Empirical studies show that OptoPrime is capable of first-order numerical optimization, prompt optimization, hyper-parameter tuning, robot controller design, code debugging, and more. The authors believe that Trace, OptoPrime, and the OPTO framework will enable the next generation of interactive agents that automatically adapt using various kinds of feedback.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an interesting and novel approach to optimizing computational workflows in AI systems. The Trace framework and the OPTO mathematical setup provide a new perspective on how to optimize complex workflows, and the proposed OptoPrime optimizer demonstrates promising results in various optimization tasks. However, the paper does not provide a detailed comparison with existing optimization techniques, which could help to better understand the advantages and limitations of the proposed approach. Additionally, the paper does not discuss the scalability and"
  },
  {
    "objectID": "posts/Trace_is_the_New_AutoDiff____Unlocking_Efficient_Optimization_of_Computational_Workflows/2024-06-23-Trace_is_the_New_AutoDiff____Unlocking_Efficient_Optimization_of_Computational_Workflows.html#appendix",
    "href": "posts/Trace_is_the_New_AutoDiff____Unlocking_Efficient_Optimization_of_Computational_Workflows/2024-06-23-Trace_is_the_New_AutoDiff____Unlocking_Efficient_Optimization_of_Computational_Workflows.html#appendix",
    "title": "Trace is the New AutoDiff – Unlocking Efficient Optimization of Computational Workflows",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16218v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16218v1\n\n\nTruncated\nFalse\n\n\nWord Count\n16085"
  },
  {
    "objectID": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#major-findings",
    "href": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#major-findings",
    "title": "McEval: Massively Multilingual Code Evaluation",
    "section": "Major Findings",
    "text": "Major Findings\n\nMcEval is the first massively multilingual code evaluation benchmark, covering 40 programming languages with 16K test samples.\nThe benchmark includes challenging code completion, understanding, and generation evaluation tasks with finely curated multilingual instruction corpora McEval-Instruct.\nThe authors introduce an effective multilingual coder mCoder trained on McEval-Instruct to support multilingual programming language generation."
  },
  {
    "objectID": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#analysis-and-critique",
    "href": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#analysis-and-critique",
    "title": "McEval: Massively Multilingual Code Evaluation",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\n\nThe paper does not provide a detailed comparison of McEval with existing benchmarks, making it difficult to assess its advantages and limitations.\nThe paper does not discuss the potential biases in the data used for training mCoder, which could impact its performance on certain tasks or languages.\nThe paper does not provide a detailed analysis of the performance of mCoder on different tasks and languages, making it difficult to assess its strengths and weaknesses.\nThe paper does not discuss the potential applications of McEval and mCoder in real-world software development scenarios.\nThe paper does not discuss the potential ethical implications of using mCoder for code generation, such as the risk of generating code that violates software licenses or copyright laws."
  },
  {
    "objectID": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#appendix",
    "href": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#appendix",
    "title": "McEval: Massively Multilingual Code Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07436v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07436v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7788"
  },
  {
    "objectID": "posts/AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models/2024-06-24-AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models.html#summary",
    "href": "posts/AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models/2024-06-24-AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models.html#summary",
    "title": "AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models",
    "section": "Summary:",
    "text": "Summary:\n\nThe paper introduces a unified framework, AutoDetect, to automatically expose weaknesses in LLMs across various tasks.\nThe framework is inspired by the educational assessment process and consists of three LLM-powered agents: Examiner, Questioner, and Assessor.\nAutoDetect demonstrates significant success in uncovering flaws, with an identification success rate exceeding 30% in prominent models such as ChatGPT and Claude.\nThe identified weaknesses can guide specific model improvements, proving more effective than untargeted data augmentation methods like Self-Instruct.\nThe approach has led to substantial enhancements in popular LLMs, including the Llama series and Mistral-7b, boosting their performance by over 10% across several benchmarks."
  },
  {
    "objectID": "posts/AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models/2024-06-24-AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models.html#major-findings",
    "href": "posts/AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models/2024-06-24-AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models.html#major-findings",
    "title": "AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nAutoDetect is a pioneering unified framework that aims to systematically and automatically expose potential weaknesses within LLMs across a variety of tasks.\nThe framework demonstrates exceptional adaptability and effectiveness, with a success rate of over 50% in uncovering deficiencies across multiple models and tasks.\nAutoDetect facilitates significant model improvements. Leveraging the data derived from the weakness detection process, we can effectively enhance model performance, yielding over 10% improvements on several tasks."
  },
  {
    "objectID": "posts/AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models/2024-06-24-AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models/2024-06-24-AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models.html#analysis-and-critique",
    "title": "AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper provides a comprehensive and well-structured approach to identifying weaknesses in LLMs.\nThe use of three specialized roles implemented by LLM-based agents allows for a thorough and tailored testing framework.\nThe iterative search process enables the adjustment of question difficulty for the target model, effectively identifying weaknesses.\nHowever, the paper does not discuss the potential limitations or biases of the framework, which could be a topic for future research.\nAdditionally, the paper does not provide a detailed comparison with other existing methods for weakness detection in LLMs.\nThe paper also does not discuss the potential scalability issues or computational costs associated with the framework.\nFinally, the paper does not provide a detailed analysis of the impact of the identified weaknesses on the overall performance of"
  },
  {
    "objectID": "posts/AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models/2024-06-24-AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models.html#appendix",
    "href": "posts/AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models/2024-06-24-AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models.html#appendix",
    "title": "AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16714v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16714v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5957"
  },
  {
    "objectID": "posts/LoRA_Guard_Parameter_Efficient_Guardrail_Adaptation_for_Content_Moderation_of_Large_Language_Models/2024-07-03-LoRA_Guard_Parameter_Efficient_Guardrail_Adaptation_for_Content_Moderation_of_Large_Language_Models.html#appendix",
    "href": "posts/LoRA_Guard_Parameter_Efficient_Guardrail_Adaptation_for_Content_Moderation_of_Large_Language_Models/2024-07-03-LoRA_Guard_Parameter_Efficient_Guardrail_Adaptation_for_Content_Moderation_of_Large_Language_Models.html#appendix",
    "title": "LoRA-Guard: Parameter-Efficient Guardrail Adaptation for Content Moderation of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02987v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02987v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10286"
  },
  {
    "objectID": "posts/Neural_embedding_of_beliefs_reveals_the_role_of_relative_dissonance_in_human_decision_making/2024-08-13-Neural_embedding_of_beliefs_reveals_the_role_of_relative_dissonance_in_human_decision_making.html#appendix",
    "href": "posts/Neural_embedding_of_beliefs_reveals_the_role_of_relative_dissonance_in_human_decision_making/2024-08-13-Neural_embedding_of_beliefs_reveals_the_role_of_relative_dissonance_in_human_decision_making.html#appendix",
    "title": "Neural embedding of beliefs reveals the role of relative dissonance in human decision-making",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.07237v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.07237v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10768"
  },
  {
    "objectID": "posts/LGR2_Language_Guided_Reward_Relabeling_for_Accelerating_Hierarchical_Reinforcement_Learning/2024-06-09-LGR2_Language_Guided_Reward_Relabeling_for_Accelerating_Hierarchical_Reinforcement_Learning.html#appendix",
    "href": "posts/LGR2_Language_Guided_Reward_Relabeling_for_Accelerating_Hierarchical_Reinforcement_Learning/2024-06-09-LGR2_Language_Guided_Reward_Relabeling_for_Accelerating_Hierarchical_Reinforcement_Learning.html#appendix",
    "title": "LGR2: Language Guided Reward Relabeling for Accelerating Hierarchical Reinforcement Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05881v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05881v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10516"
  },
  {
    "objectID": "posts/Multi_Granularity_Semantic_Revision_for_Large_Language_Model_Distillation/2024-07-14-Multi_Granularity_Semantic_Revision_for_Large_Language_Model_Distillation.html#appendix",
    "href": "posts/Multi_Granularity_Semantic_Revision_for_Large_Language_Model_Distillation/2024-07-14-Multi_Granularity_Semantic_Revision_for_Large_Language_Model_Distillation.html#appendix",
    "title": "Multi-Granularity Semantic Revision for Large Language Model Distillation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10068v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10068v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7336"
  },
  {
    "objectID": "posts/Exploring_the_Role_of_Transliteration_in_In_Context_Learning_for_Low_resource_Languages_Written_in_Non_Latin_Scripts/2024-07-02-Exploring_the_Role_of_Transliteration_in_In_Context_Learning_for_Low_resource_Languages_Written_in_Non_Latin_Scripts.html#appendix",
    "href": "posts/Exploring_the_Role_of_Transliteration_in_In_Context_Learning_for_Low_resource_Languages_Written_in_Non_Latin_Scripts/2024-07-02-Exploring_the_Role_of_Transliteration_in_In_Context_Learning_for_Low_resource_Languages_Written_in_Non_Latin_Scripts.html#appendix",
    "title": "Exploring the Role of Transliteration in In-Context Learning for Low-resource Languages Written in Non-Latin Scripts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02320v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02320v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3417"
  },
  {
    "objectID": "posts/TwIPS_A_Large_Language_Model_Powered_Texting_Application_to_Simplify_Conversational_Nuances_for_Autistic_Users/2024-07-25-TwIPS_A_Large_Language_Model_Powered_Texting_Application_to_Simplify_Conversational_Nuances_for_Autistic_Users.html",
    "href": "posts/TwIPS_A_Large_Language_Model_Powered_Texting_Application_to_Simplify_Conversational_Nuances_for_Autistic_Users/2024-07-25-TwIPS_A_Large_Language_Model_Powered_Texting_Application_to_Simplify_Conversational_Nuances_for_Autistic_Users.html",
    "title": "TwIPS: A Large Language Model Powered Texting Application to Simplify Conversational Nuances for Autistic Users",
    "section": "",
    "text": "Summary:\nTwIPS is a prototype texting application powered by a large language model (LLM) designed to assist autistic users in deciphering tone and meaning, ensuring emotional tone alignment, and providing alternative phrasing for messages that could be misconstrued. The application includes three features: Interpret, Preview, and Suggest. Interpret describes the overall tone and meaning of incoming messages and identifies ambiguous language elements. Preview allows users to preview the recipient’s likely emotional reaction to their message, and Suggest complements Preview by offering a differently phrased alternative message.\nAn in-lab user study with 8 autistic participants revealed that TwIPS enabled a convenient way for participants to seek clarifications, provided a better alternative to tone indicators, and facilitated constructive reflection on writing technique and style. Participants’ feedback for improving the prototype centered around enhancing personalization and implementing measures to prevent over-relying on the application.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/TwIPS_A_Large_Language_Model_Powered_Texting_Application_to_Simplify_Conversational_Nuances_for_Autistic_Users/2024-07-25-TwIPS_A_Large_Language_Model_Powered_Texting_Application_to_Simplify_Conversational_Nuances_for_Autistic_Users.html#appendix",
    "href": "posts/TwIPS_A_Large_Language_Model_Powered_Texting_Application_to_Simplify_Conversational_Nuances_for_Autistic_Users/2024-07-25-TwIPS_A_Large_Language_Model_Powered_Texting_Application_to_Simplify_Conversational_Nuances_for_Autistic_Users.html#appendix",
    "title": "TwIPS: A Large Language Model Powered Texting Application to Simplify Conversational Nuances for Autistic Users",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17760v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17760v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17125"
  },
  {
    "objectID": "posts/Real_Time_Anomaly_Detection_and_Reactive_Planning_with_Large_Language_Models/2024-07-11-Real_Time_Anomaly_Detection_and_Reactive_Planning_with_Large_Language_Models.html",
    "href": "posts/Real_Time_Anomaly_Detection_and_Reactive_Planning_with_Large_Language_Models/2024-07-11-Real_Time_Anomaly_Detection_and_Reactive_Planning_with_Large_Language_Models.html",
    "title": "Real-Time Anomaly Detection and Reactive Planning with Large Language Models",
    "section": "",
    "text": "Summary:\nThis paper presents a two-stage reasoning framework for detecting and mitigating out-of-distribution failure modes in robotic systems using large language models (LLMs). The first stage is a fast binary anomaly classifier that analyzes observations in the LLM embedding space, which may trigger a slower fallback selection stage that utilizes the reasoning capabilities of generative LLMs. These stages correspond to branch points in a model predictive control strategy that maintains the joint feasibility of continuing along various fallback plans to account for the slow reasoner’s latency as soon as an anomaly is detected, ensuring safety. The fast anomaly classifier outperforms autoregressive reasoning with state-of-the-art GPT models, even when instantiated with relatively small language models. This enables the runtime monitor to improve the trustworthiness of dynamic robotic systems, such as quadrotors or autonomous vehicles, under resource and time constraints.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an innovative approach to detecting and mitigating out-of-distribution failure modes in robotic systems using large language models. The two-stage reasoning framework and the model predictive control strategy provide a promising solution to ensure safety in dynamic robotic systems. However, the paper does not provide a detailed analysis of the limitations and potential biases of the proposed approach. Additionally, the paper does not discuss the methodological issues, conflicting evidence, or areas that require further research or clarification. Further research is needed to evaluate the proposed approach in real-world scenarios and to address the potential limitations and biases of the approach."
  },
  {
    "objectID": "posts/Real_Time_Anomaly_Detection_and_Reactive_Planning_with_Large_Language_Models/2024-07-11-Real_Time_Anomaly_Detection_and_Reactive_Planning_with_Large_Language_Models.html#appendix",
    "href": "posts/Real_Time_Anomaly_Detection_and_Reactive_Planning_with_Large_Language_Models/2024-07-11-Real_Time_Anomaly_Detection_and_Reactive_Planning_with_Large_Language_Models.html#appendix",
    "title": "Real-Time Anomaly Detection and Reactive Planning with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08735v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08735v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18740"
  },
  {
    "objectID": "posts/Beyond_Demographics_Aligning_Role_playing_LLM_based_Agents_Using_Human_Belief_Networks/2024-06-25-Beyond_Demographics_Aligning_Role_playing_LLM_based_Agents_Using_Human_Belief_Networks.html#appendix",
    "href": "posts/Beyond_Demographics_Aligning_Role_playing_LLM_based_Agents_Using_Human_Belief_Networks/2024-06-25-Beyond_Demographics_Aligning_Role_playing_LLM_based_Agents_Using_Human_Belief_Networks.html#appendix",
    "title": "Beyond Demographics: Aligning Role-playing LLM-based Agents Using Human Belief Networks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17232v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17232v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7041"
  },
  {
    "objectID": "posts/Sparser_is_Faster_and_Less_is_More_Efficient_Sparse_Attention_for_Long_Range_Transformers/2024-06-24-Sparser_is_Faster_and_Less_is_More_Efficient_Sparse_Attention_for_Long_Range_Transformers.html",
    "href": "posts/Sparser_is_Faster_and_Less_is_More_Efficient_Sparse_Attention_for_Long_Range_Transformers/2024-06-24-Sparser_is_Faster_and_Less_is_More_Efficient_Sparse_Attention_for_Long_Range_Transformers.html",
    "title": "Sparser is Faster and Less is More: Efficient Sparse Attention for Long-Range Transformers",
    "section": "",
    "text": "Summary:\nThe paper introduces SparseK Attention, a novel sparse attention mechanism designed to overcome computational and memory obstacles in long-range Transformer computing. This approach integrates a scoring network and a differentiable top-k mask operator, SparseK, to select a constant number of KV pairs for each query, enabling gradient-based optimization. SparseK Attention offers linear time complexity and constant memory footprint during generation. Experimental results reveal that SparseK Attention outperforms previous sparse attention methods and provides significant speed improvements during both training and inference, particularly in language modeling and downstream tasks. The method can be seamlessly integrated into pre-trained Large Language Models (LLMs) with minimal fine-tuning, offering a practical solution for effectively managing long-range dependencies in diverse applications.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a promising approach to addressing the computational and memory challenges in long-range Transformer computing. The proposed SparseK Attention mechanism offers a practical solution for managing long-range dependencies in diverse applications. However, the paper does not discuss potential limitations or biases that may arise from the use of this method. Additionally, the method’s performance on different types of data and tasks, as well as its generalizability, are not thoroughly evaluated. Further research is needed to explore these aspects and ensure the robustness and applicability of the SparseK Attention mechanism."
  },
  {
    "objectID": "posts/Sparser_is_Faster_and_Less_is_More_Efficient_Sparse_Attention_for_Long_Range_Transformers/2024-06-24-Sparser_is_Faster_and_Less_is_More_Efficient_Sparse_Attention_for_Long_Range_Transformers.html#appendix",
    "href": "posts/Sparser_is_Faster_and_Less_is_More_Efficient_Sparse_Attention_for_Long_Range_Transformers/2024-06-24-Sparser_is_Faster_and_Less_is_More_Efficient_Sparse_Attention_for_Long_Range_Transformers.html#appendix",
    "title": "Sparser is Faster and Less is More: Efficient Sparse Attention for Long-Range Transformers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16747v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16747v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9535"
  },
  {
    "objectID": "posts/ANOLE_An_Open_Autoregressive_Native_Large_Multimodal_Models_for_Interleaved_Image_Text_Generation/2024-07-08-ANOLE_An_Open_Autoregressive_Native_Large_Multimodal_Models_for_Interleaved_Image_Text_Generation.html#appendix",
    "href": "posts/ANOLE_An_Open_Autoregressive_Native_Large_Multimodal_Models_for_Interleaved_Image_Text_Generation/2024-07-08-ANOLE_An_Open_Autoregressive_Native_Large_Multimodal_Models_for_Interleaved_Image_Text_Generation.html#appendix",
    "title": "ANOLE: An Open, Autoregressive, Native Large Multimodal Models for Interleaved Image-Text Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06135v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06135v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3311"
  },
  {
    "objectID": "posts/Semantic_Understanding_and_Data_Imputation_using_Large_Language_Model_to_Accelerate_Recommendation_System/2024-07-14-Semantic_Understanding_and_Data_Imputation_using_Large_Language_Model_to_Accelerate_Recommendation_System.html#appendix",
    "href": "posts/Semantic_Understanding_and_Data_Imputation_using_Large_Language_Model_to_Accelerate_Recommendation_System/2024-07-14-Semantic_Understanding_and_Data_Imputation_using_Large_Language_Model_to_Accelerate_Recommendation_System.html#appendix",
    "title": "Semantic Understanding and Data Imputation using Large Language Model to Accelerate Recommendation System",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10078v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10078v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2986"
  },
  {
    "objectID": "posts/Practical_Unlearning_for_Large_Language_Models/2024-07-14-Practical_Unlearning_for_Large_Language_Models.html#summary-1",
    "href": "posts/Practical_Unlearning_for_Large_Language_Models/2024-07-14-Practical_Unlearning_for_Large_Language_Models.html#summary-1",
    "title": "Practical Unlearning for Large Language Models",
    "section": "Summary:",
    "text": "Summary:\nThe paper proposes a novel framework called O3 for practical unlearning in large language models (LLMs). The O3 framework addresses the challenges of balancing unlearning effectiveness and model utility preservation in continuous scenarios without using any retained data. It includes an Out-Of-Distribution (OOD) detection module to assess the similarity between input data and unlearning data, and an Orthogonal Low-rank adapter (LoRA) for continuously unlearning requested data. The OOD detector is trained with a novel contrastive entropy loss and a local-global layer-aggregated scoring mechanism. The orthogonal LoRA achieves parameter disentanglement among continual unlearning requests. During inference, the O3 framework can smartly decide whether and to what extent to load the unlearning LoRA based on the OOD detector’s predictions. The O3 framework is computationally efficient and does not rely on any retained data."
  },
  {
    "objectID": "posts/Practical_Unlearning_for_Large_Language_Models/2024-07-14-Practical_Unlearning_for_Large_Language_Models.html#major-findings",
    "href": "posts/Practical_Unlearning_for_Large_Language_Models/2024-07-14-Practical_Unlearning_for_Large_Language_Models.html#major-findings",
    "title": "Practical Unlearning for Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe O3 framework consistently achieves the best trade-off between unlearning effectiveness and utility preservation, especially when facing continuous unlearning requests.\nThe O3 framework does not require any retained data, making it more computationally efficient than existing LLM unlearning methods.\nThe OOD detector in the O3 framework is trained with a novel contrastive entropy loss and a local-global layer-aggregated scoring mechanism, which allows it to achieve truly unsupervised OOD detection.\nThe orthogonal LoRA in the O3 framework enables parameter disentanglement among continual unlearning requests, ensuring that the unlearning effectiveness of different requests does not interfere with each other."
  },
  {
    "objectID": "posts/Practical_Unlearning_for_Large_Language_Models/2024-07-14-Practical_Unlearning_for_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/Practical_Unlearning_for_Large_Language_Models/2024-07-14-Practical_Unlearning_for_Large_Language_Models.html#analysis-and-critique",
    "title": "Practical Unlearning for Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe O3 framework is a promising approach for practical unlearning in LLMs. It addresses the challenges of balancing unlearning effectiveness and model utility preservation in continuous scenarios without using any retained data. The OOD detector and orthogonal LoRA are novel components that enable the O3 framework to achieve superior performance compared to existing LLM unlearning methods. However, the O3 framework has not been tested on a wide range of tasks and datasets, and its performance may vary depending on the specific task and dataset. Additionally, the O3 framework assumes that the unlearning data is available during the unlearning operation, which may not"
  },
  {
    "objectID": "posts/Practical_Unlearning_for_Large_Language_Models/2024-07-14-Practical_Unlearning_for_Large_Language_Models.html#appendix",
    "href": "posts/Practical_Unlearning_for_Large_Language_Models/2024-07-14-Practical_Unlearning_for_Large_Language_Models.html#appendix",
    "title": "Practical Unlearning for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10223v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10223v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13558"
  },
  {
    "objectID": "posts/CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models/2024-07-02-CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models.html",
    "href": "posts/CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models/2024-07-02-CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models.html",
    "title": "CEB: Compositional Evaluation Benchmark for Fairness in Large Language Models",
    "section": "",
    "text": "Summary: The paper introduces a Compositional Evaluation Benchmark (CEB) to address the limitations of existing bias evaluation efforts for Large Language Models (LLMs). CEB consists of 11,004 samples covering different types of bias across various social groups and tasks. The curation of CEB is based on a newly proposed compositional taxonomy that characterizes each dataset from three dimensions: bias types, social groups, and tasks. The paper demonstrates that the levels of bias vary across these dimensions, providing guidance for the development of specific bias mitigation methods.\nMajor Findings: 1. The introduction of CEB, a Compositional Evaluation Benchmark, to address the limitations of existing bias evaluation efforts for LLMs. 2. The curation of CEB is based on a newly proposed compositional taxonomy that characterizes each dataset from three dimensions: bias types, social groups, and tasks."
  },
  {
    "objectID": "posts/CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models/2024-07-02-CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models.html#appendix",
    "href": "posts/CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models/2024-07-02-CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models.html#appendix",
    "title": "CEB: Compositional Evaluation Benchmark for Fairness in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02408v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02408v1\n\n\nTruncated\nTrue\n\n\nWord Count\n32723"
  },
  {
    "objectID": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#summary-1",
    "href": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#summary-1",
    "title": "FragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models",
    "section": "Summary:",
    "text": "Summary:\n\nThe paper proposes a method to improve the processing of long contexts in Large Language Models (LLMs) by exploiting fragment-level relations in external memory.\nThe authors formulate fragment-level relations and present several instantiations for different text types.\nThey introduce a relation-aware fragment assessment criteria and present the fragment-connected Hierarchical Memory based LLM.\nThe proposed method is validated on long story understanding, repository-level code generation, and long-term chatting tasks."
  },
  {
    "objectID": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#major-findings",
    "href": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#major-findings",
    "title": "FragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nFragment-level Relations: The authors propose a method to exploit fragment-level relations in external memory to improve the processing of long contexts in LLMs.\nRelation-aware Fragment Assessment: The authors introduce a relation-aware fragment assessment criteria to better assess the importance of each fragment in the context.\nFragment-connected Hierarchical Memory based LLM: The authors present a new LLM architecture that incorporates fragment-level relations in external memory to improve the processing of long contexts."
  },
  {
    "objectID": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#analysis-and-critique",
    "title": "FragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe proposed method effectively addresses the issue of isolated fragment processing in existing External Memory augmented LLMs.\nThe paper provides a comprehensive evaluation of the proposed method on various long text processing tasks, demonstrating its effectiveness.\nHowever, the paper does not discuss the potential limitations or challenges of the proposed method, such as the computational overhead or the impact on the model’s performance.\nAdditionally, the paper does not provide a comparison with other existing methods for processing long contexts in LLMs.\nThe paper could benefit from a more detailed discussion of the potential applications and implications of the proposed method in real-world scenarios.\nOverall, the paper presents a promising approach to improve the processing of long contexts in LLMs, but further research is needed to fully evaluate its potential and limitations."
  },
  {
    "objectID": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#appendix",
    "href": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#appendix",
    "title": "FragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03092v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03092v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7567"
  },
  {
    "objectID": "posts/Preference_Learning_Algorithms_Do_Not_Learn_Preference_Rankings/2024-05-29-Preference_Learning_Algorithms_Do_Not_Learn_Preference_Rankings.html#appendix",
    "href": "posts/Preference_Learning_Algorithms_Do_Not_Learn_Preference_Rankings/2024-05-29-Preference_Learning_Algorithms_Do_Not_Learn_Preference_Rankings.html#appendix",
    "title": "Preference Learning Algorithms Do Not Learn Preference Rankings",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.19534v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.19534v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10665"
  },
  {
    "objectID": "posts/iMotion_LLM_Motion_Prediction_Instruction_Tuning/2024-06-10-iMotion_LLM_Motion_Prediction_Instruction_Tuning.html#appendix",
    "href": "posts/iMotion_LLM_Motion_Prediction_Instruction_Tuning/2024-06-10-iMotion_LLM_Motion_Prediction_Instruction_Tuning.html#appendix",
    "title": "iMotion-LLM: Motion Prediction Instruction Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06211v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06211v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5777"
  },
  {
    "objectID": "posts/Evaluating_Large_Language_Models_for_Automatic_Register_Transfer_Logic_Generation_via_High_Level_Synthesis/2024-08-05-Evaluating_Large_Language_Models_for_Automatic_Register_Transfer_Logic_Generation_via_High_Level_Synthesis.html#major-findings",
    "href": "posts/Evaluating_Large_Language_Models_for_Automatic_Register_Transfer_Logic_Generation_via_High_Level_Synthesis/2024-08-05-Evaluating_Large_Language_Models_for_Automatic_Register_Transfer_Logic_Generation_via_High_Level_Synthesis.html#major-findings",
    "title": "Evaluating Large Language Models for Automatic Register Transfer Logic Generation via High-Level Synthesis",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe proposed software pipeline for automated Verilog generation via HLS outperforms previous techniques of direct Verilog RTL generation by LLMs in terms of average functional correctness rates, reaching a score of 0.86 in the metric.\nThe reliability of hardware design is a key factor, and the generated final Verilog code is evaluated through a robust validation procedure.\nThe proposed software pipeline enables the evaluation of the generated final Verilog code through a robust validation procedure, ensuring the reliability of the hardware design."
  },
  {
    "objectID": "posts/Evaluating_Large_Language_Models_for_Automatic_Register_Transfer_Logic_Generation_via_High_Level_Synthesis/2024-08-05-Evaluating_Large_Language_Models_for_Automatic_Register_Transfer_Logic_Generation_via_High_Level_Synthesis.html#analysis-and-critique",
    "href": "posts/Evaluating_Large_Language_Models_for_Automatic_Register_Transfer_Logic_Generation_via_High_Level_Synthesis/2024-08-05-Evaluating_Large_Language_Models_for_Automatic_Register_Transfer_Logic_Generation_via_High_Level_Synthesis.html#analysis-and-critique",
    "title": "Evaluating Large Language Models for Automatic Register Transfer Logic Generation via High-Level Synthesis",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper does not provide a detailed comparison of the proposed approach with other existing techniques for automated RTL generation and validation using LLMs.\nThe paper does not discuss the limitations and challenges of the proposed approach, such as the need for a large amount of open-source codebases in HDLs like Verilog and VHDL for training the LLMs.\nThe paper does not provide a detailed analysis of the results, such as the impact of the size and complexity of the problems on the performance of the proposed approach.\nThe paper does not discuss the potential applications and implications of the proposed approach for the design and verification of digital hardware.\nThe paper does not provide a clear and concise summary of the main contributions and findings of the paper."
  },
  {
    "objectID": "posts/Evaluating_Large_Language_Models_for_Automatic_Register_Transfer_Logic_Generation_via_High_Level_Synthesis/2024-08-05-Evaluating_Large_Language_Models_for_Automatic_Register_Transfer_Logic_Generation_via_High_Level_Synthesis.html#appendix",
    "href": "posts/Evaluating_Large_Language_Models_for_Automatic_Register_Transfer_Logic_Generation_via_High_Level_Synthesis/2024-08-05-Evaluating_Large_Language_Models_for_Automatic_Register_Transfer_Logic_Generation_via_High_Level_Synthesis.html#appendix",
    "title": "Evaluating Large Language Models for Automatic Register Transfer Logic Generation via High-Level Synthesis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02793v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02793v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3718"
  },
  {
    "objectID": "posts/HLSPilot_LLM_based_High_Level_Synthesis/2024-08-13-HLSPilot_LLM_based_High_Level_Synthesis.html#appendix",
    "href": "posts/HLSPilot_LLM_based_High_Level_Synthesis/2024-08-13-HLSPilot_LLM_based_High_Level_Synthesis.html#appendix",
    "title": "HLSPilot: LLM-based High-Level Synthesis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.06810v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.06810v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5801"
  },
  {
    "objectID": "posts/MEDSAGE_Enhancing_Robustness_of_Medical_Dialogue_Summarization_to_ASR_Errors_with_LLM_generated_Synthetic_Dialogues/2024-08-26-MEDSAGE_Enhancing_Robustness_of_Medical_Dialogue_Summarization_to_ASR_Errors_with_LLM_generated_Synthetic_Dialogues.html#major-findings",
    "href": "posts/MEDSAGE_Enhancing_Robustness_of_Medical_Dialogue_Summarization_to_ASR_Errors_with_LLM_generated_Synthetic_Dialogues/2024-08-26-MEDSAGE_Enhancing_Robustness_of_Medical_Dialogue_Summarization_to_ASR_Errors_with_LLM_generated_Synthetic_Dialogues.html#major-findings",
    "title": "MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues",
    "section": "Major Findings",
    "text": "Major Findings\n\nLLMs can effectively model ASR noise, improving the robustness and accuracy of medical dialogue summarization systems.\nIncorporating noisy data generated by LLMs into the training process significantly enhances the performance of medical dialogue summarization systems.\nThe proposed MEDSAGE approach addresses the challenges of noisy ASR outputs in critical applications, offering a robust solution to enhance the reliability of clinical dialogue summarization."
  },
  {
    "objectID": "posts/MEDSAGE_Enhancing_Robustness_of_Medical_Dialogue_Summarization_to_ASR_Errors_with_LLM_generated_Synthetic_Dialogues/2024-08-26-MEDSAGE_Enhancing_Robustness_of_Medical_Dialogue_Summarization_to_ASR_Errors_with_LLM_generated_Synthetic_Dialogues.html#analysis-and-critique",
    "href": "posts/MEDSAGE_Enhancing_Robustness_of_Medical_Dialogue_Summarization_to_ASR_Errors_with_LLM_generated_Synthetic_Dialogues/2024-08-26-MEDSAGE_Enhancing_Robustness_of_Medical_Dialogue_Summarization_to_ASR_Errors_with_LLM_generated_Synthetic_Dialogues.html#analysis-and-critique",
    "title": "MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\nThe paper presents a novel approach to address the challenges of noisy ASR outputs in medical dialogue summarization. The use of LLMs for generating synthetic samples for data augmentation is a promising solution to improve the robustness of summarization models. However, the paper does not provide a comprehensive comparison with other data augmentation techniques or error correction methods. Additionally, the evaluation is limited to a single dataset, and the generalizability of the proposed approach to other medical domains or languages remains to be explored. Further research is needed to validate the effectiveness of MEDSAGE in real-world clinical settings and to address potential limitations and biases in the generated synthetic data."
  },
  {
    "objectID": "posts/MEDSAGE_Enhancing_Robustness_of_Medical_Dialogue_Summarization_to_ASR_Errors_with_LLM_generated_Synthetic_Dialogues/2024-08-26-MEDSAGE_Enhancing_Robustness_of_Medical_Dialogue_Summarization_to_ASR_Errors_with_LLM_generated_Synthetic_Dialogues.html#appendix",
    "href": "posts/MEDSAGE_Enhancing_Robustness_of_Medical_Dialogue_Summarization_to_ASR_Errors_with_LLM_generated_Synthetic_Dialogues/2024-08-26-MEDSAGE_Enhancing_Robustness_of_Medical_Dialogue_Summarization_to_ASR_Errors_with_LLM_generated_Synthetic_Dialogues.html#appendix",
    "title": "MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.14418v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.14418v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6803"
  },
  {
    "objectID": "posts/TBA_Faster_Large_Language_Model_Training_Using_SSD_Based_Activation_Offloading/2024-08-19-TBA_Faster_Large_Language_Model_Training_Using_SSD_Based_Activation_Offloading.html",
    "href": "posts/TBA_Faster_Large_Language_Model_Training_Using_SSD_Based_Activation_Offloading/2024-08-19-TBA_Faster_Large_Language_Model_Training_Using_SSD_Based_Activation_Offloading.html",
    "title": "TBA: Faster Large Language Model Training Using SSD-Based Activation Offloading",
    "section": "",
    "text": "The paper “TBA: Faster Large Language Model Training Using SSD-Based Activation Offloading” proposes a software framework called TBA to offload activations in LLM training to NVMe SSDs. The authors demonstrate the viability of TBA on large-scale systems by modeling the performance, estimated SSD lifespan, and the required per-GPU PCIe bandwidth. The paper also discusses the design and implementation of TBA, including the use of PyTorch hooks to alter its execution behavior and the optimization techniques used to achieve full overlap of activation transfers with computation. The evaluation shows that TBA achieves almost the same training time per step as the original system without TBA while reducing the activations peak memory use by up to 47%. The paper also introduces the recompute-offload-keep (ROK) curve to compare the TBA offloading with two other tensor placement strategies, keeping activations in memory and layerwise full recomputation. TBA has the same performance as keeping activations in memory and lower memory peak compared with activation checkpointing. The paper concludes by discussing the limitations and potential biases of the article."
  },
  {
    "objectID": "posts/TBA_Faster_Large_Language_Model_Training_Using_SSD_Based_Activation_Offloading/2024-08-19-TBA_Faster_Large_Language_Model_Training_Using_SSD_Based_Activation_Offloading.html#appendix",
    "href": "posts/TBA_Faster_Large_Language_Model_Training_Using_SSD_Based_Activation_Offloading/2024-08-19-TBA_Faster_Large_Language_Model_Training_Using_SSD_Based_Activation_Offloading.html#appendix",
    "title": "TBA: Faster Large Language Model Training Using SSD-Based Activation Offloading",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10013v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10013v1\n\n\nTruncated\nFalse\n\n\nWord Count\n23878"
  },
  {
    "objectID": "posts/Towards_Human_AI_Collaboration_in_Healthcare_Guided_Deferral_Systems_with_Large_Language_Models/2024-06-11-Towards_Human_AI_Collaboration_in_Healthcare_Guided_Deferral_Systems_with_Large_Language_Models.html#appendix",
    "href": "posts/Towards_Human_AI_Collaboration_in_Healthcare_Guided_Deferral_Systems_with_Large_Language_Models/2024-06-11-Towards_Human_AI_Collaboration_in_Healthcare_Guided_Deferral_Systems_with_Large_Language_Models.html#appendix",
    "title": "Towards Human-AI Collaboration in Healthcare: Guided Deferral Systems with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07212v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07212v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4804"
  },
  {
    "objectID": "posts/CollectiveSFT_Scaling_Large_Language_Models_for_Chinese_Medical_Benchmark_with_Collective_Instructions_in_Healthcare/2024-07-29-CollectiveSFT_Scaling_Large_Language_Models_for_Chinese_Medical_Benchmark_with_Collective_Instructions_in_Healthcare.html#appendix",
    "href": "posts/CollectiveSFT_Scaling_Large_Language_Models_for_Chinese_Medical_Benchmark_with_Collective_Instructions_in_Healthcare/2024-07-29-CollectiveSFT_Scaling_Large_Language_Models_for_Chinese_Medical_Benchmark_with_Collective_Instructions_in_Healthcare.html#appendix",
    "title": "CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19705v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19705v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2837"
  },
  {
    "objectID": "posts/OMG_LLaVA_Bridging_Image_level_Object_level_Pixel_level_Reasoning_and_Understanding/2024-06-27-OMG_LLaVA_Bridging_Image_level_Object_level_Pixel_level_Reasoning_and_Understanding.html#appendix",
    "href": "posts/OMG_LLaVA_Bridging_Image_level_Object_level_Pixel_level_Reasoning_and_Understanding/2024-06-27-OMG_LLaVA_Bridging_Image_level_Object_level_Pixel_level_Reasoning_and_Understanding.html#appendix",
    "title": "OMG-LLaVA: Bridging Image-level, Object-level, Pixel-level Reasoning and Understanding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19389v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19389v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9015"
  },
  {
    "objectID": "posts/Automated_Educational_Question_Generation_at_Different_Blooms_Skill_Levels_using_Large_Language_Models_Strategies_and_Evaluation/2024-08-08-Automated_Educational_Question_Generation_at_Different_Blooms_Skill_Levels_using_Large_Language_Models_Strategies_and_Evaluation.html#appendix",
    "href": "posts/Automated_Educational_Question_Generation_at_Different_Blooms_Skill_Levels_using_Large_Language_Models_Strategies_and_Evaluation/2024-08-08-Automated_Educational_Question_Generation_at_Different_Blooms_Skill_Levels_using_Large_Language_Models_Strategies_and_Evaluation.html#appendix",
    "title": "Automated Educational Question Generation at Different Bloom’s Skill Levels using Large Language Models: Strategies and Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04394v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04394v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5838"
  },
  {
    "objectID": "posts/Large_language_models_for_generating_rules_yay_or_nay/2024-06-10-Large_language_models_for_generating_rules_yay_or_nay.html#appendix",
    "href": "posts/Large_language_models_for_generating_rules_yay_or_nay/2024-06-10-Large_language_models_for_generating_rules_yay_or_nay.html#appendix",
    "title": "Large language models for generating rules, yay or nay?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06835v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06835v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4575"
  },
  {
    "objectID": "posts/LLaMAX_Scaling_Linguistic_Horizons_of_LLM_by_Enhancing_Translation_Capabilities_Beyond_100_Languages/2024-07-08-LLaMAX_Scaling_Linguistic_Horizons_of_LLM_by_Enhancing_Translation_Capabilities_Beyond_100_Languages.html#appendix",
    "href": "posts/LLaMAX_Scaling_Linguistic_Horizons_of_LLM_by_Enhancing_Translation_Capabilities_Beyond_100_Languages/2024-07-08-LLaMAX_Scaling_Linguistic_Horizons_of_LLM_by_Enhancing_Translation_Capabilities_Beyond_100_Languages.html#appendix",
    "title": "LLaMAX: Scaling Linguistic Horizons of LLM by Enhancing Translation Capabilities Beyond 100 Languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05975v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05975v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10244"
  },
  {
    "objectID": "posts/Efficient_course_recommendations_with_T5_based_ranking_and_summarization/2024-06-27-Efficient_course_recommendations_with_T5_based_ranking_and_summarization.html#appendix",
    "href": "posts/Efficient_course_recommendations_with_T5_based_ranking_and_summarization/2024-06-27-Efficient_course_recommendations_with_T5_based_ranking_and_summarization.html#appendix",
    "title": "Efficient course recommendations with T5-based ranking and summarization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19018v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19018v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9587"
  },
  {
    "objectID": "posts/How_to_Understand_Whole_Software_Repository/2024-06-03-How_to_Understand_Whole_Software_Repository.html#appendix",
    "href": "posts/How_to_Understand_Whole_Software_Repository/2024-06-03-How_to_Understand_Whole_Software_Repository.html#appendix",
    "title": "How to Understand Whole Software Repository?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01422v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01422v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10556"
  },
  {
    "objectID": "posts/Towards_a_Personal_Health_Large_Language_Model/2024-06-10-Towards_a_Personal_Health_Large_Language_Model.html",
    "href": "posts/Towards_a_Personal_Health_Large_Language_Model/2024-06-10-Towards_a_Personal_Health_Large_Language_Model.html",
    "title": "Towards a Personal Health Large Language Model",
    "section": "",
    "text": "Summary:\nThe paper introduces Personal Health Large Language Model (PH-LLM), a version of Gemini fine-tuned for personal health and wellness. PH-LLM is evaluated on three aspects of personal health: generating personalized insights and recommendations for user goals in the domains of sleep and fitness, assessing levels of expert domain knowledge, and predicting patient-reported outcomes in sleep quality from detailed sensor information. The model is benchmarked against expert human responses and evaluated through comprehensive human and automatic evaluation of domain-specific rubrics. The results show that both Gemini Ultra 1.0 and PH-LLM are not statistically different from expert performance in fitness, while experts remain superior for sleep. However, fine-tuning PH-LLM provided significant improvements in using relevant domain knowledge and personalizing information for sleep insights. PH-LLM achieved 79% on sleep (N=629 questions) and 88% on fitness (N=99 questions) in multiple choice question examinations, both of which exceed average scores from a sample of human experts. The model also demonstrated the ability to predict self-reported assessments of sleep quality by training it to predict self-reported sleep disruption and sleep impairment outcomes from textual and multimodal encoding representations of wearable sensor data.\nMajor Findings:"
  },
  {
    "objectID": "posts/Towards_a_Personal_Health_Large_Language_Model/2024-06-10-Towards_a_Personal_Health_Large_Language_Model.html#appendix",
    "href": "posts/Towards_a_Personal_Health_Large_Language_Model/2024-06-10-Towards_a_Personal_Health_Large_Language_Model.html#appendix",
    "title": "Towards a Personal Health Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06474v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06474v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17580"
  },
  {
    "objectID": "posts/RAG_Foundry_A_Framework_for_Enhancing_LLMs_for_Retrieval_Augmented_Generation/2024-08-05-RAG_Foundry_A_Framework_for_Enhancing_LLMs_for_Retrieval_Augmented_Generation.html#appendix",
    "href": "posts/RAG_Foundry_A_Framework_for_Enhancing_LLMs_for_Retrieval_Augmented_Generation/2024-08-05-RAG_Foundry_A_Framework_for_Enhancing_LLMs_for_Retrieval_Augmented_Generation.html#appendix",
    "title": "RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02545v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02545v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10367"
  },
  {
    "objectID": "posts/C2P_Featuring_Large_Language_Models_with_Causal_Reasoning/2024-07-25-C2P_Featuring_Large_Language_Models_with_Causal_Reasoning.html#appendix",
    "href": "posts/C2P_Featuring_Large_Language_Models_with_Causal_Reasoning/2024-07-25-C2P_Featuring_Large_Language_Models_with_Causal_Reasoning.html#appendix",
    "title": "C2P: Featuring Large Language Models with Causal Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.18069v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.18069v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10834"
  },
  {
    "objectID": "posts/An_Actionable_Framework_for_Assessing_Bias_and_Fairness_in_Large_Language_Model_Use_Cases/2024-07-15-An_Actionable_Framework_for_Assessing_Bias_and_Fairness_in_Large_Language_Model_Use_Cases.html#appendix",
    "href": "posts/An_Actionable_Framework_for_Assessing_Bias_and_Fairness_in_Large_Language_Model_Use_Cases/2024-07-15-An_Actionable_Framework_for_Assessing_Bias_and_Fairness_in_Large_Language_Model_Use_Cases.html#appendix",
    "title": "An Actionable Framework for Assessing Bias and Fairness in Large Language Model Use Cases",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10853v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10853v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11496"
  },
  {
    "objectID": "posts/EAGLE_2_Faster_Inference_of_Language_Models_with_Dynamic_Draft_Trees/2024-06-24-EAGLE_2_Faster_Inference_of_Language_Models_with_Dynamic_Draft_Trees.html#appendix",
    "href": "posts/EAGLE_2_Faster_Inference_of_Language_Models_with_Dynamic_Draft_Trees/2024-06-24-EAGLE_2_Faster_Inference_of_Language_Models_with_Dynamic_Draft_Trees.html#appendix",
    "title": "EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16858v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16858v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6645"
  },
  {
    "objectID": "posts/KaPO_Knowledge_aware_Preference_Optimization_for_Controllable_Knowledge_Selection_in_Retrieval_Augmented_Language_Models/2024-08-06-KaPO_Knowledge_aware_Preference_Optimization_for_Controllable_Knowledge_Selection_in_Retrieval_Augmented_Language_Models.html#appendix",
    "href": "posts/KaPO_Knowledge_aware_Preference_Optimization_for_Controllable_Knowledge_Selection_in_Retrieval_Augmented_Language_Models/2024-08-06-KaPO_Knowledge_aware_Preference_Optimization_for_Controllable_Knowledge_Selection_in_Retrieval_Augmented_Language_Models.html#appendix",
    "title": "KaPO: Knowledge-aware Preference Optimization for Controllable Knowledge Selection in Retrieval-Augmented Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03297v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03297v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6056"
  },
  {
    "objectID": "posts/MM_Forecast_A_Multimodal_Approach_to_Temporal_Event_Forecasting_with_Large_Language_Models/2024-08-08-MM_Forecast_A_Multimodal_Approach_to_Temporal_Event_Forecasting_with_Large_Language_Models.html#major-findings",
    "href": "posts/MM_Forecast_A_Multimodal_Approach_to_Temporal_Event_Forecasting_with_Large_Language_Models/2024-08-08-MM_Forecast_A_Multimodal_Approach_to_Temporal_Event_Forecasting_with_Large_Language_Models.html#major-findings",
    "title": "MM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe study identifies two essential functions of images in temporal event forecasting: highlighting and complementary.\nThe proposed MM-Forecast framework recognizes these functions using MLLMs and integrates them into LLM-based forecasting models.\nThe evaluation of MM-Forecast on the MidEast-TE-mm dataset shows that it can accurately identify image functions and improve forecasting performance."
  },
  {
    "objectID": "posts/MM_Forecast_A_Multimodal_Approach_to_Temporal_Event_Forecasting_with_Large_Language_Models/2024-08-08-MM_Forecast_A_Multimodal_Approach_to_Temporal_Event_Forecasting_with_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/MM_Forecast_A_Multimodal_Approach_to_Temporal_Event_Forecasting_with_Large_Language_Models/2024-08-08-MM_Forecast_A_Multimodal_Approach_to_Temporal_Event_Forecasting_with_Large_Language_Models.html#analysis-and-critique",
    "title": "MM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper addresses an important and emerging problem in the field of temporal event forecasting, namely the integration of visual information into LLM-based models.\nThe proposed MM-Forecast framework is a promising approach to address this problem, as it leverages the superior multimodal understanding and reasoning capabilities of MLLMs.\nThe evaluation of MM-Forecast on the MidEast-TE-mm dataset provides empirical evidence of its effectiveness in improving forecasting performance.\nHowever, the paper does not discuss potential limitations or challenges in applying the proposed method to other datasets or domains.\nThe paper also does not provide a detailed comparison of MM-Forecast with other existing methods for temporal event forecasting.\nFuture research could explore the generalizability of MM-Forecast to other datasets and domains, as well as compare its performance with other state-of-the-art methods."
  },
  {
    "objectID": "posts/MM_Forecast_A_Multimodal_Approach_to_Temporal_Event_Forecasting_with_Large_Language_Models/2024-08-08-MM_Forecast_A_Multimodal_Approach_to_Temporal_Event_Forecasting_with_Large_Language_Models.html#appendix",
    "href": "posts/MM_Forecast_A_Multimodal_Approach_to_Temporal_Event_Forecasting_with_Large_Language_Models/2024-08-08-MM_Forecast_A_Multimodal_Approach_to_Temporal_Event_Forecasting_with_Large_Language_Models.html#appendix",
    "title": "MM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.04388v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.04388v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8512"
  },
  {
    "objectID": "posts/Psychomatics____A_Multidisciplinary_Framework_for_Understanding_Artificial_Minds/2024-07-23-Psychomatics____A_Multidisciplinary_Framework_for_Understanding_Artificial_Minds.html#appendix",
    "href": "posts/Psychomatics____A_Multidisciplinary_Framework_for_Understanding_Artificial_Minds/2024-07-23-Psychomatics____A_Multidisciplinary_Framework_for_Understanding_Artificial_Minds.html#appendix",
    "title": "Psychomatics – A Multidisciplinary Framework for Understanding Artificial Minds",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16444v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16444v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11619"
  },
  {
    "objectID": "posts/RAG_Optimized_Tibetan_Tourism_LLMs_Enhancing_Accuracy_and_Personalization/2024-08-21-RAG_Optimized_Tibetan_Tourism_LLMs_Enhancing_Accuracy_and_Personalization.html#appendix",
    "href": "posts/RAG_Optimized_Tibetan_Tourism_LLMs_Enhancing_Accuracy_and_Personalization/2024-08-21-RAG_Optimized_Tibetan_Tourism_LLMs_Enhancing_Accuracy_and_Personalization.html#appendix",
    "title": "RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12003v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12003v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5092"
  },
  {
    "objectID": "posts/A_Collaborative_Data_Analytics_System_with_Recommender_for_Diverse_Users/2024-06-17-A_Collaborative_Data_Analytics_System_with_Recommender_for_Diverse_Users.html#appendix",
    "href": "posts/A_Collaborative_Data_Analytics_System_with_Recommender_for_Diverse_Users/2024-06-17-A_Collaborative_Data_Analytics_System_with_Recommender_for_Diverse_Users.html#appendix",
    "title": "A Collaborative Data Analytics System with Recommender for Diverse Users",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11232v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11232v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13618"
  },
  {
    "objectID": "posts/On_LLM_Wizards_Identifying_Large_Language_Models_Behaviors_for_Wizard_of_Oz_Experiments/2024-07-10-On_LLM_Wizards_Identifying_Large_Language_Models_Behaviors_for_Wizard_of_Oz_Experiments.html#appendix",
    "href": "posts/On_LLM_Wizards_Identifying_Large_Language_Models_Behaviors_for_Wizard_of_Oz_Experiments/2024-07-10-On_LLM_Wizards_Identifying_Large_Language_Models_Behaviors_for_Wizard_of_Oz_Experiments.html#appendix",
    "title": "On LLM Wizards: Identifying Large Language Models’ Behaviors for Wizard of Oz Experiments",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08067v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08067v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13493"
  },
  {
    "objectID": "posts/MathOdyssey_Benchmarking_Mathematical_Problem_Solving_Skills_in_Large_Language_Models_Using_Odyssey_Math_Data/2024-06-26-MathOdyssey_Benchmarking_Mathematical_Problem_Solving_Skills_in_Large_Language_Models_Using_Odyssey_Math_Data.html#appendix",
    "href": "posts/MathOdyssey_Benchmarking_Mathematical_Problem_Solving_Skills_in_Large_Language_Models_Using_Odyssey_Math_Data/2024-06-26-MathOdyssey_Benchmarking_Mathematical_Problem_Solving_Skills_in_Large_Language_Models_Using_Odyssey_Math_Data.html#appendix",
    "title": "MathOdyssey: Benchmarking Mathematical Problem-Solving Skills in Large Language Models Using Odyssey Math Data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18321v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18321v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5533"
  },
  {
    "objectID": "posts/Evaluating_Cultural_Adaptability_of_a_Large_Language_Model_via_Simulation_of_Synthetic_Personas/2024-08-13-Evaluating_Cultural_Adaptability_of_a_Large_Language_Model_via_Simulation_of_Synthetic_Personas.html#appendix",
    "href": "posts/Evaluating_Cultural_Adaptability_of_a_Large_Language_Model_via_Simulation_of_Synthetic_Personas/2024-08-13-Evaluating_Cultural_Adaptability_of_a_Large_Language_Model_via_Simulation_of_Synthetic_Personas.html#appendix",
    "title": "Evaluating Cultural Adaptability of a Large Language Model via Simulation of Synthetic Personas",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.06929v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.06929v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5805"
  },
  {
    "objectID": "posts/Time_Series_Analysis_for_Education_Methods_Applications_and_Future_Directions/2024-08-25-Time_Series_Analysis_for_Education_Methods_Applications_and_Future_Directions.html",
    "href": "posts/Time_Series_Analysis_for_Education_Methods_Applications_and_Future_Directions/2024-08-25-Time_Series_Analysis_for_Education_Methods_Applications_and_Future_Directions.html",
    "title": "Time Series Analysis for Education: Methods, Applications, and Future Directions",
    "section": "",
    "text": "Summary:\nThis paper provides a comprehensive review of time series analysis techniques specifically within the educational context. The authors explore the landscape of educational data analytics, categorizing various data sources and types relevant to education. They then review four prominent time series methods—forecasting, classification, clustering, and anomaly detection—illustrating their specific application points in educational settings. The paper also presents a range of educational scenarios and applications, focusing on how these methods are employed to address diverse educational tasks. Finally, the authors discuss future directions, including personalized learning analytics, multimodal data fusion, and the role of large language models (LLMs) in educational time series.\nMajor Findings:\nAnalysis and Critique:\nThis paper offers a comprehensive overview of time series analysis in educational contexts, covering mainstream methods and their practical applications in real-world educational scenarios. The authors emphasize the importance of a detailed taxonomy of educational data, which is crucial for understanding and applying time series techniques in education. However, the paper could benefit from a more in-depth discussion of the limitations and potential biases of these methods, as well as the challenges associated with integrating advanced techniques in educational time series. Additionally, the authors could provide more concrete examples of how these methods have been applied in specific educational settings, highlighting their impact on student outcomes and learning experiences."
  },
  {
    "objectID": "posts/Time_Series_Analysis_for_Education_Methods_Applications_and_Future_Directions/2024-08-25-Time_Series_Analysis_for_Education_Methods_Applications_and_Future_Directions.html#appendix",
    "href": "posts/Time_Series_Analysis_for_Education_Methods_Applications_and_Future_Directions/2024-08-25-Time_Series_Analysis_for_Education_Methods_Applications_and_Future_Directions.html#appendix",
    "title": "Time Series Analysis for Education: Methods, Applications, and Future Directions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.13960v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.13960v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14772"
  },
  {
    "objectID": "posts/CHECKWHY_Causal_Fact_Verification_via_Argument_Structure/2024-08-20-CHECKWHY_Causal_Fact_Verification_via_Argument_Structure.html#major-findings",
    "href": "posts/CHECKWHY_Causal_Fact_Verification_via_Argument_Structure/2024-08-20-CHECKWHY_Causal_Fact_Verification_via_Argument_Structure.html#major-findings",
    "title": "CHECKWHY: Causal Fact Verification via Argument Structure",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nCheckWhy Dataset: The paper introduces a new dataset, CheckWhy, for causal fact verification. The dataset consists of over 19K “why” claim-evidence-argument structure triplets, with supports, refutes, and not enough info labels.\nImportance of Argument Structure: The paper validates the importance of incorporating the argument structure for causal fact verification. The argument structure is composed of connected evidence, representing the reasoning process from foundational evidence to claim establishment.\nExperiments on State-of-the-art Models: The paper conducts extensive experiments on state-of-the-art models to validate the importance of incorporating the argument structure for causal fact verification."
  },
  {
    "objectID": "posts/CHECKWHY_Causal_Fact_Verification_via_Argument_Structure/2024-08-20-CHECKWHY_Causal_Fact_Verification_via_Argument_Structure.html#analysis-and-critique",
    "href": "posts/CHECKWHY_Causal_Fact_Verification_via_Argument_Structure/2024-08-20-CHECKWHY_Causal_Fact_Verification_via_Argument_Structure.html#analysis-and-critique",
    "title": "CHECKWHY: Causal Fact Verification via Argument Structure",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nLimited Scope: The paper focuses on a specific type of fact verification, i.e., causal fact verification. The findings may not be generalizable to other types of fact verification tasks.\nPotential Bias: The paper uses a human-model collaboration annotation approach to generate claims, evidence, and corresponding argument structures. This approach may introduce potential bias in the dataset.\nComplexity of Argument Structure: The paper acknowledges the complexity of the argument structure and the difficulty in producing satisfying argument structures for causal claims. This complexity may limit the applicability of the dataset in real-world scenarios.\nAbsence of Real-world Context: The paper mentions that the label assigned to each claim is based on distinct argument structures, which may not always correspond to real-world circumstances. This absence of real-world context may limit the practical utility of the dataset.\nDifficulty in Retrieving Evidence: The paper acknowled"
  },
  {
    "objectID": "posts/CHECKWHY_Causal_Fact_Verification_via_Argument_Structure/2024-08-20-CHECKWHY_Causal_Fact_Verification_via_Argument_Structure.html#appendix",
    "href": "posts/CHECKWHY_Causal_Fact_Verification_via_Argument_Structure/2024-08-20-CHECKWHY_Causal_Fact_Verification_via_Argument_Structure.html#appendix",
    "title": "CHECKWHY: Causal Fact Verification via Argument Structure",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10918v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10918v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8359"
  },
  {
    "objectID": "posts/Comparative_Analysis_of_Encoder_Based_NER_and_Large_Language_Models_for_Skill_Extraction_from_Russian_Job_Vacancies/2024-07-29-Comparative_Analysis_of_Encoder_Based_NER_and_Large_Language_Models_for_Skill_Extraction_from_Russian_Job_Vacancies.html#appendix",
    "href": "posts/Comparative_Analysis_of_Encoder_Based_NER_and_Large_Language_Models_for_Skill_Extraction_from_Russian_Job_Vacancies/2024-07-29-Comparative_Analysis_of_Encoder_Based_NER_and_Large_Language_Models_for_Skill_Extraction_from_Russian_Job_Vacancies.html#appendix",
    "title": "Comparative Analysis of Encoder-Based NER and Large Language Models for Skill Extraction from Russian Job Vacancies",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19816v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19816v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4205"
  },
  {
    "objectID": "posts/Towards_Evaluating_and_Building_Versatile_Large_Language_Models_for_Medicine/2024-08-22-Towards_Evaluating_and_Building_Versatile_Large_Language_Models_for_Medicine.html",
    "href": "posts/Towards_Evaluating_and_Building_Versatile_Large_Language_Models_for_Medicine/2024-08-22-Towards_Evaluating_and_Building_Versatile_Large_Language_Models_for_Medicine.html",
    "title": "Towards Evaluating and Building Versatile Large Language Models for Medicine",
    "section": "",
    "text": "Summary:\nThe study introduces MedS-Bench, a comprehensive benchmark for evaluating the performance of large language models (LLMs) in clinical contexts. Unlike existing benchmarks, MedS-Bench covers 11 high-level clinical tasks, including clinical report summarization, treatment recommendations, diagnosis, named entity recognition, and medical concept explanation. The authors evaluated six leading LLMs and found that even the most sophisticated models struggle with these complex tasks. To address these limitations, they developed MedS-Ins, a large-scale instruction tuning dataset for medicine, comprising 58 medically oriented language corpora, totaling 13.5 million samples across 122 tasks. A proof-of-concept experiment demonstrated the dataset’s utility by performing instruction tuning on a lightweight, open-source medical language model, which significantly outperformed existing models across nearly all clinical tasks. The authors have made the MedS-Ins dataset fully accessible and launched a dynamic leaderboard for MedS-Bench to track progress and enhance the adaptation of general LLMs to the medical domain.\nMajor Findings:\nAnalysis and Critique:\nThe study provides a valuable contribution to the field by introducing a comprehensive benchmark for evaluating LLMs in clinical contexts. The authors’ findings highlight the limitations of existing models in handling complex clinical tasks and underscore the need for further research in this area. The development of MedS-Ins as a large-scale instruction tuning dataset for medicine is a promising step towards addressing these limitations. However, the study’s scope"
  },
  {
    "objectID": "posts/Towards_Evaluating_and_Building_Versatile_Large_Language_Models_for_Medicine/2024-08-22-Towards_Evaluating_and_Building_Versatile_Large_Language_Models_for_Medicine.html#appendix",
    "href": "posts/Towards_Evaluating_and_Building_Versatile_Large_Language_Models_for_Medicine/2024-08-22-Towards_Evaluating_and_Building_Versatile_Large_Language_Models_for_Medicine.html#appendix",
    "title": "Towards Evaluating and Building Versatile Large Language Models for Medicine",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.12547v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.12547v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14320"
  },
  {
    "objectID": "posts/What_if_Red_Can_Talk_Dynamic_Dialogue_Generation_Using_Large_Language_Models/2024-07-29-What_if_Red_Can_Talk_Dynamic_Dialogue_Generation_Using_Large_Language_Models.html#appendix",
    "href": "posts/What_if_Red_Can_Talk_Dynamic_Dialogue_Generation_Using_Large_Language_Models/2024-07-29-What_if_Red_Can_Talk_Dynamic_Dialogue_Generation_Using_Large_Language_Models.html#appendix",
    "title": "What if Red Can Talk? Dynamic Dialogue Generation Using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20382v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20382v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4779"
  },
  {
    "objectID": "posts/Adversarial_Search_Engine_Optimization_for_Large_Language_Models/2024-06-26-Adversarial_Search_Engine_Optimization_for_Large_Language_Models.html#appendix",
    "href": "posts/Adversarial_Search_Engine_Optimization_for_Large_Language_Models/2024-06-26-Adversarial_Search_Engine_Optimization_for_Large_Language_Models.html#appendix",
    "title": "Adversarial Search Engine Optimization for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18382v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18382v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13149"
  },
  {
    "objectID": "posts/Joint_Demonstration_and_Preference_Learning_Improves_Policy_Alignment_with_Human_Feedback/2024-06-11-Joint_Demonstration_and_Preference_Learning_Improves_Policy_Alignment_with_Human_Feedback.html#appendix",
    "href": "posts/Joint_Demonstration_and_Preference_Learning_Improves_Policy_Alignment_with_Human_Feedback/2024-06-11-Joint_Demonstration_and_Preference_Learning_Improves_Policy_Alignment_with_Human_Feedback.html#appendix",
    "title": "Joint Demonstration and Preference Learning Improves Policy Alignment with Human Feedback",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06874v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06874v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10718"
  },
  {
    "objectID": "posts/FreeTraj_Tuning_Free_Trajectory_Control_in_Video_Diffusion_Models/2024-06-24-FreeTraj_Tuning_Free_Trajectory_Control_in_Video_Diffusion_Models.html#appendix",
    "href": "posts/FreeTraj_Tuning_Free_Trajectory_Control_in_Video_Diffusion_Models/2024-06-24-FreeTraj_Tuning_Free_Trajectory_Control_in_Video_Diffusion_Models.html#appendix",
    "title": "FreeTraj: Tuning-Free Trajectory Control in Video Diffusion Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16863v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16863v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8202"
  },
  {
    "objectID": "posts/Chat2Layout_Interactive_3D_Furniture_Layout_with_a_Multimodal_LLM/2024-07-31-Chat2Layout_Interactive_3D_Furniture_Layout_with_a_Multimodal_LLM.html#appendix",
    "href": "posts/Chat2Layout_Interactive_3D_Furniture_Layout_with_a_Multimodal_LLM/2024-07-31-Chat2Layout_Interactive_3D_Furniture_Layout_with_a_Multimodal_LLM.html#appendix",
    "title": "Chat2Layout: Interactive 3D Furniture Layout with a Multimodal LLM",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21333v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21333v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10112"
  },
  {
    "objectID": "posts/Step_by_Step_Unmasking_for_Parameter_Efficient_Fine_tuning_of_Large_Language_Models/2024-08-26-Step_by_Step_Unmasking_for_Parameter_Efficient_Fine_tuning_of_Large_Language_Models.html#appendix",
    "href": "posts/Step_by_Step_Unmasking_for_Parameter_Efficient_Fine_tuning_of_Large_Language_Models/2024-08-26-Step_by_Step_Unmasking_for_Parameter_Efficient_Fine_tuning_of_Large_Language_Models.html#appendix",
    "title": "Step-by-Step Unmasking for Parameter-Efficient Fine-tuning of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.14470v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.14470v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8198"
  },
  {
    "objectID": "posts/Demystifying_the_Communication_Characteristics_for_Distributed_Transformer_Models/2024-08-19-Demystifying_the_Communication_Characteristics_for_Distributed_Transformer_Models.html#appendix",
    "href": "posts/Demystifying_the_Communication_Characteristics_for_Distributed_Transformer_Models/2024-08-19-Demystifying_the_Communication_Characteristics_for_Distributed_Transformer_Models.html#appendix",
    "title": "Demystifying the Communication Characteristics for Distributed Transformer Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-20\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10197v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10197v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6460"
  },
  {
    "objectID": "posts/IRCAN_Mitigating_Knowledge_Conflicts_in_LLM_Generation_via_Identifying_and_Reweighting_Context_Aware_Neurons/2024-06-26-IRCAN_Mitigating_Knowledge_Conflicts_in_LLM_Generation_via_Identifying_and_Reweighting_Context_Aware_Neurons.html#appendix",
    "href": "posts/IRCAN_Mitigating_Knowledge_Conflicts_in_LLM_Generation_via_Identifying_and_Reweighting_Context_Aware_Neurons/2024-06-26-IRCAN_Mitigating_Knowledge_Conflicts_in_LLM_Generation_via_Identifying_and_Reweighting_Context_Aware_Neurons.html#appendix",
    "title": "IRCAN: Mitigating Knowledge Conflicts in LLM Generation via Identifying and Reweighting Context-Aware Neurons",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18406v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18406v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6376"
  },
  {
    "objectID": "posts/Model_Tells_You_Where_to_Merge_Adaptive_KV_Cache_Merging_for_LLMs_on_Long_Context_Tasks/2024-07-11-Model_Tells_You_Where_to_Merge_Adaptive_KV_Cache_Merging_for_LLMs_on_Long_Context_Tasks.html#appendix",
    "href": "posts/Model_Tells_You_Where_to_Merge_Adaptive_KV_Cache_Merging_for_LLMs_on_Long_Context_Tasks/2024-07-11-Model_Tells_You_Where_to_Merge_Adaptive_KV_Cache_Merging_for_LLMs_on_Long_Context_Tasks.html#appendix",
    "title": "Model Tells You Where to Merge: Adaptive KV Cache Merging for LLMs on Long-Context Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08454v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08454v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8835"
  },
  {
    "objectID": "posts/Synthetic_Patient_Physician_Dialogue_Generation_from_Clinical_Notes_Using_LLM/2024-08-12-Synthetic_Patient_Physician_Dialogue_Generation_from_Clinical_Notes_Using_LLM.html#appendix",
    "href": "posts/Synthetic_Patient_Physician_Dialogue_Generation_from_Clinical_Notes_Using_LLM/2024-08-12-Synthetic_Patient_Physician_Dialogue_Generation_from_Clinical_Notes_Using_LLM.html#appendix",
    "title": "Synthetic Patient-Physician Dialogue Generation from Clinical Notes Using LLM",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.06285v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.06285v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3867"
  },
  {
    "objectID": "posts/Collective_Innovation_in_Groups_of_Large_Language_Models/2024-07-07-Collective_Innovation_in_Groups_of_Large_Language_Models.html#appendix",
    "href": "posts/Collective_Innovation_in_Groups_of_Large_Language_Models/2024-07-07-Collective_Innovation_in_Groups_of_Large_Language_Models.html#appendix",
    "title": "Collective Innovation in Groups of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05377v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05377v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8010"
  },
  {
    "objectID": "posts/OneLove_beyond_the_field____A_few_shot_pipeline_for_topic_and_sentiment_analysis_during_the_FIFA_World_Cup_in_Qatar/2024-08-05-OneLove_beyond_the_field____A_few_shot_pipeline_for_topic_and_sentiment_analysis_during_the_FIFA_World_Cup_in_Qatar.html#appendix",
    "href": "posts/OneLove_beyond_the_field____A_few_shot_pipeline_for_topic_and_sentiment_analysis_during_the_FIFA_World_Cup_in_Qatar/2024-08-05-OneLove_beyond_the_field____A_few_shot_pipeline_for_topic_and_sentiment_analysis_during_the_FIFA_World_Cup_in_Qatar.html#appendix",
    "title": "OneLove beyond the field – A few-shot pipeline for topic and sentiment analysis during the FIFA World Cup in Qatar",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02520v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02520v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4830"
  },
  {
    "objectID": "posts/Is_ChatGPT_a_Better_Explainer_than_My_Professor_Evaluating_the_Explanation_Capabilities_of_LLMs_in_Conversation_Compared_to_a_Human_Baseline/2024-06-26-Is_ChatGPT_a_Better_Explainer_than_My_Professor_Evaluating_the_Explanation_Capabilities_of_LLMs_in_Conversation_Compared_to_a_Human_Baseline.html#appendix",
    "href": "posts/Is_ChatGPT_a_Better_Explainer_than_My_Professor_Evaluating_the_Explanation_Capabilities_of_LLMs_in_Conversation_Compared_to_a_Human_Baseline/2024-06-26-Is_ChatGPT_a_Better_Explainer_than_My_Professor_Evaluating_the_Explanation_Capabilities_of_LLMs_in_Conversation_Compared_to_a_Human_Baseline.html#appendix",
    "title": "Is ChatGPT a Better Explainer than My Professor?: Evaluating the Explanation Capabilities of LLMs in Conversation Compared to a Human Baseline",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18512v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18512v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4167"
  },
  {
    "objectID": "posts/Unleashing_the_Power_of_Data_Tsunami_A_Comprehensive_Survey_on_Data_Assessment_and_Selection_for_Instruction_Tuning_of_Language_Models/2024-08-04-Unleashing_the_Power_of_Data_Tsunami_A_Comprehensive_Survey_on_Data_Assessment_and_Selection_for_Instruction_Tuning_of_Language_Models.html",
    "href": "posts/Unleashing_the_Power_of_Data_Tsunami_A_Comprehensive_Survey_on_Data_Assessment_and_Selection_for_Instruction_Tuning_of_Language_Models/2024-08-04-Unleashing_the_Power_of_Data_Tsunami_A_Comprehensive_Survey_on_Data_Assessment_and_Selection_for_Instruction_Tuning_of_Language_Models.html",
    "title": "Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data Assessment and Selection for Instruction Tuning of Language Models",
    "section": "",
    "text": "Summary:\nThis paper presents a comprehensive review of existing literature on data assessment and selection methods for instruction tuning of large language models (LLMs). The study aims to unify a wide array of methods under the context of instruction tuning and categorize them into quality-based, diversity-based, and importance-based methods. The paper also discusses the limitations of existing methods and proposes promising avenues for future studies.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive review of existing literature on data assessment and selection methods for instruction tuning of LLMs. The study categorizes the methods into three main perspectives: quality, diversity, and importance, providing a rationalized organization taxonomy for structured elaboration. However, the paper only provides details of certain typical, representative methods to avoid being tediously long. The paper also discusses the limitations of existing methods and proposes promising avenues for future studies.\nOne potential limitation of the study is that it does not provide a detailed analysis of the performance of each method. The paper only reports the performance of typical data selection methods and provides discussions on the comparison between these methods. Future studies could provide a more detailed analysis of the performance of each method and compare their strengths and weaknesses.\nAnother potential limitation is that the paper does not discuss the scalability of the methods. With the increasing size of LLMs, it is important to consider the scalability of the data assessment and selection methods. Future studies could investigate the scalability of the methods and propose solutions to improve their scalability.\nIn conclusion, the paper provides a comprehensive review of existing literature on data assessment and selection methods for instruction tuning of LLMs. The study categorizes the methods into three main perspectives: quality, diversity, and importance,"
  },
  {
    "objectID": "posts/Unleashing_the_Power_of_Data_Tsunami_A_Comprehensive_Survey_on_Data_Assessment_and_Selection_for_Instruction_Tuning_of_Language_Models/2024-08-04-Unleashing_the_Power_of_Data_Tsunami_A_Comprehensive_Survey_on_Data_Assessment_and_Selection_for_Instruction_Tuning_of_Language_Models.html#appendix",
    "href": "posts/Unleashing_the_Power_of_Data_Tsunami_A_Comprehensive_Survey_on_Data_Assessment_and_Selection_for_Instruction_Tuning_of_Language_Models/2024-08-04-Unleashing_the_Power_of_Data_Tsunami_A_Comprehensive_Survey_on_Data_Assessment_and_Selection_for_Instruction_Tuning_of_Language_Models.html#appendix",
    "title": "Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data Assessment and Selection for Instruction Tuning of Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2408.02085v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.02085v1\n\n\nTruncated\nFalse\n\n\nWord Count\n21595"
  },
  {
    "objectID": "posts/GenSco_Can_Question_Decomposition_based_Passage_Alignment_improve_Question_Answering/2024-07-14-GenSco_Can_Question_Decomposition_based_Passage_Alignment_improve_Question_Answering.html#appendix",
    "href": "posts/GenSco_Can_Question_Decomposition_based_Passage_Alignment_improve_Question_Answering/2024-07-14-GenSco_Can_Question_Decomposition_based_Passage_Alignment_improve_Question_Answering.html#appendix",
    "title": "GenSco: Can Question Decomposition based Passage Alignment improve Question Answering?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10245v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10245v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7220"
  },
  {
    "objectID": "posts/Efficient_and_Deployable_Knowledge_Infusion_for_Open_World_Recommendations_via_Large_Language_Models/2024-08-20-Efficient_and_Deployable_Knowledge_Infusion_for_Open_World_Recommendations_via_Large_Language_Models.html",
    "href": "posts/Efficient_and_Deployable_Knowledge_Infusion_for_Open_World_Recommendations_via_Large_Language_Models/2024-08-20-Efficient_and_Deployable_Knowledge_Infusion_for_Open_World_Recommendations_via_Large_Language_Models.html",
    "title": "Efficient and Deployable Knowledge Infusion for Open-World Recommendations via Large Language Models",
    "section": "",
    "text": "Summary:\nThe paper proposes an Open-World Recommendation Framework with Efficient and Deployable Knowledge Infusion from Large Language Models (LLMs), called REKI. The framework aims to acquire two types of external knowledge about users and items from LLMs. It introduces factorization prompting to elicit accurate knowledge reasoning on user preferences and items. With factorization prompting, individual knowledge extraction and collective knowledge extraction are developed for different scales of recommendation scenarios, effectively reducing offline resource consumption. The generated user and item knowledge undergoes efficient transformation and condensation into augmented vectors through a hybridized expert-integrated network, ensuring its compatibility with the recommendation task. The obtained vectors can then be directly used to enhance the performance of any conventional recommendation model. Extensive experiments demonstrate that REKI significantly outperforms the state-of-the-art baselines and is compatible with a diverse array of recommendation algorithms and tasks. REKI has been deployed to Huawei’s news and music recommendation platforms and gained a 7% and 1.99% improvement during the online A/B test.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel framework, REKI, for incorporating external knowledge from LLMs into recommendation models. The use of factorization prompting and individual/collective knowledge extraction techniques"
  },
  {
    "objectID": "posts/Efficient_and_Deployable_Knowledge_Infusion_for_Open_World_Recommendations_via_Large_Language_Models/2024-08-20-Efficient_and_Deployable_Knowledge_Infusion_for_Open_World_Recommendations_via_Large_Language_Models.html#appendix",
    "href": "posts/Efficient_and_Deployable_Knowledge_Infusion_for_Open_World_Recommendations_via_Large_Language_Models/2024-08-20-Efficient_and_Deployable_Knowledge_Infusion_for_Open_World_Recommendations_via_Large_Language_Models.html#appendix",
    "title": "Efficient and Deployable Knowledge Infusion for Open-World Recommendations via Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-27\n\n\nAbstract\nhttps://arxiv.org/abs/2408.10520v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.10520v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18779"
  },
  {
    "objectID": "posts/Anomaly_Detection_on_Unstable_Logs_with_GPT_Models/2024-06-11-Anomaly_Detection_on_Unstable_Logs_with_GPT_Models.html#appendix",
    "href": "posts/Anomaly_Detection_on_Unstable_Logs_with_GPT_Models/2024-06-11-Anomaly_Detection_on_Unstable_Logs_with_GPT_Models.html#appendix",
    "title": "Anomaly Detection on Unstable Logs with GPT Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07467v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07467v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11408"
  },
  {
    "objectID": "posts/Leveraging_Hybrid_Intelligence_Towards_Sustainable_and_Energy_Efficient_Machine_Learning/2024-07-15-Leveraging_Hybrid_Intelligence_Towards_Sustainable_and_Energy_Efficient_Machine_Learning.html#appendix",
    "href": "posts/Leveraging_Hybrid_Intelligence_Towards_Sustainable_and_Energy_Efficient_Machine_Learning/2024-07-15-Leveraging_Hybrid_Intelligence_Towards_Sustainable_and_Energy_Efficient_Machine_Learning.html#appendix",
    "title": "Leveraging Hybrid Intelligence Towards Sustainable and Energy-Efficient Machine Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10580v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10580v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3800"
  },
  {
    "objectID": "posts/Understanding_the_Importance_of_Evolutionary_Search_in_Automated_Heuristic_Design_with_Large_Language_Models/2024-07-15-Understanding_the_Importance_of_Evolutionary_Search_in_Automated_Heuristic_Design_with_Large_Language_Models.html",
    "href": "posts/Understanding_the_Importance_of_Evolutionary_Search_in_Automated_Heuristic_Design_with_Large_Language_Models/2024-07-15-Understanding_the_Importance_of_Evolutionary_Search_in_Automated_Heuristic_Design_with_Large_Language_Models.html",
    "title": "Understanding the Importance of Evolutionary Search in Automated Heuristic Design with Large Language Models",
    "section": "",
    "text": "Summary:\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/Understanding_the_Importance_of_Evolutionary_Search_in_Automated_Heuristic_Design_with_Large_Language_Models/2024-07-15-Understanding_the_Importance_of_Evolutionary_Search_in_Automated_Heuristic_Design_with_Large_Language_Models.html#appendix",
    "href": "posts/Understanding_the_Importance_of_Evolutionary_Search_in_Automated_Heuristic_Design_with_Large_Language_Models/2024-07-15-Understanding_the_Importance_of_Evolutionary_Search_in_Automated_Heuristic_Design_with_Large_Language_Models.html#appendix",
    "title": "Understanding the Importance of Evolutionary Search in Automated Heuristic Design with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10873v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10873v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9933"
  },
  {
    "objectID": "posts/When_Box_Meets_Graph_Neural_Network_in_Tag_aware_Recommendation/2024-06-17-When_Box_Meets_Graph_Neural_Network_in_Tag_aware_Recommendation.html#appendix",
    "href": "posts/When_Box_Meets_Graph_Neural_Network_in_Tag_aware_Recommendation/2024-06-17-When_Box_Meets_Graph_Neural_Network_in_Tag_aware_Recommendation.html#appendix",
    "title": "When Box Meets Graph Neural Network in Tag-aware Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12020v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12020v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8318"
  },
  {
    "objectID": "posts/A_Logical_Fallacy_Informed_Framework_for_Argument_Generation/2024-08-07-A_Logical_Fallacy_Informed_Framework_for_Argument_Generation.html",
    "href": "posts/A_Logical_Fallacy_Informed_Framework_for_Argument_Generation/2024-08-07-A_Logical_Fallacy_Informed_Framework_for_Argument_Generation.html",
    "title": "A Logical Fallacy-Informed Framework for Argument Generation",
    "section": "",
    "text": "Summary:\nThe paper “A Logical Fallacy-Informed Framework for Argument Generation” by Luca Mouchel et al. introduces a fallacy-informed framework called FIPO, which leverages preference optimization methods to steer Large Language Models (LLMs) towards generating logically sound arguments. The authors observe that LLMs struggle with generating coherent arguments due to their oversight of logical fallacies. FIPO includes a classification loss to capture fine-grained information on fallacy categories. The results on argumentation datasets show that FIPO reduces fallacy errors by up to 17.5%. Human evaluation results indicate that the quality of generated arguments by FIPO significantly outperforms fine-tuned baselines and prior preference optimization methods, such as DPO.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an innovative approach to addressing the challenge of generating logically sound arguments using LLMs. The proposed FIPO framework effectively reduces fallacy errors and improves the quality of generated arguments. However, the study has some limitations. The evaluation is primarily based on argumentation datasets, and the generalizability of the findings to other domains remains to be explored. Additionally, the study does not discuss the potential biases that LLMs may have, which could impact the generated arguments. Future research should address these limitations and explore the application of FIPO in other domains."
  },
  {
    "objectID": "posts/A_Logical_Fallacy_Informed_Framework_for_Argument_Generation/2024-08-07-A_Logical_Fallacy_Informed_Framework_for_Argument_Generation.html#appendix",
    "href": "posts/A_Logical_Fallacy_Informed_Framework_for_Argument_Generation/2024-08-07-A_Logical_Fallacy_Informed_Framework_for_Argument_Generation.html#appendix",
    "title": "A Logical Fallacy-Informed Framework for Argument Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-13\n\n\nAbstract\nhttps://arxiv.org/abs/2408.03618v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2408.03618v1\n\n\nTruncated\nFalse\n\n\nWord Count\n16410"
  },
  {
    "objectID": "posts/Tulip_Agent____Enabling_LLM_Based_Agents_to_Solve_Tasks_Using_Large_Tool_Libraries/2024-07-31-Tulip_Agent____Enabling_LLM_Based_Agents_to_Solve_Tasks_Using_Large_Tool_Libraries.html",
    "href": "posts/Tulip_Agent____Enabling_LLM_Based_Agents_to_Solve_Tasks_Using_Large_Tool_Libraries/2024-07-31-Tulip_Agent____Enabling_LLM_Based_Agents_to_Solve_Tasks_Using_Large_Tool_Libraries.html",
    "title": "Tulip Agent – Enabling LLM-Based Agents to Solve Tasks Using Large Tool Libraries",
    "section": "",
    "text": "Summary:\nThe Tulip Agent is an architecture for autonomous LLM-based agents that can access a large number of tools in a tool library. Unlike state-of-the-art implementations, the Tulip Agent does not encode the descriptions of all available tools in the system prompt, which counts against the model’s context window, or embed the entire prompt for retrieving suitable tools. Instead, the Tulip Agent can recursively search for suitable tools in its extensible tool library, implemented as a vector store. This architecture significantly reduces inference costs, allows using even large tool libraries, and enables the agent to adapt and extend its set of tools. The architecture is evaluated with several ablation studies in a mathematics context and demonstrated to be generalizable with an application to robotics.\nMajor Findings:\nAnalysis and Critique:\nThe Tulip Agent architecture presents a promising approach for enabling LLM-based agents to access and use large tool libraries. However, there are several potential limitations and areas for further research.\nFirst, the Tulip Agent architecture relies on the ability of the LLM to search for and retrieve suitable tools from the tool library. This may be challenging for LLMs with limited context windows or limited ability to reason about the relationships between tools and tasks.\nSecond, the Tulip Agent architecture assumes that the tool library is well-structured and that the tools are well-documented. In practice, tool libraries may be incomplete, inconsistent, or otherwise imperfect, which could impact the performance of the Tulip Agent.\nThird, the Tulip Agent architecture does not address the problem of tool selection, which is a critical aspect of tool use. In practice, an agent may need to select from a large number of potentially relevant tools, and the Tulip Agent architecture does not provide a mechanism for doing so.\nFinally, the Tulip Agent architecture is evaluated in a limited set of"
  },
  {
    "objectID": "posts/Tulip_Agent____Enabling_LLM_Based_Agents_to_Solve_Tasks_Using_Large_Tool_Libraries/2024-07-31-Tulip_Agent____Enabling_LLM_Based_Agents_to_Solve_Tasks_Using_Large_Tool_Libraries.html#appendix",
    "href": "posts/Tulip_Agent____Enabling_LLM_Based_Agents_to_Solve_Tasks_Using_Large_Tool_Libraries/2024-07-31-Tulip_Agent____Enabling_LLM_Based_Agents_to_Solve_Tasks_Using_Large_Tool_Libraries.html#appendix",
    "title": "Tulip Agent – Enabling LLM-Based Agents to Solve Tasks Using Large Tool Libraries",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-08-06\n\n\nAbstract\nhttps://arxiv.org/abs/2407.21778v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.21778v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17475"
  },
  {
    "objectID": "posts/LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs/2024-06-26-LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs.html#major-findings",
    "href": "posts/LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs/2024-06-26-LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs.html#major-findings",
    "title": "LongIns: A Challenging Long-context Instruction-based Exam for LLMs",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe top-performing GPT-4 with 128k context length performs poorly on the evaluation context window of 16k in LongIns.\nSignificant efforts are still needed for the multi-hop reasoning ability of many existing LLMs under short context windows (&lt;4k).\nMost models fail to achieve high scores when the critical information length is only 8k, and even GPT-4 and GPT-4o score poorly at 16k length."
  },
  {
    "objectID": "posts/LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs/2024-06-26-LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs.html#analysis-and-critique",
    "href": "posts/LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs/2024-06-26-LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs.html#analysis-and-critique",
    "title": "LongIns: A Challenging Long-context Instruction-based Exam for LLMs",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper provides a valuable contribution to the field by introducing a benchmark that focuses on the actual comprehensible window length of LLMs, which is often overlooked in existing benchmarks.\nThe authors evaluate a diverse set of LLMs, providing a comprehensive analysis of their long-context understanding capabilities.\nHowever, the paper does not discuss the potential limitations of the proposed benchmark, such as the generalizability of the findings to other types of tasks or the potential biases in the dataset.\nAdditionally, the paper does not provide a detailed analysis of the methodology used to generate the dataset, which could impact the validity of the results.\nFinally, the paper does not discuss the potential implications of the findings for the development of LLMs or the design of future benchmarks."
  },
  {
    "objectID": "posts/LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs/2024-06-26-LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs.html#appendix",
    "href": "posts/LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs/2024-06-26-LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs.html#appendix",
    "title": "LongIns: A Challenging Long-context Instruction-based Exam for LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17588v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17588v2\n\n\nTruncated\nFalse\n\n\nWord Count\n5491"
  },
  {
    "objectID": "posts/Odyssey_Empowering_Agents_with_Open_World_Skills/2024-07-22-Odyssey_Empowering_Agents_with_Open_World_Skills.html",
    "href": "posts/Odyssey_Empowering_Agents_with_Open_World_Skills/2024-07-22-Odyssey_Empowering_Agents_with_Open_World_Skills.html",
    "title": "Odyssey: Empowering Agents with Open-World Skills",
    "section": "",
    "text": "Summary:\nThe paper introduces ODYSSEY, a new framework that empowers Large Language Model (LLM)-based agents with open-world skills to explore the vast Minecraft world. ODYSSEY comprises three key parts: (1) An interactive agent with an open-world skill library that consists of 40 primitive skills and 183 compositional skills. (2) A fine-tuned LLaMA-3 model trained on a large question-answering dataset with 390k+ instruction entries derived from the Minecraft Wiki. (3) A new open-world benchmark includes thousands of long-term planning tasks, tens of dynamic-immediate planning tasks, and one autonomous exploration task.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a comprehensive framework for developing and evaluating autonomous embodied agents in open-world environments. The use of LLMs in Minecraft has been explored in previous works, but the proposed ODYSSEY framework provides a more stable and efficient method for generating complex policies for broader exploration and more complex tasks. However, the use of open-source LLMs is prone to generating hallucinations, which can decrease agent performance. The authors plan to address this issue by employing retrieval-augmented generation to improve LLMs in Minecraft. Additionally, the skill library is still text-based, which limits its functionality in tasks requiring visual information. The authors plan to integrate visual processing capabilities into the skill library to expand its capabilities.\nThe paper also introduces a new open-world benchmark that encompasses tasks requiring long-term planning, dynamic-"
  },
  {
    "objectID": "posts/Odyssey_Empowering_Agents_with_Open_World_Skills/2024-07-22-Odyssey_Empowering_Agents_with_Open_World_Skills.html#appendix",
    "href": "posts/Odyssey_Empowering_Agents_with_Open_World_Skills/2024-07-22-Odyssey_Empowering_Agents_with_Open_World_Skills.html#appendix",
    "title": "Odyssey: Empowering Agents with Open-World Skills",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.15325v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.15325v1\n\n\nTruncated\nFalse\n\n\nWord Count\n24246"
  },
  {
    "objectID": "posts/Towards_Open_World_Grasping_with_Large_Vision_Language_Models/2024-06-26-Towards_Open_World_Grasping_with_Large_Vision_Language_Models.html#major-findings",
    "href": "posts/Towards_Open_World_Grasping_with_Large_Vision_Language_Models/2024-06-26-Towards_Open_World_Grasping_with_Large_Vision_Language_Models.html#major-findings",
    "title": "Towards Open-World Grasping with Large Vision-Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nClarity of Visual Markers: The authors find that the most common failure mode of visual marker prompting with GPT-4v is that it sometimes struggles to discriminate which ID corresponds to what segment, especially in cluttered scenes. Techniques such as overlaying numeric IDs with minimal overlap, coloring both the internal of each segment’s mask and its ID with the same unique color, and increasing the resolution of the marked image and the size layout of the markers can assist in making the markers more clear to the VLM.\nReference Image and Chain-of-Thoughts: The authors propose techniques to ameliorate the issue of GPT-4v sometimes referring to regions with wrong IDs, especially in highly cluttered scenes. They suggest passing both the original (reference) and the marked image and constructing a text prompt that explains that the latter corresponds to annotated segments of the first. They also find that VLMs share similar properties with LLMs and prompting them to reason about their final answer before producing it can robustify the response quality.\nSelf-consistency and In-context Examples: The authors observe that the outputs of GPT-4v are not always reproducible, even with exactly the same prompt. They propose using the self-consistency method developed for LLMs to reduce the effect of this phenomenon and robustify VLM outputs. They also find that in-context examples can improve the robustness of the grasp planning and contact reasoning stages."
  },
  {
    "objectID": "posts/Towards_Open_World_Grasping_with_Large_Vision_Language_Models/2024-06-26-Towards_Open_World_Grasping_with_Large_Vision_Language_Models.html#analysis-and-critique",
    "href": "posts/Towards_Open_World_Grasping_with_Large_Vision_Language_Models/2024-06-26-Towards_Open_World_Grasping_with_Large_Vision_Language_Models.html#analysis-and-critique",
    "title": "Towards Open-World Grasping with Large Vision-Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe article provides a comprehensive exploration of various techniques to improve the performance of VLMs in open-world grasping tasks. However, the study is limited to the GPT-4v model, and the results may not generalize to other VLMs. The authors also acknowledge that the actual model specifics of GPT-4v are unknown, which makes it difficult to fully understand the reasons behind its performance. Furthermore, the study does not provide"
  },
  {
    "objectID": "posts/Towards_Open_World_Grasping_with_Large_Vision_Language_Models/2024-06-26-Towards_Open_World_Grasping_with_Large_Vision_Language_Models.html#appendix",
    "href": "posts/Towards_Open_World_Grasping_with_Large_Vision_Language_Models/2024-06-26-Towards_Open_World_Grasping_with_Large_Vision_Language_Models.html#appendix",
    "title": "Towards Open-World Grasping with Large Vision-Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18722v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18722v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3751"
  },
  {
    "objectID": "posts/Ragnarök_A_Reusable_RAG_Framework_and_Baselines_for_TREC_2024_Retrieval_Augmented_Generation_Track/2024-06-24-Ragnarök_A_Reusable_RAG_Framework_and_Baselines_for_TREC_2024_Retrieval_Augmented_Generation_Track.html#appendix",
    "href": "posts/Ragnarök_A_Reusable_RAG_Framework_and_Baselines_for_TREC_2024_Retrieval_Augmented_Generation_Track/2024-06-24-Ragnarök_A_Reusable_RAG_Framework_and_Baselines_for_TREC_2024_Retrieval_Augmented_Generation_Track.html#appendix",
    "title": "Ragnarök: A Reusable RAG Framework and Baselines for TREC 2024 Retrieval-Augmented Generation Track",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16828v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16828v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6500"
  },
  {
    "objectID": "posts/LLMs_Understanding_of_Natural_Language_Revealed/2024-07-29-LLMs_Understanding_of_Natural_Language_Revealed.html#appendix",
    "href": "posts/LLMs_Understanding_of_Natural_Language_Revealed/2024-07-29-LLMs_Understanding_of_Natural_Language_Revealed.html#appendix",
    "title": "LLMs’ Understanding of Natural Language Revealed",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19630v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19630v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10131"
  },
  {
    "objectID": "posts/Vox_Populi_Vox_AI_Using_Language_Models_to_Estimate_German_Public_Opinion/2024-07-11-Vox_Populi_Vox_AI_Using_Language_Models_to_Estimate_German_Public_Opinion.html",
    "href": "posts/Vox_Populi_Vox_AI_Using_Language_Models_to_Estimate_German_Public_Opinion/2024-07-11-Vox_Populi_Vox_AI_Using_Language_Models_to_Estimate_German_Public_Opinion.html",
    "title": "Vox Populi, Vox AI? Using Language Models to Estimate German Public Opinion",
    "section": "",
    "text": "Summary:\nThis academic paper explores the use of large language models (LLMs), specifically GPT-3.5, to estimate public opinion and predict voting behavior in Germany. The study compares the LLM’s predicted vote choices with the actual vote choices reported by respondents in the German Longitudinal Election Study (GLES). The findings reveal that GPT-3.5 overestimated the vote shares for the Greens, the Left, and non-voters, while underestimating the vote shares for FDP and AfD when compared to GLES. The LLM’s overall predictive accuracy was modest, with a matching prediction rate of 0.46. GPT-3.5’s predictions were more accurate for voters of the Greens, CDU/CSU, and the Left, but displayed poor predictive power for FDP and AfD voters. The study also highlights the limitations of using LL"
  },
  {
    "objectID": "posts/Vox_Populi_Vox_AI_Using_Language_Models_to_Estimate_German_Public_Opinion/2024-07-11-Vox_Populi_Vox_AI_Using_Language_Models_to_Estimate_German_Public_Opinion.html#appendix",
    "href": "posts/Vox_Populi_Vox_AI_Using_Language_Models_to_Estimate_German_Public_Opinion/2024-07-11-Vox_Populi_Vox_AI_Using_Language_Models_to_Estimate_German_Public_Opinion.html#appendix",
    "title": "Vox Populi, Vox AI? Using Language Models to Estimate German Public Opinion",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08563v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08563v1\n\n\nTruncated\nTrue\n\n\nWord Count\n29238"
  }
]