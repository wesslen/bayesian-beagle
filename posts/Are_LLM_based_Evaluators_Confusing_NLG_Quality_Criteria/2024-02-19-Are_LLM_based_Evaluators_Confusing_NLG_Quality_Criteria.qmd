
---
title: "Are LLM-based Evaluators Confusing NLG Quality Criteria?"
id: "2402.12055v1"
description: "LLMs perform well in NLG but confuse evaluation criteria, requiring further research and improvements."
author: Xinyu Hu, Mingqi Gao, Sen Hu, Yang Zhang, Yicheng Chen, Teng Xu, Xiaojun Wan
date: "2024-02-19"
image: "../../img/2402.12055v1/image_1.png"
categories: ['robustness', 'architectures', 'security']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.12055v1/image_1.png)

### Summary:
- The article discusses the challenges and limitations of Large Language Models (LLMs) in evaluating natural language generation (NLG) tasks. It proposes a hierarchical classification system for NLG quality criteria and conducts perturbation attacks to analyze LLMs' evaluation behaviors. The findings reveal confusion issues inherent in LLMs, necessitating further research and improvements for LLM-based evaluation.

### Major Findings:
1. LLMs exhibit confusion issues in evaluating different aspects of NLG tasks.
2. Detailed descriptions of criteria lead to more accurate evaluations by LLMs.
3. Perturbation attacks highlight the impact of different perturbations on the quality of text generated by LLMs.

### Analysis and Critique:
- The article provides valuable insights into the challenges and limitations of LLM-based evaluation for NLG tasks.
- The proposed classification system and perturbation attacks offer a structured approach to understanding and addressing the confusion issues inherent in LLMs.
- The findings emphasize the need for further research and improvements in LLM-based evaluation to enhance reliability and accuracy.
- The article's content sheds light on the shortcomings of LLM-based evaluation and the complexities involved in improving the evaluation capabilities of LLMs.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-26       |
| Abstract | [https://arxiv.org/abs/2402.12055v1](https://arxiv.org/abs/2402.12055v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.12055v1](https://browse.arxiv.org/html/2402.12055v1)       |
| Truncated       | True       |
| Word Count       | 66566       |