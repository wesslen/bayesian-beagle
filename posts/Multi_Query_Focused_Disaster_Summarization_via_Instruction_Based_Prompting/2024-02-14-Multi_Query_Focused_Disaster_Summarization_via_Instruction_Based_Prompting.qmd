
---
title: "Multi-Query Focused Disaster Summarization via Instruction-Based Prompting"
id: "2402.09008v1"
description: "CrisisFACTS advances disaster summarization using web sources, retrieval, and QA-motivated prompting. Strong results shown."
author: Philipp Seeberger, Korbinian Riedhammer
date: "2024-02-14"
image: "../../img/2402.09008v1/image_1.png"
categories: ['prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.09008v1/image_1.png)

### **Summary:**
- The paper describes a method for automatic summarization of mass-emergency events using multi-stream fact-finding with a focus on web sources such as Twitter, Reddit, Facebook, and Webnews.
- The proposed method uses a combination of retrieval, reranking, and an embarrassingly simple instruction-following summarization.
- The system relies on BM25 and MonoT5 for retrieval and the open-source Large Language Model (LLM) LLaMA-13b for summarization.

### Major Findings:
1. The proposed LLM-based event nugget generation approach achieves competitive performance and surpasses the majority of systems in the CrisisFACTS 2023 Track.
2. The system outperforms both the majority of TREC participantsâ€™ systems as well as extractive baselines in terms of comprehensiveness and redundancy measures.
3. The experiments show that rather simple prompting approaches surpass extractive baselines and the majority of submitted CrisisFACTS systems.

### Analysis and Critique:
- The qualitative analysis reveals shortcomings and limitations of the proposed approach, including incorrect facts, incomplete citations, and formatting issues in the generated responses.
- The BERTScore metric used for automatic evaluation may lead to flawed results due to token limits and the format of event summaries.
- The paper acknowledges the need for further development efforts to address surface form issues and improve the robustness of the system.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-15       |
| Abstract | [https://arxiv.org/abs/2402.09008v1](https://arxiv.org/abs/2402.09008v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.09008v1](https://browse.arxiv.org/html/2402.09008v1)       |
| Truncated       | False       |
| Word Count       | 6665       |