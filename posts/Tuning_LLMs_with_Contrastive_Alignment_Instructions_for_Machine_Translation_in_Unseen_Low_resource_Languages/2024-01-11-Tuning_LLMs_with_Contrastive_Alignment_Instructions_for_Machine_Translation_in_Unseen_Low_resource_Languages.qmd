
---
title: "Tuning LLMs with Contrastive Alignment Instructions for Machine Translation in Unseen, Low-resource Languages"
id: "2401.05811v1"
description: "New method, AlignInstruct, improves large language model (LLM) translation for unseen languages and low-resource languages using cross-lingual supervision."
author: ['Zhuoyuan Mao', 'Yen Yu']
date: "2024-01-11"
image: "https://browse.arxiv.org/html/2401.05811v1/x1.png"
categories: ['production', 'architectures', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.05811v1/x1.png)

### Summary of "Tuning LLMs with Contrastive Alignment Instructions for Machine Translation in Unseen, Low-resource Languages"

#### Major Findings
- LLMs fine-tuned using contrastive alignment instructions (AlignInstruct) led to consistent improvements in translation quality across various translation directions involving English.
- Discriminator-based instructions outperformed generative counterparts for cross-lingual instructions on previously unseen languages, showcasing the effectiveness of AlignInstruct.
- AlignInstruct improved translation performance in 30 zero-shot directions not involving English.
  
### Introduction
- Despite the success of LLMs in NLP tasks for prevalent languages, low-resource languages remain a significant challenge due to limited pre-training data.
- Previous studies explored extending language support using continual pre-training or parameter efficient fine-tuning (PEFT) methods on monolingual tasks, but extending language support for cross-lingual tasks remains underexplored.

### Methodology
- Baseline: MTInstruct involved fine-tuning LLMs using MT instructions, while AlignInstruct formulated a cross-lingual discriminator using statistical word alignments to provide cross-lingual supervision.
- AlignInstruct was compared with two generative variants: HintInstruct and ReviseInstruct.
- Statistical word alignments extracted from parallel corpora were utilized in the AlignInstruct method.

### Experimental Settings
- Experiments fine-tuned BLOOMZ models in up to 24 unseen languages, showing that MTInstruct effectively induced translation capabilities and AlignInstruct led to consistent improvements in translation quality.
- Zero-shot translation evaluations demonstrated AlignInstruct's improvements in translation quality, especially when exclusively fine-tuned with three unseen languages.

### Evaluation and Analysis
- Various experimental configurations and curricula were explored: multi-task fine-tuning, pre-fine-tuning & fine-tuning, and mixed fine-tuning, showing the efficacy of AlignInstruct in enhancing translation quality.
- AlignInstruct consistently outperformed generative counterparts across metrics and model sizes.
- Improved translation quality was observed for zero-shot directions not involving English.

### Conclusion
- AlignInstruct's strength over the MTInstruct baseline and other instruction variants was demonstrated in multilingual and zero-shot findings.
  
### Critique
- The paper does not compare translations in low-resource languages with best-performing multilingual NMT models, which could provide a benchmark for the proposed techniques.
- The study focused primarily on enhancing the MTInstruct baseline through improved cross-lingual alignment within LLMs rather than delving into the best combination of techniques for MT fine-tuning in LLMs.

Overall, the study effectively demonstrates the efficacy of AlignInstruct for improving translation quality in unseen, low-resource languages, while raising opportunities for future exploration. However, it could benefit from additional comparisons with state-of-the-art multilingual NMT models and exploration of varied templates for MT instructions.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-29       |
| Abstract | [http://arxiv.org/abs/2401.05811v1](http://arxiv.org/abs/2401.05811v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.05811v1](https://browse.arxiv.org/html/2401.05811v1)       |
| Truncated       | False       |
| Word Count       | 9056       |