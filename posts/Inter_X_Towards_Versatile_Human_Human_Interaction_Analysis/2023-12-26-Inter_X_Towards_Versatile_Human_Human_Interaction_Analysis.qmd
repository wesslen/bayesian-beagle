
---
title: "Inter-X: Towards Versatile Human-Human Interaction Analysis"
id: "2312.16051v1"
description: "Largest human-human interaction dataset with accurate body movements, hand gestures, and textual descriptions for research."
author: ['Liang Xu', 'Xintao Lv', 'Yichao Yan', 'Xin Jin', 'Shuwen Wu', 'Congsheng Xu', 'Yifan Liu', 'Yizhou Zhou', 'Fengyun Rao', 'Xingdong Sheng', 'Yunhui Liu', 'Wenjun Zeng', 'Xiaokang Yang']
date: "2023-12-26"
image: "https://browse.arxiv.org/html/2312.16051v1/x2.png"
categories: ['hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2312.16051v1/x2.png)

# Inter-X: Towards Versatile Human-Human Interaction Analysis

## Major Takeaways
- **Inter-X Dataset**: Proposes the Inter-X dataset, a comprehensive human-human interaction dataset with accurate body movements, diverse interaction patterns, and detailed hand gestures.
- **Unified Benchmark**: Introduces a unified benchmark for 4 categories of downstream tasks in the perceptual and generative directions.
- **Extensive Experiments**: Conducts extensive experiments and analysis, showing that Inter-X poses challenges for human-human interaction-related tasks.

## Abstract
The paper introduces the Inter-X dataset, a large-scale human-human interaction dataset with accurate body movements, diverse interaction patterns, and detailed hand gestures. It also proposes a unified benchmark for 4 categories of downstream tasks from both perceptual and generative directions.

## Introduction
- Understanding human-human interactions is crucial for intelligent digital human systems with applications in surveillance, AR/VR, games, and robotics.
- Existing datasets lack accurate body motions, hand gestures, and fine-grained textual descriptions, hindering progress in human-human interaction analysis.

## Related Work
- Discusses existing human motion and human-human interaction datasets and their functionalities.

## The Inter-X Dataset
### Data Capturing System
- Utilizes an optical MoCap system for accurate body movements and inertial gloves for capturing finger gestures without occlusions.
- Captures 40 daily interaction categories, involving 11K motion sequences and 8.1M frames.

### Data Postprocessing
- Involves aligning body poses from the MoCap system with finger gestures and segmenting interaction snippets.

## Dataset Taxonomy
- Enriches the dataset with high-precision human-human interaction sequences and multifaceted annotations, including textual descriptions, action categories, interaction order, and relationship/personality information.

## Task Taxonomy
- Outlines 4 categories of downstream tasks enabled by the dataset: Texts related Tasks, Actions related Tasks, Interaction-order related Tasks, and Relationship & Personality related Tasks.

## Experiments
- Reports experiments and evaluations for text-conditioned interaction generation, action-conditioned interaction generation, human reaction generation, and human interaction recognition.

## Conclusion and Limitation
- Highlights the contributions of the Inter-X dataset and acknowledges limitations in facial expressions and the duration of interactions.

## Appendix
- Includes additional experiments, SMPL-X optimization details, the action categories, samples of textual annotations, and visualization results.

# Critique
The paper provides a comprehensive overview and detailed insights into the creation and applications of the Inter-X dataset. However, it would benefit from more visual representations of the dataset and further comparisons with existing datasets to highlight the unique advantages of Inter-X. Additionally, while the experiments and evaluations are extensive, more discussion on the limitations and challenges faced during the dataset creation and experiments would add depth to the paper. Finally, a more in-depth discussion on potential future uses and applications of the dataset would enhance the paper's impact.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-29       |
| Abstract | [http://arxiv.org/abs/2312.16051v1](http://arxiv.org/abs/2312.16051v1)        |
| HTML     | [https://browse.arxiv.org/html/2312.16051v1](https://browse.arxiv.org/html/2312.16051v1)       |
| Truncated       | False       |
| Word Count       | 11982       |