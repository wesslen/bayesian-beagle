
---
title: "Can GPT-4 Identify Propaganda? Annotation and Detection of Propaganda Spans in News Articles"
id: "2402.17478v1"
description: "Increased propaganda on media, limited detection in non-English content, GPT-4 struggles with fine-grained detection."
author: Maram Hasanain, Fatema Ahmed, Firoj Alam
date: "2024-02-27"
image: "https://browse.arxiv.org/html/2402.17478v1/extracted/5434613/figures/prop_example.png"
categories: ['production', 'robustness', 'architectures']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.17478v1/extracted/5434613/figures/prop_example.png)

### **Summary:**
- The article discusses the use of propaganda in mainstream and social media to manipulate or mislead users.
- Efforts to automatically detect propaganda techniques in textual, visual, or multimodal content have primarily focused on English content.
- The article introduces the ArPro dataset, the largest propaganda dataset to date, comprised of paragraphs from newspaper articles labeled at the text span level following a taxonomy of 23 propagandistic techniques.
- The study evaluates the performance of large language models (LLMs), using GPT-4, for fine-grained propaganda detection from text and compares it to fine-tuned models.

### Major Findings:
1. The ArPro dataset is the largest to date for fine-grained propaganda detection, with annotations at the text span level following a taxonomy of 23 propagandistic techniques.
2. GPT-4's performance degrades as the task moves from simply classifying a paragraph as propagandistic or not, to the fine-grained task of detecting propaganda techniques and their manifestation in text.
3. Fine-tuned models consistently outperform GPT-4 in a zero-shot setting, and GPT-4 struggles with the task across multiple languages.

### Analysis and Critique:
- The article provides valuable insights into the challenges of detecting propaganda techniques in different languages and the limitations of large language models like GPT-4.
- The study raises awareness about the subjectivity, contextual variations, linguistic and cultural nuances, and cognitive biases involved in annotating text with propagandistic techniques.
- The article acknowledges the potential biases introduced by subjective annotations and urges researchers and users of the dataset to remain careful of its limitations when developing models or conducting further research.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.17478v1](https://arxiv.org/abs/2402.17478v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.17478v1](https://browse.arxiv.org/html/2402.17478v1)       |
| Truncated       | False       |
| Word Count       | 7017       |