
---
title: "Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?"
id: "2402.18272v1"
description: "Multi-agent discussion improves LLM reasoning, but single-agent with strong prompts performs similarly."
author: Qineng Wang, Zihao Wang, Ying Su, Hanghang Tong, Yangqiu Song
date: "2024-02-28"
image: "https://browse.arxiv.org/html/2402.18272v1/extracted/5436554/assets/pic/fig1.png"
categories: ['education', 'hci', 'prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.18272v1/extracted/5436554/assets/pic/fig1.png)

### **Summary:**
Recent progress in LLMs discussion suggests that multi-agent discussion improves the reasoning abilities of LLMs. In this work, a novel group discussion framework is proposed to enrich the set of discussion mechanisms. The results show that a single-agent LLM with strong prompts can achieve almost the same performance as the best existing discussion approach on a wide range of reasoning tasks and backbone LLMs. Multi-agent discussion performs better than a single agent only when there is no demonstration in the prompt. Further study reveals the common interaction mechanisms of LLMs during the discussion.

### Major Findings:
1. A single-agent LLM with strong prompts can achieve almost the same performance as the best existing discussion approach on a wide range of reasoning tasks and backbone LLMs.
2. Multi-agent discussion performs better than a single agent only when there is no demonstration in the prompt.
3. Common interaction mechanisms of LLMs during the discussion were revealed.

### Analysis and Critique:
- The study provides valuable insights into the effectiveness of multi-agent discussions for reasoning tasks.
- The findings suggest that prompt engineering can significantly boost reasoning performance in large language models.
- The study highlights the potential for multi-agent discussions to enhance reasoning abilities in scenarios where expert knowledge or detailed examples are insufficient.
- The research also identifies two common types of errors in multi-agent discussions: Judge Mistake and Wrong Answer Propagation.
- The study provides a comprehensive and fair assessment of the performance of a strong single agent and multi-agent discussions, offering valuable insights for future research.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.18272v1](https://arxiv.org/abs/2402.18272v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.18272v1](https://browse.arxiv.org/html/2402.18272v1)       |
| Truncated       | False       |
| Word Count       | 9233       |