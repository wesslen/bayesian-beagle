
---
title: "CLR-Fact: Evaluating the Complex Logical Reasoning Capability of Large Language Models over Factual Knowledge"
id: "2407.20564v1"
description: "LLMs excel in general knowledge reasoning but struggle with domain-specific knowledge. Chain-of-Thought demonstrations improve performance, but set intersections pose challenges."
author: Tianshi Zheng, Jiaxin Bai, Yicheng Wang, Tianqing Fang, Yue Guo, Yauwai Yim, Yangqiu Song
date: "2024-07-30"
image: "https://browse.arxiv.org/html/2407.20564v1/x1.png"
categories: ['education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2407.20564v1/x1.png)

### Summary:

The paper presents a systematic evaluation of state-of-the-art large language models (LLMs) for their complex logical reasoning abilities over factual knowledge. The evaluation is conducted using a novel benchmark of automatically generated complex reasoning questions over general domain and biomedical knowledge graphs. The experiments reveal that LLMs excel at reasoning over general world knowledge but face significant challenges with specialized domain-specific knowledge. The use of explicit Chain-of-Thought demonstrations can substantially improve LLM performance on complex logical reasoning tasks with diverse logical operations. However, controlled evaluations uncover an asymmetry where LLMs display proficiency at set union operations, but struggle considerably with set intersections - a key building block of logical reasoning.

### Major Findings:

1. LLMs excel at reasoning over general knowledge but struggle with domain-specific knowledge like biomedical facts.
2. LLMs perform poorly on questions involving negations or set complementation, highlighting a significant limitation in their ability to comprehend and reason with negative statements and set exclusion operations.
3. LLMs exhibited proficiency at set union operations, but faced major difficulties with set intersections, suggesting an asymmetric grasp of set combinations versus identifying common elements across sets.
4. The Chain-of-Thought prompting technique is effective for enhancing LM performance on complex questions requiring multi-step logical reasoning.
5. Selecting demonstration examples based on semantic similarity to the query, such that the examples structurally align with the target reasoning pattern, provided an intuitive and effective method for improving LM performance through in-context learning.

### Analysis and Critique:

The paper provides a comprehensive evaluation of LLMs for complex logical reasoning over factual knowledge. However, there are a few limitations and areas for further research. The evaluation is limited to a specific set of complex reasoning questions and may not generalize to other types of reasoning tasks. Additionally, the evaluation focuses on the performance of LLMs and does not consider other factors such as computational efficiency or interpretability. Further research is needed to explore the performance of LLMs on a wider range of reasoning tasks and to develop more efficient and interpretable models for complex logical reasoning.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-06       |
| Abstract | [https://arxiv.org/abs/2407.20564v1](https://arxiv.org/abs/2407.20564v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.20564v1](https://browse.arxiv.org/html/2407.20564v1)       |
| Truncated       | False       |
| Word Count       | 6369       |