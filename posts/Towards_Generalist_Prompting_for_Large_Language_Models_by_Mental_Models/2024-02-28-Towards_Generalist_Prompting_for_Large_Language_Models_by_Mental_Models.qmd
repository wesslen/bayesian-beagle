
---
title: "Towards Generalist Prompting for Large Language Models by Mental Models"
id: "2402.18252v1"
description: "Large language models need specially designed prompting methods for optimal performance. MeMo achieves this."
author: Haoxiang Guan, Jiyan He, Shuxin Zheng, En-Hong Chen, Weiming Zhang, Nenghai Yu
date: "2024-02-28"
image: "https://browse.arxiv.org/html/2402.18252v1/x1.png"
categories: ['hci', 'prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.18252v1/x1.png)

### **Summary:**
- Large language models (LLMs) have shown impressive performance on various tasks, but still require specially designed prompting methods for optimal performance.
- The article introduces the concept of generalist prompting, aiming to achieve optimal or near-optimal performance on a wide range of tasks without manual selection and customization of prompts.
- MeMo (Mental Models) is proposed as a simple-designed prompting method that effectively fulfills the criteria of generalist prompting, achieving state-of-the-art results on diverse tasks in zero-shot settings.

### **Major Findings:**
1. The evolution of artificial intelligence (AI) models towards generalist capabilities has followed a distinct trajectory, with LLMs capable of handling a wide range of natural language processing tasks.
2. MeMo, as a generalist prompting method, achieves or is near to the state-of-the-art performance on diverse tasks with LLMs in zero-shot settings, eliminating manual selection and customization of prompts.
3. MeMo leverages the concept of mental models to enable LLMs to autonomously select and apply suitable mental models for problem-solving, surpassing existing prompting methods that require task-specific customization.

### **Analysis and Critique:**
- MeMo suffers from high computational costs due to the long prompt that informs LLMs with the knowledge of mental models.
- The approach relies on the availability and quality of exemplars, which can affect the selection and application of mental models.
- The article does not guarantee the correctness or consistency of the mental models that LLMs employ, which can lead to errors or contradictions in some cases.
- Future work could investigate how to verify and refine the mental models that LLMs generate, as well as how to enable LLMs to understand and apply mental models more accurately.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-29       |
| Abstract | [https://arxiv.org/abs/2402.18252v1](https://arxiv.org/abs/2402.18252v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.18252v1](https://browse.arxiv.org/html/2402.18252v1)       |
| Truncated       | False       |
| Word Count       | 6820       |