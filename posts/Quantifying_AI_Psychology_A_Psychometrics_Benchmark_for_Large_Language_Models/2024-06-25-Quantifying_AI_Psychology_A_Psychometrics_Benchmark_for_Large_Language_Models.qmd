
---
title: "Quantifying AI Psychology: A Psychometrics Benchmark for Large Language Models"
id: "2406.17675v1"
description: "LLMs exhibit psychological attributes, but self-reported traits may differ from real-world behaviors, according to a new psychometric benchmark."
author: Yuan Li, Yue Huang, Hongyi Wang, Xiangliang Zhang, James Zou, Lichao Sun
date: "2024-06-25"
image: "https://browse.arxiv.org/html/2406.17675v1/x1.png"
categories: ['hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.17675v1/x1.png)

### Summary:

This paper presents a comprehensive psychometrics benchmark for Large Language Models (LLMs) to assess their psychological attributes. The benchmark covers six psychological dimensions: personality, values, emotion, theory of mind, motivation, and intelligence. The study aims to deepen the understanding of LLMs' behaviors and predict their actions, inspired by how psychology facilitates understanding human behaviors. The benchmark includes a framework for psychological dimension identification, assessment dataset curation, and assessment with results validation. The findings reveal that LLMs manifest a broad spectrum of psychological attributes, with discrepancies between LLMs' self-reported traits and their behaviors in real-world scenarios. The study also uncovers concerns about the reliability of the test and the applicability of psychometric tests designed for humans to LLMs.

### Major Findings:

1. LLMs show consistent behavior in tasks that require reasoning, such as theory of mind or emotional intelligence tasks. However, responses to preference-based questions, which do not have definitive answers, display significant variability across different models. Utilizing specific prompts (e.g., role-playing prompts) can improve response consistency toward designated attributes.
2. LLMs may exhibit discrepancies between their self-reported traits and their behaviors in open-ended responses. For instance, a model might score low on extraversion in closed-form assessments yet demonstrate extraverted traits in open-ended responses. This discrepancy is also observed in human responses, where individuals may provide socially desirable answers on rating scales, whereas open-ended questions allow for more nuanced expressions that better reflect complex thoughts.
3. LLMs are sensitive to prompt perturbations that humans might find trivial. This sensitivity can impact LLM performance and stability of their psychological attributes. Concerns remain about the reliability of the test, including the applicability of psychometric tests designed for humans to LLMs and the potential for measurement errors.

### Analysis and Critique:

The study provides a thorough psychometric assessment of LLMs, offering insights into reliable evaluation and potential applications in AI and social sciences. However, there are limitations and potential biases that should be considered. The study acknowledges the fundamental differences between humans and LLMs, such as the question of whether LLMs possess agency and the sensitivity of LLMs to prompt perturbations. Additionally, the study highlights

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-07       |
| Abstract | [https://arxiv.org/abs/2406.17675v1](https://arxiv.org/abs/2406.17675v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.17675v1](https://browse.arxiv.org/html/2406.17675v1)       |
| Truncated       | False       |
| Word Count       | 22287       |