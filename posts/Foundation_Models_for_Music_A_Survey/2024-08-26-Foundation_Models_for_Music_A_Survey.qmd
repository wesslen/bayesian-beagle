
---
title: "Foundation Models for Music: A Survey"
id: "2408.14340v1"
description: "TL;DR: This review explores foundation models in music, discussing representation, generation, ethics, and future trends."
author: Yinghao Ma, Anders Øland, Anton Ragni, Bleiz MacSen Del Sette, Charalampos Saitis, Chris Donahue, Chenghua Lin, Christos Plachouras, Emmanouil Benetos, Elio Quinton, Elona Shatri, Fabio Morreale, Ge Zhang, György Fazekas, Gus Xia, Huan Zhang, Ilaria Manco, Jiawen Huang, Julien Guinot, Liwei Lin, Luca Marinelli, Max W. Y. Lam, Megha Sharma, Qiuqiang Kong, Roger B. Dannenberg, Ruibin Yuan, Shangda Wu, Shih-Lun Wu, Shuqi Dai, Shun Lei, Shiyin Kang, Simon Dixon, Wenhu Chen, Wehhao Huang, Xingjian Du, Xingwei Qu, Xu Tan, Yizhi Li, Zeyue Tian, Zhiyong Wu, Zhizheng Wu, Ziyang Ma, Ziyu Wang
date: "2024-08-26"
image: "https://browse.arxiv.org/html/2408.14340v1/extracted/5814373/fig/1.png"
categories: ['production', 'architectures']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.14340v1/extracted/5814373/fig/1.png)

**Summary:**

The paper discusses the significance of foundation models (FMs) in music, which have the potential to address data scarcity, reduce annotation costs, and enhance generalisation in music information retrieval and creation. FMs can provide a better understanding of unseen structures, genres, or instruments, and contribute to the protection of the cultural heritage of music. The paper focuses on two types of self-supervisedly pre-trained foundation models: single-modality pre-trained models in the waveform or symbolic domain, and multimodal pre-trained models that can take both natural language and music as input.

**Major Findings:**

1. Foundation models (FMs) can address data scarcity, reduce annotation costs, and enhance generalisation in music information retrieval and creation.
2. FMs can provide a better understanding of unseen structures, genres, or instruments, and contribute to the protection

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-27       |
| Abstract | [https://arxiv.org/abs/2408.14340v1](https://arxiv.org/abs/2408.14340v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.14340v1](https://browse.arxiv.org/html/2408.14340v1)       |
| Truncated       | True       |
| Word Count       | 74043       |