
---
title: "Biomedical Large Languages Models Seem not to be Superior to Generalist Models on Unseen Medical Data"
id: "2408.13833v1"
description: "Biomedical LLMs underperform general-purpose ones on clinical tasks, challenging assumptions about domain-specific adaptation."
author: Felix J. Dorfner, Amin Dada, Felix Busch, Marcus R. Makowski, Tianyu Han, Daniel Truhn, Jens Kleesiek, Madhumita Sushil, Jacqueline Lammert, Lisa C. Adams, Keno K. Bressem
date: "2024-08-25"
image: "https://browse.arxiv.org/html/2408.13833v1/x1.png"
categories: ['social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.13833v1/x1.png)

# Summary

**Summary:**

- The study evaluates the performance of biomedically fine-tuned large language models (LLMs) against their general-purpose counterparts on clinical tasks.
- The evaluation is based on clinical case challenges from the New England Journal of Medicine (NEJM) and the Journal of the American Medical Association (JAMA), as well as several clinical tasks such as information extraction, document summarization, and clinical coding.
- The benchmarks used are specifically chosen to be likely outside the fine-tuning datasets of biomedical models, ensuring a fair assessment.
- The study hypothesizes that the biomedical models outperform their general-purpose counterparts due to their domain-specific nature.

**Major Findings:**

1. Biomedical LLMs mostly perform inferior to their general-purpose counterparts, especially on tasks not focused on medical knowledge.
2. Larger models show similar performance on case tasks, while smaller biomedical models show more pronounced underperformance.
3. Similar trends are observed across the CLUE (Clinical Language Understanding Evaluation) benchmark tasks, with general-purpose models often performing better on text generation, question answering, and coding tasks.

**Analysis and Critique:**

- The study challenges prevailing assumptions about domain-specific adaptation of LLMs and highlights the need for more rigorous evaluation frameworks in healthcare AI.
- The study suggests that fine-tuning LLMs to biomedical data may not provide the expected benefits and may potentially lead to reduced performance.
- The study raises questions about the added value of fine-tuning, as limited availability of domain-specific data may struggle to introduce novel information not already present in the training data of large AI companies.
- The study suggests that alternative approaches, such as retrieval-augmented generation, may be more effective in enhancing the biomedical capabilities of LLMs without compromising their general knowledge.

**Limitations:**

- The study's evaluation is based on a limited number of benchmarks, which may not fully represent the complexity and diversity of real-world clinical scenarios.
- The study does not cover detailed medical knowledge such as nuanced diagnostic criteria, extensive patient history considerations, and comprehensive treatment recommendations.
- The study's findings may not be

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-27       |
| Abstract | [https://arxiv.org/abs/2408.13833v1](https://arxiv.org/abs/2408.13833v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.13833v1](https://browse.arxiv.org/html/2408.13833v1)       |
| Truncated       | False       |
| Word Count       | 5104       |