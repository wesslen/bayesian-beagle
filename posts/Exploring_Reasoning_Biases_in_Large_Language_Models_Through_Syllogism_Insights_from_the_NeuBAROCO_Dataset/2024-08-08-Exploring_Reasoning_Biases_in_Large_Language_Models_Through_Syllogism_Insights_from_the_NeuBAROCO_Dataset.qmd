
---
title: "Exploring Reasoning Biases in Large Language Models Through Syllogism: Insights from the NeuBAROCO Dataset"
id: "2408.04403v1"
description: "TL;DR: LLMs show human-like reasoning biases in syllogistic problems, with room for improvement in non-entailment/contradiction cases."
author: Kentaro Ozeki, Risako Ando, Takanobu Morishita, Hirohiko Abe, Koji Mineshima, Mitsuhiro Okada
date: "2024-08-08"
image: "../../../bayesian-beagle.png"
categories: ['social-sciences', 'education', 'prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

**Summary:**

This paper explores the logical reasoning abilities of large language models (LLMs) in natural language, focusing on syllogistic reasoning. The authors present a syllogism dataset called NeuBAROCO, which consists of syllogistic reasoning problems in English and Japanese. The dataset was originally designed for psychological experiments to assess human reasoning capabilities. The study's experiments with leading LLMs indicate that these models exhibit reasoning biases similar to humans, along with other error tendencies. The primary limitations of LLMs lie in the reasoning process itself rather than the interpretation of syllogisms.

**Major Findings:**

1. LLMs exhibit reasoning biases similar to humans, along with other error tendencies.
2. There is significant room for improvement in reasoning problems where the relationship between premises and hypotheses is neither entailment nor contradiction.
3. The primary limitations of LLMs lie in the reasoning process itself rather than the interpretation of syllogisms.

**Analysis and Critique:**

1. The study's focus on syllogistic reasoning is a deliberate choice to facilitate comparisons with insights from extensive research on biases and reasoning in cognitive science. However, this focus may limit the generalizability of the findings to other forms of reasoning.
2. The use of a bilingual dataset (Japanese and English) is a strength of the study, as it allows for the evaluation of LLMs in different languages. However, the study does not discuss potential differences in reasoning biases between languages.
3. The study's reliance on a single dataset (NeuBAROCO) may limit the generalizability of the findings. Future research should consider using multiple datasets to validate the findings.
4. The study does not discuss the potential impact of the size and architecture of LLMs on their reasoning abilities. Future research should consider these factors to provide a more comprehensive understanding of LLMs' reasoning abilities.
5. The study's focus on LLMs' reasoning abilities in natural language may not fully capture their reasoning abilities in other domains, such as mathematics or logic. Future research should consider evaluating LLMs' reasoning abilities in these domains.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-13       |
| Abstract | [https://arxiv.org/abs/2408.04403v1](https://arxiv.org/abs/2408.04403v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.04403v1](https://browse.arxiv.org/html/2408.04403v1)       |
| Truncated       | False       |
| Word Count       | 7155       |