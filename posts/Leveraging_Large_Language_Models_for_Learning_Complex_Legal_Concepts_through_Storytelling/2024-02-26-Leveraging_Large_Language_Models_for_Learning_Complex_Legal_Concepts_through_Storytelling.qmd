
---
title: "Leveraging Large Language Models for Learning Complex Legal Concepts through Storytelling"
id: "2402.17019v1"
description: "Using large language models to create legal stories improves comprehension and interest in law."
author: Hang Jiang, Xiajie Zhang, Robert Mahari, Daniel Kessler, Eric Ma, Tal August, Irene Li, Alex 'Sandy' Pentland, Yoon Kim, Jad Kabbara, Deb Roy
date: "2024-02-26"
image: "https://browse.arxiv.org/html/2402.17019v1/x1.png"
categories: ['prompt-engineering', 'education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.17019v1/x1.png)

### **Summary:**
This academic article explores the use of large language models (LLMs) to help non-experts learn complex legal concepts through storytelling. The authors introduce a new dataset, LegalStories, which consists of legal doctrines accompanied by stories and multiple-choice questions generated by LLMs. The study evaluates the effectiveness of storytelling with LLMs through a randomized controlled trial (RCT) experiment with legal novices. The findings suggest that LLM-generated stories enhance comprehension of legal concepts and interest in law among non-native speakers compared to only definitions. The study has strong implications for using LLMs to promote teaching and learning in the legal field and beyond.

### **Major Findings:**
1. LLM-generated stories enhance comprehension of legal concepts and interest in law among non-native speakers compared to only definitions.
2. Stories consistently help participants relate legal concepts to their lives.
3. Learning with stories shows a higher retention rate for non-native speakers in the follow-up assessment.

### **Analysis and Critique:**
- **Limitations of the Study:**
  - The sample size of the RCT experiment was limited, which may have impacted the statistical power of the results.
  - The study relied on human experts to audit and improve the LLM-generated content, which may limit the scalability of the approach.
  - The study did not explore various prompting strategies to generate LLM-based concept explanations or elaborations.
- **Ethical Considerations:**
  - The study followed ethical guidelines and obtained consent from participants.
  - The authors were aware of the potential biases and risks associated with LLMs and took a human-centered approach to mitigate these risks.
  - The study used a human-in-the-loop approach to ensure the quality and trustworthiness of the educational content generated by LLMs.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.17019v1](https://arxiv.org/abs/2402.17019v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.17019v1](https://browse.arxiv.org/html/2402.17019v1)       |
| Truncated       | False       |
| Word Count       | 12219       |