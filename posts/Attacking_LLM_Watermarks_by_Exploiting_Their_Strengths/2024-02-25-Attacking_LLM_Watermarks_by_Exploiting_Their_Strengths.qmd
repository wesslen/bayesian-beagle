
---
title: "Attacking LLM Watermarks by Exploiting Their Strengths"
id: "2402.16187v1"
description: "Generative models create human-like content, but watermarking to verify source is vulnerable to attacks."
author: Qi Pang, Shengyuan Hu, Wenting Zheng, Virginia Smith
date: "2024-02-25"
image: "https://browse.arxiv.org/html/2402.16187v1/x1.png"
categories: ['robustness', 'security']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.16187v1/x1.png)

Overall, the results of our defense technique show that it can effectively mitigate spoofing attacks exploiting the detection API while having a negligible impact on utility. The defense can be generalized to all LLM watermarking schemes and provides a significant improvement in security against spoofing attacks.

In conclusion, our work has revealed new attack vectors that exploit common properties of LLM watermarks. By developing realistic attacks and defenses and providing a simple set of guidelines for watermarking in practice, we aim to serve as a resource for the development of secure LLM watermarking systems. We acknowledge that by outlining such attacks, there is a risk that our work may increase the prevalence of watermark removal or spoofing attacks performed in practice. However, we believe that this is an important step towards educating the community about potential risks in watermarking systems and ultimately creating more effective defenses for secure LLM watermarking.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.16187v1](https://arxiv.org/abs/2402.16187v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.16187v1](https://browse.arxiv.org/html/2402.16187v1)       |
| Truncated       | False       |
| Word Count       | 11211       |