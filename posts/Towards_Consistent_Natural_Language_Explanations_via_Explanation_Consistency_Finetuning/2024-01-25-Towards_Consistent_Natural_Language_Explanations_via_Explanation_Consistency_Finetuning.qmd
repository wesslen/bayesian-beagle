
---
title: "Towards Consistent Natural-Language Explanations via Explanation-Consistency Finetuning"
id: "2401.13986v1"
description: "Large language models generate convincing explanations but lack consistency. Explanation-consistency finetuning improves explanation coherence across various datasets."
author: ['Yanda Chen', 'Chandan Singh', 'Xiaodong Liu', 'Simiao Zuo', 'Bin Yu', 'He He', 'Jianfeng Gao']
date: "2024-01-25"
image: "https://browse.arxiv.org/html/2401.13986v1/x1.png"
categories: ['production', 'prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.13986v1/x1.png)

**Summary:**
The article introduces the concept of explanation-consistency finetuning (EC-finetuning), a method utilized to enhance the consistency of natural-language explanations generated by large language models (LLMs) across related examples. The authors highlight the inconsistency issue in LLMs, where different explanations are provided for similar questions. EC-finetuning involves finetuning LLMs on carefully constructed synthetic data to ensure consistent explanations. The study demonstrates a 10.0% relative improvement in explanation consistency across various question-answering datasets through EC-finetuning, as well as generalization to seven out-of-distribution datasets not seen during finetuning, with a relative improvement of 4.5%. The results suggest that EC-finetuning could be beneficial for enabling users to develop accurate mental models of LLMs from their explanations.

### Major Findings:
1. EC-finetuning yields a 10.0% relative improvement in explaining consistency on four finetuning datasets.
2. The method generalizes to seven out-of-distribution datasets, demonstrating a relative improvement of 4.5%.
3. The proposed methodology has the potential to enhance users' mental models of LLMs from provided explanations.

### Analysis and Critique:
The article makes a valuable contribution to addressing the inconsistency issue in LLMs' natural-language explanations. However, the study could benefit from a more in-depth discussion on the potential limitations of EC-finetuning, such as the computational overhead of generating synthetic data and the generalizability of this approach to other types of LLM tasks. Additionally, the article could benefit from an exploration of potential biases or challenges associated with the synthetic data construction. Future research could focus on scaling up EC-finetuning to larger LLMs and investigating its applicability to more complex tasks. Moreover, incorporating a comparative analysis with existing methods for improving explanation consistency in LLMs could provide a more comprehensive understanding of the effectiveness of EC-finetuning.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-02       |
| Abstract | [http://arxiv.org/abs/2401.13986v1](http://arxiv.org/abs/2401.13986v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.13986v1](https://browse.arxiv.org/html/2401.13986v1)       |
| Truncated       | False       |
| Word Count       | 8347       |