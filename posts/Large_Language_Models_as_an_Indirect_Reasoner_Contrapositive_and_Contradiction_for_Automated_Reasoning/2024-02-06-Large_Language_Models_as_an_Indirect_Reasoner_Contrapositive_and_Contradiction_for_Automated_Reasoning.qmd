
---
title: "Large Language Models as an Indirect Reasoner: Contrapositive and Contradiction for Automated Reasoning"
id: "2402.03667v1"
description: "New method improves Large Language Models' reasoning power by 27-31% in factual and math tasks."
author: Yanfang Zhang, Yiliu Sun, Yibing Zhan, Dapeng Tao, Dacheng Tao, Chen Gong
date: "2024-02-06"
image: "https://browse.arxiv.org/html/2402.03667v1/x1.png"
categories: ['prompt-engineering', 'education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.03667v1/x1.png)

### Summary:
- The paper proposes an Indirect Reasoning (IR) method to enhance the reasoning power of Large Language Models (LLMs) by employing the logic of contrapositives and contradictions.
- The IR method comprises two steps: leveraging the logical equivalence of contrapositive to augment the data and rules, and designing prompt templates to trigger LLMs to conduct IR based on proof by contradiction.
- Experimental results show that the IR method enhances the overall accuracy of factual reasoning by 27.33% and mathematic proof by 31.43% when compared with traditional Direct Reasoning (DR) methods.
- The proposed IR method is simple yet effective and can be integrated with existing DR methods to further boost the reasoning abilities of LLMs.

### Major Findings:
1. The IR method significantly improves the overall accuracy of factual reasoning and mathematic proof tasks when compared with traditional DR methods.
2. Combining IR and DR in the Direct-Indirect Reasoning (DIR) framework outperforms either DR or IR alone, enriching the reasoning paths of LLMs.
3. Rule augmentation improves the performances of both DR and IR, leading to improved reasoning ability for LLMs.

### Analysis and Critique:
- The paper provides a comprehensive and well-structured approach to enhancing the reasoning abilities of LLMs through the IR method.
- The experimental results demonstrate the effectiveness of the IR method in improving the overall accuracy of LLMs in various reasoning tasks.
- The proposed DIR framework shows promising results in combining IR and DR to further improve the reasoning abilities of LLMs.
- The paper acknowledges the limitations of popular LLMs and the potential for generating incorrect and biased answers, highlighting the need for further research in this area.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.03667v1](https://arxiv.org/abs/2402.03667v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.03667v1](https://browse.arxiv.org/html/2402.03667v1)       |
| Truncated       | False       |
| Word Count       | 7259       |