
---
title: "CausalQuest: Collecting Natural Causal Questions for AI Agents"
id: "2405.20318v1"
description: "CausalQuest: A Dataset of 13,500 Natural Causal Questions for AI Agents, Achieving F1 Scores of Up to 0.877."
author: Roberto Ceraolo, Dmitrii Kharlapenko, Amélie Reymond, Rada Mihalcea, Mrinmaya Sachan, Bernhard Schölkopf, Zhijing Jin
date: "2024-05-30"
image: "../../../bayesian-beagle.png"
categories: ['production', 'social-sciences']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

**Summary:**

The paper introduces CausalQuest, a dataset of 13,500 naturally occurring questions sourced from social networks, search engines, and AI assistants. The authors formalize the definition of causal questions and establish a taxonomy for finer-grained classification. The dataset is labeled through a combined effort of human annotators and large language models (LLMs). The study finds that 42% of the questions humans ask are causal, with the majority seeking to understand the causes behind given effects. Using this dataset, the authors train efficient classifiers for the binary task of identifying causal questions, achieving high performance with F1 scores of up to 0.877.

**Major Findings:**

1. 42% of the questions humans ask are causal, with the majority seeking to understand the causes behind given effects.
2. The authors establish a taxonomy for finer

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2405.20318v1](https://arxiv.org/abs/2405.20318v1)        |
| HTML     | [https://browse.arxiv.org/html/2405.20318v1](https://browse.arxiv.org/html/2405.20318v1)       |
| Truncated       | True       |
| Word Count       | 30408       |