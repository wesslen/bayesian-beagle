
---
title: "Decision-Making Behavior Evaluation Framework for LLMs under Uncertain Context"
id: "2406.05972v1"
description: "LLMs, like ChatGPT-4.0-Turbo, Claude-3-Opus, and Gemini-1.0-pro, exhibit human-like decision-making patterns but vary in risk, probability, and loss aversion. Ethical implications and biases should be considered when deploying LLMs in decision-making scenarios."
author: Jingru Jia, Zehua Yuan, Junhao Pan, Paul McNamara, Deming Chen
date: "2024-06-10"
image: "https://browse.arxiv.org/html/2406.05972v1/extracted/5652805/paramexplain.png"
categories: ['robustness', 'hci', 'social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.05972v1/extracted/5652805/paramexplain.png)

### Summary:

- The study proposes a framework to evaluate the decision-making behaviors of large language models (LLMs) based on behavioral economics theories.
- The framework is applied to three commercial LLMs: ChatGPT-4.0-Turbo, Claude-3-Opus, and Gemini-1.0-pro.
- The results reveal that LLMs generally exhibit human-like patterns, such as risk aversion and loss aversion, with a tendency to overweight small probabilities.
- However, there are significant variations in the degree to which these behaviors are expressed across different LLMs.
- The study also explores the behavior of LLMs when embedded with socio-demographic features of human beings, uncovering significant disparities across various demographic characteristics.

### Major Findings:

1. LLMs generally exhibit patterns similar to humans, such as risk aversion and loss aversion, with a tendency to overweight small probabilities.
2. There are significant variations in the degree to which these behaviors are expressed across different LLMs.
3. When modeled with attributes of sexual minority groups or physical disabilities, Claude-3-Opus displays increased risk aversion, leading to more conservative choices.

### Analysis and Critique:

- The study highlights the need for careful consideration of the ethical implications and potential biases in deploying LLMs in decision-making scenarios.
- The study advocates for the development of standards and guidelines to ensure that LLMs operate within ethical boundaries while enhancing their utility in complex decision-making environments.
- The study does not provide a detailed analysis of the methodology used to evaluate the LLMs, which could be a potential limitation.
- The study does not discuss the potential implications of these findings for the development and deployment of LLMs in real-world applications.
- The study does not provide a comparison of the performance of the evaluated LLMs with other existing models, which could be a potential area for future research.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-23       |
| Abstract | [https://arxiv.org/abs/2406.05972v1](https://arxiv.org/abs/2406.05972v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.05972v1](https://browse.arxiv.org/html/2406.05972v1)       |
| Truncated       | False       |
| Word Count       | 6256       |