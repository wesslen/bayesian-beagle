
---
title: "Hiding Text in Large Language Models: Introducing Unconditional Token Forcing Confusion"
id: "2406.02481v1"
description: "TL;DR: Hidden text in LLMs can be extracted via Unconditional Token Forcing, but can be made resistant with Unconditional Token Forcing Confusion."
author: Jakub Hoscilowicz, Pawel Popiolek, Jan Rudkowski, Jedrzej Bieniasz, Artur Janicki
date: "2024-06-04"
image: "https://browse.arxiv.org/html/2406.02481v1/extracted/5642916/repeated.png"
categories: ['production']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.02481v1/extracted/5642916/repeated.png)

# Summary:

The article introduces a novel method called Unconditional Token Forcing for extracting fingerprints embedded within LLMs. The authors demonstrate that embedding hidden text in the LLM via fine-tuning, though seemingly secure due to the vast number of potential triggers, is susceptible to extraction through analysis of the LLM’s output decoding process. The proposed approach, Unconditional Token Forcing, is based on the hypothesis that iteratively feeding each token from the LLM’s vocabulary into the model should reveal sequences with abnormally high token probabilities, indicating potential embedded text candidates. The authors also present a method to hide text in such a way that it is resistant to Unconditional Token Forcing, which they named Unconditional Token Forcing Confusion.

# Major Findings:

1. The authors propose a novel method called Unconditional Token Forcing for extracting fingerprints embedded within LLMs.
2. The proposed approach is based on the hypothesis that iteratively feeding each token from the LLM’s vocabulary into the model should reveal sequences with abnormally high token probabilities, indicating potential embedded text candidates.
3. The authors also present a method to hide text in such a way that it is resistant to Unconditional Token Forcing, which they named Unconditional Token Forcing Confusion.

# Analysis and Critique:

* The article provides a detailed explanation of the proposed method and its implementation, making it easy to understand and replicate.
* The authors demonstrate the effectiveness of their approach through experiments, but it is unclear how well it would perform on larger and more complex models.
* The proposed method of hiding text to make it resistant to Unconditional Token Forcing is not well-explained and may not be practical for all use cases.
* The article does not discuss the potential ethical implications of embedding hidden text in LLMs, such as the risk of creating covert communication channels or data leakage.
* The article does not discuss the potential limitations of the proposed method, such as the computational resources required to iterate over the entire vocabulary of the LLM.
* The article does not discuss the potential impact of the proposed method on the performance of the LLM, such as the potential degradation of the model's ability to generate coherent and accurate text.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2406.02481v1](https://arxiv.org/abs/2406.02481v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.02481v1](https://browse.arxiv.org/html/2406.02481v1)       |
| Truncated       | False       |
| Word Count       | 3809       |