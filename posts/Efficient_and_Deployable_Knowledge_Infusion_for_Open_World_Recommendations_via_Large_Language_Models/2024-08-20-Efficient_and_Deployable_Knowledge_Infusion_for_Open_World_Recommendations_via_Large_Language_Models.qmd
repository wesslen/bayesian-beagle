
---
title: "Efficient and Deployable Knowledge Infusion for Open-World Recommendations via Large Language Models"
id: "2408.10520v1"
description: "REKI: A framework using LLMs for open-world recommendations, improving performance in Huawei's news and music platforms."
author: Yunjia Xi, Weiwen Liu, Jianghao Lin, Muyan Weng, Xiaoling Cai, Hong Zhu, Jieming Zhu, Bo Chen, Ruiming Tang, Yong Yu, Weinan Zhang
date: "2024-08-20"
image: "https://browse.arxiv.org/html/2408.10520v1/x1.png"
categories: ['recommender']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.10520v1/x1.png)

**Summary:**

The paper proposes an Open-World Recommendation Framework with Efficient and Deployable Knowledge Infusion from Large Language Models (LLMs), called REKI. The framework aims to acquire two types of external knowledge about users and items from LLMs. It introduces factorization prompting to elicit accurate knowledge reasoning on user preferences and items. With factorization prompting, individual knowledge extraction and collective knowledge extraction are developed for different scales of recommendation scenarios, effectively reducing offline resource consumption. The generated user and item knowledge undergoes efficient transformation and condensation into augmented vectors through a hybridized expert-integrated network, ensuring its compatibility with the recommendation task. The obtained vectors can then be directly used to enhance the performance of any conventional recommendation model. Extensive experiments demonstrate that REKI significantly outperforms the state-of-the-art baselines and is compatible with a diverse array of recommendation algorithms and tasks. REKI has been deployed to Huawei’s news and music recommendation platforms and gained a 7% and 1.99% improvement during the online A/B test.

**Major Findings:**

1. The proposed REKI framework effectively acquires external knowledge about users and items from LLMs, improving the performance of recommendation models.
2. Factorization prompting is introduced to elicit accurate knowledge reasoning on user preferences and items, enhancing the quality of the acquired knowledge.
3. Individual knowledge extraction and collective knowledge extraction are developed for different scales of recommendation scenarios, reducing offline resource consumption.
4. The hybridized expert-integrated network efficiently transforms and condenses the generated user and item knowledge into augmented vectors, ensuring compatibility with the recommendation task.
5. Extensive experiments demonstrate that REKI significantly outperforms the state-of-the-art baselines and is compatible with various recommendation algorithms and tasks.
6. REKI has been successfully deployed to Huawei’s news and music recommendation platforms, resulting in a 7% and 1.99% improvement during the online A/B test.

**Analysis and Critique:**

The paper presents a novel framework, REKI, for incorporating external knowledge from LLMs into recommendation models. The use of factorization prompting and individual/collective knowledge extraction techniques

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-27       |
| Abstract | [https://arxiv.org/abs/2408.10520v1](https://arxiv.org/abs/2408.10520v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.10520v1](https://browse.arxiv.org/html/2408.10520v1)       |
| Truncated       | False       |
| Word Count       | 18779       |