[
  {
    "objectID": "posts/prodigy-db-intro/index.html",
    "href": "posts/prodigy-db-intro/index.html",
    "title": "Retrieving Prodigy annotations in Python",
    "section": "",
    "text": "By default, Prodigy includes SQLite database to save annotations.\nProdigy offers three helpful commands to manipulate."
  },
  {
    "objectID": "posts/prodigy-db-intro/index.html#db-in",
    "href": "posts/prodigy-db-intro/index.html#db-in",
    "title": "Retrieving Prodigy annotations in Python",
    "section": "db-in",
    "text": "db-in\npython -m prodigy db-in new_dataset /path/to/data.jsonl"
  },
  {
    "objectID": "posts/prodigy-db-intro/index.html#db-out",
    "href": "posts/prodigy-db-intro/index.html#db-out",
    "title": "Retrieving Prodigy annotations in Python",
    "section": "db-out",
    "text": "db-out\npython -m prodigy db-out new_dataset > /path/to/data.jsonl"
  },
  {
    "objectID": "posts/prodigy-db-intro/index.html#db-merge",
    "href": "posts/prodigy-db-intro/index.html#db-merge",
    "title": "Retrieving Prodigy annotations in Python",
    "section": "db-merge",
    "text": "db-merge\npython -m prodigy db-merge new_dataset  \n\n## Accessing the database programmatically\n\nProdigy also offers a database component that enables retrieving \n\nfrom prodigy.components.db import connect\ndb = connect() examples = db.get_dataset(“my_dataset”)\n\nHow to use when have them. Use it to describe format for data.\n\n##\n\n\n##\n\nfrom prodigy.components.db import connect\nexamples = [{“text”: “hello world”, “_task_hash”: 123, “_input_hash”: 456}]\ndb = connect() # uses settings from prodigy.json db.add_dataset(“test_dataset”) # add dataset assert “test_dataset” in db # check that dataset was added db.add_examples(examples, [“test_dataset”]) # add examples to dataset dataset = db.get_dataset(“test_dataset”) # retrieve a dataset assert len(dataset) == 1 # check that examples were added\n\nHow to find other datasets\n\nall_dataset_names = db.datasets ```"
  },
  {
    "objectID": "posts/2022-09-27-prodigy-iaa-textcat/index.html",
    "href": "posts/2022-09-27-prodigy-iaa-textcat/index.html",
    "title": "Inter-annotator Agreement (IAA) in Prodigy",
    "section": "",
    "text": "TODO: add preview image"
  },
  {
    "objectID": "posts/2022-09-27-prodigy-iaa-textcat/index.html#multi-user-sessions-in-prodigy",
    "href": "posts/2022-09-27-prodigy-iaa-textcat/index.html#multi-user-sessions-in-prodigy",
    "title": "Inter-annotator Agreement (IAA) in Prodigy",
    "section": "Multi-user sessions in Prodigy",
    "text": "Multi-user sessions in Prodigy\nSince v1.7.0 was released, Prodigy has offered multi-user sessions within the same Prodigy instance. This functionality enables dividing up Prodigy annotations across different annotators when saving annotations to the same dataset and performing an identical task.\nTODO: 2-3 sentences on example, link to past TECH issues\n# news_headlines.jsonl\n{'text': 'Uber’s Lesson: Silicon Valley’s Start-Up Machine Needs Fixing',\n 'meta': {'source': 'The New York Times'}\n}\nTODO: add section on data input/formatting\n\n\nTerminal\n\npython -m prodigy textcat.manual news_textcat news_headlines.jsonl --label TECHNOLOGY\n\nUsing 1 label(s): TECHNOLOGY\n\n✨  Starting the web server at http://localhost:8080 ...\nOpen the app in your browser and start annotating!\n\n\n\n\nTo create a custom named session, add ?session=xxx to the annotation app URL. For example, annotator Jordan may access a running Prodigy project via http://localhost:8080/?session=jordan. The example shows running the textcat.manual Prodigy recipe but this works for any Prodigy recipe. This will enable use to track each annotator so we can calculate inter-annotator agreement.\n\nInternally, this will request and send back annotations with a session identifier consisting of the current dataset name and the session ID – for example, textcat-jordan. Every time annotator Jordan labels examples for this dataset, their annotations will be associated with this session identifier.\nLet’s say that in addition to Jordan, we also asked a second annotator, Alex, do both label 20 records in the dataset to determine whether the news headlines are technology-related or not. We provide both their respective URL and have them complete their annotations.\nTo pull their annotations, we’ll use Prodigy’s get_dataset_examples() function:\n\nfrom prodigy.components.db import connect\nimport pprint\n\ndb = connect()\nexamples = db.get_dataset_examples(\"news_textcat\")\n\npprint.pprint(examples[0])\n\n{'_annotator_id': 'news_textcat-jordan',\n '_input_hash': 1886699658,\n '_session_id': 'news_textcat-jordan',\n '_task_hash': -257308161,\n '_timestamp': 1659908691,\n '_view_id': 'classification',\n 'answer': 'accept',\n 'label': 'TECHNOLOGY',\n 'meta': {'source': 'The New York Times'},\n 'text': 'Uber’s Lesson: Silicon Valley’s Start-Up Machine Needs Fixing'}\n\n\n\n\n\n\n\n\nHint\n\n\n\nTODO: deprecation of get_dataset\n\n\nSince we’re interested in text classification annotations, we’ll focus on the \"answer\" values comparing those that are \"reject\" versus \"accept\".\n\nimport pandas as pd\n\n# keep only the \"accept\" and \"reject\" answers\nanno = [eg for eg in examples if eg[\"answer\"] in [\"accept\", \"reject\"]]\n\n# convert to a dataframe\ndf = pd.DataFrame(anno)\n\ndf_annotations = df.pivot(\n    index=['_input_hash'], \n    columns='_session_id', \n    values='answer'\n)\n\ndf_annotations.head(n=1)\n\n\n\n\n\n  \n    \n      _session_id\n      news_textcat-alex\n      news_textcat-jordan\n    \n    \n      _input_hash\n      \n      \n    \n  \n  \n    \n      -584314991\n      reject\n      reject"
  },
  {
    "objectID": "posts/2022-09-27-prodigy-iaa-textcat/index.html#cohens-kappa",
    "href": "posts/2022-09-27-prodigy-iaa-textcat/index.html#cohens-kappa",
    "title": "Inter-annotator Agreement (IAA) in Prodigy",
    "section": "Cohen’s Kappa",
    "text": "Cohen’s Kappa\nTODO: 2-3 sentences on Cohen’s Kappa.\n\nfrom sklearn.metrics import cohen_kappa_score\n\nkappa = cohen_kappa_score(\n    df_annotations['news_textcat-alex'], \n    df_annotations['news_textcat-jordan'], \n    labels=None, \n    weights=None\n)\n\nprint(kappa)\n\n0.736842105263158\n\n\nSo we’ve found a Cohen’s Kappa of 0.737, which is fairly high.\nTODO: Discussion on interpreting Cohen’s Kappa\n\n\n\n\n\n\nImportant\n\n\n\nIn practice, you may have many more complexities like saving different annotations to different datasets, multi-class classification, span-based tasks like named entity recognition (NER) or spancat, or handling for more than two annotators. This use case is the simplest case; however, I hope to create more advanced use cases in the future."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ryan’s Blog",
    "section": "",
    "text": "prodigy\n\n\ndatabase\n\n\n\n\n\n\n\nRyan Wesslen\n\n\nSep 30, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprodigy\n\n\nchinese\n\n\nner\n\n\nconfig\n\n\n\nOverview of how to get started with Chinese in Prodigy\n\n\n\nRyan Wesslen\n\n\nSep 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprodigy\n\n\ntextcat\n\n\ninter-rater relilability\n\n\nmulti-user sessions\n\n\n\n\n\n\n\nRyan Wesslen\n\n\nSep 27, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Ryan Wesslen",
    "section": "",
    "text": "I’m a machine learning engineer at Explosion"
  },
  {
    "objectID": "posts/2022-09-30-prodigy-db-intro/index.html",
    "href": "posts/2022-09-30-prodigy-db-intro/index.html",
    "title": "Retrieving Prodigy annotations in Python",
    "section": "",
    "text": "By default, Prodigy includes SQLite database to save annotations.\nProdigy offers three helpful commands to manipulate."
  },
  {
    "objectID": "posts/2022-09-30-prodigy-db-intro/index.html#db-in",
    "href": "posts/2022-09-30-prodigy-db-intro/index.html#db-in",
    "title": "Retrieving Prodigy annotations in Python",
    "section": "db-in",
    "text": "db-in\npython -m prodigy db-in new_dataset /path/to/data.jsonl"
  },
  {
    "objectID": "posts/2022-09-30-prodigy-db-intro/index.html#db-out",
    "href": "posts/2022-09-30-prodigy-db-intro/index.html#db-out",
    "title": "Retrieving Prodigy annotations in Python",
    "section": "db-out",
    "text": "db-out\npython -m prodigy db-out new_dataset > /path/to/data.jsonl\npython -m prodigy db-out issue-5948 | jq"
  },
  {
    "objectID": "posts/2022-09-30-prodigy-db-intro/index.html#db-merge",
    "href": "posts/2022-09-30-prodigy-db-intro/index.html#db-merge",
    "title": "Retrieving Prodigy annotations in Python",
    "section": "db-merge",
    "text": "db-merge\npython -m prodigy db-merge new_dataset"
  },
  {
    "objectID": "posts/2022-09-30-prodigy-db-intro/index.html#accessing-the-database-programmatically",
    "href": "posts/2022-09-30-prodigy-db-intro/index.html#accessing-the-database-programmatically",
    "title": "Retrieving Prodigy annotations in Python",
    "section": "Accessing the database programmatically",
    "text": "Accessing the database programmatically\nProdigy also offers a database component that enables retrieving\nfrom prodigy.components.db import connect\n\ndb = connect()\nexamples = db.get_dataset(\"my_dataset\")\nHow to use when have them. Use it to describe format for data.\nfrom prodigy.components.db import connect\n\nexamples = [{\"text\": \"hello world\", \"_task_hash\": 123, \"_input_hash\": 456}]\n\ndb = connect()                               # uses settings from prodigy.json\ndb.add_dataset(\"test_dataset\")               # add dataset\nassert \"test_dataset\" in db                  # check that dataset was added\ndb.add_examples(examples, [\"test_dataset\"])  # add examples to dataset\ndataset = db.get_dataset(\"test_dataset\")     # retrieve a dataset\nassert len(dataset) == 1                     # check that examples were added\nHow to find other datasets\nall_dataset_names = db.datasets"
  },
  {
    "objectID": "posts/2022-09-28-prodigy-chinese-arabic/index.html",
    "href": "posts/2022-09-28-prodigy-chinese-arabic/index.html",
    "title": "Using Prodigy with Chinese",
    "section": "",
    "text": "To get started you need to make sure you have one of the pipelines installed.\npython -m spacy download zh_core_web_sm\nNext, we need an input file. Prodigy can use .txt, .csv, and .jsonl files if they follow these input data formats. Let’s say we have a file named zh_headlines.txt of 10 article news headlines.\n# zh_headlines.txt\n新闻人物：有望成为意大利首位女总理的右翼党魁梅洛尼是谁？\n安倍晋三国葬为何在日本充满争议\n中共二十大“懒人包”：你可能想了解的几个基本问题\nNASA进行防御实验，以飞行器直接撞击小行星\n查尔斯国王如何帮助拯救英国农家奶酪\n斯诺登在美国面临间谍指控，可能导致数十年监禁。\n普京授予斯诺登俄罗斯公民身份\n疫情管控放松\n各国新冠疫情渐次“收尾” 大流行怎么定义？\n世界奇观：拥有两千年历史的土耳其地下城\nSince we have an initial ner component, let’s consider refining three entity types: ORG, PERSON, and DATE so we’ll use ner.correct. We can also modify Prodigy configuration and change the user interface instructions to Chinese. It is one of seven languages that are available (English, German, Dutch, Spanish, Portuguese, French, and Chinese). You can implement it through setting PRODIGY_CONFIG_OVERRIDES.\nPRODIGY_CONFIG_OVERRIDES='{\"ui_lang\": \"zh\"}' python -m prodigy ner.correct example_dataset zh_core_web_sm ./chinese_headlines.txt --label ORG,PERSON,DATE\n\nYou can also play with a demo of this interface."
  },
  {
    "objectID": "posts/2022-09-28-prodigy-chinese/index.html",
    "href": "posts/2022-09-28-prodigy-chinese/index.html",
    "title": "Using Prodigy with Chinese",
    "section": "",
    "text": "To get started you need to make sure you have one of the pipelines installed.\npython -m spacy download zh_core_web_sm\nNext, we need an input file. Prodigy can use .txt, .csv, and .jsonl files if they follow these input data formats. Let’s say we have a file named zh_headlines.txt of 10 article news headlines.\n# zh_headlines.txt\n新闻人物：有望成为意大利首位女总理的右翼党魁梅洛尼是谁？\n安倍晋三国葬为何在日本充满争议\n中共二十大“懒人包”：你可能想了解的几个基本问题\nNASA进行防御实验，以飞行器直接撞击小行星\n查尔斯国王如何帮助拯救英国农家奶酪\n斯诺登在美国面临间谍指控，可能导致数十年监禁。\n普京授予斯诺登俄罗斯公民身份\n疫情管控放松\n各国新冠疫情渐次“收尾” 大流行怎么定义？\n世界奇观：拥有两千年历史的土耳其地下城\nSince we have an initial ner component, let’s consider refining three entity types: ORG, PERSON, and DATE so we’ll use ner.correct. We can also modify Prodigy configuration and change the user interface instructions to Chinese. It is one of seven languages that are available (English, German, Dutch, Spanish, Portuguese, French, and Chinese). You can implement it through setting PRODIGY_CONFIG_OVERRIDES.\nPRODIGY_CONFIG_OVERRIDES='{\"ui_lang\": \"zh\"}' python -m prodigy ner.correct example_dataset zh_core_web_sm ./chinese_headlines.txt --label ORG,PERSON,DATE\n\nYou can also play with a demo of this interface."
  }
]