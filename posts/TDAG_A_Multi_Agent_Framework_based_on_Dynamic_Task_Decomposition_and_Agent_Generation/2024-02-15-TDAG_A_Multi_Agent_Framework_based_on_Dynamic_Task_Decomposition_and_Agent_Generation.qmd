
---
title: "TDAG: A Multi-Agent Framework based on Dynamic Task Decomposition and Agent Generation"
id: "2402.10178v1"
description: "TL;DR: Proposed multi-agent framework enhances adaptability in real-world tasks, outperforming established baselines."
author: Yaoxiang Wang, Zhiyong Wu, Junfeng Yao, Jinsong Su
date: "2024-02-15"
image: "../../img/2402.10178v1/image_1.png"
categories: ['hci', 'architectures']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.10178v1/image_1.png)

### Summary:
- The article proposes a multi-agent framework, TDAG, for addressing the challenges faced by Large Language Model (LLM)-based agents in executing complex, real-world tasks.
- It introduces ItineraryBench, a benchmark designed to evaluate agents' abilities in travel planning, featuring interconnected, progressively complex tasks with a fine-grained evaluation system.
- The TDAG framework dynamically decomposes complex tasks into smaller subtasks and assigns each to a specifically generated subagent, resulting in superior adaptability and context awareness in complex task scenarios.

### Major Findings:
1. The TDAG framework significantly outperforms established baselines, showcasing its superior adaptability and context awareness in complex task scenarios.
2. The ItineraryBench introduces a fine-grained evaluation system, providing a more nuanced assessment of an agent's capabilities, especially in partial task completions.
3. The dynamic task decomposition and agent generation components of the TDAG framework are crucial for optimizing task execution in complex, unpredictable environments.

### Analysis and Critique:
- The TDAG framework demonstrates superior performance compared to established baselines, highlighting the effectiveness of dynamic task decomposition and agent generation.
- The benchmark, ItineraryBench, provides a comprehensive evaluation of agents' capabilities in travel planning, but its generalizability to other domains may be limited.
- The TDAG framework, while effective, may consume more computational resources and result in slower inference speeds, which could be a potential limitation in resource-constrained environments.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.10178v1](https://arxiv.org/abs/2402.10178v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.10178v1](https://browse.arxiv.org/html/2402.10178v1)       |
| Truncated       | False       |
| Word Count       | 10656       |