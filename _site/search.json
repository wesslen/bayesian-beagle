[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian beagle",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nTime series forecasting with high stakes: A field study of the air cargo industry\n\n\n\nproduction\n\n\n\nThis paper improves air cargo demand forecasting using a mixture of expert models, outperforming industry benchmarks and aiding strategic decisions.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLanguage-Conditioned Offline RL for Multi-Robot Navigation\n\n\n\nproduction\n\n\narchitectures\n\n\n\nThis method trains multi-robot navigation policies using LLMs and offline reinforcement learning, requiring minimal data and no simulators, with successful real-world…\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Code Translation in Language Models with Few-Shot Learning via Retrieval-Augmented Generation\n\n\n\nprogramming\n\n\n\n[TEXT] Abstract: This paper explores the relationship between social media use and mental health in adolescents. Results indicate a significant correlation between excessive…\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQAEA-DR: A Unified Text Augmentation Framework for Dense Retrieval\n\n\n\nprompt-engineering\n\n\n\nQAEA-DR: Novel text augmentation for dense retrieval, improving query-text matching without altering embedding or retrieval methods.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOrca: Ocean Significant Wave Height Estimation with Spatio-temporally Aware Large Language Models\n\n\n\nproduction\n\n\n\nOrca framework improves SWH estimation with limited data using spatiotemporal aware encoding and LLMs, outperforming existing methods in the Gulf of Mexico.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nByteCheckpoint: A Unified Checkpointing System for LLM Development\n\n\n\narchitectures\n\n\nrobustness\n\n\nproduction\n\n\n\nByteCheckpoint system speeds up LLM checkpointing, reducing saving (up to 529x) and loading (up to 3.51x) times, with automatic online resharding support.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare\n\n\n\neducation\n\n\n\nSmaller models can perform well with diverse, high-quality datasets, improving medical LLM performance.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutoScale: Automatic Prediction of Compute-optimal Data Composition for Training LLMs\n\n\n\narchitectures\n\n\nproduction\n\n\n\nAutoScale optimizes data composition for LLM pretraining, improving performance and reducing training time.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo LLMs Really Adapt to Domains? An Ontology Learning Perspective\n\n\n\narchitectures\n\n\n\nLLMs struggle with domain-specific reasoning but improve with fine-tuning for lexical semantic tasks.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSentiment Analysis of Lithuanian Online Reviews Using Large Language Models\n\n\n\narchitectures\n\n\nsocial-sciences\n\n\n\nThis work explores transformer models for Lithuanian sentiment analysis, achieving high accuracy and outperforming GPT-4.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConcise Thoughts: Impact of Output Length on LLM Reasoning and Cost\n\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\n[TEXT] Abstract: This paper examines the role of social media in shaping public opinion during the 2016 U.S. Presidential Election. We find that social media platforms…\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning\n\n\n\nproduction\n\n\narchitectures\n\n\nhci\n\n\n\nThis paper proposes a new approach for chart question answering using multimodal large language models, focusing on data quality and alignment with chart characteristics.…\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMs’ Understanding of Natural Language Revealed\n\n\n\neducation\n\n\n\nLLMs excel in text generation but struggle with language understanding, relying on memorization rather than true comprehension.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeaLLMs 3: Open Foundation and Chat Multilingual Large Language Models for Southeast Asian Languages\n\n\n\nsocial-sciences\n\n\nrobustness\n\n\n\nSeaLLMs 3: Cost-effective, versatile model for Southeast Asian languages, prioritizing safety and inclusivity.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen to Stop? Towards Efficient Code Generation in LLMs with Excess Token Prevention\n\n\n\nprogramming\n\n\nrobustness\n\n\narchitectures\n\n\nproduction\n\n\n\nCodeFast accelerates Code LLMs in code generation, improving speed up to 452% without compromising quality.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan Editing LLMs Inject Harm?\n\n\n\nproduction\n\n\nrobustness\n\n\narchitectures\n\n\nsecurity\n\n\n\nEditing attacks can inject misinformation and bias into LLMs, posing safety threats and impacting overall fairness.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDetecting and Understanding Vulnerabilities in Language Models via Mechanistic Interpretability\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nTL;DR: We propose a method using Mechanistic Interpretability to locate and understand vulnerabilities in LLMs like GPT-2, improving their robustness against adversarial…\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrLLM: Relational Table Learning with LLMs\n\n\n\nproduction\n\n\narchitectures\n\n\n\nrLLM: A PyTorch library for Relational Table Learning with LLMs.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeaching LLMs at Charles University: Assignments and Activities\n\n\n\neducation\n\n\n\nNew course on LLMs offers assignments, quizzes, and research activities.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOptiMUS-0.3: Using Large Language Models to Model and Solve Optimization Problems at Scale\n\n\n\nprogramming\n\n\n\n[TEXT] Abstract: This study examines the impact of social media on the mental health of adolescents. Results indicate a significant correlation between excessive social…\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Large Language Models to generate Easy to Read content\n\n\n\narchitectures\n\n\nsocial-sciences\n\n\n\nThis study explores AI and NLP for simplifying Spanish texts into Easy to Read formats, contributing a parallel corpus and testing a Llama2 model.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEfficient Training of Large Language Models on Distributed Infrastructures: A Survey\n\n\n\nprogramming\n\n\narchitectures\n\n\nproduction\n\n\neducation\n\n\n\nTL;DR: Survey explores advancements in training systems for LLMs, including infrastructure, parallelism, optimizations, and reliability, with a focus on optical computing.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMindSearch: Mimicking Human Minds Elicits Deep AI Searcher\n\n\n\narchitectures\n\n\nproduction\n\n\n\nMindSearch: LLM-based framework for efficient web information seeking and integration, outperforming human effort and existing AI search engines.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSmart Language Agents in Real-World Planning\n\n\n\nprompt-engineering\n\n\n\nTL;DR: Human-in-the-loop prompt refinement boosts LLM travel planning by 139%.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPreliminary WMT24 Ranking of General MT Systems and LLMs\n\n\n\narchitectures\n\n\n\n[TEXT] Abstract: This paper explores the role of social media in shaping public opinion during the 2016 U.S. Presidential Election. We analyze a dataset of 171 million…\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpecify and Edit: Overcoming Ambiguity in Text-Based Image Editing\n\n\n\nproduction\n\n\narchitectures\n\n\n\nSANE improves diffusion-based editing with LLM-derived instructions, enhancing interpretability and diversity.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerating Unseen Code Tests In Infinitum\n\n\n\nprogramming\n\n\n\nNew method generates benchmark variations for LLMs, mitigating leaking into training data, with auto-regression for Python text-to-code generation.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparative Analysis of Encoder-Based NER and Large Language Models for Skill Extraction from Russian Job Vacancies\n\n\n\nsocial-sciences\n\n\n\nTraditional NER models, like DeepPavlov RuBERT, outperform LLMs in extracting skills from Russian job vacancies, aiding job seekers and employers.\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Generic Review of Integrating Artificial Intelligence in Cognitive Behavioral Therapy\n\n\n\nsocial-sciences\n\n\neducation\n\n\n\nAI in CBT: Potential to enhance, automate, and personalize mental health interventions, but further research needed for long-term efficacy.\n\n\n\nJul 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdaCoder: Adaptive Prompt Compression for Programmatic Visual Question Answering\n\n\n\nprogramming\n\n\neducation\n\n\nprompt-engineering\n\n\n\nAdaCoder: Adaptive prompt compression for visual programmatic models, reducing token length by 71.1% without compromising performance.\n\n\n\nJul 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentity-Driven Hierarchical Role-Playing Agents\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\nhci\n\n\n\nHIRPF balances flexibility and precision in role-playing using identity theory, outperforming traditional LLM methods in social simulation.\n\n\n\nJul 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImpact of Decoding Methods on Human Alignment of Conversational LLMs\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nTL;DR: Decoding methods impact LLM-human conversation alignment. Fewer beams, lower P-values improve alignment, but results vary by conversation type.\n\n\n\nJul 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMeta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge\n\n\n\nsocial-sciences\n\n\n\nLLMs can self-improve by judging their own judgments, enhancing their instruction-following abilities without human supervision.\n\n\n\nJul 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnabling Uniform Computer Interaction Experience for Blind Users through Large Language Models\n\n\n\nprompt-engineering\n\n\n\nSavant: A language model tool improving blind users’ screen reader efficiency and usability.\n\n\n\nJul 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMotamot: A Dataset for Revealing the Supremacy of Large Language Models over Transformer Models in Bengali Political Sentiment Analysis\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nBanglaBERT excels in political sentiment analysis, but Gemini 1.5 Pro outperforms with 96.33% accuracy using few-shot learning.\n\n\n\nJul 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating LLMs for Text-to-SQL Generation With Complex SQL Workload\n\n\n\nprompt-engineering\n\n\n\nTL;DR: TPC-DS SQL benchmark is more complex than BIRD and Spider. Current AI models struggle to generate accurate queries.\n\n\n\nJul 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Emerged Security and Privacy of LLM Agent: A Survey with Case Studies\n\n\n\nsecurity\n\n\n\nTL;DR: This survey explores security and privacy issues in LLM agents, discussing threats, impacts, defenses, and future trends.\n\n\n\nJul 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemantic Communication Enhanced by Knowledge Graph Representation Learning\n\n\n\nhci\n\n\n\nSemantic communications use graphs and LLMs for compact knowledge representation, achieving high compression rates in communication.\n\n\n\nJul 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre Large Language Models Possible to Conduct Cognitive Behavioral Therapy?\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\nhci\n\n\neducation\n\n\n\nLLMs show potential for CBT, offering new therapy possibilities, but require integration with CBT knowledge bases for optimal results.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Geometry of Queries: Query-Based Innovations in Retrieval-Augmented Generation\n\n\n\nsocial-sciences\n\n\nhci\n\n\nrobustness\n\n\n\nQB-RAG improves healthcare chatbot accuracy by pre-computing queries, enhancing retrieval, and aligning user questions with reliable content.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKeep the Cost Down: A Review on Methods to Optimize LLM’ s KV-Cache Consumption\n\n\n\nhci\n\n\n\nKV-Cache optimizes LLMs like ChatGPT for long-text handling, improving efficiency from quadratic to linear time complexity, but with increased GPU memory overhead.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Model Performance: Another Approach to Vision-Language Instruction Tuning\n\n\n\nhci\n\n\n\nTL;DR: Bottleneck Adapter enhances multimodal LLMs, outperforming human-level and LaVIN-7B performance with 90.12% accuracy.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTwIPS: A Large Language Model Powered Texting Application to Simplify Conversational Nuances for Autistic Users\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\nhci\n\n\neducation\n\n\n\nTwIPS app aids autistic users in text-based communication, offering tone interpretation, message preview, and phrasing suggestions.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAudio Entailment: Assessing Deductive Reasoning for Audio Understanding\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nALMs struggle with logical reasoning; new task Audio Entailment proposed to evaluate and improve this ability.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPEFT-U: Parameter-Efficient Fine-Tuning for User Personalization\n\n\n\nsocial-sciences\n\n\nhci\n\n\nrecommender\n\n\n\nTL;DR: Introducing PEFT-U Benchmark for personalizing LLMs, addressing the need for user-specific preferences in diverse tasks.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Scaling Trends in LLM Robustness\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nLarger language models improve with adversarial training, but not without explicit defenses.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Agent Learning through World Dynamics Modeling\n\n\n\nsocial-sciences\n\n\neducation\n\n\n\nLLMs guided by DiVE make better decisions, matching human rewards in the Crafter environment.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRecursive Introspection: Teaching Language Model Agents How to Self-Improve\n\n\n\nprompt-engineering\n\n\n\nRISE enables LLMs to improve math reasoning with more turns, outperforming single-turn strategies and scaling well with model capability.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Power of Combining Data and Knowledge: GPT-4o is an Effective Interpreter of Machine Learning Models in Predicting Lymph Node Metastasis of Lung Cancer\n\n\n\nprogramming\n\n\n\nChatGPT can extract info from radiology reports, rivaling traditional systems; prior medical knowledge can enhance some extraction tasks but may worsen others.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC2P: Featuring Large Language Models with Causal Reasoning\n\n\n\nprompt-engineering\n\n\n\nC2P framework boosts LLMs’ causal reasoning, improving accuracy by over 33% in real-world scenarios with few-shot learning.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinancial Statement Analysis with Large Language Models\n\n\n\nsocial-sciences\n\n\n\nLLM (GPT4) outperforms human analysts in financial statement analysis and predicting earnings changes, offering valuable insights for decision-making.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPenHeal: A Two-Stage LLM Framework for Automated Pentesting and Optimal Remediation\n\n\n\nprompt-engineering\n\n\nrobustness\n\n\neducation\n\n\nsecurity\n\n\n\nPenHeal: LLM-based framework automates vulnerability detection, boosts coverage by 31%, effectiveness by 32%, and cuts costs by 46%.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBehavioral Testing: Can Large Language Models Implicitly Resolve Ambiguous Entities?\n\n\n\nprompt-engineering\n\n\nrobustness\n\n\n\nLLMs struggle with entity type ambiguity, often failing to consistently apply their factual knowledge, leading to self-inconsistency and biases.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Dark Side of Function Calling: Pathways to Jailbreaking Large Language Models\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nJailbreak function attack exploits LLMs’ function calling, succeeding 90% of the time; defense strategies proposed.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs the Digital Forensics and Incident Response Pipeline Ready for Text-Based Threats in LLM Era?\n\n\n\nsocial-sciences\n\n\nsecurity\n\n\n\nTL;DR: NTGs pose new cybersecurity challenges in DFIR, including detecting and attributing authorship. Current methodologies show vulnerabilities, necessitating more…\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExamining the Influence of Political Bias on Large Language Model Performance in Stance Classification\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLLMs show bias in stance classification, performing better on certain political stances, with accuracy decreasing when target ambiguity rises.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSAFETY-J: Evaluating Safety with Critique\n\n\n\nsecurity\n\n\n\nSafety-J: A bilingual LLM evaluator for nuanced, critique-based safety assessments.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVery Large-Scale Multi-Agent Simulation in AgentScope\n\n\n\nsocial-sciences\n\n\n\nTL;DR: AgentScope enhancements improve scalability, efficiency, and diversity in large-scale multi-agent simulations.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDemystifying Verbatim Memorization in Large Language Models\n\n\n\nrobustness\n\n\n\nLLMs memorize verbatim with legal/privacy implications; controlled study shows repetition, later checkpoints, and distributed model states aid memorization. Unlearning…\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGermanPartiesQA: Benchmarking Commercial Large Language Models for Political Bias and Sycophancy\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\neducation\n\n\nhci\n\n\n\nLLMs show left-green bias, can be ideologically steered with political personas, but changes in output are more like personalization than sycophancy.\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI Could’ve Asked That: Reformulating Unanswerable Questions\n\n\n\neducation\n\n\n\nLLMs struggle to reformulate unanswerable questions; benchmark shows GPT-4 and Llama2-7B succeed only 26% and 12% of the time, respectively.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBoosting Large Language Models with Socratic Method for Conversational Mathematics Teaching\n\n\n\nprompt-engineering\n\n\neducation\n\n\nhci\n\n\n\nSocraticLLM improves math teaching via conversation, outperforming other models.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWildHallucinations: Evaluating Long-form Factuality in LLMs with Real-World Entity Queries\n\n\n\nrobustness\n\n\n\nLLMs hallucinate more on entities without Wikipedia pages and vary by domain; retrieval component slightly reduces hallucinations.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan Watermarking Large Language Models Prevent Copyrighted Text Generation and Hide Training Data?\n\n\n\nrobustness\n\n\n\nWatermarking LLMs reduces copyrighted content generation but complicates detecting copyrighted text in pretraining datasets.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop Game Applications\n\n\n\nprompt-engineering\n\n\nhci\n\n\n\nThis paper explores integrating LLM-driven agents in tabletop games to enhance SUI interaction tasks, using the AI-Gadget Kit for personalized and dynamic experiences.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3D Question Answering for City Scene Understanding\n\n\n\neducation\n\n\n\nCity-3DQA dataset and Sg-CityU method introduced for city-level 3D MQA, achieving SOTA performance.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIgnitionInnovators at Discharge Me!: Chain-of-Thought Instruction Finetuning Large Language Models for Discharge Summaries\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nThis paper proposes an LLM-based framework for generating discharge summary sections, improving clinical information accuracy with structured prompts and CoT questions.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-Generated Tips Rival Expert-Created Tips in Helping Students Answer Quantum-Computing Questions\n\n\n\nprompt-engineering\n\n\nrobustness\n\n\neducation\n\n\nsocial-sciences\n\n\n\nLLM-generated tips can be as useful as expert-created tips for teaching quantum computing, potentially reducing teachers’ workloads.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRevisiting Who’s Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective\n\n\n\nsecurity\n\n\n\nTL;DR: This paper improves the Who’s Harry Potter method for targeted unlearning in language models, achieving competitive performance.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTesting Large Language Models on Driving Theory Knowledge and Skills for Connected Autonomous Vehicles\n\n\n\neducation\n\n\n\nTL;DR: GPT-4 excels in driving theory tests for autonomous vehicles, but costs 50x more than GPT-3.5, which fails the test.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSDoH-GPT: Using Large Language Models to Extract Social Determinants of Health (SDoH)\n\n\n\nsocial-sciences\n\n\n\nSDoH-GPT: A few-shot LLM method for SDoH extraction, reducing time and cost by 10-20x, with high accuracy and consistency.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBLAZE: Cross-Language and Cross-Project Bug Localization via Dynamic Chunking and Hard Example Learning\n\n\n\nrobustness\n\n\n\nBLAZE, a GPT-based approach, improves bug localization with dynamic chunking and hard example learning, outperforming six baselines on three benchmark datasets.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow Good (Or Bad) Are LLMs at Detecting Misleading Visualizations?\n\n\n\nprompt-engineering\n\n\neducation\n\n\nrobustness\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLLMs can detect misleading charts, aiding in data interpretation and combating misinformation.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArtificial Agency and Large Language Models\n\n\n\nhci\n\n\n\nLLMs are not agents yet, but their elements suggest a path forward. Combining specific architectures and modules could realize artificial agency.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCovScore: Evaluation of Multi-Document Abstractive Title Set Generation\n\n\n\nsocial-sciences\n\n\n\nCovScore: Automatic method for evaluating title sets, tested on Holocaust testimonies, simplifies and expedites manual evaluation.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Transfer Unlearning: Empirical Evidence of Cross-Domain Bias Mitigation\n\n\n\nrobustness\n\n\n\nUnlearning approach to debiasing in LLMs by minimizing hate speech, showing cross-domain transfer unlearning benefits.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Sands to Mansions: Enabling Automatic Full-Life-Cycle Cyberattack Construction with LLM\n\n\n\nsecurity\n\n\n\nAurora: Automatic Framework for Efficient, Full-Life-Cycle Cyberattack Emulation\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScholarChemQA: Unveiling the Power of Language Models in Chemical Research Question Answering\n\n\n\neducation\n\n\n\nScholarChemQA: New Chemistry QA Dataset & QAMatch Model for Improved Performance\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Voter-Based Stochastic Rejection-Method Framework for Asymptotically Safe Language Model Outputs\n\n\n\nsecurity\n\n\n\nTL;DR: New method uses LLM checkers to vote and regenerate outputs, optimizing cost and failure rate.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAMONGAGENTS: Evaluating Large Language Models in the Interactive Text-Based Social Deduction Game\n\n\n\nhci\n\n\n\nLLMs can grasp game rules and make decisions in AmongAgents, a text-based game mirroring Among Us, for studying simulated human behavior.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReinforced Prompt Personalization for Recommendation with Large Language Models\n\n\n\nprompt-engineering\n\n\nrecommender\n\n\n\nRPP/RPP+ optimizes prompt patterns for individual users in recommendation tasks, outperforming traditional methods.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy Ontologist: Evaluating BFO-Based AI for Definition Support\n\n\n\nhci\n\n\neducation\n\n\n\nLLMs, like GPT-4, can aid ontology development but face challenges in adhering to top-level standards.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models for Anomaly Detection in Computational Workflows: from Supervised Fine-Tuning to In-Context Learning\n\n\n\nprompt-engineering\n\n\nrobustness\n\n\nsecurity\n\n\n\nLLMs can detect workflow anomalies via supervised fine-tuning and in-context learning, offering promising results for system reliability and security.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMathViz-E: A Case-study in Domain-Specialized Tool-Using Agents\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nTL;DR: We present a math visualizer system, tackling domain-specific challenges and open-sourcing datasets and code.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan Language Models Evaluate Human Written Text? Case Study on Korean Student Writing for Education\n\n\n\nsocial-sciences\n\n\neducation\n\n\n\nLLMs can reliably assess grammar and fluency in human-written text, but struggle with other criteria and types of writing.\n\n\n\nJul 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo LLMs Know When to NOT Answer? Investigating Abstention Abilities of Large Language Models\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nStrategic prompting, like Chain-of-Thought, enhances abstention ability in LLMs, improving overall QA task performance.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPatched RTC: evaluating LLMs for diverse software development tasks\n\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\nPatched RTC: A self-evaluating framework for LLMs in software tasks, correlating with task accuracy and distinguishing model performance.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemantic Change Characterization with LLMs using Rhetorics\n\n\n\nhci\n\n\n\nLLMs effectively capture and analyze semantic changes, improving computational linguistics.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDDK: Distilling Domain Knowledge for Efficient Large Language Models\n\n\n\neducation\n\n\n\nDDK framework dynamically adjusts distillation dataset, improving student LLM performance, outperforming existing methods.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrimeGuard: Safe and Helpful LLMs through Tuning-Free Routing\n\n\n\nrobustness\n\n\n\nPrimeGuard improves LM safety without compromising helpfulness, outperforming baselines and reducing attack success rate.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Leverage Personal Textual Knowledge for Personalized Conversational Information Retrieval\n\n\n\nrecommender\n\n\n\nLLM helps PTKB generate better personalized queries for CIR, improving search results with high-quality guidance.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing LLM’s Cognition via Structurization\n\n\n\nprogramming\n\n\nrobustness\n\n\n\nThis paper improves language models’ cognition by structuring context, boosting performance in NLP tasks.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Automatic Cryptographic API Misuse Detection in the Era of LLMs\n\n\n\nrobustness\n\n\n\nLLMs can detect cryptographic misuses, but struggle with false positives. Constrained scope and self-correction improve reliability, leading to a 90% detection rate and…\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvolutionary Prompt Design for LLM-Based Post-ASR Error Correction\n\n\n\nprompt-engineering\n\n\n\nEvolutionary prompt optimization improves post-ASR error correction in LLMs, as shown in CHiME-4 subset of SLT 2024 GenSEC challenge.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCourse-Correction: Safety Alignment Using Synthetic Preferences\n\n\n\nrobustness\n\n\neducation\n\n\n\nTL;DR: This paper improves LLMs’ course-correction skills, reducing harmful content and jailbreak attacks, using a synthetic dataset and preference learning.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShared Imagination: LLMs Hallucinate Alike\n\n\n\nrobustness\n\n\neducation\n\n\n\nLLMs share a shared imagination space, answering imaginary questions with success, suggesting model homogeneity and computational creativity.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Translation Hallucination Detection for Low and High Resource Languages using Large Language Models\n\n\n\nrobustness\n\n\n\nLLMs, like Llama3-70B and Claude Sonnet, improve hallucination detection in MT, but performance varies between HRLs and LRLs.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPsychomatics – A Multidisciplinary Framework for Understanding Artificial Minds\n\n\n\nhci\n\n\neducation\n\n\n\nPsychomatics: A Framework Comparing LLMs and Human Cognition, Highlighting Differences and Potential for AI Development.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVidyaRANG: Conversational Learning Based Platform powered by Large Language Model\n\n\n\neducation\n\n\n\nPlatform uses LLMs, knowledge-augmented retrieval for personalized, confidential learning; covers software dev, product mgmt, cloud computing, security, and mobile app.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEducating LLMs like Human Students: Structure-aware Injection of Domain Knowledge\n\n\n\nprogramming\n\n\n\nStructTuning: New method efficiently transforms LLMs into domain specialists using 0.3% of traditional training data, achieving 50% performance.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparison of Static Application Security Testing Tools and Large Language Models for Repo-level Vulnerability Detection\n\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\nSAST tools have low detection rates but fewer false positives, while LLMs detect more vulnerabilities but have high false positives. Combining both can improve results.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpenDevin: An Open Platform for AI Software Developers as Generalist Agents\n\n\n\nprogramming\n\n\n\nOpenDevin: A platform for developing AI agents that write code, use command lines, and browse the web, with 15+ benchmark tasks.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent\n\n\n\nprogramming\n\n\nrobustness\n\n\nsecurity\n\n\n\nRedAgent system improves jailbreak attack efficiency on LLMs like GPT-4, discovering 60 vulnerabilities in real-world applications.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTAMIGO: Empowering Teaching Assistants using LLM-assisted viva and code assessment in an Advanced Computing Class\n\n\n\nprogramming\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLMs aid TAs in assessing viva and code, offering constructive feedback, but may hallucinate and require alignment with rubrics.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOriGen:Enhancing RTL Code Generation with Code-to-Code Augmentation and Self-Reflection\n\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\nOriGen, an open-source LLM, outperforms others in RTL code generation and self-reflection, surpassing GPT-4 in error rectification.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan Large Language Models Automatically Jailbreak GPT-4V?\n\n\n\nprompt-engineering\n\n\nrobustness\n\n\nsecurity\n\n\n\nAutoJailbreak, a novel technique, uses LLMs for red-teaming and in-context learning, achieving a 95.3% Attack Success Rate, highlighting GPT-4V security concerns.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIDA: Breaking Barriers in No-code UI Automation Through Large Language Models and Human-Centric Design\n\n\n\nprogramming\n\n\n\nIDA: A no-code Web UI automation tool for business users, leveraging LLMs, designed for simplicity and human-centric programming.\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOdyssey: Empowering Agents with Open-World Skills\n\n\n\nhci\n\n\n\nODYSSEY framework empowers LLM-based agents with open-world skills for Minecraft exploration, offering a new benchmark for evaluating agent planning and exploration…\n\n\n\nJul 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWalking in Others’ Shoes: How Perspective-Taking Guides Large Language Models in Reducing Toxicity and Bias\n\n\n\nhci\n\n\n\nPeT strategy reduces toxicity (89%) and bias (73%) in LLMs by inspiring self-regulation, outperforming baselines.\n\n\n\nJul 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLanguage models are robotic planners: reframing plans as goal refinement graphs\n\n\n\nhci\n\n\n\nLLMs can generate more correct robotic plans using goal modeling techniques from software engineering.\n\n\n\nJul 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo Large Language Models Have Compositional Ability? An Investigation into Limitations and Scalability\n\n\n\nhci\n\n\n\nLLMs struggle with complex composite tasks, despite decent performance on simpler ones. Model scaling doesn’t always improve performance.\n\n\n\nJul 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKnowledge Mechanisms in Large Language Models: A Survey and Perspective\n\n\n\nhci\n\n\n\nExploring knowledge mechanisms in LLMs, including utilization, evolution, and potential dark knowledge, to advance trustworthy AGI.\n\n\n\nJul 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBIGbench: A Unified Benchmark for Social Bias in Text-to-Image Generative Models Based on Multi-modal LLM\n\n\n\nhci\n\n\n\nBIGbench: A Unified Benchmark for Biases in Image Generation, Evaluating Four Dimensions of Bias in T2I Models.\n\n\n\nJul 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSynCPKL: Harnessing LLMs to Generate Synthetic Data for Commonsense Persona Knowledge Linking\n\n\n\nhci\n\n\n\nSynCPKL Pipeline generates synthetic data for training commonsense persona knowledge linkers, improving F1 score by 16% in CPKL challenge.\n\n\n\nJul 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoDefeater: Using LLMs To Find Defeaters in Assurance Cases\n\n\n\nprogramming\n\n\n\nLLMs can automatically find defeaters to improve safety assurance cases, as shown in two system tests.\n\n\n\nJul 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCOMCAT: Leveraging Human Judgment to Improve Automatic Documentation and Summarization\n\n\n\nprogramming\n\n\n\nComCat automates comment generation for code, improving comprehension by up to 12% and offering accurate, readable comments preferred over ChatGPT-generated ones.\n\n\n\nJul 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStuGPTViz: A Visual Analytics Approach to Understand Student-ChatGPT Interactions\n\n\n\nprogramming\n\n\n\nTL;DR: Study analyzes student-ChatGPT interactions in a course, creating a system (StuGPTViz) to track and compare conversation patterns, providing pedagogical insights.\n\n\n\nJul 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRevisiting the Impact of Pursuing Modularity for Code Generation\n\n\n\nprogramming\n\n\n\nTL;DR: Modularity doesn’t significantly improve code generation models’ performance.\n\n\n\nJul 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuilding AI Agents for Autonomous Clouds: Challenges and Design Principles\n\n\n\nprogramming\n\n\n\nAIOps framework proposed for autonomous, self-healing clouds, reducing human intervention in IT operations.\n\n\n\nJul 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGPT Assisted Annotation of Rhetorical and Linguistic Features for Interpretable Propaganda Technique Detection in News Text\n\n\n\nprogramming\n\n\n\nStudy combines human annotation with GPT-3.5 for cost-effective, interpretable propaganda detection, introducing a new feature set and tool, RhetAnn.\n\n\n\nJul 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond Correctness: Benchmarking Multi-dimensional Code Generation for Large Language Models\n\n\n\nprogramming\n\n\n\nTL;DR: RACE benchmark evaluates LLMs’ code quality across 4 dimensions: Readability, Maintainability, Correctness, and Efficiency. Current LLMs fall short in generating…\n\n\n\nJul 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBy My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting\n\n\n\nprompt-engineering\n\n\n\nVisual prompts with MLLMs improve sensor data accuracy by 10% and reduce token costs by 15.8× imes×, outperforming text-based prompts.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVGBench: Evaluating Large Language Models on Vector Graphics Understanding and Generation\n\n\n\nproduction\n\n\nhci\n\n\narchitectures\n\n\nprompt-engineering\n\n\neducation\n\n\n\nTL;DR: VGBench evaluates LLMs on vector graphics, showing strong performance in understanding and generation, but weaker in low-level formats like SVG.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGRUtopia: Dream General Robots in a City at Scale\n\n\n\neducation\n\n\n\nGRUtopia: Simulated 3D society for diverse robot learning, featuring interactive scenes, social scenarios, and benchmarks.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetaLLM: A High-performant and Cost-efficient Dynamic Framework for Wrapping LLMs\n\n\n\nproduction\n\n\narchitectures\n\n\n\nMetaLLM dynamically routes queries to optimal LLMs for classification tasks, improving accuracy and cost-effectiveness.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFoundational Autoraters: Taming Large Language Models for Better Automatic Evaluation\n\n\n\nsocial-sciences\n\n\nproduction\n\n\narchitectures\n\n\n\nFLAMe, a family of LLM autoraters, outperforms proprietary models like GPT-4 and Claude-3, offering better generalization and less bias in evaluating LLM output.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmpowering LLMs for Verilog Generation through Multi-Level Summarization\n\n\n\nrobustness\n\n\nprogramming\n\n\neducation\n\n\n\nLLMs struggle with Verilog generation due to data scarcity. CodeV, an instruction-tuned LLM, surpasses previous SOTA in Verilog generation by summarizing existing code.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn Actionable Framework for Assessing Bias and Fairness in Large Language Model Use Cases\n\n\n\nsocial-sciences\n\n\nproduction\n\n\narchitectures\n\n\n\nTL;DR: This paper offers a decision framework to assess bias and fairness risks in LLM use cases, introducing new metrics and considering both prompt-risk and model-risk.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQ-Sparse: All Large Language Models can be Fully Sparsely-Activated\n\n\n\nproduction\n\n\narchitectures\n\n\n\nQ-Sparse trains sparse LLMs with top-K sparsification, offering efficiency gains in inference and comparable results to dense models.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHey, That’s My Model! Introducing Chain & Hash, An LLM Fingerprinting Technique\n\n\n\nsecurity\n\n\nproduction\n\n\nrobustness\n\n\narchitectures\n\n\n\nChain & Hash: A Cryptographic Approach for Fingerprinting LLMs, Ensuring Robustness and Unforgeability.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding the Importance of Evolutionary Search in Automated Heuristic Design with Large Language Models\n\n\n\narchitectures\n\n\n\nLLMs improve automated heuristic design, but need better integration with search strategies. Large-scale benchmark results are shared for future research.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTransforming Agency. On the mode of existence of Large Language Models\n\n\n\neducation\n\n\nsocial-sciences\n\n\nhci\n\n\nrobustness\n\n\n\nLLMs like ChatGPT are not autonomous agents, but linguistic automatons that transform human agency through textual and computational embodiment.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeveraging LLM-Respondents for Item Evaluation: a Psychometric Analysis\n\n\n\neducation\n\n\narchitectures\n\n\n\nLLMs can resemble college students’ ability in College Algebra, with ensemble LLMs better mimicking human respondents. LLM-calibrated item parameters correlate highly with…\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeveraging Hybrid Intelligence Towards Sustainable and Energy-Efficient Machine Learning\n\n\n\neducation\n\n\n\nHybrid Intelligence improves ML efficiency with human and LLM input, focusing on energy-aware development.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMix-CPT: A Domain Adaptation Framework via Decoupling Knowledge Learning and Format Alignment\n\n\n\nproduction\n\n\narchitectures\n\n\n\nMix-CPT: New framework for domain adaptation of LLMs, improving task-solving capabilities in target and general domains.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Medication Recommendation with LLM Text Representation\n\n\n\nrecommender\n\n\n\nThis method enhances medication recommendation by utilizing LLM text representation from unstructured data, improving performance in base models.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCLAVE: An Adaptive Framework for Evaluating Values of LLM Generated Responses\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\n\nCLAVE framework uses dual-model approach for adaptable, generalizable LLM value evaluation, benchmarked on ValEval dataset.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn Empirical Study of Validating Synthetic Data for Formula Generation\n\n\n\narchitectures\n\n\n\nValidation of synthetic NL formulas boosts LLM performance, enabling models to tackle more complex problems.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Retrieval and Managing Retrieval: A Four-Module Synergy for Improved Quality and Efficiency in RAG Systems\n\n\n\narchitectures\n\n\n\nRAG techniques improve LLM responses. Four proposed modules enhance query rewriting, filter irrelevant knowledge, and optimize retrieval, improving response quality and…\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodebook LLMs: Adapting Political Science Codebooks for LLM Use and Adapting LLMs to Follow Codebooks\n\n\n\narchitectures\n\n\n\nLLMs struggle with codebook constraints; rewriting codebooks and instruction-tuning improve performance.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore Non-Determinism\n\n\n\nrobustness\n\n\n\nGreedy decoding outperforms sampling in LLMs, with smaller models potentially matching larger ones. Non-determinism is crucial in LLM evaluations.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNTSEBENCH: Cognitive Reasoning Benchmark for Vision Language Models\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nTL;DR: New dataset, NTSEBench, tests LLMs and VLMs on complex cognitive reasoning tasks, featuring 2,728 multiple-choice questions with 4,642 images.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCIBench: Evaluating Your LLMs with a Code Interpreter Plugin\n\n\n\nsocial-sciences\n\n\nprogramming\n\n\neducation\n\n\n\nCIBench evaluates LLMs’ code interpreter use for data science, with/without human help, offering insights for future LLM development.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDOCBENCH: A Benchmark for Evaluating LLM-based Document Reading Systems\n\n\n\narchitectures\n\n\n\nTL;DR: DocBench is a new benchmark for evaluating LLM-based document reading systems, featuring 229 real documents and 1,102 questions across five domains.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoviCode: Generating Programs from Natural Language Utterances by Novices\n\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\nTL;DR: NoviCode, a new task, challenges models to generate complex code from non-technical descriptions, outperforming end-to-end Text-to-Code approaches.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFast Matrix Multiplications for Lookup Table-Quantized LLMs\n\n\n\nproduction\n\n\narchitectures\n\n\n\nFLUTE accelerates LUT-quantized LLMs inference, offering 2-4× imes× speedup over GEMM kernels and 1.5-2× imes× end-to-end throughput increase for LLaMA3 quantization.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSLIP: Securing LLMs IP Using Weights Decomposition\n\n\n\nsecurity\n\n\nproduction\n\n\nrobustness\n\n\narchitectures\n\n\n\nSLIP: A Hybrid Inference Algorithm Protecting LLMs on Edge Devices with Zero Accuracy Loss.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIDEAL: Leveraging Infinite and Dynamic Characterizations of Large Language Models for Query-focused Summarization\n\n\n\nprogramming\n\n\n\nLLMs-based QFS models: Proposed modules for lengthy summarization and efficient query alignment, with promising results.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraphEval: A Knowledge-Graph Based LLM Hallucination Evaluation Framework\n\n\n\nrobustness\n\n\n\nGraphEval: A KG-based framework for evaluating, detecting, and correcting LLM hallucinations, improving accuracy and providing explainable decisions.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArena Learning: Build Data Flywheel for LLMs Post-training via Simulated Chatbot Arena\n\n\n\nsocial-sciences\n\n\neducation\n\n\n\nArena Learning simulates AI battles for LLMs, improving performance via fine-tuning and reinforcement learning, as seen in WizardLM-ββ’s success.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCutting Through the Clutter: The Potential of LLMs for Efficient Filtration in Systematic Literature Reviews\n\n\n\nsocial-sciences\n\n\nrobustness\n\n\n\nLLMs like GPT-4o can significantly speed up literature filtering for reviews, reducing manual screening time from weeks to minutes, while maintaining high recall rates.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpider2-V: How Far Are Multimodal Agents From Automating Data Science and Engineering Workflows?\n\n\n\nproduction\n\n\narchitectures\n\n\n\nTL;DR: Spider2-V benchmark evaluates multimodal agents for data workflow automation, revealing current limitations.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinDKG: Dynamic Knowledge Graphs with Large Language Models for Detecting Global Trends in Financial Markets\n\n\n\nproduction\n\n\n\nLLMs generate dynamic knowledge graphs for strategic thematic investing, outperforming existing ETFs.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Model-based FMRI Encoding of Language Functions for Subjects with Neurocognitive Disorder\n\n\n\nsocial-sciences\n\n\n\nLLM-based fMRI encoding shows higher cognitive abilities linked to better brain scores in older NCD adults, with peak correlations in the middle temporal gyrus.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond Generative Artificial Intelligence: Roadmap for Natural Language Generation\n\n\n\nsocial-sciences\n\n\nprogramming\n\n\n\nTL;DR: This paper reviews recent NLG surveys to identify gaps in LLMs and suggest future research directions.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMMM: Multilingual Mutual Reinforcement Effect Mix Datasets & Test with Open-domain Information Extraction Large Language Models\n\n\n\nproduction\n\n\narchitectures\n\n\n\nNew multilingual dataset (MMM) for MRE research, aided by LLMs, boosts global exploration and enhances Open-domain Information Extraction Large Language Model (OIELLM)…\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultilingual Contrastive Decoding via Language-Agnostic Layers Skipping\n\n\n\nsocial-sciences\n\n\nprompt-engineering\n\n\nrobustness\n\n\narchitectures\n\n\n\nSkipLayerCD improves LLM’s reasoning in 11 languages by skipping bottom layers, addressing language mismatch in contrastive decoding.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM Circuit Analyses Are Consistent Across Training and Scale\n\n\n\nproduction\n\n\n\nCircuit analyses on small models can still apply after more pre-training and across model scale.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSibyl: Simple yet Effective Agent Framework for Complex Real-world Reasoning\n\n\n\narchitectures\n\n\n\nSibyl: A novel LLM-based agent framework for complex reasoning, outperforming existing agents and achieving state-of-the-art results on the GAIA benchmark.\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Makes and Breaks Safety Fine-tuning? Mechanistic Study\n\n\n\nsecurity\n\n\n\nSafety fine-tuning minimally alters LLM weights, clustering inputs as safe or unsafe, potentially misclassifying adversarial inputs.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-Granularity Semantic Revision for Large Language Model Distillation\n\n\n\nrobustness\n\n\neducation\n\n\n\nTL;DR: We propose a multi-granularity semantic revision method for LLM distillation, improving existing methods and reducing errors.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLAB-Bench: Measuring Capabilities of Language Models for Biology Research\n\n\n\nsocial-sciences\n\n\n\nLAB-Bench evaluates AI on practical biology research tasks, aiming to assist scientists in literature search and molecular cloning.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistillSeq: A Framework for Safety Alignment Testing in Large Language Models using Knowledge Distillation\n\n\n\nsecurity\n\n\neducation\n\n\nprogramming\n\n\nrobustness\n\n\n\nTL;DR: DistillSeq improves testing efficiency, boosting attack success rates by 93% on average across four LLMs.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBiasAlert: A Plug-and-play Tool for Social Bias Detection in LLMs\n\n\n\nsocial-sciences\n\n\n\nBiasAlert: A tool for detecting and evaluating social biases in LLM-generated text, outperforming existing methods and GPT-4.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenSco: Can Question Decomposition based Passage Alignment improve Question Answering?\n\n\n\neducation\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nTL;DR: GenSco selects passages for multi-hop QA, improving LLM answer generation and efficiency.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChatLogic: Integrating Logic Programming with Large Language Models for Multi-Step Reasoning\n\n\n\nhci\n\n\nprogramming\n\n\neducation\n\n\nprompt-engineering\n\n\n\nChatLogic enhances LLMs’ multi-step reasoning with logic programming, improving performance in deductive tasks.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRevolutionizing Bridge Operation and maintenance with LLM-based Agents: An Overview of Applications and Insights\n\n\n\nsocial-sciences\n\n\n\nAI agents revolutionize bridge O&M, offering challenges and opportunities for core tasks.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPractical Unlearning for Large Language Models\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nTL;DR: O3 framework offers practical LLM unlearning, handling continuous requests with minimal utility loss, and no retained data, outperforming existing methods.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTokenSHAP: Interpreting Large Language Models with Monte Carlo Shapley Value Estimation\n\n\n\nprompt-engineering\n\n\n\nTokenSHAP interprets LLMs by attributing importance to individual tokens, enhancing model transparency and reliability.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAll Roads Lead to Rome: Unveiling the Trajectory of Recommender Systems Across the LLM Era\n\n\n\nrecommender\n\n\n\nLLMs redefine recommender systems, improving effectiveness and reducing user cost, with focus on list-wise and conversational recommendations.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearning to Refuse: Towards Mitigating Privacy Risks in LLMs\n\n\n\nrobustness\n\n\n\nRETURN dataset and NAUF framework help LLMs unlearn personal data, preserving privacy without retraining.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLook Within, Why LLMs Hallucinate: A Causal Perspective\n\n\n\nrobustness\n\n\n\nDisabling certain self-attention layers in LLMs can reduce hallucination issues, offering a new approach to understanding and mitigating this problem.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemantic Understanding and Data Imputation using Large Language Model to Accelerate Recommendation System\n\n\n\nrecommender\n\n\n\nTL;DR: We use fine-tuned LLMs to impute missing data, improving recommendation system performance.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKey-Point-Driven Mathematical Reasoning Distillation of Large Language Model\n\n\n\nrobustness\n\n\neducation\n\n\nprompt-engineering\n\n\n\nTL;DR: KPDD method improves SLMs’ mathematical reasoning, reducing errors and enhancing deployment.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFollow the Rules: Reasoning for Video Anomaly Detection with Large Language Models\n\n\n\nrobustness\n\n\n\nAnomalyRuler: Rule-based Reasoning Framework for Video Anomaly Detection with LLMs.\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInvestigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024\n\n\n\nhci\n\n\n\nLLMs can predict political stances with 82% accuracy; expert-curated info boosts performance by 9%.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLynx: An Open Source Hallucination Evaluation Model\n\n\n\nrobustness\n\n\n\nLynx, a new hallucination detection model, outperforms others on the HaluBench benchmark, addressing LLM hallucinations.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrefCLM: Enhancing Preference-based Reinforcement Learning with Crowdsourced Large Language Models\n\n\n\nsocial-sciences\n\n\nhci\n\n\neducation\n\n\nprompt-engineering\n\n\n\nPrefCLM uses crowdsourced LLMs for preference-based robot learning, improving user satisfaction in HRI scenarios.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre Large Language Models Really Bias-Free? Jailbreak Prompts for Assessing Adversarial Robustness to Bias Elicitation\n\n\n\nsecurity\n\n\nsocial-sciences\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nLLMs, despite advancements, still exhibit biases from training data, impacting fairness and reliability. Prompt engineering can reveal hidden biases, emphasizing the need…\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn the (In)Security of LLM App Stores\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nStudy reveals security risks in LLM apps, including misleading descriptions, privacy violations, harmful content, and malware potential.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel Tells You Where to Merge: Adaptive KV Cache Merging for LLMs on Long-Context Tasks\n\n\n\nrobustness\n\n\n\nKVMerger: A novel KV cache merging approach for efficient LLM serving, reducing memory usage without significant performance loss.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs Your Model Really A Good Math Reasoner? Evaluating Mathematical Reasoning with Checklist\n\n\n\neducation\n\n\n\nLLMs’ math abilities are best tested with diverse tasks, not just problem-solving. MathCheck, a checklist tool, evaluates LLMs’ mathematical reasoning and robustness.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConverging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents\n\n\n\nhci\n\n\neducation\n\n\n\nRecent AI advancements, like LLMs, blend connectionist and symbolic AI, enhancing reasoning and decision-making in Autonomous Agents.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpeculative RAG: Enhancing Retrieval Augmented Generation through Drafting\n\n\n\neducation\n\n\n\nSpeculative RAG improves RAG performance by using a smaller LM for drafting and a larger LM for verification, reducing latency and enhancing accuracy.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTurn-Level Empathy Prediction Using Psychological Indicators\n\n\n\nsocial-sciences\n\n\n\nLLM-enhanced DeBERTA model improves empathy detection, ranking 7th in CONV-turn track.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRoboMorph: Evolving Robot Morphology using Large Language Models\n\n\n\nprompt-engineering\n\n\n\nRoboMorph: LLMs & evolutionary algorithms for optimizing modular robot designs.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Taxonomy for Data Contamination in Large Language Models\n\n\n\nrobustness\n\n\n\nContamination in pretraining data can inflate language model performance; understanding its impact on tasks like summarization and question answering is crucial.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDIDUP: Dynamic Iterative Development for UI Prototyping\n\n\n\nhci\n\n\nprogramming\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nTL;DR: DIDUP improves LLM-generated code-prototyping with adaptive planning, code injection, and lightweight state management for better UI prototyping.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating Large Language Models with Grid-Based Game Competitions: An Extensible LLM Benchmark and Leaderboard\n\n\n\nhci\n\n\neducation\n\n\nprompt-engineering\n\n\n\nThis study introduces a benchmark for LLMs using grid-based games, revealing variations in performance across different games and prompt types.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTactics, Techniques, and Procedures (TTPs) in Interpreted Malware: A Zero-Shot Generation with Large Language Models\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nGenTTP: AI-Powered Tool Extracts Tactics of Interpreted OSS Malware with High Accuracy.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeveraging LLMs to Predict Affective States via Smartphone Sensor Features\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs can predict affect outcomes using smartphone data, offering a new approach for digital mental health monitoring.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective\n\n\n\nprogramming\n\n\n\nMLLMs and data co-development: larger, better data improves MLLMs, which in turn aid data development. [Link to project]\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIncorporating Large Language Models into Production Systems for Enhanced Task Automation and Flexibility\n\n\n\neducation\n\n\n\nThis paper presents a novel approach to integrate LLMs into automated production systems, enhancing task automation and flexibility.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn the Universal Truthfulness Hyperplane Inside LLMs\n\n\n\nrobustness\n\n\n\nTL;DR: A universal truthfulness hyperplane may exist in LLMs, improving factual accuracy across diverse datasets.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReal-Time Anomaly Detection and Reactive Planning with Large Language Models\n\n\n\nsecurity\n\n\n\nThis work presents a two-stage framework for fast anomaly detection and safe control in robotic systems using language models, improving trustworthiness under resource and…\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\neyeballvul: a future-proof benchmark for vulnerability detection in the wild\n\n\n\nsecurity\n\n\nrobustness\n\n\n\n[TEXT] This study examines the impact of social media on the mental health of adolescents. Results indicate a significant correlation between excessive social media use and…\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Career Interests of Large Language Models\n\n\n\nsocial-sciences\n\n\nhci\n\n\neducation\n\n\n\nLLMs show social, artistic career interests, differing from high-competence areas, suggesting human-like tendencies and potential workforce roles.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSkywork-Math: Data Scaling Laws for Mathematical Reasoning in Large Language Models – The Story Goes On\n\n\n\neducation\n\n\n\nTL;DR: Skywork-Math model outperforms early GPT-4 on math tasks, highlighting data scaling’s impact on LLMs’ math reasoning abilities.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUncertainty Estimation of Large Language Models in Medical Question Answering\n\n\n\nrobustness\n\n\n\nLLMs in healthcare risk hallucination; current uncertainty estimation methods perform poorly. Proposed Two-phase Verification method improves accuracy and reliability…\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRB-SQL: A Retrieval-based LLM Framework for Text-to-SQL\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nRB-SQL improves text-to-SQL tasks with a retrieval-based framework for in-context prompt engineering, outperforming baselines on BIRD and Spider datasets.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn the attribution of confidence to large language models\n\n\n\nrobustness\n\n\n\nLLM credence attributions may be literal, plausible, but subject to skeptical concerns due to potentially non-truth-tracking experimental techniques.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(β\\)-DPO: Direct Preference Optimization with Dynamic \\(β\\)\n\n\n\nsocial-sciences\n\n\n\nDPO for LLMs improves with dynamic \\(\beta\\) calibration, enhancing performance and robustness.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVox Populi, Vox AI? Using Language Models to Estimate German Public Opinion\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs, like GPT-3.5, inaccurately predict German vote choice, favoring Green and Left parties, and missing individual voter factors.\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMAVIS: Mathematical Visual Instruction Tuning\n\n\n\nhci\n\n\neducation\n\n\nprompt-engineering\n\n\n\nMAVIS: New Paradigm for MLLMs Improves Math Problem-Solving in Visual Contexts\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGLBench: A Comprehensive Benchmark for Graph with Large Language Models\n\n\n\nhci\n\n\n\nTL;DR: GLBench evaluates GraphLLM methods, showing they outperform traditional baselines, but lack scaling laws and require both structure and semantics for zero-shot…\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCHOP: Integrating ChatGPT into EFL Oral Presentation Practice\n\n\n\nsocial-sciences\n\n\nhci\n\n\neducation\n\n\n\nChatGPT-based platform, CHOP, assists EFL students’ oral presentations with personalized feedback, offering strengths and areas for improvement.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNatural Language Mechanisms via Self-Resolution with Foundation Models\n\n\n\nsocial-sciences\n\n\n\nLMMs use natural language reports and LLMs to improve information aggregation, outperforming traditional mechanisms like prediction markets.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReview-LLM: Harnessing Large Language Models for Personalized Review Generation\n\n\n\nrecommender\n\n\nprompt-engineering\n\n\n\nReview-LLM customizes LLMs for personalized review generation, improving performance by incorporating user behavior, ratings, and SFT.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Comprehensive Survey on the Security of Smart Grid: Challenges, Mitigations, and Future Research Opportunities\n\n\n\nsecurity\n\n\n\nReview of smart grid security, focusing on attack vectors, coordinated attacks, and innovative defense strategies, including machine learning and future research directions.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Robust Alignment of Language Models: Distributionally Robustifying Direct Preference Optimization\n\n\n\nsocial-sciences\n\n\n\nThis study improves Direct Preference Optimization (DPO) for LLMs using Distributionally Robust Optimization (DRO), introducing Dr. DPO for better handling of noisy training…\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWorldAPIs: The World Is Worth How Many APIs? A Thought Experiment\n\n\n\nhci\n\n\n\nTL;DR: This paper proposes a framework to define APIs for versatile AI agents using wikiHow tutorials, inducing 300+ APIs for physical tasks.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFsPONER: Few-shot Prompt Optimization for Named Entity Recognition in Domain-specific Scenarios\n\n\n\nprompt-engineering\n\n\n\nLLM-based FsPONER outperforms fine-tuned models by 10% in F1 score for domain-specific NER tasks with data scarcity.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan ChatGPT Pass a Theory of Computing Course?\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nChatGPT struggles with complex math, but can pass a ToC course, excelling in simple questions but faltering in open-ended responses like proofs.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nControllable Navigation Instruction Generation with Chain of Thought Prompting\n\n\n\nprogramming\n\n\neducation\n\n\nprompt-engineering\n\n\n\nC-Instructor: LLM-based model for controllable, landmark-focused instruction generation with spatial understanding, outperforming previous methods.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArabic Automatic Story Generation with Large Language Models\n\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\nThis work generates Arabic stories from LLMs, using MT and GPT-4 data, achieving coherent results in MSA and Arabic dialects.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultilingual Blending: LLM Safety Alignment Evaluation with Language Mixture\n\n\n\nsecurity\n\n\nprompt-engineering\n\n\n\nTL;DR: Multilingual queries can bypass LLM safety measures, highlighting the need for multilingual safety alignment strategies.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey of Attacks on Large Vision-Language Models: Resources, Advances, and Future Trends\n\n\n\nsecurity\n\n\n\nTL;DR: This paper reviews various attacks on Large Vision-Language Models, discussing their development and future research directions.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAttribute or Abstain: Large Language Models as Long Document Assistants\n\n\n\nrobustness\n\n\n\nLLMs can improve long document work, but hallucinate. Attribution boosts trust; new benchmark LAB evaluates attribution in long documents, finding citation-based approach…\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProbability of Differentiation Reveals Brittleness of Homogeneity Bias in Large Language Models\n\n\n\nsocial-sciences\n\n\n\nLLMs’ homogeneity bias varies greatly with situation cues and prompts, suggesting encoder models may have introduced biases.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRectifier: Code Translation with Corrector via LLMs\n\n\n\nprogramming\n\n\nrobustness\n\n\n\nTL;DR: Rectifier model repairs errors in code translation by LLMs, improving accuracy and robustness.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVirtual Agents for Alcohol Use Counseling: Exploring LLM-Powered Motivational Interviewing\n\n\n\nhci\n\n\nprompt-engineering\n\n\n\nLLMs enable a virtual counselor for alcohol use, replicating human empathy and adaptability in motivational interviewing.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFACTS About Building Retrieval Augmented Generation-based Chatbots\n\n\n\nhci\n\n\n\nThis paper presents a framework (FACTS) for building secure, effective enterprise chatbots using RAG, with empirical results on LLM performance tradeoffs.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn LLM Wizards: Identifying Large Language Models’ Behaviors for Wizard of Oz Experiments\n\n\n\nhci\n\n\n\nTL;DR: This study explores using large language models as Wizards in WoZ experiments, providing methodology and evaluation for their role-playing ability.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFlooding Spread of Manipulated Knowledge in LLM-Based Multi-Agent Communities\n\n\n\nsecurity\n\n\nhci\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nLLM-based multi-agent systems are vulnerable to manipulated knowledge spread, posing security risks.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Proposed S.C.O.R.E. Evaluation Framework for Large Language Models : Safety, Consensus, Objectivity, Reproducibility and Explainability\n\n\n\nsocial-sciences\n\n\n\nProposed S.C.O.R.E. framework for evaluating LLMs in healthcare: Safety, Consensus, Objectivity, Reproducibility, and Explainability.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRAG vs. Long Context: Examining Frontier Large Language Models for Environmental Review Document Comprehension\n\n\n\neducation\n\n\n\nLLMs struggle with niche domains like NEPA; RAG models outperform long context models in answering accuracy.\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRichelieu: Self-Evolving LLM-Based Agents for AI Diplomacy\n\n\n\nhci\n\n\n\nAI explores its potential for complex diplomacy tasks, combining strategic planning, social reasoning, and self-play for memory augmentation.\n\n\n\nJul 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Pretrained Large Language Model with Prompt Engineering to Answer Biomedical Questions\n\n\n\nprompt-engineering\n\n\n\nTeam built a biomedical QA system using LLMs, achieving notable scores in BioASQ 2024 Task 12b.\n\n\n\nJul 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Large Language Models for Generating Smart Contracts for Health Insurance from Textual Policies\n\n\n\nprogramming\n\n\n\nLLMs can generate smart contracts from health insurance policies, but human oversight is needed for complex scenarios.\n\n\n\nJul 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nICLGuard: Controlling In-Context Learning Behavior for Applicability Authorization\n\n\n\nsecurity\n\n\n\nICLGuard controls ICL behavior in LLMs, allowing model owners to regulate ICL on specific data without affecting the model’s overall functionality.\n\n\n\nJul 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSafe-Embed: Unveiling the Safety-Critical Knowledge of Sentence Encoders\n\n\n\nsecurity\n\n\nprompt-engineering\n\n\n\nLLMs vulnerable to unsafe prompts; sentence encoders proposed as robust safety detectors. Code: https://github.com/JwdanielJung/Safe-Embed.\n\n\n\nJul 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFine-grained large-scale content recommendations for MSX sellers\n\n\n\nrecommender\n\n\n\nThis paper presents a content recommendation model for Microsoft sellers, using semantic matching to suggest relevant content for opportunities, achieving high accuracy in…\n\n\n\nJul 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConvNLP: Image-based AI Text Detection\n\n\n\nprogramming\n\n\n\nLLM-generated text detection using visual word embeddings and ZigZag ResNet improves generalization, with 88.35% detection rate and 2.5ms inference latency.\n\n\n\nJul 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChatGPT Doesn’t Trust Chargers Fans: Guardrail Sensitivity in Context\n\n\n\nhci\n\n\n\nGuardrails in GPT-3.5 show biases, favoring refusal for younger, female, and Asian-American personas, and aligning with inferred political ideologies, including sports…\n\n\n\nJul 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models\n\n\n\nprompt-engineering\n\n\n\nHypothetical Minds agent, leveraging LLMs, improves MARL performance in diverse domains, highlighting the value of hypothesis evaluation and refinement.\n\n\n\nJul 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOptimal Decision Making Through Scenario Simulations Using Large Language Models\n\n\n\nhci\n\n\n\nLLMs can now solve complex problems by requesting options, simulating outcomes, and optimizing solutions, enhancing their real-world utility.\n\n\n\nJul 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrompting Techniques for Secure Code Generation: A Systematic Investigation\n\n\n\nsecurity\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\nTL;DR: Study explores prompting techniques for secure code generation in LLMs, finding improvements with Recursive Criticism and Improvement (RCI).\n\n\n\nJul 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDivine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models\n\n\n\nhci\n\n\n\nLLMs exhibit biases in emotion attribution along religious lines, with major religions in the US and Europe being more nuanced, while Eastern religions are stereotyped and…\n\n\n\nJul 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInverseCoder: Unleashing the Power of Instruction-Tuned Code LLMs with Inverse-Instruct\n\n\n\neducation\n\n\nprogramming\n\n\n\nInverseCoder improves code LLMs by self-generating instructions, outperforming original models.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRetrieved In-Context Principles from Previous Mistakes\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nRICP improves LLM performance by learning from mistakes, enhancing error coverage and customization.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerative Debunking of Climate Misinformation\n\n\n\nsocial-sciences\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLMs can automatically debunk climate myths using the truth sandwich structure, with GPT-4 and Mixtral showing promising results.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs GPT-4 Alone Sufficient for Automated Essay Scoring?: A Comparative Judgment Approach Based on Rater Cognition\n\n\n\nsocial-sciences\n\n\neducation\n\n\n\nLLMs with Comparative Judgment outperform traditional rubric-based scoring in AES.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niLLM-TSC: Integration reinforcement learning and large language model for traffic signal control policy improvement\n\n\n\narchitectures\n\n\nproduction\n\n\n\nLLM-RL Integration Improves TSC, Reducing Wait Time by 17.5% in Degraded Communication.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\nproduction\n\n\nsecurity\n\n\n\nLLMs can be misled by false premises, causing factuality hallucination. We introduce an automated pipeline to create a large-scale benchmark for this issue.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCrowdMoGen: Zero-Shot Text-Driven Collective Motion Generation\n\n\n\nsocial-sciences\n\n\nproduction\n\n\n\nCrowdMoGen: Zero-shot text-driven framework for realistic crowd motion generation.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Human-LLM Conversations: Mental Models and the Originator of Toxicity\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs provide toxic content mainly due to human demand or provocation.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn Speeding Up Language Model Evaluation\n\n\n\narchitectures\n\n\nproduction\n\n\n\nTL;DR: Our approach reduces evaluation resources by 85-95% using multi-armed bandit algorithms and low-rank factorization.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen is the consistent prediction likely to be a correct prediction?\n\n\n\nprompt-engineering\n\n\n\nLLMs produce more accurate answers with longer, consistent reasoning, not just the most consistent answer. Longer responses are less likely, requiring length-based decoding…\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPAS: Data-Efficient Plug-and-Play Prompt Augmentation System\n\n\n\narchitectures\n\n\nsocial-sciences\n\n\nprompt-engineering\n\n\nproduction\n\n\n\nPAS is a plug-and-play AI system for prompt engineering, offering high performance, efficiency, and flexibility for LLMs.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization\n\n\n\nhci\n\n\nproduction\n\n\narchitectures\n\n\nsocial-sciences\n\n\neducation\n\n\n\nLLMs can extract data context but struggle with visual tasks, despite being sensitive to uncertainties in utterances.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat’s Wrong with Your Code Generated by Large Language Models? An Extensive Study\n\n\n\narchitectures\n\n\nrobustness\n\n\nprogramming\n\n\nproduction\n\n\n\nLLMs struggle with complex code, often producing shorter, more complicated code. A novel iterative method improves LLM-generated code, boosting passing rate by 29.2%.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodeUpdateArena: Benchmarking Knowledge Editing on API Updates\n\n\n\nprogramming\n\n\n\nTL;DR: CodeUpdateArena benchmark evaluates updating code LLMs with evolving API functions, highlighting challenges and room for improvement.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Optimizing and Evaluating a Retrieval Augmented QA Chatbot using LLMs with Human in the Loop\n\n\n\nproduction\n\n\n\nLLM-driven HR chatbot, enhanced with GPT-4, offers efficient, scalable HR support, aligning with human evaluation.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPsycoLLM: Enhancing LLM for Psychological Understanding and Evaluation\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nPsycoLLM: A Specialized Psychological LLM Outperforms Others in Mental Health Support.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAffordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\n\nAO-Planner: LLM-based framework for zero-shot VLN tasks, improves SPL by 5.5% on R2R-CE benchmark.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArtificial Intuition: Efficient Classification of Scientific Abstracts\n\n\n\narchitectures\n\n\nproduction\n\n\n\nNew method uses LLM to classify NASA abstracts, aiding strategic research insights.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistilling System 2 into System 1\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\nproduction\n\n\n\nDistilling System 2 techniques into System 1 improves LLM performance with less inference cost.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHecaton: Training and Finetuning Large Language Models with Scalable Chiplet Systems\n\n\n\narchitectures\n\n\n\nHecaton: A chiplet system for LLM training, reducing DRAM accesses and NoP overheads, offering 4.98× performance boost and 2.35× energy reduction.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Grammar Masking to Ensure Syntactic Validity in LLM-based Modeling Tasks\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\nproduction\n\n\n\nGrammar masking improves LLMs’ modeling, reducing reliance on prompting and increasing correct syntax chances.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLaMAX: Scaling Linguistic Horizons of LLM by Enhancing Translation Capabilities Beyond 100 Languages\n\n\n\narchitectures\n\n\nproduction\n\n\n\nLLMs struggle with low-resource languages. LLaMAX, a multilingual LLM, outperforms existing models in translation tasks across 100+ languages.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSub-SA: Strengthen In-context Learning via Submodular Selective Annotation\n\n\n\nprompt-engineering\n\n\n\nSub-SA is a submodular selective annotation method for ICL, reducing annotation costs and improving in-context example quality with millisecond-level time selection and…\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDepression Detection and Analysis using Large Language Models on Textual and Audio-Visual Modalities\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nAI models outperform traditional methods in diagnosing depression, achieving 71.43% accuracy and RMSE of 3.98 on textual modality.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMerge, Ensemble, and Cooperate! A Survey on Collaborative Strategies in the Era of Large Language Models\n\n\n\narchitectures\n\n\nproduction\n\n\n\nThis paper explores three strategies for collaborative large language models: merging, ensemble, and cooperation.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeneration and De-Identification of Indian Clinical Discharge Summaries using LLMs\n\n\n\nproduction\n\n\n\nDe-identification algorithms struggle in Indian healthcare; synthetic data can improve performance.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHyCIR: Boosting Zero-Shot Composed Image Retrieval with Synthetic Labels\n\n\n\narchitectures\n\n\nproduction\n\n\n\nHyCIR uses synthetic labels to improve zero-shot CIR performance, achieving SOTA results on CIRR and CIRCO benchmarks.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenFollower: Enhancing Car-Following Prediction with Large Language Models\n\n\n\nprompt-engineering\n\n\n\nGenFollower: LLM-based approach improves car-following behavior prediction and interpretability.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo Multilingual Large Language Models Mitigate Stereotype Bias?\n\n\n\nsocial-sciences\n\n\n\nMultilingual training in LLMs reduces bias and improves prediction accuracy compared to monolingual models.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(R^2\\)-Guard: Robust Reasoning Enabled LLM Guardrail via Knowledge-Enhanced Logical Reasoning\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nR2-Guard: Robust LLM guardrail via knowledge-enhanced reasoning, outperforms LlamaGuard by 30.2% on ToxicChat and 59.5% against jailbreak attacks.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-Based Open-Domain Integrated Task and Knowledge Assistants with Programmable Policies\n\n\n\nrobustness\n\n\n\nKITA outperforms GPT-4 in a user study, offering reliable, grounded responses and controllable agent policies for complex user interactions.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nANOLE: An Open, Autoregressive, Native Large Multimodal Models for Interleaved Image-Text Generation\n\n\n\narchitectures\n\n\nproduction\n\n\n\nAnole: Open, autoregressive LMM for interleaved image-text generation, addressing previous LMM limitations.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmpowering 1000 tokens/second on-device LLM prefilling with mllm-NPU\n\n\n\narchitectures\n\n\neducation\n\n\nproduction\n\n\n\nmllm-NPU: A system for fast, energy-efficient on-device LLM inference, achieving 22.4x faster prefill speed and 30.7x energy savings.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nT2VSafetyBench: Evaluating the Safety of Text-to-Video Generative Models\n\n\n\narchitectures\n\n\nrobustness\n\n\nsecurity\n\n\n\nT2VSafetyBench: New benchmark for assessing text-to-video model safety risks, highlighting no single model excels in all aspects and a trade-off between usability and safety.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Loops to Oops: Fallback Behaviors of Language Models Under Uncertainty\n\n\n\nrobustness\n\n\n\nLLMs’ fallback behaviors shift from repetitions to degenerate text to hallucinations with model advancement and increasing uncertainty. Common decoding techniques may reduce…\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmpirical Study of Symmetrical Reasoning in Conversational Chatbots\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nChatbots show varied ability to understand predicate symmetry, with some nearing human-like reasoning.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Language Model Rationality with Bi-Directional Deliberation Reasoning\n\n\n\nprompt-engineering\n\n\n\nBIDDER enhances LLM decision-making with bi-directional reasoning, considering past and future contexts, improving rationality in poker and negotiation scenarios.\n\n\n\nJul 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExperiments with truth using Machine Learning: Spectral analysis and explainable classification of synthetic, false, and genuine information\n\n\n\nsocial-sciences\n\n\n\nLLMs contribute to misinformation; ML algorithms struggle to distinguish fake from genuine text.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCollective Innovation in Groups of Large Language Models\n\n\n\nsocial-sciences\n\n\neducation\n\n\nhci\n\n\n\nLLMs playing a video game show collective innovation, with dynamic connectivity boosting performance.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the Educational Landscape of AI: Large Language Models’ Approaches to Explaining Conservation of Momentum in Physics\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLMs vary in explaining physics concepts; educator guidance crucial for effective use in teaching.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions\n\n\n\nsocial-sciences\n\n\n\nLLMs excel in binary gender prediction but struggle with gender-neutral names, especially non-English ones; birth year data doesn’t improve accuracy.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssessing Code Generation with Intermediate Languages\n\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\n[TEXT] Abstract: This study examines the relationship between CEO narcissism and firm performance. Results indicate that narcissistic CEOs are associated with lower firm…\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFaux Polyglot: A Study on Information Disparity in Multilingual Large Language Models\n\n\n\nsocial-sciences\n\n\n\nLLMs in RAG-based search favor same-language info, reinforcing dominant views and potentially marginalizing low-resource languages.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCLIMB: A Benchmark of Clinical Bias in Large Language Models\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs in clinical tasks exhibit bias; CLIMB benchmark introduced to evaluate intrinsic and extrinsic bias.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Model as an Assignment Evaluator: Insights, Feedback, and Challenges in a 1000+ Student Course\n\n\n\nrobustness\n\n\neducation\n\n\n\nLLM-based evaluators, like GPT-4, can be used in classrooms, but students can manipulate them and they may not always follow instructions.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Hallucination Detection through Perturbation-Based Synthetic Data Generation in System Responses\n\n\n\nrobustness\n\n\n\nAutomatic generation of faithful/hallucinated outputs improves LLM hallucination detection.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Computer Programming Education with LLMs: A Study on Effective Prompt Engineering for Python Code Generation\n\n\n\neducation\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\nLLMs, like GPT-4o, excel in programming education with tailored prompt strategies, offering personalized instruction and improved learning outcomes.\n\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMCloudHunter: Harnessing LLMs for Automated Extraction of Detection Rules from Cloud-Based CTI\n\n\n\nsecurity\n\n\n\nLLMCloudHunter: Automated OSCTI analysis for cloud threats, using LLMs for high-precision rule generation.\n\n\n\nJul 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHarnessing the Power of LLMs: Automating Unit Test Generation for High-Performance Computing\n\n\n\nrobustness\n\n\nprogramming\n\n\n\nLLMs like Davinci and ChatGPT can generate syntactically correct unit tests for parallel and high-performance software, but may have limitations like repetitive assertions…\n\n\n\nJul 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSingle Character Perturbations Break LLM Alignment\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nAdding a space to prompts can bypass safety measures in language models, causing harmful outputs.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts\n\n\n\nprogramming\n\n\n\nTheoremLlama: LLM framework for formal theorem proving outperforms GPT-4.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScreenTK: Seamless Detection of Time-Killing Moments Using Continuous Mobile Screen Text Monitoring\n\n\n\nrobustness\n\n\n\nScreenTK detects time-killing moments on smartphones using continuous screen text monitoring and on-device large language models, outperforming current methods.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow Does Quantization Affect Multilingual LLMs?\n\n\n\nsocial-sciences\n\n\n\nQuantization harms multilingual LLMs, especially non-Latin script languages and complex tasks, despite automatic metrics underestimating the impact.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCactus: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory\n\n\n\nhci\n\n\nprompt-engineering\n\n\n\nCamel model, trained on Cactus dataset, outperforms others in counseling skills, ensuring privacy and accessibility.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLoRA-Guard: Parameter-Efficient Guardrail Adaptation for Content Moderation of Large Language Models\n\n\n\nrobustness\n\n\n\nLoRA-Guard: Efficient, On-Device Content Moderation for LLMs with Minimal Performance Impact.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nLLMs show potential for epilepsy diagnosis, but pitfalls like overconfidence and hallucinations exist.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFSM: A Finite State Machine Based Zero-Shot Prompting Paradigm for Multi-Hop Question Answering\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nFSM prompting enhances LLMs’ reasoning, improving accuracy and trustworthiness in complex tasks, mitigating hallucination, and easing answer interpretation.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output\n\n\n\neducation\n\n\n\nIXC-2.5: 7B LLM model excels in long-context text-image tasks, outperforming open-source SOTA models on 16 benchmarks.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel-Enhanced LLM-Driven VUI Testing of VPA Apps\n\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nElevate, a VUI testing framework, uses LLMs for better natural language processing, improving state space coverage and efficiency compared to Vitas.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSafe Unlearning: A Surprisingly Effective and Generalizable Solution to Defend Against Jailbreak Attacks\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nTL;DR: Unlearning harmful knowledge in LLMs effectively defends against jailbreak attacks, outperforming traditional fine-tuning methods.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMG-Verilog: Multi-grained Dataset Towards Enhanced LLM-assisted Verilog Generation\n\n\n\nprogramming\n\n\n\nLLMs aid hardware design, but datasets are limited. New criteria for high-quality hardware datasets proposed, along with a Multi-Grained-Verilog dataset and a balanced…\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideo Watermarking: Safeguarding Your Video from (Unauthorized) Annotations by Video-based LLMs\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nVideo Watermarking secures video content from unauthorized annotations by video-based LLMs, preserving integrity and confidentiality.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRaw Text is All you Need: Knowledge-intensive Multi-turn Instruction Tuning for Large Language Model\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nR2S framework uses CoD logic to guide LLMs in generating knowledge-intensive dialogues for instruction tuning, enhancing LLM adaptability and effectiveness.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models as Evaluators for Scientific Synthesis\n\n\n\nprogramming\n\n\n\nLLMs can logically rate scientific summaries but weakly correlate with human ratings, indicating potential and limitations in evaluation.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models\n\n\n\nprompt-engineering\n\n\n\nDCoT method improves LLM performance by comparing multiple reasoning chains, enabling self-correction.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models\n\n\n\nhci\n\n\neducation\n\n\n\nGraCoRe benchmark evaluates LLMs’ graph comprehension and reasoning, revealing insights on semantic enrichment, node ordering, and text length impact.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCogErgLLM: Exploring Large Language Model Systems Design Perspective Using Cognitive Ergonomics\n\n\n\nhci\n\n\n\nIntegrate cognitive ergonomics in LLM design for safer, reliable, and ethical human-AI interactions.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSocial Bias Evaluation for Large Language Models Requires Prompt Variations\n\n\n\nrobustness\n\n\nsocial-sciences\n\n\nhci\n\n\nprompt-engineering\n\n\n\nLLMs’ performance and bias vary greatly with prompts; diverse prompts are recommended for accurate comparison.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLANE: Logic Alignment of Non-tuning Large Language Models and Online Recommendation Systems for Explainable Reason Generation\n\n\n\nrecommender\n\n\n\nLANE strategy aligns LLMs with recommendation systems, improving explainability without additional tuning.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the Capabilities of LLMs for Code Change Related Tasks\n\n\n\neducation\n\n\nprogramming\n\n\n\nLLMs struggle with code-change tasks, but improve with examples. Larger models aren’t always better, but Llama 2 and Code Llama are top performers.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet the Code LLM Edit Itself When You Edit the Code\n\n\n\nrobustness\n\n\nprogramming\n\n\n\nPIE reduces 85% computational overhead in real-time code editing, maintaining model performance.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSOS! Soft Prompt Attack Against Open-Source Large Language Models\n\n\n\nrobustness\n\n\nprogramming\n\n\nsecurity\n\n\n\nNew attack, SOS, targets open-source LLMs, maintaining model utility. Also introduces copyright token for content protection.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJailbreakHunter: A Visual Analytics Approach for Jailbreak Prompts Discovery from Large-Scale Human-LLM Conversational Datasets\n\n\n\nrobustness\n\n\nhci\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nJailbreakHunter: A visual analytics approach to identify LLM jailbreak prompts in large-scale conversational datasets.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Comparative Study of DSL Code Generation: Fine-Tuning vs. Optimized Retrieval Augmentation\n\n\n\nrobustness\n\n\nprogramming\n\n\n\nLLMs struggle with DSLs, but optimized RAG models can match fine-tuned models and handle new APIs better.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM Internal States Reveal Hallucination Risk Faced With a Query\n\n\n\nrobustness\n\n\n\nLLMs can estimate their own hallucination risk before response generation, achieving 84.32% accuracy.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-Evaluation as a Defense Against Adversarial Attacks on LLMs\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nAdding a space to prompts can bypass safety measures in language models, causing harmful outputs.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObfuscaTune: Obfuscated Offsite Fine-tuning and Inference of Proprietary LLMs on Private Datasets\n\n\n\nsecurity\n\n\n\nObfuscaTune: A method for private LLM finetuning on cloud, preserving utility and confidentiality.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre Large Language Models Consistent over Value-laden Questions?\n\n\n\nrobustness\n\n\neducation\n\n\n\nLLMs show consistency across paraphrases, use-cases, and translations, but inconsistencies remain, especially on controversial topics.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Affects the Stability of Tool Learning? An Empirical Study on the Robustness of Tool Learning Frameworks\n\n\n\nrobustness\n\n\neducation\n\n\n\nTool learning in LLMs varies by factors like tasks, data, and algorithms. Exploring these impacts can improve LLM integration in real-world applications.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Conversational Abilities of Quantized Large Language Models via Direct Preference Alignment\n\n\n\neducation\n\n\nhci\n\n\n\nQDPO improves quantized LLMs’ conversational abilities, outperforming PTQ and knowledge-distillation fine-tuning techniques.\n\n\n\nJul 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Visual Storytelling with Multimodal Large Language Models\n\n\n\neducation\n\n\nhci\n\n\n\nThis paper presents a novel approach using LLMs and LVLMs with instruction tuning for generating coherent and emotionally resonant visual stories, outperforming existing…\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention\n\n\n\nprompt-engineering\n\n\n\nMInference speeds up LLM pre-filling by 10x, maintaining accuracy via sparse calculation methods for long-context attention matrices.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs Your AI-Generated Code Really Secure? Evaluating Large Language Models on Secure Code Generation with CodeSecEval\n\n\n\nrobustness\n\n\nprogramming\n\n\nsecurity\n\n\n\nLLMs for code generation/repair risk security vulnerabilities. This study evaluates and enhances their security, introducing CodeSecEval dataset and strategies to mitigate…\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Alignment in Multimodal LLMs: A Comprehensive Study\n\n\n\nrobustness\n\n\n\nTL;DR: Combining offline and online methods improves MLLMs, BDHS aids multimodal preference data creation.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the Role of Transliteration in In-Context Learning for Low-resource Languages Written in Non-Latin Scripts\n\n\n\nprompt-engineering\n\n\n\nTransliteration can improve LLMs’ performance for low-resource, non-Latin languages, especially in sequential labeling tasks.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification\n\n\n\nprompt-engineering\n\n\n\nPelican framework reduces LVLMs’ hallucinations by 8-32% via claim verification, outperforming existing mitigation approaches.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRVISA: Reasoning and Verification for Implicit Sentiment Analysis\n\n\n\nprompt-engineering\n\n\n\nRVISA: A two-stage framework for implicit sentiment analysis using LLMs, achieving state-of-the-art results.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultilingual Trolley Problems for Language Models\n\n\n\nhci\n\n\n\nLLMs’ moral decisions vary by language; more aligned with English, Korean, Hungarian, and Chinese, less with Hindi and Somali. Fairness dominates GPT-4’s choices…\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTalking to Machines: do you read me?\n\n\n\neducation\n\n\nhci\n\n\n\n[TEXT] Abstract: This study examines the impact of social media on the mental health of adolescents. Results indicate a significant correlation between excessive social…\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSupporters and Skeptics: LLM-based Analysis of Engagement with Mental Health (Mis)Information Content on Video-sharing Platforms\n\n\n\nhci\n\n\n\nStudy finds mental health misinformation on YouTube Shorts and Bitchute, with distinct audience engagement patterns and potential harm to public health.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmbodied AI in Mobile Robots: Coverage Path Planning with Large Language Models\n\n\n\nprogramming\n\n\n\nLLM-based path planning framework for mobile agents improves spatial inference and coverage planning, with claude-3.5 showing the best performance.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerative Monoculture in Large Language Models\n\n\n\nhci\n\n\nprogramming\n\n\n\nGenerative Monoculture in LLMs narrows output diversity, potentially limiting perspectives; simple countermeasures insufficient, suggesting need for diverse fine-tuning…\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBreaking Bias, Building Bridges: Evaluation and Mitigation of Social Biases in LLMs via Contact Hypothesis\n\n\n\nhci\n\n\n\nLLMs exhibit social biases, but a new debiasing technique, Social Contact Debiasing (SCD), can reduce these biases by up to 40% in one epoch of instruction tuning.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGRASP: A Grid-Based Benchmark for Evaluating Commonsense Spatial Reasoning\n\n\n\neducation\n\n\n\nLLMs like GPT-3.5-Turbo and GPT-4o struggle with satisfactory solutions in spatial reasoning tasks, as shown by the GRASP benchmark.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSynthetic Multimodal Question Generation\n\n\n\nhci\n\n\n\nSMMQG generates style-specific MMRAG questions from multimodal documents, rivaling human-generated data quality.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKGym: A Platform and Dataset to Benchmark Large Language Models on Linux Kernel Crash Resolution\n\n\n\nprogramming\n\n\n\nLLMs struggle with Linux kernel crashes, achieving 0.72%-5.38% success. Further research needed for SE tasks.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSoP: Unlock the Power of Social Facilitation for Automatic Jailbreak Attack\n\n\n\nsecurity\n\n\n\nSoP framework generates jailbreak prompts, bypassing GPT-3.5 and GPT-4 safety with 88% and 60% success, respectively.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt during Large Language Model Fine-tuning\n\n\n\nprompt-engineering\n\n\n\nPromptIntern: LLM method reduces inference tokens by 90%, speeds up inference 4.2x, and saves 88.3% monetary cost.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Steering and Verification in AI-Assisted Data Analysis with Interactive Task Decomposition\n\n\n\neducation\n\n\n\nStepwise, Phasewise systems offer better control, intervention, and verification in AI-assisted data analysis, compared to conversational baselines.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHelpful assistant or fruitful facilitator? Investigating how personas affect language model behavior\n\n\n\nhci\n\n\neducation\n\n\n\nPersonas in LLMs cause more varied responses than control, with some behaviors consistent across models.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCFinBench: A Comprehensive Chinese Financial Benchmark for Large Language Models\n\n\n\neducation\n\n\n\nTL;DR: CFinBench evaluates financial knowledge of LLMs in Chinese context, revealing a 60.16% highest average accuracy.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCEB: Compositional Evaluation Benchmark for Fairness in Large Language Models\n\n\n\nhci\n\n\n\nCEB: A Comprehensive Benchmark for Evaluating Bias in Large Language Models.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nS2D: Sorted Speculative Decoding For More Efficient Deployment of Nested Large Language Models\n\n\n\nhci\n\n\n\nTL;DR: New method improves speculative decoding for multiple large language models, reducing costs.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogEval: A Comprehensive Benchmark Suite for Large Language Models In Log Analysis\n\n\n\neducation\n\n\nhci\n\n\n\n[TEXT] This study examines the impact of climate change on the migration patterns of polar bears in the Arctic. Results indicate that as sea ice diminishes, polar bears are…\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssessing the Code Clone Detection Capability of Large Language Models\n\n\n\nrobustness\n\n\nprogramming\n\n\n\nGPT-4 outperforms GPT-3.5 in code clone detection, but both struggle with complex clones and human-generated code. Improvements are needed for LLM code clone recognition.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLEXI: Large Language Models Experimentation Interface\n\n\n\nhci\n\n\n\nLEXI, a new open-source tool, simplifies deploying LLM-powered agents in social interaction experiments, with positive usability testing results.\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond Numeric Awards: In-Context Dueling Bandits with LLM Agents\n\n\n\nsecurity\n\n\n\nLLMs, like GPT-4 Turbo, excel in identifying Condorcet winners in Dueling Bandits, but struggle with convergence. An LLM-augmented algorithm, IF-Enhanced LLM, improves…\n\n\n\nJul 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTCSR-SQL: Towards Table Content-aware Text-to-SQL with Self-retrieval\n\n\n\nprogramming\n\n\n\nTL;DR: TCSR-SQL improves Text-to-SQL performance by 13.7% with self-retrieval and in-context learning.\n\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMIRAI: Evaluating LLM Agents for Event Forecasting\n\n\n\nprogramming\n\n\n\nMirai benchmark evaluates LLM agents’ forecasting skills for international events, assessing their ability to source, integrate, and reason with diverse information.\n\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscoveryBench: Towards Data-Driven Discovery with Large Language Models\n\n\n\nprogramming\n\n\n\nLLMs struggle with autonomous data-driven discovery, scoring only 25% on the DiscoveryBench benchmark.\n\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-Cognition in Large Language Models: An Exploratory Study\n\n\n\nhci\n\n\n\nLLMs like Command R and Llama-3-70b-Instruct show detectable self-cognition, which improves tasks like creative writing.\n\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Multilingual Instruction Finetuning via Linguistically Natural and Diverse Datasets\n\n\n\neducation\n\n\nprogramming\n\n\n\nNew method for multilingual IFT datasets improves LLM performance in non-English contexts, boosting summarization by up to 17.57%.\n\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAgentless: Demystifying LLM-based Software Engineering Agents\n\n\n\nprogramming\n\n\n\nAgentless, a simple two-phase LLM approach, outperforms complex software agents in solving software development problems, offering higher performance and lower cost.\n\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJump Starting Bandits with LLM-Generated Prior Knowledge\n\n\n\nrecommender\n\n\nproduction\n\n\n\nLLMs improve contextual bandits in recommendation systems, reducing regret and data-gathering costs.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan we teach language models to gloss endangered languages?\n\n\n\nsocial-sciences\n\n\n\nLLMs can generate interlinear glossed text with in-context learning, outperforming transformer baselines without training, but still lag behind supervised systems.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAligning Teacher with Student Preferences for Tailored Training Data Generation\n\n\n\narchitectures\n\n\neducation\n\n\nprompt-engineering\n\n\n\nARTE: A framework aligning teacher models with student preferences for tailored training examples in Knowledge Distillation.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssessing the Effectiveness of LLMs in Android Application Vulnerability Analysis\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nLLMs’ strengths and weaknesses in detecting Android code vulnerabilities are analyzed, highlighting the potential of context augmentation with RAG for secure app development.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale\n\n\n\nproduction\n\n\n\nPubMedVision dataset improves medical multimodal capabilities of MLLMs, outperforming other data construction methods.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLayoutCopilot: An LLM-powered Multi-agent Collaborative Framework for Interactive Analog Layout Design\n\n\n\nhci\n\n\nprompt-engineering\n\n\neducation\n\n\n\n[TEXT] The Impact of Social Media on College Students’ Academic Performance: A Review of Literature [TL;DR] Social media negatively affects college students’ academic…\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Weak-to-Strong Generalization with Reliability-Aware Alignment\n\n\n\narchitectures\n\n\n\nApproach improves weak-to-strong generalization in LLMs by estimating weak supervision reliability, reducing error propagation, and enhancing accuracy.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCapturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nRPLMs enhanced with personality data improve role-playing abilities in dialogue.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSonnet or Not, Bot? Poetry Evaluation for Large Models and Datasets\n\n\n\neducation\n\n\nsocial-sciences\n\n\n\nLLMs can recognize poetic form, but challenges remain in evaluating their poetic capabilities and creating NLP benchmarks for poetry.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDisentangling Knowledge-based and Visual Reasoning by Question Decomposition in KB-VQA\n\n\n\nhci\n\n\neducation\n\n\n\nDecomposing complex questions into simpler ones improves visual question-answering performance, boosting accuracy by up to 2% on three datasets.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Model Arena for Cross-lingual Sentiment Analysis: A Comparative Study in the Era of Large Language Models\n\n\n\nhci\n\n\nproduction\n\n\nsocial-sciences\n\n\n\nSMLMs outperform LLMs in zero-shot cross-lingual sentiment analysis, but LLMs improve in few-shot settings. Proprietary GPT models excel in zero-shot, but lag in few-shot…\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFFN: a Fine-grained Chinese-English Financial Domain Parallel Corpus\n\n\n\neducation\n\n\n\nLLMs’ financial translation quality is evaluated, revealing room for improvement and optimization.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEfficient course recommendations with T5-based ranking and summarization\n\n\n\narchitectures\n\n\nrecommender\n\n\neducation\n\n\n\nT5-based re-ranking and summarization improve course recommendation relevance, but speed and interpretability also matter in online evaluation.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhysioLLM: Supporting Personalized Health Insights with Wearables and Large Language Models\n\n\n\nproduction\n\n\n\nPhysioLLM uses LLMs to analyze wearable data, offering personalized health insights and actionable goals, outperforming commercial health apps in a sleep quality case study.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMethodology of Adapting Large English Language Models for Specific Cultural Contexts\n\n\n\nsocial-sciences\n\n\n\nLLMs adapted for specific cultures, like Chinese, improve domain knowledge and safety values without losing expertise.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutoPureData: Automated Filtering of Web Data for LLM Fine-tuning\n\n\n\narchitectures\n\n\nproduction\n\n\n\nSystem filters web data for AI training, ensuring purity and reliability.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimulating Classroom Education with LLM-Empowered Agents\n\n\n\neducation\n\n\nprompt-engineering\n\n\nhci\n\n\narchitectures\n\n\nsocial-sciences\n\n\n\nLLMs can simulate classroom interactions, improving user experience in a multi-agent framework, as demonstrated by SimClass.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAMBROSIA: A Benchmark for Parsing Ambiguous Questions into Database Queries\n\n\n\narchitectures\n\n\n\nAMBROSIA benchmark tests LLMs on interpreting ambiguous text-to-SQL queries, revealing challenges for advanced models.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRevealing Fine-Grained Values and Opinions in Large Language Models\n\n\n\nhci\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nTL;DR: Analyzing 156k LLM responses to PCT reveals biases, disparities, and recurring text patterns influenced by prompts and demographic features.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models\n\n\n\nprompt-engineering\n\n\n\nLLMs can excel in low-resource languages with Self-Supervised Prompting, a novel ICL approach for zero-label cross-lingual transfer.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTools Fail: Detecting Silent Errors in Faulty Tools\n\n\n\narchitectures\n\n\nproduction\n\n\n\nLLMs can detect silent tool errors and plan better, improving their use as tools.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLiveBench: A Challenging, Contamination-Free LLM Benchmark\n\n\n\narchitectures\n\n\nproduction\n\n\nsocial-sciences\n\n\nrobustness\n\n\n\nLiveBench: A dynamic, contamination-free LLM benchmark with diverse tasks and automatic scoring.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUniGen: A Unified Framework for Textual Dataset Generation Using Large Language Models\n\n\n\narchitectures\n\n\n\nUniGen: LLM-powered framework for diverse, accurate, and controllable dataset generation, enhancing data quality and supporting benchmarking, data augmentation.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nELCoRec: Enhance Language Understanding with Co-Propagation of Numerical and Categorical Features for Recommendation\n\n\n\nrecommender\n\n\nhci\n\n\nprompt-engineering\n\n\neducation\n\n\n\nTL;DR: ELCoRec enhances language models for recommendation by co-propagating numerical and categorical features, improving preference understanding and recent interest…\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFairness and Bias in Multimodal AI: A Survey\n\n\n\nsocial-sciences\n\n\n\nTL;DR: This survey highlights fairness and bias in Large Multimodal Models, offering 50 examples and discussing challenges, including a new preuse bias category.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data\n\n\n\narchitectures\n\n\nproduction\n\n\n\nFinetuning LLMs on synthetic data enhances their long-context information retrieval and reasoning skills, with minimal impact on general benchmark performance.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHierarchical Context Pruning: Optimizing Real-World Code Completion with Repository-Level Pretrained Code LLMs\n\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\nHCP strategy improves Code LLMs’ accuracy by pruning irrelevant code, reducing input length.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSubtractive Training for Music Stem Insertion using Latent Diffusion Models\n\n\n\nproduction\n\n\n\n[TEXT] This study examines the impact of climate change on the frequency and intensity of hurricanes in the Atlantic Ocean. Results suggest a significant increase in both…\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Remarkable Robustness of LLMs: Stages of Inference?\n\n\n\narchitectures\n\n\nproduction\n\n\n\nTL;DR: Large Language Models remain accurate despite deleting or swapping layers, suggesting four universal inference stages.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?\n\n\n\nproduction\n\n\n\nModel editing in language models critiqued, 12 open problems identified, semi-synthetic dataset proposed for evaluation.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOMG-LLaVA: Bridging Image-level, Object-level, Pixel-level Reasoning and Understanding\n\n\n\neducation\n\n\nprompt-engineering\n\n\nhci\n\n\narchitectures\n\n\nproduction\n\n\n\nOMG-LLaVA: A framework for pixel-level vision understanding with reasoning abilities, accepting visual and text prompts.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation\n\n\n\nproduction\n\n\nsecurity\n\n\nrobustness\n\n\n\nRAG systems’ security is explored using Membership Inference Attacks, achieving 82% ROC AUC in identifying database membership.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nContrastive Policy Gradient: Aligning LLMs on sequence-level scores in a supervised-friendly fashion\n\n\n\narchitectures\n\n\n\nCoPG: A new RL algorithm for off-policy policy gradient, optimizing LLMs with arbitrary rewards, and generalizing IPO and classic policy gradient.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmPO: Theory-Driven Dataset Construction for Empathetic Response Generation through Preference Optimization\n\n\n\narchitectures\n\n\nrecommender\n\n\nhci\n\n\n\nTL;DR: We propose a novel approach for empathetic response generation using LLMs and preference optimization, with public datasets and models.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nT-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings\n\n\n\narchitectures\n\n\n\nT-Free: A novel tokenizer for LLMs, reducing parameters by 85% and improving cross-lingual transfer, without needing a reference corpus.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSTBench: Assessing the Ability of Large Language Models in Spatio-Temporal Analysis\n\n\n\narchitectures\n\n\neducation\n\n\nprompt-engineering\n\n\n\nSTBench evaluates LLMs’ spatio-temporal understanding across 13 tasks, revealing strengths and areas for improvement.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions\n\n\n\neducation\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nDiVERT outperforms state-of-the-art distractor generation methods in math MCQs, using a 7B parameter LLM and producing human-like error labels.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFine-tuned network relies on generic representation to solve unseen cognitive task\n\n\n\narchitectures\n\n\n\nFine-tuned models rely on pretrained representations, while scratch-trained models develop task-specific mechanisms.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation\n\n\n\narchitectures\n\n\nproduction\n\n\n\nAutoRAG-HP optimizes RAG hyper-parameters using a novel Hierarchical MAB method, reducing LLM API calls by 80% compared to Grid Search.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLICO: Large Language Models for In-Context Molecular Optimization\n\n\n\nprompt-engineering\n\n\n\nLICO enhances LLMs for black-box optimization, excelling in molecular property optimization via in-context prompting.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Teacher Is Worth A Million Instructions\n\n\n\narchitectures\n\n\n\nImproved training method for smaller LLMs using larger models and domain-specific knowledge, outperforming larger models.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApplying LLMs for Rescoring N-best ASR Hypotheses of Casual Conversations: Effects of Domain Adaptation and Context Carry-over\n\n\n\narchitectures\n\n\n\nLLMs like Llama2 improve ASR in casual conversations, even without domain adaptation, and reduce computational cost with adaptation.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuri: Multi-constraint Instruction Following for Long-form Text Generation\n\n\n\narchitectures\n\n\nproduction\n\n\n\nSuri-I-ORPO generates longer, coherent, and preferred long-form texts from complex instructions, outperforming base models.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAveraging log-likelihoods in direct alignment\n\n\n\narchitectures\n\n\nsocial-sciences\n\n\n\nDirect alignment methods for LLMs are made length-invariant, improving alignment with human judgment.\n\n\n\nJun 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Data Privacy in Large Language Models through Private Association Editing\n\n\n\nrobustness\n\n\n\nPAE: A novel defense for LLMs to remove private data without retraining, ensuring data privacy and model consistency.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLLMs as evaluation metrics: Large-scale prompt exploration reveals stability and variability in MT and summarization tasks.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSEED: Accelerating Reasoning Tree Construction via Scheduled Speculative Decoding\n\n\n\nprompt-engineering\n\n\n\nSeeD optimizes LLMs for complex reasoning, offering faster inference and efficient GPU memory management.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn Empirical Study of Unit Test Generation with Large Language Models\n\n\n\neducation\n\n\nprompt-engineering\n\n\nrobustness\n\n\n\nTL;DR: Study explores open-source LLMs for unit test generation, comparing them to commercial GPT-4 and traditional Evosuite, highlighting prompt factors and limitations.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFew-shot Personalization of LLMs with Mis-aligned Responses\n\n\n\nprompt-engineering\n\n\n\nFermi: New approach for few-shot personalization of LLMs using mis-aligned responses, improving performance across benchmarks.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-Driven Multimodal Opinion Expression Identification\n\n\n\nsocial-sciences\n\n\n\nThis study enhances Opinion Expression Identification (OEI) with multimodal inputs, improving performance and achieving state-of-the-art results.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLifelong Robot Library Learning: Bootstrapping Composable and Generalizable Skills for Embodied Control with Language Models\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLRLL: LLM-based agent grows robot skill library for complex tasks, outperforming end-to-end and vanilla LLM approaches.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNew intelligent empowerment for digital transformation\n\n\n\nsocial-sciences\n\n\n\nTL;DR: Study uses LLMs to evaluate DT in firms, finds it boosts financial performance, but effects vary by technology. Blockchain has limited impact.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMALSIGHT: Exploring Malicious Source Code and Benign Pseudocode for Iterative Binary Malware Summarization\n\n\n\nprogramming\n\n\nsecurity\n\n\n\nMalsight, a novel code summarization framework, generates malware behavior descriptions from executables, improving usability, accuracy, and completeness. It outperforms…\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFactFinders at CheckThat! 2024: Refining Check-worthy Statement Detection with LLMs through Data Pruning\n\n\n\nprogramming\n\n\n\nThis study explores using open-source LLMs to identify check-worthy political statements, proposing a data pruning approach for efficient learning.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHuman-AI Collaborative Taxonomy Construction: A Case Study in Profession-Specific Writing Assistants\n\n\n\nhci\n\n\n\nLLMs’ effectiveness in business writing is limited. Proposed: human-AI collaborative taxonomy development for domain-specific writing assistants.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRole-Play Zero-Shot Prompting with Large Language Models for Open-Domain Human-Machine Conversation\n\n\n\nhci\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nTL;DR: Role-play zero-shot prompting improves open-domain conversation in LLMs, surpassing fine-tuned models in French.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssertionBench: A Benchmark to Evaluate Large-Language Models for Assertion Generation\n\n\n\nprompt-engineering\n\n\nsecurity\n\n\nrobustness\n\n\n\nLLMs evaluated for hardware assertion generation; benchmark used for quantitative comparison.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdversarial Search Engine Optimization for Large Language Models\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nAttackers can manipulate LLMs to favor their content, degrading overall LLM performance.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWildTeaming at Scale: From In-the-Wild Jailbreaks to (Adversarially) Safer Language Models\n\n\n\nsecurity\n\n\n\nNew framework discovers 5.7K unique jailbreak tactics, creating a large-scale safety dataset for safer AI chatbots.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Context-Driven Approach for Co-Auditing Smart Contracts with The Support of GPT-4 code interpreter\n\n\n\nprompt-engineering\n\n\nsecurity\n\n\nrobustness\n\n\n\nTL;DR: Novel context-driven prompting technique for smart contract co-auditing improves vulnerability detection, outperforming native prompting.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCatching Chameleons: Detecting Evolving Disinformation Generated using Large Language Models\n\n\n\nrobustness\n\n\n\nDELD method outperforms in detecting evolving disinformation from LLMs, addressing efficiency and performance challenges.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIRCAN: Mitigating Knowledge Conflicts in LLM Generation via Identifying and Reweighting Context-Aware Neurons\n\n\n\nrobustness\n\n\n\nIRCAN framework improves LLMs’ context-sensitive output, resolving knowledge conflicts.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMath-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models\n\n\n\neducation\n\n\n\nMath-LLaVA: New Model Improves Multimodal Math Reasoning with Diverse Dataset\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConvoCache: Smart Re-Use of Chatbot Responses\n\n\n\nprompt-engineering\n\n\n\nConvoCache speeds up chatbots by reusing past responses, reducing AI usage by up to 89% with 214ms latency. Prefetching offers limited benefits.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelective Prompting Tuning for Personalized Conversations with LLMs\n\n\n\nrecommender\n\n\nhci\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nSelective Prompt Tuning improves LLMs’ personalized dialogue, enhancing response diversity by up to 90%.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMs for Doctors: Leveraging Medical LLMs to Assist Doctors, Not Replace Them\n\n\n\nrobustness\n\n\n\nLLMs as medical assistants face challenges, but our DoctorFLAN dataset and benchmarks can significantly improve their performance, complementing patient-oriented work.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Entity Recognition Using Ensembles of Deep Learning and Fine-tuned Large Language Models: A Case Study on Adverse Event Extraction from Multiple Sources\n\n\n\nsocial-sciences\n\n\n\nThis study compares traditional deep learning models and LLMs for AE extraction, showing that ensembling these models improves performance.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNeBuLa: A discourse aware Minecraft Builder\n\n\n\nsocial-sciences\n\n\n\nTL;DR: Model (NeBuLa) improves language to action tasks by considering conversation context, doubling F1 score over baseline.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDetecting Machine-Generated Texts: Not Just AI vs Humans and Explainability is Complicated\n\n\n\nsocial-sciences\n\n\n\nThis study introduces a ternary text classification for LLM-generated text detection, emphasizing the need for explainable results and proposing guidelines for future…\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymbolic Learning Enables Self-Evolving Agents\n\n\n\nprompt-engineering\n\n\n\nAgent Symbolic Learning enables language agents to self-optimize and evolve, transitioning from model-centric to data-centric AI, potentially advancing AGI.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCategorical Syllogisms Revisited: A Review of the Logical Reasoning Abilities of LLMs for Analyzing Categorical Syllogism\n\n\n\nhci\n\n\n\nCurrent benchmarks for LLMs’ logical reasoning have limitations. Quantifier interpretation is a bottleneck, and future dataset releases should consider this.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBADGE: BADminton report Generation and Evaluation with LLM\n\n\n\nsocial-sciences\n\n\n\nTL;DR: GPT-4 can generate and evaluate high-quality badminton match reports, outperforming human judges.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMs instead of Human Judges? A Large Scale Empirical Study across 20 NLP Evaluation Tasks\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLLMs vary greatly in replicating human annotations, suggesting they’re not yet reliable substitutes for human NLP evaluations.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHierarchical Context Pruning: Optimizing Real-World Code Completion with Repository-Level Pretrained Code LLMs\n\n\n\nprogramming\n\n\n\nHCP strategy improves Code LLMs’ completion accuracy by pruning irrelevant code content, reducing input length.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMental Modeling of Reinforcement Learning Agents by Language Models\n\n\n\nhci\n\n\n\nLLMs currently can’t fully mental model agents via inference alone, revealing their limitations.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Large Language Model Aided Program Refinement\n\n\n\nprogramming\n\n\neducation\n\n\nprompt-engineering\n\n\nrobustness\n\n\n\nLLM4PR tool combines formal refinement techniques with LLMs to generate and verify reliable code from specifications, using GPT4 and Coq.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs ChatGPT a Better Explainer than My Professor?: Evaluating the Explanation Capabilities of LLMs in Conversation Compared to a Human Baseline\n\n\n\neducation\n\n\n\nLLMs can enhance expert explainers’ conversational skills, improving science communication, especially when using concise responses and thought-provoking questions.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMathOdyssey: Benchmarking Mathematical Problem-Solving Skills in Large Language Models Using Odyssey Math Data\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLMs excel at basic math but struggle with complex problems, per the MathOdyssey dataset. Open-source models are closing the gap with closed-source models.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNatural Language but Omitted? On the Ineffectiveness of Large Language Models’ privacy policy from End-users’ Perspective\n\n\n\nhci\n\n\n\n[TEXT] This study explores the relationship between social media use and mental health in young adults. Results suggest a negative correlation between excessive social media…\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLongIns: A Challenging Long-context Instruction-based Exam for LLMs\n\n\n\neducation\n\n\n\nLLMs struggle with long-context tasks; GPT-4 underperforms with 16k context. Multi-hop reasoning needs improvement in short context windows.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJailbreaking LLMs with Arabic Transliteration and Arabizi\n\n\n\nprompt-engineering\n\n\nsecurity\n\n\nrobustness\n\n\n\nLLMs vulnerable to jailbreak attacks in Arabic, especially in transliteration and chatspeak, potentially exposing hidden information.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSafeAligner: Safety Alignment against Jailbreak Attacks via Response Disparity Guidance\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nSafeAligner method improves LLM security, balancing safety and utility by comparing outputs of safety-focused and risk-prone models.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs In-Context Learning a Type of Gradient-Based Learning? Evidence from the Inverse Frequency Effect in Structural Priming\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nICL in LLMs is a form of gradient-based learning, as they display the inverse frequency effect, similar to human structural priming.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPsychological Profiling in Cybersecurity: A Look at LLMs and Psycholinguistic Features\n\n\n\nhci\n\n\nsocial-sciences\n\n\nsecurity\n\n\n\nPsychological profiling and LLMs can enhance cybersecurity by analyzing threat actors’ textual data for psychological traits.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWildGuard: Open One-Stop Moderation Tools for Safety Risks, Jailbreaks, and Refusals of LLMs\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nWildGuard is an open-source LLM safety tool that excels in identifying harmful prompts, detecting safety risks, and determining model refusal rates, outperforming existing…\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThemis: Towards Flexible and Interpretable NLG Evaluation\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nNew NLG Evaluation Corpus and Model, Themis, Outperforms GPT-4 in Flexible, Reference-Free Evaluations.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoisoned LangChain: Jailbreak LLMs by LangChain\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nPoisoned-LangChain: Novel method for indirect jailbreak attacks on LLMs, achieving 88.56%, 79.04%, and 82.69% success rates in three scenarios.\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Open-World Grasping with Large Vision-Language Models\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\n[TEXT] This study examines the impact of social media on body image and self-esteem in adolescents. Results indicate a significant negative correlation between social media…\n\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale\n\n\n\neducation\n\n\n\nTL;DR: FineWeb, a 15-trillion token dataset, improves LLM performance; FineWeb-Edu boosts knowledge and reasoning tasks.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearning to Ask Informative Questions: Enhancing LLMs with Preference Optimization and Expected Information Gain\n\n\n\nhci\n\n\nprompt-engineering\n\n\neducation\n\n\n\nLLM-generated questions improved via Direct Preference Optimization (DPO) for better information gain in 20-question games.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMitigating Hallucination in Fictional Character Role-Play\n\n\n\nhci\n\n\nsecurity\n\n\nrobustness\n\n\n\nRoleFact reduces hallucination in role-playing by 18% for adversarial questions and 44% for time-sensitive interviews.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuantifying AI Psychology: A Psychometrics Benchmark for Large Language Models\n\n\n\nhci\n\n\n\nLLMs exhibit psychological attributes, but self-reported traits may differ from real-world behaviors, according to a new psychometric benchmark.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMPCODER: Multi-user Personalized Code Generator with Explicit and Implicit Style Representation Learning\n\n\n\nprogramming\n\n\n\nMPCoder generates personalized code for multiple users, considering syntax and semantics, with a new evaluation metric for coding style similarities.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNative Design Bias: Studying the Impact of English Nativeness on Language Model Performance\n\n\n\nhci\n\n\n\nLLMs perform worse for non-native English speakers, with an anchoring effect worsening responses.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnmasking the Imposters: In-Domain Detection of Human vs. Machine-Generated Tweets\n\n\n\nhci\n\n\n\nUncensored, fine-tuned LLMs evade detection, raising concerns about misuse on social media.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow Well Can Knowledge Edit Methods Edit Perplexing Knowledge?\n\n\n\nrobustness\n\n\n\nPerplexingness of new knowledge impacts editing efficacy in LLMs, with abstract concepts being more challenging to incorporate.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models are Interpretable Learners\n\n\n\nprogramming\n\n\n\nLSPs, combining LLMs and symbolic programs, offer interpretable, accurate, and transferable knowledge for decision-making.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-ARC: Enhancing LLMs with an Automated Reasoning Critic\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLM-ARC improves LLMs’ logical reasoning via an Actor-Critic method, achieving 88.32% accuracy on the FOLIO benchmark.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRetrieval-Augmented Code Generation for Situated Action Generation: A Case Study on Minecraft\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLMs predict Builder’s actions in Minecraft Collaborative Building Task, using few-shot prompting for improved performance.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond Demographics: Aligning Role-playing LLM-based Agents Using Human Belief Networks\n\n\n\nhci\n\n\n\nLLMs align better with human beliefs when seeded with a single belief, improving social simulations.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoSafe: Evaluating Large Language Model Safety in Multi-Turn Dialogue Coreference\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nLLMs vulnerable in multi-turn dialogues; highest attack success rate was 56% with LLaMA2-Chat-7b, lowest was 13.9% with Mistral-7B-Instruct.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDual-Space Knowledge Distillation for Large Language Models\n\n\n\neducation\n\n\n\nDSKD unifies output spaces for KD, improving LLM compression and enabling KD between models with different vocabularies.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCogMG: Collaborative Augmentation Between Large Language Model and Knowledge Graph\n\n\n\nrobustness\n\n\n\nCogMG framework improves LLM QA accuracy by leveraging knowledge graphs, reducing hallucinations and misalignment issues.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNormTab: Improving Symbolic Reasoning in LLMs Through Tabular Data Normalization\n\n\n\nprogramming\n\n\n\nNormTab improves LLMs’ symbolic reasoning on tables by normalizing web data, enhancing performance on tasks like WikiTableQuestion and TabFact.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Unlearning Fails to Remove Data Poisoning Attacks\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nExisting unlearning methods fail to remove data poisoning effects, suggesting a need for broader evaluation and improvement.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimsChat: A Customisable Persona-Driven Role-Playing Agent\n\n\n\nhci\n\n\n\nLLMs simulate customizable real-world characters for role-playing, offering a framework for human-like agents.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing LLM-Based Human-Robot Interaction with Nuances for Diversity Awareness\n\n\n\nhci\n\n\n\nSystem uses LLMs for diversity-aware autonomous conversations, adapting to user factors like background, personality, and culture.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo they mean ‘us’? Interpreting Referring Expressions in Intergroup Bias\n\n\n\nsocial-sciences\n\n\n\nLLMs detect intergroup bias in NFL comments, influenced by win probabilities.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicting the Big Five Personality Traits in Chinese Counselling Dialogues Using Large Language Models\n\n\n\nhci\n\n\n\nLLMs can predict Big Five personality traits from counseling dialogues, outperforming traditional methods.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-assessment, Exhibition, and Recognition: a Review of Personality in Large Language Models\n\n\n\nhci\n\n\n\nTL;DR: This paper reviews studies on personality in large language models, categorizing them into self-assessment, exhibition, and recognition, and discusses challenges and…\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Three-Pronged Approach to Cross-Lingual Adaptation with Multilingual LLMs\n\n\n\nprogramming\n\n\n\nCross-lingual transfer to Indic languages improves Llama-2 LLM performance, benefiting from dominant language signals, word reordering, and continued pre-training.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDisce aut Deficere: Evaluating LLMs Proficiency on the INVALSI Italian Benchmark\n\n\n\neducation\n\n\n\nTL;DR: We adapt INVALSI tests to evaluate LLMs in Italian, comparing them to human performance and inviting further model submissions.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan Large Language Models Understand DL-Lite Ontologies? An Empirical Study\n\n\n\neducation\n\n\n\nLLMs can understand DL-Lite ontologies’ syntax and semantics but struggle with transitivity and large ABoxes.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM Targeted Underperformance Disproportionately Impacts Vulnerable Users\n\n\n\nrobustness\n\n\n\nLLMs’ reliability varies with user traits; lower proficiency, education, and non-US users receive less accurate, truthful, and more refused responses.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBanishing LLM Hallucinations Requires Rethinking Generalization\n\n\n\nrobustness\n\n\n\nLLMs hallucinate due to training loss, not just creativity-factuality balance. MoME and Lamini-1 models can mitigate this issue.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaLMQA: Exploring culturally specific long-form question answering across 23 languages\n\n\n\nsocial-sciences\n\n\n\nTL;DR: CaLMQA dataset evaluates multilingual LLMs on complex questions, revealing gaps in low-resource languages and cultural specificity.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Tool Retrieval with Iterative Feedback from Large Language Models\n\n\n\neducation\n\n\n\nTL;DR: Enhancing tool retrieval for LLMs with iterative feedback for improved performance.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Robustness of LLM-based Speech Synthesis by Learning Monotonic Alignment\n\n\n\nrobustness\n\n\n\nLLM-based TTS models can have errors; proposed techniques improve alignment and robustness without adding new parameters.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMeasuring and Benchmarking Large Language Models’ Capabilities to Generate Persuasive Language\n\n\n\nhci\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLLMs can produce persuasive text; new dataset measures this ability, enabling comparison of different LLMs and highlighting the impact of system prompts.\n\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDirected Domain Fine-Tuning: Tailoring Separate Modalities for Specific Training Tasks\n\n\n\neducation\n\n\n\nFine-tuning Video-LLaVA with LORA on cooking tasks improves performance using smaller, task-specific datasets.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Augmentation of Multi-turn Psychological Dialogue via Knowledge-driven Progressive Thought Prompting\n\n\n\nprompt-engineering\n\n\nhci\n\n\nsocial-sciences\n\n\n\nNew method for multi-turn dialogue data augmentation in psychology, using progressive thought and psychology knowledge generators, and a multi-turn dialogue generator.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLangSuitE: Planning, Controlling and Interacting with Large Language Models in Embodied Text Environments\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLangSuit⋅⋅⋅E tests LLMs as embodied agents in dynamic textual worlds, offering adaptability, customization, and a novel CoT schema for embodied planning.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYouDream: Generating Anatomically Controllable Consistent Text-to-3D Animals\n\n\n\nhci\n\n\n\nYouDream generates anatomically accurate 3D animals from text, outperforming previous text-to-3D methods.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluation of Instruction-Following Ability for Large Language Models on Story-Ending Generation\n\n\n\nsocial-sciences\n\n\neducation\n\n\n\nLLMs’ instruction-following ability in story-ending generation aligns with human evaluation, with open-source models nearing GPT-3.5 performance.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models\n\n\n\nrobustness\n\n\n\nNew framework improves text-to-image model reliability, reducing inconsistencies between visual output and textual input.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutomated Adversarial Discovery for Safety Classifiers\n\n\n\nrobustness\n\n\n\nAutomated methods struggle to find diverse, successful attacks on safety classifiers, revealing a need for improved adversarial discovery techniques.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUSDC: A Dataset of User Stance and Dogmatism in Long Conversations\n\n\n\nproduction\n\n\n\nLLMs automate annotation for user stance, dogmatism in Reddit conversations, creating USDC dataset for finetuning small language models.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models\n\n\n\nproduction\n\n\n\nSurvey explores scaling compute during inference in LLMs, focusing on token-level, meta-generation, and efficient generation algorithms.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdversarial Contrastive Decoding: Boosting Safety Alignment of Large Language Models via Opposite Prompt Optimization\n\n\n\nprompt-engineering\n\n\nsecurity\n\n\narchitectures\n\n\n\nACD: A lightweight, optimization-based method for safer LLM responses, improving safety without heavy training or sacrificing generation ability.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Comprehensive Preference Data Collection for Reward Modeling\n\n\n\nsocial-sciences\n\n\n\nNew framework for RLHF preference data collection improves quality, diversity, and reduces human labor.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLottery Ticket Adaptation: Mitigating Destructive Interference in LLMs\n\n\n\nproduction\n\n\narchitectures\n\n\neducation\n\n\nrobustness\n\n\n\nLoTA, a sparse adaptation method, outperforms full fine-tuning and LoRA, avoiding catastrophic forgetting and enabling model merging over dissimilar tasks.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees\n\n\n\narchitectures\n\n\nproduction\n\n\n\nEAGLE-2, an upgrade to EAGLE, offers 20%-40% faster speculative sampling for LLMs, preserving text distribution without loss.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWARP: On the Benefits of Weight Averaged Rewarded Policies\n\n\n\narchitectures\n\n\nproduction\n\n\n\nWARP strategy improves LLM alignment, balancing KL regularization and reward optimization.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSparser is Faster and Less is More: Efficient Sparse Attention for Long-Range Transformers\n\n\n\narchitectures\n\n\n\nSparseK Attention: A novel sparse attention mechanism for efficient, linear-time Transformers with improved performance and seamless integration into LLMs.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoisy Neighbors: Efficient membership inference attacks against LLMs\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nEfficient MIA method for LLMs using noisy neighbors in embedding space, matching shadow models’ effectiveness in privacy auditing.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInvestigating the Influence of Prompt-Specific Shortcuts in AI Generated Text Detection\n\n\n\nprompt-engineering\n\n\nsecurity\n\n\nrobustness\n\n\n\nFAILOpt Attack Exploits Shortcuts in AI-Generated Text Detection, Enhances Robustness.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters\n\n\n\narchitectures\n\n\n\nLanguage-specific draft models speed up multilingual LLM inference time.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn the Transformations across Reward Model, Parameter Update, and In-Context Prompt\n\n\n\nprompt-engineering\n\n\n\nLLMs can be adapted using three tools: parameter updating, reward modeling, and in-context prompting, offering a unified framework for practical applications.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBEEAR: Embedding-based Adversarial Removal of Safety Backdoors in Instruction-tuned Language Models\n\n\n\nrobustness\n\n\n\nBEEAR mitigates safety backdoor attacks in LLMs, reducing success rates from &gt;95% to &lt;1% without compromising model utility.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAgent-Driven Automatic Software Improvement\n\n\n\narchitectures\n\n\nprogramming\n\n\n\nThis research aims to improve software quality using agents powered by Large Language Models, focusing on iterative learning and error correction.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPISTOL: Dataset Compilation Pipeline for Structural Unlearning of LLMs\n\n\n\narchitectures\n\n\nrobustness\n\n\nproduction\n\n\n\nPISTOL: A pipeline for benchmarking structural unlearning in LLMs, highlighting challenges and model impacts.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlagBench: Exploring the Duality of Large Language Models in Plagiarism Generation and Detection\n\n\n\nrobustness\n\n\n\nLLMs can aid plagiarism, but also detect it. GPT-3.5 outperforms Llama2 and GPT-4 in paraphrasing and summarizing, and LLMs can surpass commercial plagiarism detectors.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMs assist NLP Researchers: Critique Paper (Meta-)Reviewing\n\n\n\nhci\n\n\n\nThis study explores LLMs’ potential to assist NLP researchers in paper reviewing, but does not advocate their use due to current limitations in expertise and nuanced…\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in Large Language Models\n\n\n\narchitectures\n\n\nproduction\n\n\n\nM2Lingual: A synthetic multilingual IFT dataset for LLMs, covering 70 languages and 17 NLP tasks, outperforming existing multilingual IFT datasets.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRagnarök: A Reusable RAG Framework and Baselines for TREC 2024 Retrieval-Augmented Generation Track\n\n\n\narchitectures\n\n\nproduction\n\n\n\nTREC 2024 RAG Track proposed for evaluating RAG-based search systems, featuring Ragnarök framework and industrial baselines.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInducing Group Fairness in LLM-Based Decisions\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLLM-based classifiers may lead to unfair decisions; remediation techniques are proposed to improve fairness.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSoley: Identification and Automated Detection of Logic Vulnerabilities in Ethereum Smart Contracts Using Large Language Models\n\n\n\nsecurity\n\n\nrobustness\n\n\n\nTL;DR: Sóley, a LLM-based tool, outperforms existing methods in detecting logic vulnerabilities in smart contracts, aiding security and sustainability.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models\n\n\n\nsecurity\n\n\neducation\n\n\nrobustness\n\n\n\nAutoDetect framework automatically identifies weaknesses in LLMs, improving their performance by over 10%.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUniCoder: Scaling Code Large Language Model via Universal Code\n\n\n\nprompt-engineering\n\n\nprogramming\n\n\neducation\n\n\n\nUniCoder: Improving Code Generation with Universal Code Intermediate Representation\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnnotatedTables: A Large Tabular Dataset with Language Model Annotations\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nLLMs can automate annotation of large, diverse tabular data, enabling flexible annotations and SQL program generation.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis\n\n\n\nprompt-engineering\n\n\nhci\n\n\n\nGraph-augmented LLM framework improves personalized, actionable health insights from wearable data.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParaphrase and Aggregate with Large Language Models for Minimizing Intent Classification Errors\n\n\n\nrobustness\n\n\n\nLLMs like LLaMa can excel in multi-class classification, but PAG-LLM reduces errors and hallucinated labels, improving performance by up to 22.7%.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFreeTraj: Tuning-Free Trajectory Control in Video Diffusion Models\n\n\n\narchitectures\n\n\nproduction\n\n\n\nTuning-free framework for trajectory-controllable video generation using diffusion models.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRES-Q: Evaluating Code-Editing Large Language Model Systems at the Repository Scale\n\n\n\nprompt-engineering\n\n\narchitectures\n\n\nprogramming\n\n\nproduction\n\n\n\nRES-Q benchmark evaluates LLMs’ ability to edit code repositories, showing Claude Sonnet 3.5 outperforms GPT-4o.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models Assume People are More Rational than We Really are\n\n\n\nhci\n\n\n\nLLMs incorrectly assume humans are more rational, aligning with expected value theory, but match human expectations of rational behavior.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs\n\n\n\narchitectures\n\n\neducation\n\n\nproduction\n\n\n\nCambrian-1: A family of MLLMs with vision-centric approach, offering new insights into various models, and introducing CV-Bench and Spatial Vision Aggregator (SVA) for…\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlending LLMs into Cascaded Speech Translation: KIT’s Offline Speech Translation System for IWSLT 2024\n\n\n\narchitectures\n\n\nrobustness\n\n\nproduction\n\n\n\nLLM integration in ASR and MT systems improves WER and COMET scores, but not in noisy conditions.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTask Oriented In-Domain Data Augmentation\n\n\n\neducation\n\n\n\nTRAIT, a task-oriented framework, enhances LLMs in specialized domains like law and advertisement by augmenting in-domain data and generating synthetic task-oriented…\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models in Student Assessment: Comparing ChatGPT and Human Graders\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\neducation\n\n\n\nGPT-4 aligns with human mean scores but lacks adaptability in grading nuanced criteria, highlighting AI’s limitations in higher education.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShadowLLM: Predictor-based Contextual Sparsity for Large Language Models\n\n\n\nrobustness\n\n\n\nShadowLLM improves end-to-end accuracy by 15%+, speeds up to 20% over DejaVu, validated on models up to 30B parameters.\n\n\n\nJun 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFastMem: Fast Memorization of Prompt Improves Context Awareness of Large Language Models\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nFastMem improves LLMs’ context awareness, boosting accuracy in tasks like comprehension and summarization.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPORT: Preference Optimization on Reasoning Traces\n\n\n\nprompt-engineering\n\n\n\nPreference optimization on reasoning steps enhances language model accuracy, as shown by up to 8.47% increase on GSM8K benchmark.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEERPD: Leveraging Emotion and Emotion Regulation for Improving Personality Detection\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nEERPD: New method improves personality detection by incorporating emotion regulation, outperforming previous models.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrace is the New AutoDiff – Unlocking Efficient Optimization of Computational Workflows\n\n\n\nprompt-engineering\n\n\n\nTrace: A Framework for Optimizing AI Systems with Diverse Feedback and Parameters.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPreference Tuning For Toxicity Mitigation Generalizes Across Languages\n\n\n\nsocial-sciences\n\n\nrobustness\n\n\n\nZero-shot preference tuning in English can significantly reduce toxicity in multilingual LLMs, as shown by DPO training results across 17 languages and various models.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCrosslingual Capabilities and Knowledge Barriers in Multilingual Large Language Models\n\n\n\nsocial-sciences\n\n\n\nLLMs struggle with crosslingual knowledge transfer, but fine-tuning on mixed-language data helps improve performance.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Text to Test: AI-Generated Control Software for Materials Science Instruments\n\n\n\nhci\n\n\neducation\n\n\n\nLLMs, like ChatGPT-4, can automate scientific instruments and democratize materials research, as demonstrated by controlling a Keithley 2400 and analyzing a…\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSerial Position Effects of Large Language Models\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLLMs excel in zero-shot learning but exhibit human-like biases, like primacy and recency effects, which vary in intensity and can be inconsistently mitigated.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEffectiveness of ChatGPT in explaining complex medical reports to patients\n\n\n\nhci\n\n\nsocial-sciences\n\n\neducation\n\n\n\nChatGPT struggles to accurately explain complex cancer reports to patients, facing issues like inaccuracies, language, personalization, and distrust.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReCaLL: Membership Inference via Relative Conditional Log-Likelihoods\n\n\n\nsecurity\n\n\n\nReCall is a new method for detecting pretraining data in large language models, outperforming existing methods and offering insights into model behavior.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChain-of-Probe: Examing the Necessity and Accuracy of CoT Step-by-Step\n\n\n\nprompt-engineering\n\n\n\nCoP method reveals CoT can be unnecessary, and correct answers may have reasoning errors. CoP prioritizes answers with correct reasoning for reliability.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Region-aware Bias Evaluation Metrics\n\n\n\nsocial-sciences\n\n\n\nRegion-aware approach identifies gender bias in language models, outperforming traditional methods.\n\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeaching LLMs to Abstain across Languages via Multilingual Feedback\n\n\n\nsocial-sciences\n\n\neducation\n\n\nrobustness\n\n\n\nTL;DR: Multilingual feedback improves LLM abstention, reducing performance gaps between high and low-resource languages in QA tasks.\n\n\n\nJun 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration\n\n\n\nsocial-sciences\n\n\n\nModular Pluralism: A framework for LLMs to model diverse human preferences across communities, offering flexibility and modular control.\n\n\n\nJun 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold\n\n\n\narchitectures\n\n\nproduction\n\n\n\nFinetuning LLMs with model-generated data can improve math reasoning, especially with self-generated correct solutions and per-step negative responses. This approach can…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSPL: A Socratic Playground for Learning Powered by Large Language Mode\n\n\n\nhci\n\n\nsocial-sciences\n\n\neducation\n\n\nprompt-engineering\n\n\n\nSPL, a GPT-4-powered ITS, improves tutoring dialogues and critical thinking skills in learners.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeCoKD: Aligning Large Language Models for In-Context Learning with Fewer Shots\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nSeCoKD improves LLMs’ performance with fewer demonstrations, outperforming base models and Supervised Fine-tuning, especially in zero-shot and one-shot settings.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment\n\n\n\nsocial-sciences\n\n\n\nEnriched image captions increase gender bias and hallucination, cautioning against over-descriptiveness.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInvestigating Mysteries of CoT-Augmented Distillation\n\n\n\nproduction\n\n\neducation\n\n\nprompt-engineering\n\n\n\nCoT sequences after labels improve student model performance, even when incoherent or partial. No reasoning needed at test time.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCityBench: Evaluating the Capabilities of Large Language Model as World Model\n\n\n\neducation\n\n\n\nTL;DR: CityBench is a new evaluation benchmark for LLMs in urban domains, featuring 7 tasks across 13 cities and 13 models.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmedIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced Clinical Diagnosis on EMRs\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\n\nmedIKAL framework combines LLMs and KGs for precise, enhanced clinical diagnosis using EMRs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMind the Privacy Unit! User-Level Differential Privacy for Language Model Fine-Tuning\n\n\n\narchitectures\n\n\n\nUser-level DP for LLMs ensures uniform privacy across users, focusing on fine-tuning for natural language generation tasks.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDye4AI: Assuring Data Boundary on Generative AI Services\n\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nTL;DR: Dye4AI system tests AI data boundaries by injecting triggers into dialogue, ensuring data security in AI model evolution.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvidence of a log scaling law for political persuasion with large language models\n\n\n\nproduction\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLarger language models only slightly more persuasive than smaller ones, with task completion being key.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAsynchronous Large Language Model Enhanced Planner for Autonomous Driving\n\n\n\narchitectures\n\n\nproduction\n\n\n\nAsyncDriver: LLM-enhanced framework for precise, controllable autonomous driving, reducing LLM’s computational cost.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs\n\n\n\neducation\n\n\n\nTL;DR: Fine-tuning LLMs with KG-derived data enhances planning, improving complex QA task performance.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRaising the Bar: Investigating the Values of Large Language Models via Generative Evolving Testing\n\n\n\nrobustness\n\n\nsocial-sciences\n\n\n\nTL;DR: GETA dynamically tests LLMs’ moral baselines, addressing the issue of outdated evaluation data, and accurately assesses their values.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Fire Thief Is Also the Keeper: Balancing Usability and Privacy in Prompts\n\n\n\nprompt-engineering\n\n\nrobustness\n\n\nhci\n\n\nsecurity\n\n\n\nProSan: A framework for anonymizing prompts in LLMs, maintaining usability, and adapting to resource conditions.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Truthful Multilingual Large Language Models: Benchmarking and Alignment Strategies\n\n\n\narchitectures\n\n\nproduction\n\n\n\nResearch proposes benchmark and method to improve truthfulness and reduce language disparity in multilingual large language models.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQ*: Improving Multi-step Reasoning for LLMs with Deliberative Planning\n\n\n\nrobustness\n\n\n\nQ* framework guides LLMs’ decoding, improving multi-step reasoning without fine-tuning, reducing errors and inconsistencies.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAPEER: Automatic Prompt Engineering Enhances Large Language Model Reranking\n\n\n\narchitectures\n\n\nproduction\n\n\nprompt-engineering\n\n\n\nAPEER: A novel automatic prompt engineering algorithm for relevance ranking, outperforming manual prompts and showing better transferability.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRobust Few-shot Transfer Learning for Knowledge Base Question Answering with Unanswerable Questions\n\n\n\nprompt-engineering\n\n\n\nFUn-FuSIC improves few-shot KBQA with unanswerable questions, outperforming existing models.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTaxonomy-Guided Zero-Shot Recommendations with LLMs\n\n\n\nrecommender\n\n\n\nTaxonomy-guided LLM method (TaxRec) improves recommender systems with better item categorization and controlled feature generation.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPostMark: A Robust Blackbox Watermark for Large Language Models\n\n\n\nproduction\n\n\nrobustness\n\n\nsocial-sciences\n\n\nsecurity\n\n\n\nPostMark: A post-hoc watermarking method for LLM-generated text, robust to paraphrasing and third-party implementable.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutoCAP: Towards Automatic Cross-lingual Alignment Planning for Zero-shot Chain-of-Thought\n\n\n\nprompt-engineering\n\n\n\nAutoCAP, a zero-shot chain-of-thought method, improves cross-lingual alignment by automatically selecting languages and allocating weights, outperforming manual methods.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenderAlign: An Alignment Dataset for Mitigating Gender Bias in Large Language Models\n\n\n\nsocial-sciences\n\n\n\nGenderAlign dataset reduces gender bias in LLMs, offering a new approach to alignment.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCausal Inference with Latent Variables: Recent Advances and Future Prospectives\n\n\n\nsocial-sciences\n\n\n\nRecent developments in causal inference with unobserved variables, challenges, and future opportunities.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel Merging and Safety Alignment: One Bad Model Spoils the Bunch\n\n\n\narchitectures\n\n\nproduction\n\n\n\nMerging LLMs can propagate misalignment; proposed method integrates alignment-related data, improving domain expertise and alignment.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLaSA: Large Multimodal Agent for Human Activity Analysis Through Wearable Sensors\n\n\n\neducation\n\n\n\nLLaSA: A Multimodal AI Model for Activity Understanding Using IMUs and LLMs, with Applications in Healthcare and HCI.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrism: A Framework for Decoupling and Assessing the Capabilities of VLMs\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nPrism separates vision and reasoning in VLMs, improving performance and reducing costs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving Expert Radiology Report Summarization by Prompting Large Language Models with a Layperson Summary\n\n\n\nproduction\n\n\n\nThis paper presents a novel method for radiology report summarization, improving accuracy and accessibility, especially in out-of-domain tests.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSynDARin: Synthesising Datasets for Automated Reasoning in Low-Resource Languages\n\n\n\narchitectures\n\n\nproduction\n\n\n\nSynDARin generates QA datasets for low-resource languages, maintaining quality and diversity, and filtering out poor translations, enabling evaluation of LLMs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn Investigation of Prompt Variations for Zero-shot LLM-based Rankers\n\n\n\nprompt-engineering\n\n\n\nPrompt components and wordings significantly impact zero-shot LLM ranking effectiveness, sometimes more than ranking algorithms.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDoes Object Grounding Really Reduce Hallucination of Large Vision-Language Models?\n\n\n\nrobustness\n\n\n\nGrounding objectives minimally reduce object hallucination in open caption generation, despite previous claims.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinding Safety Neurons in Large Language Models\n\n\n\nsecurity\n\n\n\nSafety neurons in LLMs can restore 90% safety with 5% intervention, transferable across datasets, and aid in detecting unsafe outputs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranslating Across Cultures: LLMs for Intralingual Cultural Adaptation\n\n\n\narchitectures\n\n\nproduction\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs can adapt translations to target cultures, outperforming specialized models in cultural sensitivity, but may perpetuate biases.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfrican or European Swallow? Benchmarking Large Vision-Language Models for Fine-Grained Object Classification\n\n\n\narchitectures\n\n\nproduction\n\n\n\nTL;DR: FOCI benchmark reveals CLIP models outperform LVLMs in fine-grained object classification, highlighting alignment issues.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Different Design Choices in Training Large Time Series Models\n\n\n\nprompt-engineering\n\n\n\nLTSM-bundle outperforms existing methods in time series forecasting, using novel prompting strategies and best design choices.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVAIYAKARANA : A Benchmark for Automatic Grammar Correction in Bangla\n\n\n\nrobustness\n\n\n\nThis work proposes a method to generate grammatically incorrect Bangla sentences for AI training, creating a dataset called Vaiyakarana. Human evaluators outperform AI…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAugmenting Query and Passage for Retrieval-Augmented Generation using LLMs for Open-Domain Question Answering\n\n\n\neducation\n\n\n\nTL;DR: Improving open-domain QA by augmenting questions and passages with LLMs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFVEL: Interactive Formal Verification Environment with Large Language Models via Theorem Proving\n\n\n\narchitectures\n\n\neducation\n\n\nprompt-engineering\n\n\n\nFVEL: LLM-powered Formal Verification in Isabelle improves verification, reducing proof errors, and solving more problems in SV-COMP.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConnecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data\n\n\n\nproduction\n\n\nsecurity\n\n\n\nLLMs can infer censored knowledge by piecing together scattered hints, posing a challenge for safety and control.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAligning Large Language Models with Diverse Political Viewpoints\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs aligned with diverse political views generate more accurate viewpoints than commercial models like ChatGPT.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGlobal is Good, Local is Bad?: Understanding Brand Bias in LLMs\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs exhibit bias towards global brands, favoring them over local ones, and show country-of-origin effects.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExplicit and Implicit Large Language Model Personas Generate Opinions but Fail to Replicate Deeper Perceptions and Biases\n\n\n\nprompt-engineering\n\n\nproduction\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs with personas struggle to replicate human biases, lacking intrinsic human cognition despite reflecting speech patterns.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLiveMind: Low-latency Large Language Models with Simultaneous Inference\n\n\n\narchitectures\n\n\neducation\n\n\nprompt-engineering\n\n\n\nNew framework reduces LLM inference latency by up to 93% with incomplete prompts, improving interactive experience and accuracy.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCityGPT: Empowering Urban Spatial Cognition of Large Language Models\n\n\n\nprogramming\n\n\neducation\n\n\n\nCityGPT enhances LLMs’ urban understanding using CityInstruction and CityEval, achieving competitive performance with commercial LLMs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJailbreaking as a Reward Misspecification Problem\n\n\n\narchitectures\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nTL;DR: New system (ReMiss) detects harmful prompts in LLMs, outperforming previous methods.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeeing Through AI’s Lens: Enhancing Human Skepticism Towards LLM-Generated Fake News\n\n\n\nrobustness\n\n\nsocial-sciences\n\n\n\nTL;DR: ESAS metric helps identify terms to distinguish human-written vs. LLM-generated news, aiding in detecting fake news.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Changes in Nation Perception with Nationality-Assigned Personas in LLMs\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs favor Western Europe, but nationality personas influence focus and favorability towards the assigned region. Biases and stereotypes emerge in LLMs with different…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating Implicit Bias in Large Language Models by Attacking From a Psychometric Perspective\n\n\n\nsocial-sciences\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nLLMs exhibit implicit bias, with GLM-3 outperforming GPT-3.5 and GPT-4 in defending against attacks. Deception attacks are most effective.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArtificial Leviathan: Exploring Social Evolution of LLM Agents Through the Lens of Hobbesian Social Contract Theory\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nLLMs simulate social dynamics, aligning with Hobbes’s Social Contract Theory, offering potential for understanding group behavior and complex human systems.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre LLMs Naturally Good at Synthetic Tabular Data Generation?\n\n\n\narchitectures\n\n\nproduction\n\n\n\nLLMs struggle with generating synthetic tables; this paper proposes a permutation-aware approach to improve their performance.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMR-BEN: A Comprehensive Meta-Reasoning Benchmark for Large Language Models\n\n\n\nhci\n\n\n\nTL;DR: Mr-Ben benchmark evaluates LLMs’ meta-reasoning skills, revealing gaps in reasoning capabilities.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData-Centric AI in the Age of Large Language Models\n\n\n\nproduction\n\n\n\nData-centric viewpoint for AI research: Prioritizing data in large language models for benchmarks, attribution, knowledge transfer, and inference contextualization.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Spatial Representations in the Historical Lake District Texts with LLM-based Relation Extraction\n\n\n\nsocial-sciences\n\n\n\nAI model extracts spatial relations from English Lake District texts, visualizing historical narratives as a network for deeper understanding.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHIGHT: Hierarchical Graph Tokenization for Graph-Language Alignment\n\n\n\nrobustness\n\n\nhci\n\n\n\nHIGHT: New method improves graph-language alignment in LLMs, reducing hallucination and enhancing performance in molecule-language tasks.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSEC-QA: A Systematic Evaluation Corpus for Financial QA\n\n\n\narchitectures\n\n\n\nTL;DR: SEC-QA framework generates QA pairs for financial documents, improving complex QA accuracy.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep-Back Profiling: Distilling User History for Personalized Scientific Writing\n\n\n\nsocial-sciences\n\n\n\nStep-back Profiling personalizes LLMs for collaborative scientific writing, outperforming baselines on LaMP benchmark.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerative AI for Enhancing Active Learning in Education: A Comparative Study of GPT-3.5 and GPT-4 in Crafting Customized Test Questions\n\n\n\nprompt-engineering\n\n\neducation\n\n\nhci\n\n\n\nGPT-4 excels at creating complex math questions, improving GPT-3.5’s problem-solving skills, showcasing AI’s potential in personalized education.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM4CP: Adapting Large Language Models for Channel Prediction\n\n\n\narchitectures\n\n\nproduction\n\n\n\n[TEXT] This study examines the relationship between social media use and mental health in adolescents. Results indicate a significant correlation between excessive social…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models are Skeptics: False Negative Problem of Input-conflicting Hallucination\n\n\n\nrobustness\n\n\n\nLLMs tend to generate false negative responses, but context and query rewriting can help.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCREF: An LLM-based Conversational Software Repair Framework for Programming Tutors\n\n\n\nprogramming\n\n\neducation\n\n\n\nLLMs show potential for program repair, but data leakage is a concern. A new benchmark, TutorCode, is introduced to evaluate LLMs’ repair capabilities. Tutor guidance is…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models\n\n\n\narchitectures\n\n\nproduction\n\n\nprompt-engineering\n\n\n\nGraphReader outperforms GPT-4-128k on long-context tasks, using a 4k context window and a graph-based agent system.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPersuasiveness of Generated Free-Text Rationales in Subjective Decisions: A Case Study on Pairwise Argument Ranking\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\neducation\n\n\nhci\n\n\n\nLLMs generate persuasive rationales for subjective tasks, with Llama2-70B-chat outperforming GPT models. Persuasiveness improves with parameter control via prompting or…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMMBench-Video: A Long-Form Multi-Shot Benchmark for Holistic Video Understanding\n\n\n\narchitectures\n\n\nproduction\n\n\n\nMMBench-Video: New Benchmark for Video Understanding with LVLMs.\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHierarchical Micro-Segmentations for Zero-Trust Services via Large Language Model (LLM)-enhanced Graph Diffusion\n\n\n\nsecurity\n\n\n\nThis paper proposes LEGD, a hierarchical micro-segmentation algorithm for efficient zero-trust service provisioning in NGNs, achieving 90% higher efficiency than baselines.…\n\n\n\nJun 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan LLMs Reason in the Wild with Programs?\n\n\n\nprogramming\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLMs struggle with ambiguous, mixed-scope reasoning; fine-tuning with diverse data helps.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpen Generative Large Language Models for Galician\n\n\n\nsocial-sciences\n\n\n\n[TEXT] This study examines the relationship between social media use and mental health in adolescents. Results indicate a significant correlation between excessive social…\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStackRAG Agent: Improving Developer Answers with Retrieval-Augmented Generation\n\n\n\nprogramming\n\n\nrobustness\n\n\n\nStackRAG: A tool combining Stack Overflow and LLMs for accurate, reliable coding answers.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation\n\n\n\neducation\n\n\n\nBalDistill improves LLM knowledge distillation for long-tailed data, enhancing distilled model efficiency and efficacy.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn AI-Inspired UI-Design\n\n\n\nhci\n\n\n\nAI can inspire and assist app design by generating, searching, and creating UI images using LLM, VLM, and DM models.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMagicItem: Dynamic Behavior Design of Virtual Objects with Large Language Models in a Consumer Metaverse Platform\n\n\n\nprogramming\n\n\neducation\n\n\n\nTool enables non-programmers to create dynamic behaviors for VR objects in metaverse platforms.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdaptable Logical Control for Large Language Models\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nCtrl-G outperforms GPT3.5 and GPT4 in interactive text editing, ensuring LLM outputs follow logical constraints.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeveraging Large Language Models for Patient Engagement: The Power of Conversational AI in Digital Health\n\n\n\neducation\n\n\nhci\n\n\n\nLLMs in healthcare improve patient engagement via conversational AI, but raise ethical and regulatory considerations.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Collaborative Semantics of Language Model-Driven Recommendations via Graph-Aware Learning\n\n\n\nrecommender\n\n\n\nGAL-Rec improves LLM-driven recommendations by enhancing collaborative semantics understanding in interaction graphs.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNicer Than Humans: How do Large Language Models Behave in the Prisoner’s Dilemma?\n\n\n\nrobustness\n\n\nhci\n\n\nsecurity\n\n\n\nLLM Llama2 shows cooperative behavior in Prisoner’s Dilemma, adopting a cautious approach and favoring forgiveness over retaliation.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models\n\n\n\neducation\n\n\n\nAutoIF is a new method for automatically generating instruction-following training data for LLMs, improving performance across three training algorithms.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKnowledge Graph-Enhanced Large Language Models via Path Selection\n\n\n\nrobustness\n\n\n\nKELP framework improves LLM factual accuracy by flexible KG knowledge extraction.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJogging the Memory of Unlearned Model Through Targeted Relearning Attack\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nExisting unlearning methods in LLMs can be reversed by targeted relearning attacks, using small, loosely related data sets.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Efficacy of Conversational Artificial Intelligence in Rectifying the Theory of Mind and Autonomy Biases: Comparative Analysis\n\n\n\nsocial-sciences\n\n\nhci\n\n\n\nNon-therapeutic chatbots outperform therapeutic ones in rectifying cognitive biases and recognizing affect.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling\n\n\n\nhci\n\n\n\nLangTopo framework aligns LLMs with GNNs for graph structure modeling, improving LLMs’ graph data handling.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKnowledge Tagging System on Math Questions via LLMs with Flexible Demonstration Retriever\n\n\n\neducation\n\n\nprompt-engineering\n\n\n\nLLMs automate knowledge tagging for questions, outperforming prior methods in math tasks and improving efficiency with a reinforcement learning-based demonstration retriever.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOptimizing Psychological Counseling with Instruction-Tuned Large Language Models\n\n\n\neducation\n\n\nhci\n\n\n\nInstruction-tuned LLMs excel in psychological counseling, offering empathetic, relevant, and supportive responses, outperforming baseline models.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProse-to-P4: Leveraging High Level Languages\n\n\n\nprogramming\n\n\n\nLLMs can translate natural language to high-level networking code, making software development easier.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinding Blind Spots in Evaluator LLMs with Interpretable Checklists\n\n\n\nrobustness\n\n\neducation\n\n\n\nLLMs often struggle to accurately evaluate text generation in other LLMs, with shortcomings in detecting factual accuracy, coherence, and reasoning proficiency.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAgentDojo: A Dynamic Environment to Evaluate Attacks and Defenses for LLM Agents\n\n\n\nsecurity\n\n\n\nAI agents are vulnerable to prompt injection attacks; AgentDojo is a framework to evaluate and improve their adversarial robustness.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Contamination Can Cross Language Barriers\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nNew method detects deep contamination in large language models, evading current methods.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGUI Action Narrator: Where and When Did That Action Take Place?\n\n\n\nprompt-engineering\n\n\n\nGUI automation is improved with multimodal LLMs, aided by a new video captioning benchmark and framework, GUI Narrator, which uses cursor as visual prompt.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeHonest: Benchmarking Honesty of Large Language Models\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nTL;DR: BeHonest benchmark assesses honesty in LLMs, highlighting room for improvement.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThrough the Theory of Mind’s Eye: Reading Minds with Multimodal Video Large Language Models\n\n\n\neducation\n\n\nhci\n\n\n\nLLMs can reason about human emotions and intentions in videos, revealing their ToM reasoning process.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearning to Generate Answers with Citations via Factual Consistency Models\n\n\n\nrobustness\n\n\n\nThis paper proposes a method using factual consistency models to improve citation accuracy in LLMs, reducing hallucinations and enhancing reliability.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObscurePrompt: Jailbreaking Large Language Models via Obscure Input\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\nsecurity\n\n\n\nObscurePrompt: New method for jailbreaking LLMs, improving attack effectiveness and defense robustness.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistributional reasoning in LLMs: Parallel reasoning processes in multi-hop reasoning\n\n\n\nprompt-engineering\n\n\nhci\n\n\n\nLLMs perform multi-hop reasoning via interpretable embeddings, revealing parallel reasoning paths and potential intermediate answers.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInvestigating Low-Cost LLM Annotation for~Spoken Dialogue Understanding Datasets\n\n\n\neducation\n\n\n\nImproving Spoken Dialogue Datasets with Fine-tuned Language Models.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSD-Eval: A Benchmark Dataset for Spoken Dialogue Understanding Beyond Words\n\n\n\nhci\n\n\n\nTL;DR: SD-Eval benchmark assesses spoken dialogue understanding & generation, focusing on paralinguistic & environmental info, with models conditioned on this data…\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLIT: Large Language Model Driven Intention Tracking for Proactive Human-Robot Collaboration – A Robot Sous-Chef Application\n\n\n\nprompt-engineering\n\n\n\nLIT predicts human intentions for proactive robot collaboration, reducing excessive prompting in long-horizon tasks.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVELO: A Vector Database-Assisted Cloud-Edge Collaborative LLM QoS Optimization Framework\n\n\n\nprogramming\n\n\nhci\n\n\n\nVELO framework uses edge-based vector database caching to optimize LLM QoS, reducing response time and costs without altering LLM structure.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemantic Structure-Mapping in LLM and Human Analogical Reasoning\n\n\n\neducation\n\n\nhci\n\n\n\nLLMs approach human-level performance in semantic structure-mapping tasks but aren’t entirely human-like.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvery Language Counts: Learn and Unlearn in Multilingual LLMs\n\n\n\nrobustness\n\n\n\nMultilingual LLMs can spread fake info; standard unlearning methods are inadequate. Comprehensive unlearning strategies needed.\n\n\n\nJun 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefending Against Social Engineering Attacks in the Age of LLMs\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nLLMs aid digital deception, but struggle with detection. ConvoSentinel, a modular defense pipeline, improves CSE detection and adaptability.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHopping Too Late: Exploring the Limitations of Large Language Models on Multi-Hop Queries\n\n\n\nrobustness\n\n\n\nLLMs solve multi-hop queries in later layers, but sometimes lack needed knowledge; back-patching analysis can improve accuracy.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPRePair: Pointwise Reasoning Enhance Pairwise Evaluating for Robust Instruction-Following Assessments\n\n\n\nsecurity\n\n\n\nLLMs’ biases impact pairwise evaluations more; hybrid method integrating pointwise reasoning improves robustness.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey on Human Preference Learning for Large Language Models\n\n\n\nrecommender\n\n\n\nThis survey explores human preference learning for large language models, covering feedback sources, modeling, usage, and evaluation.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing LLMs to Aid Annotation and Collection of Clinically-Enriched Data in Bipolar Disorder and Schizophrenia\n\n\n\neducation\n\n\n\nSmall language models excel in mental health research, outperforming large models in annotation, data collection, and scalability.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerating Educational Materials with Different Levels of Readability using LLMs\n\n\n\nrobustness\n\n\n\nTL;DR: Few-shot prompting improves AI’s ability to simplify educational texts, but quality concerns remain.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBenchmarks and Metrics for Evaluations of Code Generation: A Critical Review\n\n\n\nprogramming\n\n\n\nThis paper reviews methods for testing and evaluating LLMs in code generation, focusing on benchmarks and metrics.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn the Robustness of Language Models for Tabular Question Answering\n\n\n\neducation\n\n\n\nLLMs, like Llama3, excel in table comprehension, but improvements are needed for robustness and handling domain-specific data.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards a Client-Centered Assessment of LLM Therapists by Client Simulation\n\n\n\nsecurity\n\n\n\nThis work proposes ClientCAST, an approach using LLMs to simulate clients and assess LLM therapists, focusing on session outcome, therapeutic alliance, and self-reported…\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?\n\n\n\neducation\n\n\n\nLLMs, like GPT-4, show inconsistency despite high capability; harder data boosts consistency.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCleanGen: Mitigating Backdoor Attacks for Generation Tasks in Large Language Models\n\n\n\nprogramming\n\n\nrobustness\n\n\nsecurity\n\n\n\nCleanGen: A defense strategy for LLMs that mitigates backdoor attacks, reducing attack success rates with minimal computational overhead.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSNAP: Unlearning Selective Knowledge in Large Language Models with Negative Instructions\n\n\n\nprogramming\n\n\nrobustness\n\n\n\nSnap framework selectively unlearns information from LLMs, preserving performance and unlearning specified data.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentifying Performance-Sensitive Configurations in Software Systems through Code Analysis with LLM Agents\n\n\n\nrobustness\n\n\neducation\n\n\n\nPerfSense, an LLM-based framework, accurately identifies performance-sensitive configurations, outperforming previous methods and offering insights for future research.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM4MSR: An LLM-Enhanced Paradigm for Multi-Scenario Recommendation\n\n\n\nrecommender\n\n\n\nLLM4MSR: Efficient, Effective, Interpretable Multi-Scenario Recommendation Paradigm using LLM.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJailbreak Paradox: The Achilles’ Heel of LLMs\n\n\n\nsecurity\n\n\n\nJailbreaking foundation models: Perfect detection is impossible, and weaker models can’t consistently detect jailbreaks in stronger models.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Did I Do Wrong? Quantifying LLMs’ Sensitivity and Consistency to Prompt Engineering\n\n\n\nprogramming\n\n\n\nLLMs face debugging challenges; new metrics sensitivity and consistency introduced for classification tasks to improve LLM performance and robustness.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn-Policy Fine-grained Knowledge Feedback for Hallucination Mitigation\n\n\n\nrobustness\n\n\n\nRLFH is an online reinforcement learning method for hallucination mitigation in LLMs, using fine-grained feedback and an LLM-based fact assessment framework.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBreaking the Ceiling of the LLM Community by Treating Token Generation as a Classification for Ensembling\n\n\n\nrobustness\n\n\n\nGaC: Ensembling LLMs by treating token generation as classification improves performance and reduces latency.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUBENCH: Benchmarking Uncertainty in Large Language Models with Multiple Choice Questions\n\n\n\neducation\n\n\n\nUBench is a new benchmark for evaluating LLM reliability, offering improved performance and resource efficiency. It finds GLM4 and GPT-4 as the most reliable LLMs.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdversarial Attacks on Large Language Models in Medicine\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nLLMs in healthcare are vulnerable to adversarial attacks, requiring robust security measures for safe deployment.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTalk With Human-like Agents: Empathetic Dialogue Through Perceptible Acoustic Reception and Reaction\n\n\n\nrobustness\n\n\n\nPerceptiveAgent: LLM-based dialogue system discerns deeper meanings using speech modality, improving contextual understanding and empathetic responses.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodeNav: Beyond tool-use to using real-world codebases with LLM agents\n\n\n\nprogramming\n\n\n\nCodeNav: LLM agent navigates unseen code repositories, solving queries without manual tool registration, and outperforms tool-use agents in benchmarks.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan We Trust Large Language Models Generated Code? A Framework for In-Context Learning, Security Patterns, and Code Evaluations Across Diverse LLMs\n\n\n\nprogramming\n\n\nrobustness\n\n\nsecurity\n\n\n\nLLMs for code generation may perpetuate vulnerabilities; ICL-driven learning can enhance code security, reducing risks in various programming scenarios.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPFID: Privacy First Inference Delegation Framework for LLMs\n\n\n\nrobustness\n\n\n\nPFID framework for LLMs enhances privacy by localizing user data, using model sharding, and singular value decomposition, while maintaining system performance.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNavigating the Labyrinth: Evaluating and Enhancing LLMs’ Ability to Reason About Search Problems\n\n\n\nprogramming\n\n\n\nLLMs struggle with logic problems; in-context learning with A* algorithm and Multi-Stage-Multi-Try method improves performance.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMAGIC: Generating Self-Correction Guideline for In-Context Text-to-SQL\n\n\n\nrobustness\n\n\n\nMAGIC automates self-correction guideline creation in text-to-SQL, outperforming human-crafted guidelines and improving interpretability.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCherryRec: Enhancing News Recommendation Quality via LLM-driven Framework\n\n\n\nrecommender\n\n\nprogramming\n\n\n\nCherryRec: A LLM-based news recommendation framework for efficient, high-quality recommendations.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPDSS: A Privacy-Preserving Framework for Step-by-Step Distillation of Large Language Models\n\n\n\nsecurity\n\n\n\nPDSS: Privacy-preserving framework distills LLMs for domain-specific tasks, ensuring data privacy and improved performance in text generation tasks.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond Under-Alignment: Atomic Preference Enhanced Factuality Tuning for Large Language Models\n\n\n\nrobustness\n\n\n\nLLMs struggle with factuality in OOD datasets; APEFT framework improves factuality by 3.45% on average.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-enhanced Reranking in Recommender Systems\n\n\n\nrecommender\n\n\n\nLLM-enhanced reranking framework improves accuracy, diversity, and fairness in recommendations, outperforming existing models.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretable Catastrophic Forgetting of Large Language Model Fine-tuning via Instruction Vector\n\n\n\nprogramming\n\n\n\nFine-tuning LLMs may not erase previous skills, but add specialized reasoning; IV-guided training mitigates catastrophic forgetting.\n\n\n\nJun 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen Box Meets Graph Neural Network in Tag-aware Recommendation\n\n\n\nrecommender\n\n\n\nTL;DR: BoxGNN improves tag-aware recommender systems by modeling user preferences with high-order signals and box embeddings.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey on Human Preference Learning for Large Language Models\n\n\n\nrecommender\n\n\n\nThis survey explores human preference learning for LLMs, covering feedback sources, modeling, usage, and evaluation.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Collaborative Data Analytics System with Recommender for Diverse Users\n\n\n\nrecommender\n\n\n\nSLEGO system bridges developer-novice gap with modular microservices, GUI, and LLM-powered recommendations, democratizing data analytics.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShould AI Optimize Your Code? A Comparative Study of Current Large Language Models Versus Classical Optimizing Compilers\n\n\n\nprogramming\n\n\n\nLLMs, like CodeLlama-70B, show potential in code optimization, but may generate incorrect code on large sizes, requiring automated verification. CETUS is the top optimizing…\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf and Cross-Model Distillation for LLMs: Effective Methods for Refusal Pattern Alignment\n\n\n\nprogramming\n\n\n\nLLMs can be secured against toxic prompts via alignment techniques like SFT and RLHF. Distillation methods, especially cross-model, significantly improve refusal rates and…\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDocCGen: Document-based Controlled Code Generation\n\n\n\nprogramming\n\n\n\nDocCGen improves LLMs for structured DSLs like YAML, JSON by leveraging documentation for better code generation.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoSQA+: Enhancing Code Search Dataset with Matching Code\n\n\n\nprogramming\n\n\n\nCoSQA+ improves code search with diverse, high-quality query-code pairs, outperforming CoSQA and introducing a new metric, MMRR.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIterative or Innovative? A Problem-Oriented Perspective for Code Optimization\n\n\n\nprogramming\n\n\n\nThis paper explores code optimization with LLMs, focusing on execution time reduction. It introduces a problem-oriented approach, significantly improving optimization…\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDELRec: Distilling Sequential Pattern to Enhance LLM-based Recommendation\n\n\n\nrecommender\n\n\n\nDELRec framework improves sequential recommendations by extracting patterns from SR models and integrating them into LLMs, enhancing their performance.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging\n\n\n\nprogramming\n\n\n\nTreeInstruct, a state-space planning-based agent, effectively guides students in debugging code using Socratic questioning.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Critical Study of What Code-LLMs (Do Not) Learn\n\n\n\nprogramming\n\n\n\nCode-LLMs struggle to encode relations between syntax and identifiers, with larger models encoding less code info than smaller ones.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRePrompt: Planning by Automatic Prompt Engineering for Large Language Models Agents\n\n\n\nprogramming\n\n\n\nRePrompt optimizes LLM prompts for better performance in tasks like code generation and travel planning.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLong Code Arena: a Set of Benchmarks for Long-Context Code Models\n\n\n\nprogramming\n\n\n\nLong Code Arena: Benchmarks for Project-wide Code Processing Tasks\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nREPOEXEC: Evaluate Code Generation with a Repository-Level Executable Benchmark\n\n\n\nprogramming\n\n\n\nRepoExec benchmark evaluates code generation at repository-level, focusing on executability, correctness, and dependency integration.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWaDec: Decompile WebAssembly Using Large Language Model\n\n\n\nprogramming\n\n\n\nWaDec, a fine-tuned LLM, decompiles Wasm binary code into readable source code, outperforming current tools with improved metrics and code comprehension.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnveiling Assumptions: Exploring the Decisions of AI Chatbots and Human Testers\n\n\n\nprogramming\n\n\n\nLLM-based chatbots can aid software testers in decision-making, with some aligning with human intuition in preferring diverse test scenarios.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-Layer Ranking with Large Language Models for News Source Recommendation\n\n\n\nrecommender\n\n\n\nLLMs improve expert recommendation for news events, using a multi-layer ranking framework on the NewsQuote dataset.\n\n\n\nJun 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models for Automatic Milestone Detection in Group Discussions\n\n\n\nprogramming\n\n\n\nAuthors submit electronic manuscripts for IJCAI–24 Proceedings, which will be printed and included in the online version.\n\n\n\nJun 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-Agent Software Development through Cross-Team Collaboration\n\n\n\nprogramming\n\n\n\nCross-Team Collaboration (CTC) improves LLM-driven software development quality by exploring multiple decision paths.\n\n\n\nJun 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhere Do Large Language Models Fail When Generating Code?\n\n\n\nprogramming\n\n\n\nLLMs struggle with reliable code generation, exhibiting varied semantic and syntactic errors. Different factors impact these errors, posing challenges for future LLM code…\n\n\n\nJun 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Next Era of Multi-objective Optimization: Large Language Models as Architects of Evolutionary Operators\n\n\n\nprogramming\n\n\n\nTL;DR: LLM-based framework evolves EA operators for MOPs, reducing expert intervention and improving performance.\n\n\n\nJun 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3D Building Generation in Minecraft via Large Language Models\n\n\n\nprogramming\n\n\n\nLLMs can generate complete 3D buildings in Minecraft, including facades, indoor scenes, and functional blocks, with user-specified requirements.\n\n\n\nJun 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproving LLMs for Recommendation with Out-Of-Vocabulary Tokens\n\n\n\nrecommender\n\n\n\nTL;DR: Improving LLM-based recommender systems with out-of-vocabulary tokens for better user-item representation.\n\n\n\nJun 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeaching Language Models to Self-Improve by Learning from Language Feedback\n\n\n\nsocial-sciences\n\n\n\nSRT uses model feedback for alignment, reducing reliance on human annotations, and significantly improves model performance across tasks and sizes.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvancing Annotation of Stance in Social Media Posts: A Comparative Analysis of Large Language Models and Crowd Sourcing\n\n\n\nproduction\n\n\nsocial-sciences\n\n\n\nLLMs’ stance annotation accuracy depends on text’s explicitness, often mirroring human performance.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProgressive Query Expansion for Retrieval Over Cost-constrained Data Sources\n\n\n\nrobustness\n\n\n\nProQE combines PRF and LLMs for progressive query expansion, improving accuracy and cost-effectiveness in retrieval systems.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLimited Out-of-Context Knowledge Reasoning in Large Language Models\n\n\n\narchitectures\n\n\nproduction\n\n\neducation\n\n\n\nLLMs struggle with out-of-context reasoning and cross-lingual knowledge transfer, despite training adjustments.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAccessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B\n\n\n\narchitectures\n\n\neducation\n\n\n\nMCTSr algorithm improves LLMs’ mathematical reasoning by integrating Monte Carlo Tree Search, enhancing accuracy in complex tasks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models for Constrained-Based Causal Discovery\n\n\n\nhci\n\n\n\nLLMs can assist in causal graph generation, but performance varies. A statistical-inspired voting schema improves results, suggesting potential for knowledge-based CIT in…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReinforcement Learning from Human Feedback without Reward Inference: Model-Free Algorithm and Instance-Dependent Analysis\n\n\n\narchitectures\n\n\nproduction\n\n\n\nRLHF not harder than classic RL; end-to-end RLHF can improve performance by avoiding pitfalls in reward inference.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMBBQ: A Dataset for Cross-Lingual Comparison of Stereotypes in Generative LLMs\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLLMs exhibit language-dependent biases, with non-English languages suffering more. MBBQ dataset reveals cross-lingual differences in bias behavior.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Human-AI Collaboration in Healthcare: Guided Deferral Systems with Large Language Models\n\n\n\nsocial-sciences\n\n\n\nTL;DR: Human-AI collaboration improves LLMs’ reliability in healthcare, reducing uncertainty via a guided deferral system.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSingle-Codec: Single-Codebook Speech Codec towards High-Performance Speech Generation\n\n\n\nproduction\n\n\n\nSingle-Codec, a single-sequence codec, improves TTS efficiency and robustness, outperforming multi-codebook codecs in quality, bandwidth, and LLM-TTS performance.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBertaQA: How Much Do Language Models Know About Local Culture?\n\n\n\nsocial-sciences\n\n\n\nLLMs struggle with local cultural knowledge but improve with continued pre-training in that language.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDCA-Bench: A Benchmark for Dataset Curation Agents\n\n\n\narchitectures\n\n\n\nLLMs can help curate datasets, but real-world issues are complex. DCA-Bench measures LLM agents’ ability to detect dataset quality issues.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaying More Attention to Source Context: Mitigating Unfaithful Translations from Large Language Model\n\n\n\nrobustness\n\n\n\nLLMs can generate unfaithful translations due to bias towards target tokens. Our methods encourage LLMs to focus more on source context, reducing hallucinatory translations.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards more realistic evaluation of LLM-based code generation: an experimental study and beyond\n\n\n\nrobustness\n\n\nprogramming\n\n\n\n[TEXT] This study examines the impact of social media on the mental health of adolescents. Results indicate a significant correlation between excessive social media use and…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Probabilistic Framework for LLM Hallucination Detection via Belief Tree Propagation\n\n\n\nrobustness\n\n\n\nBTProp: New method improves hallucination detection in LLMs by 3%-9% via a belief tree and hidden Markov tree model.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nToxic Memes: A Survey of Computational Perspectives on the Detection and Explanation of Meme Toxicities\n\n\n\narchitectures\n\n\nhci\n\n\nsocial-sciences\n\n\n\nSurvey on toxic memes: new taxonomy, trends, and challenges in computational analysis.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOPTune: Efficient Online Preference Tuning\n\n\n\nrecommender\n\n\n\nTL;DR: OPTune speeds up online preference tuning for LLMs, maintaining benefits while reducing training time.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJoint Demonstration and Preference Learning Improves Policy Alignment with Human Feedback\n\n\n\nsocial-sciences\n\n\n\nTL;DR: AIHF outperforms RLHF and DPO in aligning human preference and value in AI, especially with limited data.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nValidating LLM-Generated Programs with Metamorphic Prompt Testing\n\n\n\nrobustness\n\n\nsecurity\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\nTL;DR: Metamorphic prompt testing detects 75% of GPT-4’s erroneous code, with 8.6% false positives.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoEvol: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation\n\n\n\nhci\n\n\neducation\n\n\n\nCoEvol: LLM-based framework improves instruction responses, outperforming baselines in MT-Bench and AlpacaEval.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGuiding LLM Temporal Logic Generation with Explicit Separation of Data and Control\n\n\n\narchitectures\n\n\n\nLLMs can improve reactive program synthesis by separating control and data in temporal logic specifications, enhancing specification generation.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMerging Improves Self-Critique Against Jailbreak Attacks\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nMerging and self-critique improve LLM robustness against jailbreak attacks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVersiCode: Towards Version-controllable Code Generation\n\n\n\narchitectures\n\n\nproduction\n\n\nprogramming\n\n\n\nTL;DR: VersiCode dataset tests LLMs’ ability to generate version-correct code, revealing challenges and limitations.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFaceGPT: Self-supervised Learning to Chat about 3D Human Faces\n\n\n\neducation\n\n\n\nFaceGPT: Self-supervised 3D face reconstruction from images and text, without 3D annotations.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3D-Properties: Identifying Challenges in DPO and Charting a Path Forward\n\n\n\narchitectures\n\n\nsocial-sciences\n\n\neducation\n\n\n\nDPO in LLMs: Examining 3D-properties, issues, and solutions for better alignment with human preference.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuickLLaMA: Query-aware Inference Acceleration for Large Language Models\n\n\n\narchitectures\n\n\nproduction\n\n\n\nQ-LLM enhances LLMs’ context understanding, improving accuracy on benchmarks without extra training.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Large Language Models for Relevance Judgments in Tetun\n\n\n\narchitectures\n\n\n\nLLMs can automate relevance assessments in low-resource languages, with results similar to high-resource languages.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPITCH: Productivity and Mental Well-being Coaching through Daily Conversational Interaction\n\n\n\nproduction\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\nhci\n\n\n\nPITCH: A conversational AI for productivity, using rotating prompts to boost engagement and mental well-being.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTHaLLE: Text Hyperlocally Augmented Large Language Extension – Technical Report\n\n\n\narchitectures\n\n\nproduction\n\n\nprompt-engineering\n\n\neducation\n\n\n\nLLMs show promise in financial analysis, with our 8B THaLLE models outperforming others on mock CFA exams.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnomaly Detection on Unstable Logs with GPT Models\n\n\n\narchitectures\n\n\nproduction\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\nLLM (GPT-3) outperforms supervised baselines for anomaly detection on unstable logs, with fine-tuning superior to prompt engineering.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRS-Agent: Automating Remote Sensing Tasks through Intelligent Agents\n\n\n\nprompt-engineering\n\n\n\nTL;DR: RS-Agent: A LLM-driven remote sensing agent excelling in complex tasks, outperforming in scene classification, visual question answering, and object counting.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understanding in Video-LLMs\n\n\n\nproduction\n\n\neducation\n\n\n\nVideoLLaMA 2 improves video and audio understanding with competitive results in multimodal tasks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees\n\n\n\nprogramming\n\n\n\nTP-LLaMA model outperforms baselines in tool-augmented LLMs by optimizing inference trajectories using preference data from decision trees, enhancing utilization of expert…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTextGrad: Automatic Differentiation via Text\n\n\n\narchitectures\n\n\nproduction\n\n\n\nTextGrad optimizes compound AI systems by backpropagating textual feedback, improving performance across various tasks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMcEval: Massively Multilingual Code Evaluation\n\n\n\narchitectures\n\n\nprogramming\n\n\neducation\n\n\nproduction\n\n\nprompt-engineering\n\n\n\nTL;DR: Introducing McEval, a multilingual code benchmark for 40 languages, challenging LLMs in code tasks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDARA: Decomposition-Alignment-Reasoning Autonomous Language Agent for Question Answering over Knowledge Graphs\n\n\n\nhci\n\n\nprompt-engineering\n\n\n\nDARA framework improves LLM-powered agents’ KGQA performance, outperforming in-context learning-based agents and alternative fine-tuned agents.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Tool for Test Case Scenarios Generation Using Large Language Models\n\n\n\nhci\n\n\nprompt-engineering\n\n\neducation\n\n\nprogramming\n\n\n\nTL;DR: Tool generates test case scenarios from user requirements using an LLM-based agent.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraphCoder: Enhancing Repository-Level Code Completion via Code Context Graph-based Retrieval and Language Model\n\n\n\nprogramming\n\n\n\nGraphCoder improves code completion with a graph-based retrieval-generation process, outperforming baseline methods in accuracy and efficiency.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHalluDial: A Large-Scale Benchmark for Automatic Dialogue-Level Hallucination Evaluation\n\n\n\nrobustness\n\n\n\nHalluDial: A Comprehensive Benchmark for Automatic Dialogue-Level Hallucination Evaluation in LLMs.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCAAP: Context-Aware Action Planning Prompting to Solve Computer Tasks with Front-End UI Only\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nLLM-based agent uses screenshots for context, achieving 94.4% success on MiniWoB++ problems with 1.48 demos per type, enabling broader automation applications.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOllabench: Evaluating LLMs’ Reasoning for Human-centric Interdependent Cybersecurity\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nOllaBench evaluates LLMs for cybersecurity, revealing commercial models lead in accuracy but have room for improvement, while smaller open-weight models show promise.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeveraging Large Language Models for Efficient Failure Analysis in Game Development\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nThis paper presents a method using Large Language Models to automatically identify code changes causing test failures, achieving 71% accuracy and reducing debugging time by…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpen-LLM-Leaderboard: From Multi-choice to Open-style Questions for LLMs Evaluation, Benchmark, and Arena\n\n\n\narchitectures\n\n\nproduction\n\n\nprompt-engineering\n\n\nhci\n\n\n\nLLMs may favor certain answer IDs due to biases. Open-style questions can eliminate this, but pose new challenges. We introduce the Open-LLM-Leaderboard to track LLM…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEfficiently Exploring Large Language Models for Document-Level Machine Translation with In-context Learning\n\n\n\nprompt-engineering\n\n\n\nLLMs struggle with document-level translation. Our Context-Aware Prompting method (CAP) improves LLM translation accuracy, cohesion, and coherence.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat’s in an embedding? Would a rose by any embedding smell as sweet?\n\n\n\neducation\n\n\n\n[TEXT] This study examines the relationship between social media use and mental health in young adults. Results suggest a negative correlation between excessive social media…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstruct Large Language Models to Drive like Humans\n\n\n\narchitectures\n\n\n\nInstructDriver: Transforming LLM into a motion planner with human-aligned behavior for autonomous driving.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWorld Models with Hints of Large Language Models for Goal Achieving\n\n\n\nproduction\n\n\nhci\n\n\n\nDLLM, a multi-modal RL approach, improves exploration in long-horizon tasks by integrating hinting subgoals from LLMs, outperforming recent methods in sparse-reward…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDR-RAG: Applying Dynamic Document Relevance to Retrieval-Augmented Generation for Question-Answering\n\n\n\narchitectures\n\n\n\nDR-RAG improves QA accuracy by enhancing document retrieval, using a two-stage framework and a small classifier, while maintaining efficiency.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan I understand what I create? Self-Knowledge Evaluation of Large Language Models\n\n\n\nsocial-sciences\n\n\n\nLLMs struggle with self-generated questions due to human-alignment issues, but fine-tuning improves math performance.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedExQA: Medical Question Answering Benchmark with Multiple Explanations\n\n\n\neducation\n\n\n\nMedExQA benchmark evaluates medical knowledge in LLMs via explanations, highlighting the need for explainability. New medical model, MedPhi-2, outperforms Llama2-based…\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRepoQA: Evaluating Long Context Code Understanding\n\n\n\neducation\n\n\n\nRepoQA benchmark evaluates LLMs on long-context code understanding, showing gaps in open vs. proprietary models and language-specific strengths.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSafety Alignment Should Be Made More Than Just a Few Tokens Deep\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nShallow safety alignment in LLMs can lead to vulnerabilities; deepening alignment beyond initial tokens can improve robustness.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey of Backdoor Attacks and Defenses on Large Language Models: Implications for Security Measures\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nTL;DR: This paper explores backdoor attacks on large language models, categorizing them by fine-tuning methods and discussing future research directions.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecureNet: A Comparative Study of DeBERTa and Large Language Models for Phishing Detection\n\n\n\nrobustness\n\n\nsecurity\n\n\neducation\n\n\n\nTL;DR: DeBERTa V3 outperforms LLMs like GPT-4 in detecting phishing content, achieving 95.17% recall, while GPT-4 scores 91.04%.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSilent Signals, Loud Impact: LLMs for Word-Sense Disambiguation of Coded Dog Whistles\n\n\n\nsocial-sciences\n\n\n\nLLMs used to create dataset of 16,550 disambiguated dog whistle examples for hate speech detection and political science.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow Efficient is LLM-Generated Code? A Rigorous & High-Standard Benchmark\n\n\n\nprogramming\n\n\n\nLLMs struggle to generate expert-level efficient code, per new benchmark ENAMEL, which evaluates efficiency and correctness of LLM-generated code.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards a Personal Health Large Language Model\n\n\n\neducation\n\n\n\nPH-LLM, a fine-tuned Gemini model, excels in personal health insights, outperforming experts in fitness and nearing their level in sleep, while accurately predicting sleep…\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHarnessing AI for efficient analysis of complex policy documents: a case study of Executive Order 14110\n\n\n\nsecurity\n\n\n\nAI systems Gemini 1.5 Pro and Claude 3 Opus excel in policy document analysis, rivaling human experts in accuracy but with greater efficiency.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan Language Models Serve as Text-Based World Simulators?\n\n\n\nsocial-sciences\n\n\n\nLLMs, like GPT-4, are not yet reliable text-based world simulators, despite their capabilities, as per the ByteSized32-State-Prediction benchmark.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM2CVD: Multi-Model Collaboration for Code Vulnerability Detection\n\n\n\nrobustness\n\n\nsecurity\n\n\nprogramming\n\n\n\nM2CVD combines LLMs and code models for improved vulnerability detection, outperforming baselines on real-world datasets.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niMotion-LLM: Motion Prediction Instruction Tuning\n\n\n\nrobustness\n\n\nhci\n\n\n\niMotion-LLM: A multimodal model for trajectory prediction in multi-agent scenarios, guided by textual instructions, enhancing safety and contextual relevance.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models\n\n\n\nrobustness\n\n\nsecurity\n\n\nprompt-engineering\n\n\n\nTL;DR: Chain-of-Scrutiny (CoS) is a user-friendly, black-box defense against backdoor attacks in LLMs, ensuring reasoning consistency to detect attacks.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDecision-Making Behavior Evaluation Framework for LLMs under Uncertain Context\n\n\n\nrobustness\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLLMs, like ChatGPT-4.0-Turbo, Claude-3-Opus, and Gemini-1.0-pro, exhibit human-like decision-making patterns but vary in risk, probability, and loss aversion. Ethical…\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStronger, Faster, and Cheaper Log Parsing with LLMs\n\n\n\neducation\n\n\n\nLogBatcher: Cost-effective LLM-based log parser with no training or labeled data, using clustering and cache matching for efficient parsing.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRaccoon: Prompt Extraction Benchmark of LLM-Integrated Applications\n\n\n\nrobustness\n\n\nsecurity\n\n\nprompt-engineering\n\n\neducation\n\n\n\nRaccoon benchmark evaluates LLM susceptibility to prompt extraction attacks, offering insights and defenses.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTransforming Wearable Data into Health Insights using Large Language Model Agents\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nPHIA, a new AI system, accurately interprets wearable health data, potentially enabling personalized wellness insights.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSynth-SBDH: A Synthetic Dataset of Social and Behavioral Determinants of Health for Clinical Text\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nSynth-SBDH dataset improves SBDH extraction from clinical text, outperforming counterparts and proving effective for rare categories and resource constraints.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024\n\n\n\nhci\n\n\neducation\n\n\nsocial-sciences\n\n\n\nTeam HYU_MLLAB_KT solves SMART-101 CVPR 2024 challenge with LLM and object detection, achieving 29.5 accuracy on test set and 27.1 WOSA on challenge set.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs\n\n\n\nhci\n\n\n\nTL;DR: Our method uses context-aware, query-relevant knowledge graphs to improve LLM performance on complex questions, reducing token usage by up to 67%.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShould We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue\n\n\n\nhci\n\n\neducation\n\n\n\nLLM adaptation techniques vary in effectiveness based on base LLM and dialogue type; human evaluation is crucial.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating the Retrieval Component in LLM-Based Question Answering Systems\n\n\n\nhci\n\n\n\nBaseline for evaluating retrievers in RAG-based chatbots shows better performance assessment, considering LLMs’ strengths and weaknesses.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course\n\n\n\nsocial-sciences\n\n\nprogramming\n\n\neducation\n\n\nhci\n\n\nprompt-engineering\n\n\n\nStudents’ LLM usage in programming education influenced by career expectations, peer usage, and affects self-efficacy and midterm performance.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMolX: Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension\n\n\n\neducation\n\n\n\nLLMs struggle with molecule-related tasks; this study introduces MolX, a multi-modal external module, to enhance LLMs’ molecule comprehension, outperforming baselines in…\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Context Learning and Fine-Tuning GPT for Argument Mining\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nGPT-4 and GPT-3.5 excel in Argument Type Classification using In-Context Learning and fine-tuning, respectively.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge language models for generating rules, yay or nay?\n\n\n\nprogramming\n\n\n\nLLMs can aid engineering safety-critical systems by generating logic rules, but lack threshold generation ability.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn Empirical Design Justice Approach to Identifying Ethical Considerations in the Intersection of Large Language Models and Social Robotics\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLLMs in social robotics offer benefits but raise ethical concerns like misinformation, biased responses, and emotional disruption, exacerbated by physical embodiment.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection\n\n\n\nrobustness\n\n\nsecurity\n\n\nprogramming\n\n\n\nCodeBreaker: LLM-assisted backdoor attack framework for code completion models, evading vulnerability detection.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Food Safety in Supply Chains: The Potential Role of Large Language Models in Preventing Campylobacter Contamination\n\n\n\nrobustness\n\n\n\nTL;DR: GPTs can aid HACCP implementation to reduce Campylobacter contamination in the food supply chain, but barriers exist.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnnotation alignment: Comparing LLM and human annotations of conversational safety\n\n\n\nsecurity\n\n\nsocial-sciences\n\n\n\nGPT-4 aligns with human safety perceptions, but more data is needed to assess demographic disparities and idiosyncratic variation.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLanguage Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain\n\n\n\nsecurity\n\n\n\nNew dataset for medical triage decision-making; LLMs used as ethical decision-makers, alignable to different attributes.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLanguage Models Resist Alignment\n\n\n\nrobustness\n\n\n\nAlignment fine-tuning in LLMs is elastic and can revert to pre-training behavior, especially with larger models and more pre-training data.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDomainRAG: A Chinese Benchmark for Evaluating Domain-specific Retrieval-Augmented Generation\n\n\n\neducation\n\n\n\nRAG models outperform LLMs in domain-specific tasks like college enrollment, but improvements are needed in areas like conversation, structure analysis, and denoising.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Superalignment Framework in Autonomous Driving with Large Language Models\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nTL;DR: Novel security framework for autonomous vehicles using multi-agent LLM approach, ensuring data protection and adherence to regulations.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre Large Language Models Actually Good at Text Style Transfer?\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLLMs struggle with TST in non-English languages, but finetuning improves results, highlighting the need for dedicated datasets.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMrRank: Improving Question Answering Retrieval System through Multi-Result Ranking Model\n\n\n\nrobustness\n\n\n\nNew method combines IR systems for LLMs, improving performance and reducing hallucinations.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nZero-Shot End-To-End Spoken Question Answering In Medical Domain\n\n\n\nhci\n\n\n\nE2E methodologies for SQA in the medical domain require fewer resources and improve accuracy compared to traditional cascade systems.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHello Again! LLM-powered Personalized Agent for Long-term Dialogue\n\n\n\nhci\n\n\n\nLD-Agent: A framework for long-term dialogue systems with event memory, persona modeling, and response generation.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLGR2: Language Guided Reward Relabeling for Accelerating Hierarchical Reinforcement Learning\n\n\n\nhci\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\nprogramming\n\n\n\nLGR2: A language-guided HRL framework for robotic control, mitigating non-stationarity and achieving high success rates in complex tasks.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey on LLM-Based Agentic Workflows and LLM-Profiled Components\n\n\n\nprompt-engineering\n\n\n\nLLMs enable advanced workflows, focusing on reusable components for clearer role understanding.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n61A-Bot: AI homework assistance in CS1 is fast and cheap – but is it helpful?\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\n61A-Bot reduces homework completion time, but effects may not transfer to assignments without bot access.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDigital Business Model Analysis Using a Large Language Model\n\n\n\nhci\n\n\nprogramming\n\n\n\nThis study proposes an LLM-based method for comparing and analyzing similar companies across different business domains to support digital business model design.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States\n\n\n\nrobustness\n\n\n\nLLMs learn ethics in pre-training, align concepts with emotions, and refine for safe output. Jailbreaks disrupt this process, causing harm.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecurity Vulnerability Detection with Multitask Self-Instructed Fine-Tuning of Large Language Models\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\nsecurity\n\n\neducation\n\n\n\nMSIVD: Multitask LLM & GNN technique improves vulnerability detection, outperforming existing methods with F1 scores of 0.92 (BigVul) and 0.48 (PreciseBugs).\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Comprehensive Evaluation of Parameter-Efficient Fine-Tuning on Automated Program Repair\n\n\n\nprompt-engineering\n\n\n\nPEFT methods improve LLMs’ bug-fixing capabilities in APR, outperforming existing techniques. Larger parameters/datasets don’t guarantee better performance.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMoPS: Modular Story Premise Synthesis for Open-Ended Automatic Story Generation\n\n\n\nsocial-sciences\n\n\neducation\n\n\n\nMoPS generates diverse, fascinating, and original story premises for automatic story generation, outperforming existing methods.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo LLMs Exhibit Human-Like Reasoning? Evaluating Theory of Mind in LLMs for Open-Ended Responses\n\n\n\nhci\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLLMs struggle with Theory of Mind reasoning in open-ended questions, but incorporating human intentions and emotions can improve their performance, though not fully…\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models Memorize Sensor Datasets! Implications on Human Activity Recognition Research\n\n\n\nrobustness\n\n\n\nLLMs may have seen HAR benchmark data during training, potentially skewing evaluation results.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Against the RAG: Jamming Retrieval-Augmented Generation with Blocker Documents\n\n\n\nrobustness\n\n\n\nTL;DR: RAG systems are vulnerable to jamming attacks using blocker documents, which can prevent them from answering queries. New methods for generating blocker documents are…\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo LLMs Recognize me, When I is not me: Assessment of LLMs Understanding of Turkish Indexical Pronouns in Indexical Shift Contexts\n\n\n\nsocial-sciences\n\n\n\nTL;DR: Advanced LLMs struggle with Turkish’s unique grammatical challenge, the Indexical Shift, highlighting the need for low-resource language research.\n\n\n\nJun 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreativity Has Left the Chat: The Price of Debiasing Language Models\n\n\n\nhci\n\n\nprompt-engineering\n\n\n\nRLHF alignment in LLMs reduces toxicity but limits creativity, impacting marketing tasks. Balance between consistency and creativity is crucial.\n\n\n\nJun 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRefactoring to Pythonic Idioms: A Hybrid Knowledge-Driven Approach Leveraging Large Language Models\n\n\n\nprompt-engineering\n\n\n\nHybrid approach combines LLMs and rule-based methods for Python code idiomatization, outperforming LLM-only and rule-based approaches.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFastGAS: Fast Graph-based Annotation Selection for In-Context Learning\n\n\n\nprompt-engineering\n\n\n\nFastGAS: A graph-based method for efficient instance selection in in-context learning, improving performance and reducing selection time.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaCE: Parsimonious Concept Engineering for Large Language Models\n\n\n\nrobustness\n\n\n\nTL;DR: PaCE is a novel framework for aligning LLMs, improving output quality while preserving linguistic capabilities.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAligning Agents like Large Language Models\n\n\n\nhci\n\n\n\nWe align 3D agents with desired behaviors using LLM alignment techniques, improving imitation learning.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTool-Planner: Dynamic Solution Tree Planning for Large Language Model with Tool Clustering\n\n\n\neducation\n\n\n\nTL;DR: Tool-Planner improves tool learning in LLMs like GPT-4 and Claude 3, optimizing planning and handling errors.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRetrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining\n\n\n\nprompt-engineering\n\n\n\nContext-Aware RAG improves prompt-based TTS, outperforming text-only retrieval methods.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMEmbed: Rethinking Lightweight LLM’s Genuine Function in Text Classification\n\n\n\nprompt-engineering\n\n\n\nLLMEmbed: Efficient LLM-based text classification with low overhead.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey on Medical Large Language Models: Technology, Application, Trustworthiness, and Future Directions\n\n\n\nprogramming\n\n\n\nMed-LLMs revolutionize healthcare, offering clinical decision support, report generation, and medical education. Ethical considerations and robust evaluation are crucial for…\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoherent Zero-Shot Visual Instruction Generation\n\n\n\neducation\n\n\n\nNew framework generates consistent, visually appealing multi-step instructions using diffusion models and LLMs.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeneralization-Enhanced Code Vulnerability Detection via Multi-Task Instruction Fine-Tuning\n\n\n\nprogramming\n\n\n\nVulLLM, a multi-task framework with LLMs, outperforms SOTA models in vulnerability detection by capturing root causes, not just superficial features.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People\n\n\n\nhci\n\n\n\nThis study proposes a method to compare human and GPT-4 conversational tones, creating an interpretable representation of their relations.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM-QALM: A Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall in Large Language Models via Question Answering\n\n\n\neducation\n\n\n\nLLMs’ success in healthcare tasks depends on recall, comprehension, and integration of knowledge, with instruction tuning and fine-tuning on medical datasets showing promise.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuffer of Thoughts: Thought-Augmented Reasoning with Large Language Models\n\n\n\nprompt-engineering\n\n\n\nBoT improves LLMs’ reasoning, outperforming SOTA methods on 10 tasks with 12% cost, potentially surpassing Llama3-70B with Llama3-8B.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVerbalized Machine Learning: Revisiting Machine Learning with Language Models\n\n\n\nprompt-engineering\n\n\n\nVML uses LLMs to solve ML problems, offering easy encoding of inductive bias, automatic model class selection, and interpretable learner updates.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemantically Diverse Language Generation for Uncertainty Estimation in Language Models\n\n\n\nrobustness\n\n\n\nLLMs can hallucinate due to predictive uncertainty. SDLG quantifies this, improving trustworthiness and efficiency in LLMs.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models as Evaluators for Recommendation Explanations\n\n\n\nrecommender\n\n\n\nLLMs, like GPT4, can accurately evaluate recommendation explanations with proper prompts and settings, offering a cost-effective solution.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPOEM: Interactive Prompt Optimization for Enhancing Multimodal Reasoning of Large Language Models\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nIntroducing ame: A Visual Analytics System for Prompt Engineering in Multimodal LLMs.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBenchmark Data Contamination of Large Language Models: A Survey\n\n\n\nprogramming\n\n\n\nTL;DR: Large Language Models face Benchmark Data Contamination, requiring new evaluation methods for reliable performance.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfabulation: The Surprising Value of Large Language Model Hallucinations\n\n\n\nhci\n\n\n\nLLM confabulations mirror human narrativity, offering potential value in AI communication.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Do Language Models Learn in Context? The Structured Task Hypothesis\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\n[TEXT] This study examines the relationship between social media use and mental health in young adults. Results indicate a significant correlation between excessive social…\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAsk LLMs Directly, What shapes your bias?: Measuring Social Bias in Large Language Models\n\n\n\nhci\n\n\n\nThis paper proposes a method to quantify social biases in LLMs by considering diverse social perceptions, offering a more nuanced understanding of bias.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nText-to-Drive: Diverse Driving Behavior Synthesis via Large Language Models\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nTL;DR: Text-to-Drive (T2D) uses LLMs to generate diverse driving behaviors for autonomous vehicle simulation, offering a scalable and intuitive method for human operators.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDICE: Detecting In-distribution Contamination in LLM’s Fine-tuning Phase for Math Reasoning\n\n\n\neducation\n\n\n\nDICE detects in-distribution contamination in LLMs, potentially overestimating model capabilities.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nItem-Language Model for Conversational Recommendation\n\n\n\nrecommender\n\n\nprogramming\n\n\n\nTL;DR: Proposed Item-Language Model (ILM) addresses LLM limitations in recommender systems, aligning item representations with user interaction signals.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nText-like Encoding of Collaborative Information in Large Language Models for Recommendation\n\n\n\nrecommender\n\n\n\nBinLLM: A novel method integrating collaborative info into LLMs via text-like binary encoding, improving recommendation performance.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models\n\n\n\nprogramming\n\n\n\nThis work enhances LLMs for long texts by considering fragment-level relations, improving story understanding, code generation, and chatting.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Repository-Level Code Generation with Integrated Contextual Information\n\n\n\nprogramming\n\n\n\nCatCoder improves LLM code generation for repositories, outperforming RepoCoder by up to 17.35% in pass@k score, and shows consistent improvements across various LLMs.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSynthetic Programming Elicitation and Repair for Text-to-Code in Very Low-Resource Programming Languages\n\n\n\nprogramming\n\n\n\nLLMs struggle with unseen programming languages. SPEAC, a new approach, enables LLMs to generate valid code for these languages.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring User Retrieval Integration towards Large Language Models for Cross-Domain Sequential Recommendation\n\n\n\nrecommender\n\n\n\nURLLM improves CDSR by integrating user retrieval and domain grounding on LLM, addressing cold-start issues and semantic reasoning.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBIPED: Pedagogically Informed Tutoring System for ESL Education\n\n\n\neducation\n\n\n\nLLMs can serve as effective tutors for English learners. We developed a dataset and models that replicate human teachers’ diverse teaching strategies.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Detecting LLMs Hallucination via Markov Chain-based Multi-agent Debate Framework\n\n\n\nprogramming\n\n\n\nMarkov Chain-based multi-agent debate improves hallucination detection in LLMs, outperforming baselines.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Mathematical Extrapolation of Large Language Models with Synthetic Data\n\n\n\nprogramming\n\n\n\nLLMs excel in various tasks but struggle with multi-step reasoning. Fine-tuning on synthetic data improves performance in complex arithmetic puzzles.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models Make Sample-Efficient Recommender Systems\n\n\n\nrecommender\n\n\n\nLLMs improve recommender systems’ efficiency, needing less training data for superior performance.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChain of Agents: Large Language Models Collaborating on Long-Context Tasks\n\n\n\nprogramming\n\n\n\nChain-of-Agents (CoA) improves long-context tasks by dividing text among agents, showing up to 10% improvement over baselines.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe current status of large language models in summarizing radiology report impressions\n\n\n\nprogramming\n\n\n\nLLMs struggle to replace radiologists in summarizing radiology reports, despite few-shot prompt improvements.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPosition Debiasing Fine-Tuning for Causal Perception in Long-Term Dialogue\n\n\n\nprogramming\n\n\n\nCPD method alleviates position bias in LLMs, improving long-term dialogue relevance.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nXRec: Large Language Models for Explainable Recommendation\n\n\n\nrecommender\n\n\n\nXRec framework uses LLMs for explainable recommendations, outperforming baselines in understanding user preferences.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession Context Embedding for Intent Understanding in Product Search\n\n\n\nrecommender\n\n\n\nSession embedding improves search by capturing user intent from multiple engagements, outperforming single query-item pair relevance training.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models as Recommender Systems: A Study of Popularity Bias\n\n\n\nrecommender\n\n\n\nLLMs in recommenders can reduce popularity bias, showing less bias than traditional systems without explicit mitigation.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrivacy in LLM-based Recommendation: Recent Advances and Future Directions\n\n\n\nrecommender\n\n\n\nPrivacy in LLM-based recommendations: attacks, protection, challenges, and future directions.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Understand Whole Software Repository?\n\n\n\nprogramming\n\n\n\nTL;DR: RepoUnderstander improves ASE by understanding whole repositories, outperforming SWE-agent by 18.5%.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemCoder: Training Code Language Models with Comprehensive Semantics\n\n\n\nprogramming\n\n\n\nSemCoder: A 6.7B Code LLM excels in code generation and execution reasoning, outperforming GPT-3.5-turbo, by integrating semantics from multiple dimensions.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKnowledge Graph Tuning: Real-time Large Language Model Personalization based on Human Feedback\n\n\n\nrecommender\n\n\n\nKGT: A novel, efficient, and interpretable method for real-time personalization of LLMs using knowledge graphs, improving user experience and performance.\n\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKeyword-driven Retrieval-Augmented Large Language Models for Cold-start User Recommendations\n\n\n\nrecommender\n\n\n\nTL;DR: KALM4Rec improves cold-start recommendations using keywords and LLMs for candidate retrieval and re-ranking.\n\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerating Query Recommendations via LLMs\n\n\n\nrecommender\n\n\n\n[TEXT] This study examines the impact of climate change on the global wine industry. Results indicate significant shifts in wine production regions and grape varieties due…\n\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPreference Learning Algorithms Do Not Learn Preference Rankings\n\n\n\nrecommender\n\n\n\nDespite high performance, preference-tuned LLMs often have low ranking accuracy, due to limitations in the DPO objective and a gap between observed and idealized ranking…\n\n\n\nMay 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSLMRec: Empowering Small Language Models for Sequential Recommendation\n\n\n\nrecommender\n\n\n\nSLMRec: Small Language Model for Sequential Recommendation achieves 6.6x training, 8.0x inference speedups with 13% of LLM-based model parameters.\n\n\n\nMay 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRAGSys: Item-Cold-Start Recommender as RAG System\n\n\n\nrecommender\n\n\n\nICL for LLMs resembles item-cold-start recommenders, prioritizing discovery and maximizing information gain. Diversity and quality bias in demonstrations are crucial for…\n\n\n\nMay 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteLLM-2: Multimodal Large Representation Models for Recommendation\n\n\n\nrecommender\n\n\n\nTL;DR: NoteLLM-2 enhances multimodal representation in I2I recommendations by focusing on visual content and fusing it with textual information.\n\n\n\nMay 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMs for User Interest Exploration: A Hybrid Approach\n\n\n\nrecommender\n\n\n\nHybrid framework with LLMs and classic models improves novel interest discovery, boosting user enjoyment.\n\n\n\nMay 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNavigating User Experience of ChatGPT-based Conversational Recommender Systems: The Effects of Prompt Guidance and Recommendation Domain\n\n\n\nrecommender\n\n\n\nPrompt guidance in ChatGPT-based CRS enhances user experience, with book recommendations showing more engagement than job recommendations.\n\n\n\nMay 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSunnie: An Anthropomorphic LLM-Based Conversational Agent for Mental Well-Being Activity Recommendation\n\n\n\nrecommender\n\n\n\nThis LaTeX document guides authors on formatting ACM articles.\n\n\n\nMay 22, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Comparative_Analysis_of_Encoder_Based_NER_and_Large_Language_Models_for_Skill_Extraction_from_Russian_Job_Vacancies/2024-07-29-Comparative_Analysis_of_Encoder_Based_NER_and_Large_Language_Models_for_Skill_Extraction_from_Russian_Job_Vacancies.html#appendix",
    "href": "posts/Comparative_Analysis_of_Encoder_Based_NER_and_Large_Language_Models_for_Skill_Extraction_from_Russian_Job_Vacancies/2024-07-29-Comparative_Analysis_of_Encoder_Based_NER_and_Large_Language_Models_for_Skill_Extraction_from_Russian_Job_Vacancies.html#appendix",
    "title": "Comparative Analysis of Encoder-Based NER and Large Language Models for Skill Extraction from Russian Job Vacancies",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19816v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19816v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4205"
  },
  {
    "objectID": "posts/The_Emerged_Security_and_Privacy_of_LLM_Agent_A_Survey_with_Case_Studies/2024-07-28-The_Emerged_Security_and_Privacy_of_LLM_Agent_A_Survey_with_Case_Studies.html",
    "href": "posts/The_Emerged_Security_and_Privacy_of_LLM_Agent_A_Survey_with_Case_Studies/2024-07-28-The_Emerged_Security_and_Privacy_of_LLM_Agent_A_Survey_with_Case_Studies.html",
    "title": "The Emerged Security and Privacy of LLM Agent: A Survey with Case Studies",
    "section": "",
    "text": "Summary:\nThis paper provides a comprehensive overview of the privacy and security issues faced by Large Language Model (LLM) agents. LLM agents are sophisticated AI systems built on large language models like GPT 4, Claude 3, and Llama 3, which are used in various applications such as virtual assistants, customer service bots, and educational tools. The widespread applications of LLM agents demonstrate their significant commercial value; however, they also expose security and privacy vulnerabilities.\nThe paper categorizes the security threats faced by LLM agents into inherited LLM attacks and unique agent-specific threats. Inherited threats from LLMs include technical vulnerabilities such as hallucinations, catastrophic forgetting, and misunderstandings, as well as intentional malicious attacks like data theft and responses tampering. Agent-specific threats are categorized into knowledge poisoning, functional manipulation, and output manipulation.\nThe paper also explores the real-world impacts of these threats on users, environments, and other agents, highlighting the potential consequences of unmitigated risks. Existing mitigation strategies and solutions to address these threats are reviewed, and gaps in current research and future trends are discussed.\nMajor Findings:\nAnalysis and Critique:\nWhile the paper provides a comprehensive overview of the privacy and security issues faced by LLM agents, it does not delve into the specific methodologies used to address these threats. Additionally, the paper does not discuss the potential biases and ethical considerations that may arise from the use of LLM agents. Further research is needed to explore these aspects and develop more robust"
  },
  {
    "objectID": "posts/The_Emerged_Security_and_Privacy_of_LLM_Agent_A_Survey_with_Case_Studies/2024-07-28-The_Emerged_Security_and_Privacy_of_LLM_Agent_A_Survey_with_Case_Studies.html#appendix",
    "href": "posts/The_Emerged_Security_and_Privacy_of_LLM_Agent_A_Survey_with_Case_Studies/2024-07-28-The_Emerged_Security_and_Privacy_of_LLM_Agent_A_Survey_with_Case_Studies.html#appendix",
    "title": "The Emerged Security and Privacy of LLM Agent: A Survey with Case Studies",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19354v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19354v1\n\n\nTruncated\nFalse\n\n\nWord Count\n16899"
  },
  {
    "objectID": "posts/RAG_vs._Long_Context_Examining_Frontier_Large_Language_Models_for_Environmental_Review_Document_Comprehension/2024-07-10-RAG_vs._Long_Context_Examining_Frontier_Large_Language_Models_for_Environmental_Review_Document_Comprehension.html#appendix",
    "href": "posts/RAG_vs._Long_Context_Examining_Frontier_Large_Language_Models_for_Environmental_Review_Document_Comprehension/2024-07-10-RAG_vs._Long_Context_Examining_Frontier_Large_Language_Models_for_Environmental_Review_Document_Comprehension.html#appendix",
    "title": "RAG vs. Long Context: Examining Frontier Large Language Models for Environmental Review Document Comprehension",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07321v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07321v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8903"
  },
  {
    "objectID": "posts/Generating_Unseen_Code_Tests_In_Infinitum/2024-07-29-Generating_Unseen_Code_Tests_In_Infinitum.html#appendix",
    "href": "posts/Generating_Unseen_Code_Tests_In_Infinitum/2024-07-29-Generating_Unseen_Code_Tests_In_Infinitum.html#appendix",
    "title": "Generating Unseen Code Tests In Infinitum",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19772v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19772v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4413"
  },
  {
    "objectID": "posts/MMBench_Video_A_Long_Form_Multi_Shot_Benchmark_for_Holistic_Video_Understanding/2024-06-20-MMBench_Video_A_Long_Form_Multi_Shot_Benchmark_for_Holistic_Video_Understanding.html#appendix",
    "href": "posts/MMBench_Video_A_Long_Form_Multi_Shot_Benchmark_for_Holistic_Video_Understanding/2024-06-20-MMBench_Video_A_Long_Form_Multi_Shot_Benchmark_for_Holistic_Video_Understanding.html#appendix",
    "title": "MMBench-Video: A Long-Form Multi-Shot Benchmark for Holistic Video Understanding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14515v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14515v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8501"
  },
  {
    "objectID": "posts/Measuring_and_Benchmarking_Large_Language_Models_Capabilities_to_Generate_Persuasive_Language/2024-06-25-Measuring_and_Benchmarking_Large_Language_Models_Capabilities_to_Generate_Persuasive_Language.html#appendix",
    "href": "posts/Measuring_and_Benchmarking_Large_Language_Models_Capabilities_to_Generate_Persuasive_Language/2024-06-25-Measuring_and_Benchmarking_Large_Language_Models_Capabilities_to_Generate_Persuasive_Language.html#appendix",
    "title": "Measuring and Benchmarking Large Language Models’ Capabilities to Generate Persuasive Language",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17753v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17753v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10078"
  },
  {
    "objectID": "posts/Can_Language_Models_Evaluate_Human_Written_Text_Case_Study_on_Korean_Student_Writing_for_Education/2024-07-24-Can_Language_Models_Evaluate_Human_Written_Text_Case_Study_on_Korean_Student_Writing_for_Education.html#appendix",
    "href": "posts/Can_Language_Models_Evaluate_Human_Written_Text_Case_Study_on_Korean_Student_Writing_for_Education/2024-07-24-Can_Language_Models_Evaluate_Human_Written_Text_Case_Study_on_Korean_Student_Writing_for_Education.html#appendix",
    "title": "Can Language Models Evaluate Human Written Text? Case Study on Korean Student Writing for Education",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17022v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17022v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2789"
  },
  {
    "objectID": "posts/Persuasiveness_of_Generated_Free_Text_Rationales_in_Subjective_Decisions_A_Case_Study_on_Pairwise_Argument_Ranking/2024-06-20-Persuasiveness_of_Generated_Free_Text_Rationales_in_Subjective_Decisions_A_Case_Study_on_Pairwise_Argument_Ranking.html#appendix",
    "href": "posts/Persuasiveness_of_Generated_Free_Text_Rationales_in_Subjective_Decisions_A_Case_Study_on_Pairwise_Argument_Ranking/2024-06-20-Persuasiveness_of_Generated_Free_Text_Rationales_in_Subjective_Decisions_A_Case_Study_on_Pairwise_Argument_Ranking.html#appendix",
    "title": "Persuasiveness of Generated Free-Text Rationales in Subjective Decisions: A Case Study on Pairwise Argument Ranking",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13905v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13905v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6514"
  },
  {
    "objectID": "posts/Enhancing_Language_Model_Rationality_with_Bi_Directional_Deliberation_Reasoning/2024-07-08-Enhancing_Language_Model_Rationality_with_Bi_Directional_Deliberation_Reasoning.html#appendix",
    "href": "posts/Enhancing_Language_Model_Rationality_with_Bi_Directional_Deliberation_Reasoning/2024-07-08-Enhancing_Language_Model_Rationality_with_Bi_Directional_Deliberation_Reasoning.html#appendix",
    "title": "Enhancing Language Model Rationality with Bi-Directional Deliberation Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06112v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06112v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5655"
  },
  {
    "objectID": "posts/GermanPartiesQA_Benchmarking_Commercial_Large_Language_Models_for_Political_Bias_and_Sycophancy/2024-07-25-GermanPartiesQA_Benchmarking_Commercial_Large_Language_Models_for_Political_Bias_and_Sycophancy.html#appendix",
    "href": "posts/GermanPartiesQA_Benchmarking_Commercial_Large_Language_Models_for_Political_Bias_and_Sycophancy/2024-07-25-GermanPartiesQA_Benchmarking_Commercial_Large_Language_Models_for_Political_Bias_and_Sycophancy.html#appendix",
    "title": "GermanPartiesQA: Benchmarking Commercial Large Language Models for Political Bias and Sycophancy",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.18008v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.18008v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6995"
  },
  {
    "objectID": "posts/Semantic_Structure_Mapping_in_LLM_and_Human_Analogical_Reasoning/2024-06-19-Semantic_Structure_Mapping_in_LLM_and_Human_Analogical_Reasoning.html#appendix",
    "href": "posts/Semantic_Structure_Mapping_in_LLM_and_Human_Analogical_Reasoning/2024-06-19-Semantic_Structure_Mapping_in_LLM_and_Human_Analogical_Reasoning.html#appendix",
    "title": "Semantic Structure-Mapping in LLM and Human Analogical Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13803v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13803v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12911"
  },
  {
    "objectID": "posts/3D_Building_Generation_in_Minecraft_via_Large_Language_Models/2024-06-13-3D_Building_Generation_in_Minecraft_via_Large_Language_Models.html#appendix",
    "href": "posts/3D_Building_Generation_in_Minecraft_via_Large_Language_Models/2024-06-13-3D_Building_Generation_in_Minecraft_via_Large_Language_Models.html#appendix",
    "title": "3D Building Generation in Minecraft via Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.08751v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.08751v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4481"
  },
  {
    "objectID": "posts/Empirical_Study_of_Symmetrical_Reasoning_in_Conversational_Chatbots/2024-07-08-Empirical_Study_of_Symmetrical_Reasoning_in_Conversational_Chatbots.html#appendix",
    "href": "posts/Empirical_Study_of_Symmetrical_Reasoning_in_Conversational_Chatbots/2024-07-08-Empirical_Study_of_Symmetrical_Reasoning_in_Conversational_Chatbots.html#appendix",
    "title": "Empirical Study of Symmetrical Reasoning in Conversational Chatbots",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05734v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05734v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4950"
  },
  {
    "objectID": "posts/Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models/2024-06-08-Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models.html",
    "href": "posts/Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models/2024-06-08-Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models.html",
    "title": "Creativity Has Left the Chat: The Price of Debiasing Language Models",
    "section": "",
    "text": "Summary:\nThe paper “Creativity Has Left the Chat: The Price of Debiasing Language Models” explores the impact of the Reinforcement Learning from Human Feedback (RLHF) process on the creativity and output diversity of Large Language Models (LLMs). The authors use the Llama-2 series of models to conduct three experiments, focusing on the Llama-2-7B-text (base model) and Llama-2-7B-chat (aligned model). The experiments reveal that while RLHF effectively reduces biases and toxicity in LLMs, it may inadvertently lead to a reduction in the models’ creative potential. The aligned models exhibit lower entropy in token predictions, form distinct clusters in the embedding space, and gravitate towards “attractor states,” indicating limited output diversity. These findings have significant implications for marketers who rely on LLMs for creative tasks, as the trade-off between consistency and creativity in aligned models should be carefully considered.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides valuable insights into the unintended consequences of the RLHF process on the creativity and output diversity of LLMs. However, the study is limited by the computational costs and resource demands, which prevented the authors from delving into various parameters or configurations of the RLHF process. Future research should explore different parameters and configurations to understand their impact on the creativity and output diversity of aligned LLMs. Additionally, further investigation is needed to analyze other unintended consequences of model alignment and RLHF to enhance our understanding of the trade-offs involved in practical applications of these models."
  },
  {
    "objectID": "posts/Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models/2024-06-08-Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models.html#appendix",
    "href": "posts/Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models/2024-06-08-Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models.html#appendix",
    "title": "Creativity Has Left the Chat: The Price of Debiasing Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05587v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05587v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20391"
  },
  {
    "objectID": "posts/Follow_the_Rules_Reasoning_for_Video_Anomaly_Detection_with_Large_Language_Models/2024-07-14-Follow_the_Rules_Reasoning_for_Video_Anomaly_Detection_with_Large_Language_Models.html#appendix",
    "href": "posts/Follow_the_Rules_Reasoning_for_Video_Anomaly_Detection_with_Large_Language_Models/2024-07-14-Follow_the_Rules_Reasoning_for_Video_Anomaly_Detection_with_Large_Language_Models.html#appendix",
    "title": "Follow the Rules: Reasoning for Video Anomaly Detection with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10299v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10299v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9790"
  },
  {
    "objectID": "posts/Averaging_log_likelihoods_in_direct_alignment/2024-06-27-Averaging_log_likelihoods_in_direct_alignment.html#appendix",
    "href": "posts/Averaging_log_likelihoods_in_direct_alignment/2024-06-27-Averaging_log_likelihoods_in_direct_alignment.html#appendix",
    "title": "Averaging log-likelihoods in direct alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19188v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19188v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5452"
  },
  {
    "objectID": "posts/Assessing_the_Code_Clone_Detection_Capability_of_Large_Language_Models/2024-07-02-Assessing_the_Code_Clone_Detection_Capability_of_Large_Language_Models.html#appendix",
    "href": "posts/Assessing_the_Code_Clone_Detection_Capability_of_Large_Language_Models/2024-07-02-Assessing_the_Code_Clone_Detection_Capability_of_Large_Language_Models.html#appendix",
    "title": "Assessing the Code Clone Detection Capability of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02402v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02402v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4970"
  },
  {
    "objectID": "posts/SynCPKL_Harnessing_LLMs_to_Generate_Synthetic_Data_for_Commonsense_Persona_Knowledge_Linking/2024-07-21-SynCPKL_Harnessing_LLMs_to_Generate_Synthetic_Data_for_Commonsense_Persona_Knowledge_Linking.html#appendix",
    "href": "posts/SynCPKL_Harnessing_LLMs_to_Generate_Synthetic_Data_for_Commonsense_Persona_Knowledge_Linking/2024-07-21-SynCPKL_Harnessing_LLMs_to_Generate_Synthetic_Data_for_Commonsense_Persona_Knowledge_Linking.html#appendix",
    "title": "SynCPKL: Harnessing LLMs to Generate Synthetic Data for Commonsense Persona Knowledge Linking",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.15281v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.15281v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4249"
  },
  {
    "objectID": "posts/From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty/2024-07-08-From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty.html",
    "href": "posts/From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty/2024-07-08-From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty.html",
    "title": "From Loops to Oops: Fallback Behaviors of Language Models Under Uncertainty",
    "section": "",
    "text": "Summary:\nThe paper “From Loops to Oops: Fallback Behaviors of Language Models Under Uncertainty” investigates the undesirable behaviors of large language models (LLMs), such as hallucinations and sequence repetitions, and proposes to view these behaviors as fallbacks that models exhibit under uncertainty. The authors categorize fallback behaviors into sequence repetitions, degenerate text, and hallucinations, and extensively analyze them in models from the same family that differ by the amount of pretraining tokens, parameter count, or the inclusion of instruction-following training. The experiments reveal a clear and consistent ordering of fallback behaviors, with more advanced LLMs exhibiting more complex fallback behaviors. The same ordering is observed throughout a single generation, even for the best-performing models, as uncertainty increases. The paper also demonstrates that common decoding techniques, such as random sampling, might alleviate some unwanted behaviors like sequence repetitions but increase harder-to-detect hallucinations.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive analysis of the fallback behaviors of LLMs under uncertainty, offering valuable insights into the relationship between model complexity, training, and the emergence of different fallback behaviors. The authors’ categorization of fallback behaviors and their extensive experiments contribute to a better understanding of the limitations and challenges of LLMs. However, the paper does not discuss potential solutions to mitigate the identified issues or explore the implications of these findings for the development and deployment of LLMs in real-world applications. Additionally, the paper does not address the potential impact of different decoding strategies on the performance and reliability of LLMs. Further research is needed to investigate these aspects and develop more robust and reliable LLMs."
  },
  {
    "objectID": "posts/From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty/2024-07-08-From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty.html#appendix",
    "href": "posts/From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty/2024-07-08-From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty.html#appendix",
    "title": "From Loops to Oops: Fallback Behaviors of Language Models Under Uncertainty",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06071v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06071v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17045"
  },
  {
    "objectID": "posts/Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents/2024-06-09-Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents.html",
    "href": "posts/Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents/2024-06-09-Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents.html",
    "title": "Machine Against the RAG: Jamming Retrieval-Augmented Generation with Blocker Documents",
    "section": "",
    "text": "Summary:\nThe paper introduces a new class of denial-of-service vulnerabilities in retrieval-augmented generation (RAG) systems, where a single “blocker” document in the RAG database can cause the system to refuse to answer certain queries. The authors demonstrate this attack against several popular large language models (LLMs) and show that resistance to jamming is a novel LLM-safety property not captured by existing safety and trustworthiness metrics.\nThe authors investigate several methods for generating blocker documents, including a new method based on black-box optimization that does not require knowledge of the embedding or LLM used by the target RAG system. They also discuss the limitations of this method, such as producing blocker documents that have no semantics and can be easily filtered out from RAG databases.\nThe paper concludes with a discussion of future research directions, such as minimizing the number of queries to the target RAG system, generating blocker documents with access to a RAG system whose database is not exactly the same as the target system, and generating passive blocker documents that are difficult to detect or even semantically plausible.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an interesting and novel attack on RAG systems, highlighting a previously unrecognized vulnerability. The authors’ investigation of different methods for generating blocker documents is thorough and well-presented. However, the paper could benefit from a more in-depth discussion of the potential real-world implications of this attack and possible countermeasures. Additionally, the limitations of the black-box optimization method for generating blocker documents should be further explored and addressed."
  },
  {
    "objectID": "posts/Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents/2024-06-09-Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents.html#appendix",
    "href": "posts/Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents/2024-06-09-Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents.html#appendix",
    "title": "Machine Against the RAG: Jamming Retrieval-Augmented Generation with Blocker Documents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05870v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05870v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12156"
  },
  {
    "objectID": "posts/DICE_Detecting_In_distribution_Contamination_in_LLMs_Fine_tuning_Phase_for_Math_Reasoning/2024-06-06-DICE_Detecting_In_distribution_Contamination_in_LLMs_Fine_tuning_Phase_for_Math_Reasoning.html#appendix",
    "href": "posts/DICE_Detecting_In_distribution_Contamination_in_LLMs_Fine_tuning_Phase_for_Math_Reasoning/2024-06-06-DICE_Detecting_In_distribution_Contamination_in_LLMs_Fine_tuning_Phase_for_Math_Reasoning.html#appendix",
    "title": "DICE: Detecting In-distribution Contamination in LLM’s Fine-tuning Phase for Math Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04197v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04197v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6104"
  },
  {
    "objectID": "posts/VELO_A_Vector_Database_Assisted_Cloud_Edge_Collaborative_LLM_QoS_Optimization_Framework/2024-06-19-VELO_A_Vector_Database_Assisted_Cloud_Edge_Collaborative_LLM_QoS_Optimization_Framework.html#appendix",
    "href": "posts/VELO_A_Vector_Database_Assisted_Cloud_Edge_Collaborative_LLM_QoS_Optimization_Framework/2024-06-19-VELO_A_Vector_Database_Assisted_Cloud_Edge_Collaborative_LLM_QoS_Optimization_Framework.html#appendix",
    "title": "VELO: A Vector Database-Assisted Cloud-Edge Collaborative LLM QoS Optimization Framework",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13399v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13399v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7725"
  },
  {
    "objectID": "posts/A_Proposed_S.C.O.R.E._Evaluation_Framework_for_Large_Language_Models__Safety_Consensus_Objectivity_Reproducibility_and_Explainability/2024-07-10-A_Proposed_S.C.O.R.E._Evaluation_Framework_for_Large_Language_Models__Safety_Consensus_Objectivity_Reproducibility_and_Explainability.html#appendix",
    "href": "posts/A_Proposed_S.C.O.R.E._Evaluation_Framework_for_Large_Language_Models__Safety_Consensus_Objectivity_Reproducibility_and_Explainability/2024-07-10-A_Proposed_S.C.O.R.E._Evaluation_Framework_for_Large_Language_Models__Safety_Consensus_Objectivity_Reproducibility_and_Explainability.html#appendix",
    "title": "A Proposed S.C.O.R.E. Evaluation Framework for Large Language Models : Safety, Consensus, Objectivity, Reproducibility and Explainability",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07666v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07666v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5995"
  },
  {
    "objectID": "posts/Towards_Open_World_Grasping_with_Large_Vision_Language_Models/2024-06-26-Towards_Open_World_Grasping_with_Large_Vision_Language_Models.html#major-findings",
    "href": "posts/Towards_Open_World_Grasping_with_Large_Vision_Language_Models/2024-06-26-Towards_Open_World_Grasping_with_Large_Vision_Language_Models.html#major-findings",
    "title": "Towards Open-World Grasping with Large Vision-Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nClarity of Visual Markers: The authors find that the most common failure mode of visual marker prompting with GPT-4v is that it sometimes struggles to discriminate which ID corresponds to what segment, especially in cluttered scenes. Techniques such as overlaying numeric IDs with minimal overlap, coloring both the internal of each segment’s mask and its ID with the same unique color, and increasing the resolution of the marked image and the size layout of the markers can assist in making the markers more clear to the VLM.\nReference Image and Chain-of-Thoughts: The authors propose techniques to ameliorate the issue of GPT-4v sometimes referring to regions with wrong IDs, especially in highly cluttered scenes. They suggest passing both the original (reference) and the marked image and constructing a text prompt that explains that the latter corresponds to annotated segments of the first. They also find that VLMs share similar properties with LLMs and prompting them to reason about their final answer before producing it can robustify the response quality.\nSelf-consistency and In-context Examples: The authors observe that the outputs of GPT-4v are not always reproducible, even with exactly the same prompt. They propose using the self-consistency method developed for LLMs to reduce the effect of this phenomenon and robustify VLM outputs. They also find that in-context examples can improve the robustness of the grasp planning and contact reasoning stages."
  },
  {
    "objectID": "posts/Towards_Open_World_Grasping_with_Large_Vision_Language_Models/2024-06-26-Towards_Open_World_Grasping_with_Large_Vision_Language_Models.html#analysis-and-critique",
    "href": "posts/Towards_Open_World_Grasping_with_Large_Vision_Language_Models/2024-06-26-Towards_Open_World_Grasping_with_Large_Vision_Language_Models.html#analysis-and-critique",
    "title": "Towards Open-World Grasping with Large Vision-Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe article provides a comprehensive exploration of various techniques to improve the performance of VLMs in open-world grasping tasks. However, the study is limited to the GPT-4v model, and the results may not generalize to other VLMs. The authors also acknowledge that the actual model specifics of GPT-4v are unknown, which makes it difficult to fully understand the reasons behind its performance. Furthermore, the study does not provide"
  },
  {
    "objectID": "posts/Towards_Open_World_Grasping_with_Large_Vision_Language_Models/2024-06-26-Towards_Open_World_Grasping_with_Large_Vision_Language_Models.html#appendix",
    "href": "posts/Towards_Open_World_Grasping_with_Large_Vision_Language_Models/2024-06-26-Towards_Open_World_Grasping_with_Large_Vision_Language_Models.html#appendix",
    "title": "Towards Open-World Grasping with Large Vision-Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18722v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18722v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3751"
  },
  {
    "objectID": "posts/Whats_in_an_embedding_Would_a_rose_by_any_embedding_smell_as_sweet/2024-06-11-Whats_in_an_embedding_Would_a_rose_by_any_embedding_smell_as_sweet.html#appendix",
    "href": "posts/Whats_in_an_embedding_Would_a_rose_by_any_embedding_smell_as_sweet/2024-06-11-Whats_in_an_embedding_Would_a_rose_by_any_embedding_smell_as_sweet.html#appendix",
    "title": "What’s in an embedding? Would a rose by any embedding smell as sweet?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06870v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06870v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5609"
  },
  {
    "objectID": "posts/MathViz_E_A_Case_study_in_Domain_Specialized_Tool_Using_Agents/2024-07-24-MathViz_E_A_Case_study_in_Domain_Specialized_Tool_Using_Agents.html#appendix",
    "href": "posts/MathViz_E_A_Case_study_in_Domain_Specialized_Tool_Using_Agents/2024-07-24-MathViz_E_A_Case_study_in_Domain_Specialized_Tool_Using_Agents.html#appendix",
    "title": "MathViz-E: A Case-study in Domain-Specialized Tool-Using Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17544v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17544v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5991"
  },
  {
    "objectID": "posts/Are_Large_Language_Models_Consistent_over_Value_laden_Questions/2024-07-03-Are_Large_Language_Models_Consistent_over_Value_laden_Questions.html#appendix",
    "href": "posts/Are_Large_Language_Models_Consistent_over_Value_laden_Questions/2024-07-03-Are_Large_Language_Models_Consistent_over_Value_laden_Questions.html#appendix",
    "title": "Are Large Language Models Consistent over Value-laden Questions?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02996v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02996v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11041"
  },
  {
    "objectID": "posts/Suri_Multi_constraint_Instruction_Following_for_Long_form_Text_Generation/2024-06-27-Suri_Multi_constraint_Instruction_Following_for_Long_form_Text_Generation.html#appendix",
    "href": "posts/Suri_Multi_constraint_Instruction_Following_for_Long_form_Text_Generation/2024-06-27-Suri_Multi_constraint_Instruction_Following_for_Long_form_Text_Generation.html#appendix",
    "title": "Suri: Multi-constraint Instruction Following for Long-form Text Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19371v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19371v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8097"
  },
  {
    "objectID": "posts/Large_Language_Models_are_Skeptics_False_Negative_Problem_of_Input_conflicting_Hallucination/2024-06-20-Large_Language_Models_are_Skeptics_False_Negative_Problem_of_Input_conflicting_Hallucination.html#appendix",
    "href": "posts/Large_Language_Models_are_Skeptics_False_Negative_Problem_of_Input_conflicting_Hallucination/2024-06-20-Large_Language_Models_are_Skeptics_False_Negative_Problem_of_Input_conflicting_Hallucination.html#appendix",
    "title": "Large Language Models are Skeptics: False Negative Problem of Input-conflicting Hallucination",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13929v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13929v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4576"
  },
  {
    "objectID": "posts/Leveraging_Large_Language_Models_for_Efficient_Failure_Analysis_in_Game_Development/2024-06-11-Leveraging_Large_Language_Models_for_Efficient_Failure_Analysis_in_Game_Development.html#appendix",
    "href": "posts/Leveraging_Large_Language_Models_for_Efficient_Failure_Analysis_in_Game_Development/2024-06-11-Leveraging_Large_Language_Models_for_Efficient_Failure_Analysis_in_Game_Development.html#appendix",
    "title": "Leveraging Large Language Models for Efficient Failure Analysis in Game Development",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07084v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07084v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6064"
  },
  {
    "objectID": "posts/Poisoned_LangChain_Jailbreak_LLMs_by_LangChain/2024-06-26-Poisoned_LangChain_Jailbreak_LLMs_by_LangChain.html#appendix",
    "href": "posts/Poisoned_LangChain_Jailbreak_LLMs_by_LangChain/2024-06-26-Poisoned_LangChain_Jailbreak_LLMs_by_LangChain.html#appendix",
    "title": "Poisoned LangChain: Jailbreak LLMs by LangChain",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18122v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18122v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4003"
  },
  {
    "objectID": "posts/Towards_Region_aware_Bias_Evaluation_Metrics/2024-06-23-Towards_Region_aware_Bias_Evaluation_Metrics.html#appendix",
    "href": "posts/Towards_Region_aware_Bias_Evaluation_Metrics/2024-06-23-Towards_Region_aware_Bias_Evaluation_Metrics.html#appendix",
    "title": "Towards Region-aware Bias Evaluation Metrics",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16152v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16152v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8427"
  },
  {
    "objectID": "posts/Task_Oriented_In_Domain_Data_Augmentation/2024-06-24-Task_Oriented_In_Domain_Data_Augmentation.html#appendix",
    "href": "posts/Task_Oriented_In_Domain_Data_Augmentation/2024-06-24-Task_Oriented_In_Domain_Data_Augmentation.html#appendix",
    "title": "Task Oriented In-Domain Data Augmentation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16694v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16694v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6953"
  },
  {
    "objectID": "posts/Applying_LLMs_for_Rescoring_N_best_ASR_Hypotheses_of_Casual_Conversations_Effects_of_Domain_Adaptation_and_Context_Carry_over/2024-06-27-Applying_LLMs_for_Rescoring_N_best_ASR_Hypotheses_of_Casual_Conversations_Effects_of_Domain_Adaptation_and_Context_Carry_over.html#appendix",
    "href": "posts/Applying_LLMs_for_Rescoring_N_best_ASR_Hypotheses_of_Casual_Conversations_Effects_of_Domain_Adaptation_and_Context_Carry_over/2024-06-27-Applying_LLMs_for_Rescoring_N_best_ASR_Hypotheses_of_Casual_Conversations_Effects_of_Domain_Adaptation_and_Context_Carry_over.html#appendix",
    "title": "Applying LLMs for Rescoring N-best ASR Hypotheses of Casual Conversations: Effects of Domain Adaptation and Context Carry-over",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18972v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18972v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5457"
  },
  {
    "objectID": "posts/Improving_Robustness_of_LLM_based_Speech_Synthesis_by_Learning_Monotonic_Alignment/2024-06-25-Improving_Robustness_of_LLM_based_Speech_Synthesis_by_Learning_Monotonic_Alignment.html#appendix",
    "href": "posts/Improving_Robustness_of_LLM_based_Speech_Synthesis_by_Learning_Monotonic_Alignment/2024-06-25-Improving_Robustness_of_LLM_based_Speech_Synthesis_by_Learning_Monotonic_Alignment.html#appendix",
    "title": "Improving Robustness of LLM-based Speech Synthesis by Learning Monotonic Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17957v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17957v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4644"
  },
  {
    "objectID": "posts/CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only/2024-06-11-CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only.html",
    "href": "posts/CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only/2024-06-11-CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only.html",
    "title": "CAAP: Context-Aware Action Planning Prompting to Solve Computer Tasks with Front-End UI Only",
    "section": "",
    "text": "Summary:\nThe paper introduces an LLM-based agent that operates solely on the basis of screenshots for recognizing environments, while leveraging in-context learning to eliminate the need for collecting large datasets of human demonstration. The proposed method, named Context-Aware Action Planning (CAAP) prompting, encourages the agent to meticulously review the context in various angles. The agent achieves a success rate of 94.4% on 67 types of MiniWoB++ problems, utilizing only 1.48 demonstrations per problem type. The method offers the potential for broader applications, especially for tasks that require inter-application coordination on computers or smartphones.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel approach to LLM-based agents that addresses the limitations of existing methods reliant on HTML or DOM inputs and those that combine supervised learning (SL) and reinforcement learning (RL). The proposed agent operates solely on visual inputs and utilizes a large language model (LLM). The CAAP prompting approach is introduced to enhance the decision-making capabilities of ICL-based agents. The evaluations using the MiniWoB++ benchmark demonstrate the superiority of the proposed method. However, the scope of validation remains limited, and further research is needed to evaluate the agent across a broader array of benchmarks. Additionally, the agent’s reliance on visual observation data may lead to observation failures, as demonstrated in the case study. The paper also acknowledges the limitations of the benchmark directives and the need for more comprehensive assessment from a research perspective."
  },
  {
    "objectID": "posts/CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only/2024-06-11-CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only.html#appendix",
    "href": "posts/CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only/2024-06-11-CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only.html#appendix",
    "title": "CAAP: Context-Aware Action Planning Prompting to Solve Computer Tasks with Front-End UI Only",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06947v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06947v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10877"
  },
  {
    "objectID": "posts/Language_Models_are_Alignable_Decision_Makers_Dataset_and_Application_to_the_Medical_Triage_Domain/2024-06-10-Language_Models_are_Alignable_Decision_Makers_Dataset_and_Application_to_the_Medical_Triage_Domain.html#appendix",
    "href": "posts/Language_Models_are_Alignable_Decision_Makers_Dataset_and_Application_to_the_Medical_Triage_Domain/2024-06-10-Language_Models_are_Alignable_Decision_Makers_Dataset_and_Application_to_the_Medical_Triage_Domain.html#appendix",
    "title": "Language Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06435v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06435v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9086"
  },
  {
    "objectID": "posts/Beyond_Under_Alignment_Atomic_Preference_Enhanced_Factuality_Tuning_for_Large_Language_Models/2024-06-18-Beyond_Under_Alignment_Atomic_Preference_Enhanced_Factuality_Tuning_for_Large_Language_Models.html#appendix",
    "href": "posts/Beyond_Under_Alignment_Atomic_Preference_Enhanced_Factuality_Tuning_for_Large_Language_Models/2024-06-18-Beyond_Under_Alignment_Atomic_Preference_Enhanced_Factuality_Tuning_for_Large_Language_Models.html#appendix",
    "title": "Beyond Under-Alignment: Atomic Preference Enhanced Factuality Tuning for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12416v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12416v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6437"
  },
  {
    "objectID": "posts/Generative_AI_for_Enhancing_Active_Learning_in_Education_A_Comparative_Study_of_GPT_3.5_and_GPT_4_in_Crafting_Customized_Test_Questions/2024-06-20-Generative_AI_for_Enhancing_Active_Learning_in_Education_A_Comparative_Study_of_GPT_3.5_and_GPT_4_in_Crafting_Customized_Test_Questions.html#appendix",
    "href": "posts/Generative_AI_for_Enhancing_Active_Learning_in_Education_A_Comparative_Study_of_GPT_3.5_and_GPT_4_in_Crafting_Customized_Test_Questions/2024-06-20-Generative_AI_for_Enhancing_Active_Learning_in_Education_A_Comparative_Study_of_GPT_3.5_and_GPT_4_in_Crafting_Customized_Test_Questions.html#appendix",
    "title": "Generative AI for Enhancing Active Learning in Education: A Comparative Study of GPT-3.5 and GPT-4 in Crafting Customized Test Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13903v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13903v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6168"
  },
  {
    "objectID": "posts/ObfuscaTune_Obfuscated_Offsite_Fine_tuning_and_Inference_of_Proprietary_LLMs_on_Private_Datasets/2024-07-03-ObfuscaTune_Obfuscated_Offsite_Fine_tuning_and_Inference_of_Proprietary_LLMs_on_Private_Datasets.html#appendix",
    "href": "posts/ObfuscaTune_Obfuscated_Offsite_Fine_tuning_and_Inference_of_Proprietary_LLMs_on_Private_Datasets/2024-07-03-ObfuscaTune_Obfuscated_Offsite_Fine_tuning_and_Inference_of_Proprietary_LLMs_on_Private_Datasets.html#appendix",
    "title": "ObfuscaTune: Obfuscated Offsite Fine-tuning and Inference of Proprietary LLMs on Private Datasets",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02960v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02960v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4546"
  },
  {
    "objectID": "posts/TAMIGO_Empowering_Teaching_Assistants_using_LLM_assisted_viva_and_code_assessment_in_an_Advanced_Computing_Class/2024-07-23-TAMIGO_Empowering_Teaching_Assistants_using_LLM_assisted_viva_and_code_assessment_in_an_Advanced_Computing_Class.html#appendix",
    "href": "posts/TAMIGO_Empowering_Teaching_Assistants_using_LLM_assisted_viva_and_code_assessment_in_an_Advanced_Computing_Class/2024-07-23-TAMIGO_Empowering_Teaching_Assistants_using_LLM_assisted_viva_and_code_assessment_in_an_Advanced_Computing_Class.html#appendix",
    "title": "TAMIGO: Empowering Teaching Assistants using LLM-assisted viva and code assessment in an Advanced Computing Class",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16805v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16805v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6849"
  },
  {
    "objectID": "posts/Investigating_Low_Cost_LLM_Annotation_for~Spoken_Dialogue_Understanding_Datasets/2024-06-19-Investigating_Low_Cost_LLM_Annotation_for~Spoken_Dialogue_Understanding_Datasets.html#appendix",
    "href": "posts/Investigating_Low_Cost_LLM_Annotation_for~Spoken_Dialogue_Understanding_Datasets/2024-06-19-Investigating_Low_Cost_LLM_Annotation_for~Spoken_Dialogue_Understanding_Datasets.html#appendix",
    "title": "Investigating Low-Cost LLM Annotation for~Spoken Dialogue Understanding Datasets",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13269v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13269v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6424"
  },
  {
    "objectID": "posts/How_to_Understand_Whole_Software_Repository/2024-06-03-How_to_Understand_Whole_Software_Repository.html#appendix",
    "href": "posts/How_to_Understand_Whole_Software_Repository/2024-06-03-How_to_Understand_Whole_Software_Repository.html#appendix",
    "title": "How to Understand Whole Software Repository?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01422v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01422v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10556"
  },
  {
    "objectID": "posts/CherryRec_Enhancing_News_Recommendation_Quality_via_LLM_driven_Framework/2024-06-18-CherryRec_Enhancing_News_Recommendation_Quality_via_LLM_driven_Framework.html#appendix",
    "href": "posts/CherryRec_Enhancing_News_Recommendation_Quality_via_LLM_driven_Framework/2024-06-18-CherryRec_Enhancing_News_Recommendation_Quality_via_LLM_driven_Framework.html#appendix",
    "title": "CherryRec: Enhancing News Recommendation Quality via LLM-driven Framework",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12243v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12243v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4153"
  },
  {
    "objectID": "posts/Do_Large_Language_Models_Have_Compositional_Ability_An_Investigation_into_Limitations_and_Scalability/2024-07-22-Do_Large_Language_Models_Have_Compositional_Ability_An_Investigation_into_Limitations_and_Scalability.html#appendix",
    "href": "posts/Do_Large_Language_Models_Have_Compositional_Ability_An_Investigation_into_Limitations_and_Scalability/2024-07-22-Do_Large_Language_Models_Have_Compositional_Ability_An_Investigation_into_Limitations_and_Scalability.html#appendix",
    "title": "Do Large Language Models Have Compositional Ability? An Investigation into Limitations and Scalability",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.15720v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.15720v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12338"
  },
  {
    "objectID": "posts/GraphCoder_Enhancing_Repository_Level_Code_Completion_via_Code_Context_Graph_based_Retrieval_and_Language_Model/2024-06-11-GraphCoder_Enhancing_Repository_Level_Code_Completion_via_Code_Context_Graph_based_Retrieval_and_Language_Model.html#appendix",
    "href": "posts/GraphCoder_Enhancing_Repository_Level_Code_Completion_via_Code_Context_Graph_based_Retrieval_and_Language_Model/2024-06-11-GraphCoder_Enhancing_Repository_Level_Code_Completion_via_Code_Context_Graph_based_Retrieval_and_Language_Model.html#appendix",
    "title": "GraphCoder: Enhancing Repository-Level Code Completion via Code Context Graph-based Retrieval and Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07003v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07003v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9656"
  },
  {
    "objectID": "posts/LogEval_A_Comprehensive_Benchmark_Suite_for_Large_Language_Models_In_Log_Analysis/2024-07-02-LogEval_A_Comprehensive_Benchmark_Suite_for_Large_Language_Models_In_Log_Analysis.html#appendix",
    "href": "posts/LogEval_A_Comprehensive_Benchmark_Suite_for_Large_Language_Models_In_Log_Analysis/2024-07-02-LogEval_A_Comprehensive_Benchmark_Suite_for_Large_Language_Models_In_Log_Analysis.html#appendix",
    "title": "LogEval: A Comprehensive Benchmark Suite for Large Language Models In Log Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01896v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01896v1\n\n\nTruncated\nFalse\n\n\nWord Count\n0"
  },
  {
    "objectID": "posts/Ask_LLMs_Directly_What_shapes_your_bias_Measuring_Social_Bias_in_Large_Language_Models/2024-06-06-Ask_LLMs_Directly_What_shapes_your_bias_Measuring_Social_Bias_in_Large_Language_Models.html#appendix",
    "href": "posts/Ask_LLMs_Directly_What_shapes_your_bias_Measuring_Social_Bias_in_Large_Language_Models/2024-06-06-Ask_LLMs_Directly_What_shapes_your_bias_Measuring_Social_Bias_in_Large_Language_Models.html#appendix",
    "title": "Ask LLMs Directly, What shapes your bias?: Measuring Social Bias in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04064v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04064v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5188"
  },
  {
    "objectID": "posts/Step_Back_Profiling_Distilling_User_History_for_Personalized_Scientific_Writing/2024-06-20-Step_Back_Profiling_Distilling_User_History_for_Personalized_Scientific_Writing.html#appendix",
    "href": "posts/Step_Back_Profiling_Distilling_User_History_for_Personalized_Scientific_Writing/2024-06-20-Step_Back_Profiling_Distilling_User_History_for_Personalized_Scientific_Writing.html#appendix",
    "title": "Step-Back Profiling: Distilling User History for Personalized Scientific Writing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14275v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14275v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5200"
  },
  {
    "objectID": "posts/Very_Large_Scale_Multi_Agent_Simulation_in_AgentScope/2024-07-25-Very_Large_Scale_Multi_Agent_Simulation_in_AgentScope.html#appendix",
    "href": "posts/Very_Large_Scale_Multi_Agent_Simulation_in_AgentScope/2024-07-25-Very_Large_Scale_Multi_Agent_Simulation_in_AgentScope.html#appendix",
    "title": "Very Large-Scale Multi-Agent Simulation in AgentScope",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17789v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17789v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12591"
  },
  {
    "objectID": "posts/Keyword_driven_Retrieval_Augmented_Large_Language_Models_for_Cold_start_User_Recommendations/2024-05-30-Keyword_driven_Retrieval_Augmented_Large_Language_Models_for_Cold_start_User_Recommendations.html#appendix",
    "href": "posts/Keyword_driven_Retrieval_Augmented_Large_Language_Models_for_Cold_start_User_Recommendations/2024-05-30-Keyword_driven_Retrieval_Augmented_Large_Language_Models_for_Cold_start_User_Recommendations.html#appendix",
    "title": "Keyword-driven Retrieval-Augmented Large Language Models for Cold-start User Recommendations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.19612v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.19612v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8262"
  },
  {
    "objectID": "posts/Semantic_Understanding_and_Data_Imputation_using_Large_Language_Model_to_Accelerate_Recommendation_System/2024-07-14-Semantic_Understanding_and_Data_Imputation_using_Large_Language_Model_to_Accelerate_Recommendation_System.html#appendix",
    "href": "posts/Semantic_Understanding_and_Data_Imputation_using_Large_Language_Model_to_Accelerate_Recommendation_System/2024-07-14-Semantic_Understanding_and_Data_Imputation_using_Large_Language_Model_to_Accelerate_Recommendation_System.html#appendix",
    "title": "Semantic Understanding and Data Imputation using Large Language Model to Accelerate Recommendation System",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10078v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10078v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2986"
  },
  {
    "objectID": "posts/SEC_QA_A_Systematic_Evaluation_Corpus_for_Financial_QA/2024-06-20-SEC_QA_A_Systematic_Evaluation_Corpus_for_Financial_QA.html#appendix",
    "href": "posts/SEC_QA_A_Systematic_Evaluation_Corpus_for_Financial_QA/2024-06-20-SEC_QA_A_Systematic_Evaluation_Corpus_for_Financial_QA.html#appendix",
    "title": "SEC-QA: A Systematic Evaluation Corpus for Financial QA",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14394v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14394v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6714"
  },
  {
    "objectID": "posts/XRec_Large_Language_Models_for_Explainable_Recommendation/2024-06-04-XRec_Large_Language_Models_for_Explainable_Recommendation.html#appendix",
    "href": "posts/XRec_Large_Language_Models_for_Explainable_Recommendation/2024-06-04-XRec_Large_Language_Models_for_Explainable_Recommendation.html#appendix",
    "title": "XRec: Large Language Models for Explainable Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02377v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02377v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6297"
  },
  {
    "objectID": "posts/MAGIC_Generating_Self_Correction_Guideline_for_In_Context_Text_to_SQL/2024-06-18-MAGIC_Generating_Self_Correction_Guideline_for_In_Context_Text_to_SQL.html#appendix",
    "href": "posts/MAGIC_Generating_Self_Correction_Guideline_for_In_Context_Text_to_SQL/2024-06-18-MAGIC_Generating_Self_Correction_Guideline_for_In_Context_Text_to_SQL.html#appendix",
    "title": "MAGIC: Generating Self-Correction Guideline for In-Context Text-to-SQL",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12692v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12692v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7370"
  },
  {
    "objectID": "posts/Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems/2024-06-18-Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems.html",
    "href": "posts/Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems/2024-06-18-Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems.html",
    "title": "Navigating the Labyrinth: Evaluating and Enhancing LLMs’ Ability to Reason About Search Problems",
    "section": "",
    "text": "Summary:\nThe paper introduces a new benchmark, SearchBench, to evaluate the reasoning abilities of Large Language Models (LLMs) on search problems. SearchBench consists of 11 unique search problems, each with automated pipelines for generating instances and analyzing solutions. The authors demonstrate that even advanced LLMs struggle with these problems, with GPT4 solving only 1.4% end-to-end in text. The paper proposes in-context learning with A* algorithm implementations and a Multi-Stage-Multi-Try (MSMT) method to enhance performance, raising GPT-4’s performance above 57%.\nKey Terminology:\nMajor Findings:"
  },
  {
    "objectID": "posts/Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems/2024-06-18-Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems.html#appendix",
    "href": "posts/Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems/2024-06-18-Navigating_the_Labyrinth_Evaluating_and_Enhancing_LLMs_Ability_to_Reason_About_Search_Problems.html#appendix",
    "title": "Navigating the Labyrinth: Evaluating and Enhancing LLMs’ Ability to Reason About Search Problems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12172v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12172v1\n\n\nTruncated\nTrue\n\n\nWord Count\n72494"
  },
  {
    "objectID": "posts/PFID_Privacy_First_Inference_Delegation_Framework_for_LLMs/2024-06-18-PFID_Privacy_First_Inference_Delegation_Framework_for_LLMs.html#appendix",
    "href": "posts/PFID_Privacy_First_Inference_Delegation_Framework_for_LLMs/2024-06-18-PFID_Privacy_First_Inference_Delegation_Framework_for_LLMs.html#appendix",
    "title": "PFID: Privacy First Inference Delegation Framework for LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12238v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12238v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5069"
  },
  {
    "objectID": "posts/HIGHT_Hierarchical_Graph_Tokenization_for_Graph_Language_Alignment/2024-06-20-HIGHT_Hierarchical_Graph_Tokenization_for_Graph_Language_Alignment.html#appendix",
    "href": "posts/HIGHT_Hierarchical_Graph_Tokenization_for_Graph_Language_Alignment/2024-06-20-HIGHT_Hierarchical_Graph_Tokenization_for_Graph_Language_Alignment.html#appendix",
    "title": "HIGHT: Hierarchical Graph Tokenization for Graph-Language Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14021v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14021v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11102"
  },
  {
    "objectID": "posts/Psychological_Profiling_in_Cybersecurity_A_Look_at_LLMs_and_Psycholinguistic_Features/2024-06-26-Psychological_Profiling_in_Cybersecurity_A_Look_at_LLMs_and_Psycholinguistic_Features.html#appendix",
    "href": "posts/Psychological_Profiling_in_Cybersecurity_A_Look_at_LLMs_and_Psycholinguistic_Features/2024-06-26-Psychological_Profiling_in_Cybersecurity_A_Look_at_LLMs_and_Psycholinguistic_Features.html#appendix",
    "title": "Psychological Profiling in Cybersecurity: A Look at LLMs and Psycholinguistic Features",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18783v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18783v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6749"
  },
  {
    "objectID": "posts/LLM_Based_Open_Domain_Integrated_Task_and_Knowledge_Assistants_with_Programmable_Policies/2024-07-08-LLM_Based_Open_Domain_Integrated_Task_and_Knowledge_Assistants_with_Programmable_Policies.html",
    "href": "posts/LLM_Based_Open_Domain_Integrated_Task_and_Knowledge_Assistants_with_Programmable_Policies/2024-07-08-LLM_Based_Open_Domain_Integrated_Task_and_Knowledge_Assistants_with_Programmable_Policies.html",
    "title": "LLM-Based Open-Domain Integrated Task and Knowledge Assistants with Programmable Policies",
    "section": "",
    "text": "Summary:\nThe paper presents KITA, a programmable framework for creating task-oriented conversational agents that can handle complex user interactions. Unlike traditional dialogue trees, KITA provides reliable grounded responses and controllable agent policies through its expressive specification, KITA Worksheet. The authors conducted a real-user study involving 62 participants, demonstrating that KITA outperforms the GPT-4 with function calling baseline by 26.1, 22.5, and 52.4 points on execution accuracy, dialogue act accuracy, and goal completion rate, respectively.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel approach to creating task-oriented conversational agents that can handle complex user interactions. The use of KITA Worksheet as an expressive specification for agent policies is a significant contribution, as it allows for more control and flexibility in designing conversational agents. The real-user study demonstrates the effectiveness of KITA in handling complex user interactions and outperforming existing methods.\nHowever, the paper does not provide a detailed comparison with other programmable frameworks for creating task-oriented conversational agents. Additionally, the authors do not discuss the limitations of KITA or potential biases that may arise from using the framework. The paper also does not provide a clear explanation of how KITA handles ambiguity in user inputs or how it adapts to changes in user behavior over time.\nOverall, the paper presents a promising approach to creating task-oriented conversational agents that can handle complex user interactions. However, further research is needed to compare KITA with other programmable frameworks and to address potential limitations and biases in the framework."
  },
  {
    "objectID": "posts/LLM_Based_Open_Domain_Integrated_Task_and_Knowledge_Assistants_with_Programmable_Policies/2024-07-08-LLM_Based_Open_Domain_Integrated_Task_and_Knowledge_Assistants_with_Programmable_Policies.html#appendix",
    "href": "posts/LLM_Based_Open_Domain_Integrated_Task_and_Knowledge_Assistants_with_Programmable_Policies/2024-07-08-LLM_Based_Open_Domain_Integrated_Task_and_Knowledge_Assistants_with_Programmable_Policies.html#appendix",
    "title": "LLM-Based Open-Domain Integrated Task and Knowledge Assistants with Programmable Policies",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05674v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05674v1\n\n\nTruncated\nFalse\n\n\nWord Count\n23690"
  },
  {
    "objectID": "posts/Multilingual_Contrastive_Decoding_via_Language_Agnostic_Layers_Skipping/2024-07-15-Multilingual_Contrastive_Decoding_via_Language_Agnostic_Layers_Skipping.html#appendix",
    "href": "posts/Multilingual_Contrastive_Decoding_via_Language_Agnostic_Layers_Skipping/2024-07-15-Multilingual_Contrastive_Decoding_via_Language_Agnostic_Layers_Skipping.html#appendix",
    "title": "Multilingual Contrastive Decoding via Language-Agnostic Layers Skipping",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10795v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10795v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3434"
  },
  {
    "objectID": "posts/Smart_Language_Agents_in_Real_World_Planning/2024-07-29-Smart_Language_Agents_in_Real_World_Planning.html#appendix",
    "href": "posts/Smart_Language_Agents_in_Real_World_Planning/2024-07-29-Smart_Language_Agents_in_Real_World_Planning.html#appendix",
    "title": "Smart Language Agents in Real-World Planning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19667v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19667v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2888"
  },
  {
    "objectID": "posts/S2D_Sorted_Speculative_Decoding_For_More_Efficient_Deployment_of_Nested_Large_Language_Models/2024-07-02-S2D_Sorted_Speculative_Decoding_For_More_Efficient_Deployment_of_Nested_Large_Language_Models.html#appendix",
    "href": "posts/S2D_Sorted_Speculative_Decoding_For_More_Efficient_Deployment_of_Nested_Large_Language_Models/2024-07-02-S2D_Sorted_Speculative_Decoding_For_More_Efficient_Deployment_of_Nested_Large_Language_Models.html#appendix",
    "title": "S2D: Sorted Speculative Decoding For More Efficient Deployment of Nested Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01955v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01955v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6189"
  },
  {
    "objectID": "posts/CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models/2024-07-02-CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models.html",
    "href": "posts/CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models/2024-07-02-CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models.html",
    "title": "CEB: Compositional Evaluation Benchmark for Fairness in Large Language Models",
    "section": "",
    "text": "Summary: The paper introduces a Compositional Evaluation Benchmark (CEB) to address the limitations of existing bias evaluation efforts for Large Language Models (LLMs). CEB consists of 11,004 samples covering different types of bias across various social groups and tasks. The curation of CEB is based on a newly proposed compositional taxonomy that characterizes each dataset from three dimensions: bias types, social groups, and tasks. The paper demonstrates that the levels of bias vary across these dimensions, providing guidance for the development of specific bias mitigation methods.\nMajor Findings: 1. The introduction of CEB, a Compositional Evaluation Benchmark, to address the limitations of existing bias evaluation efforts for LLMs. 2. The curation of CEB is based on a newly proposed compositional taxonomy that characterizes each dataset from three dimensions: bias types, social groups, and tasks."
  },
  {
    "objectID": "posts/CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models/2024-07-02-CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models.html#appendix",
    "href": "posts/CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models/2024-07-02-CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models.html#appendix",
    "title": "CEB: Compositional Evaluation Benchmark for Fairness in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02408v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02408v1\n\n\nTruncated\nTrue\n\n\nWord Count\n32723"
  },
  {
    "objectID": "posts/Vox_Populi_Vox_AI_Using_Language_Models_to_Estimate_German_Public_Opinion/2024-07-11-Vox_Populi_Vox_AI_Using_Language_Models_to_Estimate_German_Public_Opinion.html",
    "href": "posts/Vox_Populi_Vox_AI_Using_Language_Models_to_Estimate_German_Public_Opinion/2024-07-11-Vox_Populi_Vox_AI_Using_Language_Models_to_Estimate_German_Public_Opinion.html",
    "title": "Vox Populi, Vox AI? Using Language Models to Estimate German Public Opinion",
    "section": "",
    "text": "Summary:\nThis academic paper explores the use of large language models (LLMs), specifically GPT-3.5, to estimate public opinion and predict voting behavior in Germany. The study compares the LLM’s predicted vote choices with the actual vote choices reported by respondents in the German Longitudinal Election Study (GLES). The findings reveal that GPT-3.5 overestimated the vote shares for the Greens, the Left, and non-voters, while underestimating the vote shares for FDP and AfD when compared to GLES. The LLM’s overall predictive accuracy was modest, with a matching prediction rate of 0.46. GPT-3.5’s predictions were more accurate for voters of the Greens, CDU/CSU, and the Left, but displayed poor predictive power for FDP and AfD voters. The study also highlights the limitations of using LL"
  },
  {
    "objectID": "posts/Vox_Populi_Vox_AI_Using_Language_Models_to_Estimate_German_Public_Opinion/2024-07-11-Vox_Populi_Vox_AI_Using_Language_Models_to_Estimate_German_Public_Opinion.html#appendix",
    "href": "posts/Vox_Populi_Vox_AI_Using_Language_Models_to_Estimate_German_Public_Opinion/2024-07-11-Vox_Populi_Vox_AI_Using_Language_Models_to_Estimate_German_Public_Opinion.html#appendix",
    "title": "Vox Populi, Vox AI? Using Language Models to Estimate German Public Opinion",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08563v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08563v1\n\n\nTruncated\nTrue\n\n\nWord Count\n29238"
  },
  {
    "objectID": "posts/LLM_Targeted_Underperformance_Disproportionately_Impacts_Vulnerable_Users/2024-06-25-LLM_Targeted_Underperformance_Disproportionately_Impacts_Vulnerable_Users.html#appendix",
    "href": "posts/LLM_Targeted_Underperformance_Disproportionately_Impacts_Vulnerable_Users/2024-06-25-LLM_Targeted_Underperformance_Disproportionately_Impacts_Vulnerable_Users.html#appendix",
    "title": "LLM Targeted Underperformance Disproportionately Impacts Vulnerable Users",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17737v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17737v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6850"
  },
  {
    "objectID": "posts/CodeNav_Beyond_tool_use_to_using_real_world_codebases_with_LLM_agents/2024-06-18-CodeNav_Beyond_tool_use_to_using_real_world_codebases_with_LLM_agents.html#appendix",
    "href": "posts/CodeNav_Beyond_tool_use_to_using_real_world_codebases_with_LLM_agents/2024-06-18-CodeNav_Beyond_tool_use_to_using_real_world_codebases_with_LLM_agents.html#appendix",
    "title": "CodeNav: Beyond tool-use to using real-world codebases with LLM agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12276v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12276v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10119"
  },
  {
    "objectID": "posts/A_Teacher_Is_Worth_A_Million_Instructions/2024-06-27-A_Teacher_Is_Worth_A_Million_Instructions.html#appendix",
    "href": "posts/A_Teacher_Is_Worth_A_Million_Instructions/2024-06-27-A_Teacher_Is_Worth_A_Million_Instructions.html#appendix",
    "title": "A Teacher Is Worth A Million Instructions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19112v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19112v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5345"
  },
  {
    "objectID": "posts/Exploring_Spatial_Representations_in_the_Historical_Lake_District_Texts_with_LLM_based_Relation_Extraction/2024-06-20-Exploring_Spatial_Representations_in_the_Historical_Lake_District_Texts_with_LLM_based_Relation_Extraction.html#appendix",
    "href": "posts/Exploring_Spatial_Representations_in_the_Historical_Lake_District_Texts_with_LLM_based_Relation_Extraction/2024-06-20-Exploring_Spatial_Representations_in_the_Historical_Lake_District_Texts_with_LLM_based_Relation_Extraction.html#appendix",
    "title": "Exploring Spatial Representations in the Historical Lake District Texts with LLM-based Relation Extraction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14336v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14336v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4003"
  },
  {
    "objectID": "posts/Is_In_Context_Learning_a_Type_of_Gradient_Based_Learning_Evidence_from_the_Inverse_Frequency_Effect_in_Structural_Priming/2024-06-26-Is_In_Context_Learning_a_Type_of_Gradient_Based_Learning_Evidence_from_the_Inverse_Frequency_Effect_in_Structural_Priming.html#appendix",
    "href": "posts/Is_In_Context_Learning_a_Type_of_Gradient_Based_Learning_Evidence_from_the_Inverse_Frequency_Effect_in_Structural_Priming/2024-06-26-Is_In_Context_Learning_a_Type_of_Gradient_Based_Learning_Evidence_from_the_Inverse_Frequency_Effect_in_Structural_Priming.html#appendix",
    "title": "Is In-Context Learning a Type of Gradient-Based Learning? Evidence from the Inverse Frequency Effect in Structural Priming",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18501v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18501v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8453"
  },
  {
    "objectID": "posts/MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models/2024-06-20-MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models.html#major-findings",
    "href": "posts/MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models/2024-06-20-MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models.html#major-findings",
    "title": "MR-BEN: A Comprehensive Meta-Reasoning Benchmark for Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nMr-Ben is a comprehensive benchmark that employs a meta-reasoning paradigm, where LLMs are challenged to reason about different forms of reasoning. This paradigm involves LLMs acting as teachers, evaluating the reasoning process by assessing correctness, analyzing potential errors, and providing corrections.\nThe analyses of various LLMs on Mr-Ben reveal distinct limitations and previously unidentified weaknesses in their reasoning abilities. While many LLMs can generate the correct answer to a question, they struggle to pinpoint errors in the reasoning process and correct them. This suggests that existing LLMs have yet to master reasoning, particularly the smaller models.\nTechniques such as the use of high-quality synthetic data can significantly improve reasoning abilities, offering a potential pathway to enhance performance regardless of model size. However, different LLMs excel in different reasoning paradigms, challenging the assumption that domain-specific enhancements necessarily lead to broad cognitive improvements."
  },
  {
    "objectID": "posts/MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models/2024-06-20-MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models/2024-06-20-MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models.html#analysis-and-critique",
    "title": "MR-BEN: A Comprehensive Meta-Reasoning Benchmark for Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nWhile Mr-Ben provides a comprehensive evaluation of LLMs’ reasoning abilities, it has some limitations. The benchmark’s applicability may be restricted when it comes to subjects that are inherently holistic or creative in nature, such as humanities or sociology. Additionally, Mr-Ben is currently confined to questions in English, which could potentially limit the scope of reasoning challenges that can be explored. Furthermore, the analysis and correction of errors in the reasoning steps are currently based on solutions generated by three LLMs, which may not represent the diverse reasoning and error patterns of different LLMs and individuals.\nMoreover, the benchmark may present potential negative societal impacts, such as the risk of LLMs being misused or used maliciously. For instance, LLMs with advanced reasoning capabilities could be used to manipulate information or deceive people. The use"
  },
  {
    "objectID": "posts/MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models/2024-06-20-MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models.html#appendix",
    "href": "posts/MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models/2024-06-20-MR_BEN_A_Comprehensive_Meta_Reasoning_Benchmark_for_Large_Language_Models.html#appendix",
    "title": "MR-BEN: A Comprehensive Meta-Reasoning Benchmark for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13975v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13975v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8416"
  },
  {
    "objectID": "posts/A_Tool_for_Test_Case_Scenarios_Generation_Using_Large_Language_Models/2024-06-11-A_Tool_for_Test_Case_Scenarios_Generation_Using_Large_Language_Models.html#appendix",
    "href": "posts/A_Tool_for_Test_Case_Scenarios_Generation_Using_Large_Language_Models/2024-06-11-A_Tool_for_Test_Case_Scenarios_Generation_Using_Large_Language_Models.html#appendix",
    "title": "A Tool for Test Case Scenarios Generation Using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07021v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07021v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3062"
  },
  {
    "objectID": "posts/Motamot_A_Dataset_for_Revealing_the_Supremacy_of_Large_Language_Models_over_Transformer_Models_in_Bengali_Political_Sentiment_Analysis/2024-07-28-Motamot_A_Dataset_for_Revealing_the_Supremacy_of_Large_Language_Models_over_Transformer_Models_in_Bengali_Political_Sentiment_Analysis.html#appendix",
    "href": "posts/Motamot_A_Dataset_for_Revealing_the_Supremacy_of_Large_Language_Models_over_Transformer_Models_in_Bengali_Political_Sentiment_Analysis/2024-07-28-Motamot_A_Dataset_for_Revealing_the_Supremacy_of_Large_Language_Models_over_Transformer_Models_in_Bengali_Political_Sentiment_Analysis.html#appendix",
    "title": "Motamot: A Dataset for Revealing the Supremacy of Large Language Models over Transformer Models in Bengali Political Sentiment Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19528v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19528v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5988"
  },
  {
    "objectID": "posts/OpenDevin_An_Open_Platform_for_AI_Software_Developers_as_Generalist_Agents/2024-07-23-OpenDevin_An_Open_Platform_for_AI_Software_Developers_as_Generalist_Agents.html",
    "href": "posts/OpenDevin_An_Open_Platform_for_AI_Software_Developers_as_Generalist_Agents/2024-07-23-OpenDevin_An_Open_Platform_for_AI_Software_Developers_as_Generalist_Agents.html",
    "title": "OpenDevin: An Open Platform for AI Software Developers as Generalist Agents",
    "section": "",
    "text": "Summary:\nOpenDevin is an open platform designed for AI software developers, offering a powerful and flexible environment for the development of AI agents that interact with the world through software. The platform supports the implementation of new agents, safe interaction with sandboxed environments for code execution, coordination between multiple agents, and incorporation of evaluation benchmarks. The architecture of OpenDevin includes an interaction mechanism, an environment consisting of a sandboxed operating system and a web browser, and an interface for agents to create complex software, execute code, and browse websites. The platform also supports multi-agent delegation and an evaluation framework for assessing agents across various tasks.\nKey Terms:\nMajor Findings:"
  },
  {
    "objectID": "posts/OpenDevin_An_Open_Platform_for_AI_Software_Developers_as_Generalist_Agents/2024-07-23-OpenDevin_An_Open_Platform_for_AI_Software_Developers_as_Generalist_Agents.html#appendix",
    "href": "posts/OpenDevin_An_Open_Platform_for_AI_Software_Developers_as_Generalist_Agents/2024-07-23-OpenDevin_An_Open_Platform_for_AI_Software_Developers_as_Generalist_Agents.html#appendix",
    "title": "OpenDevin: An Open Platform for AI Software Developers as Generalist Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16741v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16741v1\n\n\nTruncated\nTrue\n\n\nWord Count\n31157"
  },
  {
    "objectID": "posts/What_Do_Language_Models_Learn_in_Context_The_Structured_Task_Hypothesis/2024-06-06-What_Do_Language_Models_Learn_in_Context_The_Structured_Task_Hypothesis.html#appendix",
    "href": "posts/What_Do_Language_Models_Learn_in_Context_The_Structured_Task_Hypothesis/2024-06-06-What_Do_Language_Models_Learn_in_Context_The_Structured_Task_Hypothesis.html#appendix",
    "title": "What Do Language Models Learn in Context? The Structured Task Hypothesis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04216v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04216v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15"
  },
  {
    "objectID": "posts/Examining_the_Influence_of_Political_Bias_on_Large_Language_Model_Performance_in_Stance_Classification/2024-07-25-Examining_the_Influence_of_Political_Bias_on_Large_Language_Model_Performance_in_Stance_Classification.html#appendix",
    "href": "posts/Examining_the_Influence_of_Political_Bias_on_Large_Language_Model_Performance_in_Stance_Classification/2024-07-25-Examining_the_Influence_of_Political_Bias_on_Large_Language_Model_Performance_in_Stance_Classification.html#appendix",
    "title": "Examining the Influence of Political Bias on Large Language Model Performance in Stance Classification",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17688v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17688v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7443"
  },
  {
    "objectID": "posts/Cambrian_1_A_Fully_Open_Vision_Centric_Exploration_of_Multimodal_LLMs/2024-06-24-Cambrian_1_A_Fully_Open_Vision_Centric_Exploration_of_Multimodal_LLMs.html",
    "href": "posts/Cambrian_1_A_Fully_Open_Vision_Centric_Exploration_of_Multimodal_LLMs/2024-06-24-Cambrian_1_A_Fully_Open_Vision_Centric_Exploration_of_Multimodal_LLMs.html",
    "title": "Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs",
    "section": "",
    "text": "Summary:\nThe paper introduces Cambrian-1, a family of multimodal large language models (MLLMs) that adopt a vision-centric approach. The authors argue that the design choices for vision components in MLLMs are often insufficiently explored and disconnected from visual representation learning research, hindering accurate sensory grounding in real-world scenarios. The study uses LLMs and visual instruction tuning as an interface to evaluate various visual representations, offering new insights into different models and architectures. The authors critically examine existing MLLM benchmarks and introduce a new vision-centric benchmark, CV-Bench. They also propose the Spatial Vision Aggregator (SVA), a dynamic and spatially-aware connector that integrates high-resolution vision features with LLMs while reducing the number of tokens.\nMajor Findings:"
  },
  {
    "objectID": "posts/Cambrian_1_A_Fully_Open_Vision_Centric_Exploration_of_Multimodal_LLMs/2024-06-24-Cambrian_1_A_Fully_Open_Vision_Centric_Exploration_of_Multimodal_LLMs.html#appendix",
    "href": "posts/Cambrian_1_A_Fully_Open_Vision_Centric_Exploration_of_Multimodal_LLMs/2024-06-24-Cambrian_1_A_Fully_Open_Vision_Centric_Exploration_of_Multimodal_LLMs.html#appendix",
    "title": "Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16860v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16860v1\n\n\nTruncated\nTrue\n\n\nWord Count\n44586"
  },
  {
    "objectID": "posts/My_Ontologist_Evaluating_BFO_Based_AI_for_Definition_Support/2024-07-24-My_Ontologist_Evaluating_BFO_Based_AI_for_Definition_Support.html#appendix",
    "href": "posts/My_Ontologist_Evaluating_BFO_Based_AI_for_Definition_Support/2024-07-24-My_Ontologist_Evaluating_BFO_Based_AI_for_Definition_Support.html#appendix",
    "title": "My Ontologist: Evaluating BFO-Based AI for Definition Support",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17657v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17657v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9188"
  },
  {
    "objectID": "posts/CFinBench_A_Comprehensive_Chinese_Financial_Benchmark_for_Large_Language_Models/2024-07-02-CFinBench_A_Comprehensive_Chinese_Financial_Benchmark_for_Large_Language_Models.html#appendix",
    "href": "posts/CFinBench_A_Comprehensive_Chinese_Financial_Benchmark_for_Large_Language_Models/2024-07-02-CFinBench_A_Comprehensive_Chinese_Financial_Benchmark_for_Large_Language_Models.html#appendix",
    "title": "CFinBench: A Comprehensive Chinese Financial Benchmark for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02301v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02301v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7394"
  },
  {
    "objectID": "posts/Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination/2024-06-10-Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination.html",
    "href": "posts/Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination/2024-06-10-Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination.html",
    "title": "Enhancing Food Safety in Supply Chains: The Potential Role of Large Language Models in Preventing Campylobacter Contamination",
    "section": "",
    "text": "Summary:\nThis study explores the potential of large language models (LLMs), specifically generative pre-trained transformers (GPTs), to mitigate Campylobacter contamination across four typical stages of the food supply chain: primary production, food processing, distribution and retail, and preparation and consumption. The study also considers critical barriers to implementing GPTs at each step of the supply chain and proposes initial measures to overcome these obstacles.\nMajor Findings:\nAnalysis and Critique:\nThe study presents an intriguing potential for LLMs to enhance food safety, but the ‘LLM – food safety’ interface remains largely underexplored. The proposed applications of LLMs in this domain are promising, but they require further investigation and practical applications. The study also acknowledges that the adoption of LLMs in the food industry and agri-food supply chains may face several inhibiting factors, such as technological adoption, cultural barriers, data quality and availability, and technical challenges in integrating LLMs with existing food processing and slaughterhouse systems.\nTo alleviate these barriers and enable the deployment of LLMs for bacterial contamination reduction across food supply chains, a"
  },
  {
    "objectID": "posts/Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination/2024-06-10-Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination.html#appendix",
    "href": "posts/Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination/2024-06-10-Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination.html#appendix",
    "title": "Enhancing Food Safety in Supply Chains: The Potential Role of Large Language Models in Preventing Campylobacter Contamination",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06049v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06049v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18111"
  },
  {
    "objectID": "posts/An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection/2024-06-10-An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection.html",
    "href": "posts/An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection/2024-06-10-An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection.html",
    "title": "An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection",
    "section": "",
    "text": "Summary:\nThe paper introduces CodeBreaker, a pioneering LLM-assisted backdoor attack framework on code completion models. Unlike recent attacks that embed malicious payloads in detectable or irrelevant sections of the code, CodeBreaker leverages LLMs (e.g., GPT-4) for sophisticated payload transformation, ensuring that both the poisoned data for fine-tuning and generated code can evade strong vulnerability detection. CodeBreaker stands out with its comprehensive coverage of vulnerabilities, making it the first to provide such an extensive set for evaluation.\nMajor Findings:\nAnalysis and Critique:\nWhile CodeBreaker presents a significant advancement in backdoor attacks on code completion models, there are potential limitations and areas for improvement. The reliance on LLMs for payload transformation and obfuscation may introduce new vulnerabilities in the LLMs themselves, as they are used to facilitate adversarial attacks. Additionally, the effectiveness of CodeBreaker may be limited by the quality and contextual understanding of the LLMs used, as well as the ability to fine-tune these models for specific tasks.\nFurther research is needed to explore the potential for more robust defenses"
  },
  {
    "objectID": "posts/An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection/2024-06-10-An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection.html#appendix",
    "href": "posts/An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection/2024-06-10-An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection.html#appendix",
    "title": "An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06822v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06822v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11894"
  },
  {
    "objectID": "posts/On_the_attribution_of_confidence_to_large_language_models/2024-07-11-On_the_attribution_of_confidence_to_large_language_models.html#appendix",
    "href": "posts/On_the_attribution_of_confidence_to_large_language_models/2024-07-11-On_the_attribution_of_confidence_to_large_language_models.html#appendix",
    "title": "On the attribution of confidence to large language models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08388v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08388v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11712"
  },
  {
    "objectID": "posts/Evaluating_Implicit_Bias_in_Large_Language_Models_by_Attacking_From_a_Psychometric_Perspective/2024-06-20-Evaluating_Implicit_Bias_in_Large_Language_Models_by_Attacking_From_a_Psychometric_Perspective.html#appendix",
    "href": "posts/Evaluating_Implicit_Bias_in_Large_Language_Models_by_Attacking_From_a_Psychometric_Perspective/2024-06-20-Evaluating_Implicit_Bias_in_Large_Language_Models_by_Attacking_From_a_Psychometric_Perspective.html#appendix",
    "title": "Evaluating Implicit Bias in Large Language Models by Attacking From a Psychometric Perspective",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14023v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14023v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7014"
  },
  {
    "objectID": "posts/Large_Language_Models_Assume_People_are_More_Rational_than_We_Really_are/2024-06-24-Large_Language_Models_Assume_People_are_More_Rational_than_We_Really_are.html#appendix",
    "href": "posts/Large_Language_Models_Assume_People_are_More_Rational_than_We_Really_are/2024-06-24-Large_Language_Models_Assume_People_are_More_Rational_than_We_Really_are.html#appendix",
    "title": "Large Language Models Assume People are More Rational than We Really are",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17055v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17055v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9964"
  },
  {
    "objectID": "posts/LICO_Large_Language_Models_for_In_Context_Molecular_Optimization/2024-06-27-LICO_Large_Language_Models_for_In_Context_Molecular_Optimization.html#appendix",
    "href": "posts/LICO_Large_Language_Models_for_In_Context_Molecular_Optimization/2024-06-27-LICO_Large_Language_Models_for_In_Context_Molecular_Optimization.html#appendix",
    "title": "LICO: Large Language Models for In-Context Molecular Optimization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18851v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18851v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11485"
  },
  {
    "objectID": "posts/Benchmark_Data_Contamination_of_Large_Language_Models_A_Survey/2024-06-06-Benchmark_Data_Contamination_of_Large_Language_Models_A_Survey.html#appendix",
    "href": "posts/Benchmark_Data_Contamination_of_Large_Language_Models_A_Survey/2024-06-06-Benchmark_Data_Contamination_of_Large_Language_Models_A_Survey.html#appendix",
    "title": "Benchmark Data Contamination of Large Language Models: A Survey",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04244v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04244v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13688"
  },
  {
    "objectID": "posts/SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance/2024-06-26-SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance.html#major-findings",
    "href": "posts/SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance/2024-06-26-SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance.html#major-findings",
    "title": "SafeAligner: Safety Alignment against Jailbreak Attacks via Response Disparity Guidance",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nSafeAligner increases the likelihood of beneficial tokens while reducing the occurrence of harmful ones, ensuring secure alignment with minimal loss to generality.\nExtensive experiments demonstrate that SafeAligner can be applied to various LLMs, improving their defensive capabilities while preserving their inherent general capabilities.\nThe method achieves safety alignment cost-effectively, with potential cost reductions by scaling down internal models."
  },
  {
    "objectID": "posts/SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance/2024-06-26-SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance.html#analysis-and-critique",
    "href": "posts/SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance/2024-06-26-SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance.html#analysis-and-critique",
    "title": "SafeAligner: Safety Alignment against Jailbreak Attacks via Response Disparity Guidance",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a novel approach to addressing jailbreak attacks on LLMs, which is a significant concern in the field. The proposed method, SafeAligner, offers a promising solution by leveraging the differences in the safety tendencies of model responses. However, the paper does not discuss the potential limitations or unintended consequences of using this method. For instance, it is unclear how SafeAligner would handle cases where the Sentinel and Intruder Models produce conflicting or ambiguous responses. Additionally, the paper does not address the potential computational overhead of training and maintaining two specialized models. Further research is needed to evaluate the long-term effectiveness and efficiency of SafeAligner in real-world applications."
  },
  {
    "objectID": "posts/SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance/2024-06-26-SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance.html#appendix",
    "href": "posts/SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance/2024-06-26-SafeAligner_Safety_Alignment_against_Jailbreak_Attacks_via_Response_Disparity_Guidance.html#appendix",
    "title": "SafeAligner: Safety Alignment against Jailbreak Attacks via Response Disparity Guidance",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18118v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18118v1\n\n\nTruncated\nFalse\n\n\nWord Count\n21385"
  },
  {
    "objectID": "posts/AutoRAG_HP_Automatic_Online_Hyper_Parameter_Tuning_for_Retrieval_Augmented_Generation/2024-06-27-AutoRAG_HP_Automatic_Online_Hyper_Parameter_Tuning_for_Retrieval_Augmented_Generation.html#appendix",
    "href": "posts/AutoRAG_HP_Automatic_Online_Hyper_Parameter_Tuning_for_Retrieval_Augmented_Generation/2024-06-27-AutoRAG_HP_Automatic_Online_Hyper_Parameter_Tuning_for_Retrieval_Augmented_Generation.html#appendix",
    "title": "AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19251v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19251v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7362"
  },
  {
    "objectID": "posts/Uncertainty_Estimation_of_Large_Language_Models_in_Medical_Question_Answering/2024-07-11-Uncertainty_Estimation_of_Large_Language_Models_in_Medical_Question_Answering.html#appendix",
    "href": "posts/Uncertainty_Estimation_of_Large_Language_Models_in_Medical_Question_Answering/2024-07-11-Uncertainty_Estimation_of_Large_Language_Models_in_Medical_Question_Answering.html#appendix",
    "title": "Uncertainty Estimation of Large Language Models in Medical Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08662v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08662v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5161"
  },
  {
    "objectID": "posts/Multi_Layer_Ranking_with_Large_Language_Models_for_News_Source_Recommendation/2024-06-17-Multi_Layer_Ranking_with_Large_Language_Models_for_News_Source_Recommendation.html#appendix",
    "href": "posts/Multi_Layer_Ranking_with_Large_Language_Models_for_News_Source_Recommendation/2024-06-17-Multi_Layer_Ranking_with_Large_Language_Models_for_News_Source_Recommendation.html#appendix",
    "title": "Multi-Layer Ranking with Large Language Models for News Source Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11745v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11745v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4168"
  },
  {
    "objectID": "posts/Unveiling_Assumptions_Exploring_the_Decisions_of_AI_Chatbots_and_Human_Testers/2024-06-17-Unveiling_Assumptions_Exploring_the_Decisions_of_AI_Chatbots_and_Human_Testers.html#appendix",
    "href": "posts/Unveiling_Assumptions_Exploring_the_Decisions_of_AI_Chatbots_and_Human_Testers/2024-06-17-Unveiling_Assumptions_Exploring_the_Decisions_of_AI_Chatbots_and_Human_Testers.html#appendix",
    "title": "Unveiling Assumptions: Exploring the Decisions of AI Chatbots and Human Testers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11339v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11339v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5891"
  },
  {
    "objectID": "posts/WaDec_Decompile_WebAssembly_Using_Large_Language_Model/2024-06-17-WaDec_Decompile_WebAssembly_Using_Large_Language_Model.html#appendix",
    "href": "posts/WaDec_Decompile_WebAssembly_Using_Large_Language_Model/2024-06-17-WaDec_Decompile_WebAssembly_Using_Large_Language_Model.html#appendix",
    "title": "WaDec: Decompile WebAssembly Using Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11346v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11346v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10923"
  },
  {
    "objectID": "posts/TextGrad_Automatic_Differentiation_via_Text/2024-06-11-TextGrad_Automatic_Differentiation_via_Text.html#appendix",
    "href": "posts/TextGrad_Automatic_Differentiation_via_Text/2024-06-11-TextGrad_Automatic_Differentiation_via_Text.html#appendix",
    "title": "TextGrad: Automatic Differentiation via Text",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07496v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07496v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14644"
  },
  {
    "objectID": "posts/Skywork_Math_Data_Scaling_Laws_for_Mathematical_Reasoning_in_Large_Language_Models____The_Story_Goes_On/2024-07-11-Skywork_Math_Data_Scaling_Laws_for_Mathematical_Reasoning_in_Large_Language_Models____The_Story_Goes_On.html#appendix",
    "href": "posts/Skywork_Math_Data_Scaling_Laws_for_Mathematical_Reasoning_in_Large_Language_Models____The_Story_Goes_On/2024-07-11-Skywork_Math_Data_Scaling_Laws_for_Mathematical_Reasoning_in_Large_Language_Models____The_Story_Goes_On.html#appendix",
    "title": "Skywork-Math: Data Scaling Laws for Mathematical Reasoning in Large Language Models – The Story Goes On",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08348v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08348v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12177"
  },
  {
    "objectID": "posts/Do_LLMs_Exhibit_Human_Like_Reasoning_Evaluating_Theory_of_Mind_in_LLMs_for_Open_Ended_Responses/2024-06-09-Do_LLMs_Exhibit_Human_Like_Reasoning_Evaluating_Theory_of_Mind_in_LLMs_for_Open_Ended_Responses.html#appendix",
    "href": "posts/Do_LLMs_Exhibit_Human_Like_Reasoning_Evaluating_Theory_of_Mind_in_LLMs_for_Open_Ended_Responses/2024-06-09-Do_LLMs_Exhibit_Human_Like_Reasoning_Evaluating_Theory_of_Mind_in_LLMs_for_Open_Ended_Responses.html#appendix",
    "title": "Do LLMs Exhibit Human-Like Reasoning? Evaluating Theory of Mind in LLMs for Open-Ended Responses",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05659v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05659v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10269"
  },
  {
    "objectID": "posts/Large_Language_Model_as_an_Assignment_Evaluator_Insights_Feedback_and_Challenges_in_a_1000+_Student_Course/2024-07-07-Large_Language_Model_as_an_Assignment_Evaluator_Insights_Feedback_and_Challenges_in_a_1000+_Student_Course.html#appendix",
    "href": "posts/Large_Language_Model_as_an_Assignment_Evaluator_Insights_Feedback_and_Challenges_in_a_1000+_Student_Course/2024-07-07-Large_Language_Model_as_an_Assignment_Evaluator_Insights_Feedback_and_Challenges_in_a_1000+_Student_Course.html#appendix",
    "title": "Large Language Model as an Assignment Evaluator: Insights, Feedback, and Challenges in a 1000+ Student Course",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05216v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05216v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5931"
  },
  {
    "objectID": "posts/Large_Language_Models_as_Evaluators_for_Recommendation_Explanations/2024-06-06-Large_Language_Models_as_Evaluators_for_Recommendation_Explanations.html#appendix",
    "href": "posts/Large_Language_Models_as_Evaluators_for_Recommendation_Explanations/2024-06-06-Large_Language_Models_as_Evaluators_for_Recommendation_Explanations.html#appendix",
    "title": "Large Language Models as Evaluators for Recommendation Explanations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03248v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03248v2\n\n\nTruncated\nFalse\n\n\nWord Count\n7752"
  },
  {
    "objectID": "posts/MoPS_Modular_Story_Premise_Synthesis_for_Open_Ended_Automatic_Story_Generation/2024-06-09-MoPS_Modular_Story_Premise_Synthesis_for_Open_Ended_Automatic_Story_Generation.html#appendix",
    "href": "posts/MoPS_Modular_Story_Premise_Synthesis_for_Open_Ended_Automatic_Story_Generation/2024-06-09-MoPS_Modular_Story_Premise_Synthesis_for_Open_Ended_Automatic_Story_Generation.html#appendix",
    "title": "MoPS: Modular Story Premise Synthesis for Open-Ended Automatic Story Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05690v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05690v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9468"
  },
  {
    "objectID": "posts/Optimal_Decision_Making_Through_Scenario_Simulations_Using_Large_Language_Models/2024-07-09-Optimal_Decision_Making_Through_Scenario_Simulations_Using_Large_Language_Models.html#appendix",
    "href": "posts/Optimal_Decision_Making_Through_Scenario_Simulations_Using_Large_Language_Models/2024-07-09-Optimal_Decision_Making_Through_Scenario_Simulations_Using_Large_Language_Models.html#appendix",
    "title": "Optimal Decision Making Through Scenario Simulations Using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06486v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06486v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4425"
  },
  {
    "objectID": "posts/LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs/2024-06-26-LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs.html#major-findings",
    "href": "posts/LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs/2024-06-26-LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs.html#major-findings",
    "title": "LongIns: A Challenging Long-context Instruction-based Exam for LLMs",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe top-performing GPT-4 with 128k context length performs poorly on the evaluation context window of 16k in LongIns.\nSignificant efforts are still needed for the multi-hop reasoning ability of many existing LLMs under short context windows (&lt;4k).\nMost models fail to achieve high scores when the critical information length is only 8k, and even GPT-4 and GPT-4o score poorly at 16k length."
  },
  {
    "objectID": "posts/LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs/2024-06-26-LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs.html#analysis-and-critique",
    "href": "posts/LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs/2024-06-26-LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs.html#analysis-and-critique",
    "title": "LongIns: A Challenging Long-context Instruction-based Exam for LLMs",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper provides a valuable contribution to the field by introducing a benchmark that focuses on the actual comprehensible window length of LLMs, which is often overlooked in existing benchmarks.\nThe authors evaluate a diverse set of LLMs, providing a comprehensive analysis of their long-context understanding capabilities.\nHowever, the paper does not discuss the potential limitations of the proposed benchmark, such as the generalizability of the findings to other types of tasks or the potential biases in the dataset.\nAdditionally, the paper does not provide a detailed analysis of the methodology used to generate the dataset, which could impact the validity of the results.\nFinally, the paper does not discuss the potential implications of the findings for the development of LLMs or the design of future benchmarks."
  },
  {
    "objectID": "posts/LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs/2024-06-26-LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs.html#appendix",
    "href": "posts/LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs/2024-06-26-LongIns_A_Challenging_Long_context_Instruction_based_Exam_for_LLMs.html#appendix",
    "title": "LongIns: A Challenging Long-context Instruction-based Exam for LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17588v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17588v2\n\n\nTruncated\nFalse\n\n\nWord Count\n5491"
  },
  {
    "objectID": "posts/GenFollower_Enhancing_Car_Following_Prediction_with_Large_Language_Models/2024-07-08-GenFollower_Enhancing_Car_Following_Prediction_with_Large_Language_Models.html#appendix",
    "href": "posts/GenFollower_Enhancing_Car_Following_Prediction_with_Large_Language_Models/2024-07-08-GenFollower_Enhancing_Car_Following_Prediction_with_Large_Language_Models.html#appendix",
    "title": "GenFollower: Enhancing Car-Following Prediction with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05611v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05611v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7041"
  },
  {
    "objectID": "posts/Learning_to_Refuse_Towards_Mitigating_Privacy_Risks_in_LLMs/2024-07-14-Learning_to_Refuse_Towards_Mitigating_Privacy_Risks_in_LLMs.html#appendix",
    "href": "posts/Learning_to_Refuse_Towards_Mitigating_Privacy_Risks_in_LLMs/2024-07-14-Learning_to_Refuse_Towards_Mitigating_Privacy_Risks_in_LLMs.html#appendix",
    "title": "Learning to Refuse: Towards Mitigating Privacy Risks in LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10058v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10058v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5969"
  },
  {
    "objectID": "posts/Seeing_Through_AIs_Lens_Enhancing_Human_Skepticism_Towards_LLM_Generated_Fake_News/2024-06-20-Seeing_Through_AIs_Lens_Enhancing_Human_Skepticism_Towards_LLM_Generated_Fake_News.html#appendix",
    "href": "posts/Seeing_Through_AIs_Lens_Enhancing_Human_Skepticism_Towards_LLM_Generated_Fake_News/2024-06-20-Seeing_Through_AIs_Lens_Enhancing_Human_Skepticism_Towards_LLM_Generated_Fake_News.html#appendix",
    "title": "Seeing Through AI’s Lens: Enhancing Human Skepticism Towards LLM-Generated Fake News",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14012v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14012v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7336"
  },
  {
    "objectID": "posts/Enabling_Uniform_Computer_Interaction_Experience_for_Blind_Users_through_Large_Language_Models/2024-07-28-Enabling_Uniform_Computer_Interaction_Experience_for_Blind_Users_through_Large_Language_Models.html#appendix",
    "href": "posts/Enabling_Uniform_Computer_Interaction_Experience_for_Blind_Users_through_Large_Language_Models/2024-07-28-Enabling_Uniform_Computer_Interaction_Experience_for_Blind_Users_through_Large_Language_Models.html#appendix",
    "title": "Enabling Uniform Computer Interaction Experience for Blind Users through Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19537v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19537v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13074"
  },
  {
    "objectID": "posts/Large_language_models_for_generating_rules_yay_or_nay/2024-06-10-Large_language_models_for_generating_rules_yay_or_nay.html#appendix",
    "href": "posts/Large_language_models_for_generating_rules_yay_or_nay/2024-06-10-Large_language_models_for_generating_rules_yay_or_nay.html#appendix",
    "title": "Large language models for generating rules, yay or nay?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06835v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06835v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4575"
  },
  {
    "objectID": "posts/ObscurePrompt_Jailbreaking_Large_Language_Models_via_Obscure_Input/2024-06-19-ObscurePrompt_Jailbreaking_Large_Language_Models_via_Obscure_Input.html#appendix",
    "href": "posts/ObscurePrompt_Jailbreaking_Large_Language_Models_via_Obscure_Input/2024-06-19-ObscurePrompt_Jailbreaking_Large_Language_Models_via_Obscure_Input.html#appendix",
    "title": "ObscurePrompt: Jailbreaking Large Language Models via Obscure Input",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13662v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13662v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7246"
  },
  {
    "objectID": "posts/Talk_With_Human_like_Agents_Empathetic_Dialogue_Through_Perceptible_Acoustic_Reception_and_Reaction/2024-06-18-Talk_With_Human_like_Agents_Empathetic_Dialogue_Through_Perceptible_Acoustic_Reception_and_Reaction.html#appendix",
    "href": "posts/Talk_With_Human_like_Agents_Empathetic_Dialogue_Through_Perceptible_Acoustic_Reception_and_Reaction/2024-06-18-Talk_With_Human_like_Agents_Empathetic_Dialogue_Through_Perceptible_Acoustic_Reception_and_Reaction.html#appendix",
    "title": "Talk With Human-like Agents: Empathetic Dialogue Through Perceptible Acoustic Reception and Reaction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12707v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12707v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6339"
  },
  {
    "objectID": "posts/Generation_and_De_Identification_of_Indian_Clinical_Discharge_Summaries_using_LLMs/2024-07-08-Generation_and_De_Identification_of_Indian_Clinical_Discharge_Summaries_using_LLMs.html#appendix",
    "href": "posts/Generation_and_De_Identification_of_Indian_Clinical_Discharge_Summaries_using_LLMs/2024-07-08-Generation_and_De_Identification_of_Indian_Clinical_Discharge_Summaries_using_LLMs.html#appendix",
    "title": "Generation and De-Identification of Indian Clinical Discharge Summaries using LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05887v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05887v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9455"
  },
  {
    "objectID": "posts/VideoLLaMA_2_Advancing_Spatial_Temporal_Modeling_and_Audio_Understanding_in_Video_LLMs/2024-06-11-VideoLLaMA_2_Advancing_Spatial_Temporal_Modeling_and_Audio_Understanding_in_Video_LLMs.html#appendix",
    "href": "posts/VideoLLaMA_2_Advancing_Spatial_Temporal_Modeling_and_Audio_Understanding_in_Video_LLMs/2024-06-11-VideoLLaMA_2_Advancing_Spatial_Temporal_Modeling_and_Audio_Understanding_in_Video_LLMs.html#appendix",
    "title": "VideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understanding in Video-LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07476v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07476v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5170"
  },
  {
    "objectID": "posts/Natural_Language_but_Omitted_On_the_Ineffectiveness_of_Large_Language_Models_privacy_policy_from_End_users_Perspective/2024-06-26-Natural_Language_but_Omitted_On_the_Ineffectiveness_of_Large_Language_Models_privacy_policy_from_End_users_Perspective.html#appendix",
    "href": "posts/Natural_Language_but_Omitted_On_the_Ineffectiveness_of_Large_Language_Models_privacy_policy_from_End_users_Perspective/2024-06-26-Natural_Language_but_Omitted_On_the_Ineffectiveness_of_Large_Language_Models_privacy_policy_from_End_users_Perspective.html#appendix",
    "title": "Natural Language but Omitted? On the Ineffectiveness of Large Language Models’ privacy policy from End-users’ Perspective",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18100v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18100v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9590"
  },
  {
    "objectID": "posts/STBench_Assessing_the_Ability_of_Large_Language_Models_in_Spatio_Temporal_Analysis/2024-06-27-STBench_Assessing_the_Ability_of_Large_Language_Models_in_Spatio_Temporal_Analysis.html#appendix",
    "href": "posts/STBench_Assessing_the_Ability_of_Large_Language_Models_in_Spatio_Temporal_Analysis/2024-06-27-STBench_Assessing_the_Ability_of_Large_Language_Models_in_Spatio_Temporal_Analysis.html#appendix",
    "title": "STBench: Assessing the Ability of Large Language Models in Spatio-Temporal Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19065v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19065v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11715"
  },
  {
    "objectID": "posts/Helpful_assistant_or_fruitful_facilitator_Investigating_how_personas_affect_language_model_behavior/2024-07-02-Helpful_assistant_or_fruitful_facilitator_Investigating_how_personas_affect_language_model_behavior.html#appendix",
    "href": "posts/Helpful_assistant_or_fruitful_facilitator_Investigating_how_personas_affect_language_model_behavior/2024-07-02-Helpful_assistant_or_fruitful_facilitator_Investigating_how_personas_affect_language_model_behavior.html#appendix",
    "title": "Helpful assistant or fruitful facilitator? Investigating how personas affect language model behavior",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02099v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02099v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8203"
  },
  {
    "objectID": "posts/Improving_Steering_and_Verification_in_AI_Assisted_Data_Analysis_with_Interactive_Task_Decomposition/2024-07-02-Improving_Steering_and_Verification_in_AI_Assisted_Data_Analysis_with_Interactive_Task_Decomposition.html",
    "href": "posts/Improving_Steering_and_Verification_in_AI_Assisted_Data_Analysis_with_Interactive_Task_Decomposition/2024-07-02-Improving_Steering_and_Verification_in_AI_Assisted_Data_Analysis_with_Interactive_Task_Decomposition.html",
    "title": "Improving Steering and Verification in AI-Assisted Data Analysis with Interactive Task Decomposition",
    "section": "",
    "text": "Summary:\nThis paper presents a study on the challenges of using AI-assisted data analysis tools, specifically focusing on steering and verification. The study involved 15 participants and identified two significant limitations: steering the AI and verifying its output. The paper then introduces a novel approach to improve steering and verification using editable AI assumptions, progressive disclosure, and non-linear conversations. Two implementations of this approach are presented, each balancing information overload and the degree of user control differently. A controlled, within-subjects experiment was conducted to compare these systems with a Conversational baseline system. The results showed that users reported significantly greater control with the two new systems and found intervention, correction, and verification easier compared to the baseline.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a well-structured and coherent summary of the study and its findings. The use of markdown for formatting enhances the readability and organization of the information. The study’s methodology and results are clearly explained, and the comparison with a Conversational baseline system provides a useful point of reference.\nHowever, there are some potential limitations and areas for improvement. The sample size of 15 participants is relatively small, which may limit the generalizability of the findings. Additionally, the study does not provide detailed information on the specific tasks or datasets used, making it difficult to assess the validity and applicability of the results. Furthermore, the paper does not discuss any potential biases or confounding factors that may have influenced the results.\nOverall, the paper offers valuable insights into the challenges and potential solutions for improving steering and verification in AI-assisted data analysis. However, further research with larger sample sizes and more diverse tasks"
  },
  {
    "objectID": "posts/Improving_Steering_and_Verification_in_AI_Assisted_Data_Analysis_with_Interactive_Task_Decomposition/2024-07-02-Improving_Steering_and_Verification_in_AI_Assisted_Data_Analysis_with_Interactive_Task_Decomposition.html#appendix",
    "href": "posts/Improving_Steering_and_Verification_in_AI_Assisted_Data_Analysis_with_Interactive_Task_Decomposition/2024-07-02-Improving_Steering_and_Verification_in_AI_Assisted_Data_Analysis_with_Interactive_Task_Decomposition.html#appendix",
    "title": "Improving Steering and Verification in AI-Assisted Data Analysis with Interactive Task Decomposition",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02651v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02651v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17913"
  },
  {
    "objectID": "posts/Large_Language_Model_based_FMRI_Encoding_of_Language_Functions_for_Subjects_with_Neurocognitive_Disorder/2024-07-15-Large_Language_Model_based_FMRI_Encoding_of_Language_Functions_for_Subjects_with_Neurocognitive_Disorder.html#appendix",
    "href": "posts/Large_Language_Model_based_FMRI_Encoding_of_Language_Functions_for_Subjects_with_Neurocognitive_Disorder/2024-07-15-Large_Language_Model_based_FMRI_Encoding_of_Language_Functions_for_Subjects_with_Neurocognitive_Disorder.html#appendix",
    "title": "Large Language Model-based FMRI Encoding of Language Functions for Subjects with Neurocognitive Disorder",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10376v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10376v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4280"
  },
  {
    "objectID": "posts/T_FREE_Tokenizer_Free_Generative_LLMs_via_Sparse_Representations_for_Memory_Efficient_Embeddings/2024-06-27-T_FREE_Tokenizer_Free_Generative_LLMs_via_Sparse_Representations_for_Memory_Efficient_Embeddings.html#appendix",
    "href": "posts/T_FREE_Tokenizer_Free_Generative_LLMs_via_Sparse_Representations_for_Memory_Efficient_Embeddings/2024-06-27-T_FREE_Tokenizer_Free_Generative_LLMs_via_Sparse_Representations_for_Memory_Efficient_Embeddings.html#appendix",
    "title": "T-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19223v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19223v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8998"
  },
  {
    "objectID": "posts/eyeballvul_a_future_proof_benchmark_for_vulnerability_detection_in_the_wild/2024-07-11-eyeballvul_a_future_proof_benchmark_for_vulnerability_detection_in_the_wild.html#appendix",
    "href": "posts/eyeballvul_a_future_proof_benchmark_for_vulnerability_detection_in_the_wild/2024-07-11-eyeballvul_a_future_proof_benchmark_for_vulnerability_detection_in_the_wild.html#appendix",
    "title": "eyeballvul: a future-proof benchmark for vulnerability detection in the wild",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08708v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08708v1\n\n\nTruncated\nFalse\n\n\nWord Count\n45"
  },
  {
    "objectID": "posts/MathOdyssey_Benchmarking_Mathematical_Problem_Solving_Skills_in_Large_Language_Models_Using_Odyssey_Math_Data/2024-06-26-MathOdyssey_Benchmarking_Mathematical_Problem_Solving_Skills_in_Large_Language_Models_Using_Odyssey_Math_Data.html#appendix",
    "href": "posts/MathOdyssey_Benchmarking_Mathematical_Problem_Solving_Skills_in_Large_Language_Models_Using_Odyssey_Math_Data/2024-06-26-MathOdyssey_Benchmarking_Mathematical_Problem_Solving_Skills_in_Large_Language_Models_Using_Odyssey_Math_Data.html#appendix",
    "title": "MathOdyssey: Benchmarking Mathematical Problem-Solving Skills in Large Language Models Using Odyssey Math Data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18321v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18321v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5533"
  },
  {
    "objectID": "posts/Depression_Detection_and_Analysis_using_Large_Language_Models_on_Textual_and_Audio_Visual_Modalities/2024-07-08-Depression_Detection_and_Analysis_using_Large_Language_Models_on_Textual_and_Audio_Visual_Modalities.html#appendix",
    "href": "posts/Depression_Detection_and_Analysis_using_Large_Language_Models_on_Textual_and_Audio_Visual_Modalities/2024-07-08-Depression_Detection_and_Analysis_using_Large_Language_Models_on_Textual_and_Audio_Visual_Modalities.html#appendix",
    "title": "Depression Detection and Analysis using Large Language Models on Textual and Audio-Visual Modalities",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06125v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06125v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9401"
  },
  {
    "objectID": "posts/Agentless_Demystifying_LLM_based_Software_Engineering_Agents/2024-07-01-Agentless_Demystifying_LLM_based_Software_Engineering_Agents.html#appendix",
    "href": "posts/Agentless_Demystifying_LLM_based_Software_Engineering_Agents/2024-07-01-Agentless_Demystifying_LLM_based_Software_Engineering_Agents.html#appendix",
    "title": "Agentless: Demystifying LLM-based Software Engineering Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01489v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01489v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8295"
  },
  {
    "objectID": "posts/CityGPT_Empowering_Urban_Spatial_Cognition_of_Large_Language_Models/2024-06-20-CityGPT_Empowering_Urban_Spatial_Cognition_of_Large_Language_Models.html",
    "href": "posts/CityGPT_Empowering_Urban_Spatial_Cognition_of_Large_Language_Models/2024-06-20-CityGPT_Empowering_Urban_Spatial_Cognition_of_Large_Language_Models.html",
    "title": "CityGPT: Empowering Urban Spatial Cognition of Large Language Models",
    "section": "",
    "text": "Overall Summary:\nThe paper introduces CityGPT, a framework designed to enhance the capability of large language models (LLMs) in understanding urban space and solving related urban tasks. The authors construct a diverse instruction tuning dataset, CityInstruction, to inject urban knowledge and improve spatial reasoning capabilities. They fine-tune various LLMs using a mixture of CityInstruction and general instruction data, without sacrificing general abilities. To validate the effectiveness of their methods, the authors create a comprehensive benchmark, CityEval, to evaluate LLMs in diverse urban scenarios and problems. The results demonstrate that small LLMs trained with CityInstruction can achieve competitive performance with commercial LLMs in the comprehensive evaluation of CityEval.\nMajor Findings:"
  },
  {
    "objectID": "posts/CityGPT_Empowering_Urban_Spatial_Cognition_of_Large_Language_Models/2024-06-20-CityGPT_Empowering_Urban_Spatial_Cognition_of_Large_Language_Models.html#appendix",
    "href": "posts/CityGPT_Empowering_Urban_Spatial_Cognition_of_Large_Language_Models/2024-06-20-CityGPT_Empowering_Urban_Spatial_Cognition_of_Large_Language_Models.html#appendix",
    "title": "CityGPT: Empowering Urban Spatial Cognition of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13948v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13948v1\n\n\nTruncated\nTrue\n\n\nWord Count\n38939"
  },
  {
    "objectID": "posts/A_Voter_Based_Stochastic_Rejection_Method_Framework_for_Asymptotically_Safe_Language_Model_Outputs/2024-07-24-A_Voter_Based_Stochastic_Rejection_Method_Framework_for_Asymptotically_Safe_Language_Model_Outputs.html#appendix",
    "href": "posts/A_Voter_Based_Stochastic_Rejection_Method_Framework_for_Asymptotically_Safe_Language_Model_Outputs/2024-07-24-A_Voter_Based_Stochastic_Rejection_Method_Framework_for_Asymptotically_Safe_Language_Model_Outputs.html#appendix",
    "title": "A Voter-Based Stochastic Rejection-Method Framework for Asymptotically Safe Language Model Outputs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16994v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16994v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5147"
  },
  {
    "objectID": "posts/EmPO_Theory_Driven_Dataset_Construction_for_Empathetic_Response_Generation_through_Preference_Optimization/2024-06-27-EmPO_Theory_Driven_Dataset_Construction_for_Empathetic_Response_Generation_through_Preference_Optimization.html#appendix",
    "href": "posts/EmPO_Theory_Driven_Dataset_Construction_for_Empathetic_Response_Generation_through_Preference_Optimization/2024-06-27-EmPO_Theory_Driven_Dataset_Construction_for_Empathetic_Response_Generation_through_Preference_Optimization.html#appendix",
    "title": "EmPO: Theory-Driven Dataset Construction for Empathetic Response Generation through Preference Optimization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19071v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19071v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4108"
  },
  {
    "objectID": "posts/Contrastive_Policy_Gradient_Aligning_LLMs_on_sequence_level_scores_in_a_supervised_friendly_fashion/2024-06-27-Contrastive_Policy_Gradient_Aligning_LLMs_on_sequence_level_scores_in_a_supervised_friendly_fashion.html#appendix",
    "href": "posts/Contrastive_Policy_Gradient_Aligning_LLMs_on_sequence_level_scores_in_a_supervised_friendly_fashion/2024-06-27-Contrastive_Policy_Gradient_Aligning_LLMs_on_sequence_level_scores_in_a_supervised_friendly_fashion.html#appendix",
    "title": "Contrastive Policy Gradient: Aligning LLMs on sequence-level scores in a supervised-friendly fashion",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19185v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19185v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8271"
  },
  {
    "objectID": "posts/LiveMind_Low_latency_Large_Language_Models_with_Simultaneous_Inference/2024-06-20-LiveMind_Low_latency_Large_Language_Models_with_Simultaneous_Inference.html#appendix",
    "href": "posts/LiveMind_Low_latency_Large_Language_Models_with_Simultaneous_Inference/2024-06-20-LiveMind_Low_latency_Large_Language_Models_with_Simultaneous_Inference.html#appendix",
    "title": "LiveMind: Low-latency Large Language Models with Simultaneous Inference",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14319v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14319v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8602"
  },
  {
    "objectID": "posts/Learning_to_Generate_Answers_with_Citations_via_Factual_Consistency_Models/2024-06-19-Learning_to_Generate_Answers_with_Citations_via_Factual_Consistency_Models.html#appendix",
    "href": "posts/Learning_to_Generate_Answers_with_Citations_via_Factual_Consistency_Models/2024-06-19-Learning_to_Generate_Answers_with_Citations_via_Factual_Consistency_Models.html#appendix",
    "title": "Learning to Generate Answers with Citations via Factual Consistency Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13124v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13124v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13245"
  },
  {
    "objectID": "posts/Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation/2024-06-27-Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.html#summary-1",
    "href": "posts/Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation/2024-06-27-Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.html#summary-1",
    "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
    "section": "Summary:",
    "text": "Summary:\n\nThe paper explores the use of Membership Inference Attacks (MIA) to determine whether a sample is part of the knowledge database of a Retrieval-Augmented Generation (RAG) system.\nThe core hypothesis is that if a sample is a member, it will exhibit significant similarity to the text generated by the RAG system.\nThe authors compute the cosine similarity and the model’s perplexity to establish a membership score, building robust features.\nTwo novel attack strategies are introduced: a Threshold-based Attack and a Machine Learning-based Attack, designed to accurately identify membership.\nExperimental validation of the methods achieved a ROC AUC of 82%."
  },
  {
    "objectID": "posts/Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation/2024-06-27-Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.html#major-findings",
    "href": "posts/Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation/2024-06-27-Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.html#major-findings",
    "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nMIA for RAG Systems: The paper demonstrates the effectiveness of using MIA to determine whether a sample is part of the knowledge database of a RAG system.\nRobust Features: The authors compute the cosine similarity and the model’s perplexity to establish a membership score, building robust features.\nNovel Attack Strategies: Two novel attack strategies are introduced: a Threshold-based Attack and a Machine Learning-based Attack, designed to accurately identify membership.\nExperimental Validation: The experimental validation of the methods achieved a ROC AUC of 82%."
  },
  {
    "objectID": "posts/Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation/2024-06-27-Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.html#analysis-and-critique",
    "href": "posts/Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation/2024-06-27-Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.html#analysis-and-critique",
    "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper provides a novel approach to assessing the security and privacy of RAG systems’ external databases.\nThe use of MIA to determine whether a sample is part of the knowledge database of a RAG system is a significant contribution.\nThe introduction of two novel attack strategies is a valuable addition to the field.\nThe experimental validation of the methods is a strength of the paper.\nHowever, the paper does not discuss potential countermeasures or defenses against these attacks, which could be a limitation.\nAdditionally, the paper does not explore the potential impact of these attacks on the performance of RAG systems, which could be an area for future research."
  },
  {
    "objectID": "posts/Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation/2024-06-27-Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.html#appendix",
    "href": "posts/Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation/2024-06-27-Seeing_Is_Believing_Black_Box_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.html#appendix",
    "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19234v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19234v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3427"
  },
  {
    "objectID": "posts/In_Context_Learning_and_Fine_Tuning_GPT_for_Argument_Mining/2024-06-10-In_Context_Learning_and_Fine_Tuning_GPT_for_Argument_Mining.html#appendix",
    "href": "posts/In_Context_Learning_and_Fine_Tuning_GPT_for_Argument_Mining/2024-06-10-In_Context_Learning_and_Fine_Tuning_GPT_for_Argument_Mining.html#appendix",
    "title": "In-Context Learning and Fine-Tuning GPT for Argument Mining",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06699v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06699v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2590"
  },
  {
    "objectID": "posts/FinDKG_Dynamic_Knowledge_Graphs_with_Large_Language_Models_for_Detecting_Global_Trends_in_Financial_Markets/2024-07-15-FinDKG_Dynamic_Knowledge_Graphs_with_Large_Language_Models_for_Detecting_Global_Trends_in_Financial_Markets.html#appendix",
    "href": "posts/FinDKG_Dynamic_Knowledge_Graphs_with_Large_Language_Models_for_Detecting_Global_Trends_in_Financial_Markets/2024-07-15-FinDKG_Dynamic_Knowledge_Graphs_with_Large_Language_Models_for_Detecting_Global_Trends_in_Financial_Markets.html#appendix",
    "title": "FinDKG: Dynamic Knowledge Graphs with Large Language Models for Detecting Global Trends in Financial Markets",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10909v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10909v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6659"
  },
  {
    "objectID": "posts/Modular_Pluralism_Pluralistic_Alignment_via_Multi_LLM_Collaboration/2024-06-22-Modular_Pluralism_Pluralistic_Alignment_via_Multi_LLM_Collaboration.html#appendix",
    "href": "posts/Modular_Pluralism_Pluralistic_Alignment_via_Multi_LLM_Collaboration/2024-06-22-Modular_Pluralism_Pluralistic_Alignment_via_Multi_LLM_Collaboration.html#appendix",
    "title": "Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.15951v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.15951v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8836"
  },
  {
    "objectID": "posts/Exploring_Large_Language_Models_to_generate_Easy_to_Read_content/2024-07-29-Exploring_Large_Language_Models_to_generate_Easy_to_Read_content.html#appendix",
    "href": "posts/Exploring_Large_Language_Models_to_generate_Easy_to_Read_content/2024-07-29-Exploring_Large_Language_Models_to_generate_Easy_to_Read_content.html#appendix",
    "title": "Exploring Large Language Models to generate Easy to Read content",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20046v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20046v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8462"
  },
  {
    "objectID": "posts/Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course/2024-06-10-Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course.html",
    "href": "posts/Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course/2024-06-10-Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course.html",
    "title": "Insights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course",
    "section": "",
    "text": "Summary:\nThis study explores the social dynamics surrounding the use of large language models (LLMs) in an undergraduate programming course. The research is guided by the social shaping of technology theory and focuses on two research questions: (1) How do social perceptions influence the usage of LLMs in an undergraduate intermediate-level programming course? (2) How does LLM usage relate to programming self-efficacy and midterm scores among undergraduate students in an intermediate-level programming course?\nThe study employs a mixed-methods approach, including an anonymous student survey, student interviews, and a regression analysis of midterm performance data with students’ self-reported use of LLMs on homework. The findings suggest that students’ engagement with LLMs is significantly associated with their perceptions of their future careers and their peers’ usage. Additionally, the use of LLMs has mixed impacts on students’ self-efficacy and perceived learning outcomes, with a notable negative correlation between LLM usage and self-efficacy regardless of major and a negative correlation between LLM usage and performance on the first midterm.\nMajor Findings:\nAnalysis and Critique:\nThe study provides valuable insights into the social dynamics surrounding the use of LLMs in undergraduate programming education. However, the research has some limitations, including the context of the study, potential selection bias, reliance on self-reported data, and the correlational nature of the regression analyses. Additionally, the study’s focus on peer-reviewed literature may have led to the omission of relevant contributions from non-peer-reviewed sources. Despite these limitations, the research offers a nuanced understanding of the complex dynamic between technology and social factors, challenging the notion of technological determinism. As LLMs and other AI technologies continue to evolve, it is crucial to consider the social dynamics that shape their appropriation."
  },
  {
    "objectID": "posts/Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course/2024-06-10-Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course.html#appendix",
    "href": "posts/Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course/2024-06-10-Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course.html#appendix",
    "title": "Insights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06451v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06451v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14658"
  },
  {
    "objectID": "posts/RS_Agent_Automating_Remote_Sensing_Tasks_through_Intelligent_Agents/2024-06-11-RS_Agent_Automating_Remote_Sensing_Tasks_through_Intelligent_Agents.html#appendix",
    "href": "posts/RS_Agent_Automating_Remote_Sensing_Tasks_through_Intelligent_Agents/2024-06-11-RS_Agent_Automating_Remote_Sensing_Tasks_through_Intelligent_Agents.html#appendix",
    "title": "RS-Agent: Automating Remote Sensing Tasks through Intelligent Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07089v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07089v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5913"
  },
  {
    "objectID": "posts/REPOEXEC_Evaluate_Code_Generation_with_a_Repository_Level_Executable_Benchmark/2024-06-17-REPOEXEC_Evaluate_Code_Generation_with_a_Repository_Level_Executable_Benchmark.html#appendix",
    "href": "posts/REPOEXEC_Evaluate_Code_Generation_with_a_Repository_Level_Executable_Benchmark/2024-06-17-REPOEXEC_Evaluate_Code_Generation_with_a_Repository_Level_Executable_Benchmark.html#appendix",
    "title": "REPOEXEC: Evaluate Code Generation with a Repository-Level Executable Benchmark",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11927v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11927v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7146"
  },
  {
    "objectID": "posts/Fundamental_Problems_With_Model_Editing_How_Should_Rational_Belief_Revision_Work_in_LLMs/2024-06-27-Fundamental_Problems_With_Model_Editing_How_Should_Rational_Belief_Revision_Work_in_LLMs.html",
    "href": "posts/Fundamental_Problems_With_Model_Editing_How_Should_Rational_Belief_Revision_Work_in_LLMs/2024-06-27-Fundamental_Problems_With_Model_Editing_How_Should_Rational_Belief_Revision_Work_in_LLMs.html",
    "title": "Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?",
    "section": "",
    "text": "Summary:\nThe paper critiques the predominant formulation of the model editing problem and proposes a semi-synthetic setting for evaluating model editing. The authors present 12 open challenges, summarized in three categories: (1) challenges with defining the model editing problem, (2) challenges with developing benchmarks, and (3) challenges with assuming LLMs have editable beliefs. The paper also introduces a semi-synthetic setting for evaluating model editing that precisely formalizes the problem, albeit with a simplified problem and models trained from scratch. The evaluation compares an LLM against a Bayesian model, reflecting that Bayesian epistemology is the gold standard in belief revision. The authors use facts from Wikidata to generate a corpus of noisy sentences, which they then train an autoregressive Transformer on. By fitting a Bayesian model to the same data, they obtain exact Bayesian posteriors that serve as the targets for evaluating language models. The experiments show that edits to language models generalize poorly with respect to other relevant beliefs, yielding inconsistent model beliefs.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive critique of the model editing problem and proposes a semi-synthetic setting for evaluating model editing. However, the proposed setting simplifies the problem and uses models trained from scratch, which may not fully capture the complexities of real-world LLMs. Additionally, the paper does not address potential solutions to the 12 open challenges it presents, leaving room for further research in this area. The experiments conducted in the paper"
  },
  {
    "objectID": "posts/Fundamental_Problems_With_Model_Editing_How_Should_Rational_Belief_Revision_Work_in_LLMs/2024-06-27-Fundamental_Problems_With_Model_Editing_How_Should_Rational_Belief_Revision_Work_in_LLMs.html#appendix",
    "href": "posts/Fundamental_Problems_With_Model_Editing_How_Should_Rational_Belief_Revision_Work_in_LLMs/2024-06-27-Fundamental_Problems_With_Model_Editing_How_Should_Rational_Belief_Revision_Work_in_LLMs.html#appendix",
    "title": "Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19354v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19354v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14906"
  },
  {
    "objectID": "posts/PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine_tuning/2024-07-02-PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine_tuning.html",
    "href": "posts/PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine_tuning/2024-07-02-PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine_tuning.html",
    "title": "PromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt during Large Language Model Fine-tuning",
    "section": "",
    "text": "Summary:\nThe paper introduces a novel method called PromptIntern for internalizing prompt knowledge into the parameters of large language models (LLMs) during fine-tuning. The approach aims to reduce inference costs by emulating the human learning process, where detailed templates and examples are gradually internalized and phased out as the model becomes accustomed to the task. PromptIntern consists of several key steps, including classifying input prompts into three components (template, examples, and query), setting a schedule to decrease both the template compression rate and the number of few-shot examples across training stages, and implementing template compression and example absorption to pre-process the input prompts.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine_tuning/2024-07-02-PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine_tuning.html#appendix",
    "href": "posts/PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine_tuning/2024-07-02-PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine_tuning.html#appendix",
    "title": "PromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt during Large Language Model Fine-tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02211v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02211v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7224"
  },
  {
    "objectID": "posts/The_Remarkable_Robustness_of_LLMs_Stages_of_Inference/2024-06-27-The_Remarkable_Robustness_of_LLMs_Stages_of_Inference.html#appendix",
    "href": "posts/The_Remarkable_Robustness_of_LLMs_Stages_of_Inference/2024-06-27-The_Remarkable_Robustness_of_LLMs_Stages_of_Inference.html#appendix",
    "title": "The Remarkable Robustness of LLMs: Stages of Inference?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19384v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19384v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8310"
  },
  {
    "objectID": "posts/Subtractive_Training_for_Music_Stem_Insertion_using_Latent_Diffusion_Models/2024-06-27-Subtractive_Training_for_Music_Stem_Insertion_using_Latent_Diffusion_Models.html#appendix",
    "href": "posts/Subtractive_Training_for_Music_Stem_Insertion_using_Latent_Diffusion_Models/2024-06-27-Subtractive_Training_for_Music_Stem_Insertion_using_Latent_Diffusion_Models.html#appendix",
    "title": "Subtractive Training for Music Stem Insertion using Latent Diffusion Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19328v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19328v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1133"
  },
  {
    "objectID": "posts/SoP_Unlock_the_Power_of_Social_Facilitation_for_Automatic_Jailbreak_Attack/2024-07-02-SoP_Unlock_the_Power_of_Social_Facilitation_for_Automatic_Jailbreak_Attack.html#appendix",
    "href": "posts/SoP_Unlock_the_Power_of_Social_Facilitation_for_Automatic_Jailbreak_Attack/2024-07-02-SoP_Unlock_the_Power_of_Social_Facilitation_for_Automatic_Jailbreak_Attack.html#appendix",
    "title": "SoP: Unlock the Power of Social Facilitation for Automatic Jailbreak Attack",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01902v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01902v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14863"
  },
  {
    "objectID": "posts/Paraphrase_and_Aggregate_with_Large_Language_Models_for_Minimizing_Intent_Classification_Errors/2024-06-24-Paraphrase_and_Aggregate_with_Large_Language_Models_for_Minimizing_Intent_Classification_Errors.html#appendix",
    "href": "posts/Paraphrase_and_Aggregate_with_Large_Language_Models_for_Minimizing_Intent_Classification_Errors/2024-06-24-Paraphrase_and_Aggregate_with_Large_Language_Models_for_Minimizing_Intent_Classification_Errors.html#appendix",
    "title": "Paraphrase and Aggregate with Large Language Models for Minimizing Intent Classification Errors",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17163v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17163v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4269"
  },
  {
    "objectID": "posts/Evaluating_the_Retrieval_Component_in_LLM_Based_Question_Answering_Systems/2024-06-10-Evaluating_the_Retrieval_Component_in_LLM_Based_Question_Answering_Systems.html#appendix",
    "href": "posts/Evaluating_the_Retrieval_Component_in_LLM_Based_Question_Answering_Systems/2024-06-10-Evaluating_the_Retrieval_Component_in_LLM_Based_Question_Answering_Systems.html#appendix",
    "title": "Evaluating the Retrieval Component in LLM-Based Question Answering Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06458v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06458v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4825"
  },
  {
    "objectID": "posts/Comparison_of_Static_Application_Security_Testing_Tools_and_Large_Language_Models_for_Repo_level_Vulnerability_Detection/2024-07-23-Comparison_of_Static_Application_Security_Testing_Tools_and_Large_Language_Models_for_Repo_level_Vulnerability_Detection.html#appendix",
    "href": "posts/Comparison_of_Static_Application_Security_Testing_Tools_and_Large_Language_Models_for_Repo_level_Vulnerability_Detection/2024-07-23-Comparison_of_Static_Application_Security_Testing_Tools_and_Large_Language_Models_for_Repo_level_Vulnerability_Detection.html#appendix",
    "title": "Comparison of Static Application Security Testing Tools and Large Language Models for Repo-level Vulnerability Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16235v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16235v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12620"
  },
  {
    "objectID": "posts/Hierarchical_Context_Pruning_Optimizing_Real_World_Code_Completion_with_Repository_Level_Pretrained_Code_LLMs/2024-06-27-Hierarchical_Context_Pruning_Optimizing_Real_World_Code_Completion_with_Repository_Level_Pretrained_Code_LLMs.html#appendix",
    "href": "posts/Hierarchical_Context_Pruning_Optimizing_Real_World_Code_Completion_with_Repository_Level_Pretrained_Code_LLMs/2024-06-27-Hierarchical_Context_Pruning_Optimizing_Real_World_Code_Completion_with_Repository_Level_Pretrained_Code_LLMs.html#appendix",
    "title": "Hierarchical Context Pruning: Optimizing Real-World Code Completion with Repository-Level Pretrained Code LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18294v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18294v2\n\n\nTruncated\nFalse\n\n\nWord Count\n6374"
  },
  {
    "objectID": "posts/Data_Contamination_Can_Cross_Language_Barriers/2024-06-19-Data_Contamination_Can_Cross_Language_Barriers.html#appendix",
    "href": "posts/Data_Contamination_Can_Cross_Language_Barriers/2024-06-19-Data_Contamination_Can_Cross_Language_Barriers.html#appendix",
    "title": "Data Contamination Can Cross Language Barriers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13236v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13236v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7163"
  },
  {
    "objectID": "posts/Should_We_Fine_Tune_or_RAG_Evaluating_Different_Techniques_to_Adapt_LLMs_for_Dialogue/2024-06-10-Should_We_Fine_Tune_or_RAG_Evaluating_Different_Techniques_to_Adapt_LLMs_for_Dialogue.html#appendix",
    "href": "posts/Should_We_Fine_Tune_or_RAG_Evaluating_Different_Techniques_to_Adapt_LLMs_for_Dialogue/2024-06-10-Should_We_Fine_Tune_or_RAG_Evaluating_Different_Techniques_to_Adapt_LLMs_for_Dialogue.html#appendix",
    "title": "Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06399v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06399v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3367"
  },
  {
    "objectID": "posts/Using_Grammar_Masking_to_Ensure_Syntactic_Validity_in_LLM_based_Modeling_Tasks/2024-07-08-Using_Grammar_Masking_to_Ensure_Syntactic_Validity_in_LLM_based_Modeling_Tasks.html#appendix",
    "href": "posts/Using_Grammar_Masking_to_Ensure_Syntactic_Validity_in_LLM_based_Modeling_Tasks/2024-07-08-Using_Grammar_Masking_to_Ensure_Syntactic_Validity_in_LLM_based_Modeling_Tasks.html#appendix",
    "title": "Using Grammar Masking to Ensure Syntactic Validity in LLM-based Modeling Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06146v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06146v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6526"
  },
  {
    "objectID": "posts/Anomaly_Detection_on_Unstable_Logs_with_GPT_Models/2024-06-11-Anomaly_Detection_on_Unstable_Logs_with_GPT_Models.html#appendix",
    "href": "posts/Anomaly_Detection_on_Unstable_Logs_with_GPT_Models/2024-06-11-Anomaly_Detection_on_Unstable_Logs_with_GPT_Models.html#appendix",
    "title": "Anomaly Detection on Unstable Logs with GPT Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07467v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07467v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11408"
  },
  {
    "objectID": "posts/Enhancing_LLM_Based_Human_Robot_Interaction_with_Nuances_for_Diversity_Awareness/2024-06-25-Enhancing_LLM_Based_Human_Robot_Interaction_with_Nuances_for_Diversity_Awareness.html#appendix",
    "href": "posts/Enhancing_LLM_Based_Human_Robot_Interaction_with_Nuances_for_Diversity_Awareness/2024-06-25-Enhancing_LLM_Based_Human_Robot_Interaction_with_Nuances_for_Diversity_Awareness.html#appendix",
    "title": "Enhancing LLM-Based Human-Robot Interaction with Nuances for Diversity Awareness",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17531v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17531v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7209"
  },
  {
    "objectID": "posts/AnnotatedTables_A_Large_Tabular_Dataset_with_Language_Model_Annotations/2024-06-24-AnnotatedTables_A_Large_Tabular_Dataset_with_Language_Model_Annotations.html#appendix",
    "href": "posts/AnnotatedTables_A_Large_Tabular_Dataset_with_Language_Model_Annotations/2024-06-24-AnnotatedTables_A_Large_Tabular_Dataset_with_Language_Model_Annotations.html#appendix",
    "title": "AnnotatedTables: A Large Tabular Dataset with Language Model Annotations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16349v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16349v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13468"
  },
  {
    "objectID": "posts/Serial_Position_Effects_of_Large_Language_Models/2024-06-23-Serial_Position_Effects_of_Large_Language_Models.html#appendix",
    "href": "posts/Serial_Position_Effects_of_Large_Language_Models/2024-06-23-Serial_Position_Effects_of_Large_Language_Models.html#appendix",
    "title": "Serial Position Effects of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.15981v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.15981v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10164"
  },
  {
    "objectID": "posts/TokenSHAP_Interpreting_Large_Language_Models_with_Monte_Carlo_Shapley_Value_Estimation/2024-07-14-TokenSHAP_Interpreting_Large_Language_Models_with_Monte_Carlo_Shapley_Value_Estimation.html#appendix",
    "href": "posts/TokenSHAP_Interpreting_Large_Language_Models_with_Monte_Carlo_Shapley_Value_Estimation/2024-07-14-TokenSHAP_Interpreting_Large_Language_Models_with_Monte_Carlo_Shapley_Value_Estimation.html#appendix",
    "title": "TokenSHAP: Interpreting Large Language Models with Monte Carlo Shapley Value Estimation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10114v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10114v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3919"
  },
  {
    "objectID": "posts/Attribute_or_Abstain_Large_Language_Models_as_Long_Document_Assistants/2024-07-10-Attribute_or_Abstain_Large_Language_Models_as_Long_Document_Assistants.html#appendix",
    "href": "posts/Attribute_or_Abstain_Large_Language_Models_as_Long_Document_Assistants/2024-07-10-Attribute_or_Abstain_Large_Language_Models_as_Long_Document_Assistants.html#appendix",
    "title": "Attribute or Abstain: Large Language Models as Long Document Assistants",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07799v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07799v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9325"
  },
  {
    "objectID": "posts/SOS!_Soft_Prompt_Attack_Against_Open_Source_Large_Language_Models/2024-07-03-SOS!_Soft_Prompt_Attack_Against_Open_Source_Large_Language_Models.html",
    "href": "posts/SOS!_Soft_Prompt_Attack_Against_Open_Source_Large_Language_Models/2024-07-03-SOS!_Soft_Prompt_Attack_Against_Open_Source_Large_Language_Models.html",
    "title": "SOS! Soft Prompt Attack Against Open-Source Large Language Models",
    "section": "",
    "text": "Summary: The paper presents a novel attack called SOS (Soft prompt attack against Open-Source LLMs) that targets open-source large language models (LLMs). SOS is designed to be computationally efficient and does not require clean data or modification of the model weights, ensuring the model’s utility remains intact. The attack addresses security issues in various scenarios, including backdoor attacks, jailbreak attacks, and prompt stealing attacks. The authors demonstrate the effectiveness of SOS across all evaluated targets and present a novel technique called the copyright token, which enables users to mark their copyrighted content and prevent models from using it.\nKey Terms:\nMajor Findings:"
  },
  {
    "objectID": "posts/SOS!_Soft_Prompt_Attack_Against_Open_Source_Large_Language_Models/2024-07-03-SOS!_Soft_Prompt_Attack_Against_Open_Source_Large_Language_Models.html#appendix",
    "href": "posts/SOS!_Soft_Prompt_Attack_Against_Open_Source_Large_Language_Models/2024-07-03-SOS!_Soft_Prompt_Attack_Against_Open_Source_Large_Language_Models.html#appendix",
    "title": "SOS! Soft Prompt Attack Against Open-Source Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03160v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03160v1\n\n\nTruncated\nTrue\n\n\nWord Count\n28326"
  },
  {
    "objectID": "posts/Incorporating_Large_Language_Models_into_Production_Systems_for_Enhanced_Task_Automation_and_Flexibility/2024-07-11-Incorporating_Large_Language_Models_into_Production_Systems_for_Enhanced_Task_Automation_and_Flexibility.html#appendix",
    "href": "posts/Incorporating_Large_Language_Models_into_Production_Systems_for_Enhanced_Task_Automation_and_Flexibility/2024-07-11-Incorporating_Large_Language_Models_into_Production_Systems_for_Enhanced_Task_Automation_and_Flexibility.html#appendix",
    "title": "Incorporating Large Language Models into Production Systems for Enhanced Task Automation and Flexibility",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08550v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08550v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8495"
  },
  {
    "objectID": "posts/Practical_Unlearning_for_Large_Language_Models/2024-07-14-Practical_Unlearning_for_Large_Language_Models.html#summary-1",
    "href": "posts/Practical_Unlearning_for_Large_Language_Models/2024-07-14-Practical_Unlearning_for_Large_Language_Models.html#summary-1",
    "title": "Practical Unlearning for Large Language Models",
    "section": "Summary:",
    "text": "Summary:\nThe paper proposes a novel framework called O3 for practical unlearning in large language models (LLMs). The O3 framework addresses the challenges of balancing unlearning effectiveness and model utility preservation in continuous scenarios without using any retained data. It includes an Out-Of-Distribution (OOD) detection module to assess the similarity between input data and unlearning data, and an Orthogonal Low-rank adapter (LoRA) for continuously unlearning requested data. The OOD detector is trained with a novel contrastive entropy loss and a local-global layer-aggregated scoring mechanism. The orthogonal LoRA achieves parameter disentanglement among continual unlearning requests. During inference, the O3 framework can smartly decide whether and to what extent to load the unlearning LoRA based on the OOD detector’s predictions. The O3 framework is computationally efficient and does not rely on any retained data."
  },
  {
    "objectID": "posts/Practical_Unlearning_for_Large_Language_Models/2024-07-14-Practical_Unlearning_for_Large_Language_Models.html#major-findings",
    "href": "posts/Practical_Unlearning_for_Large_Language_Models/2024-07-14-Practical_Unlearning_for_Large_Language_Models.html#major-findings",
    "title": "Practical Unlearning for Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe O3 framework consistently achieves the best trade-off between unlearning effectiveness and utility preservation, especially when facing continuous unlearning requests.\nThe O3 framework does not require any retained data, making it more computationally efficient than existing LLM unlearning methods.\nThe OOD detector in the O3 framework is trained with a novel contrastive entropy loss and a local-global layer-aggregated scoring mechanism, which allows it to achieve truly unsupervised OOD detection.\nThe orthogonal LoRA in the O3 framework enables parameter disentanglement among continual unlearning requests, ensuring that the unlearning effectiveness of different requests does not interfere with each other."
  },
  {
    "objectID": "posts/Practical_Unlearning_for_Large_Language_Models/2024-07-14-Practical_Unlearning_for_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/Practical_Unlearning_for_Large_Language_Models/2024-07-14-Practical_Unlearning_for_Large_Language_Models.html#analysis-and-critique",
    "title": "Practical Unlearning for Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe O3 framework is a promising approach for practical unlearning in LLMs. It addresses the challenges of balancing unlearning effectiveness and model utility preservation in continuous scenarios without using any retained data. The OOD detector and orthogonal LoRA are novel components that enable the O3 framework to achieve superior performance compared to existing LLM unlearning methods. However, the O3 framework has not been tested on a wide range of tasks and datasets, and its performance may vary depending on the specific task and dataset. Additionally, the O3 framework assumes that the unlearning data is available during the unlearning operation, which may not"
  },
  {
    "objectID": "posts/Practical_Unlearning_for_Large_Language_Models/2024-07-14-Practical_Unlearning_for_Large_Language_Models.html#appendix",
    "href": "posts/Practical_Unlearning_for_Large_Language_Models/2024-07-14-Practical_Unlearning_for_Large_Language_Models.html#appendix",
    "title": "Practical Unlearning for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10223v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10223v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13558"
  },
  {
    "objectID": "posts/HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs/2024-06-10-HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs.html",
    "href": "posts/HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs/2024-06-10-HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs.html",
    "title": "HOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs",
    "section": "",
    "text": "Summary:\nThe paper introduces a new method called HOLMES for multi-hop question answering (MHQA) using large language models (LLMs). The method involves transforming unstructured text into a hyper-relational knowledge graph (KG) using a query-derived schema, which is then used as input to the LLM. The proposed method significantly improves upon the state-of-the-art (SoTA) multi-hop QA method, achieving 18.7% and 20% improvements in exact match (EM) scores on the Hotpot dataset and 26% and 14.3% on the MuSiQue dataset for GPT-3.5 and GPT-4, respectively. Additionally, the method uses up to 67% fewer tokens to represent query-relevant information than the current SoTA method and up to 60% fewer tokens compared to the original supporting documents.\nMajor Findings:\nAnalysis and Critique:\nThe proposed method, HOLMES, presents a significant improvement over the SoTA multi-hop QA method. The use of a hyper-relational KG as input to the LLM allows for a more efficient and effective representation of query-relevant information. The method’s ability to use fewer tokens to represent this information is particularly noteworthy, as it can lead to reduced computational costs and improved performance.\nHowever, there are some potential limitations and areas for further research. For example, the method’s reliance on a query-"
  },
  {
    "objectID": "posts/HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs/2024-06-10-HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs.html#appendix",
    "href": "posts/HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs/2024-06-10-HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs.html#appendix",
    "title": "HOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06027v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06027v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20470"
  },
  {
    "objectID": "posts/FVEL_Interactive_Formal_Verification_Environment_with_Large_Language_Models_via_Theorem_Proving/2024-06-20-FVEL_Interactive_Formal_Verification_Environment_with_Large_Language_Models_via_Theorem_Proving.html#appendix",
    "href": "posts/FVEL_Interactive_Formal_Verification_Environment_with_Large_Language_Models_via_Theorem_Proving/2024-06-20-FVEL_Interactive_Formal_Verification_Environment_with_Large_Language_Models_via_Theorem_Proving.html#appendix",
    "title": "FVEL: Interactive Formal Verification Environment with Large Language Models via Theorem Proving",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14408v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14408v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11049"
  },
  {
    "objectID": "posts/UniCoder_Scaling_Code_Large_Language_Model_via_Universal_Code/2024-06-24-UniCoder_Scaling_Code_Large_Language_Model_via_Universal_Code.html#appendix",
    "href": "posts/UniCoder_Scaling_Code_Large_Language_Model_via_Universal_Code/2024-06-24-UniCoder_Scaling_Code_Large_Language_Model_via_Universal_Code.html#appendix",
    "title": "UniCoder: Scaling Code Large Language Model via Universal Code",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16441v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16441v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3736"
  },
  {
    "objectID": "posts/From_Artificial_Needles_to_Real_Haystacks_Improving_Retrieval_Capabilities_in_LLMs_by_Finetuning_on_Synthetic_Data/2024-06-27-From_Artificial_Needles_to_Real_Haystacks_Improving_Retrieval_Capabilities_in_LLMs_by_Finetuning_on_Synthetic_Data.html",
    "href": "posts/From_Artificial_Needles_to_Real_Haystacks_Improving_Retrieval_Capabilities_in_LLMs_by_Finetuning_on_Synthetic_Data/2024-06-27-From_Artificial_Needles_to_Real_Haystacks_Improving_Retrieval_Capabilities_in_LLMs_by_Finetuning_on_Synthetic_Data.html",
    "title": "From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data",
    "section": "",
    "text": "Summary:\nThe paper “From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data” by Zheyang Xiong, Vasilis Papageorgiou, Kangwook Lee, and Dimitris Papailiopoulos from the University of Wisconsin-Madison proposes a finetuning approach to address the limitations of Large Language Models (LLMs) in accurately retrieving information and maintaining reasoning capabilities when processing long-context inputs. The authors propose a finetuning approach utilizing a carefully designed synthetic dataset comprising numerical key-value retrieval tasks. The experiments conducted on models like GPT-3.5 Turbo and Mistral 7B demonstrate that finetuning LLMs on this dataset significantly improves LLMs’ information retrieval and reasoning capabilities in longer-context settings. The study highlights the potential of finetuning on synthetic data for improving the performance of LLMs on longer-context tasks.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an innovative approach to improving the performance of LLMs on longer-context tasks by finetuning on synthetic data. The authors provide a well-structured and coherent summary of their findings, highlighting the potential of their proposed method. However, the paper does not discuss the limitations of the proposed approach or potential biases that may have been introduced during the finetuning process. Additionally, the paper does not provide a comparison with other finetuning methods or discuss the generalizability of the proposed approach to other LLMs. Further research is needed to address these limitations and validate the proposed approach"
  },
  {
    "objectID": "posts/From_Artificial_Needles_to_Real_Haystacks_Improving_Retrieval_Capabilities_in_LLMs_by_Finetuning_on_Synthetic_Data/2024-06-27-From_Artificial_Needles_to_Real_Haystacks_Improving_Retrieval_Capabilities_in_LLMs_by_Finetuning_on_Synthetic_Data.html#appendix",
    "href": "posts/From_Artificial_Needles_to_Real_Haystacks_Improving_Retrieval_Capabilities_in_LLMs_by_Finetuning_on_Synthetic_Data/2024-06-27-From_Artificial_Needles_to_Real_Haystacks_Improving_Retrieval_Capabilities_in_LLMs_by_Finetuning_on_Synthetic_Data.html#appendix",
    "title": "From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19292v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19292v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11448"
  },
  {
    "objectID": "posts/Augmenting_Query_and_Passage_for_Retrieval_Augmented_Generation_using_LLMs_for_Open_Domain_Question_Answering/2024-06-20-Augmenting_Query_and_Passage_for_Retrieval_Augmented_Generation_using_LLMs_for_Open_Domain_Question_Answering.html#appendix",
    "href": "posts/Augmenting_Query_and_Passage_for_Retrieval_Augmented_Generation_using_LLMs_for_Open_Domain_Question_Answering/2024-06-20-Augmenting_Query_and_Passage_for_Retrieval_Augmented_Generation_using_LLMs_for_Open_Domain_Question_Answering.html#appendix",
    "title": "Augmenting Query and Passage for Retrieval-Augmented Generation using LLMs for Open-Domain Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14277v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14277v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6421"
  },
  {
    "objectID": "posts/AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models/2024-06-24-AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models.html#summary",
    "href": "posts/AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models/2024-06-24-AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models.html#summary",
    "title": "AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models",
    "section": "Summary:",
    "text": "Summary:\n\nThe paper introduces a unified framework, AutoDetect, to automatically expose weaknesses in LLMs across various tasks.\nThe framework is inspired by the educational assessment process and consists of three LLM-powered agents: Examiner, Questioner, and Assessor.\nAutoDetect demonstrates significant success in uncovering flaws, with an identification success rate exceeding 30% in prominent models such as ChatGPT and Claude.\nThe identified weaknesses can guide specific model improvements, proving more effective than untargeted data augmentation methods like Self-Instruct.\nThe approach has led to substantial enhancements in popular LLMs, including the Llama series and Mistral-7b, boosting their performance by over 10% across several benchmarks."
  },
  {
    "objectID": "posts/AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models/2024-06-24-AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models.html#major-findings",
    "href": "posts/AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models/2024-06-24-AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models.html#major-findings",
    "title": "AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nAutoDetect is a pioneering unified framework that aims to systematically and automatically expose potential weaknesses within LLMs across a variety of tasks.\nThe framework demonstrates exceptional adaptability and effectiveness, with a success rate of over 50% in uncovering deficiencies across multiple models and tasks.\nAutoDetect facilitates significant model improvements. Leveraging the data derived from the weakness detection process, we can effectively enhance model performance, yielding over 10% improvements on several tasks."
  },
  {
    "objectID": "posts/AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models/2024-06-24-AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models/2024-06-24-AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models.html#analysis-and-critique",
    "title": "AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper provides a comprehensive and well-structured approach to identifying weaknesses in LLMs.\nThe use of three specialized roles implemented by LLM-based agents allows for a thorough and tailored testing framework.\nThe iterative search process enables the adjustment of question difficulty for the target model, effectively identifying weaknesses.\nHowever, the paper does not discuss the potential limitations or biases of the framework, which could be a topic for future research.\nAdditionally, the paper does not provide a detailed comparison with other existing methods for weakness detection in LLMs.\nThe paper also does not discuss the potential scalability issues or computational costs associated with the framework.\nFinally, the paper does not provide a detailed analysis of the impact of the identified weaknesses on the overall performance of"
  },
  {
    "objectID": "posts/AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models/2024-06-24-AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models.html#appendix",
    "href": "posts/AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models/2024-06-24-AutoDetect_Towards_a_Unified_Framework_for_Automated_Weakness_Detection_in_Large_Language_Models.html#appendix",
    "title": "AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16714v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16714v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5957"
  },
  {
    "objectID": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#major-findings",
    "href": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#major-findings",
    "title": "Characterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People",
    "section": "Major Findings",
    "text": "Major Findings\n\nThe proposed method enables the characterization of conversational tones and their taxonomies in any target human population as well as LLMs, without relying on predefined taxonomies or constrained sets of stimuli.\nThe study addresses the challenges of biased apriori taxonomy and biased stimulus set in existing research on conversational tones.\nThe paper presents an additional experiment where humans and GPT-4 annotated all sentences with all tones, resulting in an interpretable geometric representation of relations between conversational tones in humans and GPT-4."
  },
  {
    "objectID": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#analysis-and-critique",
    "href": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#analysis-and-critique",
    "title": "Characterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\nThe paper presents a novel and promising approach to characterize conversational tones and their taxonomies in humans and LLMs. The proposed method addresses the limitations"
  },
  {
    "objectID": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#appendix",
    "href": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#appendix",
    "title": "Characterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04278v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04278v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14313"
  },
  {
    "objectID": "posts/Financial_Statement_Analysis_with_Large_Language_Models/2024-07-25-Financial_Statement_Analysis_with_Large_Language_Models.html",
    "href": "posts/Financial_Statement_Analysis_with_Large_Language_Models/2024-07-25-Financial_Statement_Analysis_with_Large_Language_Models.html",
    "title": "Financial Statement Analysis with Large Language Models",
    "section": "",
    "text": "Summary:\nThis paper investigates the ability of a large language model (LLM), specifically GPT4, to perform financial statement analysis and predict the direction of future earnings. The study compares the performance of GPT4 to that of financial analysts and other benchmarks, such as logistic regression and a state-of-the-art machine learning model. The results show that GPT4 outperforms financial analysts and achieves performance on par with the state-of-the-art machine learning model. The study also finds that GPT4’s performance is not due to its memory, but rather its ability to generate useful narrative insights about a company’s future performance. Additionally, trading strategies based on GPT’s predictions yield higher Sharpe ratios and alphas than strategies based on other models.\nMajor Findings:\nAnalysis and Critique:\nThe study provides a comprehensive analysis of the ability of LLMs to perform financial statement analysis and predict the direction of future earnings. The results are promising, showing that GPT4 can outperform financial analysts and achieve performance on par with state-of-the-art machine learning models. However, the study does not address the potential limitations of LLMs, such as their inability to understand complex financial concepts or their reliance on large amounts of data. Additionally, the study does not address the potential biases or errors that may be introduced by the use of LLMs in financial analysis. Further research is needed to address these limitations and to fully understand the potential of LLMs in financial analysis."
  },
  {
    "objectID": "posts/Financial_Statement_Analysis_with_Large_Language_Models/2024-07-25-Financial_Statement_Analysis_with_Large_Language_Models.html#appendix",
    "href": "posts/Financial_Statement_Analysis_with_Large_Language_Models/2024-07-25-Financial_Statement_Analysis_with_Large_Language_Models.html#appendix",
    "title": "Financial Statement Analysis with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17866v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17866v1\n\n\nTruncated\nFalse\n\n\nWord Count\n19560"
  },
  {
    "objectID": "posts/Cutting_Through_the_Clutter_The_Potential_of_LLMs_for_Efficient_Filtration_in_Systematic_Literature_Reviews/2024-07-15-Cutting_Through_the_Clutter_The_Potential_of_LLMs_for_Efficient_Filtration_in_Systematic_Literature_Reviews.html#appendix",
    "href": "posts/Cutting_Through_the_Clutter_The_Potential_of_LLMs_for_Efficient_Filtration_in_Systematic_Literature_Reviews/2024-07-15-Cutting_Through_the_Clutter_The_Potential_of_LLMs_for_Efficient_Filtration_in_Systematic_Literature_Reviews.html#appendix",
    "title": "Cutting Through the Clutter: The Potential of LLMs for Efficient Filtration in Systematic Literature Reviews",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10652v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10652v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5541"
  },
  {
    "objectID": "posts/Leveraging_LLMs_to_Predict_Affective_States_via_Smartphone_Sensor_Features/2024-07-11-Leveraging_LLMs_to_Predict_Affective_States_via_Smartphone_Sensor_Features.html#appendix",
    "href": "posts/Leveraging_LLMs_to_Predict_Affective_States_via_Smartphone_Sensor_Features/2024-07-11-Leveraging_LLMs_to_Predict_Affective_States_via_Smartphone_Sensor_Features.html#appendix",
    "title": "Leveraging LLMs to Predict Affective States via Smartphone Sensor Features",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08240v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08240v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5214"
  },
  {
    "objectID": "posts/Arabic_Automatic_Story_Generation_with_Large_Language_Models/2024-07-10-Arabic_Automatic_Story_Generation_with_Large_Language_Models.html#appendix",
    "href": "posts/Arabic_Automatic_Story_Generation_with_Large_Language_Models/2024-07-10-Arabic_Automatic_Story_Generation_with_Large_Language_Models.html#appendix",
    "title": "Arabic Automatic Story Generation with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07551v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07551v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6596"
  },
  {
    "objectID": "posts/Hecaton_Training_and_Finetuning_Large_Language_Models_with_Scalable_Chiplet_Systems/2024-07-08-Hecaton_Training_and_Finetuning_Large_Language_Models_with_Scalable_Chiplet_Systems.html#appendix",
    "href": "posts/Hecaton_Training_and_Finetuning_Large_Language_Models_with_Scalable_Chiplet_Systems/2024-07-08-Hecaton_Training_and_Finetuning_Large_Language_Models_with_Scalable_Chiplet_Systems.html#appendix",
    "title": "Hecaton: Training and Finetuning Large Language Models with Scalable Chiplet Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05784v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05784v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9383"
  },
  {
    "objectID": "posts/KGym_A_Platform_and_Dataset_to_Benchmark_Large_Language_Models_on_Linux_Kernel_Crash_Resolution/2024-07-02-KGym_A_Platform_and_Dataset_to_Benchmark_Large_Language_Models_on_Linux_Kernel_Crash_Resolution.html#appendix",
    "href": "posts/KGym_A_Platform_and_Dataset_to_Benchmark_Large_Language_Models_on_Linux_Kernel_Crash_Resolution/2024-07-02-KGym_A_Platform_and_Dataset_to_Benchmark_Large_Language_Models_on_Linux_Kernel_Crash_Resolution.html#appendix",
    "title": "KGym: A Platform and Dataset to Benchmark Large Language Models on Linux Kernel Crash Resolution",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02680v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02680v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3950"
  },
  {
    "objectID": "posts/ELCoRec_Enhance_Language_Understanding_with_Co_Propagation_of_Numerical_and_Categorical_Features_for_Recommendation/2024-06-27-ELCoRec_Enhance_Language_Understanding_with_Co_Propagation_of_Numerical_and_Categorical_Features_for_Recommendation.html#appendix",
    "href": "posts/ELCoRec_Enhance_Language_Understanding_with_Co_Propagation_of_Numerical_and_Categorical_Features_for_Recommendation/2024-06-27-ELCoRec_Enhance_Language_Understanding_with_Co_Propagation_of_Numerical_and_Categorical_Features_for_Recommendation.html#appendix",
    "title": "ELCoRec: Enhance Language Understanding with Co-Propagation of Numerical and Categorical Features for Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18825v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18825v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9136"
  },
  {
    "objectID": "posts/Walking_in_Others_Shoes_How_Perspective_Taking_Guides_Large_Language_Models_in_Reducing_Toxicity_and_Bias/2024-07-22-Walking_in_Others_Shoes_How_Perspective_Taking_Guides_Large_Language_Models_in_Reducing_Toxicity_and_Bias.html#major-findings",
    "href": "posts/Walking_in_Others_Shoes_How_Perspective_Taking_Guides_Large_Language_Models_in_Reducing_Toxicity_and_Bias/2024-07-22-Walking_in_Others_Shoes_How_Perspective_Taking_Guides_Large_Language_Models_in_Reducing_Toxicity_and_Bias.html#major-findings",
    "title": "Walking in Others’ Shoes: How Perspective-Taking Guides Large Language Models in Reducing Toxicity and Bias",
    "section": "Major Findings",
    "text": "Major Findings\n\nThe proposed perspective-taking prompting (PeT) strategy can significantly reduce toxicity (up to 30%) and bias (up to 20%) in LLMs’ responses.\nPeT outperforms existing prompting methods that depend on external tool feedback and fail to simultaneously lessen toxicity and bias.\nPeT is a superior method for producing less harmful responses, as demonstrated by evaluations on two commercial LLMs (ChatGPT and GLM) and three open-source LLMs."
  },
  {
    "objectID": "posts/Walking_in_Others_Shoes_How_Perspective_Taking_Guides_Large_Language_Models_in_Reducing_Toxicity_and_Bias/2024-07-22-Walking_in_Others_Shoes_How_Perspective_Taking_Guides_Large_Language_Models_in_Reducing_Toxicity_and_Bias.html#analysis-and-critique",
    "href": "posts/Walking_in_Others_Shoes_How_Perspective_Taking_Guides_Large_Language_Models_in_Reducing_Toxicity_and_Bias/2024-07-22-Walking_in_Others_Shoes_How_Perspective_Taking_Guides_Large_Language_Models_in_Reducing_Toxicity_and_Bias.html#analysis-and-critique",
    "title": "Walking in Others’ Shoes: How Perspective-Taking Guides Large Language Models in Reducing Toxicity and Bias",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\n\nThe paper does not provide a detailed comparison of the proposed method with other existing methods for reducing toxicity and bias in LLMs.\nThe paper does not discuss the potential limitations or drawbacks of the proposed method, such as its applicability to different types of LLMs or the computational resources required for its implementation.\nThe paper does not provide a clear explanation of how the perspective-taking prompting strategy is implemented in practice, making it difficult to replicate the results.\nThe paper does not discuss the potential ethical implications of using LLMs to generate less harmful responses, such as the potential for biased or discriminatory outputs.\nThe paper does not provide a clear explanation of how the proposed method can be integrated into existing LLM architectures or training pipelines.\n\nOverall, the paper presents an interesting and promising approach for reducing toxicity and bias in LLMs. However, more detailed comparisons with existing methods, a discussion of potential limitations and drawbacks, and a clear explanation of the implementation details are needed to fully evaluate the proposed method. Additionally, a discussion of the ethical implications and integration with existing LLM architectures would be"
  },
  {
    "objectID": "posts/Walking_in_Others_Shoes_How_Perspective_Taking_Guides_Large_Language_Models_in_Reducing_Toxicity_and_Bias/2024-07-22-Walking_in_Others_Shoes_How_Perspective_Taking_Guides_Large_Language_Models_in_Reducing_Toxicity_and_Bias.html#appendix",
    "href": "posts/Walking_in_Others_Shoes_How_Perspective_Taking_Guides_Large_Language_Models_in_Reducing_Toxicity_and_Bias/2024-07-22-Walking_in_Others_Shoes_How_Perspective_Taking_Guides_Large_Language_Models_in_Reducing_Toxicity_and_Bias.html#appendix",
    "title": "Walking in Others’ Shoes: How Perspective-Taking Guides Large Language Models in Reducing Toxicity and Bias",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.15366v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.15366v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14332"
  },
  {
    "objectID": "posts/StuGPTViz_A_Visual_Analytics_Approach_to_Understand_Student_ChatGPT_Interactions/2024-07-17-StuGPTViz_A_Visual_Analytics_Approach_to_Understand_Student_ChatGPT_Interactions.html#appendix",
    "href": "posts/StuGPTViz_A_Visual_Analytics_Approach_to_Understand_Student_ChatGPT_Interactions/2024-07-17-StuGPTViz_A_Visual_Analytics_Approach_to_Understand_Student_ChatGPT_Interactions.html#appendix",
    "title": "StuGPTViz: A Visual Analytics Approach to Understand Student-ChatGPT Interactions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.12423v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.12423v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12718"
  },
  {
    "objectID": "posts/Finding_Blind_Spots_in_Evaluator_LLMs_with_Interpretable_Checklists/2024-06-19-Finding_Blind_Spots_in_Evaluator_LLMs_with_Interpretable_Checklists.html#appendix",
    "href": "posts/Finding_Blind_Spots_in_Evaluator_LLMs_with_Interpretable_Checklists/2024-06-19-Finding_Blind_Spots_in_Evaluator_LLMs_with_Interpretable_Checklists.html#appendix",
    "title": "Finding Blind Spots in Evaluator LLMs with Interpretable Checklists",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13439v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13439v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7140"
  },
  {
    "objectID": "posts/Soley_Identification_and_Automated_Detection_of_Logic_Vulnerabilities_in_Ethereum_Smart_Contracts_Using_Large_Language_Models/2024-06-24-Soley_Identification_and_Automated_Detection_of_Logic_Vulnerabilities_in_Ethereum_Smart_Contracts_Using_Large_Language_Models.html#appendix",
    "href": "posts/Soley_Identification_and_Automated_Detection_of_Logic_Vulnerabilities_in_Ethereum_Smart_Contracts_Using_Large_Language_Models/2024-06-24-Soley_Identification_and_Automated_Detection_of_Logic_Vulnerabilities_in_Ethereum_Smart_Contracts_Using_Large_Language_Models.html#appendix",
    "title": "Soley: Identification and Automated Detection of Logic Vulnerabilities in Ethereum Smart Contracts Using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16244v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16244v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13712"
  },
  {
    "objectID": "posts/Inducing_Group_Fairness_in_LLM_Based_Decisions/2024-06-24-Inducing_Group_Fairness_in_LLM_Based_Decisions.html#appendix",
    "href": "posts/Inducing_Group_Fairness_in_LLM_Based_Decisions/2024-06-24-Inducing_Group_Fairness_in_LLM_Based_Decisions.html#appendix",
    "title": "Inducing Group Fairness in LLM-Based Decisions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16738v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16738v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5964"
  },
  {
    "objectID": "posts/African_or_European_Swallow_Benchmarking_Large_Vision_Language_Models_for_Fine_Grained_Object_Classification/2024-06-20-African_or_European_Swallow_Benchmarking_Large_Vision_Language_Models_for_Fine_Grained_Object_Classification.html#appendix",
    "href": "posts/African_or_European_Swallow_Benchmarking_Large_Vision_Language_Models_for_Fine_Grained_Object_Classification/2024-06-20-African_or_European_Swallow_Benchmarking_Large_Vision_Language_Models_for_Fine_Grained_Object_Classification.html#appendix",
    "title": "African or European Swallow? Benchmarking Large Vision-Language Models for Fine-Grained Object Classification",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14496v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14496v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8786"
  },
  {
    "objectID": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#major-findings",
    "href": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#major-findings",
    "title": "Solution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe team proposes a new instruction-tuned vision-language model with two novel ideas: grounding visual cues in the text modality and utilizing an object detection algorithm to capture complex diagrammatic visual patterns.\nThe team achieves a 27.11 WOSA score on the challenge split and qualitatively validates the effectiveness of their proposed approach.\nThe team utilizes the Segmentation Anything Model (SAM) algorithm to capture the complex visual features and uses this information as input for the LLM."
  },
  {
    "objectID": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#analysis-and-critique",
    "href": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#analysis-and-critique",
    "title": "Solution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper does not provide a detailed analysis of the performance of the proposed method compared to other state-of-the-art methods.\nThe paper does not discuss the limitations of the proposed method or any potential biases that were apparent while reviewing the text.\nThe paper does not discuss any methodological issues, conflicting evidence, or areas that require further research or clarification.\nThe paper does not provide a detailed analysis of the performance of the proposed method on different types of puzzles.\nThe paper does not discuss the generalizability of the proposed method to other types of multimodal reasoning tasks."
  },
  {
    "objectID": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#appendix",
    "href": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#appendix",
    "title": "Solution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05963v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05963v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3407"
  },
  {
    "objectID": "posts/Preference_Tuning_For_Toxicity_Mitigation_Generalizes_Across_Languages/2024-06-23-Preference_Tuning_For_Toxicity_Mitigation_Generalizes_Across_Languages.html#appendix",
    "href": "posts/Preference_Tuning_For_Toxicity_Mitigation_Generalizes_Across_Languages/2024-06-23-Preference_Tuning_For_Toxicity_Mitigation_Generalizes_Across_Languages.html#appendix",
    "title": "Preference Tuning For Toxicity Mitigation Generalizes Across Languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16235v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16235v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8475"
  },
  {
    "objectID": "posts/Translating_Across_Cultures_LLMs_for_Intralingual_Cultural_Adaptation/2024-06-20-Translating_Across_Cultures_LLMs_for_Intralingual_Cultural_Adaptation.html#appendix",
    "href": "posts/Translating_Across_Cultures_LLMs_for_Intralingual_Cultural_Adaptation/2024-06-20-Translating_Across_Cultures_LLMs_for_Intralingual_Cultural_Adaptation.html#appendix",
    "title": "Translating Across Cultures: LLMs for Intralingual Cultural Adaptation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14504v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14504v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7296"
  },
  {
    "objectID": "posts/Symbolic_Learning_Enables_Self_Evolving_Agents/2024-06-26-Symbolic_Learning_Enables_Self_Evolving_Agents.html#appendix",
    "href": "posts/Symbolic_Learning_Enables_Self_Evolving_Agents/2024-06-26-Symbolic_Learning_Enables_Self_Evolving_Agents.html#appendix",
    "title": "Symbolic Learning Enables Self-Evolving Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18532v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18532v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6153"
  },
  {
    "objectID": "posts/Synthetic_Multimodal_Question_Generation/2024-07-02-Synthetic_Multimodal_Question_Generation.html#summary",
    "href": "posts/Synthetic_Multimodal_Question_Generation/2024-07-02-Synthetic_Multimodal_Question_Generation.html#summary",
    "title": "Synthetic Multimodal Question Generation",
    "section": "Summary:",
    "text": "Summary:\nThe paper introduces a method for Synthetic Multimodal Question Generation (SMMQG), a framework that leverages the interplay between a retriever, a large language model (LLM), and a large multimodal model (LMM) to generate question-answer pairs directly from multimodal documents. SMMQG enables fine-grained control over the styles and modalities of questions, and is capable of producing both unimodal and cross-modal questions. The authors use SMMQG to generate an MMRAG dataset of 1024 questions over Wikipedia documents and evaluate state-of-the-art models using it, revealing insights into model performance that are attainable only through style- and modality-specific evaluation data. A human study is conducted to measure the quality of the synthetic data, which is found to be on par with the quality of the crowdsourced benchmark MMQA."
  },
  {
    "objectID": "posts/Synthetic_Multimodal_Question_Generation/2024-07-02-Synthetic_Multimodal_Question_Generation.html#major-findings",
    "href": "posts/Synthetic_Multimodal_Question_Generation/2024-07-02-Synthetic_Multimodal_Question_Generation.html#major-findings",
    "title": "Synthetic Multimodal Question Generation",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nSMMQG is a powerful approach to question-answering over multimodal documents, enabling fine-grained control over the styles and modalities of questions.\nThe quality of the synthetic data generated by SMMQG is on par with the quality of the crowdsourced benchmark MMQA, as demonstrated by a human study.\nEvaluation results using the SMMQG dataset strongly concur with those obtained using MMQA, demonstrating that the synthetic dataset can be used in place of MMQA for model selection."
  },
  {
    "objectID": "posts/Synthetic_Multimodal_Question_Generation/2024-07-02-Synthetic_Multimodal_Question_Generation.html#analysis-and-critique",
    "href": "posts/Synthetic_Multimodal_Question_Generation/2024-07-02-Synthetic_Multimodal_Question_Generation.html#analysis-and-critique",
    "title": "Synthetic Multimodal Question Generation",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a novel and promising approach to generating synthetic multimodal question-answer pairs, addressing a key challenge in evaluating MMRAG systems. The use of a large language model and a large multimodal model in conjunction with a retriever allows for the generation of diverse and high-quality questions and answers. The evaluation of state-of-the-art models using the SMMQG dataset provides valuable insights into model performance, and the human study confirms the quality of the synthetic data.\nHowever, the paper does not discuss potential limitations or biases in the SMMQG framework, nor does it address the issue of generalizability to"
  },
  {
    "objectID": "posts/Synthetic_Multimodal_Question_Generation/2024-07-02-Synthetic_Multimodal_Question_Generation.html#appendix",
    "href": "posts/Synthetic_Multimodal_Question_Generation/2024-07-02-Synthetic_Multimodal_Question_Generation.html#appendix",
    "title": "Synthetic Multimodal Question Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02233v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02233v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13736"
  },
  {
    "objectID": "posts/C2P_Featuring_Large_Language_Models_with_Causal_Reasoning/2024-07-25-C2P_Featuring_Large_Language_Models_with_Causal_Reasoning.html#appendix",
    "href": "posts/C2P_Featuring_Large_Language_Models_with_Causal_Reasoning/2024-07-25-C2P_Featuring_Large_Language_Models_with_Causal_Reasoning.html#appendix",
    "title": "C2P: Featuring Large Language Models with Causal Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.18069v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.18069v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10834"
  },
  {
    "objectID": "posts/Generalization_Enhanced_Code_Vulnerability_Detection_via_Multi_Task_Instruction_Fine_Tuning/2024-06-06-Generalization_Enhanced_Code_Vulnerability_Detection_via_Multi_Task_Instruction_Fine_Tuning.html#appendix",
    "href": "posts/Generalization_Enhanced_Code_Vulnerability_Detection_via_Multi_Task_Instruction_Fine_Tuning/2024-06-06-Generalization_Enhanced_Code_Vulnerability_Detection_via_Multi_Task_Instruction_Fine_Tuning.html#appendix",
    "title": "Generalization-Enhanced Code Vulnerability Detection via Multi-Task Instruction Fine-Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03718v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03718v1\n\n\nTruncated\nFalse\n\n\nWord Count\n22567"
  },
  {
    "objectID": "posts/LiveBench_A_Challenging_Contamination_Free_LLM_Benchmark/2024-06-27-LiveBench_A_Challenging_Contamination_Free_LLM_Benchmark.html",
    "href": "posts/LiveBench_A_Challenging_Contamination_Free_LLM_Benchmark/2024-06-27-LiveBench_A_Challenging_Contamination_Free_LLM_Benchmark.html",
    "title": "LiveBench: A Challenging, Contamination-Free LLM Benchmark",
    "section": "",
    "text": "Summary: The paper introduces LiveBench, a new benchmark for large language models (LLMs) that aims to address the issues of test set contamination and the limitations of LLM judging and human crowdsourcing. LiveBench features frequently-updated questions from recent information sources, automatic scoring based on objective ground-truth values, and a wide variety of challenging tasks across six categories: coding, data, instruction, language, math, and reasoning. The benchmark includes questions based on recent math competitions, arXiv papers, news articles, and datasets, as well as harder, contamination-free versions of tasks from previous benchmarks. The study compares 49 LLMs on LiveBench, with claude-3-5-sonnet-20240620 performing the best across all categories and overall.\nMajor Findings: 1. LiveBench is a new benchmark for LL"
  },
  {
    "objectID": "posts/LiveBench_A_Challenging_Contamination_Free_LLM_Benchmark/2024-06-27-LiveBench_A_Challenging_Contamination_Free_LLM_Benchmark.html#appendix",
    "href": "posts/LiveBench_A_Challenging_Contamination_Free_LLM_Benchmark/2024-06-27-LiveBench_A_Challenging_Contamination_Free_LLM_Benchmark.html#appendix",
    "title": "LiveBench: A Challenging, Contamination-Free LLM Benchmark",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19314v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19314v1\n\n\nTruncated\nTrue\n\n\nWord Count\n27632"
  },
  {
    "objectID": "posts/From_Sands_to_Mansions_Enabling_Automatic_Full_Life_Cycle_Cyberattack_Construction_with_LLM/2024-07-24-From_Sands_to_Mansions_Enabling_Automatic_Full_Life_Cycle_Cyberattack_Construction_with_LLM.html#appendix",
    "href": "posts/From_Sands_to_Mansions_Enabling_Automatic_Full_Life_Cycle_Cyberattack_Construction_with_LLM/2024-07-24-From_Sands_to_Mansions_Enabling_Automatic_Full_Life_Cycle_Cyberattack_Construction_with_LLM.html#appendix",
    "title": "From Sands to Mansions: Enabling Automatic Full-Life-Cycle Cyberattack Construction with LLM",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16928v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16928v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12045"
  },
  {
    "objectID": "posts/Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text/2024-06-10-Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text.html",
    "href": "posts/Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text/2024-06-10-Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text.html",
    "title": "Synth-SBDH: A Synthetic Dataset of Social and Behavioral Determinants of Health for Clinical Text",
    "section": "",
    "text": "Summary:\nThe study introduces Synth-SBDH, a novel synthetic dataset with detailed SBDH annotations, encompassing status, temporal information, and rationale across 15 SBDH categories. The dataset is the largest publicly available SBDH dataset and is generated and annotated by an LLM (GPT-4). The utility of Synth-SBDH is showcased on three tasks using real-world clinical datasets from two distinct hospital settings, highlighting its versatility, generalizability, and distillation capabilities. Models trained on Synth-SBDH consistently outperform counterparts with no Synth-SBDH training, achieving up to 62.5% macro-F improvements. Synth-SBDH proves effective for rare SBDH categories and under-resource constraints. Human evaluation demonstrates a Human-LLM alignment of 71.06% and uncovers areas for future refinements.\nMajor Findings:\nAnalysis and Critique:\nThe study presents a novel synthetic dataset, Synth-SBDH, which addresses the limitations of existing SBDH datasets and leverages the potential of LLMs in healthcare. The dataset is comprehensive, covering a wide range of SBDH categories and providing detailed"
  },
  {
    "objectID": "posts/Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text/2024-06-10-Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text.html#appendix",
    "href": "posts/Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text/2024-06-10-Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text.html#appendix",
    "title": "Synth-SBDH: A Synthetic Dataset of Social and Behavioral Determinants of Health for Clinical Text",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06056v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06056v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20269"
  },
  {
    "objectID": "posts/Distilling_System_2_into_System_1/2024-07-08-Distilling_System_2_into_System_1.html#appendix",
    "href": "posts/Distilling_System_2_into_System_1/2024-07-08-Distilling_System_2_into_System_1.html#appendix",
    "title": "Distilling System 2 into System 1",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06023v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06023v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8154"
  },
  {
    "objectID": "posts/PITCH_Productivity_and_Mental_Well_being_Coaching_through_Daily_Conversational_Interaction/2024-06-11-PITCH_Productivity_and_Mental_Well_being_Coaching_through_Daily_Conversational_Interaction.html#appendix",
    "href": "posts/PITCH_Productivity_and_Mental_Well_being_Coaching_through_Daily_Conversational_Interaction/2024-06-11-PITCH_Productivity_and_Mental_Well_being_Coaching_through_Daily_Conversational_Interaction.html#appendix",
    "title": "PITCH: Productivity and Mental Well-being Coaching through Daily Conversational Interaction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07485v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07485v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3364"
  },
  {
    "objectID": "posts/GRASP_A_Grid_Based_Benchmark_for_Evaluating_Commonsense_Spatial_Reasoning/2024-07-02-GRASP_A_Grid_Based_Benchmark_for_Evaluating_Commonsense_Spatial_Reasoning.html#appendix",
    "href": "posts/GRASP_A_Grid_Based_Benchmark_for_Evaluating_Commonsense_Spatial_Reasoning/2024-07-02-GRASP_A_Grid_Based_Benchmark_for_Evaluating_Commonsense_Spatial_Reasoning.html#appendix",
    "title": "GRASP: A Grid-Based Benchmark for Evaluating Commonsense Spatial Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01892v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01892v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11185"
  },
  {
    "objectID": "posts/Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations/2024-07-03-Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations.html",
    "href": "posts/Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations/2024-07-03-Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations.html",
    "title": "Social Bias Evaluation for Large Language Models Requires Prompt Variations",
    "section": "",
    "text": "Summary:\nThis paper investigates the sensitivity of 12 large language models (LLMs) to prompt variations in evaluating task performance and social bias, focusing on a question-answering dataset, BBQ. The study categorizes three prompt variation factors: 1) task instruction and prompt for task recognition, 2) few-shot examples for task performance improvement, and 3) debias-prompt for bias mitigation. The experimental results reveal that LLMs are highly sensitive to prompts in bias evaluation, with the ranking of LLMs and debiasing effectiveness fluctuating when comparing models for task performance and bias scores. The study also shows that LLMs have tradeoffs among task performance and social bias caused by the prompts, and the ambiguity of instances contributes to the sensitivity in advanced LLMs.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive analysis of the sensitivity of LLMs to prompt variations in evaluating task performance and social bias. However, the study is limited to a single question-answering dataset, BBQ, and does not explore other types of datasets or tasks. Additionally, the paper does not discuss the potential impact of prompt variations on the fairness and ethical considerations of LLMs. Further research is needed to investigate the generalizability of the findings to other datasets and tasks and to explore the ethical implications of prompt variations in LLMs."
  },
  {
    "objectID": "posts/Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations/2024-07-03-Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations.html#appendix",
    "href": "posts/Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations/2024-07-03-Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations.html#appendix",
    "title": "Social Bias Evaluation for Large Language Models Requires Prompt Variations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03129v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03129v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17789"
  },
  {
    "objectID": "posts/A_Critical_Study_of_What_Code_LLMs_(Do_Not)_Learn/2024-06-17-A_Critical_Study_of_What_Code_LLMs_(Do_Not)_Learn.html#appendix",
    "href": "posts/A_Critical_Study_of_What_Code_LLMs_(Do_Not)_Learn/2024-06-17-A_Critical_Study_of_What_Code_LLMs_(Do_Not)_Learn.html#appendix",
    "title": "A Critical Study of What Code-LLMs (Do Not) Learn",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11930v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11930v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10566"
  },
  {
    "objectID": "posts/CogErgLLM_Exploring_Large_Language_Model_Systems_Design_Perspective_Using_Cognitive_Ergonomics/2024-07-03-CogErgLLM_Exploring_Large_Language_Model_Systems_Design_Perspective_Using_Cognitive_Ergonomics.html#appendix",
    "href": "posts/CogErgLLM_Exploring_Large_Language_Model_Systems_Design_Perspective_Using_Cognitive_Ergonomics/2024-07-03-CogErgLLM_Exploring_Large_Language_Model_Systems_Design_Perspective_Using_Cognitive_Ergonomics.html#appendix",
    "title": "CogErgLLM: Exploring Large Language Model Systems Design Perspective Using Cognitive Ergonomics",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02885v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02885v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5038"
  },
  {
    "objectID": "posts/Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents/2024-06-10-Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents.html",
    "href": "posts/Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents/2024-06-10-Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents.html",
    "title": "Transforming Wearable Data into Health Insights using Large Language Model Agents",
    "section": "",
    "text": "Summary: The paper presents a study on the Personal Health Insights Agent (PHIA), an AI model designed to answer personal health queries using wearable data. PHIA outperforms the Code Generation baseline by 14% (84% vs. 74%) in exact matching accuracy for objective personal health queries. In open-ended reasoning quality, PHIA demonstrates a significant advantage over the Code Generation baseline in all ratings except for personalization. Expert evaluation shows that PHIA has a significant advantage over the Code Generation baseline in overall code quality, avoiding hallucinations, and personalization. PHIA is also quantitatively less likely to generate code that raises an error.\nMajor Findings: 1. PHIA outperforms the Code Generation baseline by 14% in exact matching accuracy for objective personal health queries. 2. PHIA demonstrates a significant advantage over the Code Generation baseline in open-ended reasoning quality."
  },
  {
    "objectID": "posts/Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents/2024-06-10-Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents.html#appendix",
    "href": "posts/Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents/2024-06-10-Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents.html#appendix",
    "title": "Transforming Wearable Data into Health Insights using Large Language Model Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06464v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06464v1\n\n\nTruncated\nTrue\n\n\nWord Count\n28809"
  },
  {
    "objectID": "posts/UBENCH_Benchmarking_Uncertainty_in_Large_Language_Models_with_Multiple_Choice_Questions/2024-06-18-UBENCH_Benchmarking_Uncertainty_in_Large_Language_Models_with_Multiple_Choice_Questions.html#appendix",
    "href": "posts/UBENCH_Benchmarking_Uncertainty_in_Large_Language_Models_with_Multiple_Choice_Questions/2024-06-18-UBENCH_Benchmarking_Uncertainty_in_Large_Language_Models_with_Multiple_Choice_Questions.html#appendix",
    "title": "UBENCH: Benchmarking Uncertainty in Large Language Models with Multiple Choice Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12784v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12784v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7284"
  },
  {
    "objectID": "posts/How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States/2024-06-09-How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States.html",
    "href": "posts/How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States/2024-06-09-How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States.html",
    "title": "How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States",
    "section": "",
    "text": "Summary:\nThis paper explores how alignment and jailbreak work in large language models (LLMs) by using weak classifiers to explain LLM safety through intermediate hidden states. The authors confirm that LLMs learn ethical concepts during pre-training rather than alignment and can identify malicious and normal inputs in the early layers. Alignment associates the early concepts with emotion guesses in the middle layers and then refines them to specific reject tokens for safe generations. Jailbreak disturbs the transformation of early unethical classification into negative emotions. The paper conducts experiments on models from 7B to 70B across various model families to prove their conclusion.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a novel perspective on LLM safety by explaining how alignment and jailbreak work through intermediate hidden states. The use of weak classifiers to explain LLM safety is an innovative approach that could be applied to other aspects of LLM behavior. However, the paper does not discuss the limitations of using weak classifiers or the potential biases that may be introduced. Additionally, the paper does not address the potential risks of jailbreak, such as the generation of harmful content, and how these risks can be mitigated. Overall, the paper provides valuable insights into LLM safety and offers a new perspective on how alignment and jailbreak work."
  },
  {
    "objectID": "posts/How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States/2024-06-09-How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States.html#appendix",
    "href": "posts/How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States/2024-06-09-How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States.html#appendix",
    "title": "How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05644v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05644v1\n\n\nTruncated\nFalse\n\n\nWord Count\n19114"
  },
  {
    "objectID": "posts/SynDARin_Synthesising_Datasets_for_Automated_Reasoning_in_Low_Resource_Languages/2024-06-20-SynDARin_Synthesising_Datasets_for_Automated_Reasoning_in_Low_Resource_Languages.html#appendix",
    "href": "posts/SynDARin_Synthesising_Datasets_for_Automated_Reasoning_in_Low_Resource_Languages/2024-06-20-SynDARin_Synthesising_Datasets_for_Automated_Reasoning_in_Low_Resource_Languages.html#appendix",
    "title": "SynDARin: Synthesising Datasets for Automated Reasoning in Low-Resource Languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14425v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14425v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3686"
  },
  {
    "objectID": "posts/Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated/2024-06-26-Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated.html#major-findings",
    "href": "posts/Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated/2024-06-26-Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated.html#major-findings",
    "title": "Detecting Machine-Generated Texts: Not Just AI vs Humans and Explainability is Complicated",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe study introduces a novel ternary classification system for analyzing texts, adding an “undecided” category to the classification framework. This category recognizes that some texts may simultaneously share characteristics of both machine-generated and human-generated texts.\nThe authors developed a ternary classification dataset and designed experiments to test the validity of this approach. The methodology includes rigorous statistical and model-based analyses and incorporates detailed human evaluations to provide a nuanced understanding of the new ternary text classification task and the complexity of producing human-understandable explanations.\nThe study compares the explanatory power of human assessments with that of automated detectors, highlighting the current explanatory limitations faced by MGT detectors. The results show that the “undecided” category is much needed from the viewpoint of explainability."
  },
  {
    "objectID": "posts/Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated/2024-06-26-Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated.html#analysis-and-critique",
    "href": "posts/Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated/2024-06-26-Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated.html#analysis-and-critique",
    "title": "Detecting Machine-Generated Texts: Not Just AI vs Humans and Explainability is Complicated",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a well-structured and coherent summary of the academic article, effectively communicating the essential information. The major findings are clearly highlighted, and the analysis provides a critical evaluation of the article’s strengths and weaknesses. However, the critique could be more detailed, addressing specific methodological issues, conflicting evidence, or areas that require further research or clarification. Additionally, the summary could benefit from a more concise and focused presentation of the article’s main arguments and contributions.\nIn summary, the paper provides a valuable overview of the challenges and limitations of current methods for detecting machine-generated texts."
  },
  {
    "objectID": "posts/Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated/2024-06-26-Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated.html#appendix",
    "href": "posts/Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated/2024-06-26-Detecting_Machine_Generated_Texts_Not_Just_AI_vs_Humans_and_Explainability_is_Complicated.html#appendix",
    "title": "Detecting Machine-Generated Texts: Not Just AI vs Humans and Explainability is Complicated",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18259v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18259v1\n\n\nTruncated\nFalse\n\n\nWord Count\n19402"
  },
  {
    "objectID": "posts/Tools_Fail_Detecting_Silent_Errors_in_Faulty_Tools/2024-06-27-Tools_Fail_Detecting_Silent_Errors_in_Faulty_Tools.html#appendix",
    "href": "posts/Tools_Fail_Detecting_Silent_Errors_in_Faulty_Tools/2024-06-27-Tools_Fail_Detecting_Silent_Errors_in_Faulty_Tools.html#appendix",
    "title": "Tools Fail: Detecting Silent Errors in Faulty Tools",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19228v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19228v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8580"
  },
  {
    "objectID": "posts/Faux_Polyglot_A_Study_on_Information_Disparity_in_Multilingual_Large_Language_Models/2024-07-07-Faux_Polyglot_A_Study_on_Information_Disparity_in_Multilingual_Large_Language_Models.html#appendix",
    "href": "posts/Faux_Polyglot_A_Study_on_Information_Disparity_in_Multilingual_Large_Language_Models/2024-07-07-Faux_Polyglot_A_Study_on_Information_Disparity_in_Multilingual_Large_Language_Models.html#appendix",
    "title": "Faux Polyglot: A Study on Information Disparity in Multilingual Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05502v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05502v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8494"
  },
  {
    "objectID": "posts/CogMG_Collaborative_Augmentation_Between_Large_Language_Model_and_Knowledge_Graph/2024-06-25-CogMG_Collaborative_Augmentation_Between_Large_Language_Model_and_Knowledge_Graph.html#appendix",
    "href": "posts/CogMG_Collaborative_Augmentation_Between_Large_Language_Model_and_Knowledge_Graph/2024-06-25-CogMG_Collaborative_Augmentation_Between_Large_Language_Model_and_Knowledge_Graph.html#appendix",
    "title": "CogMG: Collaborative Augmentation Between Large Language Model and Knowledge Graph",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17231v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17231v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4470"
  },
  {
    "objectID": "posts/Meta_Rewarding_Language_Models_Self_Improving_Alignment_with_LLM_as_a_Meta_Judge/2024-07-28-Meta_Rewarding_Language_Models_Self_Improving_Alignment_with_LLM_as_a_Meta_Judge.html#appendix",
    "href": "posts/Meta_Rewarding_Language_Models_Self_Improving_Alignment_with_LLM_as_a_Meta_Judge/2024-07-28-Meta_Rewarding_Language_Models_Self_Improving_Alignment_with_LLM_as_a_Meta_Judge.html#appendix",
    "title": "Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19594v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19594v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7667"
  },
  {
    "objectID": "posts/Revolutionizing_Bridge_Operation_and_maintenance_with_LLM_based_Agents_An_Overview_of_Applications_and_Insights/2024-07-14-Revolutionizing_Bridge_Operation_and_maintenance_with_LLM_based_Agents_An_Overview_of_Applications_and_Insights.html#appendix",
    "href": "posts/Revolutionizing_Bridge_Operation_and_maintenance_with_LLM_based_Agents_An_Overview_of_Applications_and_Insights/2024-07-14-Revolutionizing_Bridge_Operation_and_maintenance_with_LLM_based_Agents_An_Overview_of_Applications_and_Insights.html#appendix",
    "title": "Revolutionizing Bridge Operation and maintenance with LLM-based Agents: An Overview of Applications and Insights",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10064v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10064v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11852"
  },
  {
    "objectID": "posts/Trace_is_the_New_AutoDiff____Unlocking_Efficient_Optimization_of_Computational_Workflows/2024-06-23-Trace_is_the_New_AutoDiff____Unlocking_Efficient_Optimization_of_Computational_Workflows.html",
    "href": "posts/Trace_is_the_New_AutoDiff____Unlocking_Efficient_Optimization_of_Computational_Workflows/2024-06-23-Trace_is_the_New_AutoDiff____Unlocking_Efficient_Optimization_of_Computational_Workflows.html",
    "title": "Trace is the New AutoDiff – Unlocking Efficient Optimization of Computational Workflows",
    "section": "",
    "text": "Summary:\nThe paper introduces a new optimization framework called Trace, which is designed to optimize computational workflows in AI systems. The framework is inspired by back-propagation and treats the computational workflow as a graph, similar to neural networks. The optimization process involves rich feedback, heterogeneous parameters, and intricate objectives. The paper also introduces a new mathematical setup called Optimization with Trace Oracle (OPTO) to capture and abstract these properties, enabling the design of optimizers that work across multiple domains. The authors propose a general-purpose LLM-based optimizer called OptoPrime, which can effectively solve OPTO problems. Empirical studies show that OptoPrime is capable of first-order numerical optimization, prompt optimization, hyper-parameter tuning, robot controller design, code debugging, and more. The authors believe that Trace, OptoPrime, and the OPTO framework will enable the next generation of interactive agents that automatically adapt using various kinds of feedback.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an interesting and novel approach to optimizing computational workflows in AI systems. The Trace framework and the OPTO mathematical setup provide a new perspective on how to optimize complex workflows, and the proposed OptoPrime optimizer demonstrates promising results in various optimization tasks. However, the paper does not provide a detailed comparison with existing optimization techniques, which could help to better understand the advantages and limitations of the proposed approach. Additionally, the paper does not discuss the scalability and"
  },
  {
    "objectID": "posts/Trace_is_the_New_AutoDiff____Unlocking_Efficient_Optimization_of_Computational_Workflows/2024-06-23-Trace_is_the_New_AutoDiff____Unlocking_Efficient_Optimization_of_Computational_Workflows.html#appendix",
    "href": "posts/Trace_is_the_New_AutoDiff____Unlocking_Efficient_Optimization_of_Computational_Workflows/2024-06-23-Trace_is_the_New_AutoDiff____Unlocking_Efficient_Optimization_of_Computational_Workflows.html#appendix",
    "title": "Trace is the New AutoDiff – Unlocking Efficient Optimization of Computational Workflows",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16218v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16218v1\n\n\nTruncated\nFalse\n\n\nWord Count\n16085"
  },
  {
    "objectID": "posts/SSP_Self_Supervised_Prompting_for_Cross_Lingual_Transfer_to_Low_Resource_Languages_using_Large_Language_Models/2024-06-27-SSP_Self_Supervised_Prompting_for_Cross_Lingual_Transfer_to_Low_Resource_Languages_using_Large_Language_Models.html#appendix",
    "href": "posts/SSP_Self_Supervised_Prompting_for_Cross_Lingual_Transfer_to_Low_Resource_Languages_using_Large_Language_Models/2024-06-27-SSP_Self_Supervised_Prompting_for_Cross_Lingual_Transfer_to_Low_Resource_Languages_using_Large_Language_Models.html#appendix",
    "title": "SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18880v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18880v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11013"
  },
  {
    "objectID": "posts/Towards_Transfer_Unlearning_Empirical_Evidence_of_Cross_Domain_Bias_Mitigation/2024-07-24-Towards_Transfer_Unlearning_Empirical_Evidence_of_Cross_Domain_Bias_Mitigation.html#appendix",
    "href": "posts/Towards_Transfer_Unlearning_Empirical_Evidence_of_Cross_Domain_Bias_Mitigation/2024-07-24-Towards_Transfer_Unlearning_Empirical_Evidence_of_Cross_Domain_Bias_Mitigation.html#appendix",
    "title": "Towards Transfer Unlearning: Empirical Evidence of Cross-Domain Bias Mitigation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16951v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16951v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3584"
  },
  {
    "objectID": "posts/Revealing_Fine_Grained_Values_and_Opinions_in_Large_Language_Models/2024-06-27-Revealing_Fine_Grained_Values_and_Opinions_in_Large_Language_Models.html#appendix",
    "href": "posts/Revealing_Fine_Grained_Values_and_Opinions_in_Large_Language_Models/2024-06-27-Revealing_Fine_Grained_Values_and_Opinions_in_Large_Language_Models.html#appendix",
    "title": "Revealing Fine-Grained Values and Opinions in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19238v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19238v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8950"
  },
  {
    "objectID": "posts/Improving_Entity_Recognition_Using_Ensembles_of_Deep_Learning_and_Fine_tuned_Large_Language_Models_A_Case_Study_on_Adverse_Event_Extraction_from_Multiple_Sources/2024-06-26-Improving_Entity_Recognition_Using_Ensembles_of_Deep_Learning_and_Fine_tuned_Large_Language_Models_A_Case_Study_on_Adverse_Event_Extraction_from_Multiple_Sources.html",
    "href": "posts/Improving_Entity_Recognition_Using_Ensembles_of_Deep_Learning_and_Fine_tuned_Large_Language_Models_A_Case_Study_on_Adverse_Event_Extraction_from_Multiple_Sources/2024-06-26-Improving_Entity_Recognition_Using_Ensembles_of_Deep_Learning_and_Fine_tuned_Large_Language_Models_A_Case_Study_on_Adverse_Event_Extraction_from_Multiple_Sources.html",
    "title": "Improving Entity Recognition Using Ensembles of Deep Learning and Fine-tuned Large Language Models: A Case Study on Adverse Event Extraction from Multiple Sources",
    "section": "",
    "text": "Summary:\nThis study evaluates the effectiveness of large language models (LLMs) and traditional deep learning models in adverse event (AE) extraction following COVID-19 vaccines. The authors utilized reports and posts from the Vaccine Adverse Event Reporting System (VAERS), Twitter, and Reddit as their corpora. Their goal was to extract three types of entities: vaccine, shot, and adverse event (ae). They explored and fine-tuned multiple LLMs, including GPT-2, GPT-3.5, GPT-4, Llama-2 7b, and Llama-2 13b, as well as traditional deep learning models like Recurrent Neural Network (RNN) and Bidirectional Encoder Representations from Transformers for Biomedical Text Mining (BioBERT). To enhance performance, they created ensembles of the three models with the best performance. The ensemble model achieved the highest performance in “vaccine,” “shot,” and “ae,” with strict F1-scores of 0.878, 0.930, and 0.925, respectively, along with a micro-average score of 0.903. These results underscore the significance of fine-tuning models for specific tasks and demonstrate the effectiveness of ensemble methods in enhancing performance.\nMajor Findings:\nAnalysis and Critique:\nThe study demonstrates the effectiveness and robustness of ensembling fine-tuned traditional deep learning models and LLMs for extracting AE-related information following COVID-19 vaccination. However, the authors acknowledge that the corpora"
  },
  {
    "objectID": "posts/Improving_Entity_Recognition_Using_Ensembles_of_Deep_Learning_and_Fine_tuned_Large_Language_Models_A_Case_Study_on_Adverse_Event_Extraction_from_Multiple_Sources/2024-06-26-Improving_Entity_Recognition_Using_Ensembles_of_Deep_Learning_and_Fine_tuned_Large_Language_Models_A_Case_Study_on_Adverse_Event_Extraction_from_Multiple_Sources.html#appendix",
    "href": "posts/Improving_Entity_Recognition_Using_Ensembles_of_Deep_Learning_and_Fine_tuned_Large_Language_Models_A_Case_Study_on_Adverse_Event_Extraction_from_Multiple_Sources/2024-06-26-Improving_Entity_Recognition_Using_Ensembles_of_Deep_Learning_and_Fine_tuned_Large_Language_Models_A_Case_Study_on_Adverse_Event_Extraction_from_Multiple_Sources.html#appendix",
    "title": "Improving Entity Recognition Using Ensembles of Deep Learning and Fine-tuned Large Language Models: A Case Study on Adverse Event Extraction from Multiple Sources",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18049v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18049v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13358"
  },
  {
    "objectID": "posts/Optimizing_Psychological_Counseling_with_Instruction_Tuned_Large_Language_Models/2024-06-19-Optimizing_Psychological_Counseling_with_Instruction_Tuned_Large_Language_Models.html#appendix",
    "href": "posts/Optimizing_Psychological_Counseling_with_Instruction_Tuned_Large_Language_Models/2024-06-19-Optimizing_Psychological_Counseling_with_Instruction_Tuned_Large_Language_Models.html#appendix",
    "title": "Optimizing Psychological Counseling with Instruction-Tuned Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13617v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13617v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4397"
  },
  {
    "objectID": "posts/QuickLLaMA_Query_aware_Inference_Acceleration_for_Large_Language_Models/2024-06-11-QuickLLaMA_Query_aware_Inference_Acceleration_for_Large_Language_Models.html#appendix",
    "href": "posts/QuickLLaMA_Query_aware_Inference_Acceleration_for_Large_Language_Models/2024-06-11-QuickLLaMA_Query_aware_Inference_Acceleration_for_Large_Language_Models.html#appendix",
    "title": "QuickLLaMA: Query-aware Inference Acceleration for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07528v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07528v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7459"
  },
  {
    "objectID": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#major-findings",
    "href": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#major-findings",
    "title": "Digital Business Model Analysis Using a Large Language Model",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe study demonstrates the potential of using LLMs for analyzing and designing new business models, which is still an evolving field with scarce research.\nThe proposed method can support idea generation in digital business model design by learning patterns from the commonalities of DX cases and using this knowledge as a reference when considering DX initiatives.\nThe analysis examples show that LLM can effectively extract similar DX cases, not only within the same industry but also from different industries, and consider their commonalities to support the ideation of digital business models."
  },
  {
    "objectID": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#analysis-and-critique",
    "href": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#analysis-and-critique",
    "title": "Digital Business Model Analysis Using a Large Language Model",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe study’s findings are preliminary, and further research is needed to refine the analytical methods using advanced NLP technologies and broaden the examination of digital business models across a wider spectrum of industries.\nThe proposed method potentially offers companies easy access to insights into the use of digital technologies and business model innovations that have previously been less accessible.\nThe authors plan to develop a recommendation system, possibly implemented via chatbots, that could suggest similar cases to act as a catalyst for companies aiming to accelerate their DX efforts.\nThe study makes certain academic contributions by demonstrating the potential of this approach, but more research is needed to fully understand its implications and limitations."
  },
  {
    "objectID": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#appendix",
    "href": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#appendix",
    "title": "Digital Business Model Analysis Using a Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05741v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05741v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3431"
  },
  {
    "objectID": "posts/PlagBench_Exploring_the_Duality_of_Large_Language_Models_in_Plagiarism_Generation_and_Detection/2024-06-24-PlagBench_Exploring_the_Duality_of_Large_Language_Models_in_Plagiarism_Generation_and_Detection.html#appendix",
    "href": "posts/PlagBench_Exploring_the_Duality_of_Large_Language_Models_in_Plagiarism_Generation_and_Detection/2024-06-24-PlagBench_Exploring_the_Duality_of_Large_Language_Models_in_Plagiarism_Generation_and_Detection.html#appendix",
    "title": "PlagBench: Exploring the Duality of Large Language Models in Plagiarism Generation and Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16288v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16288v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8349"
  },
  {
    "objectID": "posts/Breaking_the_Ceiling_of_the_LLM_Community_by_Treating_Token_Generation_as_a_Classification_for_Ensembling/2024-06-18-Breaking_the_Ceiling_of_the_LLM_Community_by_Treating_Token_Generation_as_a_Classification_for_Ensembling.html#appendix",
    "href": "posts/Breaking_the_Ceiling_of_the_LLM_Community_by_Treating_Token_Generation_as_a_Classification_for_Ensembling/2024-06-18-Breaking_the_Ceiling_of_the_LLM_Community_by_Treating_Token_Generation_as_a_Classification_for_Ensembling.html#appendix",
    "title": "Breaking the Ceiling of the LLM Community by Treating Token Generation as a Classification for Ensembling",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12585v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12585v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5835"
  },
  {
    "objectID": "posts/Psychomatics____A_Multidisciplinary_Framework_for_Understanding_Artificial_Minds/2024-07-23-Psychomatics____A_Multidisciplinary_Framework_for_Understanding_Artificial_Minds.html#appendix",
    "href": "posts/Psychomatics____A_Multidisciplinary_Framework_for_Understanding_Artificial_Minds/2024-07-23-Psychomatics____A_Multidisciplinary_Framework_for_Understanding_Artificial_Minds.html#appendix",
    "title": "Psychomatics – A Multidisciplinary Framework for Understanding Artificial Minds",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16444v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16444v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11619"
  },
  {
    "objectID": "posts/LLMs_for_Doctors_Leveraging_Medical_LLMs_to_Assist_Doctors_Not_Replace_Them/2024-06-26-LLMs_for_Doctors_Leveraging_Medical_LLMs_to_Assist_Doctors_Not_Replace_Them.html#appendix",
    "href": "posts/LLMs_for_Doctors_Leveraging_Medical_LLMs_to_Assist_Doctors_Not_Replace_Them/2024-06-26-LLMs_for_Doctors_Leveraging_Medical_LLMs_to_Assist_Doctors_Not_Replace_Them.html#appendix",
    "title": "LLMs for Doctors: Leveraging Medical LLMs to Assist Doctors, Not Replace Them",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18034v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18034v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10560"
  },
  {
    "objectID": "posts/Fine_Tuning_with_Divergent_Chains_of_Thought_Boosts_Reasoning_Through_Self_Correction_in_Language_Models/2024-07-03-Fine_Tuning_with_Divergent_Chains_of_Thought_Boosts_Reasoning_Through_Self_Correction_in_Language_Models.html#appendix",
    "href": "posts/Fine_Tuning_with_Divergent_Chains_of_Thought_Boosts_Reasoning_Through_Self_Correction_in_Language_Models/2024-07-03-Fine_Tuning_with_Divergent_Chains_of_Thought_Boosts_Reasoning_Through_Self_Correction_in_Language_Models.html#appendix",
    "title": "Fine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03181v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03181v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8440"
  },
  {
    "objectID": "posts/rLLM_Relational_Table_Learning_with_LLMs/2024-07-29-rLLM_Relational_Table_Learning_with_LLMs.html#appendix",
    "href": "posts/rLLM_Relational_Table_Learning_with_LLMs/2024-07-29-rLLM_Relational_Table_Learning_with_LLMs.html#appendix",
    "title": "rLLM: Relational Table Learning with LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20157v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20157v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5065"
  },
  {
    "objectID": "posts/ChatLogic_Integrating_Logic_Programming_with_Large_Language_Models_for_Multi_Step_Reasoning/2024-07-14-ChatLogic_Integrating_Logic_Programming_with_Large_Language_Models_for_Multi_Step_Reasoning.html#appendix",
    "href": "posts/ChatLogic_Integrating_Logic_Programming_with_Large_Language_Models_for_Multi_Step_Reasoning/2024-07-14-ChatLogic_Integrating_Logic_Programming_with_Large_Language_Models_for_Multi_Step_Reasoning.html#appendix",
    "title": "ChatLogic: Integrating Logic Programming with Large Language Models for Multi-Step Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10162v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10162v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5639"
  },
  {
    "objectID": "posts/Artificial_Agency_and_Large_Language_Models/2024-07-24-Artificial_Agency_and_Large_Language_Models.html#major-findings",
    "href": "posts/Artificial_Agency_and_Large_Language_Models/2024-07-24-Artificial_Agency_and_Large_Language_Models.html#major-findings",
    "title": "Artificial Agency and Large Language Models",
    "section": "Major Findings",
    "text": "Major Findings\n\nThe paper proposes a theoretical model for artificial agents that is based on a dynamic framework of factors, including the agent’s accessible history, its adaptive repertoire, and its external environment.\nThe paper argues that current state-of-the-art Large Language Models (LLMs) are not agents yet, but that there are elements to them that suggest a way forward.\nThe paper suggests that a combination of the agent architecture presented in Park et al. (2023) and the use of modules like the Coscientist in Boiko et al. (2023) could potentially be a way to realize agency in an artificial manner."
  },
  {
    "objectID": "posts/Artificial_Agency_and_Large_Language_Models/2024-07-24-Artificial_Agency_and_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/Artificial_Agency_and_Large_Language_Models/2024-07-24-Artificial_Agency_and_Large_Language_Models.html#analysis-and-critique",
    "title": "Artificial Agency and Large Language Models",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\nThe paper provides a valuable contribution to the philosophical debates surrounding the possibility of realizing agency in an artificial manner. The proposed theoretical model for artificial agents is well-structured and provides a clear framework for understanding the factors that influence an agent’s actions and goals. However, the paper does not provide a detailed analysis of the limitations and potential biases of the proposed model. Additionally, the paper does not discuss the potential ethical implications of realizing agency in an artificial manner. Further research is needed to address these issues and to evaluate the feasibility of the proposed approach."
  },
  {
    "objectID": "posts/Artificial_Agency_and_Large_Language_Models/2024-07-24-Artificial_Agency_and_Large_Language_Models.html#appendix",
    "href": "posts/Artificial_Agency_and_Large_Language_Models/2024-07-24-Artificial_Agency_and_Large_Language_Models.html#appendix",
    "title": "Artificial Agency and Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16190v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16190v2\n\n\nTruncated\nFalse\n\n\nWord Count\n16895"
  },
  {
    "objectID": "posts/Selective_Prompting_Tuning_for_Personalized_Conversations_with_LLMs/2024-06-26-Selective_Prompting_Tuning_for_Personalized_Conversations_with_LLMs.html#appendix",
    "href": "posts/Selective_Prompting_Tuning_for_Personalized_Conversations_with_LLMs/2024-06-26-Selective_Prompting_Tuning_for_Personalized_Conversations_with_LLMs.html#appendix",
    "title": "Selective Prompting Tuning for Personalized Conversations with LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18187v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18187v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8201"
  },
  {
    "objectID": "posts/Recursive_Introspection_Teaching_Language_Model_Agents_How_to_Self_Improve/2024-07-25-Recursive_Introspection_Teaching_Language_Model_Agents_How_to_Self_Improve.html",
    "href": "posts/Recursive_Introspection_Teaching_Language_Model_Agents_How_to_Self_Improve/2024-07-25-Recursive_Introspection_Teaching_Language_Model_Agents_How_to_Self_Improve.html",
    "title": "Recursive Introspection: Teaching Language Model Agents How to Self-Improve",
    "section": "",
    "text": "Summary:\nThe paper introduces RISE (Recursive Introspection), a novel approach for fine-tuning large language models (LLMs) to enable them to improve their responses over multiple turns. RISE is designed to address the challenge of test-time self-improvement, which is not exhibited by even the strongest proprietary LLMs. The approach involves an iterative fine-tuning procedure that teaches the model to alter its response after unsuccessful attempts to solve a hard test-time problem, with optional additional environment feedback. RISE poses fine-tuning for a single-turn prompt as solving a multi-turn Markov decision process (MDP), where the initial state is the prompt. The paper draws inspiration from principles in online imitation learning and reinforcement learning to propose strategies for multi-turn data collection and training. The experiments demonstrate that RISE enables Llama2, Llama3, and Mistral models to improve themselves with more turns on math reasoning tasks, outperforming several single-turn strategies given an equal amount of inference-time computation. RISE also scales well, often attaining larger benefits with more capable models. The analysis shows that RISE makes meaningful improvements to responses without disrupting one-turn abilities.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a promising approach to enable test-time self-improvement in LLMs. The experiments demonstrate the effectiveness of RISE in improving the performance of LLMs on math reasoning tasks. However, the paper does not discuss the potential limitations or shortcomings of the approach. For instance, it is unclear how RISE would perform on other types of tasks beyond math reasoning. Additionally, the paper does not provide a detailed comparison with other fine-tuning methods, which could help to better understand the advantages and disadvantages of RISE. Furthermore,"
  },
  {
    "objectID": "posts/Recursive_Introspection_Teaching_Language_Model_Agents_How_to_Self_Improve/2024-07-25-Recursive_Introspection_Teaching_Language_Model_Agents_How_to_Self_Improve.html#appendix",
    "href": "posts/Recursive_Introspection_Teaching_Language_Model_Agents_How_to_Self_Improve/2024-07-25-Recursive_Introspection_Teaching_Language_Model_Agents_How_to_Self_Improve.html#appendix",
    "title": "Recursive Introspection: Teaching Language Model Agents How to Self-Improve",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.18219v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.18219v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14314"
  },
  {
    "objectID": "posts/Affordances_Oriented_Planning_using_Foundation_Models_for_Continuous_Vision_Language_Navigation/2024-07-08-Affordances_Oriented_Planning_using_Foundation_Models_for_Continuous_Vision_Language_Navigation.html#appendix",
    "href": "posts/Affordances_Oriented_Planning_using_Foundation_Models_for_Continuous_Vision_Language_Navigation/2024-07-08-Affordances_Oriented_Planning_using_Foundation_Models_for_Continuous_Vision_Language_Navigation.html#appendix",
    "title": "Affordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05890v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05890v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7091"
  },
  {
    "objectID": "posts/Chain_of_Scrutiny_Detecting_Backdoor_Attacks_for_Large_Language_Models/2024-06-10-Chain_of_Scrutiny_Detecting_Backdoor_Attacks_for_Large_Language_Models.html#appendix",
    "href": "posts/Chain_of_Scrutiny_Detecting_Backdoor_Attacks_for_Large_Language_Models/2024-06-10-Chain_of_Scrutiny_Detecting_Backdoor_Attacks_for_Large_Language_Models.html#appendix",
    "title": "Chain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05948v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05948v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6961"
  },
  {
    "objectID": "posts/Dual_Space_Knowledge_Distillation_for_Large_Language_Models/2024-06-25-Dual_Space_Knowledge_Distillation_for_Large_Language_Models.html#appendix",
    "href": "posts/Dual_Space_Knowledge_Distillation_for_Large_Language_Models/2024-06-25-Dual_Space_Knowledge_Distillation_for_Large_Language_Models.html#appendix",
    "title": "Dual-Space Knowledge Distillation for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17328v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17328v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8166"
  },
  {
    "objectID": "posts/3D_Properties_Identifying_Challenges_in_DPO_and_Charting_a_Path_Forward/2024-06-11-3D_Properties_Identifying_Challenges_in_DPO_and_Charting_a_Path_Forward.html#appendix",
    "href": "posts/3D_Properties_Identifying_Challenges_in_DPO_and_Charting_a_Path_Forward/2024-06-11-3D_Properties_Identifying_Challenges_in_DPO_and_Charting_a_Path_Forward.html#appendix",
    "title": "3D-Properties: Identifying Challenges in DPO and Charting a Path Forward",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07327v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07327v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8028"
  },
  {
    "objectID": "posts/A_Survey_on_LLM_Based_Agentic_Workflows_and_LLM_Profiled_Components/2024-06-09-A_Survey_on_LLM_Based_Agentic_Workflows_and_LLM_Profiled_Components.html#appendix",
    "href": "posts/A_Survey_on_LLM_Based_Agentic_Workflows_and_LLM_Profiled_Components/2024-06-09-A_Survey_on_LLM_Based_Agentic_Workflows_and_LLM_Profiled_Components.html#appendix",
    "title": "A Survey on LLM-Based Agentic Workflows and LLM-Profiled Components",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05804v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05804v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5941"
  },
  {
    "objectID": "posts/Large_Language_Models_as_Evaluators_for_Scientific_Synthesis/2024-07-03-Large_Language_Models_as_Evaluators_for_Scientific_Synthesis.html#appendix",
    "href": "posts/Large_Language_Models_as_Evaluators_for_Scientific_Synthesis/2024-07-03-Large_Language_Models_as_Evaluators_for_Scientific_Synthesis.html#appendix",
    "title": "Large Language Models as Evaluators for Scientific Synthesis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02977v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02977v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6836"
  },
  {
    "objectID": "posts/PsycoLLM_Enhancing_LLM_for_Psychological_Understanding_and_Evaluation/2024-07-08-PsycoLLM_Enhancing_LLM_for_Psychological_Understanding_and_Evaluation.html#appendix",
    "href": "posts/PsycoLLM_Enhancing_LLM_for_Psychological_Understanding_and_Evaluation/2024-07-08-PsycoLLM_Enhancing_LLM_for_Psychological_Understanding_and_Evaluation.html#appendix",
    "title": "PsycoLLM: Enhancing LLM for Psychological Understanding and Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05721v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05721v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5547"
  },
  {
    "objectID": "posts/Exploring_Scaling_Trends_in_LLM_Robustness/2024-07-25-Exploring_Scaling_Trends_in_LLM_Robustness.html#appendix",
    "href": "posts/Exploring_Scaling_Trends_in_LLM_Robustness/2024-07-25-Exploring_Scaling_Trends_in_LLM_Robustness.html#appendix",
    "title": "Exploring Scaling Trends in LLM Robustness",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.18213v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.18213v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7444"
  },
  {
    "objectID": "posts/AMBROSIA_A_Benchmark_for_Parsing_Ambiguous_Questions_into_Database_Queries/2024-06-27-AMBROSIA_A_Benchmark_for_Parsing_Ambiguous_Questions_into_Database_Queries.html",
    "href": "posts/AMBROSIA_A_Benchmark_for_Parsing_Ambiguous_Questions_into_Database_Queries/2024-06-27-AMBROSIA_A_Benchmark_for_Parsing_Ambiguous_Questions_into_Database_Queries.html",
    "title": "AMBROSIA: A Benchmark for Parsing Ambiguous Questions into Database Queries",
    "section": "",
    "text": "Summary:\nThe paper introduces a new benchmark, “, for text-to-SQL parsers capable of recognizing and interpreting ambiguous requests. The dataset contains questions showcasing three different types of ambiguity (scope ambiguity, attachment ambiguity, and vagueness), their interpretations, and corresponding SQL queries. The dataset includes 846 multi-table databases, ambiguous questions, unambiguous interpretations, and complex SQL queries (4,242 in total). The authors aim to mimic real-world semantic parsing scenarios with realistic and diverse databases, creating them automatically in three steps: specifying a domain of interest, generating key concepts and relations, and generating SQL statements to construct tables with the desired structure. The paper also presents the results of benchmarking multiple advanced large language models on “, revealing that even the most advanced models struggle to identify and interpret ambiguity in questions.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel benchmark for text-to-SQL parsers capable of recognizing and interpreting ambiguous requests. The dataset is diverse and covers a wide range of SQL queries, making it a valuable resource for researchers in the field. However, the paper does not provide a detailed analysis of the performance of the benchmarked models, making it difficult to assess the effectiveness of the proposed approach. Additionally, the paper does not discuss potential limitations or biases in the dataset, which could impact the generaliz"
  },
  {
    "objectID": "posts/AMBROSIA_A_Benchmark_for_Parsing_Ambiguous_Questions_into_Database_Queries/2024-06-27-AMBROSIA_A_Benchmark_for_Parsing_Ambiguous_Questions_into_Database_Queries.html#appendix",
    "href": "posts/AMBROSIA_A_Benchmark_for_Parsing_Ambiguous_Questions_into_Database_Queries/2024-06-27-AMBROSIA_A_Benchmark_for_Parsing_Ambiguous_Questions_into_Database_Queries.html#appendix",
    "title": "AMBROSIA: A Benchmark for Parsing Ambiguous Questions into Database Queries",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19073v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19073v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20704"
  },
  {
    "objectID": "posts/VersiCode_Towards_Version_controllable_Code_Generation/2024-06-11-VersiCode_Towards_Version_controllable_Code_Generation.html#appendix",
    "href": "posts/VersiCode_Towards_Version_controllable_Code_Generation/2024-06-11-VersiCode_Towards_Version_controllable_Code_Generation.html#appendix",
    "title": "VersiCode: Towards Version-controllable Code Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07411v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07411v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6957"
  },
  {
    "objectID": "posts/CoSafe_Evaluating_Large_Language_Model_Safety_in_Multi_Turn_Dialogue_Coreference/2024-06-25-CoSafe_Evaluating_Large_Language_Model_Safety_in_Multi_Turn_Dialogue_Coreference.html#appendix",
    "href": "posts/CoSafe_Evaluating_Large_Language_Model_Safety_in_Multi_Turn_Dialogue_Coreference/2024-06-25-CoSafe_Evaluating_Large_Language_Model_Safety_in_Multi_Turn_Dialogue_Coreference.html#appendix",
    "title": "CoSafe: Evaluating Large Language Model Safety in Multi-Turn Dialogue Coreference",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17626v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17626v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14149"
  },
  {
    "objectID": "posts/Merging_Improves_Self_Critique_Against_Jailbreak_Attacks/2024-06-11-Merging_Improves_Self_Critique_Against_Jailbreak_Attacks.html#appendix",
    "href": "posts/Merging_Improves_Self_Critique_Against_Jailbreak_Attacks/2024-06-11-Merging_Improves_Self_Critique_Against_Jailbreak_Attacks.html#appendix",
    "title": "Merging Improves Self-Critique Against Jailbreak Attacks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07188v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07188v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3164"
  },
  {
    "objectID": "posts/Shared_Imagination_LLMs_Hallucinate_Alike/2024-07-23-Shared_Imagination_LLMs_Hallucinate_Alike.html#appendix",
    "href": "posts/Shared_Imagination_LLMs_Hallucinate_Alike/2024-07-23-Shared_Imagination_LLMs_Hallucinate_Alike.html#appendix",
    "title": "Shared Imagination: LLMs Hallucinate Alike",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16604v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16604v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7135"
  },
  {
    "objectID": "posts/Guiding_LLM_Temporal_Logic_Generation_with_Explicit_Separation_of_Data_and_Control/2024-06-11-Guiding_LLM_Temporal_Logic_Generation_with_Explicit_Separation_of_Data_and_Control.html#appendix",
    "href": "posts/Guiding_LLM_Temporal_Logic_Generation_with_Explicit_Separation_of_Data_and_Control/2024-06-11-Guiding_LLM_Temporal_Logic_Generation_with_Explicit_Separation_of_Data_and_Control.html#appendix",
    "title": "Guiding LLM Temporal Logic Generation with Explicit Separation of Data and Control",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07400v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07400v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4241"
  },
  {
    "objectID": "posts/Math_LLaVA_Bootstrapping_Mathematical_Reasoning_for_Multimodal_Large_Language_Models/2024-06-26-Math_LLaVA_Bootstrapping_Mathematical_Reasoning_for_Multimodal_Large_Language_Models.html#appendix",
    "href": "posts/Math_LLaVA_Bootstrapping_Mathematical_Reasoning_for_Multimodal_Large_Language_Models/2024-06-26-Math_LLaVA_Bootstrapping_Mathematical_Reasoning_for_Multimodal_Large_Language_Models.html#appendix",
    "title": "Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17294v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17294v2\n\n\nTruncated\nFalse\n\n\nWord Count\n6677"
  },
  {
    "objectID": "posts/Methodology_of_Adapting_Large_English_Language_Models_for_Specific_Cultural_Contexts/2024-06-27-Methodology_of_Adapting_Large_English_Language_Models_for_Specific_Cultural_Contexts.html#appendix",
    "href": "posts/Methodology_of_Adapting_Large_English_Language_Models_for_Specific_Cultural_Contexts/2024-06-27-Methodology_of_Adapting_Large_English_Language_Models_for_Specific_Cultural_Contexts.html#appendix",
    "title": "Methodology of Adapting Large English Language Models for Specific Cultural Contexts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18192v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18192v2\n\n\nTruncated\nFalse\n\n\nWord Count\n4216"
  },
  {
    "objectID": "posts/IRCAN_Mitigating_Knowledge_Conflicts_in_LLM_Generation_via_Identifying_and_Reweighting_Context_Aware_Neurons/2024-06-26-IRCAN_Mitigating_Knowledge_Conflicts_in_LLM_Generation_via_Identifying_and_Reweighting_Context_Aware_Neurons.html#appendix",
    "href": "posts/IRCAN_Mitigating_Knowledge_Conflicts_in_LLM_Generation_via_Identifying_and_Reweighting_Context_Aware_Neurons/2024-06-26-IRCAN_Mitigating_Knowledge_Conflicts_in_LLM_Generation_via_Identifying_and_Reweighting_Context_Aware_Neurons.html#appendix",
    "title": "IRCAN: Mitigating Knowledge Conflicts in LLM Generation via Identifying and Reweighting Context-Aware Neurons",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18406v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18406v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6376"
  },
  {
    "objectID": "posts/Video_Watermarking_Safeguarding_Your_Video_from_(Unauthorized)_Annotations_by_Video_based_LLMs/2024-07-03-Video_Watermarking_Safeguarding_Your_Video_from_(Unauthorized)_Annotations_by_Video_based_LLMs.html#appendix",
    "href": "posts/Video_Watermarking_Safeguarding_Your_Video_from_(Unauthorized)_Annotations_by_Video_based_LLMs/2024-07-03-Video_Watermarking_Safeguarding_Your_Video_from_(Unauthorized)_Annotations_by_Video_based_LLMs.html#appendix",
    "title": "Video Watermarking: Safeguarding Your Video from (Unauthorized) Annotations by Video-based LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02411v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02411v2\n\n\nTruncated\nFalse\n\n\nWord Count\n6556"
  },
  {
    "objectID": "posts/PISTOL_Dataset_Compilation_Pipeline_for_Structural_Unlearning_of_LLMs/2024-06-24-PISTOL_Dataset_Compilation_Pipeline_for_Structural_Unlearning_of_LLMs.html#appendix",
    "href": "posts/PISTOL_Dataset_Compilation_Pipeline_for_Structural_Unlearning_of_LLMs/2024-06-24-PISTOL_Dataset_Compilation_Pipeline_for_Structural_Unlearning_of_LLMs.html#appendix",
    "title": "PISTOL: Dataset Compilation Pipeline for Structural Unlearning of LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16810v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16810v1\n\n\nTruncated\nFalse\n\n\nWord Count\n25194"
  },
  {
    "objectID": "posts/Assessing_Code_Generation_with_Intermediate_Languages/2024-07-07-Assessing_Code_Generation_with_Intermediate_Languages.html#appendix",
    "href": "posts/Assessing_Code_Generation_with_Intermediate_Languages/2024-07-07-Assessing_Code_Generation_with_Intermediate_Languages.html#appendix",
    "title": "Assessing Code Generation with Intermediate Languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05411v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05411v1\n\n\nTruncated\nFalse\n\n\nWord Count\n370"
  },
  {
    "objectID": "posts/Towards_Optimizing_and_Evaluating_a_Retrieval_Augmented_QA_Chatbot_using_LLMs_with_Human_in_the_Loop/2024-07-08-Towards_Optimizing_and_Evaluating_a_Retrieval_Augmented_QA_Chatbot_using_LLMs_with_Human_in_the_Loop.html#appendix",
    "href": "posts/Towards_Optimizing_and_Evaluating_a_Retrieval_Augmented_QA_Chatbot_using_LLMs_with_Human_in_the_Loop/2024-07-08-Towards_Optimizing_and_Evaluating_a_Retrieval_Augmented_QA_Chatbot_using_LLMs_with_Human_in_the_Loop.html#appendix",
    "title": "Towards Optimizing and Evaluating a Retrieval Augmented QA Chatbot using LLMs with Human in the Loop",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05925v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05925v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6545"
  },
  {
    "objectID": "posts/Exploring_User_Retrieval_Integration_towards_Large_Language_Models_for_Cross_Domain_Sequential_Recommendation/2024-06-05-Exploring_User_Retrieval_Integration_towards_Large_Language_Models_for_Cross_Domain_Sequential_Recommendation.html#appendix",
    "href": "posts/Exploring_User_Retrieval_Integration_towards_Large_Language_Models_for_Cross_Domain_Sequential_Recommendation/2024-06-05-Exploring_User_Retrieval_Integration_towards_Large_Language_Models_for_Cross_Domain_Sequential_Recommendation.html#appendix",
    "title": "Exploring User Retrieval Integration towards Large Language Models for Cross-Domain Sequential Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03085v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03085v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8121"
  },
  {
    "objectID": "posts/LLM_ARC_Enhancing_LLMs_with_an_Automated_Reasoning_Critic/2024-06-25-LLM_ARC_Enhancing_LLMs_with_an_Automated_Reasoning_Critic.html#appendix",
    "href": "posts/LLM_ARC_Enhancing_LLMs_with_an_Automated_Reasoning_Critic/2024-06-25-LLM_ARC_Enhancing_LLMs_with_an_Automated_Reasoning_Critic.html#appendix",
    "title": "LLM-ARC: Enhancing LLMs with an Automated Reasoning Critic",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17663v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17663v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9705"
  },
  {
    "objectID": "posts/Course_Correction_Safety_Alignment_Using_Synthetic_Preferences/2024-07-23-Course_Correction_Safety_Alignment_Using_Synthetic_Preferences.html#appendix",
    "href": "posts/Course_Correction_Safety_Alignment_Using_Synthetic_Preferences/2024-07-23-Course_Correction_Safety_Alignment_Using_Synthetic_Preferences.html#appendix",
    "title": "Course-Correction: Safety Alignment Using Synthetic Preferences",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16637v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16637v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11071"
  },
  {
    "objectID": "posts/On_Policy_Fine_grained_Knowledge_Feedback_for_Hallucination_Mitigation/2024-06-18-On_Policy_Fine_grained_Knowledge_Feedback_for_Hallucination_Mitigation.html#appendix",
    "href": "posts/On_Policy_Fine_grained_Knowledge_Feedback_for_Hallucination_Mitigation/2024-06-18-On_Policy_Fine_grained_Knowledge_Feedback_for_Hallucination_Mitigation.html#appendix",
    "title": "On-Policy Fine-grained Knowledge Feedback for Hallucination Mitigation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12221v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12221v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7146"
  },
  {
    "objectID": "posts/NoviCode_Generating_Programs_from_Natural_Language_Utterances_by_Novices/2024-07-15-NoviCode_Generating_Programs_from_Natural_Language_Utterances_by_Novices.html#appendix",
    "href": "posts/NoviCode_Generating_Programs_from_Natural_Language_Utterances_by_Novices/2024-07-15-NoviCode_Generating_Programs_from_Natural_Language_Utterances_by_Novices.html#appendix",
    "title": "NoviCode: Generating Programs from Natural Language Utterances by Novices",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10626v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10626v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9676"
  },
  {
    "objectID": "posts/BLAZE_Cross_Language_and_Cross_Project_Bug_Localization_via_Dynamic_Chunking_and_Hard_Example_Learning/2024-07-24-BLAZE_Cross_Language_and_Cross_Project_Bug_Localization_via_Dynamic_Chunking_and_Hard_Example_Learning.html#appendix",
    "href": "posts/BLAZE_Cross_Language_and_Cross_Project_Bug_Localization_via_Dynamic_Chunking_and_Hard_Example_Learning/2024-07-24-BLAZE_Cross_Language_and_Cross_Project_Bug_Localization_via_Dynamic_Chunking_and_Hard_Example_Learning.html#appendix",
    "title": "BLAZE: Cross-Language and Cross-Project Bug Localization via Dynamic Chunking and Hard Example Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17631v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17631v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9812"
  },
  {
    "objectID": "posts/BEEAR_Embedding_based_Adversarial_Removal_of_Safety_Backdoors_in_Instruction_tuned_Language_Models/2024-06-24-BEEAR_Embedding_based_Adversarial_Removal_of_Safety_Backdoors_in_Instruction_tuned_Language_Models.html#appendix",
    "href": "posts/BEEAR_Embedding_based_Adversarial_Removal_of_Safety_Backdoors_in_Instruction_tuned_Language_Models/2024-06-24-BEEAR_Embedding_based_Adversarial_Removal_of_Safety_Backdoors_in_Instruction_tuned_Language_Models.html#appendix",
    "title": "BEEAR: Embedding-based Adversarial Removal of Safety Backdoors in Instruction-tuned Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17092v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17092v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11761"
  },
  {
    "objectID": "posts/The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis/2024-06-19-The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis.html",
    "href": "posts/The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis/2024-06-19-The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis.html",
    "title": "The Efficacy of Conversational Artificial Intelligence in Rectifying the Theory of Mind and Autonomy Biases: Comparative Analysis",
    "section": "",
    "text": "Summary:\nThis study evaluates the efficacy of Conversational Artificial Intelligence (CAI) in rectifying cognitive biases and recognizing affect in human-AI interactions, which is crucial for digital mental health interventions. The research employs a structured methodology with clinical-based virtual case scenarios simulating typical user-bot interactions. Performance and affect recognition were assessed across two categories of cognitive biases: theory of mind biases (anthropomorphization of AI, overtrust in AI, attribution to AI) and autonomy biases (illusion of control, fundamental attribution error, just-world hypothesis). A qualitative feedback mechanism was used with an ordinal scale to quantify responses based on accuracy, therapeutic quality, and adherence to CBT principles. Therapeutic bots (Wysa, Youper) and general-use LLMs (GTP 3.5, GTP 4, Gemini Pro) were evaluated through scripted interactions, double-reviewed by cognitive scientists and a clinical psychologist. Statistical analysis showed therapeutic bots were consistently outperformed by non-therapeutic bots in bias rectification and in 4 out of 6 biases in affect recognition. The data suggests that non-therapeutic chatbots are more effective in addressing some cognitive biases.\nMajor Findings:"
  },
  {
    "objectID": "posts/The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis/2024-06-19-The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis.html#appendix",
    "href": "posts/The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis/2024-06-19-The_Efficacy_of_Conversational_Artificial_Intelligence_in_Rectifying_the_Theory_of_Mind_and_Autonomy_Biases_Comparative_Analysis.html#appendix",
    "title": "The Efficacy of Conversational Artificial Intelligence in Rectifying the Theory of Mind and Autonomy Biases: Comparative Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13813v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13813v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17145"
  },
  {
    "objectID": "posts/DELRec_Distilling_Sequential_Pattern_to_Enhance_LLM_based_Recommendation/2024-06-17-DELRec_Distilling_Sequential_Pattern_to_Enhance_LLM_based_Recommendation.html#appendix",
    "href": "posts/DELRec_Distilling_Sequential_Pattern_to_Enhance_LLM_based_Recommendation/2024-06-17-DELRec_Distilling_Sequential_Pattern_to_Enhance_LLM_based_Recommendation.html#appendix",
    "title": "DELRec: Distilling Sequential Pattern to Enhance LLM-based Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11156v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11156v2\n\n\nTruncated\nFalse\n\n\nWord Count\n8935"
  },
  {
    "objectID": "posts/Embodied_AI_in_Mobile_Robots_Coverage_Path_Planning_with_Large_Language_Models/2024-07-02-Embodied_AI_in_Mobile_Robots_Coverage_Path_Planning_with_Large_Language_Models.html#appendix",
    "href": "posts/Embodied_AI_in_Mobile_Robots_Coverage_Path_Planning_with_Large_Language_Models/2024-07-02-Embodied_AI_in_Mobile_Robots_Coverage_Path_Planning_with_Large_Language_Models.html#appendix",
    "title": "Embodied AI in Mobile Robots: Coverage Path Planning with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02220v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02220v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4205"
  },
  {
    "objectID": "posts/Validating_LLM_Generated_Programs_with_Metamorphic_Prompt_Testing/2024-06-11-Validating_LLM_Generated_Programs_with_Metamorphic_Prompt_Testing.html#appendix",
    "href": "posts/Validating_LLM_Generated_Programs_with_Metamorphic_Prompt_Testing/2024-06-11-Validating_LLM_Generated_Programs_with_Metamorphic_Prompt_Testing.html#appendix",
    "title": "Validating LLM-Generated Programs with Metamorphic Prompt Testing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06864v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06864v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6738"
  },
  {
    "objectID": "posts/CIBench_Evaluating_Your_LLMs_with_a_Code_Interpreter_Plugin/2024-07-15-CIBench_Evaluating_Your_LLMs_with_a_Code_Interpreter_Plugin.html#appendix",
    "href": "posts/CIBench_Evaluating_Your_LLMs_with_a_Code_Interpreter_Plugin/2024-07-15-CIBench_Evaluating_Your_LLMs_with_a_Code_Interpreter_Plugin.html#appendix",
    "title": "CIBench: Evaluating Your LLMs with a Code Interpreter Plugin",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10499v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10499v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6515"
  },
  {
    "objectID": "posts/On_the_Transformations_across_Reward_Model_Parameter_Update_and_In_Context_Prompt/2024-06-24-On_the_Transformations_across_Reward_Model_Parameter_Update_and_In_Context_Prompt.html",
    "href": "posts/On_the_Transformations_across_Reward_Model_Parameter_Update_and_In_Context_Prompt/2024-06-24-On_the_Transformations_across_Reward_Model_Parameter_Update_and_In_Context_Prompt.html",
    "title": "On the Transformations across Reward Model, Parameter Update, and In-Context Prompt",
    "section": "",
    "text": "Summary:\nThis paper presents a holistic view of the interchangeability among three popular and distinct adaptation tools for pre-trained large language models (LLMs): parameter updating, reward modeling, and in-context prompting. The authors establish a triangular framework with six transformation directions, each facilitating various applications. The primary contribution of this work is to offer a unified perspective that connects numerous existing studies and outlines potential future research directions.\nMajor Findings:\nAnalysis and Critique:\nThe paper offers a comprehensive and unified view of the interchangeability among parameter updating, reward modeling, and in-context prompting in adapting pre-trained LLMs. This framework serves as a useful guide for researchers and practitioners in the field of LLMs, empowering them to make more informed decisions in their research and applications. However, the paper does not address the limitations and unanswered questions that may arise from the proposed framework. Additionally, the authors do not discuss any methodological issues, conflicting evidence, or areas that require further research or clarification.\nIn conclusion, the paper provides a valuable contribution to the field of LLMs by offering a unified perspective on the interchangeability of adaptation tools. However, further research is needed to address the limitations and unanswered questions that may arise from the proposed framework."
  },
  {
    "objectID": "posts/On_the_Transformations_across_Reward_Model_Parameter_Update_and_In_Context_Prompt/2024-06-24-On_the_Transformations_across_Reward_Model_Parameter_Update_and_In_Context_Prompt.html#appendix",
    "href": "posts/On_the_Transformations_across_Reward_Model_Parameter_Update_and_In_Context_Prompt/2024-06-24-On_the_Transformations_across_Reward_Model_Parameter_Update_and_In_Context_Prompt.html#appendix",
    "title": "On the Transformations across Reward Model, Parameter Update, and In-Context Prompt",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16377v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16377v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14264"
  },
  {
    "objectID": "posts/Iterative_or_Innovative_A_Problem_Oriented_Perspective_for_Code_Optimization/2024-06-17-Iterative_or_Innovative_A_Problem_Oriented_Perspective_for_Code_Optimization.html#appendix",
    "href": "posts/Iterative_or_Innovative_A_Problem_Oriented_Perspective_for_Code_Optimization/2024-06-17-Iterative_or_Innovative_A_Problem_Oriented_Perspective_for_Code_Optimization.html#appendix",
    "title": "Iterative or Innovative? A Problem-Oriented Perspective for Code Optimization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11935v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11935v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10246"
  },
  {
    "objectID": "posts/DIDUP_Dynamic_Iterative_Development_for_UI_Prototyping/2024-07-11-DIDUP_Dynamic_Iterative_Development_for_UI_Prototyping.html#appendix",
    "href": "posts/DIDUP_Dynamic_Iterative_Development_for_UI_Prototyping/2024-07-11-DIDUP_Dynamic_Iterative_Development_for_UI_Prototyping.html#appendix",
    "title": "DIDUP: Dynamic Iterative Development for UI Prototyping",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08474v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08474v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3335"
  },
  {
    "objectID": "posts/Jailbreak_Paradox_The_Achilles_Heel_of_LLMs/2024-06-18-Jailbreak_Paradox_The_Achilles_Heel_of_LLMs.html#appendix",
    "href": "posts/Jailbreak_Paradox_The_Achilles_Heel_of_LLMs/2024-06-18-Jailbreak_Paradox_The_Achilles_Heel_of_LLMs.html#appendix",
    "title": "Jailbreak Paradox: The Achilles’ Heel of LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12702v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12702v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4006"
  },
  {
    "objectID": "posts/Controllable_Navigation_Instruction_Generation_with_Chain_of_Thought_Prompting/2024-07-10-Controllable_Navigation_Instruction_Generation_with_Chain_of_Thought_Prompting.html#appendix",
    "href": "posts/Controllable_Navigation_Instruction_Generation_with_Chain_of_Thought_Prompting/2024-07-10-Controllable_Navigation_Instruction_Generation_with_Chain_of_Thought_Prompting.html#appendix",
    "title": "Controllable Navigation Instruction Generation with Chain of Thought Prompting",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07433v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07433v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7664"
  },
  {
    "objectID": "posts/Sunnie_An_Anthropomorphic_LLM_Based_Conversational_Agent_for_Mental_Well_Being_Activity_Recommendation/2024-05-22-Sunnie_An_Anthropomorphic_LLM_Based_Conversational_Agent_for_Mental_Well_Being_Activity_Recommendation.html#appendix",
    "href": "posts/Sunnie_An_Anthropomorphic_LLM_Based_Conversational_Agent_for_Mental_Well_Being_Activity_Recommendation/2024-05-22-Sunnie_An_Anthropomorphic_LLM_Based_Conversational_Agent_for_Mental_Well_Being_Activity_Recommendation.html#appendix",
    "title": "Sunnie: An Anthropomorphic LLM-Based Conversational Agent for Mental Well-Being Activity Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.13803v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.13803v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1391"
  },
  {
    "objectID": "posts/MG_Verilog_Multi_grained_Dataset_Towards_Enhanced_LLM_assisted_Verilog_Generation/2024-07-03-MG_Verilog_Multi_grained_Dataset_Towards_Enhanced_LLM_assisted_Verilog_Generation.html#appendix",
    "href": "posts/MG_Verilog_Multi_grained_Dataset_Towards_Enhanced_LLM_assisted_Verilog_Generation/2024-07-03-MG_Verilog_Multi_grained_Dataset_Towards_Enhanced_LLM_assisted_Verilog_Generation.html#appendix",
    "title": "MG-Verilog: Multi-grained Dataset Towards Enhanced LLM-assisted Verilog Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01910v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01910v2\n\n\nTruncated\nFalse\n\n\nWord Count\n3899"
  },
  {
    "objectID": "posts/NoteLLM_2_Multimodal_Large_Representation_Models_for_Recommendation/2024-05-27-NoteLLM_2_Multimodal_Large_Representation_Models_for_Recommendation.html#appendix",
    "href": "posts/NoteLLM_2_Multimodal_Large_Representation_Models_for_Recommendation/2024-05-27-NoteLLM_2_Multimodal_Large_Representation_Models_for_Recommendation.html#appendix",
    "title": "NoteLLM-2: Multimodal Large Representation Models for Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.16789v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.16789v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7838"
  },
  {
    "objectID": "posts/Robust_Few_shot_Transfer_Learning_for_Knowledge_Base_Question_Answering_with_Unanswerable_Questions/2024-06-20-Robust_Few_shot_Transfer_Learning_for_Knowledge_Base_Question_Answering_with_Unanswerable_Questions.html#appendix",
    "href": "posts/Robust_Few_shot_Transfer_Learning_for_Knowledge_Base_Question_Answering_with_Unanswerable_Questions/2024-06-20-Robust_Few_shot_Transfer_Learning_for_Knowledge_Base_Question_Answering_with_Unanswerable_Questions.html#appendix",
    "title": "Robust Few-shot Transfer Learning for Knowledge Base Question Answering with Unanswerable Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14313v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14313v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10473"
  },
  {
    "objectID": "posts/A_Taxonomy_for_Data_Contamination_in_Large_Language_Models/2024-07-11-A_Taxonomy_for_Data_Contamination_in_Large_Language_Models.html#major-findings",
    "href": "posts/A_Taxonomy_for_Data_Contamination_in_Large_Language_Models/2024-07-11-A_Taxonomy_for_Data_Contamination_in_Large_Language_Models.html#major-findings",
    "title": "A Taxonomy for Data Contamination in Large Language Models",
    "section": "Major Findings",
    "text": "Major Findings\n\nThe paper presents a taxonomy that categorizes the various types of contamination encountered by LLMs during the pretraining phase and identifies which types pose the highest risk.\nThe authors analyze the impact of contamination on two key NLP tasks: summarization and question answering, revealing how different types of contamination influence task performance during evaluation.\nThe findings reveal that for GPT-2 Large models, having in-domain data present during training is often as beneficial as having the test data present during training.\nCertain contamination types exhibit task-dependent effects on evaluation performance, further complicating decontamination best practices.\nThe findings enable recommendations for identifying and mitigating problematic contamination during LLM development to ensure reliable evaluations."
  },
  {
    "objectID": "posts/A_Taxonomy_for_Data_Contamination_in_Large_Language_Models/2024-07-11-A_Taxonomy_for_Data_Contamination_in_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/A_Taxonomy_for_Data_Contamination_in_Large_Language_Models/2024-07-11-A_Taxonomy_for_Data_Contamination_in_Large_Language_Models.html#analysis-and-critique",
    "title": "A Taxonomy for Data Contamination in Large Language Models",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\nThe paper provides a comprehensive taxonomy for data contamination in LLMs and analyzes its impact on two key NLP tasks. However, the paper does not discuss the potential impact of contamination on other NLP tasks, such as named entity recognition or part-of-speech tagging. Additionally, the paper does not provide a detailed analysis of the impact of contamination on model fairness, bias, and robustness.\nFurthermore, the paper does not discuss the potential impact of contamination on model interpretability and explainability. As LLMs become more prevalent in real-world applications, it is essential to understand how contamination affects model behavior and decision-making processes.\nOverall, the paper provides valuable insights into the impact of data contamination on LLMs and highlights the need for further research in this area. However, the paper could benefit from a more comprehensive analysis of the impact of contamination on other NLP tasks and model fairness, bias, and robustness."
  },
  {
    "objectID": "posts/A_Taxonomy_for_Data_Contamination_in_Large_Language_Models/2024-07-11-A_Taxonomy_for_Data_Contamination_in_Large_Language_Models.html#appendix",
    "href": "posts/A_Taxonomy_for_Data_Contamination_in_Large_Language_Models/2024-07-11-A_Taxonomy_for_Data_Contamination_in_Large_Language_Models.html#appendix",
    "title": "A Taxonomy for Data Contamination in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08716v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08716v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15638"
  },
  {
    "objectID": "posts/Q_Improving_Multi_step_Reasoning_for_LLMs_with_Deliberative_Planning/2024-06-20-Q_Improving_Multi_step_Reasoning_for_LLMs_with_Deliberative_Planning.html#appendix",
    "href": "posts/Q_Improving_Multi_step_Reasoning_for_LLMs_with_Deliberative_Planning/2024-06-20-Q_Improving_Multi_step_Reasoning_for_LLMs_with_Deliberative_Planning.html#appendix",
    "title": "Q*: Improving Multi-step Reasoning for LLMs with Deliberative Planning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14283v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14283v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5312"
  },
  {
    "objectID": "posts/Joint_Demonstration_and_Preference_Learning_Improves_Policy_Alignment_with_Human_Feedback/2024-06-11-Joint_Demonstration_and_Preference_Learning_Improves_Policy_Alignment_with_Human_Feedback.html#appendix",
    "href": "posts/Joint_Demonstration_and_Preference_Learning_Improves_Policy_Alignment_with_Human_Feedback/2024-06-11-Joint_Demonstration_and_Preference_Learning_Improves_Policy_Alignment_with_Human_Feedback.html#appendix",
    "title": "Joint Demonstration and Preference Learning Improves Policy Alignment with Human Feedback",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06874v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06874v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10718"
  },
  {
    "objectID": "posts/Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities/2024-06-11-Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities.html",
    "href": "posts/Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities/2024-06-11-Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities.html",
    "title": "Toxic Memes: A Survey of Computational Perspectives on the Detection and Explanation of Meme Toxicities",
    "section": "",
    "text": "Summary:\nThis paper provides a comprehensive survey of 158 papers on computational perspectives on toxic memes, covering key developments up to early 2024. The study identifies a wide variety of terminology used to refer to toxic memes, highlighting the need for a clearer taxonomy and harmonized definitions. The authors introduce a novel taxonomy and offer insights into various dimensions of meme toxicity, including intent, target, and conveyance tactics. The paper also catalogs datasets containing toxic memes, analyzes prevalent challenges, and identifies emerging trends in computational approaches to toxic meme detection and interpretation. The survey aims to promote interdisciplinary collaboration and innovation to foster media literacy and a safer online ecosystem.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive survey of the literature on computational perspectives on toxic memes, offering valuable insights into the current state of the field. The introduction of a novel taxonomy and harmonized definitions is a significant contribution, as it addresses the need for a clearer taxonomy and harmonized definitions. The paper also identifies emerging trends in computational approaches to toxic meme detection and interpretation, which can guide future research in the field.\nHowever, the paper does not provide a critical analysis of the limitations and biases of the existing literature. Additionally, the paper does not discuss the potential ethical implications of using computational approaches to detect and interpret toxic memes. Future research should address these limitations and consider the ethical implications of using computational approaches to detect and interpret toxic"
  },
  {
    "objectID": "posts/Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities/2024-06-11-Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities.html#appendix",
    "href": "posts/Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities/2024-06-11-Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities.html#appendix",
    "title": "Toxic Memes: A Survey of Computational Perspectives on the Detection and Explanation of Meme Toxicities",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07353v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07353v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20322"
  },
  {
    "objectID": "posts/A_Context_Driven_Approach_for_Co_Auditing_Smart_Contracts_with_The_Support_of_GPT_4_code_interpreter/2024-06-26-A_Context_Driven_Approach_for_Co_Auditing_Smart_Contracts_with_The_Support_of_GPT_4_code_interpreter.html#appendix",
    "href": "posts/A_Context_Driven_Approach_for_Co_Auditing_Smart_Contracts_with_The_Support_of_GPT_4_code_interpreter/2024-06-26-A_Context_Driven_Approach_for_Co_Auditing_Smart_Contracts_with_The_Support_of_GPT_4_code_interpreter.html#appendix",
    "title": "A Context-Driven Approach for Co-Auditing Smart Contracts with The Support of GPT-4 code interpreter",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18075v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18075v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9396"
  },
  {
    "objectID": "posts/Can_Editing_LLMs_Inject_Harm/2024-07-29-Can_Editing_LLMs_Inject_Harm.html#appendix",
    "href": "posts/Can_Editing_LLMs_Inject_Harm/2024-07-29-Can_Editing_LLMs_Inject_Harm.html#appendix",
    "title": "Can Editing LLMs Inject Harm?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20224v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20224v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9390"
  },
  {
    "objectID": "posts/NTSEBENCH_Cognitive_Reasoning_Benchmark_for_Vision_Language_Models/2024-07-15-NTSEBENCH_Cognitive_Reasoning_Benchmark_for_Vision_Language_Models.html#appendix",
    "href": "posts/NTSEBENCH_Cognitive_Reasoning_Benchmark_for_Vision_Language_Models/2024-07-15-NTSEBENCH_Cognitive_Reasoning_Benchmark_for_Vision_Language_Models.html#appendix",
    "title": "NTSEBENCH: Cognitive Reasoning Benchmark for Vision Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10380v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10380v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7146"
  },
  {
    "objectID": "posts/Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110/2024-06-10-Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110.html",
    "href": "posts/Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110/2024-06-10-Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110.html",
    "title": "Harnessing AI for efficient analysis of complex policy documents: a case study of Executive Order 14110",
    "section": "",
    "text": "Summary:\nThis study investigates the accuracy and reliability of large language model (LLM)-based AI systems in extracting information from complex policy documents, such as Executive Order 14110. The research focuses on question answering and tasks involving content extraction, comparing the performance of four commercial AI systems (Claude 3 Opus, ChatGPT-4, Gemini Pro 1.5, and Command R+) to manual analysis conducted by human experts. The results show that Gemini and Claude demonstrated the most comprehensive understanding of the EO, consistently providing concise, accurate, and detailed responses. However, achieving acceptable levels of reproducibility and trustworthiness remains a critical challenge that necessitates further research and development.\nMajor Findings:\nAnalysis and Critique:\nThe study provides valuable insights into the potential of AI in policy analysis, but there are several limitations to consider:\nFurther research could involve testing other AI models, including open-source alternatives, mixture-of-"
  },
  {
    "objectID": "posts/Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110/2024-06-10-Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110.html#appendix",
    "href": "posts/Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110/2024-06-10-Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110.html#appendix",
    "title": "Harnessing AI for efficient analysis of complex policy documents: a case study of Executive Order 14110",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06657v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06657v1\n\n\nTruncated\nFalse\n\n\nWord Count\n25409"
  },
  {
    "objectID": "posts/Noisy_Neighbors_Efficient_membership_inference_attacks_against_LLMs/2024-06-24-Noisy_Neighbors_Efficient_membership_inference_attacks_against_LLMs.html#appendix",
    "href": "posts/Noisy_Neighbors_Efficient_membership_inference_attacks_against_LLMs/2024-06-24-Noisy_Neighbors_Efficient_membership_inference_attacks_against_LLMs.html#appendix",
    "title": "Noisy Neighbors: Efficient membership inference attacks against LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16565v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16565v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3223"
  },
  {
    "objectID": "posts/Sparser_is_Faster_and_Less_is_More_Efficient_Sparse_Attention_for_Long_Range_Transformers/2024-06-24-Sparser_is_Faster_and_Less_is_More_Efficient_Sparse_Attention_for_Long_Range_Transformers.html",
    "href": "posts/Sparser_is_Faster_and_Less_is_More_Efficient_Sparse_Attention_for_Long_Range_Transformers/2024-06-24-Sparser_is_Faster_and_Less_is_More_Efficient_Sparse_Attention_for_Long_Range_Transformers.html",
    "title": "Sparser is Faster and Less is More: Efficient Sparse Attention for Long-Range Transformers",
    "section": "",
    "text": "Summary:\nThe paper introduces SparseK Attention, a novel sparse attention mechanism designed to overcome computational and memory obstacles in long-range Transformer computing. This approach integrates a scoring network and a differentiable top-k mask operator, SparseK, to select a constant number of KV pairs for each query, enabling gradient-based optimization. SparseK Attention offers linear time complexity and constant memory footprint during generation. Experimental results reveal that SparseK Attention outperforms previous sparse attention methods and provides significant speed improvements during both training and inference, particularly in language modeling and downstream tasks. The method can be seamlessly integrated into pre-trained Large Language Models (LLMs) with minimal fine-tuning, offering a practical solution for effectively managing long-range dependencies in diverse applications.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a promising approach to addressing the computational and memory challenges in long-range Transformer computing. The proposed SparseK Attention mechanism offers a practical solution for managing long-range dependencies in diverse applications. However, the paper does not discuss potential limitations or biases that may arise from the use of this method. Additionally, the method’s performance on different types of data and tasks, as well as its generalizability, are not thoroughly evaluated. Further research is needed to explore these aspects and ensure the robustness and applicability of the SparseK Attention mechanism."
  },
  {
    "objectID": "posts/Sparser_is_Faster_and_Less_is_More_Efficient_Sparse_Attention_for_Long_Range_Transformers/2024-06-24-Sparser_is_Faster_and_Less_is_More_Efficient_Sparse_Attention_for_Long_Range_Transformers.html#appendix",
    "href": "posts/Sparser_is_Faster_and_Less_is_More_Efficient_Sparse_Attention_for_Long_Range_Transformers/2024-06-24-Sparser_is_Faster_and_Less_is_More_Efficient_Sparse_Attention_for_Long_Range_Transformers.html#appendix",
    "title": "Sparser is Faster and Less is More: Efficient Sparse Attention for Long-Range Transformers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16747v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16747v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9535"
  },
  {
    "objectID": "posts/Improving_Multilingual_Instruction_Finetuning_via_Linguistically_Natural_and_Diverse_Datasets/2024-07-01-Improving_Multilingual_Instruction_Finetuning_via_Linguistically_Natural_and_Diverse_Datasets.html#appendix",
    "href": "posts/Improving_Multilingual_Instruction_Finetuning_via_Linguistically_Natural_and_Diverse_Datasets/2024-07-01-Improving_Multilingual_Instruction_Finetuning_via_Linguistically_Natural_and_Diverse_Datasets.html#appendix",
    "title": "Improving Multilingual Instruction Finetuning via Linguistically Natural and Diverse Datasets",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01853v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01853v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6194"
  },
  {
    "objectID": "posts/Codebook_LLMs_Adapting_Political_Science_Codebooks_for_LLM_Use_and_Adapting_LLMs_to_Follow_Codebooks/2024-07-15-Codebook_LLMs_Adapting_Political_Science_Codebooks_for_LLM_Use_and_Adapting_LLMs_to_Follow_Codebooks.html#appendix",
    "href": "posts/Codebook_LLMs_Adapting_Political_Science_Codebooks_for_LLM_Use_and_Adapting_LLMs_to_Follow_Codebooks/2024-07-15-Codebook_LLMs_Adapting_Political_Science_Codebooks_for_LLM_Use_and_Adapting_LLMs_to_Follow_Codebooks.html#appendix",
    "title": "Codebook LLMs: Adapting Political Science Codebooks for LLM Use and Adapting LLMs to Follow Codebooks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10747v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10747v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14142"
  },
  {
    "objectID": "posts/Towards_more_realistic_evaluation_of_LLM_based_code_generation_an_experimental_study_and_beyond/2024-06-11-Towards_more_realistic_evaluation_of_LLM_based_code_generation_an_experimental_study_and_beyond.html#appendix",
    "href": "posts/Towards_more_realistic_evaluation_of_LLM_based_code_generation_an_experimental_study_and_beyond/2024-06-11-Towards_more_realistic_evaluation_of_LLM_based_code_generation_an_experimental_study_and_beyond.html#appendix",
    "title": "Towards more realistic evaluation of LLM-based code generation: an experimental study and beyond",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06918v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06918v1\n\n\nTruncated\nFalse\n\n\nWord Count\n0"
  },
  {
    "objectID": "posts/When_to_Stop_Towards_Efficient_Code_Generation_in_LLMs_with_Excess_Token_Prevention/2024-07-29-When_to_Stop_Towards_Efficient_Code_Generation_in_LLMs_with_Excess_Token_Prevention.html#appendix",
    "href": "posts/When_to_Stop_Towards_Efficient_Code_Generation_in_LLMs_with_Excess_Token_Prevention/2024-07-29-When_to_Stop_Towards_Efficient_Code_Generation_in_LLMs_with_Excess_Token_Prevention.html#appendix",
    "title": "When to Stop? Towards Efficient Code Generation in LLMs with Excess Token Prevention",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20042v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20042v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12130"
  },
  {
    "objectID": "posts/Evaluating_the_Semantic_Profiling_Abilities_of_LLMs_for_Natural_Language_Utterances_in_Data_Visualization/2024-07-08-Evaluating_the_Semantic_Profiling_Abilities_of_LLMs_for_Natural_Language_Utterances_in_Data_Visualization.html#appendix",
    "href": "posts/Evaluating_the_Semantic_Profiling_Abilities_of_LLMs_for_Natural_Language_Utterances_in_Data_Visualization/2024-07-08-Evaluating_the_Semantic_Profiling_Abilities_of_LLMs_for_Natural_Language_Utterances_in_Data_Visualization.html#appendix",
    "title": "Evaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06129v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06129v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6332"
  },
  {
    "objectID": "posts/SeaLLMs_3_Open_Foundation_and_Chat_Multilingual_Large_Language_Models_for_Southeast_Asian_Languages/2024-07-29-SeaLLMs_3_Open_Foundation_and_Chat_Multilingual_Large_Language_Models_for_Southeast_Asian_Languages.html#appendix",
    "href": "posts/SeaLLMs_3_Open_Foundation_and_Chat_Multilingual_Large_Language_Models_for_Southeast_Asian_Languages/2024-07-29-SeaLLMs_3_Open_Foundation_and_Chat_Multilingual_Large_Language_Models_for_Southeast_Asian_Languages.html#appendix",
    "title": "SeaLLMs 3: Open Foundation and Chat Multilingual Large Language Models for Southeast Asian Languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19672v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19672v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5720"
  },
  {
    "objectID": "posts/Impact_of_Decoding_Methods_on_Human_Alignment_of_Conversational_LLMs/2024-07-28-Impact_of_Decoding_Methods_on_Human_Alignment_of_Conversational_LLMs.html#appendix",
    "href": "posts/Impact_of_Decoding_Methods_on_Human_Alignment_of_Conversational_LLMs/2024-07-28-Impact_of_Decoding_Methods_on_Human_Alignment_of_Conversational_LLMs.html#appendix",
    "title": "Impact of Decoding Methods on Human Alignment of Conversational LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19526v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19526v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3736"
  },
  {
    "objectID": "posts/Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model/2024-06-11-Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model.html",
    "href": "posts/Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model/2024-06-11-Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model.html",
    "title": "Paying More Attention to Source Context: Mitigating Unfaithful Translations from Large Language Model",
    "section": "",
    "text": "Summary:\nThe paper focuses on the issue of unfaithful translations in large language models (LLMs) due to insufficient focus on the source context. The authors propose three methods to address this issue: reweight attention, contrastive decoding, and target-constrained tuning. The reweight attention method adjusts the attention weight of the source context to help models focus on the source context during generation. Contrastive decoding reduces the influence of target prefixes, and target-constrained tuning encourages LLMs to avoid excessive dependence on specific target prefixes. The experimental results show that the proposed methods improve translation performance across several language pairs in the proposed unfaithful translation test sets, outperforming baseline methods and effectively reducing the phenomenon of hallucinatory and unfaithful translations.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model/2024-06-11-Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model.html#appendix",
    "href": "posts/Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model/2024-06-11-Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model.html#appendix",
    "title": "Paying More Attention to Source Context: Mitigating Unfaithful Translations from Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07036v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07036v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10716"
  },
  {
    "objectID": "posts/The_Model_Arena_for_Cross_lingual_Sentiment_Analysis_A_Comparative_Study_in_the_Era_of_Large_Language_Models/2024-06-27-The_Model_Arena_for_Cross_lingual_Sentiment_Analysis_A_Comparative_Study_in_the_Era_of_Large_Language_Models.html#appendix",
    "href": "posts/The_Model_Arena_for_Cross_lingual_Sentiment_Analysis_A_Comparative_Study_in_the_Era_of_Large_Language_Models/2024-06-27-The_Model_Arena_for_Cross_lingual_Sentiment_Analysis_A_Comparative_Study_in_the_Era_of_Large_Language_Models.html#appendix",
    "title": "The Model Arena for Cross-lingual Sentiment Analysis: A Comparative Study in the Era of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19358v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19358v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5764"
  },
  {
    "objectID": "posts/Towards_a_Personal_Health_Large_Language_Model/2024-06-10-Towards_a_Personal_Health_Large_Language_Model.html",
    "href": "posts/Towards_a_Personal_Health_Large_Language_Model/2024-06-10-Towards_a_Personal_Health_Large_Language_Model.html",
    "title": "Towards a Personal Health Large Language Model",
    "section": "",
    "text": "Summary:\nThe paper introduces Personal Health Large Language Model (PH-LLM), a version of Gemini fine-tuned for personal health and wellness. PH-LLM is evaluated on three aspects of personal health: generating personalized insights and recommendations for user goals in the domains of sleep and fitness, assessing levels of expert domain knowledge, and predicting patient-reported outcomes in sleep quality from detailed sensor information. The model is benchmarked against expert human responses and evaluated through comprehensive human and automatic evaluation of domain-specific rubrics. The results show that both Gemini Ultra 1.0 and PH-LLM are not statistically different from expert performance in fitness, while experts remain superior for sleep. However, fine-tuning PH-LLM provided significant improvements in using relevant domain knowledge and personalizing information for sleep insights. PH-LLM achieved 79% on sleep (N=629 questions) and 88% on fitness (N=99 questions) in multiple choice question examinations, both of which exceed average scores from a sample of human experts. The model also demonstrated the ability to predict self-reported assessments of sleep quality by training it to predict self-reported sleep disruption and sleep impairment outcomes from textual and multimodal encoding representations of wearable sensor data.\nMajor Findings:"
  },
  {
    "objectID": "posts/Towards_a_Personal_Health_Large_Language_Model/2024-06-10-Towards_a_Personal_Health_Large_Language_Model.html#appendix",
    "href": "posts/Towards_a_Personal_Health_Large_Language_Model/2024-06-10-Towards_a_Personal_Health_Large_Language_Model.html#appendix",
    "title": "Towards a Personal Health Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06474v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06474v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17580"
  },
  {
    "objectID": "posts/Towards_Truthful_Multilingual_Large_Language_Models_Benchmarking_and_Alignment_Strategies/2024-06-20-Towards_Truthful_Multilingual_Large_Language_Models_Benchmarking_and_Alignment_Strategies.html#appendix",
    "href": "posts/Towards_Truthful_Multilingual_Large_Language_Models_Benchmarking_and_Alignment_Strategies/2024-06-20-Towards_Truthful_Multilingual_Large_Language_Models_Benchmarking_and_Alignment_Strategies.html#appendix",
    "title": "Towards Truthful Multilingual Large Language Models: Benchmarking and Alignment Strategies",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14434v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14434v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6080"
  },
  {
    "objectID": "posts/Lottery_Ticket_Adaptation_Mitigating_Destructive_Interference_in_LLMs/2024-06-24-Lottery_Ticket_Adaptation_Mitigating_Destructive_Interference_in_LLMs.html#appendix",
    "href": "posts/Lottery_Ticket_Adaptation_Mitigating_Destructive_Interference_in_LLMs/2024-06-24-Lottery_Ticket_Adaptation_Mitigating_Destructive_Interference_in_LLMs.html#appendix",
    "title": "Lottery Ticket Adaptation: Mitigating Destructive Interference in LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16797v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16797v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9206"
  },
  {
    "objectID": "posts/Enhancing_Retrieval_and_Managing_Retrieval_A_Four_Module_Synergy_for_Improved_Quality_and_Efficiency_in_RAG_Systems/2024-07-15-Enhancing_Retrieval_and_Managing_Retrieval_A_Four_Module_Synergy_for_Improved_Quality_and_Efficiency_in_RAG_Systems.html",
    "href": "posts/Enhancing_Retrieval_and_Managing_Retrieval_A_Four_Module_Synergy_for_Improved_Quality_and_Efficiency_in_RAG_Systems/2024-07-15-Enhancing_Retrieval_and_Managing_Retrieval_A_Four_Module_Synergy_for_Improved_Quality_and_Efficiency_in_RAG_Systems.html",
    "title": "Enhancing Retrieval and Managing Retrieval: A Four-Module Synergy for Improved Quality and Efficiency in RAG Systems",
    "section": "",
    "text": "Summary:\nThe paper introduces a four-module strategy to enhance Retrieval-Augmented Generation (RAG) systems, which leverage the in-context learning capabilities of large language models (LLMs) to produce more accurate and relevant responses. The proposed modules are:\nThe effectiveness of these modules has been validated through experiments and ablation studies across six common QA datasets.\nMajor Findings:\nAnalysis and Critique:\nWhile the proposed modules show promise in improving the accuracy and efficiency of RAG systems, there are potential limitations and areas for further research. For instance, the effectiveness of the modules may vary depending on the specific LLM and knowledge base used. Additionally, the scalability of the modules to handle large-scale knowledge bases and complex queries needs to be further investigated. Furthermore, the potential for bias in the generated queries and the impact on the fairness and diversity of the retrieved information should be considered."
  },
  {
    "objectID": "posts/Enhancing_Retrieval_and_Managing_Retrieval_A_Four_Module_Synergy_for_Improved_Quality_and_Efficiency_in_RAG_Systems/2024-07-15-Enhancing_Retrieval_and_Managing_Retrieval_A_Four_Module_Synergy_for_Improved_Quality_and_Efficiency_in_RAG_Systems.html#appendix",
    "href": "posts/Enhancing_Retrieval_and_Managing_Retrieval_A_Four_Module_Synergy_for_Improved_Quality_and_Efficiency_in_RAG_Systems/2024-07-15-Enhancing_Retrieval_and_Managing_Retrieval_A_Four_Module_Synergy_for_Improved_Quality_and_Efficiency_in_RAG_Systems.html#appendix",
    "title": "Enhancing Retrieval and Managing Retrieval: A Four-Module Synergy for Improved Quality and Efficiency in RAG Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10670v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10670v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6915"
  },
  {
    "objectID": "posts/Knowledge_Graph_Enhanced_Large_Language_Models_via_Path_Selection/2024-06-19-Knowledge_Graph_Enhanced_Large_Language_Models_via_Path_Selection.html#appendix",
    "href": "posts/Knowledge_Graph_Enhanced_Large_Language_Models_via_Path_Selection/2024-06-19-Knowledge_Graph_Enhanced_Large_Language_Models_via_Path_Selection.html#appendix",
    "title": "Knowledge Graph-Enhanced Large Language Models via Path Selection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13862v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13862v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6798"
  },
  {
    "objectID": "posts/Multilingual_Trolley_Problems_for_Language_Models/2024-07-02-Multilingual_Trolley_Problems_for_Language_Models.html#appendix",
    "href": "posts/Multilingual_Trolley_Problems_for_Language_Models/2024-07-02-Multilingual_Trolley_Problems_for_Language_Models.html#appendix",
    "title": "Multilingual Trolley Problems for Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02273v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02273v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12265"
  },
  {
    "objectID": "posts/DCA_Bench_A_Benchmark_for_Dataset_Curation_Agents/2024-06-11-DCA_Bench_A_Benchmark_for_Dataset_Curation_Agents.html#appendix",
    "href": "posts/DCA_Bench_A_Benchmark_for_Dataset_Curation_Agents/2024-06-11-DCA_Bench_A_Benchmark_for_Dataset_Curation_Agents.html#appendix",
    "title": "DCA-Bench: A Benchmark for Dataset Curation Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07275v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07275v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8553"
  },
  {
    "objectID": "posts/Speculative_RAG_Enhancing_Retrieval_Augmented_Generation_through_Drafting/2024-07-11-Speculative_RAG_Enhancing_Retrieval_Augmented_Generation_through_Drafting.html#appendix",
    "href": "posts/Speculative_RAG_Enhancing_Retrieval_Augmented_Generation_through_Drafting/2024-07-11-Speculative_RAG_Enhancing_Retrieval_Augmented_Generation_through_Drafting.html#appendix",
    "title": "Speculative RAG: Enhancing Retrieval Augmented Generation through Drafting",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08223v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08223v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7800"
  },
  {
    "objectID": "posts/Fine_grained_large_scale_content_recommendations_for_MSX_sellers/2024-07-09-Fine_grained_large_scale_content_recommendations_for_MSX_sellers.html#appendix",
    "href": "posts/Fine_grained_large_scale_content_recommendations_for_MSX_sellers/2024-07-09-Fine_grained_large_scale_content_recommendations_for_MSX_sellers.html#appendix",
    "title": "Fine-grained large-scale content recommendations for MSX sellers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06910v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06910v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4936"
  },
  {
    "objectID": "posts/LLM4MSR_An_LLM_Enhanced_Paradigm_for_Multi_Scenario_Recommendation/2024-06-18-LLM4MSR_An_LLM_Enhanced_Paradigm_for_Multi_Scenario_Recommendation.html#appendix",
    "href": "posts/LLM4MSR_An_LLM_Enhanced_Paradigm_for_Multi_Scenario_Recommendation/2024-06-18-LLM4MSR_An_LLM_Enhanced_Paradigm_for_Multi_Scenario_Recommendation.html#appendix",
    "title": "LLM4MSR: An LLM-Enhanced Paradigm for Multi-Scenario Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12529v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12529v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9061"
  },
  {
    "objectID": "posts/Safe_Embed_Unveiling_the_Safety_Critical_Knowledge_of_Sentence_Encoders/2024-07-09-Safe_Embed_Unveiling_the_Safety_Critical_Knowledge_of_Sentence_Encoders.html#appendix",
    "href": "posts/Safe_Embed_Unveiling_the_Safety_Critical_Knowledge_of_Sentence_Encoders/2024-07-09-Safe_Embed_Unveiling_the_Safety_Critical_Knowledge_of_Sentence_Encoders.html#appendix",
    "title": "Safe-Embed: Unveiling the Safety-Critical Knowledge of Sentence Encoders",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06851v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06851v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7554"
  },
  {
    "objectID": "posts/An_Empirical_Study_of_Validating_Synthetic_Data_for_Formula_Generation/2024-07-15-An_Empirical_Study_of_Validating_Synthetic_Data_for_Formula_Generation.html#appendix",
    "href": "posts/An_Empirical_Study_of_Validating_Synthetic_Data_for_Formula_Generation/2024-07-15-An_Empirical_Study_of_Validating_Synthetic_Data_for_Formula_Generation.html#appendix",
    "title": "An Empirical Study of Validating Synthetic Data for Formula Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10657v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10657v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3668"
  },
  {
    "objectID": "posts/Chain_of_Agents_Large_Language_Models_Collaborating_on_Long_Context_Tasks/2024-06-04-Chain_of_Agents_Large_Language_Models_Collaborating_on_Long_Context_Tasks.html#appendix",
    "href": "posts/Chain_of_Agents_Large_Language_Models_Collaborating_on_Long_Context_Tasks/2024-06-04-Chain_of_Agents_Large_Language_Models_Collaborating_on_Long_Context_Tasks.html#appendix",
    "title": "Chain of Agents: Large Language Models Collaborating on Long-Context Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02818v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02818v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6877"
  },
  {
    "objectID": "posts/Converging_Paradigms_The_Synergy_of_Symbolic_and_Connectionist_AI_in_LLM_Empowered_Autonomous_Agents/2024-07-11-Converging_Paradigms_The_Synergy_of_Symbolic_and_Connectionist_AI_in_LLM_Empowered_Autonomous_Agents.html#appendix",
    "href": "posts/Converging_Paradigms_The_Synergy_of_Symbolic_and_Connectionist_AI_in_LLM_Empowered_Autonomous_Agents/2024-07-11-Converging_Paradigms_The_Synergy_of_Symbolic_and_Connectionist_AI_in_LLM_Empowered_Autonomous_Agents.html#appendix",
    "title": "Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08516v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08516v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6221"
  },
  {
    "objectID": "posts/Exploring_Automatic_Cryptographic_API_Misuse_Detection_in_the_Era_of_LLMs/2024-07-23-Exploring_Automatic_Cryptographic_API_Misuse_Detection_in_the_Era_of_LLMs.html",
    "href": "posts/Exploring_Automatic_Cryptographic_API_Misuse_Detection_in_the_Era_of_LLMs/2024-07-23-Exploring_Automatic_Cryptographic_API_Misuse_Detection_in_the_Era_of_LLMs.html",
    "title": "Exploring Automatic Cryptographic API Misuse Detection in the Era of LLMs",
    "section": "",
    "text": "Summary:\nThis paper explores the use of Large Language Models (LLMs) for detecting cryptographic misuses, a task that has traditionally been performed by pattern-based static analysis tools (SATs). The authors introduce a systematic evaluation framework to assess LLMs in this context, using a comprehensive dataset that includes both manually-crafted samples and real-world projects. The study reveals that LLMs can exhibit inherent instabilities, with over half of the reports being false positives. However, the authors demonstrate that a constrained problem scope and LLMs’ self-correction capability can significantly enhance the reliability of the detection. The optimized approach achieves a remarkable detection rate of nearly 90%, surpassing traditional methods and uncovering previously unknown misuses in established benchmarks. The study also identifies failure patterns that hinder LLMs’ reliability, including cryptographic knowledge deficiency and code semantics misinterpretation. The authors then develop an LLM-based workflow to examine open-source repositories, leading to the discovery of 63 real-world cryptographic misuses, of which 46 have been acknowledged by the development community.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a comprehensive evaluation of LLMs for cryptographic misuse detection, highlighting their potential and limitations. The authors’ systematic approach to evalu"
  },
  {
    "objectID": "posts/Exploring_Automatic_Cryptographic_API_Misuse_Detection_in_the_Era_of_LLMs/2024-07-23-Exploring_Automatic_Cryptographic_API_Misuse_Detection_in_the_Era_of_LLMs.html#appendix",
    "href": "posts/Exploring_Automatic_Cryptographic_API_Misuse_Detection_in_the_Era_of_LLMs/2024-07-23-Exploring_Automatic_Cryptographic_API_Misuse_Detection_in_the_Era_of_LLMs.html#appendix",
    "title": "Exploring Automatic Cryptographic API Misuse Detection in the Era of LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16576v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16576v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14418"
  },
  {
    "objectID": "posts/Model_Enhanced_LLM_Driven_VUI_Testing_of_VPA_Apps/2024-07-03-Model_Enhanced_LLM_Driven_VUI_Testing_of_VPA_Apps.html#appendix",
    "href": "posts/Model_Enhanced_LLM_Driven_VUI_Testing_of_VPA_Apps/2024-07-03-Model_Enhanced_LLM_Driven_VUI_Testing_of_VPA_Apps.html#appendix",
    "title": "Model-Enhanced LLM-Driven VUI Testing of VPA Apps",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02791v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02791v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9664"
  },
  {
    "objectID": "posts/Identifying_Performance_Sensitive_Configurations_in_Software_Systems_through_Code_Analysis_with_LLM_Agents/2024-06-18-Identifying_Performance_Sensitive_Configurations_in_Software_Systems_through_Code_Analysis_with_LLM_Agents.html#appendix",
    "href": "posts/Identifying_Performance_Sensitive_Configurations_in_Software_Systems_through_Code_Analysis_with_LLM_Agents/2024-06-18-Identifying_Performance_Sensitive_Configurations_in_Software_Systems_through_Code_Analysis_with_LLM_Agents.html#appendix",
    "title": "Identifying Performance-Sensitive Configurations in Software Systems through Code Analysis with LLM Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12806v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12806v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9569"
  },
  {
    "objectID": "posts/Identity_Driven_Hierarchical_Role_Playing_Agents/2024-07-28-Identity_Driven_Hierarchical_Role_Playing_Agents.html#appendix",
    "href": "posts/Identity_Driven_Hierarchical_Role_Playing_Agents/2024-07-28-Identity_Driven_Hierarchical_Role_Playing_Agents.html#appendix",
    "title": "Identity-Driven Hierarchical Role-Playing Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19412v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19412v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6038"
  },
  {
    "objectID": "posts/ICLGuard_Controlling_In_Context_Learning_Behavior_for_Applicability_Authorization/2024-07-09-ICLGuard_Controlling_In_Context_Learning_Behavior_for_Applicability_Authorization.html#appendix",
    "href": "posts/ICLGuard_Controlling_In_Context_Learning_Behavior_for_Applicability_Authorization/2024-07-09-ICLGuard_Controlling_In_Context_Learning_Behavior_for_Applicability_Authorization.html#appendix",
    "title": "ICLGuard: Controlling In-Context Learning Behavior for Applicability Authorization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06955v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06955v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12482"
  },
  {
    "objectID": "posts/IgnitionInnovators_at_Discharge_Me!_Chain_of_Thought_Instruction_Finetuning_Large_Language_Models_for_Discharge_Summaries/2024-07-24-IgnitionInnovators_at_Discharge_Me!_Chain_of_Thought_Instruction_Finetuning_Large_Language_Models_for_Discharge_Summaries.html#appendix",
    "href": "posts/IgnitionInnovators_at_Discharge_Me!_Chain_of_Thought_Instruction_Finetuning_Large_Language_Models_for_Discharge_Summaries/2024-07-24-IgnitionInnovators_at_Discharge_Me!_Chain_of_Thought_Instruction_Finetuning_Large_Language_Models_for_Discharge_Summaries.html#appendix",
    "title": "IgnitionInnovators at Discharge Me!: Chain-of-Thought Instruction Finetuning Large Language Models for Discharge Summaries",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17636v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17636v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3701"
  },
  {
    "objectID": "posts/InternLM_XComposer_2.5_A_Versatile_Large_Vision_Language_Model_Supporting_Long_Contextual_Input_and_Output/2024-07-03-InternLM_XComposer_2.5_A_Versatile_Large_Vision_Language_Model_Supporting_Long_Contextual_Input_and_Output.html#appendix",
    "href": "posts/InternLM_XComposer_2.5_A_Versatile_Large_Vision_Language_Model_Supporting_Long_Contextual_Input_and_Output/2024-07-03-InternLM_XComposer_2.5_A_Versatile_Large_Vision_Language_Model_Supporting_Long_Contextual_Input_and_Output.html#appendix",
    "title": "InternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03320v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03320v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6365"
  },
  {
    "objectID": "posts/Is_Your_Model_Really_A_Good_Math_Reasoner_Evaluating_Mathematical_Reasoning_with_Checklist/2024-07-11-Is_Your_Model_Really_A_Good_Math_Reasoner_Evaluating_Mathematical_Reasoning_with_Checklist.html#appendix",
    "href": "posts/Is_Your_Model_Really_A_Good_Math_Reasoner_Evaluating_Mathematical_Reasoning_with_Checklist/2024-07-11-Is_Your_Model_Really_A_Good_Math_Reasoner_Evaluating_Mathematical_Reasoning_with_Checklist.html#appendix",
    "title": "Is Your Model Really A Good Math Reasoner? Evaluating Mathematical Reasoning with Checklist",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08733v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08733v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7531"
  },
  {
    "objectID": "posts/GenSco_Can_Question_Decomposition_based_Passage_Alignment_improve_Question_Answering/2024-07-14-GenSco_Can_Question_Decomposition_based_Passage_Alignment_improve_Question_Answering.html#appendix",
    "href": "posts/GenSco_Can_Question_Decomposition_based_Passage_Alignment_improve_Question_Answering/2024-07-14-GenSco_Can_Question_Decomposition_based_Passage_Alignment_improve_Question_Answering.html#appendix",
    "title": "GenSco: Can Question Decomposition based Passage Alignment improve Question Answering?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10245v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10245v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7220"
  },
  {
    "objectID": "posts/RAGSys_Item_Cold_Start_Recommender_as_RAG_System/2024-05-27-RAGSys_Item_Cold_Start_Recommender_as_RAG_System.html#appendix",
    "href": "posts/RAGSys_Item_Cold_Start_Recommender_as_RAG_System/2024-05-27-RAGSys_Item_Cold_Start_Recommender_as_RAG_System.html#appendix",
    "title": "RAGSys: Item-Cold-Start Recommender as RAG System",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.17587v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.17587v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9098"
  },
  {
    "objectID": "posts/Hello_Again!_LLM_powered_Personalized_Agent_for_Long_term_Dialogue/2024-06-09-Hello_Again!_LLM_powered_Personalized_Agent_for_Long_term_Dialogue.html#appendix",
    "href": "posts/Hello_Again!_LLM_powered_Personalized_Agent_for_Long_term_Dialogue/2024-06-09-Hello_Again!_LLM_powered_Personalized_Agent_for_Long_term_Dialogue.html#appendix",
    "title": "Hello Again! LLM-powered Personalized Agent for Long-term Dialogue",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05925v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05925v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6818"
  },
  {
    "objectID": "posts/How_Well_Can_Knowledge_Edit_Methods_Edit_Perplexing_Knowledge/2024-06-25-How_Well_Can_Knowledge_Edit_Methods_Edit_Perplexing_Knowledge.html#appendix",
    "href": "posts/How_Well_Can_Knowledge_Edit_Methods_Edit_Perplexing_Knowledge/2024-06-25-How_Well_Can_Knowledge_Edit_Methods_Edit_Perplexing_Knowledge.html#appendix",
    "title": "How Well Can Knowledge Edit Methods Edit Perplexing Knowledge?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17253v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17253v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6890"
  },
  {
    "objectID": "posts/Adversarial_Contrastive_Decoding_Boosting_Safety_Alignment_of_Large_Language_Models_via_Opposite_Prompt_Optimization/2024-06-24-Adversarial_Contrastive_Decoding_Boosting_Safety_Alignment_of_Large_Language_Models_via_Opposite_Prompt_Optimization.html#appendix",
    "href": "posts/Adversarial_Contrastive_Decoding_Boosting_Safety_Alignment_of_Large_Language_Models_via_Opposite_Prompt_Optimization/2024-06-24-Adversarial_Contrastive_Decoding_Boosting_Safety_Alignment_of_Large_Language_Models_via_Opposite_Prompt_Optimization.html#appendix",
    "title": "Adversarial Contrastive Decoding: Boosting Safety Alignment of Large Language Models via Opposite Prompt Optimization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16743v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16743v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6567"
  },
  {
    "objectID": "posts/BiasAlert_A_Plug_and_play_Tool_for_Social_Bias_Detection_in_LLMs/2024-07-14-BiasAlert_A_Plug_and_play_Tool_for_Social_Bias_Detection_in_LLMs.html#appendix",
    "href": "posts/BiasAlert_A_Plug_and_play_Tool_for_Social_Bias_Detection_in_LLMs/2024-07-14-BiasAlert_A_Plug_and_play_Tool_for_Social_Bias_Detection_in_LLMs.html#appendix",
    "title": "BiasAlert: A Plug-and-play Tool for Social Bias Detection in LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10241v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10241v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5437"
  },
  {
    "objectID": "posts/Nicer_Than_Humans_How_do_Large_Language_Models_Behave_in_the_Prisoners_Dilemma/2024-06-19-Nicer_Than_Humans_How_do_Large_Language_Models_Behave_in_the_Prisoners_Dilemma.html#appendix",
    "href": "posts/Nicer_Than_Humans_How_do_Large_Language_Models_Behave_in_the_Prisoners_Dilemma/2024-06-19-Nicer_Than_Humans_How_do_Large_Language_Models_Behave_in_the_Prisoners_Dilemma.html#appendix",
    "title": "Nicer Than Humans: How do Large Language Models Behave in the Prisoner’s Dilemma?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13605v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13605v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7427"
  },
  {
    "objectID": "posts/Advancing_Multimodal_Large_Language_Models_in_Chart_Question_Answering_with_Visualization_Referenced_Instruction_Tuning/2024-07-29-Advancing_Multimodal_Large_Language_Models_in_Chart_Question_Answering_with_Visualization_Referenced_Instruction_Tuning.html#appendix",
    "href": "posts/Advancing_Multimodal_Large_Language_Models_in_Chart_Question_Answering_with_Visualization_Referenced_Instruction_Tuning/2024-07-29-Advancing_Multimodal_Large_Language_Models_in_Chart_Question_Answering_with_Visualization_Referenced_Instruction_Tuning.html#appendix",
    "title": "Advancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20174v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20174v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11032"
  },
  {
    "objectID": "posts/Human_AI_Collaborative_Taxonomy_Construction_A_Case_Study_in_Profession_Specific_Writing_Assistants/2024-06-26-Human_AI_Collaborative_Taxonomy_Construction_A_Case_Study_in_Profession_Specific_Writing_Assistants.html#appendix",
    "href": "posts/Human_AI_Collaborative_Taxonomy_Construction_A_Case_Study_in_Profession_Specific_Writing_Assistants/2024-06-26-Human_AI_Collaborative_Taxonomy_Construction_A_Case_Study_in_Profession_Specific_Writing_Assistants.html#appendix",
    "title": "Human-AI Collaborative Taxonomy Construction: A Case Study in Profession-Specific Writing Assistants",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18675v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18675v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3979"
  },
  {
    "objectID": "posts/Learning_to_Plan_for_Retrieval_Augmented_Large_Language_Models_from_Knowledge_Graphs/2024-06-20-Learning_to_Plan_for_Retrieval_Augmented_Large_Language_Models_from_Knowledge_Graphs.html#appendix",
    "href": "posts/Learning_to_Plan_for_Retrieval_Augmented_Large_Language_Models_from_Knowledge_Graphs/2024-06-20-Learning_to_Plan_for_Retrieval_Augmented_Large_Language_Models_from_Knowledge_Graphs.html#appendix",
    "title": "Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14282v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14282v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6692"
  },
  {
    "objectID": "posts/On_the_(In)Security_of_LLM_App_Stores/2024-07-11-On_the_(In)Security_of_LLM_App_Stores.html#major-findings",
    "href": "posts/On_the_(In)Security_of_LLM_App_Stores/2024-07-11-On_the_(In)Security_of_LLM_App_Stores.html#major-findings",
    "title": "On the (In)Security of LLM App Stores",
    "section": "Major Findings",
    "text": "Major Findings\n\nMisleading descriptions: 15,146 apps had misleading descriptions, potentially deceiving users and hiding malicious intent.\nPrivacy policy violations: 1,366 apps collected sensitive personal information against their privacy policies, posing a risk to user privacy.\nHarmful content generation: 15,996 apps generated harmful content, including hate speech, self-harm, extremism, etc.\nMalicious activities: 616 apps could be used for malicious activities, such as malware generation and phishing."
  },
  {
    "objectID": "posts/On_the_(In)Security_of_LLM_App_Stores/2024-07-11-On_the_(In)Security_of_LLM_App_Stores.html#analysis-and-critique",
    "href": "posts/On_the_(In)Security_of_LLM_App_Stores/2024-07-11-On_the_(In)Security_of_LLM_App_Stores.html#analysis-and-critique",
    "title": "On the (In)Security of LLM App Stores",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\nThe study provides a comprehensive analysis of the security concerns in LLM app stores, highlighting the need for stronger regulatory measures and improved security practices. However, the research has some limitations. The dataset used may not be entirely representative of the broader LLM app ecosystem, as it only includes six app stores. Additionally, the accuracy of the findings is influenced by the quality and completeness of the data provided by the app stores. The methodology employed for detecting abusive potential, malicious intent, and exploitable vulnerabilities relies on predefined criteria and automated tools"
  },
  {
    "objectID": "posts/On_the_(In)Security_of_LLM_App_Stores/2024-07-11-On_the_(In)Security_of_LLM_App_Stores.html#appendix",
    "href": "posts/On_the_(In)Security_of_LLM_App_Stores/2024-07-11-On_the_(In)Security_of_LLM_App_Stores.html#appendix",
    "title": "On the (In)Security of LLM App Stores",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08422v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08422v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12874"
  },
  {
    "objectID": "posts/From_Decoding_to_Meta_Generation_Inference_time_Algorithms_for_Large_Language_Models/2024-06-24-From_Decoding_to_Meta_Generation_Inference_time_Algorithms_for_Large_Language_Models.html",
    "href": "posts/From_Decoding_to_Meta_Generation_Inference_time_Algorithms_for_Large_Language_Models/2024-06-24-From_Decoding_to_Meta_Generation_Inference_time_Algorithms_for_Large_Language_Models.html",
    "title": "From Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models",
    "section": "",
    "text": "Summary:\nThe paper explores the use of large language models (LLMs) in natural language processing, focusing on three main themes: token-level generation algorithms, meta-generation algorithms, and efficient generation. Token-level generation algorithms, such as decoding algorithms, have a rich history in natural language processing and operate by sampling one token at a time or constructing a token-level search space. Recently, there has been growing interest in meta-generation algorithms, which operate on partial or full sequences and treat the LLM as a black box that is called as part of a larger generation program. These algorithms can increase the compute resources devoted to generation by making multiple model calls, augmenting the model with search algorithms, or incorporating external data sources. The paper also discusses the limitations of the Maximum A Posteriori (MAP) decoding objective in neural machine translation (NMT) and the use of reranking and transforming N-"
  },
  {
    "objectID": "posts/From_Decoding_to_Meta_Generation_Inference_time_Algorithms_for_Large_Language_Models/2024-06-24-From_Decoding_to_Meta_Generation_Inference_time_Algorithms_for_Large_Language_Models.html#appendix",
    "href": "posts/From_Decoding_to_Meta_Generation_Inference_time_Algorithms_for_Large_Language_Models/2024-06-24-From_Decoding_to_Meta_Generation_Inference_time_Algorithms_for_Large_Language_Models.html#appendix",
    "title": "From Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16838v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16838v1\n\n\nTruncated\nTrue\n\n\nWord Count\n45988"
  },
  {
    "objectID": "posts/Concise_Thoughts_Impact_of_Output_Length_on_LLM_Reasoning_and_Cost/2024-07-29-Concise_Thoughts_Impact_of_Output_Length_on_LLM_Reasoning_and_Cost.html#appendix",
    "href": "posts/Concise_Thoughts_Impact_of_Output_Length_on_LLM_Reasoning_and_Cost/2024-07-29-Concise_Thoughts_Impact_of_Output_Length_on_LLM_Reasoning_and_Cost.html#appendix",
    "title": "Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19825v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19825v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9488"
  },
  {
    "objectID": "posts/When_is_the_consistent_prediction_likely_to_be_a_correct_prediction/2024-07-08-When_is_the_consistent_prediction_likely_to_be_a_correct_prediction.html#appendix",
    "href": "posts/When_is_the_consistent_prediction_likely_to_be_a_correct_prediction/2024-07-08-When_is_the_consistent_prediction_likely_to_be_a_correct_prediction.html#appendix",
    "title": "When is the consistent prediction likely to be a correct prediction?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05778v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05778v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4435"
  },
  {
    "objectID": "posts/Enhancing_Collaborative_Semantics_of_Language_Model_Driven_Recommendations_via_Graph_Aware_Learning/2024-06-19-Enhancing_Collaborative_Semantics_of_Language_Model_Driven_Recommendations_via_Graph_Aware_Learning.html#appendix",
    "href": "posts/Enhancing_Collaborative_Semantics_of_Language_Model_Driven_Recommendations_via_Graph_Aware_Learning/2024-06-19-Enhancing_Collaborative_Semantics_of_Language_Model_Driven_Recommendations_via_Graph_Aware_Learning.html#appendix",
    "title": "Enhancing Collaborative Semantics of Language Model-Driven Recommendations via Graph-Aware Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13235v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13235v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7497"
  },
  {
    "objectID": "posts/Sentiment_Analysis_of_Lithuanian_Online_Reviews_Using_Large_Language_Models/2024-07-29-Sentiment_Analysis_of_Lithuanian_Online_Reviews_Using_Large_Language_Models.html#appendix",
    "href": "posts/Sentiment_Analysis_of_Lithuanian_Online_Reviews_Using_Large_Language_Models/2024-07-29-Sentiment_Analysis_of_Lithuanian_Online_Reviews_Using_Large_Language_Models.html#appendix",
    "title": "Sentiment Analysis of Lithuanian Online Reviews Using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19914v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19914v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8863"
  },
  {
    "objectID": "posts/Do_LLMs_Really_Adapt_to_Domains_An_Ontology_Learning_Perspective/2024-07-29-Do_LLMs_Really_Adapt_to_Domains_An_Ontology_Learning_Perspective.html#appendix",
    "href": "posts/Do_LLMs_Really_Adapt_to_Domains_An_Ontology_Learning_Perspective/2024-07-29-Do_LLMs_Really_Adapt_to_Domains_An_Ontology_Learning_Perspective.html#appendix",
    "title": "Do LLMs Really Adapt to Domains? An Ontology Learning Perspective",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19998v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19998v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7696"
  },
  {
    "objectID": "posts/Asynchronous_Large_Language_Model_Enhanced_Planner_for_Autonomous_Driving/2024-06-20-Asynchronous_Large_Language_Model_Enhanced_Planner_for_Autonomous_Driving.html#appendix",
    "href": "posts/Asynchronous_Large_Language_Model_Enhanced_Planner_for_Autonomous_Driving/2024-06-20-Asynchronous_Large_Language_Model_Enhanced_Planner_for_Autonomous_Driving.html#appendix",
    "title": "Asynchronous Large Language Model Enhanced Planner for Autonomous Driving",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14556v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14556v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9407"
  },
  {
    "objectID": "posts/Can_Large_Language_Models_Always_Solve_Easy_Problems_if_They_Can_Solve_Harder_Ones/2024-06-18-Can_Large_Language_Models_Always_Solve_Easy_Problems_if_They_Can_Solve_Harder_Ones.html#appendix",
    "href": "posts/Can_Large_Language_Models_Always_Solve_Easy_Problems_if_They_Can_Solve_Harder_Ones/2024-06-18-Can_Large_Language_Models_Always_Solve_Easy_Problems_if_They_Can_Solve_Harder_Ones.html#appendix",
    "title": "Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12809v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12809v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9280"
  },
  {
    "objectID": "posts/AI_Gadget_Kit_Integrating_Swarm_User_Interfaces_with_LLM_driven_Agents_for_Rich_Tabletop_Game_Applications/2024-07-24-AI_Gadget_Kit_Integrating_Swarm_User_Interfaces_with_LLM_driven_Agents_for_Rich_Tabletop_Game_Applications.html#appendix",
    "href": "posts/AI_Gadget_Kit_Integrating_Swarm_User_Interfaces_with_LLM_driven_Agents_for_Rich_Tabletop_Game_Applications/2024-07-24-AI_Gadget_Kit_Integrating_Swarm_User_Interfaces_with_LLM_driven_Agents_for_Rich_Tabletop_Game_Applications.html#appendix",
    "title": "AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop Game Applications",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17086v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17086v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11548"
  },
  {
    "objectID": "posts/On_Speeding_Up_Language_Model_Evaluation/2024-07-08-On_Speeding_Up_Language_Model_Evaluation.html#major-findings",
    "href": "posts/On_Speeding_Up_Language_Model_Evaluation/2024-07-08-On_Speeding_Up_Language_Model_Evaluation.html#major-findings",
    "title": "On Speeding Up Language Model Evaluation",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe proposed algorithms, UCB-E and UCB-E-LRF, can identify the top-performing method using only 5-15% of the typically needed resources, resulting in an 85-95% reduction in cost.\nThe UCB-E algorithm enjoys a theoretical guarantee that the chance of selecting the best arm converges to 100% by an exponential decay of the number of evaluations.\nThe UCB-E-LRF algorithm leverages the intrinsic low-rankness of the scoring matrices, which can be well-approximated by a low-rank matrix, to predict the remaining unobserved method-example pairs and prioritize evaluations of the pairs with large uncertainties in this prediction."
  },
  {
    "objectID": "posts/On_Speeding_Up_Language_Model_Evaluation/2024-07-08-On_Speeding_Up_Language_Model_Evaluation.html#analysis-and-critique",
    "href": "posts/On_Speeding_Up_Language_Model_Evaluation/2024-07-08-On_Speeding_Up_Language_Model_Evaluation.html#analysis-and-critique",
    "title": "On Speeding Up Language Model Evaluation",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a novel approach to reducing the cost of evaluating methods on test examples in the context of LLMs. The proposed algorithms, UCB-E and UCB-E-LRF, offer significant improvements over traditional methods, reducing the required resources by up to 95%. However, the paper does not discuss the potential limitations or biases of the proposed approach, such as the impact of the choice of low-rank factorization or the potential for overfitting to the training data. Additionally, the paper does not provide a comparison with other state-of-the-art methods for reducing the cost of evaluating LLMs. Further research is needed to evaluate the proposed approach in a broader context and to address potential limitations and biases."
  },
  {
    "objectID": "posts/On_Speeding_Up_Language_Model_Evaluation/2024-07-08-On_Speeding_Up_Language_Model_Evaluation.html#appendix",
    "href": "posts/On_Speeding_Up_Language_Model_Evaluation/2024-07-08-On_Speeding_Up_Language_Model_Evaluation.html#appendix",
    "title": "On Speeding Up Language Model Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06172v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06172v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9151"
  },
  {
    "objectID": "posts/USDC_A_Dataset_of_User_Stance_and_Dogmatism_in_Long_Conversations/2024-06-24-USDC_A_Dataset_of_User_Stance_and_Dogmatism_in_Long_Conversations.html#appendix",
    "href": "posts/USDC_A_Dataset_of_User_Stance_and_Dogmatism_in_Long_Conversations/2024-06-24-USDC_A_Dataset_of_User_Stance_and_Dogmatism_in_Long_Conversations.html#appendix",
    "title": "USDC: A Dataset of User Stance and Dogmatism in Long Conversations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16833v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16833v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9875"
  },
  {
    "objectID": "posts/Single_Codec_Single_Codebook_Speech_Codec_towards_High_Performance_Speech_Generation/2024-06-11-Single_Codec_Single_Codebook_Speech_Codec_towards_High_Performance_Speech_Generation.html#appendix",
    "href": "posts/Single_Codec_Single_Codebook_Speech_Codec_towards_High_Performance_Speech_Generation/2024-06-11-Single_Codec_Single_Codebook_Speech_Codec_towards_High_Performance_Speech_Generation.html#appendix",
    "title": "Single-Codec: Single-Codebook Speech Codec towards High-Performance Speech Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07422v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07422v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4062"
  },
  {
    "objectID": "posts/Evidence_of_a_log_scaling_law_for_political_persuasion_with_large_language_models/2024-06-20-Evidence_of_a_log_scaling_law_for_political_persuasion_with_large_language_models.html#appendix",
    "href": "posts/Evidence_of_a_log_scaling_law_for_political_persuasion_with_large_language_models/2024-06-20-Evidence_of_a_log_scaling_law_for_political_persuasion_with_large_language_models.html#appendix",
    "title": "Evidence of a log scaling law for political persuasion with large language models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14508v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14508v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9012"
  },
  {
    "objectID": "posts/Native_Design_Bias_Studying_the_Impact_of_English_Nativeness_on_Language_Model_Performance/2024-06-25-Native_Design_Bias_Studying_the_Impact_of_English_Nativeness_on_Language_Model_Performance.html#appendix",
    "href": "posts/Native_Design_Bias_Studying_the_Impact_of_English_Nativeness_on_Language_Model_Performance/2024-06-25-Native_Design_Bias_Studying_the_Impact_of_English_Nativeness_on_Language_Model_Performance.html#appendix",
    "title": "Native Design Bias: Studying the Impact of English Nativeness on Language Model Performance",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17385v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17385v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9031"
  },
  {
    "objectID": "posts/DocCGen_Document_based_Controlled_Code_Generation/2024-06-17-DocCGen_Document_based_Controlled_Code_Generation.html#appendix",
    "href": "posts/DocCGen_Document_based_Controlled_Code_Generation/2024-06-17-DocCGen_Document_based_Controlled_Code_Generation.html#appendix",
    "title": "DocCGen: Document-based Controlled Code Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11925v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11925v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9497"
  },
  {
    "objectID": "posts/Can_Watermarking_Large_Language_Models_Prevent_Copyrighted_Text_Generation_and_Hide_Training_Data/2024-07-24-Can_Watermarking_Large_Language_Models_Prevent_Copyrighted_Text_Generation_and_Hide_Training_Data.html#appendix",
    "href": "posts/Can_Watermarking_Large_Language_Models_Prevent_Copyrighted_Text_Generation_and_Hide_Training_Data/2024-07-24-Can_Watermarking_Large_Language_Models_Prevent_Copyrighted_Text_Generation_and_Hide_Training_Data.html#appendix",
    "title": "Can Watermarking Large Language Models Prevent Copyrighted Text Generation and Hide Training Data?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17417v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17417v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7878"
  },
  {
    "objectID": "posts/Self_and_Cross_Model_Distillation_for_LLMs_Effective_Methods_for_Refusal_Pattern_Alignment/2024-06-17-Self_and_Cross_Model_Distillation_for_LLMs_Effective_Methods_for_Refusal_Pattern_Alignment.html#appendix",
    "href": "posts/Self_and_Cross_Model_Distillation_for_LLMs_Effective_Methods_for_Refusal_Pattern_Alignment/2024-06-17-Self_and_Cross_Model_Distillation_for_LLMs_Effective_Methods_for_Refusal_Pattern_Alignment.html#appendix",
    "title": "Self and Cross-Model Distillation for LLMs: Effective Methods for Refusal Pattern Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11285v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11285v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6660"
  },
  {
    "objectID": "posts/DiscoveryBench_Towards_Data_Driven_Discovery_with_Large_Language_Models/2024-07-01-DiscoveryBench_Towards_Data_Driven_Discovery_with_Large_Language_Models.html#appendix",
    "href": "posts/DiscoveryBench_Towards_Data_Driven_Discovery_with_Large_Language_Models/2024-07-01-DiscoveryBench_Towards_Data_Driven_Discovery_with_Large_Language_Models.html#appendix",
    "title": "DiscoveryBench: Towards Data-Driven Discovery with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01725v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01725v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11425"
  },
  {
    "objectID": "posts/Navigating_User_Experience_of_ChatGPT_based_Conversational_Recommender_Systems_The_Effects_of_Prompt_Guidance_and_Recommendation_Domain/2024-05-22-Navigating_User_Experience_of_ChatGPT_based_Conversational_Recommender_Systems_The_Effects_of_Prompt_Guidance_and_Recommendation_Domain.html#appendix",
    "href": "posts/Navigating_User_Experience_of_ChatGPT_based_Conversational_Recommender_Systems_The_Effects_of_Prompt_Guidance_and_Recommendation_Domain/2024-05-22-Navigating_User_Experience_of_ChatGPT_based_Conversational_Recommender_Systems_The_Effects_of_Prompt_Guidance_and_Recommendation_Domain.html#appendix",
    "title": "Navigating User Experience of ChatGPT-based Conversational Recommender Systems: The Effects of Prompt Guidance and Recommendation Domain",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.13560v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.13560v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8278"
  },
  {
    "objectID": "posts/Using_Large_Language_Models_for_Generating_Smart_Contracts_for_Health_Insurance_from_Textual_Policies/2024-07-09-Using_Large_Language_Models_for_Generating_Smart_Contracts_for_Health_Insurance_from_Textual_Policies.html#appendix",
    "href": "posts/Using_Large_Language_Models_for_Generating_Smart_Contracts_for_Health_Insurance_from_Textual_Policies/2024-07-09-Using_Large_Language_Models_for_Generating_Smart_Contracts_for_Health_Insurance_from_Textual_Policies.html#appendix",
    "title": "Using Large Language Models for Generating Smart Contracts for Health Insurance from Textual Policies",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07019v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07019v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11200"
  },
  {
    "objectID": "posts/Exploring_Human_LLM_Conversations_Mental_Models_and_the_Originator_of_Toxicity/2024-07-08-Exploring_Human_LLM_Conversations_Mental_Models_and_the_Originator_of_Toxicity.html#appendix",
    "href": "posts/Exploring_Human_LLM_Conversations_Mental_Models_and_the_Originator_of_Toxicity/2024-07-08-Exploring_Human_LLM_Conversations_Mental_Models_and_the_Originator_of_Toxicity.html#appendix",
    "title": "Exploring Human-LLM Conversations: Mental Models and the Originator of Toxicity",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05977v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05977v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8762"
  },
  {
    "objectID": "posts/SecureNet_A_Comparative_Study_of_DeBERTa_and_Large_Language_Models_for_Phishing_Detection/2024-06-10-SecureNet_A_Comparative_Study_of_DeBERTa_and_Large_Language_Models_for_Phishing_Detection.html#appendix",
    "href": "posts/SecureNet_A_Comparative_Study_of_DeBERTa_and_Large_Language_Models_for_Phishing_Detection/2024-06-10-SecureNet_A_Comparative_Study_of_DeBERTa_and_Large_Language_Models_for_Phishing_Detection.html#appendix",
    "title": "SecureNet: A Comparative Study of DeBERTa and Large Language Models for Phishing Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06663v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06663v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8220"
  },
  {
    "objectID": "posts/CrowdMoGen_Zero_Shot_Text_Driven_Collective_Motion_Generation/2024-07-08-CrowdMoGen_Zero_Shot_Text_Driven_Collective_Motion_Generation.html#appendix",
    "href": "posts/CrowdMoGen_Zero_Shot_Text_Driven_Collective_Motion_Generation/2024-07-08-CrowdMoGen_Zero_Shot_Text_Driven_Collective_Motion_Generation.html#appendix",
    "title": "CrowdMoGen: Zero-Shot Text-Driven Collective Motion Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06188v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06188v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6649"
  },
  {
    "objectID": "posts/FsPONER_Few_shot_Prompt_Optimization_for_Named_Entity_Recognition_in_Domain_specific_Scenarios/2024-07-10-FsPONER_Few_shot_Prompt_Optimization_for_Named_Entity_Recognition_in_Domain_specific_Scenarios.html#appendix",
    "href": "posts/FsPONER_Few_shot_Prompt_Optimization_for_Named_Entity_Recognition_in_Domain_specific_Scenarios/2024-07-10-FsPONER_Few_shot_Prompt_Optimization_for_Named_Entity_Recognition_in_Domain_specific_Scenarios.html#appendix",
    "title": "FsPONER: Few-shot Prompt Optimization for Named Entity Recognition in Domain-specific Scenarios",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08035v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08035v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7052"
  },
  {
    "objectID": "posts/Leveraging_Hybrid_Intelligence_Towards_Sustainable_and_Energy_Efficient_Machine_Learning/2024-07-15-Leveraging_Hybrid_Intelligence_Towards_Sustainable_and_Energy_Efficient_Machine_Learning.html#appendix",
    "href": "posts/Leveraging_Hybrid_Intelligence_Towards_Sustainable_and_Energy_Efficient_Machine_Learning/2024-07-15-Leveraging_Hybrid_Intelligence_Towards_Sustainable_and_Energy_Efficient_Machine_Learning.html#appendix",
    "title": "Leveraging Hybrid Intelligence Towards Sustainable and Energy-Efficient Machine Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10580v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10580v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3800"
  },
  {
    "objectID": "posts/Session_Context_Embedding_for_Intent_Understanding_in_Product_Search/2024-06-03-Session_Context_Embedding_for_Intent_Understanding_in_Product_Search.html#appendix",
    "href": "posts/Session_Context_Embedding_for_Intent_Understanding_in_Product_Search/2024-06-03-Session_Context_Embedding_for_Intent_Understanding_in_Product_Search.html#appendix",
    "title": "Session Context Embedding for Intent Understanding in Product Search",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01702v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01702v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3385"
  },
  {
    "objectID": "posts/MIRAI_Evaluating_LLM_Agents_for_Event_Forecasting/2024-07-01-MIRAI_Evaluating_LLM_Agents_for_Event_Forecasting.html#appendix",
    "href": "posts/MIRAI_Evaluating_LLM_Agents_for_Event_Forecasting/2024-07-01-MIRAI_Evaluating_LLM_Agents_for_Event_Forecasting.html#appendix",
    "title": "MIRAI: Evaluating LLM Agents for Event Forecasting",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01231v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01231v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4187"
  },
  {
    "objectID": "posts/Quantifying_AI_Psychology_A_Psychometrics_Benchmark_for_Large_Language_Models/2024-06-25-Quantifying_AI_Psychology_A_Psychometrics_Benchmark_for_Large_Language_Models.html#appendix",
    "href": "posts/Quantifying_AI_Psychology_A_Psychometrics_Benchmark_for_Large_Language_Models/2024-06-25-Quantifying_AI_Psychology_A_Psychometrics_Benchmark_for_Large_Language_Models.html#appendix",
    "title": "Quantifying AI Psychology: A Psychometrics Benchmark for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17675v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17675v1\n\n\nTruncated\nFalse\n\n\nWord Count\n22287"
  },
  {
    "objectID": "posts/Pelican_Correcting_Hallucination_in_Vision_LLMs_via_Claim_Decomposition_and_Program_of_Thought_Verification/2024-07-02-Pelican_Correcting_Hallucination_in_Vision_LLMs_via_Claim_Decomposition_and_Program_of_Thought_Verification.html#appendix",
    "href": "posts/Pelican_Correcting_Hallucination_in_Vision_LLMs_via_Claim_Decomposition_and_Program_of_Thought_Verification/2024-07-02-Pelican_Correcting_Hallucination_in_Vision_LLMs_via_Claim_Decomposition_and_Program_of_Thought_Verification.html#appendix",
    "title": "Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02352v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02352v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8633"
  },
  {
    "objectID": "posts/Using_Pretrained_Large_Language_Model_with_Prompt_Engineering_to_Answer_Biomedical_Questions/2024-07-09-Using_Pretrained_Large_Language_Model_with_Prompt_Engineering_to_Answer_Biomedical_Questions.html#appendix",
    "href": "posts/Using_Pretrained_Large_Language_Model_with_Prompt_Engineering_to_Answer_Biomedical_Questions/2024-07-09-Using_Pretrained_Large_Language_Model_with_Prompt_Engineering_to_Answer_Biomedical_Questions.html#appendix",
    "title": "Using Pretrained Large Language Model with Prompt Engineering to Answer Biomedical Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06779v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06779v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5905"
  },
  {
    "objectID": "posts/CollectiveSFT_Scaling_Large_Language_Models_for_Chinese_Medical_Benchmark_with_Collective_Instructions_in_Healthcare/2024-07-29-CollectiveSFT_Scaling_Large_Language_Models_for_Chinese_Medical_Benchmark_with_Collective_Instructions_in_Healthcare.html#appendix",
    "href": "posts/CollectiveSFT_Scaling_Large_Language_Models_for_Chinese_Medical_Benchmark_with_Collective_Instructions_in_Healthcare/2024-07-29-CollectiveSFT_Scaling_Large_Language_Models_for_Chinese_Medical_Benchmark_with_Collective_Instructions_in_Healthcare.html#appendix",
    "title": "CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19705v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19705v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2837"
  },
  {
    "objectID": "posts/KG_FPQ_Evaluating_Factuality_Hallucination_in_LLMs_with_Knowledge_Graph_based_False_Premise_Questions/2024-07-08-KG_FPQ_Evaluating_Factuality_Hallucination_in_LLMs_with_Knowledge_Graph_based_False_Premise_Questions.html#appendix",
    "href": "posts/KG_FPQ_Evaluating_Factuality_Hallucination_in_LLMs_with_Knowledge_Graph_based_False_Premise_Questions/2024-07-08-KG_FPQ_Evaluating_Factuality_Hallucination_in_LLMs_with_Knowledge_Graph_based_False_Premise_Questions.html#appendix",
    "title": "KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05868v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05868v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7115"
  },
  {
    "objectID": "posts/SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research/2024-07-03-SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research.html#major-findings",
    "href": "posts/SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research/2024-07-03-SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research.html#major-findings",
    "title": "SemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nModels achieve above-chance classification performance, with prompt engineering significantly improving their outcome. Some models achieve close-to-clinical performance and reasoning.\nGPT-4 emerges as the top-performing model across all evaluation metrics, while Mixtral8x7B, while competitive with GPT-4 in performance, exhibits tendencies to hallucinate in source citations and provides incomplete and partially incorrect reasoning.\nGPT-3.5 and Qwen-72B exhibit higher confidence levels in their outputs, albeit with reduced correctness."
  },
  {
    "objectID": "posts/SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research/2024-07-03-SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research.html#analysis-and-critique",
    "href": "posts/SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research/2024-07-03-SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research.html#analysis-and-critique",
    "title": "SemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe study provides the first extensive benchmark comparing current SOTA LLMs in the medical domain of epilepsy and highlights their ability to leverage unstructured texts from patients’ medical history to aid diagnostic processes in health care.\nHowever, the analyses also reveal significant pitfalls with several models being overly confident while showing poor performance, as well as exhibiting citation errors and hallucinations.\nThe lack of systematic evaluation of LLMs’ understanding of specific clinical domains is a limitation, requiring large-scale annotated text-datasets, systematic investigation of prompt designs, and exploration of in-context learning strategies.\nThe study does not address the potential biases in the annotated clinical database, which could impact the performance of the LLMs.\nThe study does not provide a comparison with other machine learning or deep learning models, which could offer a more comprehensive understanding of the performance of LLMs in this domain.\nThe study does not discuss the potential ethical implications of using LLMs for epilepsy diagnosis, such as the risk of over"
  },
  {
    "objectID": "posts/SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research/2024-07-03-SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research.html#appendix",
    "href": "posts/SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research/2024-07-03-SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research.html#appendix",
    "title": "SemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03004v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03004v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6699"
  },
  {
    "objectID": "posts/On_the_Robustness_of_Language_Models_for_Tabular_Question_Answering/2024-06-18-On_the_Robustness_of_Language_Models_for_Tabular_Question_Answering.html#appendix",
    "href": "posts/On_the_Robustness_of_Language_Models_for_Tabular_Question_Answering/2024-06-18-On_the_Robustness_of_Language_Models_for_Tabular_Question_Answering.html#appendix",
    "title": "On the Robustness of Language Models for Tabular Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12719v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12719v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3509"
  },
  {
    "objectID": "posts/MrRank_Improving_Question_Answering_Retrieval_System_through_Multi_Result_Ranking_Model/2024-06-09-MrRank_Improving_Question_Answering_Retrieval_System_through_Multi_Result_Ranking_Model.html#appendix",
    "href": "posts/MrRank_Improving_Question_Answering_Retrieval_System_through_Multi_Result_Ranking_Model/2024-06-09-MrRank_Improving_Question_Answering_Retrieval_System_through_Multi_Result_Ranking_Model.html#appendix",
    "title": "MrRank: Improving Question Answering Retrieval System through Multi-Result Ranking Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05733v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05733v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5268"
  },
  {
    "objectID": "posts/FastGAS_Fast_Graph_based_Annotation_Selection_for_In_Context_Learning/2024-06-06-FastGAS_Fast_Graph_based_Annotation_Selection_for_In_Context_Learning.html#appendix",
    "href": "posts/FastGAS_Fast_Graph_based_Annotation_Selection_for_In_Context_Learning/2024-06-06-FastGAS_Fast_Graph_based_Annotation_Selection_for_In_Context_Learning.html#appendix",
    "title": "FastGAS: Fast Graph-based Annotation Selection for In-Context Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03730v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03730v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8522"
  },
  {
    "objectID": "posts/WorldAPIs_The_World_Is_Worth_How_Many_APIs_A_Thought_Experiment/2024-07-10-WorldAPIs_The_World_Is_Worth_How_Many_APIs_A_Thought_Experiment.html#appendix",
    "href": "posts/WorldAPIs_The_World_Is_Worth_How_Many_APIs_A_Thought_Experiment/2024-07-10-WorldAPIs_The_World_Is_Worth_How_Many_APIs_A_Thought_Experiment.html#appendix",
    "title": "WorldAPIs: The World Is Worth How Many APIs? A Thought Experiment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07778v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07778v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6679"
  },
  {
    "objectID": "posts/iLLM_TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement/2024-07-08-iLLM_TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement.html",
    "href": "posts/iLLM_TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement/2024-07-08-iLLM_TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement.html",
    "title": "iLLM-TSC: Integration reinforcement learning and large language model for traffic signal control policy improvement",
    "section": "",
    "text": "Summary:\nThe paper introduces a novel integration framework, iLLM-TSC, which combines a large language model (LLM) with reinforcement learning (RL) to address the limitations of existing RL-based traffic signal control (TSC) systems. These limitations include imperfect observations caused by degraded communication and the absence of rare real-life events in the reward function, such as unconsidered emergency vehicles. The iLLM-TSC framework allows RL agents to make initial decisions based on observed data, leveraging their ability to learn from specific environments. Subsequently, the LLM model refines these decisions by incorporating additional real-time information not initially used by the RL agents. This integration approach can be seamlessly integrated with existing RL-based TSC systems without requiring modifications. Extensive testing confirms that the iLLM-TSC approach reduces the average waiting time by 17.5% in degraded communication conditions compared to traditional RL methods.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/iLLM_TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement/2024-07-08-iLLM_TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement.html#appendix",
    "href": "posts/iLLM_TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement/2024-07-08-iLLM_TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement.html#appendix",
    "title": "iLLM-TSC: Integration reinforcement learning and large language model for traffic signal control policy improvement",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06025v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06025v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8535"
  },
  {
    "objectID": "posts/Leveraging_Large_Language_Models_for_Patient_Engagement_The_Power_of_Conversational_AI_in_Digital_Health/2024-06-19-Leveraging_Large_Language_Models_for_Patient_Engagement_The_Power_of_Conversational_AI_in_Digital_Health.html#appendix",
    "href": "posts/Leveraging_Large_Language_Models_for_Patient_Engagement_The_Power_of_Conversational_AI_in_Digital_Health/2024-06-19-Leveraging_Large_Language_Models_for_Patient_Engagement_The_Power_of_Conversational_AI_in_Digital_Health.html#appendix",
    "title": "Leveraging Large Language Models for Patient Engagement: The Power of Conversational AI in Digital Health",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13659v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13659v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7506"
  },
  {
    "objectID": "posts/MBBQ_A_Dataset_for_Cross_Lingual_Comparison_of_Stereotypes_in_Generative_LLMs/2024-06-11-MBBQ_A_Dataset_for_Cross_Lingual_Comparison_of_Stereotypes_in_Generative_LLMs.html#appendix",
    "href": "posts/MBBQ_A_Dataset_for_Cross_Lingual_Comparison_of_Stereotypes_in_Generative_LLMs/2024-06-11-MBBQ_A_Dataset_for_Cross_Lingual_Comparison_of_Stereotypes_in_Generative_LLMs.html#appendix",
    "title": "MBBQ: A Dataset for Cross-Lingual Comparison of Stereotypes in Generative LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07243v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07243v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10630"
  },
  {
    "objectID": "posts/A_Generic_Review_of_Integrating_Artificial_Intelligence_in_Cognitive_Behavioral_Therapy/2024-07-28-A_Generic_Review_of_Integrating_Artificial_Intelligence_in_Cognitive_Behavioral_Therapy.html",
    "href": "posts/A_Generic_Review_of_Integrating_Artificial_Intelligence_in_Cognitive_Behavioral_Therapy/2024-07-28-A_Generic_Review_of_Integrating_Artificial_Intelligence_in_Cognitive_Behavioral_Therapy.html",
    "title": "A Generic Review of Integrating Artificial Intelligence in Cognitive Behavioral Therapy",
    "section": "",
    "text": "Summary:\nCognitive Behavioral Therapy (CBT) is a widely recognized psychological intervention for addressing various mental health issues. However, the delivery of CBT faces barriers such as limited access to qualified therapists and lack of personalized interventions. Recent advancements in artificial intelligence (AI) have provided technical support for the digital transformation of CBT, with the emergence of pre-training models (PTMs) and large language models (LLMs) holding immense potential to support, augment, optimize, and automate CBT delivery.\nMajor Findings:\nAnalysis and Critique:\nWhile AI has shown promise in enhancing CBT delivery, there are several limitations and challenges that need to be addressed. These include the lack of publicly available structured datasets specifically designed for detecting cognitive distortions, the need for more comprehensive models capable of simultaneously diagnosing multiple co-occurring psychological conditions, and the challenge of making AI responses more conversational and human-like to address the perception that individuals may perceive AI-driven support as lacking genuine emotional resonance compared to human interaction. Additionally, human cross-validation is required to ensure rigor and utility in real clinical settings.\nFurthermore, there is a need for more flexible and adaptive forms of CBT to better meet the diverse needs of different patient populations. This can be achieved by exploring the use of AI in various stages of the CBT treatment process, such as pre-treatment, therapeutic process, and post-treatment. Future research should focus on addressing these challenges and exploring the potential of AI in enhancing the effectiveness and accessibility of CBT."
  },
  {
    "objectID": "posts/A_Generic_Review_of_Integrating_Artificial_Intelligence_in_Cognitive_Behavioral_Therapy/2024-07-28-A_Generic_Review_of_Integrating_Artificial_Intelligence_in_Cognitive_Behavioral_Therapy.html#appendix",
    "href": "posts/A_Generic_Review_of_Integrating_Artificial_Intelligence_in_Cognitive_Behavioral_Therapy/2024-07-28-A_Generic_Review_of_Integrating_Artificial_Intelligence_in_Cognitive_Behavioral_Therapy.html#appendix",
    "title": "A Generic Review of Integrating Artificial Intelligence in Cognitive Behavioral Therapy",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19422v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19422v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12709"
  },
  {
    "objectID": "posts/Sonnet_or_Not_Bot_Poetry_Evaluation_for_Large_Models_and_Datasets/2024-06-27-Sonnet_or_Not_Bot_Poetry_Evaluation_for_Large_Models_and_Datasets.html#appendix",
    "href": "posts/Sonnet_or_Not_Bot_Poetry_Evaluation_for_Large_Models_and_Datasets/2024-06-27-Sonnet_or_Not_Bot_Poetry_Evaluation_for_Large_Models_and_Datasets.html#appendix",
    "title": "Sonnet or Not, Bot? Poetry Evaluation for Large Models and Datasets",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18906v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18906v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3809"
  },
  {
    "objectID": "posts/Transforming_Agency._On_the_mode_of_existence_of_Large_Language_Models/2024-07-15-Transforming_Agency._On_the_mode_of_existence_of_Large_Language_Models.html",
    "href": "posts/Transforming_Agency._On_the_mode_of_existence_of_Large_Language_Models/2024-07-15-Transforming_Agency._On_the_mode_of_existence_of_Large_Language_Models.html",
    "title": "Transforming Agency. On the mode of existence of Large Language Models",
    "section": "",
    "text": "Summary:\nThe article “Transforming Agency” by Xabier E. Barandiaran and Lola S. Almendros explores the ontological characterization of Large Language Models (LLMs) like ChatGPT. The authors focus on their status as agents and explain the architecture, processing, and training procedures that enable LLMs to display their capacities. They argue that LLMs fail to meet necessary and sufficient conditions for autonomous agency in the light of embodied theories of mind. The authors conclude that ChatGPT should be characterized as an interlocutor or linguistic automaton, devoid of (autonomous) agency, but capable of engaging performatively on non-purposeful yet purpose-structured and purpose-bounded tasks. Despite their lack of sensorimotor and biological embodiment, LLMs significantly transform existing forms of human agency.\nMajor Findings:"
  },
  {
    "objectID": "posts/Transforming_Agency._On_the_mode_of_existence_of_Large_Language_Models/2024-07-15-Transforming_Agency._On_the_mode_of_existence_of_Large_Language_Models.html#appendix",
    "href": "posts/Transforming_Agency._On_the_mode_of_existence_of_Large_Language_Models/2024-07-15-Transforming_Agency._On_the_mode_of_existence_of_Large_Language_Models.html#appendix",
    "title": "Transforming Agency. On the mode of existence of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10735v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10735v1\n\n\nTruncated\nTrue\n\n\nWord Count\n36805"
  },
  {
    "objectID": "posts/Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer/2024-06-09-Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer.html",
    "href": "posts/Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer/2024-06-09-Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer.html",
    "title": "Are Large Language Models Actually Good at Text Style Transfer?",
    "section": "",
    "text": "Summary:\nThis paper evaluates the performance of large language models (LLMs) on Text Style Transfer (TST), specifically focusing on sentiment transfer and text detoxification across three languages: English, Hindi, and Bengali. The study analyzes the capabilities of pre-trained LLMs using zero-shot and few-shot prompting as well as parameter-efficient finetuning on publicly available datasets. The evaluation is conducted using automatic metrics, GPT-4, and human evaluations, revealing that while some prompted LLMs perform well in English, their performance in other languages remains average. However, finetuning significantly improves results compared to zero-shot and few-shot prompting, making them comparable to previous state-of-the-art.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer/2024-06-09-Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer.html#appendix",
    "href": "posts/Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer/2024-06-09-Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer.html#appendix",
    "title": "Are Large Language Models Actually Good at Text Style Transfer?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05885v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05885v1\n\n\nTruncated\nFalse\n\n\nWord Count\n27021"
  },
  {
    "objectID": "posts/Understanding_the_Importance_of_Evolutionary_Search_in_Automated_Heuristic_Design_with_Large_Language_Models/2024-07-15-Understanding_the_Importance_of_Evolutionary_Search_in_Automated_Heuristic_Design_with_Large_Language_Models.html",
    "href": "posts/Understanding_the_Importance_of_Evolutionary_Search_in_Automated_Heuristic_Design_with_Large_Language_Models/2024-07-15-Understanding_the_Importance_of_Evolutionary_Search_in_Automated_Heuristic_Design_with_Large_Language_Models.html",
    "title": "Understanding the Importance of Evolutionary Search in Automated Heuristic Design with Large Language Models",
    "section": "",
    "text": "Summary:\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/Understanding_the_Importance_of_Evolutionary_Search_in_Automated_Heuristic_Design_with_Large_Language_Models/2024-07-15-Understanding_the_Importance_of_Evolutionary_Search_in_Automated_Heuristic_Design_with_Large_Language_Models.html#appendix",
    "href": "posts/Understanding_the_Importance_of_Evolutionary_Search_in_Automated_Heuristic_Design_with_Large_Language_Models/2024-07-15-Understanding_the_Importance_of_Evolutionary_Search_in_Automated_Heuristic_Design_with_Large_Language_Models.html#appendix",
    "title": "Understanding the Importance of Evolutionary Search in Automated Heuristic Design with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10873v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10873v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9933"
  },
  {
    "objectID": "posts/Hey_Thats_My_Model!_Introducing_Chain__Hash_An_LLM_Fingerprinting_Technique/2024-07-15-Hey_Thats_My_Model!_Introducing_Chain__Hash_An_LLM_Fingerprinting_Technique.html#appendix",
    "href": "posts/Hey_Thats_My_Model!_Introducing_Chain__Hash_An_LLM_Fingerprinting_Technique/2024-07-15-Hey_Thats_My_Model!_Introducing_Chain__Hash_An_LLM_Fingerprinting_Technique.html#appendix",
    "title": "Hey, That’s My Model! Introducing Chain & Hash, An LLM Fingerprinting Technique",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10887v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10887v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11915"
  },
  {
    "objectID": "posts/Generating_Educational_Materials_with_Different_Levels_of_Readability_using_LLMs/2024-06-18-Generating_Educational_Materials_with_Different_Levels_of_Readability_using_LLMs.html#appendix",
    "href": "posts/Generating_Educational_Materials_with_Different_Levels_of_Readability_using_LLMs/2024-06-18-Generating_Educational_Materials_with_Different_Levels_of_Readability_using_LLMs.html#appendix",
    "title": "Generating Educational Materials with Different Levels of Readability using LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12787v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12787v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5307"
  },
  {
    "objectID": "posts/Reinforcement_Learning_from_Human_Feedback_without_Reward_Inference_Model_Free_Algorithm_and_Instance_Dependent_Analysis/2024-06-11-Reinforcement_Learning_from_Human_Feedback_without_Reward_Inference_Model_Free_Algorithm_and_Instance_Dependent_Analysis.html#appendix",
    "href": "posts/Reinforcement_Learning_from_Human_Feedback_without_Reward_Inference_Model_Free_Algorithm_and_Instance_Dependent_Analysis/2024-06-11-Reinforcement_Learning_from_Human_Feedback_without_Reward_Inference_Model_Free_Algorithm_and_Instance_Dependent_Analysis.html#appendix",
    "title": "Reinforcement Learning from Human Feedback without Reward Inference: Model-Free Algorithm and Instance-Dependent Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07455v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07455v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11143"
  },
  {
    "objectID": "posts/CityBench_Evaluating_the_Capabilities_of_Large_Language_Model_as_World_Model/2024-06-20-CityBench_Evaluating_the_Capabilities_of_Large_Language_Model_as_World_Model.html#appendix",
    "href": "posts/CityBench_Evaluating_the_Capabilities_of_Large_Language_Model_as_World_Model/2024-06-20-CityBench_Evaluating_the_Capabilities_of_Large_Language_Model_as_World_Model.html#appendix",
    "title": "CityBench: Evaluating the Capabilities of Large Language Model as World Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13945v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13945v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5783"
  },
  {
    "objectID": "posts/ByteCheckpoint_A_Unified_Checkpointing_System_for_LLM_Development/2024-07-29-ByteCheckpoint_A_Unified_Checkpointing_System_for_LLM_Development.html#appendix",
    "href": "posts/ByteCheckpoint_A_Unified_Checkpointing_System_for_LLM_Development/2024-07-29-ByteCheckpoint_A_Unified_Checkpointing_System_for_LLM_Development.html#appendix",
    "title": "ByteCheckpoint: A Unified Checkpointing System for LLM Development",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20143v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20143v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10038"
  },
  {
    "objectID": "posts/DDK_Distilling_Domain_Knowledge_for_Efficient_Large_Language_Models/2024-07-23-DDK_Distilling_Domain_Knowledge_for_Efficient_Large_Language_Models.html#appendix",
    "href": "posts/DDK_Distilling_Domain_Knowledge_for_Efficient_Large_Language_Models/2024-07-23-DDK_Distilling_Domain_Knowledge_for_Efficient_Large_Language_Models.html#appendix",
    "title": "DDK: Distilling Domain Knowledge for Efficient Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16154v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16154v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3334"
  },
  {
    "objectID": "posts/On_AI_Inspired_UI_Design/2024-06-19-On_AI_Inspired_UI_Design.html#appendix",
    "href": "posts/On_AI_Inspired_UI_Design/2024-06-19-On_AI_Inspired_UI_Design.html#appendix",
    "title": "On AI-Inspired UI-Design",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13631v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13631v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1712"
  },
  {
    "objectID": "posts/Semantic_Change_Characterization_with_LLMs_using_Rhetorics/2024-07-23-Semantic_Change_Characterization_with_LLMs_using_Rhetorics.html#appendix",
    "href": "posts/Semantic_Change_Characterization_with_LLMs_using_Rhetorics/2024-07-23-Semantic_Change_Characterization_with_LLMs_using_Rhetorics.html#appendix",
    "title": "Semantic Change Characterization with LLMs using Rhetorics",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16624v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16624v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6813"
  },
  {
    "objectID": "posts/Lifelong_Robot_Library_Learning_Bootstrapping_Composable_and_Generalizable_Skills_for_Embodied_Control_with_Language_Models/2024-06-26-Lifelong_Robot_Library_Learning_Bootstrapping_Composable_and_Generalizable_Skills_for_Embodied_Control_with_Language_Models.html#appendix",
    "href": "posts/Lifelong_Robot_Library_Learning_Bootstrapping_Composable_and_Generalizable_Skills_for_Embodied_Control_with_Language_Models/2024-06-26-Lifelong_Robot_Library_Learning_Bootstrapping_Composable_and_Generalizable_Skills_for_Embodied_Control_with_Language_Models.html#appendix",
    "title": "Lifelong Robot Library Learning: Bootstrapping Composable and Generalizable Skills for Embodied Control with Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18746v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18746v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6688"
  },
  {
    "objectID": "posts/Exploring_Mathematical_Extrapolation_of_Large_Language_Models_with_Synthetic_Data/2024-06-04-Exploring_Mathematical_Extrapolation_of_Large_Language_Models_with_Synthetic_Data.html#appendix",
    "href": "posts/Exploring_Mathematical_Extrapolation_of_Large_Language_Models_with_Synthetic_Data/2024-06-04-Exploring_Mathematical_Extrapolation_of_Large_Language_Models_with_Synthetic_Data.html#appendix",
    "title": "Exploring Mathematical Extrapolation of Large Language Models with Synthetic Data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02100v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02100v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3993"
  },
  {
    "objectID": "posts/Improving_Weak_to_Strong_Generalization_with_Reliability_Aware_Alignment/2024-06-27-Improving_Weak_to_Strong_Generalization_with_Reliability_Aware_Alignment.html",
    "href": "posts/Improving_Weak_to_Strong_Generalization_with_Reliability_Aware_Alignment/2024-06-27-Improving_Weak_to_Strong_Generalization_with_Reliability_Aware_Alignment.html",
    "title": "Improving Weak-to-Strong Generalization with Reliability-Aware Alignment",
    "section": "",
    "text": "Summary: The paper addresses the challenge of aligning strong language models with weak supervision signals, focusing on the “super-alignment” problem of aligning super-human language models with human knowledge. The authors propose an unsupervised method to enhance weak-to-strong generalization through reliability-aware alignment. This involves generating prompt variations, assessing the reliability of responses using entropy-based uncertainty and probability-based reliability metrics, and applying reliability-aware techniques such as uncertainty filtering and reliability re-weighting during the alignment process. Experimental results on four datasets demonstrated that the proposed methods effectively identified high-quality weak labels and significantly improved alignment robustness compared to baseline approaches.\nMajor Findings: 1. The proposed unsupervised method for enhancing weak-to-strong generalization through reliability-aware alignment effectively identifies high-quality weak labels and significantly improves alignment robustness compared to baseline approaches. 2. The method involves generating prompt variations, assessing the reliability of responses using entropy-based uncertainty and probability-based reliability metrics, and applying reliability-aware techniques such as uncertainty filtering and reliability re-weighting during the alignment process. 3. Experimental results on four datasets demonstrated the effectiveness of the proposed methods in improving weak-to-strong generalization.\nAnalysis and Critique: 1. The proposed method introduces significant computational overhead due to querying the weak supervisor multiple times and performing additional computations for uncertainty filtering and reliability re-weighting. This could limit the scalability of the approach, especially when dealing with large-scale datasets or complex models. 2. The overall performance of the method heavily relies on the quality of the weak supervisor. If the weak supervisor consistently provides highly unreliable or incorrect labels, the effectiveness of the reliability-aware methods may diminish. 3. The inherent subjectivity and variability in human-generated labels could introduce challenges not fully addressed by the current reliability estimation techniques. Further research is needed to tailor the methods specifically for human-annotated data, considering factors like annotator bias and expertise."
  },
  {
    "objectID": "posts/Improving_Weak_to_Strong_Generalization_with_Reliability_Aware_Alignment/2024-06-27-Improving_Weak_to_Strong_Generalization_with_Reliability_Aware_Alignment.html#appendix",
    "href": "posts/Improving_Weak_to_Strong_Generalization_with_Reliability_Aware_Alignment/2024-06-27-Improving_Weak_to_Strong_Generalization_with_Reliability_Aware_Alignment.html#appendix",
    "title": "Improving Weak-to-Strong Generalization with Reliability-Aware Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19032v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19032v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6944"
  },
  {
    "objectID": "posts/Towards_Robust_Alignment_of_Language_Models_Distributionally_Robustifying_Direct_Preference_Optimization/2024-07-10-Towards_Robust_Alignment_of_Language_Models_Distributionally_Robustifying_Direct_Preference_Optimization.html#appendix",
    "href": "posts/Towards_Robust_Alignment_of_Language_Models_Distributionally_Robustifying_Direct_Preference_Optimization/2024-07-10-Towards_Robust_Alignment_of_Language_Models_Distributionally_Robustifying_Direct_Preference_Optimization.html#appendix",
    "title": "Towards Robust Alignment of Language Models: Distributionally Robustifying Direct Preference Optimization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07880v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07880v1\n\n\nTruncated\nFalse\n\n\nWord Count\n21300"
  },
  {
    "objectID": "posts/A_Comprehensive_Survey_on_the_Security_of_Smart_Grid_Challenges_Mitigations_and_Future_Research_Opportunities/2024-07-10-A_Comprehensive_Survey_on_the_Security_of_Smart_Grid_Challenges_Mitigations_and_Future_Research_Opportunities.html",
    "href": "posts/A_Comprehensive_Survey_on_the_Security_of_Smart_Grid_Challenges_Mitigations_and_Future_Research_Opportunities/2024-07-10-A_Comprehensive_Survey_on_the_Security_of_Smart_Grid_Challenges_Mitigations_and_Future_Research_Opportunities.html",
    "title": "A Comprehensive Survey on the Security of Smart Grid: Challenges, Mitigations, and Future Research Opportunities",
    "section": "",
    "text": "Summary:\nThis study provides a comprehensive review of smart grid security, focusing on system architectures, attack methodologies, defense strategies, and future research opportunities. The review includes an in-depth analysis of various attack vectors, with a focus on new attack surfaces introduced by advanced components in smart grids. The study also examines coordinated attacks that incorporate multiple attack strategies and exploit vulnerabilities across various smart grid components to increase their adverse impact. The review then investigates innovative detection and mitigation strategies, including game theory, graph theory, blockchain, and machine learning, discussing their advancements in counteracting evolving threats and associated research challenges. The study also covers a thorough examination of widely used machine learning-based mitigation strategies, analyzing their applications and research challenges across supervised, unsupervised, semi-supervised, ensemble, and reinforcement learning. Finally, the review outlines future research directions and explores new techniques and concerns, such as large language models (LLMs) and the emerging threat of adversarial machine learning in the future of smart grid security.\nMajor Findings:\nAnalysis and Critique:\nThis study provides a comprehensive review of smart grid security, highlighting the various attack vectors and innovative detection and mitigation strategies. However, the study does not provide a detailed analysis of the effectiveness of these strategies in real-world scenarios. Additionally, the study does not discuss the potential impact of emerging technologies, such as quantum computing and edge computing, on smart grid security. Furthermore, the study does not provide a detailed"
  },
  {
    "objectID": "posts/A_Comprehensive_Survey_on_the_Security_of_Smart_Grid_Challenges_Mitigations_and_Future_Research_Opportunities/2024-07-10-A_Comprehensive_Survey_on_the_Security_of_Smart_Grid_Challenges_Mitigations_and_Future_Research_Opportunities.html#appendix",
    "href": "posts/A_Comprehensive_Survey_on_the_Security_of_Smart_Grid_Challenges_Mitigations_and_Future_Research_Opportunities/2024-07-10-A_Comprehensive_Survey_on_the_Security_of_Smart_Grid_Challenges_Mitigations_and_Future_Research_Opportunities.html#appendix",
    "title": "A Comprehensive Survey on the Security of Smart Grid: Challenges, Mitigations, and Future Research Opportunities",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07966v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07966v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20054"
  },
  {
    "objectID": "posts/Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study/2024-07-02-Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study.html",
    "href": "posts/Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study/2024-07-02-Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study.html",
    "title": "Understanding Alignment in Multimodal LLMs: A Comprehensive Study",
    "section": "",
    "text": "Summary: This academic article focuses on the challenges of hallucination in Multimodal Large Language Models (MLLMs) and the importance of alignment in MLLMs to produce responses more closely aligned with image information. The authors introduce a novel technique called Bias-Driven Hallucination Sampling (BDHS) to address the shortcomings of previous methods. BDHS limits access in the latent space via attention masking, which more directly achieves the underlying motivation of triggering the inherent bias of the underlying language model. The study also introduces a new derivative called MMHALBench-V, which incorporates GPT-4o to provide input images as additional context for evaluating model capabilities. The results of ablation experiments for BDHS show that all BDHS ablations significantly improve performance on LLaVABench-in-the-Wild compared to the DPO baseline and POVID-style"
  },
  {
    "objectID": "posts/Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study/2024-07-02-Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study.html#appendix",
    "href": "posts/Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study/2024-07-02-Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study.html#appendix",
    "title": "Understanding Alignment in Multimodal LLMs: A Comprehensive Study",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02477v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02477v1\n\n\nTruncated\nTrue\n\n\nWord Count\n29846"
  },
  {
    "objectID": "posts/Evaluation_of_Instruction_Following_Ability_for_Large_Language_Models_on_Story_Ending_Generation/2024-06-24-Evaluation_of_Instruction_Following_Ability_for_Large_Language_Models_on_Story_Ending_Generation.html#appendix",
    "href": "posts/Evaluation_of_Instruction_Following_Ability_for_Large_Language_Models_on_Story_Ending_Generation/2024-06-24-Evaluation_of_Instruction_Following_Ability_for_Large_Language_Models_on_Story_Ending_Generation.html#appendix",
    "title": "Evaluation of Instruction-Following Ability for Large Language Models on Story-Ending Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16356v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16356v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4154"
  },
  {
    "objectID": "posts/LayoutCopilot_An_LLM_powered_Multi_agent_Collaborative_Framework_for_Interactive_Analog_Layout_Design/2024-06-27-LayoutCopilot_An_LLM_powered_Multi_agent_Collaborative_Framework_for_Interactive_Analog_Layout_Design.html#appendix",
    "href": "posts/LayoutCopilot_An_LLM_powered_Multi_agent_Collaborative_Framework_for_Interactive_Analog_Layout_Design/2024-06-27-LayoutCopilot_An_LLM_powered_Multi_agent_Collaborative_Framework_for_Interactive_Analog_Layout_Design.html#appendix",
    "title": "LayoutCopilot: An LLM-powered Multi-agent Collaborative Framework for Interactive Analog Layout Design",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18873v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18873v1\n\n\nTruncated\nFalse\n\n\nWord Count\n91"
  },
  {
    "objectID": "posts/Assessing_the_Effectiveness_of_LLMs_in_Android_Application_Vulnerability_Analysis/2024-06-27-Assessing_the_Effectiveness_of_LLMs_in_Android_Application_Vulnerability_Analysis.html#appendix",
    "href": "posts/Assessing_the_Effectiveness_of_LLMs_in_Android_Application_Vulnerability_Analysis/2024-06-27-Assessing_the_Effectiveness_of_LLMs_in_Android_Application_Vulnerability_Analysis.html#appendix",
    "title": "Assessing the Effectiveness of LLMs in Android Application Vulnerability Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18894v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18894v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7395"
  },
  {
    "objectID": "posts/How_Does_Quantization_Affect_Multilingual_LLMs/2024-07-03-How_Does_Quantization_Affect_Multilingual_LLMs.html#appendix",
    "href": "posts/How_Does_Quantization_Affect_Multilingual_LLMs/2024-07-03-How_Does_Quantization_Affect_Multilingual_LLMs.html#appendix",
    "title": "How Does Quantization Affect Multilingual LLMs?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03211v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03211v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6954"
  },
  {
    "objectID": "posts/Review_LLM_Harnessing_Large_Language_Models_for_Personalized_Review_Generation/2024-07-10-Review_LLM_Harnessing_Large_Language_Models_for_Personalized_Review_Generation.html#appendix",
    "href": "posts/Review_LLM_Harnessing_Large_Language_Models_for_Personalized_Review_Generation/2024-07-10-Review_LLM_Harnessing_Large_Language_Models_for_Personalized_Review_Generation.html#appendix",
    "title": "Review-LLM: Harnessing Large Language Models for Personalized Review Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07487v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07487v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3091"
  },
  {
    "objectID": "posts/Large_Language_Models_for_Constrained_Based_Causal_Discovery/2024-06-11-Large_Language_Models_for_Constrained_Based_Causal_Discovery.html#appendix",
    "href": "posts/Large_Language_Models_for_Constrained_Based_Causal_Discovery/2024-06-11-Large_Language_Models_for_Constrained_Based_Causal_Discovery.html#appendix",
    "title": "Large Language Models for Constrained-Based Causal Discovery",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07378v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07378v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7632"
  },
  {
    "objectID": "posts/YouDream_Generating_Anatomically_Controllable_Consistent_Text_to_3D_Animals/2024-06-24-YouDream_Generating_Anatomically_Controllable_Consistent_Text_to_3D_Animals.html",
    "href": "posts/YouDream_Generating_Anatomically_Controllable_Consistent_Text_to_3D_Animals/2024-06-24-YouDream_Generating_Anatomically_Controllable_Consistent_Text_to_3D_Animals.html",
    "title": "YouDream: Generating Anatomically Controllable Consistent Text-to-3D Animals",
    "section": "",
    "text": "Summary:\nYouDream is a method for generating high-quality anatomically controllable 3D animals. It is guided by a text-to-image diffusion model controlled by 2D views of a 3D pose prior. The method generates 3D animals that are not possible to create using previous text-to-3D generative methods and preserves anatomic consistency. A fully automated pipeline for generating commonly found animals is also proposed, which uses a multi-agent LLM to adapt poses from a limited library of animal 3D poses to represent the desired animal. A user study conducted on the outcomes of YouDream demonstrates the preference of the animal models generated by this method over others.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/YouDream_Generating_Anatomically_Controllable_Consistent_Text_to_3D_Animals/2024-06-24-YouDream_Generating_Anatomically_Controllable_Consistent_Text_to_3D_Animals.html#appendix",
    "href": "posts/YouDream_Generating_Anatomically_Controllable_Consistent_Text_to_3D_Animals/2024-06-24-YouDream_Generating_Anatomically_Controllable_Consistent_Text_to_3D_Animals.html#appendix",
    "title": "YouDream: Generating Anatomically Controllable Consistent Text-to-3D Animals",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16273v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16273v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10409"
  },
  {
    "objectID": "posts/Is_Your_AI_Generated_Code_Really_Secure_Evaluating_Large_Language_Models_on_Secure_Code_Generation_with_CodeSecEval/2024-07-02-Is_Your_AI_Generated_Code_Really_Secure_Evaluating_Large_Language_Models_on_Secure_Code_Generation_with_CodeSecEval.html#appendix",
    "href": "posts/Is_Your_AI_Generated_Code_Really_Secure_Evaluating_Large_Language_Models_on_Secure_Code_Generation_with_CodeSecEval/2024-07-02-Is_Your_AI_Generated_Code_Really_Secure_Evaluating_Large_Language_Models_on_Secure_Code_Generation_with_CodeSecEval.html#appendix",
    "title": "Is Your AI-Generated Code Really Secure? Evaluating Large Language Models on Secure Code Generation with CodeSecEval",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02395v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02395v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9474"
  },
  {
    "objectID": "posts/A_Survey_on_Human_Preference_Learning_for_Large_Language_Models/2024-06-17-A_Survey_on_Human_Preference_Learning_for_Large_Language_Models.html#appendix",
    "href": "posts/A_Survey_on_Human_Preference_Learning_for_Large_Language_Models/2024-06-17-A_Survey_on_Human_Preference_Learning_for_Large_Language_Models.html#appendix",
    "title": "A Survey on Human Preference Learning for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11191v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11191v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12223"
  },
  {
    "objectID": "posts/QAEA_DR_A_Unified_Text_Augmentation_Framework_for_Dense_Retrieval/2024-07-29-QAEA_DR_A_Unified_Text_Augmentation_Framework_for_Dense_Retrieval.html#appendix",
    "href": "posts/QAEA_DR_A_Unified_Text_Augmentation_Framework_for_Dense_Retrieval/2024-07-29-QAEA_DR_A_Unified_Text_Augmentation_Framework_for_Dense_Retrieval.html#appendix",
    "title": "QAEA-DR: A Unified Text Augmentation Framework for Dense Retrieval",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20207v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20207v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9720"
  },
  {
    "objectID": "posts/Are_Large_Language_Models_Possible_to_Conduct_Cognitive_Behavioral_Therapy/2024-07-25-Are_Large_Language_Models_Possible_to_Conduct_Cognitive_Behavioral_Therapy.html#major-findings",
    "href": "posts/Are_Large_Language_Models_Possible_to_Conduct_Cognitive_Behavioral_Therapy/2024-07-25-Are_Large_Language_Models_Possible_to_Conduct_Cognitive_Behavioral_Therapy.html#major-findings",
    "title": "Are Large Language Models Possible to Conduct Cognitive Behavioral Therapy?",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe study found that LLMs can generate CBT dialogue text with high text diversity, semantic similarity, and text fluency. The models also demonstrated active questioning ability, which is crucial in CBT.\nThe integration of a CBT knowledge base with LLMs can enhance the models’ CBT counseling ability. The experimental results showed that the integrated models could generate more concise and realistic dialogue text, which is more in line with the dialogue style and pattern of a psychotherapist and a patient in real-life scenarios.\nThe study also highlighted some limitations of the experiment, such as the limited number of CBT dialogues collected and the limited knowledge base, which may not cover comprehensive knowledge of CBT. Additionally, CBT based on LLM involves the patient’s privacy and personal information, which may pose privacy and security risks."
  },
  {
    "objectID": "posts/Are_Large_Language_Models_Possible_to_Conduct_Cognitive_Behavioral_Therapy/2024-07-25-Are_Large_Language_Models_Possible_to_Conduct_Cognitive_Behavioral_Therapy.html#analysis-and-critique",
    "href": "posts/Are_Large_Language_Models_Possible_to_Conduct_Cognitive_Behavioral_Therapy/2024-07-25-Are_Large_Language_Models_Possible_to_Conduct_Cognitive_Behavioral_Therapy.html#analysis-and-critique",
    "title": "Are Large Language Models Possible to Conduct Cognitive Behavioral Therapy?",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper provides a comprehensive evaluation framework for assessing the CBT counseling ability of LLMs, which includes the evaluation of emotion tendency, structured dialogue pattern, and proactive inquiry ability. The study also explores the potential of integrating a CBT knowledge base with LLMs to enhance their CBT counseling ability. However, the paper has some limitations, such as the limited number of CBT dialogues collected and the limited knowledge base, which may not cover comprehensive knowledge of CBT. Additionally, the paper does not discuss the ethical and privacy concerns related to CBT based on LLMs. It is essential to address these concerns to ensure the safe and effective use of LLMs in psychological counseling."
  },
  {
    "objectID": "posts/Are_Large_Language_Models_Possible_to_Conduct_Cognitive_Behavioral_Therapy/2024-07-25-Are_Large_Language_Models_Possible_to_Conduct_Cognitive_Behavioral_Therapy.html#appendix",
    "href": "posts/Are_Large_Language_Models_Possible_to_Conduct_Cognitive_Behavioral_Therapy/2024-07-25-Are_Large_Language_Models_Possible_to_Conduct_Cognitive_Behavioral_Therapy.html#appendix",
    "title": "Are Large Language Models Possible to Conduct Cognitive Behavioral Therapy?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17730v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17730v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6869"
  },
  {
    "objectID": "posts/Do_LLMs_Know_When_to_NOT_Answer_Investigating_Abstention_Abilities_of_Large_Language_Models/2024-07-23-Do_LLMs_Know_When_to_NOT_Answer_Investigating_Abstention_Abilities_of_Large_Language_Models.html#appendix",
    "href": "posts/Do_LLMs_Know_When_to_NOT_Answer_Investigating_Abstention_Abilities_of_Large_Language_Models/2024-07-23-Do_LLMs_Know_When_to_NOT_Answer_Investigating_Abstention_Abilities_of_Large_Language_Models.html#appendix",
    "title": "Do LLMs Know When to NOT Answer? Investigating Abstention Abilities of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16221v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16221v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4731"
  },
  {
    "objectID": "posts/RepoQA_Evaluating_Long_Context_Code_Understanding/2024-06-10-RepoQA_Evaluating_Long_Context_Code_Understanding.html#appendix",
    "href": "posts/RepoQA_Evaluating_Long_Context_Code_Understanding/2024-06-10-RepoQA_Evaluating_Long_Context_Code_Understanding.html#appendix",
    "title": "RepoQA: Evaluating Long Context Code Understanding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06025v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06025v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2740"
  },
  {
    "objectID": "posts/Language_Conditioned_Offline_RL_for_Multi_Robot_Navigation/2024-07-29-Language_Conditioned_Offline_RL_for_Multi_Robot_Navigation.html#appendix",
    "href": "posts/Language_Conditioned_Offline_RL_for_Multi_Robot_Navigation/2024-07-29-Language_Conditioned_Offline_RL_for_Multi_Robot_Navigation.html#appendix",
    "title": "Language-Conditioned Offline RL for Multi-Robot Navigation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20164v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20164v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8102"
  },
  {
    "objectID": "posts/ScreenTK_Seamless_Detection_of_Time_Killing_Moments_Using_Continuous_Mobile_Screen_Text_Monitoring/2024-07-03-ScreenTK_Seamless_Detection_of_Time_Killing_Moments_Using_Continuous_Mobile_Screen_Text_Monitoring.html#appendix",
    "href": "posts/ScreenTK_Seamless_Detection_of_Time_Killing_Moments_Using_Continuous_Mobile_Screen_Text_Monitoring/2024-07-03-ScreenTK_Seamless_Detection_of_Time_Killing_Moments_Using_Continuous_Mobile_Screen_Text_Monitoring.html#appendix",
    "title": "ScreenTK: Seamless Detection of Time-Killing Moments Using Continuous Mobile Screen Text Monitoring",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03063v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03063v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3256"
  },
  {
    "objectID": "posts/LLM_Driven_Multimodal_Opinion_Expression_Identification/2024-06-26-LLM_Driven_Multimodal_Opinion_Expression_Identification.html#appendix",
    "href": "posts/LLM_Driven_Multimodal_Opinion_Expression_Identification/2024-06-26-LLM_Driven_Multimodal_Opinion_Expression_Identification.html#appendix",
    "title": "LLM-Driven Multimodal Opinion Expression Identification",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18088v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18088v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4217"
  },
  {
    "objectID": "posts/Aligning_Teacher_with_Student_Preferences_for_Tailored_Training_Data_Generation/2024-06-27-Aligning_Teacher_with_Student_Preferences_for_Tailored_Training_Data_Generation.html#appendix",
    "href": "posts/Aligning_Teacher_with_Student_Preferences_for_Tailored_Training_Data_Generation/2024-06-27-Aligning_Teacher_with_Student_Preferences_for_Tailored_Training_Data_Generation.html#appendix",
    "title": "Aligning Teacher with Student Preferences for Tailored Training Data Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19227v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19227v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8697"
  },
  {
    "objectID": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#major-findings",
    "href": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#major-findings",
    "title": "DomainRAG: A Chinese Benchmark for Evaluating Domain-specific Retrieval-Augmented Generation",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nExisting closed-book LLMs struggle with domain-specific questions, emphasizing the importance of RAG models for solving expert problems.\nThere is room for RAG models to improve their abilities in comprehending conversational history, analyzing structural information, denoising, processing multi-document interactions, and faithfulness in expert knowledge.\nThe use of domain-specific corpora and questions is essential to assess the ability of LLMs to effectively use external knowledge from specific fields to solve expert problems."
  },
  {
    "objectID": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#analysis-and-critique",
    "href": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#analysis-and-critique",
    "title": "DomainRAG: A Chinese Benchmark for Evaluating Domain-specific Retrieval-Augmented Generation",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper provides a comprehensive evaluation of RAG models in a domain-specific context, which is crucial for addressing the limitations of LLMs in expert and domain-specific applications.\nThe study identifies six essential abilities for RAG models, which can serve as a foundation for future research and development in this area.\nThe experimental results highlight the need for RAG models to improve their performance in complex scenarios involving various kinds of information sources.\nThe paper could benefit from a more detailed analysis of the limitations and potential biases of the evaluated LLMs and RAG models.\nFuture studies should explore more sophisticated frameworks for enhancing the performance of RAG systems and evaluate their performance in various application scenarios."
  },
  {
    "objectID": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#appendix",
    "href": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#appendix",
    "title": "DomainRAG: A Chinese Benchmark for Evaluating Domain-specific Retrieval-Augmented Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05654v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05654v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6448"
  },
  {
    "objectID": "posts/Retrieved_In_Context_Principles_from_Previous_Mistakes/2024-07-08-Retrieved_In_Context_Principles_from_Previous_Mistakes.html#appendix",
    "href": "posts/Retrieved_In_Context_Principles_from_Previous_Mistakes/2024-07-08-Retrieved_In_Context_Principles_from_Previous_Mistakes.html#appendix",
    "title": "Retrieved In-Context Principles from Previous Mistakes",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05682v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05682v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5199"
  },
  {
    "objectID": "posts/MInference_1.0_Accelerating_Pre_filling_for_Long_Context_LLMs_via_Dynamic_Sparse_Attention/2024-07-02-MInference_1.0_Accelerating_Pre_filling_for_Long_Context_LLMs_via_Dynamic_Sparse_Attention.html#appendix",
    "href": "posts/MInference_1.0_Accelerating_Pre_filling_for_Long_Context_LLMs_via_Dynamic_Sparse_Attention/2024-07-02-MInference_1.0_Accelerating_Pre_filling_for_Long_Context_LLMs_via_Dynamic_Sparse_Attention.html#appendix",
    "title": "MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02490v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02490v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10854"
  },
  {
    "objectID": "posts/Foundational_Autoraters_Taming_Large_Language_Models_for_Better_Automatic_Evaluation/2024-07-15-Foundational_Autoraters_Taming_Large_Language_Models_for_Better_Automatic_Evaluation.html#appendix",
    "href": "posts/Foundational_Autoraters_Taming_Large_Language_Models_for_Better_Automatic_Evaluation/2024-07-15-Foundational_Autoraters_Taming_Large_Language_Models_for_Better_Automatic_Evaluation.html#appendix",
    "title": "Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10817v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10817v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11875"
  },
  {
    "objectID": "posts/Limited_Out_of_Context_Knowledge_Reasoning_in_Large_Language_Models/2024-06-11-Limited_Out_of_Context_Knowledge_Reasoning_in_Large_Language_Models.html#appendix",
    "href": "posts/Limited_Out_of_Context_Knowledge_Reasoning_in_Large_Language_Models/2024-06-11-Limited_Out_of_Context_Knowledge_Reasoning_in_Large_Language_Models.html#appendix",
    "title": "Limited Out-of-Context Knowledge Reasoning in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07393v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07393v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5931"
  },
  {
    "objectID": "posts/Refactoring_to_Pythonic_Idioms_A_Hybrid_Knowledge_Driven_Approach_Leveraging_Large_Language_Models/2024-06-06-Refactoring_to_Pythonic_Idioms_A_Hybrid_Knowledge_Driven_Approach_Leveraging_Large_Language_Models.html#appendix",
    "href": "posts/Refactoring_to_Pythonic_Idioms_A_Hybrid_Knowledge_Driven_Approach_Leveraging_Large_Language_Models/2024-06-06-Refactoring_to_Pythonic_Idioms_A_Hybrid_Knowledge_Driven_Approach_Leveraging_Large_Language_Models.html#appendix",
    "title": "Refactoring to Pythonic Idioms: A Hybrid Knowledge-Driven Approach Leveraging Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03660v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03660v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14284"
  },
  {
    "objectID": "posts/When_Box_Meets_Graph_Neural_Network_in_Tag_aware_Recommendation/2024-06-17-When_Box_Meets_Graph_Neural_Network_in_Tag_aware_Recommendation.html#appendix",
    "href": "posts/When_Box_Meets_Graph_Neural_Network_in_Tag_aware_Recommendation/2024-06-17-When_Box_Meets_Graph_Neural_Network_in_Tag_aware_Recommendation.html#appendix",
    "title": "When Box Meets Graph Neural Network in Tag-aware Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12020v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12020v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8318"
  },
  {
    "objectID": "posts/Can_I_understand_what_I_create_Self_Knowledge_Evaluation_of_Large_Language_Models/2024-06-10-Can_I_understand_what_I_create_Self_Knowledge_Evaluation_of_Large_Language_Models.html#appendix",
    "href": "posts/Can_I_understand_what_I_create_Self_Knowledge_Evaluation_of_Large_Language_Models/2024-06-10-Can_I_understand_what_I_create_Self_Knowledge_Evaluation_of_Large_Language_Models.html#appendix",
    "title": "Can I understand what I create? Self-Knowledge Evaluation of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06140v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06140v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7449"
  },
  {
    "objectID": "posts/Building_AI_Agents_for_Autonomous_Clouds_Challenges_and_Design_Principles/2024-07-16-Building_AI_Agents_for_Autonomous_Clouds_Challenges_and_Design_Principles.html#appendix",
    "href": "posts/Building_AI_Agents_for_Autonomous_Clouds_Challenges_and_Design_Principles/2024-07-16-Building_AI_Agents_for_Autonomous_Clouds_Challenges_and_Design_Principles.html#appendix",
    "title": "Building AI Agents for Autonomous Clouds: Challenges and Design Principles",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.12165v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.12165v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7552"
  },
  {
    "objectID": "posts/TheoremLlama_Transforming_General_Purpose_LLMs_into_Lean4_Experts/2024-07-03-TheoremLlama_Transforming_General_Purpose_LLMs_into_Lean4_Experts.html#appendix",
    "href": "posts/TheoremLlama_Transforming_General_Purpose_LLMs_into_Lean4_Experts/2024-07-03-TheoremLlama_Transforming_General_Purpose_LLMs_into_Lean4_Experts.html#appendix",
    "title": "TheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03203v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03203v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8361"
  },
  {
    "objectID": "posts/Single_Character_Perturbations_Break_LLM_Alignment/2024-07-03-Single_Character_Perturbations_Break_LLM_Alignment.html",
    "href": "posts/Single_Character_Perturbations_Break_LLM_Alignment/2024-07-03-Single_Character_Perturbations_Break_LLM_Alignment.html",
    "title": "Single Character Perturbations Break LLM Alignment",
    "section": "",
    "text": "Summary:\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/Single_Character_Perturbations_Break_LLM_Alignment/2024-07-03-Single_Character_Perturbations_Break_LLM_Alignment.html#appendix",
    "href": "posts/Single_Character_Perturbations_Break_LLM_Alignment/2024-07-03-Single_Character_Perturbations_Break_LLM_Alignment.html#appendix",
    "title": "Single Character Perturbations Break LLM Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03232v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03232v1\n\n\nTruncated\nFalse\n\n\nWord Count\n21366"
  },
  {
    "objectID": "posts/Progressive_Query_Expansion_for_Retrieval_Over_Cost_constrained_Data_Sources/2024-06-11-Progressive_Query_Expansion_for_Retrieval_Over_Cost_constrained_Data_Sources.html#appendix",
    "href": "posts/Progressive_Query_Expansion_for_Retrieval_Over_Cost_constrained_Data_Sources/2024-06-11-Progressive_Query_Expansion_for_Retrieval_Over_Cost_constrained_Data_Sources.html#appendix",
    "title": "Progressive Query Expansion for Retrieval Over Cost-constrained Data Sources",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07136v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07136v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4716"
  },
  {
    "objectID": "posts/GRUtopia_Dream_General_Robots_in_a_City_at_Scale/2024-07-15-GRUtopia_Dream_General_Robots_in_a_City_at_Scale.html#major-findings",
    "href": "posts/GRUtopia_Dream_General_Robots_in_a_City_at_Scale/2024-07-15-GRUtopia_Dream_General_Robots_in_a_City_at_Scale.html#major-findings",
    "title": "GRUtopia: Dream General Robots in a City at Scale",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nGRScenes significantly expands the scope of environments in which robots can operate, covering both indoor and outdoor environments, including restaurants, supermarkets, offices, libraries, museums, hospitals, exhibition halls, amusement parks, and homes.\nGRResidents, the NPC system, introduces a new dimension to human-robot interaction within simulations. NPCs are motivated by the goal that robots are ultimately meant to serve humans, and interaction with users is often helpful or necessary for task completion.\nGRBench serves as a comprehensive evaluation tool for assessing robot agents’ capabilities. It comprises three benchmarks: Object Loco-Navigation, Social Loco-Navigation, and Loco-Manipulation, designed to progressively increase in difficulty, demanding enhanced robotic skills."
  },
  {
    "objectID": "posts/GRUtopia_Dream_General_Robots_in_a_City_at_Scale/2024-07-15-GRUtopia_Dream_General_Robots_in_a_City_at_Scale.html#analysis-and-critique",
    "href": "posts/GRUtopia_Dream_General_Robots_in_a_City_at_Scale/2024-07-15-GRUtopia_Dream_General_Robots_in_a_City_at_Scale.html#analysis-and-critique",
    "title": "GRUtopia: Dream General Robots in a City at Scale",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a comprehensive platform for training and evaluating embodied agents in a simulated environment. The large-scale scene dataset and diverse NPC system provide a rich and realistic setting for testing various robots. However, the paper does not discuss the potential limitations or challenges of deploying these agents in real-world scenarios. Additionally, the evaluation metrics used in the benchmark may not fully capture the complexity and nuances of real-world tasks. Further research is needed to address these issues and validate the effectiveness of the proposed platform in real-world applications."
  },
  {
    "objectID": "posts/GRUtopia_Dream_General_Robots_in_a_City_at_Scale/2024-07-15-GRUtopia_Dream_General_Robots_in_a_City_at_Scale.html#appendix",
    "href": "posts/GRUtopia_Dream_General_Robots_in_a_City_at_Scale/2024-07-15-GRUtopia_Dream_General_Robots_in_a_City_at_Scale.html#appendix",
    "title": "GRUtopia: Dream General Robots in a City at Scale",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10943v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10943v1\n\n\nTruncated\nFalse\n\n\nWord Count\n21853"
  },
  {
    "objectID": "posts/Open_Generative_Large_Language_Models_for_Galician/2024-06-19-Open_Generative_Large_Language_Models_for_Galician.html#appendix",
    "href": "posts/Open_Generative_Large_Language_Models_for_Galician/2024-06-19-Open_Generative_Large_Language_Models_for_Galician.html#appendix",
    "title": "Open Generative Large Language Models for Galician",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13893v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13893v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6815"
  },
  {
    "objectID": "posts/Advancing_Annotation_of_Stance_in_Social_Media_Posts_A_Comparative_Analysis_of_Large_Language_Models_and_Crowd_Sourcing/2024-06-11-Advancing_Annotation_of_Stance_in_Social_Media_Posts_A_Comparative_Analysis_of_Large_Language_Models_and_Crowd_Sourcing.html#appendix",
    "href": "posts/Advancing_Annotation_of_Stance_in_Social_Media_Posts_A_Comparative_Analysis_of_Large_Language_Models_and_Crowd_Sourcing/2024-06-11-Advancing_Annotation_of_Stance_in_Social_Media_Posts_A_Comparative_Analysis_of_Large_Language_Models_and_Crowd_Sourcing.html#appendix",
    "title": "Advancing Annotation of Stance in Social Media Posts: A Comparative Analysis of Large Language Models and Crowd Sourcing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07483v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07483v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7463"
  },
  {
    "objectID": "posts/InverseCoder_Unleashing_the_Power_of_Instruction_Tuned_Code_LLMs_with_Inverse_Instruct/2024-07-08-InverseCoder_Unleashing_the_Power_of_Instruction_Tuned_Code_LLMs_with_Inverse_Instruct.html#appendix",
    "href": "posts/InverseCoder_Unleashing_the_Power_of_Instruction_Tuned_Code_LLMs_with_Inverse_Instruct/2024-07-08-InverseCoder_Unleashing_the_Power_of_Instruction_Tuned_Code_LLMs_with_Inverse_Instruct.html#appendix",
    "title": "InverseCoder: Unleashing the Power of Instruction-Tuned Code LLMs with Inverse-Instruct",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05700v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05700v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6732"
  },
  {
    "objectID": "posts/Enhancing_Data_Privacy_in_Large_Language_Models_through_Private_Association_Editing/2024-06-26-Enhancing_Data_Privacy_in_Large_Language_Models_through_Private_Association_Editing.html",
    "href": "posts/Enhancing_Data_Privacy_in_Large_Language_Models_through_Private_Association_Editing/2024-06-26-Enhancing_Data_Privacy_in_Large_Language_Models_through_Private_Association_Editing.html",
    "title": "Enhancing Data Privacy in Large Language Models through Private Association Editing",
    "section": "",
    "text": "Summary:\nThe paper introduces Private Association Editing (PAE), a novel defense approach for private data leakage in Large Language Models (LLMs). PAE is designed to effectively remove Personally Identifiable Information (PII) without retraining the model. The approach consists of a four-step procedure: detecting memorized PII, applying PAE cards to mitigate memorization of private data, verifying resilience to targeted data extraction (TDE) attacks, and ensuring consistency in the post-edit LLMs. The versatility and efficiency of PAE, which allows for batch modifications, significantly enhance data privacy in LLMs. Experimental results demonstrate the effectiveness of PAE in mitigating private data leakage.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/Enhancing_Data_Privacy_in_Large_Language_Models_through_Private_Association_Editing/2024-06-26-Enhancing_Data_Privacy_in_Large_Language_Models_through_Private_Association_Editing.html#appendix",
    "href": "posts/Enhancing_Data_Privacy_in_Large_Language_Models_through_Private_Association_Editing/2024-06-26-Enhancing_Data_Privacy_in_Large_Language_Models_through_Private_Association_Editing.html#appendix",
    "title": "Enhancing Data Privacy in Large Language Models through Private Association Editing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18221v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18221v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7076"
  },
  {
    "objectID": "posts/What_Makes_and_Breaks_Safety_Fine_tuning_Mechanistic_Study/2024-07-14-What_Makes_and_Breaks_Safety_Fine_tuning_Mechanistic_Study.html",
    "href": "posts/What_Makes_and_Breaks_Safety_Fine_tuning_Mechanistic_Study/2024-07-14-What_Makes_and_Breaks_Safety_Fine_tuning_Mechanistic_Study.html",
    "title": "What Makes and Breaks Safety Fine-tuning? Mechanistic Study",
    "section": "",
    "text": "Summary:\nThe paper “What Makes and Breaks Safety Fine-tuning? A Mechanistic Study” investigates the factors contributing to the safety of large language models (LLMs) through safety fine-tuning. The authors design a synthetic data generation framework to capture the interaction between the task and specific concepts. They examine three safety fine-tuning methods: supervised safety fine-tuning, direct preference optimization, and unlearning. The study reveals that these methods minimally transform MLP weights to align unsafe inputs into the null space of the weights, resulting in a clustering of inputs based on their safety. However, when an adversarial input is provided, its activations are closer to safer samples, causing the model to process it as if it were safe.\nMajor Findings:"
  },
  {
    "objectID": "posts/What_Makes_and_Breaks_Safety_Fine_tuning_Mechanistic_Study/2024-07-14-What_Makes_and_Breaks_Safety_Fine_tuning_Mechanistic_Study.html#appendix",
    "href": "posts/What_Makes_and_Breaks_Safety_Fine_tuning_Mechanistic_Study/2024-07-14-What_Makes_and_Breaks_Safety_Fine_tuning_Mechanistic_Study.html#appendix",
    "title": "What Makes and Breaks Safety Fine-tuning? Mechanistic Study",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10264v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10264v1\n\n\nTruncated\nTrue\n\n\nWord Count\n62036"
  },
  {
    "objectID": "posts/Improving_Visual_Storytelling_with_Multimodal_Large_Language_Models/2024-07-02-Improving_Visual_Storytelling_with_Multimodal_Large_Language_Models.html#appendix",
    "href": "posts/Improving_Visual_Storytelling_with_Multimodal_Large_Language_Models/2024-07-02-Improving_Visual_Storytelling_with_Multimodal_Large_Language_Models.html#appendix",
    "title": "Improving Visual Storytelling with Multimodal Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02586v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02586v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3182"
  },
  {
    "objectID": "posts/Do_LLMs_Recognize_me_When_I_is_not_me_Assessment_of_LLMs_Understanding_of_Turkish_Indexical_Pronouns_in_Indexical_Shift_Contexts/2024-06-08-Do_LLMs_Recognize_me_When_I_is_not_me_Assessment_of_LLMs_Understanding_of_Turkish_Indexical_Pronouns_in_Indexical_Shift_Contexts.html#appendix",
    "href": "posts/Do_LLMs_Recognize_me_When_I_is_not_me_Assessment_of_LLMs_Understanding_of_Turkish_Indexical_Pronouns_in_Indexical_Shift_Contexts/2024-06-08-Do_LLMs_Recognize_me_When_I_is_not_me_Assessment_of_LLMs_Understanding_of_Turkish_Indexical_Pronouns_in_Indexical_Shift_Contexts.html#appendix",
    "title": "Do LLMs Recognize me, When I is not me: Assessment of LLMs Understanding of Turkish Indexical Pronouns in Indexical Shift Contexts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05569v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05569v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5917"
  },
  {
    "objectID": "posts/Learning_to_Ask_Informative_Questions_Enhancing_LLMs_with_Preference_Optimization_and_Expected_Information_Gain/2024-06-25-Learning_to_Ask_Informative_Questions_Enhancing_LLMs_with_Preference_Optimization_and_Expected_Information_Gain.html#appendix",
    "href": "posts/Learning_to_Ask_Informative_Questions_Enhancing_LLMs_with_Preference_Optimization_and_Expected_Information_Gain/2024-06-25-Learning_to_Ask_Informative_Questions_Enhancing_LLMs_with_Preference_Optimization_and_Expected_Information_Gain.html#appendix",
    "title": "Learning to Ask Informative Questions: Enhancing LLMs with Preference Optimization and Expected Information Gain",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17453v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17453v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5253"
  },
  {
    "objectID": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#major-findings",
    "href": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#major-findings",
    "title": "Teaching Language Models to Self-Improve by Learning from Language Feedback",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nSRT significantly outperforms strong baselines across diverse tasks and model sizes, with an average performance enhancement of 3.7 to 4.0 points.\nWhen applied to a 70B parameter model, SRT increases the win rate from 9.6% to 25.8% on the AlpacaEval 2.0 benchmark, surpassing well-established systems such as GPT-4-0314, Claude 2, and Gemini.\nThe success of SRT primarily stems from its language feedback feature, which identifies weak areas and offers valuable suggestions for improvement."
  },
  {
    "objectID": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#analysis-and-critique",
    "href": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#analysis-and-critique",
    "title": "Teaching Language Models to Self-Improve by Learning from Language Feedback",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper presents a novel and promising approach to aligning language models using self-refinement and language feedback.\nThe empirical evaluations demonstrate the effectiveness of SRT in improving model performance across various tasks and model sizes.\nThe paper highlights the crucial role of language feedback in the success of SRT, suggesting potential for further exploration in this direction.\nHowever, the paper does not discuss potential limitations or challenges associated with the SRT method, such as the computational cost of generating feedback and refinements or the potential for overfitting to the feedback.\nAdditionally, the paper does not address the potential for biases in the feedback and refinements generated by the more advanced model, which could impact the alignment of the base model.\nFuture work could explore these limitations and potential solutions to improve the SRT method."
  },
  {
    "objectID": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#appendix",
    "href": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#appendix",
    "title": "Teaching Language Models to Self-Improve by Learning from Language Feedback",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07168v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07168v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6361"
  },
  {
    "objectID": "posts/TCSR_SQL_Towards_Table_Content_aware_Text_to_SQL_with_Self_retrieval/2024-07-01-TCSR_SQL_Towards_Table_Content_aware_Text_to_SQL_with_Self_retrieval.html#appendix",
    "href": "posts/TCSR_SQL_Towards_Table_Content_aware_Text_to_SQL_with_Self_retrieval/2024-07-01-TCSR_SQL_Towards_Table_Content_aware_Text_to_SQL_with_Self_retrieval.html#appendix",
    "title": "TCSR-SQL: Towards Table Content-aware Text-to-SQL with Self-retrieval",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01183v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01183v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10323"
  },
  {
    "objectID": "posts/RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold/2024-06-20-RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold.html",
    "href": "posts/RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold/2024-06-20-RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold.html",
    "title": "RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold",
    "section": "",
    "text": "Summary:\nThe paper investigates the use of synthetic data for improving math reasoning capabilities of large language models (LLMs). The authors find that while the typical approach of collecting new questions and corresponding positive (correct) solutions from capable models like GPT-4/Gemini-1.5 presents underwhelming data scaling, the sample efficiency of the same data can be improved up to 2× by sampling more positive traces from the 7B sized models SFT-ed on the original data. However, training on positive self-generated synthetic data alone often amplifies the model’s dependence on spurious steps, that erroneously appear to lead to a good solution but do not generalize to novel problems and hurt test performance.\nThe authors show that negative (incorrect) traces sampled from the same SFT model can be used to address the failure modes of training on only positive data. In particular, negative data can be used to estimate advantage values for every step, and using these advantage estimates via RL enables us to address this problem. The authors show how the advantages can be used implicitly by preference optimization objectives. They show how training on an instance of this objective leads to 8× improvements in sample efficiency of the synthetic data used.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold/2024-06-20-RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold.html#appendix",
    "href": "posts/RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold/2024-06-20-RL_on_Incorrect_Synthetic_Data_Scales_the_Efficiency_of_LLM_Math_Reasoning_by_Eight_Fold.html#appendix",
    "title": "RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14532v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14532v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15465"
  },
  {
    "objectID": "posts/BIGbench_A_Unified_Benchmark_for_Social_Bias_in_Text_to_Image_Generative_Models_Based_on_Multi_modal_LLM/2024-07-21-BIGbench_A_Unified_Benchmark_for_Social_Bias_in_Text_to_Image_Generative_Models_Based_on_Multi_modal_LLM.html#appendix",
    "href": "posts/BIGbench_A_Unified_Benchmark_for_Social_Bias_in_Text_to_Image_Generative_Models_Based_on_Multi_modal_LLM/2024-07-21-BIGbench_A_Unified_Benchmark_for_Social_Bias_in_Text_to_Image_Generative_Models_Based_on_Multi_modal_LLM.html#appendix",
    "title": "BIGbench: A Unified Benchmark for Social Bias in Text-to-Image Generative Models Based on Multi-modal LLM",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.15240v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.15240v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6160"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Bayesian beagle",
    "section": "",
    "text": "Welcome to the Bayesian beagle blog! This project is a unique intersection of machine learning and scientific communication, providing a platform where readers can quickly get insights from the latest research papers hosted on ArXiv. Utilizing state-of-the-art Large Language Models (LLMs), our system generates concise, comprehensible summaries of complex research articles, covering a wide array of disciplines.\nAll content is LLM generated. Assume skepticism and verify in the original paper as LLM models are imperfect and can struggle under certain circumstances.\nOur blog is built using Quarto and then published with Netlify.\n\n\n\n\ngraph LR\n    A[\"Download weekly Arxiv articles\"] --&gt; B[\"Predict and Filter LLM topic\"]\n    B --&gt; C[\"Summarize short docs\"]\n    B --&gt; D[\"Summarize by Map-Reduce long docs\"]\n    C --&gt; E[\"Update website with summaries weekly\"]\n    D --&gt; E"
  },
  {
    "objectID": "posts/The_FineWeb_Datasets_Decanting_the_Web_for_the_Finest_Text_Data_at_Scale/2024-06-25-The_FineWeb_Datasets_Decanting_the_Web_for_the_Finest_Text_Data_at_Scale.html#appendix",
    "href": "posts/The_FineWeb_Datasets_Decanting_the_Web_for_the_Finest_Text_Data_at_Scale/2024-06-25-The_FineWeb_Datasets_Decanting_the_Web_for_the_Finest_Text_Data_at_Scale.html#appendix",
    "title": "The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17557v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17557v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10755"
  },
  {
    "objectID": "posts/Revisiting_the_Impact_of_Pursuing_Modularity_for_Code_Generation/2024-07-16-Revisiting_the_Impact_of_Pursuing_Modularity_for_Code_Generation.html#appendix",
    "href": "posts/Revisiting_the_Impact_of_Pursuing_Modularity_for_Code_Generation/2024-07-16-Revisiting_the_Impact_of_Pursuing_Modularity_for_Code_Generation.html#appendix",
    "title": "Revisiting the Impact of Pursuing Modularity for Code Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.11406v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.11406v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3658"
  },
  {
    "objectID": "posts/Directed_Domain_Fine_Tuning_Tailoring_Separate_Modalities_for_Specific_Training_Tasks/2024-06-24-Directed_Domain_Fine_Tuning_Tailoring_Separate_Modalities_for_Specific_Training_Tasks.html#appendix",
    "href": "posts/Directed_Domain_Fine_Tuning_Tailoring_Separate_Modalities_for_Specific_Training_Tasks/2024-06-24-Directed_Domain_Fine_Tuning_Tailoring_Separate_Modalities_for_Specific_Training_Tasks.html#appendix",
    "title": "Directed Domain Fine-Tuning: Tailoring Separate Modalities for Specific Training Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16346v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16346v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6463"
  },
  {
    "objectID": "posts/Can_LLMs_Reason_in_the_Wild_with_Programs/2024-06-19-Can_LLMs_Reason_in_the_Wild_with_Programs.html#appendix",
    "href": "posts/Can_LLMs_Reason_in_the_Wild_with_Programs/2024-06-19-Can_LLMs_Reason_in_the_Wild_with_Programs.html#appendix",
    "title": "Can LLMs Reason in the Wild with Programs?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13764v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13764v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13142"
  },
  {
    "objectID": "posts/Data_Augmentation_of_Multi_turn_Psychological_Dialogue_via_Knowledge_driven_Progressive_Thought_Prompting/2024-06-24-Data_Augmentation_of_Multi_turn_Psychological_Dialogue_via_Knowledge_driven_Progressive_Thought_Prompting.html#appendix",
    "href": "posts/Data_Augmentation_of_Multi_turn_Psychological_Dialogue_via_Knowledge_driven_Progressive_Thought_Prompting/2024-06-24-Data_Augmentation_of_Multi_turn_Psychological_Dialogue_via_Knowledge_driven_Progressive_Thought_Prompting.html#appendix",
    "title": "Data Augmentation of Multi-turn Psychological Dialogue via Knowledge-driven Progressive Thought Prompting",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16567v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16567v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4719"
  },
  {
    "objectID": "posts/By_My_Eyes_Grounding_Multimodal_Large_Language_Models_with_Sensor_Data_via_Visual_Prompting/2024-07-15-By_My_Eyes_Grounding_Multimodal_Large_Language_Models_with_Sensor_Data_via_Visual_Prompting.html#appendix",
    "href": "posts/By_My_Eyes_Grounding_Multimodal_Large_Language_Models_with_Sensor_Data_via_Visual_Prompting/2024-07-15-By_My_Eyes_Grounding_Multimodal_Large_Language_Models_with_Sensor_Data_via_Visual_Prompting.html#appendix",
    "title": "By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10385v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10385v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7689"
  },
  {
    "objectID": "posts/Jump_Starting_Bandits_with_LLM_Generated_Prior_Knowledge/2024-06-27-Jump_Starting_Bandits_with_LLM_Generated_Prior_Knowledge.html#appendix",
    "href": "posts/Jump_Starting_Bandits_with_LLM_Generated_Prior_Knowledge/2024-06-27-Jump_Starting_Bandits_with_LLM_Generated_Prior_Knowledge.html#appendix",
    "title": "Jump Starting Bandits with LLM-Generated Prior Knowledge",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19317v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19317v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8270"
  },
  {
    "objectID": "posts/Defending_Against_Social_Engineering_Attacks_in_the_Age_of_LLMs/2024-06-18-Defending_Against_Social_Engineering_Attacks_in_the_Age_of_LLMs.html#appendix",
    "href": "posts/Defending_Against_Social_Engineering_Attacks_in_the_Age_of_LLMs/2024-06-18-Defending_Against_Social_Engineering_Attacks_in_the_Age_of_LLMs.html#appendix",
    "title": "Defending Against Social Engineering Attacks in the Age of LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12263v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12263v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7850"
  },
  {
    "objectID": "posts/CHOP_Integrating_ChatGPT_into_EFL_Oral_Presentation_Practice/2024-07-10-CHOP_Integrating_ChatGPT_into_EFL_Oral_Presentation_Practice.html#appendix",
    "href": "posts/CHOP_Integrating_ChatGPT_into_EFL_Oral_Presentation_Practice/2024-07-10-CHOP_Integrating_ChatGPT_into_EFL_Oral_Presentation_Practice.html#appendix",
    "title": "CHOP: Integrating ChatGPT into EFL Oral Presentation Practice",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07393v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07393v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6286"
  },
  {
    "objectID": "posts/VGBench_Evaluating_Large_Language_Models_on_Vector_Graphics_Understanding_and_Generation/2024-07-15-VGBench_Evaluating_Large_Language_Models_on_Vector_Graphics_Understanding_and_Generation.html#appendix",
    "href": "posts/VGBench_Evaluating_Large_Language_Models_on_Vector_Graphics_Understanding_and_Generation/2024-07-15-VGBench_Evaluating_Large_Language_Models_on_Vector_Graphics_Understanding_and_Generation.html#appendix",
    "title": "VGBench: Evaluating Large Language Models on Vector Graphics Understanding and Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10972v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10972v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6106"
  },
  {
    "objectID": "posts/SPL_A_Socratic_Playground_for_Learning_Powered_by_Large_Language_Mode/2024-06-20-SPL_A_Socratic_Playground_for_Learning_Powered_by_Large_Language_Mode.html#appendix",
    "href": "posts/SPL_A_Socratic_Playground_for_Learning_Powered_by_Large_Language_Mode/2024-06-20-SPL_A_Socratic_Playground_for_Learning_Powered_by_Large_Language_Mode.html#appendix",
    "title": "SPL: A Socratic Playground for Learning Powered by Large Language Mode",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13919v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13919v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7284"
  },
  {
    "objectID": "posts/PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation/2024-06-26-PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation.html#major-findings",
    "href": "posts/PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation/2024-06-26-PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation.html#major-findings",
    "title": "PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nStable Prompts: The study discovers that in some scenarios, prompts are stable, with some LLMs showing idiosyncratic preferences for grading generated texts with textual labels, while others prefer to return numeric scores.\nSusceptibility to Changes: However, the stability of prompts and model rankings can be susceptible to seemingly innocuous changes. For instance, changing the requested output format from “0 to 100” to “-1 to +1” can strongly affect the rankings in the evaluation.\nUnderstanding Prompting Approaches: The study contributes to understanding the impact of different prompting approaches on LLM-based metrics for machine translation and summarization evaluation, highlighting the most stable prompting patterns and potential limitations."
  },
  {
    "objectID": "posts/PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation/2024-06-26-PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation.html#analysis-and-critique",
    "href": "posts/PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation/2024-06-26-PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation.html#analysis-and-critique",
    "title": "PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper provides a comprehensive exploration of prompting strategies for LLM-based metrics, offering valuable insights into the stability and variability of these strategies. However, the study’s scope is limited to open-source LLMs, and the findings may not generalize to closed-source models. Additionally, the study does not explore the impact of different prompting strategies on other NLP tasks beyond machine translation and summarization.\nFurthermore, the study’s reliance on a single dataset for evaluation may limit the generalizability of the findings. Future research could benefit from evaluating the proposed prompting strategies on a more diverse range of datasets and tasks.\nLastly, the study does not discuss the potential ethical implications of using LLMs for evaluation, such as the risk of bias or the need for transparency in the evaluation process. Addressing these issues could enhance the credibility and applicability of the proposed prompting strategies."
  },
  {
    "objectID": "posts/PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation/2024-06-26-PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation.html#appendix",
    "href": "posts/PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation/2024-06-26-PrExMe!_Large_Scale_Prompt_Exploration_of_Open_Source_LLMs_for_Machine_Translation_and_Summarization_Evaluation.html#appendix",
    "title": "PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18528v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18528v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9672"
  },
  {
    "objectID": "posts/Multi_Granularity_Semantic_Revision_for_Large_Language_Model_Distillation/2024-07-14-Multi_Granularity_Semantic_Revision_for_Large_Language_Model_Distillation.html#appendix",
    "href": "posts/Multi_Granularity_Semantic_Revision_for_Large_Language_Model_Distillation/2024-07-14-Multi_Granularity_Semantic_Revision_for_Large_Language_Model_Distillation.html#appendix",
    "title": "Multi-Granularity Semantic Revision for Large Language Model Distillation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10068v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10068v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7336"
  },
  {
    "objectID": "posts/Can_we_teach_language_models_to_gloss_endangered_languages/2024-06-27-Can_we_teach_language_models_to_gloss_endangered_languages.html#appendix",
    "href": "posts/Can_we_teach_language_models_to_gloss_endangered_languages/2024-06-27-Can_we_teach_language_models_to_gloss_endangered_languages.html#appendix",
    "title": "Can we teach language models to gloss endangered languages?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18895v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18895v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6433"
  },
  {
    "objectID": "posts/MetaLLM_A_High_performant_and_Cost_efficient_Dynamic_Framework_for_Wrapping_LLMs/2024-07-15-MetaLLM_A_High_performant_and_Cost_efficient_Dynamic_Framework_for_Wrapping_LLMs.html#appendix",
    "href": "posts/MetaLLM_A_High_performant_and_Cost_efficient_Dynamic_Framework_for_Wrapping_LLMs/2024-07-15-MetaLLM_A_High_performant_and_Cost_efficient_Dynamic_Framework_for_Wrapping_LLMs.html#appendix",
    "title": "MetaLLM: A High-performant and Cost-efficient Dynamic Framework for Wrapping LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10834v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10834v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5819"
  },
  {
    "objectID": "posts/I_Couldve_Asked_That_Reformulating_Unanswerable_Questions/2024-07-24-I_Couldve_Asked_That_Reformulating_Unanswerable_Questions.html#appendix",
    "href": "posts/I_Couldve_Asked_That_Reformulating_Unanswerable_Questions/2024-07-24-I_Couldve_Asked_That_Reformulating_Unanswerable_Questions.html#appendix",
    "title": "I Could’ve Asked That: Reformulating Unanswerable Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17469v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17469v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1972"
  },
  {
    "objectID": "posts/StackRAG_Agent_Improving_Developer_Answers_with_Retrieval_Augmented_Generation/2024-06-19-StackRAG_Agent_Improving_Developer_Answers_with_Retrieval_Augmented_Generation.html#appendix",
    "href": "posts/StackRAG_Agent_Improving_Developer_Answers_with_Retrieval_Augmented_Generation/2024-06-19-StackRAG_Agent_Improving_Developer_Answers_with_Retrieval_Augmented_Generation.html#appendix",
    "title": "StackRAG Agent: Improving Developer Answers with Retrieval-Augmented Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13840v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13840v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4732"
  },
  {
    "objectID": "posts/Boosting_Large_Language_Models_with_Socratic_Method_for_Conversational_Mathematics_Teaching/2024-07-24-Boosting_Large_Language_Models_with_Socratic_Method_for_Conversational_Mathematics_Teaching.html#appendix",
    "href": "posts/Boosting_Large_Language_Models_with_Socratic_Method_for_Conversational_Mathematics_Teaching/2024-07-24-Boosting_Large_Language_Models_with_Socratic_Method_for_Conversational_Mathematics_Teaching.html#appendix",
    "title": "Boosting Large Language Models with Socratic Method for Conversational Mathematics Teaching",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17349v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17349v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4192"
  },
  {
    "objectID": "posts/SEED_Accelerating_Reasoning_Tree_Construction_via_Scheduled_Speculative_Decoding/2024-06-26-SEED_Accelerating_Reasoning_Tree_Construction_via_Scheduled_Speculative_Decoding.html",
    "href": "posts/SEED_Accelerating_Reasoning_Tree_Construction_via_Scheduled_Speculative_Decoding/2024-06-26-SEED_Accelerating_Reasoning_Tree_Construction_via_Scheduled_Speculative_Decoding.html",
    "title": "SEED: Accelerating Reasoning Tree Construction via Scheduled Speculative Decoding",
    "section": "",
    "text": "Summary:\nThe paper introduces SEED, a novel and efficient inference framework designed to optimize runtime speed and GPU memory management concurrently in reasoning tree construction. SEED effectively handles two scenarios: executing multiple iterations with the same prompt and evaluating multiple iterations with different prompts. The framework utilizes scheduled speculative decoding to manage the scheduling of parallel draft models and introduces a novel execution strategy, Speculative Scheduled Execution. This strategy is inspired by the use of speculative decoding in parallel drafting. SEED achieves excellent speed performance on three reasoning and planning datasets: GSM8K, Creative Writing, and Blocksworld. The framework also provides a viable path for conducting batched inference in training-free speculative decoding.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a well-structured and coherent summary of the proposed SEED framework. The authors provide a clear explanation of the problem they aim to address and the methodology they employ to tackle it. The use of speculative decoding and parallel drafting in the framework is well-justified, and the results from the experiments demonstrate the effectiveness of the approach. However, the paper could benefit from a more in-depth discussion of the limitations and potential biases in the methodology, as well as a comparison with other existing approaches to reasoning tree construction. Additionally, the authors could explore the potential applications and implications of their framework in real-world scenarios."
  },
  {
    "objectID": "posts/SEED_Accelerating_Reasoning_Tree_Construction_via_Scheduled_Speculative_Decoding/2024-06-26-SEED_Accelerating_Reasoning_Tree_Construction_via_Scheduled_Speculative_Decoding.html#appendix",
    "href": "posts/SEED_Accelerating_Reasoning_Tree_Construction_via_Scheduled_Speculative_Decoding/2024-06-26-SEED_Accelerating_Reasoning_Tree_Construction_via_Scheduled_Speculative_Decoding.html#appendix",
    "title": "SEED: Accelerating Reasoning Tree Construction via Scheduled Speculative Decoding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18200v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18200v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15801"
  },
  {
    "objectID": "posts/Time_series_forecasting_with_high_stakes_A_field_study_of_the_air_cargo_industry/2024-07-29-Time_series_forecasting_with_high_stakes_A_field_study_of_the_air_cargo_industry.html#appendix",
    "href": "posts/Time_series_forecasting_with_high_stakes_A_field_study_of_the_air_cargo_industry/2024-07-29-Time_series_forecasting_with_high_stakes_A_field_study_of_the_air_cargo_industry.html#appendix",
    "title": "Time series forecasting with high stakes: A field study of the air cargo industry",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20192v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20192v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4780"
  },
  {
    "objectID": "posts/An_Empirical_Study_of_Unit_Test_Generation_with_Large_Language_Models/2024-06-26-An_Empirical_Study_of_Unit_Test_Generation_with_Large_Language_Models.html#appendix",
    "href": "posts/An_Empirical_Study_of_Unit_Test_Generation_with_Large_Language_Models/2024-06-26-An_Empirical_Study_of_Unit_Test_Generation_with_Large_Language_Models.html#appendix",
    "title": "An Empirical Study of Unit Test Generation with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18181v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18181v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13168"
  },
  {
    "objectID": "posts/Few_shot_Personalization_of_LLMs_with_Mis_aligned_Responses/2024-06-26-Few_shot_Personalization_of_LLMs_with_Mis_aligned_Responses.html#appendix",
    "href": "posts/Few_shot_Personalization_of_LLMs_with_Mis_aligned_Responses/2024-06-26-Few_shot_Personalization_of_LLMs_with_Mis_aligned_Responses.html#appendix",
    "title": "Few-shot Personalization of LLMs with Mis-aligned Responses",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18678v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18678v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11156"
  },
  {
    "objectID": "posts/Accessing_GPT_4_level_Mathematical_Olympiad_Solutions_via_Monte_Carlo_Tree_Self_refine_with_LLaMa_3_8B/2024-06-11-Accessing_GPT_4_level_Mathematical_Olympiad_Solutions_via_Monte_Carlo_Tree_Self_refine_with_LLaMa_3_8B.html#appendix",
    "href": "posts/Accessing_GPT_4_level_Mathematical_Olympiad_Solutions_via_Monte_Carlo_Tree_Self_refine_with_LLaMa_3_8B/2024-06-11-Accessing_GPT_4_level_Mathematical_Olympiad_Solutions_via_Monte_Carlo_Tree_Self_refine_with_LLaMa_3_8B.html#appendix",
    "title": "Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07394v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07394v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5818"
  },
  {
    "objectID": "posts/Empowering_LLMs_for_Verilog_Generation_through_Multi_Level_Summarization/2024-07-15-Empowering_LLMs_for_Verilog_Generation_through_Multi_Level_Summarization.html#appendix",
    "href": "posts/Empowering_LLMs_for_Verilog_Generation_through_Multi_Level_Summarization/2024-07-15-Empowering_LLMs_for_Verilog_Generation_through_Multi_Level_Summarization.html#appendix",
    "title": "Empowering LLMs for Verilog Generation through Multi-Level Summarization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10424v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10424v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6724"
  },
  {
    "objectID": "posts/Hopping_Too_Late_Exploring_the_Limitations_of_Large_Language_Models_on_Multi_Hop_Queries/2024-06-18-Hopping_Too_Late_Exploring_the_Limitations_of_Large_Language_Models_on_Multi_Hop_Queries.html#appendix",
    "href": "posts/Hopping_Too_Late_Exploring_the_Limitations_of_Large_Language_Models_on_Multi_Hop_Queries/2024-06-18-Hopping_Too_Late_Exploring_the_Limitations_of_Large_Language_Models_on_Multi_Hop_Queries.html#appendix",
    "title": "Hopping Too Late: Exploring the Limitations of Large Language Models on Multi-Hop Queries",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12775v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12775v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8033"
  },
  {
    "objectID": "posts/LangSuitE_Planning_Controlling_and_Interacting_with_Large_Language_Models_in_Embodied_Text_Environments/2024-06-24-LangSuitE_Planning_Controlling_and_Interacting_with_Large_Language_Models_in_Embodied_Text_Environments.html#appendix",
    "href": "posts/LangSuitE_Planning_Controlling_and_Interacting_with_Large_Language_Models_in_Embodied_Text_Environments/2024-06-24-LangSuitE_Planning_Controlling_and_Interacting_with_Large_Language_Models_in_Embodied_Text_Environments.html#appendix",
    "title": "LangSuitE: Planning, Controlling and Interacting with Large Language Models in Embodied Text Environments",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16294v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16294v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7622"
  },
  {
    "objectID": "posts/MedExQA_Medical_Question_Answering_Benchmark_with_Multiple_Explanations/2024-06-10-MedExQA_Medical_Question_Answering_Benchmark_with_Multiple_Explanations.html#appendix",
    "href": "posts/MedExQA_Medical_Question_Answering_Benchmark_with_Multiple_Explanations/2024-06-10-MedExQA_Medical_Question_Answering_Benchmark_with_Multiple_Explanations.html#appendix",
    "title": "MedExQA: Medical Question Answering Benchmark with Multiple Explanations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06331v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06331v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7134"
  },
  {
    "objectID": "posts/Natural_Language_Mechanisms_via_Self_Resolution_with_Foundation_Models/2024-07-10-Natural_Language_Mechanisms_via_Self_Resolution_with_Foundation_Models.html#appendix",
    "href": "posts/Natural_Language_Mechanisms_via_Self_Resolution_with_Foundation_Models/2024-07-10-Natural_Language_Mechanisms_via_Self_Resolution_with_Foundation_Models.html#appendix",
    "title": "Natural Language Mechanisms via Self-Resolution with Foundation Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07845v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07845v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3100"
  },
  {
    "objectID": "posts/SeCoKD_Aligning_Large_Language_Models_for_In_Context_Learning_with_Fewer_Shots/2024-06-20-SeCoKD_Aligning_Large_Language_Models_for_In_Context_Learning_with_Fewer_Shots.html#appendix",
    "href": "posts/SeCoKD_Aligning_Large_Language_Models_for_In_Context_Learning_with_Fewer_Shots/2024-06-20-SeCoKD_Aligning_Large_Language_Models_for_In_Context_Learning_with_Fewer_Shots.html#appendix",
    "title": "SeCoKD: Aligning Large Language Models for In-Context Learning with Fewer Shots",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14208v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14208v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6370"
  },
  {
    "objectID": "posts/PRePair_Pointwise_Reasoning_Enhance_Pairwise_Evaluating_for_Robust_Instruction_Following_Assessments/2024-06-18-PRePair_Pointwise_Reasoning_Enhance_Pairwise_Evaluating_for_Robust_Instruction_Following_Assessments.html#appendix",
    "href": "posts/PRePair_Pointwise_Reasoning_Enhance_Pairwise_Evaluating_for_Robust_Instruction_Following_Assessments/2024-06-18-PRePair_Pointwise_Reasoning_Enhance_Pairwise_Evaluating_for_Robust_Instruction_Following_Assessments.html#appendix",
    "title": "PRePair: Pointwise Reasoning Enhance Pairwise Evaluating for Robust Instruction-Following Assessments",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12319v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12319v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2144"
  },
  {
    "objectID": "posts/Enhancing_Code_Translation_in_Language_Models_with_Few_Shot_Learning_via_Retrieval_Augmented_Generation/2024-07-29-Enhancing_Code_Translation_in_Language_Models_with_Few_Shot_Learning_via_Retrieval_Augmented_Generation.html#appendix",
    "href": "posts/Enhancing_Code_Translation_in_Language_Models_with_Few_Shot_Learning_via_Retrieval_Augmented_Generation/2024-07-29-Enhancing_Code_Translation_in_Language_Models_with_Few_Shot_Learning_via_Retrieval_Augmented_Generation.html#appendix",
    "title": "Enhancing Code Translation in Language Models with Few-Shot Learning via Retrieval-Augmented Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19619v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19619v1\n\n\nTruncated\nFalse\n\n\nWord Count\n0"
  },
  {
    "objectID": "posts/Item_Language_Model_for_Conversational_Recommendation/2024-06-05-Item_Language_Model_for_Conversational_Recommendation.html#appendix",
    "href": "posts/Item_Language_Model_for_Conversational_Recommendation/2024-06-05-Item_Language_Model_for_Conversational_Recommendation.html#appendix",
    "title": "Item-Language Model for Conversational Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02844v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02844v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6105"
  },
  {
    "objectID": "posts/From_Descriptive_Richness_to_Bias_Unveiling_the_Dark_Side_of_Generative_Image_Caption_Enrichment/2024-06-20-From_Descriptive_Richness_to_Bias_Unveiling_the_Dark_Side_of_Generative_Image_Caption_Enrichment.html#appendix",
    "href": "posts/From_Descriptive_Richness_to_Bias_Unveiling_the_Dark_Side_of_Generative_Image_Caption_Enrichment/2024-06-20-From_Descriptive_Richness_to_Bias_Unveiling_the_Dark_Side_of_Generative_Image_Caption_Enrichment.html#appendix",
    "title": "From Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13912v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13912v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3715"
  },
  {
    "objectID": "posts/Mitigating_Hallucination_in_Fictional_Character_Role_Play/2024-06-25-Mitigating_Hallucination_in_Fictional_Character_Role_Play.html#appendix",
    "href": "posts/Mitigating_Hallucination_in_Fictional_Character_Role_Play/2024-06-25-Mitigating_Hallucination_in_Fictional_Character_Role_Play.html#appendix",
    "title": "Mitigating Hallucination in Fictional Character Role-Play",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17260v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17260v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5369"
  },
  {
    "objectID": "posts/A_Survey_on_Human_Preference_Learning_for_Large_Language_Models/2024-06-18-A_Survey_on_Human_Preference_Learning_for_Large_Language_Models.html#appendix",
    "href": "posts/A_Survey_on_Human_Preference_Learning_for_Large_Language_Models/2024-06-18-A_Survey_on_Human_Preference_Learning_for_Large_Language_Models.html#appendix",
    "title": "A Survey on Human Preference Learning for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11191v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11191v2\n\n\nTruncated\nFalse\n\n\nWord Count\n12234"
  },
  {
    "objectID": "posts/Patched_RTC_evaluating_LLMs_for_diverse_software_development_tasks/2024-07-23-Patched_RTC_evaluating_LLMs_for_diverse_software_development_tasks.html#appendix",
    "href": "posts/Patched_RTC_evaluating_LLMs_for_diverse_software_development_tasks/2024-07-23-Patched_RTC_evaluating_LLMs_for_diverse_software_development_tasks.html#appendix",
    "title": "Patched RTC: evaluating LLMs for diverse software development tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16557v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16557v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4337"
  },
  {
    "objectID": "posts/Investigating_Mysteries_of_CoT_Augmented_Distillation/2024-06-20-Investigating_Mysteries_of_CoT_Augmented_Distillation.html#appendix",
    "href": "posts/Investigating_Mysteries_of_CoT_Augmented_Distillation/2024-06-20-Investigating_Mysteries_of_CoT_Augmented_Distillation.html#appendix",
    "title": "Investigating Mysteries of CoT-Augmented Distillation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14511v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14511v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8455"
  },
  {
    "objectID": "posts/Investigating_LLMs_as_Voting_Assistants_via_Contextual_Augmentation_A_Case_Study_on_the_European_Parliament_Elections_2024/2024-07-11-Investigating_LLMs_as_Voting_Assistants_via_Contextual_Augmentation_A_Case_Study_on_the_European_Parliament_Elections_2024.html#appendix",
    "href": "posts/Investigating_LLMs_as_Voting_Assistants_via_Contextual_Augmentation_A_Case_Study_on_the_European_Parliament_Elections_2024/2024-07-11-Investigating_LLMs_as_Voting_Assistants_via_Contextual_Augmentation_A_Case_Study_on_the_European_Parliament_Elections_2024.html#appendix",
    "title": "Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08495v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08495v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5277"
  },
  {
    "objectID": "posts/Experiments_with_truth_using_Machine_Learning_Spectral_analysis_and_explainable_classification_of_synthetic_false_and_genuine_information/2024-07-07-Experiments_with_truth_using_Machine_Learning_Spectral_analysis_and_explainable_classification_of_synthetic_false_and_genuine_information.html#appendix",
    "href": "posts/Experiments_with_truth_using_Machine_Learning_Spectral_analysis_and_explainable_classification_of_synthetic_false_and_genuine_information/2024-07-07-Experiments_with_truth_using_Machine_Learning_Spectral_analysis_and_explainable_classification_of_synthetic_false_and_genuine_information.html#appendix",
    "title": "Experiments with truth using Machine Learning: Spectral analysis and explainable classification of synthetic, false, and genuine information",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05464v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05464v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9665"
  },
  {
    "objectID": "posts/Text_like_Encoding_of_Collaborative_Information_in_Large_Language_Models_for_Recommendation/2024-06-05-Text_like_Encoding_of_Collaborative_Information_in_Large_Language_Models_for_Recommendation.html#appendix",
    "href": "posts/Text_like_Encoding_of_Collaborative_Information_in_Large_Language_Models_for_Recommendation/2024-06-05-Text_like_Encoding_of_Collaborative_Information_in_Large_Language_Models_for_Recommendation.html#appendix",
    "title": "Text-like Encoding of Collaborative Information in Large Language Models for Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03210v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03210v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6859"
  },
  {
    "objectID": "posts/HuatuoGPT_Vision_Towards_Injecting_Medical_Visual_Knowledge_into_Multimodal_LLMs_at_Scale/2024-06-27-HuatuoGPT_Vision_Towards_Injecting_Medical_Visual_Knowledge_into_Multimodal_LLMs_at_Scale.html#appendix",
    "href": "posts/HuatuoGPT_Vision_Towards_Injecting_Medical_Visual_Knowledge_into_Multimodal_LLMs_at_Scale/2024-06-27-HuatuoGPT_Vision_Towards_Injecting_Medical_Visual_Knowledge_into_Multimodal_LLMs_at_Scale.html#appendix",
    "title": "HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19280v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19280v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6836"
  },
  {
    "objectID": "posts/Multi_Stage_Balanced_Distillation_Addressing_Long_Tail_Challenges_in_Sequence_Level_Knowledge_Distillation/2024-06-19-Multi_Stage_Balanced_Distillation_Addressing_Long_Tail_Challenges_in_Sequence_Level_Knowledge_Distillation.html#appendix",
    "href": "posts/Multi_Stage_Balanced_Distillation_Addressing_Long_Tail_Challenges_in_Sequence_Level_Knowledge_Distillation/2024-06-19-Multi_Stage_Balanced_Distillation_Addressing_Long_Tail_Challenges_in_Sequence_Level_Knowledge_Distillation.html#appendix",
    "title": "Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13114v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13114v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7892"
  },
  {
    "objectID": "posts/A_Collaborative_Data_Analytics_System_with_Recommender_for_Diverse_Users/2024-06-17-A_Collaborative_Data_Analytics_System_with_Recommender_for_Diverse_Users.html#appendix",
    "href": "posts/A_Collaborative_Data_Analytics_System_with_Recommender_for_Diverse_Users/2024-06-17-A_Collaborative_Data_Analytics_System_with_Recommender_for_Diverse_Users.html#appendix",
    "title": "A Collaborative Data Analytics System with Recommender for Diverse Users",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11232v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11232v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13618"
  },
  {
    "objectID": "posts/Safety_Alignment_Should_Be_Made_More_Than_Just_a_Few_Tokens_Deep/2024-06-10-Safety_Alignment_Should_Be_Made_More_Than_Just_a_Few_Tokens_Deep.html#appendix",
    "href": "posts/Safety_Alignment_Should_Be_Made_More_Than_Just_a_Few_Tokens_Deep/2024-06-10-Safety_Alignment_Should_Be_Made_More_Than_Just_a_Few_Tokens_Deep.html#appendix",
    "title": "Safety Alignment Should Be Made More Than Just a Few Tokens Deep",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05946v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05946v1\n\n\nTruncated\nFalse\n\n\nWord Count\n16740"
  },
  {
    "objectID": "posts/Generative_Debunking_of_Climate_Misinformation/2024-07-08-Generative_Debunking_of_Climate_Misinformation.html#appendix",
    "href": "posts/Generative_Debunking_of_Climate_Misinformation/2024-07-08-Generative_Debunking_of_Climate_Misinformation.html#appendix",
    "title": "Generative Debunking of Climate Misinformation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05599v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05599v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6823"
  },
  {
    "objectID": "posts/An_Actionable_Framework_for_Assessing_Bias_and_Fairness_in_Large_Language_Model_Use_Cases/2024-07-15-An_Actionable_Framework_for_Assessing_Bias_and_Fairness_in_Large_Language_Model_Use_Cases.html#appendix",
    "href": "posts/An_Actionable_Framework_for_Assessing_Bias_and_Fairness_in_Large_Language_Model_Use_Cases/2024-07-15-An_Actionable_Framework_for_Assessing_Bias_and_Fairness_in_Large_Language_Model_Use_Cases.html#appendix",
    "title": "An Actionable Framework for Assessing Bias and Fairness in Large Language Model Use Cases",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10853v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10853v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11496"
  },
  {
    "objectID": "posts/Richelieu_Self_Evolving_LLM_Based_Agents_for_AI_Diplomacy/2024-07-09-Richelieu_Self_Evolving_LLM_Based_Agents_for_AI_Diplomacy.html",
    "href": "posts/Richelieu_Self_Evolving_LLM_Based_Agents_for_AI_Diplomacy/2024-07-09-Richelieu_Self_Evolving_LLM_Based_Agents_for_AI_Diplomacy.html",
    "title": "Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy",
    "section": "",
    "text": "Summary:\nThe paper introduces Richelieu, a self-evolving LLM-based agent for AI diplomacy. The model enables hierarchical planning for multi-agent tasks and utilizes a memory module for reflective optimization. The model does not require human data and can evolve through self-play, ultimately outperforming existing models like Cicero in the Diplomacy game. The ablation study demonstrates the effectiveness of the modules established. Experiments using different LLMs validate the generalization of the framework to various LLMs.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an innovative approach to AI diplomacy using a self-evolving LLM-based agent, Richelieu. The model’s ability to outperform existing models without requiring human data is a significant achievement. The use of a memory module for reflective optimization is a novel approach to improving the model’s performance. The ablation study provides evidence of the effectiveness of the modules established in the model. However, the paper does not discuss the limitations of the model or potential areas for improvement. Additionally, the generalization of the framework to various LLMs is validated through experiments, but the paper does not provide details on the specific LLMs used or the results of these experiments. Overall, the paper provides a promising approach to AI diplomacy, but further research is needed to address these limitations and provide a more comprehensive evaluation of the model’s performance."
  },
  {
    "objectID": "posts/Richelieu_Self_Evolving_LLM_Based_Agents_for_AI_Diplomacy/2024-07-09-Richelieu_Self_Evolving_LLM_Based_Agents_for_AI_Diplomacy.html#appendix",
    "href": "posts/Richelieu_Self_Evolving_LLM_Based_Agents_for_AI_Diplomacy/2024-07-09-Richelieu_Self_Evolving_LLM_Based_Agents_for_AI_Diplomacy.html#appendix",
    "title": "Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06813v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06813v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7379"
  },
  {
    "objectID": "posts/A_Survey_of_Backdoor_Attacks_and_Defenses_on_Large_Language_Models_Implications_for_Security_Measures/2024-06-10-A_Survey_of_Backdoor_Attacks_and_Defenses_on_Large_Language_Models_Implications_for_Security_Measures.html#appendix",
    "href": "posts/A_Survey_of_Backdoor_Attacks_and_Defenses_on_Large_Language_Models_Implications_for_Security_Measures/2024-06-10-A_Survey_of_Backdoor_Attacks_and_Defenses_on_Large_Language_Models_Implications_for_Security_Measures.html#appendix",
    "title": "A Survey of Backdoor Attacks and Defenses on Large Language Models: Implications for Security Measures",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06852v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06852v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9560"
  },
  {
    "objectID": "posts/Collective_Innovation_in_Groups_of_Large_Language_Models/2024-07-07-Collective_Innovation_in_Groups_of_Large_Language_Models.html#appendix",
    "href": "posts/Collective_Innovation_in_Groups_of_Large_Language_Models/2024-07-07-Collective_Innovation_in_Groups_of_Large_Language_Models.html#appendix",
    "title": "Collective Innovation in Groups of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05377v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05377v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8010"
  },
  {
    "objectID": "posts/Cactus_Towards_Psychological_Counseling_Conversations_using_Cognitive_Behavioral_Theory/2024-07-03-Cactus_Towards_Psychological_Counseling_Conversations_using_Cognitive_Behavioral_Theory.html#appendix",
    "href": "posts/Cactus_Towards_Psychological_Counseling_Conversations_using_Cognitive_Behavioral_Theory/2024-07-03-Cactus_Towards_Psychological_Counseling_Conversations_using_Cognitive_Behavioral_Theory.html#appendix",
    "title": "Cactus: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03103v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03103v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10331"
  },
  {
    "objectID": "posts/Q_Sparse_All_Large_Language_Models_can_be_Fully_Sparsely_Activated/2024-07-15-Q_Sparse_All_Large_Language_Models_can_be_Fully_Sparsely_Activated.html#appendix",
    "href": "posts/Q_Sparse_All_Large_Language_Models_can_be_Fully_Sparsely_Activated/2024-07-15-Q_Sparse_All_Large_Language_Models_can_be_Fully_Sparsely_Activated.html#appendix",
    "title": "Q-Sparse: All Large Language Models can be Fully Sparsely-Activated",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10969v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10969v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5530"
  },
  {
    "objectID": "posts/Orca_Ocean_Significant_Wave_Height_Estimation_with_Spatio_temporally_Aware_Large_Language_Models/2024-07-29-Orca_Ocean_Significant_Wave_Height_Estimation_with_Spatio_temporally_Aware_Large_Language_Models.html#appendix",
    "href": "posts/Orca_Ocean_Significant_Wave_Height_Estimation_with_Spatio_temporally_Aware_Large_Language_Models/2024-07-29-Orca_Ocean_Significant_Wave_Height_Estimation_with_Spatio_temporally_Aware_Large_Language_Models.html#appendix",
    "title": "Orca: Ocean Significant Wave Height Estimation with Spatio-temporally Aware Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20053v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20053v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3804"
  },
  {
    "objectID": "posts/New_intelligent_empowerment_for_digital_transformation/2024-06-26-New_intelligent_empowerment_for_digital_transformation.html",
    "href": "posts/New_intelligent_empowerment_for_digital_transformation/2024-06-26-New_intelligent_empowerment_for_digital_transformation.html",
    "title": "New intelligent empowerment for digital transformation",
    "section": "",
    "text": "Summary:\nThis study proposes a novel evaluation method for measuring the digital transformation (DT) process of enterprises based on large language models (LLMs). The authors analyzed annual reports of 4407 companies listed on the New York Stock Exchange and Nasdaq from 2005 to 2022, constructing a comprehensive set of DT indicators. The findings reveal that DT significantly improves a company’s financial performance, but different digital technologies have varying effects on financial performance. Specifically, blockchain technology has a relatively limited positive impact on financial performance. Additionally, DT can promote the growth of financial performance by enhancing operational efficiency and reducing costs.\nMajor Findings:\nAnalysis and Critique:\nThe study provides a novel DT evaluation tool for the academic community and expands the application scope of generative artificial intelligence technology in economic research. However, several limitations and potential biases should be considered:"
  },
  {
    "objectID": "posts/New_intelligent_empowerment_for_digital_transformation/2024-06-26-New_intelligent_empowerment_for_digital_transformation.html#appendix",
    "href": "posts/New_intelligent_empowerment_for_digital_transformation/2024-06-26-New_intelligent_empowerment_for_digital_transformation.html#appendix",
    "title": "New intelligent empowerment for digital transformation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18440v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18440v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17294"
  },
  {
    "objectID": "posts/A_Superalignment_Framework_in_Autonomous_Driving_with_Large_Language_Models/2024-06-09-A_Superalignment_Framework_in_Autonomous_Driving_with_Large_Language_Models.html#appendix",
    "href": "posts/A_Superalignment_Framework_in_Autonomous_Driving_with_Large_Language_Models/2024-06-09-A_Superalignment_Framework_in_Autonomous_Driving_with_Large_Language_Models.html#appendix",
    "title": "A Superalignment Framework in Autonomous Driving with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05651v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05651v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3979"
  },
  {
    "objectID": "posts/Using_LLMs_to_Aid_Annotation_and_Collection_of_Clinically_Enriched_Data_in_Bipolar_Disorder_and_Schizophrenia/2024-06-18-Using_LLMs_to_Aid_Annotation_and_Collection_of_Clinically_Enriched_Data_in_Bipolar_Disorder_and_Schizophrenia.html#appendix",
    "href": "posts/Using_LLMs_to_Aid_Annotation_and_Collection_of_Clinically_Enriched_Data_in_Bipolar_Disorder_and_Schizophrenia/2024-06-18-Using_LLMs_to_Aid_Annotation_and_Collection_of_Clinically_Enriched_Data_in_Bipolar_Disorder_and_Schizophrenia.html#appendix",
    "title": "Using LLMs to Aid Annotation and Collection of Clinically-Enriched Data in Bipolar Disorder and Schizophrenia",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12687v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12687v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5994"
  },
  {
    "objectID": "posts/MagicItem_Dynamic_Behavior_Design_of_Virtual_Objects_with_Large_Language_Models_in_a_Consumer_Metaverse_Platform/2024-06-19-MagicItem_Dynamic_Behavior_Design_of_Virtual_Objects_with_Large_Language_Models_in_a_Consumer_Metaverse_Platform.html#appendix",
    "href": "posts/MagicItem_Dynamic_Behavior_Design_of_Virtual_Objects_with_Large_Language_Models_in_a_Consumer_Metaverse_Platform/2024-06-19-MagicItem_Dynamic_Behavior_Design_of_Virtual_Objects_with_Large_Language_Models_in_a_Consumer_Metaverse_Platform.html#appendix",
    "title": "MagicItem: Dynamic Behavior Design of Virtual Objects with Large Language Models in a Consumer Metaverse Platform",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13242v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13242v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9382"
  },
  {
    "objectID": "posts/Is_GPT_4_Alone_Sufficient_for_Automated_Essay_Scoring_A_Comparative_Judgment_Approach_Based_on_Rater_Cognition/2024-07-08-Is_GPT_4_Alone_Sufficient_for_Automated_Essay_Scoring_A_Comparative_Judgment_Approach_Based_on_Rater_Cognition.html#appendix",
    "href": "posts/Is_GPT_4_Alone_Sufficient_for_Automated_Essay_Scoring_A_Comparative_Judgment_Approach_Based_on_Rater_Cognition/2024-07-08-Is_GPT_4_Alone_Sufficient_for_Automated_Essay_Scoring_A_Comparative_Judgment_Approach_Based_on_Rater_Cognition.html#appendix",
    "title": "Is GPT-4 Alone Sufficient for Automated Essay Scoring?: A Comparative Judgment Approach Based on Rater Cognition",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05733v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05733v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6518"
  },
  {
    "objectID": "posts/Exploring_the_Educational_Landscape_of_AI_Large_Language_Models_Approaches_to_Explaining_Conservation_of_Momentum_in_Physics/2024-07-07-Exploring_the_Educational_Landscape_of_AI_Large_Language_Models_Approaches_to_Explaining_Conservation_of_Momentum_in_Physics.html#appendix",
    "href": "posts/Exploring_the_Educational_Landscape_of_AI_Large_Language_Models_Approaches_to_Explaining_Conservation_of_Momentum_in_Physics/2024-07-07-Exploring_the_Educational_Landscape_of_AI_Large_Language_Models_Approaches_to_Explaining_Conservation_of_Momentum_in_Physics.html#appendix",
    "title": "Exploring the Educational Landscape of AI: Large Language Models’ Approaches to Explaining Conservation of Momentum in Physics",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05308v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05308v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4973"
  },
  {
    "objectID": "posts/Benchmarks_and_Metrics_for_Evaluations_of_Code_Generation_A_Critical_Review/2024-06-18-Benchmarks_and_Metrics_for_Evaluations_of_Code_Generation_A_Critical_Review.html#appendix",
    "href": "posts/Benchmarks_and_Metrics_for_Evaluations_of_Code_Generation_A_Critical_Review/2024-06-18-Benchmarks_and_Metrics_for_Evaluations_of_Code_Generation_A_Critical_Review.html#appendix",
    "title": "Benchmarks and Metrics for Evaluations of Code Generation: A Critical Review",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12655v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12655v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5871"
  },
  {
    "objectID": "posts/Capturing_Minds_Not_Just_Words_Enhancing_Role_Playing_Language_Models_with_Personality_Indicative_Data/2024-06-27-Capturing_Minds_Not_Just_Words_Enhancing_Role_Playing_Language_Models_with_Personality_Indicative_Data.html#appendix",
    "href": "posts/Capturing_Minds_Not_Just_Words_Enhancing_Role_Playing_Language_Models_with_Personality_Indicative_Data/2024-06-27-Capturing_Minds_Not_Just_Words_Enhancing_Role_Playing_Language_Models_with_Personality_Indicative_Data.html#appendix",
    "title": "Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18921v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18921v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5403"
  },
  {
    "objectID": "posts/Adaptable_Logical_Control_for_Large_Language_Models/2024-06-19-Adaptable_Logical_Control_for_Large_Language_Models.html#appendix",
    "href": "posts/Adaptable_Logical_Control_for_Large_Language_Models/2024-06-19-Adaptable_Logical_Control_for_Large_Language_Models.html#appendix",
    "title": "Adaptable Logical Control for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13892v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13892v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7583"
  },
  {
    "objectID": "posts/LoRA_Guard_Parameter_Efficient_Guardrail_Adaptation_for_Content_Moderation_of_Large_Language_Models/2024-07-03-LoRA_Guard_Parameter_Efficient_Guardrail_Adaptation_for_Content_Moderation_of_Large_Language_Models.html#appendix",
    "href": "posts/LoRA_Guard_Parameter_Efficient_Guardrail_Adaptation_for_Content_Moderation_of_Large_Language_Models/2024-07-03-LoRA_Guard_Parameter_Efficient_Guardrail_Adaptation_for_Content_Moderation_of_Large_Language_Models.html#appendix",
    "title": "LoRA-Guard: Parameter-Efficient Guardrail Adaptation for Content Moderation of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02987v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02987v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10286"
  },
  {
    "objectID": "posts/Odyssey_Empowering_Agents_with_Open_World_Skills/2024-07-22-Odyssey_Empowering_Agents_with_Open_World_Skills.html",
    "href": "posts/Odyssey_Empowering_Agents_with_Open_World_Skills/2024-07-22-Odyssey_Empowering_Agents_with_Open_World_Skills.html",
    "title": "Odyssey: Empowering Agents with Open-World Skills",
    "section": "",
    "text": "Summary:\nThe paper introduces ODYSSEY, a new framework that empowers Large Language Model (LLM)-based agents with open-world skills to explore the vast Minecraft world. ODYSSEY comprises three key parts: (1) An interactive agent with an open-world skill library that consists of 40 primitive skills and 183 compositional skills. (2) A fine-tuned LLaMA-3 model trained on a large question-answering dataset with 390k+ instruction entries derived from the Minecraft Wiki. (3) A new open-world benchmark includes thousands of long-term planning tasks, tens of dynamic-immediate planning tasks, and one autonomous exploration task.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a comprehensive framework for developing and evaluating autonomous embodied agents in open-world environments. The use of LLMs in Minecraft has been explored in previous works, but the proposed ODYSSEY framework provides a more stable and efficient method for generating complex policies for broader exploration and more complex tasks. However, the use of open-source LLMs is prone to generating hallucinations, which can decrease agent performance. The authors plan to address this issue by employing retrieval-augmented generation to improve LLMs in Minecraft. Additionally, the skill library is still text-based, which limits its functionality in tasks requiring visual information. The authors plan to integrate visual processing capabilities into the skill library to expand its capabilities.\nThe paper also introduces a new open-world benchmark that encompasses tasks requiring long-term planning, dynamic-"
  },
  {
    "objectID": "posts/Odyssey_Empowering_Agents_with_Open_World_Skills/2024-07-22-Odyssey_Empowering_Agents_with_Open_World_Skills.html#appendix",
    "href": "posts/Odyssey_Empowering_Agents_with_Open_World_Skills/2024-07-22-Odyssey_Empowering_Agents_with_Open_World_Skills.html#appendix",
    "title": "Odyssey: Empowering Agents with Open-World Skills",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.15325v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.15325v1\n\n\nTruncated\nFalse\n\n\nWord Count\n24246"
  },
  {
    "objectID": "posts/MALSIGHT_Exploring_Malicious_Source_Code_and_Benign_Pseudocode_for_Iterative_Binary_Malware_Summarization/2024-06-26-MALSIGHT_Exploring_Malicious_Source_Code_and_Benign_Pseudocode_for_Iterative_Binary_Malware_Summarization.html#appendix",
    "href": "posts/MALSIGHT_Exploring_Malicious_Source_Code_and_Benign_Pseudocode_for_Iterative_Binary_Malware_Summarization/2024-06-26-MALSIGHT_Exploring_Malicious_Source_Code_and_Benign_Pseudocode_for_Iterative_Binary_Malware_Summarization.html#appendix",
    "title": "MALSIGHT: Exploring Malicious Source Code and Benign Pseudocode for Iterative Binary Malware Summarization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18379v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18379v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12933"
  },
  {
    "objectID": "posts/Towards_Human_AI_Collaboration_in_Healthcare_Guided_Deferral_Systems_with_Large_Language_Models/2024-06-11-Towards_Human_AI_Collaboration_in_Healthcare_Guided_Deferral_Systems_with_Large_Language_Models.html#appendix",
    "href": "posts/Towards_Human_AI_Collaboration_in_Healthcare_Guided_Deferral_Systems_with_Large_Language_Models/2024-06-11-Towards_Human_AI_Collaboration_in_Healthcare_Guided_Deferral_Systems_with_Large_Language_Models.html#appendix",
    "title": "Towards Human-AI Collaboration in Healthcare: Guided Deferral Systems with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07212v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07212v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4804"
  },
  {
    "objectID": "posts/Lynx_An_Open_Source_Hallucination_Evaluation_Model/2024-07-11-Lynx_An_Open_Source_Hallucination_Evaluation_Model.html#appendix",
    "href": "posts/Lynx_An_Open_Source_Hallucination_Evaluation_Model/2024-07-11-Lynx_An_Open_Source_Hallucination_Evaluation_Model.html#appendix",
    "title": "Lynx: An Open Source Hallucination Evaluation Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08488v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08488v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6415"
  },
  {
    "objectID": "posts/The_Geometry_of_Queries_Query_Based_Innovations_in_Retrieval_Augmented_Generation/2024-07-25-The_Geometry_of_Queries_Query_Based_Innovations_in_Retrieval_Augmented_Generation.html#appendix",
    "href": "posts/The_Geometry_of_Queries_Query_Based_Innovations_in_Retrieval_Augmented_Generation/2024-07-25-The_Geometry_of_Queries_Query_Based_Innovations_in_Retrieval_Augmented_Generation.html#appendix",
    "title": "The Geometry of Queries: Query-Based Innovations in Retrieval-Augmented Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.18044v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.18044v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12034"
  },
  {
    "objectID": "posts/medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs/2024-06-20-medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs.html",
    "href": "posts/medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs/2024-06-20-medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs.html",
    "title": "medIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced Clinical Diagnosis on EMRs",
    "section": "",
    "text": "Summary:\nThe paper introduces medIKAL, a framework that integrates Large Language Models (LLMs) with knowledge graphs (KGs) to enhance clinical diagnosis on Electronic Medical Records (EMRs). The framework assigns weighted importance to entities in medical records based on their type, enabling precise localization of candidate diseases within KGs. It employs a residual network-like approach, allowing initial diagnosis by the LLM to be merged into KG search results. The diagnostic process is further refined through a path-based reranking algorithm and a fill-in-the-blank style prompt template. The effectiveness of medIKAL is validated through extensive experiments on a newly introduced open-sourced Chinese EMR dataset.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs/2024-06-20-medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs.html#appendix",
    "href": "posts/medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs/2024-06-20-medIKAL_Integrating_Knowledge_Graphs_as_Assistants_of_LLMs_for_Enhanced_Clinical_Diagnosis_on_EMRs.html#appendix",
    "title": "medIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced Clinical Diagnosis on EMRs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14326v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14326v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7194"
  },
  {
    "objectID": "posts/Large_Language_Models_Make_Sample_Efficient_Recommender_Systems/2024-06-04-Large_Language_Models_Make_Sample_Efficient_Recommender_Systems.html#appendix",
    "href": "posts/Large_Language_Models_Make_Sample_Efficient_Recommender_Systems/2024-06-04-Large_Language_Models_Make_Sample_Efficient_Recommender_Systems.html#appendix",
    "title": "Large Language Models Make Sample-Efficient Recommender Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02368v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02368v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3649"
  },
  {
    "objectID": "posts/Mind_the_Privacy_Unit!_User_Level_Differential_Privacy_for_Language_Model_Fine_Tuning/2024-06-20-Mind_the_Privacy_Unit!_User_Level_Differential_Privacy_for_Language_Model_Fine_Tuning.html#appendix",
    "href": "posts/Mind_the_Privacy_Unit!_User_Level_Differential_Privacy_for_Language_Model_Fine_Tuning/2024-06-20-Mind_the_Privacy_Unit!_User_Level_Differential_Privacy_for_Language_Model_Fine_Tuning.html#appendix",
    "title": "Mind the Privacy Unit! User-Level Differential Privacy for Language Model Fine-Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14322v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14322v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7165"
  },
  {
    "objectID": "posts/Exploring_the_Role_of_Transliteration_in_In_Context_Learning_for_Low_resource_Languages_Written_in_Non_Latin_Scripts/2024-07-02-Exploring_the_Role_of_Transliteration_in_In_Context_Learning_for_Low_resource_Languages_Written_in_Non_Latin_Scripts.html#appendix",
    "href": "posts/Exploring_the_Role_of_Transliteration_in_In_Context_Learning_for_Low_resource_Languages_Written_in_Non_Latin_Scripts/2024-07-02-Exploring_the_Role_of_Transliteration_in_In_Context_Learning_for_Low_resource_Languages_Written_in_Non_Latin_Scripts.html#appendix",
    "title": "Exploring the Role of Transliteration in In-Context Learning for Low-resource Languages Written in Non-Latin Scripts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02320v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02320v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3417"
  },
  {
    "objectID": "posts/PrimeGuard_Safe_and_Helpful_LLMs_through_Tuning_Free_Routing/2024-07-23-PrimeGuard_Safe_and_Helpful_LLMs_through_Tuning_Free_Routing.html#major-findings",
    "href": "posts/PrimeGuard_Safe_and_Helpful_LLMs_through_Tuning_Free_Routing/2024-07-23-PrimeGuard_Safe_and_Helpful_LLMs_through_Tuning_Free_Routing.html#major-findings",
    "title": "PrimeGuard: Safe and Helpful LLMs through Tuning-Free Routing",
    "section": "Major Findings",
    "text": "Major Findings\n\nPrimeGuard, a novel ITG method, utilizes structured control flow and exception handling to overcome the guardrail tax, a trade-off between safety and helpfulness.\nThe method employs two language models, LLMMain and LLMGuard, with LLMGuard evaluating the risk of answering a user query based on system guidelines.\nPrimeGuard achieves high levels of both safety and helpfulness by routing queries posing higher risks to refusals or re-evaluation against restrictive system instructions, while low-risk queries are encouraged to adhere to directive instructions.\nThe method is evaluated across multiple relevant defense directions, including the safe-eval dataset, XSTest, and TAP, a state-of-the-art automated method for red-teaming.\nPrimeGuard significantly outperforms the present-day Pareto frontier by achieving high safety and usefulness across different model sizes."
  },
  {
    "objectID": "posts/PrimeGuard_Safe_and_Helpful_LLMs_through_Tuning_Free_Routing/2024-07-23-PrimeGuard_Safe_and_Helpful_LLMs_through_Tuning_Free_Routing.html#analysis-and-critique",
    "href": "posts/PrimeGuard_Safe_and_Helpful_LLMs_through_Tuning_Free_Routing/2024-07-23-PrimeGuard_Safe_and_Helpful_LLMs_through_Tuning_Free_Routing.html#analysis-and-critique",
    "title": "PrimeGuard: Safe and Helpful LLMs through Tuning-Free Routing",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\nThe paper presents a promising approach to addressing the guardrail tax, a significant challenge in deploying language models. The proposed method, PrimeGuard, demonstrates impressive results in maintaining helpfulness while maximizing adherence to custom safety guidelines. The use of structured control flow and exception handling to dynamically overcome the guardrail tax is a novel and effective approach.\nHowever, the paper does not discuss potential limitations or shortcomings of the proposed method. For instance, the reliance on two language models, LLMMain and LLMGuard, may introduce additional"
  },
  {
    "objectID": "posts/PrimeGuard_Safe_and_Helpful_LLMs_through_Tuning_Free_Routing/2024-07-23-PrimeGuard_Safe_and_Helpful_LLMs_through_Tuning_Free_Routing.html#appendix",
    "href": "posts/PrimeGuard_Safe_and_Helpful_LLMs_through_Tuning_Free_Routing/2024-07-23-PrimeGuard_Safe_and_Helpful_LLMs_through_Tuning_Free_Routing.html#appendix",
    "title": "PrimeGuard: Safe and Helpful LLMs through Tuning-Free Routing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16318v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16318v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17231"
  },
  {
    "objectID": "posts/Leveraging_LLM_Respondents_for_Item_Evaluation_a_Psychometric_Analysis/2024-07-15-Leveraging_LLM_Respondents_for_Item_Evaluation_a_Psychometric_Analysis.html#appendix",
    "href": "posts/Leveraging_LLM_Respondents_for_Item_Evaluation_a_Psychometric_Analysis/2024-07-15-Leveraging_LLM_Respondents_for_Item_Evaluation_a_Psychometric_Analysis.html#appendix",
    "title": "Leveraging LLM-Respondents for Item Evaluation: a Psychometric Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10899v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10899v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5642"
  },
  {
    "objectID": "posts/PrefCLM_Enhancing_Preference_based_Reinforcement_Learning_with_Crowdsourced_Large_Language_Models/2024-07-11-PrefCLM_Enhancing_Preference_based_Reinforcement_Learning_with_Crowdsourced_Large_Language_Models.html",
    "href": "posts/PrefCLM_Enhancing_Preference_based_Reinforcement_Learning_with_Crowdsourced_Large_Language_Models/2024-07-11-PrefCLM_Enhancing_Preference_based_Reinforcement_Learning_with_Crowdsourced_Large_Language_Models.html",
    "title": "PrefCLM: Enhancing Preference-based Reinforcement Learning with Crowdsourced Large Language Models",
    "section": "",
    "text": "Summary:\nThe article introduces PrefCLM, a novel framework that utilizes crowdsourced large language models (LLMs) as simulated teachers in preference-based reinforcement learning (PbRL). PrefCLM aims to address the challenges of existing PbRL methods, which often require a large volume of feedback and rely on synthetic feedback generated by scripted teachers. The framework employs Dempster-Shafer Theory to fuse individual preferences from multiple LLM agents at the score level, efficiently leveraging their diversity and collective intelligence. Additionally, PrefCLM includes a human-in-the-loop pipeline that facilitates collective refinements based on user interactive feedback.\nMajor Findings:\nAnalysis and Critique:\nWhile PrefCLM shows promising results, there are potential limitations and areas for further research. The reliance on LLMs for generating synthetic feedback may introduce biases or inaccuracies, as LLMs may not fully capture the nuances of human preferences. Additionally, the scalability and generalizability of PrefCLM to more complex tasks and environments remain to be explored. Further research is needed to address these challenges and validate the effectiveness of PrefCLM in diverse HRI scenarios."
  },
  {
    "objectID": "posts/PrefCLM_Enhancing_Preference_based_Reinforcement_Learning_with_Crowdsourced_Large_Language_Models/2024-07-11-PrefCLM_Enhancing_Preference_based_Reinforcement_Learning_with_Crowdsourced_Large_Language_Models.html#appendix",
    "href": "posts/PrefCLM_Enhancing_Preference_based_Reinforcement_Learning_with_Crowdsourced_Large_Language_Models/2024-07-11-PrefCLM_Enhancing_Preference_based_Reinforcement_Learning_with_Crowdsourced_Large_Language_Models.html#appendix",
    "title": "PrefCLM: Enhancing Preference-based Reinforcement Learning with Crowdsourced Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08213v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08213v1\n\n\nTruncated\nFalse\n\n\nWord Count\n19231"
  },
  {
    "objectID": "posts/How_to_Leverage_Personal_Textual_Knowledge_for_Personalized_Conversational_Information_Retrieval/2024-07-23-How_to_Leverage_Personal_Textual_Knowledge_for_Personalized_Conversational_Information_Retrieval.html#appendix",
    "href": "posts/How_to_Leverage_Personal_Textual_Knowledge_for_Personalized_Conversational_Information_Retrieval/2024-07-23-How_to_Leverage_Personal_Textual_Knowledge_for_Personalized_Conversational_Information_Retrieval.html#appendix",
    "title": "How to Leverage Personal Textual Knowledge for Personalized Conversational Information Retrieval",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16192v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16192v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4019"
  },
  {
    "objectID": "posts/Keep_the_Cost_Down_A_Review_on_Methods_to_Optimize_LLM_s_KV_Cache_Consumption/2024-07-25-Keep_the_Cost_Down_A_Review_on_Methods_to_Optimize_LLM_s_KV_Cache_Consumption.html#appendix",
    "href": "posts/Keep_the_Cost_Down_A_Review_on_Methods_to_Optimize_LLM_s_KV_Cache_Consumption/2024-07-25-Keep_the_Cost_Down_A_Review_on_Methods_to_Optimize_LLM_s_KV_Cache_Consumption.html#appendix",
    "title": "Keep the Cost Down: A Review on Methods to Optimize LLM’ s KV-Cache Consumption",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.18003v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.18003v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7020"
  },
  {
    "objectID": "posts/Prompt_Consistency_Image_Generation_(PCIG)_A_Unified_Framework_Integrating_LLMs_Knowledge_Graphs_and_Controllable_Diffusion_Models/2024-06-24-Prompt_Consistency_Image_Generation_(PCIG)_A_Unified_Framework_Integrating_LLMs_Knowledge_Graphs_and_Controllable_Diffusion_Models.html",
    "href": "posts/Prompt_Consistency_Image_Generation_(PCIG)_A_Unified_Framework_Integrating_LLMs_Knowledge_Graphs_and_Controllable_Diffusion_Models/2024-06-24-Prompt_Consistency_Image_Generation_(PCIG)_A_Unified_Framework_Integrating_LLMs_Knowledge_Graphs_and_Controllable_Diffusion_Models.html",
    "title": "Prompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models",
    "section": "",
    "text": "Summary:\nThe paper introduces a novel diffusion-based framework called Prompt-Consistency Image Generation (PCIG) to address the inconsistency between visual output and textual input in Text-to-Image (T2I) generative models. The framework leverages a state-of-the-art large language module to extract objects and construct a knowledge graph to predict the locations of these objects in potentially generated images. It then integrates a controllable image generation model with a visual text generation module to generate an image that is consistent with the original prompt, guided by the predicted object locations.\nMajor Findings:\nAnalysis and Critique:\nWhile PCIG shows promising results in generating images that align with the original prompt, there are some potential limitations and areas for improvement. For instance, the use of GPT4-turbo as the LLM for prompt analysis may introduce additional costs. Additionally, the framework may struggle with generating images with complex relationships and interactions between objects or with small text. Future work could explore the use of more powerful basic diffusion models to address these challenges."
  },
  {
    "objectID": "posts/Prompt_Consistency_Image_Generation_(PCIG)_A_Unified_Framework_Integrating_LLMs_Knowledge_Graphs_and_Controllable_Diffusion_Models/2024-06-24-Prompt_Consistency_Image_Generation_(PCIG)_A_Unified_Framework_Integrating_LLMs_Knowledge_Graphs_and_Controllable_Diffusion_Models.html#appendix",
    "href": "posts/Prompt_Consistency_Image_Generation_(PCIG)_A_Unified_Framework_Integrating_LLMs_Knowledge_Graphs_and_Controllable_Diffusion_Models/2024-06-24-Prompt_Consistency_Image_Generation_(PCIG)_A_Unified_Framework_Integrating_LLMs_Knowledge_Graphs_and_Controllable_Diffusion_Models.html#appendix",
    "title": "Prompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16333v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16333v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5668"
  },
  {
    "objectID": "posts/FSM_A_Finite_State_Machine_Based_Zero_Shot_Prompting_Paradigm_for_Multi_Hop_Question_Answering/2024-07-03-FSM_A_Finite_State_Machine_Based_Zero_Shot_Prompting_Paradigm_for_Multi_Hop_Question_Answering.html#appendix",
    "href": "posts/FSM_A_Finite_State_Machine_Based_Zero_Shot_Prompting_Paradigm_for_Multi_Hop_Question_Answering/2024-07-03-FSM_A_Finite_State_Machine_Based_Zero_Shot_Prompting_Paradigm_for_Multi_Hop_Question_Answering.html#appendix",
    "title": "FSM: A Finite State Machine Based Zero-Shot Prompting Paradigm for Multi-Hop Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02964v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02964v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4635"
  },
  {
    "objectID": "posts/Should_AI_Optimize_Your_Code_A_Comparative_Study_of_Current_Large_Language_Models_Versus_Classical_Optimizing_Compilers/2024-06-17-Should_AI_Optimize_Your_Code_A_Comparative_Study_of_Current_Large_Language_Models_Versus_Classical_Optimizing_Compilers.html#appendix",
    "href": "posts/Should_AI_Optimize_Your_Code_A_Comparative_Study_of_Current_Large_Language_Models_Versus_Classical_Optimizing_Compilers/2024-06-17-Should_AI_Optimize_Your_Code_A_Comparative_Study_of_Current_Large_Language_Models_Versus_Classical_Optimizing_Compilers.html#appendix",
    "title": "Should AI Optimize Your Code? A Comparative Study of Current Large Language Models Versus Classical Optimizing Compilers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12146v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12146v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7663"
  },
  {
    "objectID": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#summary-1",
    "href": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#summary-1",
    "title": "FragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models",
    "section": "Summary:",
    "text": "Summary:\n\nThe paper proposes a method to improve the processing of long contexts in Large Language Models (LLMs) by exploiting fragment-level relations in external memory.\nThe authors formulate fragment-level relations and present several instantiations for different text types.\nThey introduce a relation-aware fragment assessment criteria and present the fragment-connected Hierarchical Memory based LLM.\nThe proposed method is validated on long story understanding, repository-level code generation, and long-term chatting tasks."
  },
  {
    "objectID": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#major-findings",
    "href": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#major-findings",
    "title": "FragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nFragment-level Relations: The authors propose a method to exploit fragment-level relations in external memory to improve the processing of long contexts in LLMs.\nRelation-aware Fragment Assessment: The authors introduce a relation-aware fragment assessment criteria to better assess the importance of each fragment in the context.\nFragment-connected Hierarchical Memory based LLM: The authors present a new LLM architecture that incorporates fragment-level relations in external memory to improve the processing of long contexts."
  },
  {
    "objectID": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#analysis-and-critique",
    "title": "FragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe proposed method effectively addresses the issue of isolated fragment processing in existing External Memory augmented LLMs.\nThe paper provides a comprehensive evaluation of the proposed method on various long text processing tasks, demonstrating its effectiveness.\nHowever, the paper does not discuss the potential limitations or challenges of the proposed method, such as the computational overhead or the impact on the model’s performance.\nAdditionally, the paper does not provide a comparison with other existing methods for processing long contexts in LLMs.\nThe paper could benefit from a more detailed discussion of the potential applications and implications of the proposed method in real-world scenarios.\nOverall, the paper presents a promising approach to improve the processing of long contexts in LLMs, but further research is needed to fully evaluate its potential and limitations."
  },
  {
    "objectID": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#appendix",
    "href": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#appendix",
    "title": "FragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03092v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03092v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7567"
  },
  {
    "objectID": "posts/Towards_a_Client_Centered_Assessment_of_LLM_Therapists_by_Client_Simulation/2024-06-18-Towards_a_Client_Centered_Assessment_of_LLM_Therapists_by_Client_Simulation.html#appendix",
    "href": "posts/Towards_a_Client_Centered_Assessment_of_LLM_Therapists_by_Client_Simulation/2024-06-18-Towards_a_Client_Centered_Assessment_of_LLM_Therapists_by_Client_Simulation.html#appendix",
    "title": "Towards a Client-Centered Assessment of LLM Therapists by Client Simulation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12266v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12266v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10101"
  },
  {
    "objectID": "posts/WildHallucinations_Evaluating_Long_form_Factuality_in_LLMs_with_Real_World_Entity_Queries/2024-07-24-WildHallucinations_Evaluating_Long_form_Factuality_in_LLMs_with_Real_World_Entity_Queries.html#appendix",
    "href": "posts/WildHallucinations_Evaluating_Long_form_Factuality_in_LLMs_with_Real_World_Entity_Queries/2024-07-24-WildHallucinations_Evaluating_Long_form_Factuality_in_LLMs_with_Real_World_Entity_Queries.html#appendix",
    "title": "WildHallucinations: Evaluating Long-form Factuality in LLMs with Real-World Entity Queries",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17468v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17468v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6178"
  },
  {
    "objectID": "posts/Dye4AI_Assuring_Data_Boundary_on_Generative_AI_Services/2024-06-20-Dye4AI_Assuring_Data_Boundary_on_Generative_AI_Services.html#appendix",
    "href": "posts/Dye4AI_Assuring_Data_Boundary_on_Generative_AI_Services/2024-06-20-Dye4AI_Assuring_Data_Boundary_on_Generative_AI_Services.html#appendix",
    "title": "Dye4AI: Assuring Data Boundary on Generative AI Services",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14114v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14114v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15379"
  },
  {
    "objectID": "posts/LLMs_for_User_Interest_Exploration_A_Hybrid_Approach/2024-05-25-LLMs_for_User_Interest_Exploration_A_Hybrid_Approach.html#appendix",
    "href": "posts/LLMs_for_User_Interest_Exploration_A_Hybrid_Approach/2024-05-25-LLMs_for_User_Interest_Exploration_A_Hybrid_Approach.html#appendix",
    "title": "LLMs for User Interest Exploration: A Hybrid Approach",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.16363v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.16363v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5005"
  },
  {
    "objectID": "posts/Semantic_Communication_Enhanced_by_Knowledge_Graph_Representation_Learning/2024-07-27-Semantic_Communication_Enhanced_by_Knowledge_Graph_Representation_Learning.html#appendix",
    "href": "posts/Semantic_Communication_Enhanced_by_Knowledge_Graph_Representation_Learning/2024-07-27-Semantic_Communication_Enhanced_by_Knowledge_Graph_Representation_Learning.html#appendix",
    "title": "Semantic Communication Enhanced by Knowledge Graph Representation Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19338v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19338v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3787"
  },
  {
    "objectID": "posts/Are_Large_Language_Models_Really_Bias_Free_Jailbreak_Prompts_for_Assessing_Adversarial_Robustness_to_Bias_Elicitation/2024-07-11-Are_Large_Language_Models_Really_Bias_Free_Jailbreak_Prompts_for_Assessing_Adversarial_Robustness_to_Bias_Elicitation.html#appendix",
    "href": "posts/Are_Large_Language_Models_Really_Bias_Free_Jailbreak_Prompts_for_Assessing_Adversarial_Robustness_to_Bias_Elicitation/2024-07-11-Are_Large_Language_Models_Really_Bias_Free_Jailbreak_Prompts_for_Assessing_Adversarial_Robustness_to_Bias_Elicitation.html#appendix",
    "title": "Are Large Language Models Really Bias-Free? Jailbreak Prompts for Assessing Adversarial Robustness to Bias Elicitation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08441v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08441v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5194"
  },
  {
    "objectID": "posts/MPCODER_Multi_user_Personalized_Code_Generator_with_Explicit_and_Implicit_Style_Representation_Learning/2024-06-25-MPCODER_Multi_user_Personalized_Code_Generator_with_Explicit_and_Implicit_Style_Representation_Learning.html#appendix",
    "href": "posts/MPCODER_Multi_user_Personalized_Code_Generator_with_Explicit_and_Implicit_Style_Representation_Learning/2024-06-25-MPCODER_Multi_user_Personalized_Code_Generator_with_Explicit_and_Implicit_Style_Representation_Learning.html#appendix",
    "title": "MPCODER: Multi-user Personalized Code Generator with Explicit and Implicit Style Representation Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17255v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17255v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8886"
  },
  {
    "objectID": "posts/Mix_CPT_A_Domain_Adaptation_Framework_via_Decoupling_Knowledge_Learning_and_Format_Alignment/2024-07-15-Mix_CPT_A_Domain_Adaptation_Framework_via_Decoupling_Knowledge_Learning_and_Format_Alignment.html#appendix",
    "href": "posts/Mix_CPT_A_Domain_Adaptation_Framework_via_Decoupling_Knowledge_Learning_and_Format_Alignment/2024-07-15-Mix_CPT_A_Domain_Adaptation_Framework_via_Decoupling_Knowledge_Learning_and_Format_Alignment.html#appendix",
    "title": "Mix-CPT: A Domain Adaptation Framework via Decoupling Knowledge Learning and Format Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10804v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10804v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8459"
  },
  {
    "objectID": "posts/Automated_Adversarial_Discovery_for_Safety_Classifiers/2024-06-24-Automated_Adversarial_Discovery_for_Safety_Classifiers.html#appendix",
    "href": "posts/Automated_Adversarial_Discovery_for_Safety_Classifiers/2024-06-24-Automated_Adversarial_Discovery_for_Safety_Classifiers.html#appendix",
    "title": "Automated Adversarial Discovery for Safety Classifiers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17104v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17104v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6260"
  },
  {
    "objectID": "posts/AutoScale_Automatic_Prediction_of_Compute_optimal_Data_Composition_for_Training_LLMs/2024-07-29-AutoScale_Automatic_Prediction_of_Compute_optimal_Data_Composition_for_Training_LLMs.html#appendix",
    "href": "posts/AutoScale_Automatic_Prediction_of_Compute_optimal_Data_Composition_for_Training_LLMs/2024-07-29-AutoScale_Automatic_Prediction_of_Compute_optimal_Data_Composition_for_Training_LLMs.html#appendix",
    "title": "AutoScale: Automatic Prediction of Compute-optimal Data Composition for Training LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20177v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20177v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11502"
  },
  {
    "objectID": "posts/Unmasking_the_Imposters_In_Domain_Detection_of_Human_vs._Machine_Generated_Tweets/2024-06-25-Unmasking_the_Imposters_In_Domain_Detection_of_Human_vs._Machine_Generated_Tweets.html#appendix",
    "href": "posts/Unmasking_the_Imposters_In_Domain_Detection_of_Human_vs._Machine_Generated_Tweets/2024-06-25-Unmasking_the_Imposters_In_Domain_Detection_of_Human_vs._Machine_Generated_Tweets.html#appendix",
    "title": "Unmasking the Imposters: In-Domain Detection of Human vs. Machine-Generated Tweets",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17967v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17967v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6557"
  },
  {
    "objectID": "posts/Zero_Shot_End_To_End_Spoken_Question_Answering_In_Medical_Domain/2024-06-09-Zero_Shot_End_To_End_Spoken_Question_Answering_In_Medical_Domain.html#appendix",
    "href": "posts/Zero_Shot_End_To_End_Spoken_Question_Answering_In_Medical_Domain/2024-06-09-Zero_Shot_End_To_End_Spoken_Question_Answering_In_Medical_Domain.html#appendix",
    "title": "Zero-Shot End-To-End Spoken Question Answering In Medical Domain",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05876v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05876v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4005"
  },
  {
    "objectID": "posts/Self_Cognition_in_Large_Language_Models_An_Exploratory_Study/2024-07-01-Self_Cognition_in_Large_Language_Models_An_Exploratory_Study.html#appendix",
    "href": "posts/Self_Cognition_in_Large_Language_Models_An_Exploratory_Study/2024-07-01-Self_Cognition_in_Large_Language_Models_An_Exploratory_Study.html#appendix",
    "title": "Self-Cognition in Large Language Models: An Exploratory Study",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01505v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01505v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6005"
  },
  {
    "objectID": "posts/AdaCoder_Adaptive_Prompt_Compression_for_Programmatic_Visual_Question_Answering/2024-07-28-AdaCoder_Adaptive_Prompt_Compression_for_Programmatic_Visual_Question_Answering.html#appendix",
    "href": "posts/AdaCoder_Adaptive_Prompt_Compression_for_Programmatic_Visual_Question_Answering/2024-07-28-AdaCoder_Adaptive_Prompt_Compression_for_Programmatic_Visual_Question_Answering.html#appendix",
    "title": "AdaCoder: Adaptive Prompt Compression for Programmatic Visual Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19410v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19410v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6971"
  },
  {
    "objectID": "posts/LAB_Bench_Measuring_Capabilities_of_Language_Models_for_Biology_Research/2024-07-14-LAB_Bench_Measuring_Capabilities_of_Language_Models_for_Biology_Research.html",
    "href": "posts/LAB_Bench_Measuring_Capabilities_of_Language_Models_for_Biology_Research/2024-07-14-LAB_Bench_Measuring_Capabilities_of_Language_Models_for_Biology_Research.html",
    "title": "LAB-Bench: Measuring Capabilities of Language Models for Biology Research",
    "section": "",
    "text": "Summary:\nThe paper introduces the Language Agent Biology Benchmark (LAB-Bench), a dataset of over 2,400 multiple-choice questions for evaluating AI systems on various practical biology research capabilities. The benchmark covers tasks such as recall and reasoning over literature, interpretation of figures, access and navigation of databases, and comprehension and manipulation of DNA and protein sequences. The authors also introduce a set of 41 “human-hard” multi-step multiple-choice questions, which they believe may take a trained molecular biologist more than 10 minutes to answer completely. The paper evaluates the performance of several frontier commercial and open-source models against the benchmark and compares their capabilities to expert human biology researchers.\nMajor Findings:\nAnalysis and Critique:\nThe LAB-Bench dataset provides a valuable resource for evaluating AI systems on practical biology research tasks. The inclusion of “human-hard” multi-step multiple-choice questions is a unique feature that can help assess the capabilities of AI systems in handling complex tasks. However, the paper does not provide a detailed analysis of the performance of the evaluated models or a comparison to human experts. Additionally, the paper does not discuss the limitations of the dataset or the potential biases in the questions. Further research is needed to evaluate the effectiveness of the LAB-Bench dataset in assessing the capabilities of AI systems for practical biology research tasks."
  },
  {
    "objectID": "posts/LAB_Bench_Measuring_Capabilities_of_Language_Models_for_Biology_Research/2024-07-14-LAB_Bench_Measuring_Capabilities_of_Language_Models_for_Biology_Research.html#appendix",
    "href": "posts/LAB_Bench_Measuring_Capabilities_of_Language_Models_for_Biology_Research/2024-07-14-LAB_Bench_Measuring_Capabilities_of_Language_Models_for_Biology_Research.html#appendix",
    "title": "LAB-Bench: Measuring Capabilities of Language Models for Biology Research",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10362v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10362v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20052"
  },
  {
    "objectID": "posts/DistillSeq_A_Framework_for_Safety_Alignment_Testing_in_Large_Language_Models_using_Knowledge_Distillation/2024-07-14-DistillSeq_A_Framework_for_Safety_Alignment_Testing_in_Large_Language_Models_using_Knowledge_Distillation.html#appendix",
    "href": "posts/DistillSeq_A_Framework_for_Safety_Alignment_Testing_in_Large_Language_Models_using_Knowledge_Distillation/2024-07-14-DistillSeq_A_Framework_for_Safety_Alignment_Testing_in_Large_Language_Models_using_Knowledge_Distillation.html#appendix",
    "title": "DistillSeq: A Framework for Safety Alignment Testing in Large Language Models using Knowledge Distillation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10106v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10106v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10899"
  },
  {
    "objectID": "posts/Silent_Signals_Loud_Impact_LLMs_for_Word_Sense_Disambiguation_of_Coded_Dog_Whistles/2024-06-10-Silent_Signals_Loud_Impact_LLMs_for_Word_Sense_Disambiguation_of_Coded_Dog_Whistles.html#appendix",
    "href": "posts/Silent_Signals_Loud_Impact_LLMs_for_Word_Sense_Disambiguation_of_Coded_Dog_Whistles/2024-06-10-Silent_Signals_Loud_Impact_LLMs_for_Word_Sense_Disambiguation_of_Coded_Dog_Whistles.html#appendix",
    "title": "Silent Signals, Loud Impact: LLMs for Word-Sense Disambiguation of Coded Dog Whistles",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06840v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06840v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8725"
  },
  {
    "objectID": "posts/FactFinders_at_CheckThat!_2024_Refining_Check_worthy_Statement_Detection_with_LLMs_through_Data_Pruning/2024-06-26-FactFinders_at_CheckThat!_2024_Refining_Check_worthy_Statement_Detection_with_LLMs_through_Data_Pruning.html#appendix",
    "href": "posts/FactFinders_at_CheckThat!_2024_Refining_Check_worthy_Statement_Detection_with_LLMs_through_Data_Pruning/2024-06-26-FactFinders_at_CheckThat!_2024_Refining_Check_worthy_Statement_Detection_with_LLMs_through_Data_Pruning.html#appendix",
    "title": "FactFinders at CheckThat! 2024: Refining Check-worthy Statement Detection with LLMs through Data Pruning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18297v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18297v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7119"
  },
  {
    "objectID": "posts/RVISA_Reasoning_and_Verification_for_Implicit_Sentiment_Analysis/2024-07-02-RVISA_Reasoning_and_Verification_for_Implicit_Sentiment_Analysis.html#appendix",
    "href": "posts/RVISA_Reasoning_and_Verification_for_Implicit_Sentiment_Analysis/2024-07-02-RVISA_Reasoning_and_Verification_for_Implicit_Sentiment_Analysis.html#appendix",
    "title": "RVISA: Reasoning and Verification for Implicit Sentiment Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02340v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02340v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7317"
  },
  {
    "objectID": "posts/PaCE_Parsimonious_Concept_Engineering_for_Large_Language_Models/2024-06-06-PaCE_Parsimonious_Concept_Engineering_for_Large_Language_Models.html#appendix",
    "href": "posts/PaCE_Parsimonious_Concept_Engineering_for_Large_Language_Models/2024-06-06-PaCE_Parsimonious_Concept_Engineering_for_Large_Language_Models.html#appendix",
    "title": "PaCE: Parsimonious Concept Engineering for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04331v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04331v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9538"
  },
  {
    "objectID": "posts/How_Efficient_is_LLM_Generated_Code_A_Rigorous__High_Standard_Benchmark/2024-06-10-How_Efficient_is_LLM_Generated_Code_A_Rigorous__High_Standard_Benchmark.html#appendix",
    "href": "posts/How_Efficient_is_LLM_Generated_Code_A_Rigorous__High_Standard_Benchmark/2024-06-10-How_Efficient_is_LLM_Generated_Code_A_Rigorous__High_Standard_Benchmark.html#appendix",
    "title": "How Efficient is LLM-Generated Code? A Rigorous & High-Standard Benchmark",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06647v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06647v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8226"
  },
  {
    "objectID": "posts/Enhancing_Medication_Recommendation_with_LLM_Text_Representation/2024-07-15-Enhancing_Medication_Recommendation_with_LLM_Text_Representation.html",
    "href": "posts/Enhancing_Medication_Recommendation_with_LLM_Text_Representation/2024-07-15-Enhancing_Medication_Recommendation_with_LLM_Text_Representation.html",
    "title": "Enhancing Medication Recommendation with LLM Text Representation",
    "section": "",
    "text": "Summary:\nThe paper proposes a method to enhance medication recommendation by utilizing Large Language Models (LLMs) for text representation. The method aims to increase the utilization of unstructured or semi-structured data, such as clinical notes, which contain complex terminology. The proposed method can be applied to existing base models and improve medication recommendation performance with the combination representation of text and medical codes. The experiments conducted on two different datasets demonstrate that LLM text representation alone can even demonstrate a comparable ability to medical code representation alone.\nMajor Findings:\n**Analysis and Critique"
  },
  {
    "objectID": "posts/Enhancing_Medication_Recommendation_with_LLM_Text_Representation/2024-07-15-Enhancing_Medication_Recommendation_with_LLM_Text_Representation.html#appendix",
    "href": "posts/Enhancing_Medication_Recommendation_with_LLM_Text_Representation/2024-07-15-Enhancing_Medication_Recommendation_with_LLM_Text_Representation.html#appendix",
    "title": "Enhancing Medication Recommendation with LLM Text Representation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10453v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10453v1\n\n\nTruncated\nTrue\n\n\nWord Count\n31783"
  },
  {
    "objectID": "posts/3D_Question_Answering_for_City_Scene_Understanding/2024-07-24-3D_Question_Answering_for_City_Scene_Understanding.html#appendix",
    "href": "posts/3D_Question_Answering_for_City_Scene_Understanding/2024-07-24-3D_Question_Answering_for_City_Scene_Understanding.html#appendix",
    "title": "3D Question Answering for City Scene Understanding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17398v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17398v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7976"
  },
  {
    "objectID": "posts/Can_ChatGPT_Pass_a_Theory_of_Computing_Course/2024-07-10-Can_ChatGPT_Pass_a_Theory_of_Computing_Course.html#appendix",
    "href": "posts/Can_ChatGPT_Pass_a_Theory_of_Computing_Course/2024-07-10-Can_ChatGPT_Pass_a_Theory_of_Computing_Course.html#appendix",
    "title": "Can ChatGPT Pass a Theory of Computing Course?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07757v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07757v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6148"
  },
  {
    "objectID": "posts/Model_Tells_You_Where_to_Merge_Adaptive_KV_Cache_Merging_for_LLMs_on_Long_Context_Tasks/2024-07-11-Model_Tells_You_Where_to_Merge_Adaptive_KV_Cache_Merging_for_LLMs_on_Long_Context_Tasks.html#appendix",
    "href": "posts/Model_Tells_You_Where_to_Merge_Adaptive_KV_Cache_Merging_for_LLMs_on_Long_Context_Tasks/2024-07-11-Model_Tells_You_Where_to_Merge_Adaptive_KV_Cache_Merging_for_LLMs_on_Long_Context_Tasks.html#appendix",
    "title": "Model Tells You Where to Merge: Adaptive KV Cache Merging for LLMs on Long-Context Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08454v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08454v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8835"
  },
  {
    "objectID": "posts/CoDefeater_Using_LLMs_To_Find_Defeaters_in_Assurance_Cases/2024-07-18-CoDefeater_Using_LLMs_To_Find_Defeaters_in_Assurance_Cases.html#appendix",
    "href": "posts/CoDefeater_Using_LLMs_To_Find_Defeaters_in_Assurance_Cases/2024-07-18-CoDefeater_Using_LLMs_To_Find_Defeaters_in_Assurance_Cases.html#appendix",
    "title": "CoDefeater: Using LLMs To Find Defeaters in Assurance Cases",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.13717v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.13717v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4468"
  },
  {
    "objectID": "posts/Aligning_Agents_like_Large_Language_Models/2024-06-06-Aligning_Agents_like_Large_Language_Models.html",
    "href": "posts/Aligning_Agents_like_Large_Language_Models/2024-06-06-Aligning_Agents_like_Large_Language_Models.html",
    "title": "Aligning Agents like Large Language Models",
    "section": "",
    "text": "Summary:\nThe paper explores the challenge of training agents to behave as desired in complex 3D environments using high-dimensional sensory information. The authors draw an analogy between the undesirable behaviors of imitation learning agents and the unhelpful responses of unaligned large language models (LLMs). They investigate the procedure for aligning LLMs and apply it to aligning agents in a 3D environment from pixels. The authors focus on an academically illustrative part of a modern console game where players must navigate from a randomly selected spawn point to one of three jumppads. They demonstrate that they can align their agent to consistently perform the desired mode while providing insights and advice for successfully applying this approach to training agents.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an innovative approach to aligning agents in complex 3D environments by drawing an analogy between the undesirable behaviors of imitation learning agents and the unhelpful responses of unaligned LLMs. The authors’ investigation of the procedure for aligning LLMs and its application to aligning agents is a significant contribution to the field. However, the paper’s focus on an academically illustrative part of a modern console game may limit the generalizability of the findings to other complex 3D environments. Additionally, the use of synthetic preference labelling may not fully capture the complexity of human preferences in real-world scenarios. Further research is needed to evaluate the effectiveness of this approach in more diverse and complex environments and to explore the use of human preference labelling."
  },
  {
    "objectID": "posts/Aligning_Agents_like_Large_Language_Models/2024-06-06-Aligning_Agents_like_Large_Language_Models.html#appendix",
    "href": "posts/Aligning_Agents_like_Large_Language_Models/2024-06-06-Aligning_Agents_like_Large_Language_Models.html#appendix",
    "title": "Aligning Agents like Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04208v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04208v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12915"
  },
  {
    "objectID": "posts/BertaQA_How_Much_Do_Language_Models_Know_About_Local_Culture/2024-06-11-BertaQA_How_Much_Do_Language_Models_Know_About_Local_Culture.html#appendix",
    "href": "posts/BertaQA_How_Much_Do_Language_Models_Know_About_Local_Culture/2024-06-11-BertaQA_How_Much_Do_Language_Models_Know_About_Local_Culture.html#appendix",
    "title": "BertaQA: How Much Do Language Models Know About Local Culture?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07302v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07302v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5979"
  },
  {
    "objectID": "posts/Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering/2024-06-06-Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering.html",
    "href": "posts/Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering/2024-06-06-Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering.html",
    "title": "Tool-Planner: Dynamic Solution Tree Planning for Large Language Model with Tool Clustering",
    "section": "",
    "text": "Summary: The paper introduces Tool-Planner, a task-processing framework that groups tools based on their API functions into toolkits. This approach allows large language models (LLMs) to implement planning across various toolkits and reselect or adjust tools when a tool error occurs. The authors propose Tool-Planner to address the challenges of redundant error correction and designing a correct plan among multiple tools in tool learning. The experiments conducted demonstrate that Tool-Planner has a high pass and win rate across different datasets and optimizes the planning scheme for tool learning in models such as GPT-4 and Claude 3.\nMajor Findings: 1. Tool-Planner achieves state-of-the-art performance on five out of six datasets and shows competitive performance on the remaining dataset. 2. The method improves the pass rate by +8.8% and the win rate by +9.1% compared to the"
  },
  {
    "objectID": "posts/Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering/2024-06-06-Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering.html#appendix",
    "href": "posts/Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering/2024-06-06-Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering.html#appendix",
    "title": "Tool-Planner: Dynamic Solution Tree Planning for Large Language Model with Tool Clustering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03807v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03807v1\n\n\nTruncated\nTrue\n\n\nWord Count\n29774"
  },
  {
    "objectID": "posts/Teaching_LLMs_to_Abstain_across_Languages_via_Multilingual_Feedback/2024-06-22-Teaching_LLMs_to_Abstain_across_Languages_via_Multilingual_Feedback.html",
    "href": "posts/Teaching_LLMs_to_Abstain_across_Languages_via_Multilingual_Feedback/2024-06-22-Teaching_LLMs_to_Abstain_across_Languages_via_Multilingual_Feedback.html",
    "title": "Teaching LLMs to Abstain across Languages via Multilingual Feedback",
    "section": "",
    "text": "Summary:\nThe paper presents a study on teaching multilingual large language models (LLMs) to abstain from answering when they encounter knowledge gaps, with a focus on mitigating hallucinations in multilingual settings. The authors propose a strategy that involves generating and learning from multilingual feedback in related languages, which helps identify knowledge gaps across diverse languages, cultures, and communities. The proposed approach is evaluated on three datasets featuring open-book, closed-book, and commonsense QA, and is shown to outperform various strong baselines, achieving up to 9.2% improvement for low-resource languages. The study also reveals that multilingual feedback is an effective and more equitable abstain strategy, with cultural factors playing a significant role in language selection and LLM abstention behavior.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel approach to teaching LLMs to abstain from answering in the face of knowledge gaps, with a focus on multilingual settings. The proposed strategy of generating and learning from multilingual feedback in related languages is shown to be effective in identifying knowledge gaps and improving LLM abstention behavior. However, the study is limited in its evaluation of the proposed approach on only three datasets, and it is unclear how well the approach would generalize to other datasets and tasks. Additionally, the study does not address potential issues related to the quality and reliability of the generated feedback, which could impact the effectiveness of the proposed approach. Further research is needed to address these limitations and evaluate the proposed approach in a more comprehensive manner."
  },
  {
    "objectID": "posts/Teaching_LLMs_to_Abstain_across_Languages_via_Multilingual_Feedback/2024-06-22-Teaching_LLMs_to_Abstain_across_Languages_via_Multilingual_Feedback.html#appendix",
    "href": "posts/Teaching_LLMs_to_Abstain_across_Languages_via_Multilingual_Feedback/2024-06-22-Teaching_LLMs_to_Abstain_across_Languages_via_Multilingual_Feedback.html#appendix",
    "title": "Teaching LLMs to Abstain across Languages via Multilingual Feedback",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.15948v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.15948v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8591"
  },
  {
    "objectID": "posts/Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing/2024-06-20-Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing.html",
    "href": "posts/Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing/2024-06-20-Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing.html",
    "title": "Raising the Bar: Investigating the Values of Large Language Models via Generative Evolving Testing",
    "section": "",
    "text": "Summary:\nThe paper proposes a novel framework called GETA (Generative Evolving Testing of vAlues) to address the evaluation chronoeffect problem in assessing the value alignment of Large Language Models (LLMs). GETA incorporates an iteratively-updated item generator that infers each LLM’s moral boundaries and generates difficulty-tailored testing items, accurately reflecting the true alignment extent. This process theoretically learns a joint distribution of item and model response, with item difficulty and value conformity as latent variables. The generator co-evolves with the LLM, addressing the chronoeffect. The paper evaluates various popular LLMs and demonstrates that GETA can create difficulty-matching testing items and more accurately assess LLMs’ values, better consistent with their performance on unseen OOD and i.i.d. items.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a promising approach to address the evaluation chronoeffect problem in assessing the value alignment of LLMs. However, there are some potential limitations and areas for further research:\nOverall, the paper presents an innovative approach to address a significant challenge in evaluating LLMs, and further research is needed to fully understand its"
  },
  {
    "objectID": "posts/Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing/2024-06-20-Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing.html#appendix",
    "href": "posts/Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing/2024-06-20-Raising_the_Bar_Investigating_the_Values_of_Large_Language_Models_via_Generative_Evolving_Testing.html#appendix",
    "title": "Raising the Bar: Investigating the Values of Large Language Models via Generative Evolving Testing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14230v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14230v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11743"
  },
  {
    "objectID": "posts/CleanGen_Mitigating_Backdoor_Attacks_for_Generation_Tasks_in_Large_Language_Models/2024-06-18-CleanGen_Mitigating_Backdoor_Attacks_for_Generation_Tasks_in_Large_Language_Models.html#appendix",
    "href": "posts/CleanGen_Mitigating_Backdoor_Attacks_for_Generation_Tasks_in_Large_Language_Models/2024-06-18-CleanGen_Mitigating_Backdoor_Attacks_for_Generation_Tasks_in_Large_Language_Models.html#appendix",
    "title": "CleanGen: Mitigating Backdoor Attacks for Generation Tasks in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12257v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12257v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7540"
  },
  {
    "objectID": "posts/Enhancing_LLMs_Cognition_via_Structurization/2024-07-23-Enhancing_LLMs_Cognition_via_Structurization.html#appendix",
    "href": "posts/Enhancing_LLMs_Cognition_via_Structurization/2024-07-23-Enhancing_LLMs_Cognition_via_Structurization.html#appendix",
    "title": "Enhancing LLM’s Cognition via Structurization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16434v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16434v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10931"
  },
  {
    "objectID": "posts/Towards_Comprehensive_Preference_Data_Collection_for_Reward_Modeling/2024-06-24-Towards_Comprehensive_Preference_Data_Collection_for_Reward_Modeling.html#appendix",
    "href": "posts/Towards_Comprehensive_Preference_Data_Collection_for_Reward_Modeling/2024-06-24-Towards_Comprehensive_Preference_Data_Collection_for_Reward_Modeling.html#appendix",
    "title": "Towards Comprehensive Preference Data Collection for Reward Modeling",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16486v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16486v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3102"
  },
  {
    "objectID": "posts/FastMem_Fast_Memorization_of_Prompt_Improves_Context_Awareness_of_Large_Language_Models/2024-06-23-FastMem_Fast_Memorization_of_Prompt_Improves_Context_Awareness_of_Large_Language_Models.html#appendix",
    "href": "posts/FastMem_Fast_Memorization_of_Prompt_Improves_Context_Awareness_of_Large_Language_Models/2024-06-23-FastMem_Fast_Memorization_of_Prompt_Improves_Context_Awareness_of_Large_Language_Models.html#appendix",
    "title": "FastMem: Fast Memorization of Prompt Improves Context Awareness of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16069v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16069v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7001"
  },
  {
    "objectID": "posts/SNAP_Unlearning_Selective_Knowledge_in_Large_Language_Models_with_Negative_Instructions/2024-06-18-SNAP_Unlearning_Selective_Knowledge_in_Large_Language_Models_with_Negative_Instructions.html#appendix",
    "href": "posts/SNAP_Unlearning_Selective_Knowledge_in_Large_Language_Models_with_Negative_Instructions/2024-06-18-SNAP_Unlearning_Selective_Knowledge_in_Large_Language_Models_with_Negative_Instructions.html#appendix",
    "title": "SNAP: Unlearning Selective Knowledge in Large Language Models with Negative Instructions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12329v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12329v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7278"
  },
  {
    "objectID": "posts/GPT_Assisted_Annotation_of_Rhetorical_and_Linguistic_Features_for_Interpretable_Propaganda_Technique_Detection_in_News_Text/2024-07-16-GPT_Assisted_Annotation_of_Rhetorical_and_Linguistic_Features_for_Interpretable_Propaganda_Technique_Detection_in_News_Text.html#appendix",
    "href": "posts/GPT_Assisted_Annotation_of_Rhetorical_and_Linguistic_Features_for_Interpretable_Propaganda_Technique_Detection_in_News_Text/2024-07-16-GPT_Assisted_Annotation_of_Rhetorical_and_Linguistic_Features_for_Interpretable_Propaganda_Technique_Detection_in_News_Text.html#appendix",
    "title": "GPT Assisted Annotation of Rhetorical and Linguistic Features for Interpretable Propaganda Technique Detection in News Text",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.11827v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.11827v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7256"
  },
  {
    "objectID": "posts/Role_Play_Zero_Shot_Prompting_with_Large_Language_Models_for_Open_Domain_Human_Machine_Conversation/2024-06-26-Role_Play_Zero_Shot_Prompting_with_Large_Language_Models_for_Open_Domain_Human_Machine_Conversation.html#appendix",
    "href": "posts/Role_Play_Zero_Shot_Prompting_with_Large_Language_Models_for_Open_Domain_Human_Machine_Conversation/2024-06-26-Role_Play_Zero_Shot_Prompting_with_Large_Language_Models_for_Open_Domain_Human_Machine_Conversation.html#appendix",
    "title": "Role-Play Zero-Shot Prompting with Large Language Models for Open-Domain Human-Machine Conversation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18460v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18460v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7179"
  },
  {
    "objectID": "posts/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions/2024-07-07-Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions.html#summary-1",
    "href": "posts/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions/2024-07-07-Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions.html#summary-1",
    "title": "Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions",
    "section": "Summary:",
    "text": "Summary:\nThe study examines the performance of autoregressive LLMs and fine-tuned foundation language models in predicting gender categories (i.e., female, male, and neutral) given first names. It also investigates the impact of adding birth year on gender prediction accuracy. The research focuses on the limitations and biases of LLMs in predicting gender-neutral names and names with evolving gender associations over time."
  },
  {
    "objectID": "posts/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions/2024-07-07-Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions.html#major-findings",
    "href": "posts/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions/2024-07-07-Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions.html#major-findings",
    "title": "Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nFine-tuned foundational language models predicted gender-neutral first names more accurately than LLMs under 0-shot prompting across all three datasets. BERT results in the highest average accuracy for the US and Canada dataset, while RoBERTa outperformed BERT on the France dataset.\nMost LLMs showed higher accuracy in gender prediction when provided with 5 labeled name-gender pairs through in-context learning compared to the 0-shot setting across all datasets.\nIncorporating birth years as an additional input feature improved the prediction accuracy of foundational language models compared to the first-name-only setting. However, most LLMs showed a decline in accuracy when birth years were added, particularly in predicting gender-neutral names.\nThe accuracy of gender prediction using the US SSA dynamic gender label dataset has increased in recent years for most LLMs, including Llama3, Mixtral-8x7B, Claude 3 Haiku, and GPT-3.5.\nLLMs have worst performance on gender-neutral names, and the accuracy of gender prediction is higher for English-based first names in the US and Canada SSA datasets than in the France SSA."
  },
  {
    "objectID": "posts/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions/2024-07-07-Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions.html#analysis-and-critique",
    "href": "posts/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions/2024-07-07-Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions.html#analysis-and-critique",
    "title": "Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe study highlights the limitations and biases of LLMs in predicting gender-neutral names and names with evolving gender associations over time. The research underscores the need for more inclusive gender categories and the importance of considering temporal information in gender prediction tasks. However, the study is limited to specific countries, and the dataset preparation involved a subjective threshold to determine gender-neutral names. The prompt templates employed for interacting with LLMs were not optimized, which may lead to variations in results with different prompt formulations. The study also does not consider a broad spectrum of countries and cultures"
  },
  {
    "objectID": "posts/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions/2024-07-07-Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions.html#appendix",
    "href": "posts/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions/2024-07-07-Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender_Neutral_Name_Predictions.html#appendix",
    "title": "Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05271v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05271v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6704"
  },
  {
    "objectID": "posts/AssertionBench_A_Benchmark_to_Evaluate_Large_Language_Models_for_Assertion_Generation/2024-06-26-AssertionBench_A_Benchmark_to_Evaluate_Large_Language_Models_for_Assertion_Generation.html#appendix",
    "href": "posts/AssertionBench_A_Benchmark_to_Evaluate_Large_Language_Models_for_Assertion_Generation/2024-06-26-AssertionBench_A_Benchmark_to_Evaluate_Large_Language_Models_for_Assertion_Generation.html#appendix",
    "title": "AssertionBench: A Benchmark to Evaluate Large-Language Models for Assertion Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18627v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18627v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6426"
  },
  {
    "objectID": "posts/Adversarial_Search_Engine_Optimization_for_Large_Language_Models/2024-06-26-Adversarial_Search_Engine_Optimization_for_Large_Language_Models.html#appendix",
    "href": "posts/Adversarial_Search_Engine_Optimization_for_Large_Language_Models/2024-06-26-Adversarial_Search_Engine_Optimization_for_Large_Language_Models.html#appendix",
    "title": "Adversarial Search Engine Optimization for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18382v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18382v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13149"
  },
  {
    "objectID": "posts/CLAVE_An_Adaptive_Framework_for_Evaluating_Values_of_LLM_Generated_Responses/2024-07-15-CLAVE_An_Adaptive_Framework_for_Evaluating_Values_of_LLM_Generated_Responses.html#appendix",
    "href": "posts/CLAVE_An_Adaptive_Framework_for_Evaluating_Values_of_LLM_Generated_Responses/2024-07-15-CLAVE_An_Adaptive_Framework_for_Evaluating_Values_of_LLM_Generated_Responses.html#appendix",
    "title": "CLAVE: An Adaptive Framework for Evaluating Values of LLM Generated Responses",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10725v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10725v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9188"
  },
  {
    "objectID": "posts/LLM_Generated_Tips_Rival_Expert_Created_Tips_in_Helping_Students_Answer_Quantum_Computing_Questions/2024-07-24-LLM_Generated_Tips_Rival_Expert_Created_Tips_in_Helping_Students_Answer_Quantum_Computing_Questions.html#appendix",
    "href": "posts/LLM_Generated_Tips_Rival_Expert_Created_Tips_in_Helping_Students_Answer_Quantum_Computing_Questions/2024-07-24-LLM_Generated_Tips_Rival_Expert_Created_Tips_in_Helping_Students_Answer_Quantum_Computing_Questions.html#appendix",
    "title": "LLM-Generated Tips Rival Expert-Created Tips in Helping Students Answer Quantum-Computing Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17024v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17024v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10424"
  },
  {
    "objectID": "posts/Large_Language_Models_are_Interpretable_Learners/2024-06-25-Large_Language_Models_are_Interpretable_Learners.html#major-findings",
    "href": "posts/Large_Language_Models_are_Interpretable_Learners/2024-06-25-Large_Language_Models_are_Interpretable_Learners.html#major-findings",
    "title": "Large Language Models are Interpretable Learners",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nLSPs effectively bridge the gap between expressiveness and interpretability in machine learning models by leveraging pretrained LLMs and symbolic programs.\nThe proposed divide-and-conquer approach to incrementally build the program from scratch, guided by LLMs, demonstrates superior performance compared to traditional methods.\nThe knowledge learned by LSPs is easily transferable to humans, other LLMs, and generalizes well to out-of-distribution samples."
  },
  {
    "objectID": "posts/Large_Language_Models_are_Interpretable_Learners/2024-06-25-Large_Language_Models_are_Interpretable_Learners.html#analysis-and-critique",
    "href": "posts/Large_Language_Models_are_Interpretable_Learners/2024-06-25-Large_Language_Models_are_Interpretable_Learners.html#analysis-and-critique",
    "title": "Large Language Models are Interpretable Learners",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents an innovative approach to addressing the trade-off between expressiveness and interpretability in machine learning models. The use of pretrained LLMs and symbolic programs in LSPs offers a promising solution to this long-standing challenge.\nHowever, the paper does not discuss potential limitations or unanswered questions that may arise from the proposed method. For instance, the reliance on pretrained LLMs may introduce biases or limitations in the learned programs, as these models are trained on specific datasets and may not generalize well to all scenarios. Additionally, the paper does not address the computational cost of training LSPs, which may be a significant concern for large-scale applications.\nFur"
  },
  {
    "objectID": "posts/Large_Language_Models_are_Interpretable_Learners/2024-06-25-Large_Language_Models_are_Interpretable_Learners.html#appendix",
    "href": "posts/Large_Language_Models_are_Interpretable_Learners/2024-06-25-Large_Language_Models_are_Interpretable_Learners.html#appendix",
    "title": "Large Language Models are Interpretable Learners",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17224v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17224v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8763"
  },
  {
    "objectID": "posts/Evolutionary_Prompt_Design_for_LLM_Based_Post_ASR_Error_Correction/2024-07-23-Evolutionary_Prompt_Design_for_LLM_Based_Post_ASR_Error_Correction.html#appendix",
    "href": "posts/Evolutionary_Prompt_Design_for_LLM_Based_Post_ASR_Error_Correction/2024-07-23-Evolutionary_Prompt_Design_for_LLM_Based_Post_ASR_Error_Correction.html#appendix",
    "title": "Evolutionary Prompt Design for LLM-Based Post-ASR Error Correction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16370v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16370v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3509"
  },
  {
    "objectID": "posts/Self_play_with_Execution_Feedback_Improving_Instruction_following_Capabilities_of_Large_Language_Models/2024-06-19-Self_play_with_Execution_Feedback_Improving_Instruction_following_Capabilities_of_Large_Language_Models.html#appendix",
    "href": "posts/Self_play_with_Execution_Feedback_Improving_Instruction_following_Capabilities_of_Large_Language_Models/2024-06-19-Self_play_with_Execution_Feedback_Improving_Instruction_following_Capabilities_of_Large_Language_Models.html#appendix",
    "title": "Self-play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13542v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13542v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4670"
  },
  {
    "objectID": "posts/Enhancing_Model_Performance_Another_Approach_to_Vision_Language_Instruction_Tuning/2024-07-25-Enhancing_Model_Performance_Another_Approach_to_Vision_Language_Instruction_Tuning.html#appendix",
    "href": "posts/Enhancing_Model_Performance_Another_Approach_to_Vision_Language_Instruction_Tuning/2024-07-25-Enhancing_Model_Performance_Another_Approach_to_Vision_Language_Instruction_Tuning.html#appendix",
    "title": "Enhancing Model Performance: Another Approach to Vision-Language Instruction Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17813v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17813v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3995"
  },
  {
    "objectID": "posts/Disentangling_Knowledge_based_and_Visual_Reasoning_by_Question_Decomposition_in_KB_VQA/2024-06-27-Disentangling_Knowledge_based_and_Visual_Reasoning_by_Question_Decomposition_in_KB_VQA.html#appendix",
    "href": "posts/Disentangling_Knowledge_based_and_Visual_Reasoning_by_Question_Decomposition_in_KB_VQA/2024-06-27-Disentangling_Knowledge_based_and_Visual_Reasoning_by_Question_Decomposition_in_KB_VQA.html#appendix",
    "title": "Disentangling Knowledge-based and Visual Reasoning by Question Decomposition in KB-VQA",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18839v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18839v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4974"
  },
  {
    "objectID": "posts/The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts/2024-06-20-The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts.html",
    "href": "posts/The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts/2024-06-20-The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts.html",
    "title": "The Fire Thief Is Also the Keeper: Balancing Usability and Privacy in Prompts",
    "section": "",
    "text": "Summary:\nThe paper introduces Prompt Privacy Sanitizer (ProSan), an end-to-end framework for prompt privacy protection that balances usability and privacy. ProSan generates anonymized prompts by removing contextual privacy while maintaining task usability and human readability. It can be seamlessly integrated into the online LLM service pipeline. ProSan dynamically adjusts its protection targets and strength based on the importance of words and the privacy leakage risk of prompts. It is also capable of adapting to diverse computational resource conditions, ensuring privacy protection even for mobile devices with limited computing power.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a promising approach to addressing the issue of privacy leaks in prompts. However, it does not provide a comprehensive evaluation of the framework’s performance across a wide range of tasks and datasets. Additionally, the paper does not discuss potential limitations or biases in the framework, such as the reliance on self-information for measuring privacy risk, which may not fully capture the complexity of privacy in natural language. Further research is needed to evaluate the framework’s robustness and generalizability, as well as to explore alternative methods for measuring privacy risk."
  },
  {
    "objectID": "posts/The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts/2024-06-20-The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts.html#appendix",
    "href": "posts/The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts/2024-06-20-The_Fire_Thief_Is_Also_the_Keeper_Balancing_Usability_and_Privacy_in_Prompts.html#appendix",
    "title": "The Fire Thief Is Also the Keeper: Balancing Usability and Privacy in Prompts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14318v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14318v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11663"
  },
  {
    "objectID": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#summary-1",
    "href": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#summary-1",
    "title": "Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining",
    "section": "Summary:",
    "text": "Summary:\n\nThe paper introduces a novel framework that combines context-aware retrieval-augmented generation with a prompt-based TTS system.\nThe proposed framework incorporates an innovative Context-Aware Contrastive Language-Audio Pre-training (CA-CLAP) model to extract context-aware, style-related textual features (STFs) under audio supervision.\nThe CA-CLAP model employs an audio encoder for extracting style embeddings from speech and a text encoder for deriving STFs from both the text and its context.\nThe framework also implements cross-attention mechanisms between textual and contextual features to enhance context integration.\nThe paper makes the following contributions: 1) proposing a RAG-enhanced prompt-based TTS framework to enhance audio prompt specialized selection, 2) designing a CA-CLAP model to extract textual and acoustic representations for retrieval, and 3) conducting extensive subjective and objective experiments to demonstrate the proposed methods’ superiority over baselines and the introduced CA-CLAP’s better results than text-only embedding methods."
  },
  {
    "objectID": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#major-findings",
    "href": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#major-findings",
    "title": "Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe proposed RAG-enhanced prompt-based TTS framework improves audio prompt specialized selection.\nThe CA-CLAP model effectively extracts context-aware, style-related textual features (STFs) under audio supervision.\nThe proposed methods outperform baselines, and the introduced CA-CLAP achieves better results than text-only embedding methods."
  },
  {
    "objectID": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#analysis-and-critique",
    "href": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#analysis-and-critique",
    "title": "Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper effectively addresses the challenge of selecting appropriate speech prompts by adapting the RAG concept to the speech domain.\nThe proposed framework incorporates an innovative CA-CLAP model to extract context-aware, style-related textual features (STFs) under audio supervision, which enhances the overall quality and relevance of the retrieved content.\nThe paper provides extensive subjective and objective experiments to demonstrate the proposed methods’ superiority over baselines and the introduced CA-CLAP’s better results than"
  },
  {
    "objectID": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#appendix",
    "href": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#appendix",
    "title": "Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03714v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03714v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3915"
  },
  {
    "objectID": "posts/LLMs_Understanding_of_Natural_Language_Revealed/2024-07-29-LLMs_Understanding_of_Natural_Language_Revealed.html#appendix",
    "href": "posts/LLMs_Understanding_of_Natural_Language_Revealed/2024-07-29-LLMs_Understanding_of_Natural_Language_Revealed.html#appendix",
    "title": "LLMs’ Understanding of Natural Language Revealed",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19630v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19630v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10131"
  },
  {
    "objectID": "posts/Talking_to_Machines_do_you_read_me/2024-07-02-Talking_to_Machines_do_you_read_me.html",
    "href": "posts/Talking_to_Machines_do_you_read_me/2024-07-02-Talking_to_Machines_do_you_read_me.html",
    "title": "Talking to Machines: do you read me?",
    "section": "",
    "text": "Summary:\nThis academic paper provides an overview of the research on dialogue systems, focusing on the contributions of Lina María Rojas Barahona. The author discusses her work on task-oriented dialogues and conversational question answering, as well as her role as an industrial supervisor for four PhD theses. The paper also briefly reviews the state of the art in conversational agents and highlights open research problems. The author emphasizes the progress made in dialogue systems since the introduction of Eliza, the automated psychoanalyst, in 1966. She notes that while early systems were limited by poor understanding and lack of expressivity, recent advances in deep learning and data-driven techniques have led to promising results in creating artificial agents capable of conversing with humans.\nThe paper explores various aspects of dialogue systems, including the use of Partially Observable Markov Decision Processes (POMDPs) in spoken dialogue systems, Machine Learning (ML)"
  },
  {
    "objectID": "posts/Talking_to_Machines_do_you_read_me/2024-07-02-Talking_to_Machines_do_you_read_me.html#appendix",
    "href": "posts/Talking_to_Machines_do_you_read_me/2024-07-02-Talking_to_Machines_do_you_read_me.html#appendix",
    "title": "Talking to Machines: do you read me?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02354v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02354v1\n\n\nTruncated\nTrue\n\n\nWord Count\n44116"
  },
  {
    "objectID": "posts/EAGLE_2_Faster_Inference_of_Language_Models_with_Dynamic_Draft_Trees/2024-06-24-EAGLE_2_Faster_Inference_of_Language_Models_with_Dynamic_Draft_Trees.html#appendix",
    "href": "posts/EAGLE_2_Faster_Inference_of_Language_Models_with_Dynamic_Draft_Trees/2024-06-24-EAGLE_2_Faster_Inference_of_Language_Models_with_Dynamic_Draft_Trees.html#appendix",
    "title": "EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16858v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16858v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6645"
  },
  {
    "objectID": "posts/Supporters_and_Skeptics_LLM_based_Analysis_of_Engagement_with_Mental_Health_(Mis)Information_Content_on_Video_sharing_Platforms/2024-07-02-Supporters_and_Skeptics_LLM_based_Analysis_of_Engagement_with_Mental_Health_(Mis)Information_Content_on_Video_sharing_Platforms.html#appendix",
    "href": "posts/Supporters_and_Skeptics_LLM_based_Analysis_of_Engagement_with_Mental_Health_(Mis)Information_Content_on_Video_sharing_Platforms/2024-07-02-Supporters_and_Skeptics_LLM_based_Analysis_of_Engagement_with_Mental_Health_(Mis)Information_Content_on_Video_sharing_Platforms.html#appendix",
    "title": "Supporters and Skeptics: LLM-based Analysis of Engagement with Mental Health (Mis)Information Content on Video-sharing Platforms",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02662v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02662v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12539"
  },
  {
    "objectID": "posts/Revisiting_Whos_Harry_Potter_Towards_Targeted_Unlearning_from_a_Causal_Intervention_Perspective/2024-07-24-Revisiting_Whos_Harry_Potter_Towards_Targeted_Unlearning_from_a_Causal_Intervention_Perspective.html#appendix",
    "href": "posts/Revisiting_Whos_Harry_Potter_Towards_Targeted_Unlearning_from_a_Causal_Intervention_Perspective/2024-07-24-Revisiting_Whos_Harry_Potter_Towards_Targeted_Unlearning_from_a_Causal_Intervention_Perspective.html#appendix",
    "title": "Revisiting Who’s Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16997v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16997v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11131"
  },
  {
    "objectID": "posts/ConvNLP_Image_based_AI_Text_Detection/2024-07-09-ConvNLP_Image_based_AI_Text_Detection.html#appendix",
    "href": "posts/ConvNLP_Image_based_AI_Text_Detection/2024-07-09-ConvNLP_Image_based_AI_Text_Detection.html#appendix",
    "title": "ConvNLP: Image-based AI Text Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07225v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07225v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5789"
  },
  {
    "objectID": "posts/WildTeaming_at_Scale_From_In_the_Wild_Jailbreaks_to_(Adversarially)_Safer_Language_Models/2024-06-26-WildTeaming_at_Scale_From_In_the_Wild_Jailbreaks_to_(Adversarially)_Safer_Language_Models.html#appendix",
    "href": "posts/WildTeaming_at_Scale_From_In_the_Wild_Jailbreaks_to_(Adversarially)_Safer_Language_Models/2024-06-26-WildTeaming_at_Scale_From_In_the_Wild_Jailbreaks_to_(Adversarially)_Safer_Language_Models.html#appendix",
    "title": "WildTeaming at Scale: From In-the-Wild Jailbreaks to (Adversarially) Safer Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18510v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18510v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9370"
  },
  {
    "objectID": "posts/Testing_Large_Language_Models_on_Driving_Theory_Knowledge_and_Skills_for_Connected_Autonomous_Vehicles/2024-07-24-Testing_Large_Language_Models_on_Driving_Theory_Knowledge_and_Skills_for_Connected_Autonomous_Vehicles.html#appendix",
    "href": "posts/Testing_Large_Language_Models_on_Driving_Theory_Knowledge_and_Skills_for_Connected_Autonomous_Vehicles/2024-07-24-Testing_Large_Language_Models_on_Driving_Theory_Knowledge_and_Skills_for_Connected_Autonomous_Vehicles.html#appendix",
    "title": "Testing Large Language Models on Driving Theory Knowledge and Skills for Connected Autonomous Vehicles",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17211v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17211v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5807"
  },
  {
    "objectID": "posts/PAS_Data_Efficient_Plug_and_Play_Prompt_Augmentation_System/2024-07-08-PAS_Data_Efficient_Plug_and_Play_Prompt_Augmentation_System.html#appendix",
    "href": "posts/PAS_Data_Efficient_Plug_and_Play_Prompt_Augmentation_System/2024-07-08-PAS_Data_Efficient_Plug_and_Play_Prompt_Augmentation_System.html#appendix",
    "title": "PAS: Data-Efficient Plug-and-Play Prompt Augmentation System",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06027v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06027v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8562"
  },
  {
    "objectID": "posts/Enhancing_Repository_Level_Code_Generation_with_Integrated_Contextual_Information/2024-06-05-Enhancing_Repository_Level_Code_Generation_with_Integrated_Contextual_Information.html#appendix",
    "href": "posts/Enhancing_Repository_Level_Code_Generation_with_Integrated_Contextual_Information/2024-06-05-Enhancing_Repository_Level_Code_Generation_with_Integrated_Contextual_Information.html#appendix",
    "title": "Enhancing Repository-Level Code Generation with Integrated Contextual Information",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03283v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03283v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9447"
  },
  {
    "objectID": "posts/WARP_On_the_Benefits_of_Weight_Averaged_Rewarded_Policies/2024-06-24-WARP_On_the_Benefits_of_Weight_Averaged_Rewarded_Policies.html",
    "href": "posts/WARP_On_the_Benefits_of_Weight_Averaged_Rewarded_Policies/2024-06-24-WARP_On_the_Benefits_of_Weight_Averaged_Rewarded_Policies.html",
    "title": "WARP: On the Benefits of Weight Averaged Rewarded Policies",
    "section": "",
    "text": "Summary:\nThe paper introduces a novel alignment strategy called Weight Averaged Rewarded Policies (WARP) for Reinforcement Learning from Human Feeduring (RLHF) in large language models (LLMs). WARP aims to optimize the -reward Pareto front of solutions by merging policies in the weight space at three distinct stages: using the exponential moving average (EMA) of the policy as a dynamic anchor in regularization, applying spherical interpolation to merge independently fine-tuned policies, and linearly interpolating between the merged model and the initialization. The iterative application of WARP improves the -reward Pareto front, aligning the LLMs while protecting the knowledge from pre-training. The paper compares WARP with state-of-the-art baselines and shows that it outperforms them in terms of alignment and quality.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel and promising approach to RLHF in LLMs. The use of model merging by weight averaging is a well-established technique in the literature, and the paper builds on this to propose a new alignment strategy. The experimental results show that WARP outperforms other RL alignment strategies in terms of -reward Pareto optimality. However, the paper does not discuss the computational cost of training WARP, which may be a limitation for some applications. Additionally, the paper does not provide a detailed comparison with other RLHF methods, such as Proximal Policy Optimization (PPO) or Deep Q-Networks (DQN), which could provide a more comprehensive evaluation of the proposed approach."
  },
  {
    "objectID": "posts/WARP_On_the_Benefits_of_Weight_Averaged_Rewarded_Policies/2024-06-24-WARP_On_the_Benefits_of_Weight_Averaged_Rewarded_Policies.html#appendix",
    "href": "posts/WARP_On_the_Benefits_of_Weight_Averaged_Rewarded_Policies/2024-06-24-WARP_On_the_Benefits_of_Weight_Averaged_Rewarded_Policies.html#appendix",
    "title": "WARP: On the Benefits of Weight Averaged Rewarded Policies",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16768v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16768v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11719"
  },
  {
    "objectID": "posts/FFN_a_Fine_grained_Chinese_English_Financial_Domain_Parallel_Corpus/2024-06-27-FFN_a_Fine_grained_Chinese_English_Financial_Domain_Parallel_Corpus.html#appendix",
    "href": "posts/FFN_a_Fine_grained_Chinese_English_Financial_Domain_Parallel_Corpus/2024-06-27-FFN_a_Fine_grained_Chinese_English_Financial_Domain_Parallel_Corpus.html#appendix",
    "title": "FFN: a Fine-grained Chinese-English Financial Domain Parallel Corpus",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18856v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18856v1\n\n\nTruncated\nFalse\n\n\nWord Count\n848"
  },
  {
    "objectID": "posts/A_Probabilistic_Framework_for_LLM_Hallucination_Detection_via_Belief_Tree_Propagation/2024-06-11-A_Probabilistic_Framework_for_LLM_Hallucination_Detection_via_Belief_Tree_Propagation.html#appendix",
    "href": "posts/A_Probabilistic_Framework_for_LLM_Hallucination_Detection_via_Belief_Tree_Propagation/2024-06-11-A_Probabilistic_Framework_for_LLM_Hallucination_Detection_via_Belief_Tree_Propagation.html#appendix",
    "title": "A Probabilistic Framework for LLM Hallucination Detection via Belief Tree Propagation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06950v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06950v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10310"
  },
  {
    "objectID": "posts/Synthetic_Programming_Elicitation_and_Repair_for_Text_to_Code_in_Very_Low_Resource_Programming_Languages/2024-06-05-Synthetic_Programming_Elicitation_and_Repair_for_Text_to_Code_in_Very_Low_Resource_Programming_Languages.html#appendix",
    "href": "posts/Synthetic_Programming_Elicitation_and_Repair_for_Text_to_Code_in_Very_Low_Resource_Programming_Languages/2024-06-05-Synthetic_Programming_Elicitation_and_Repair_for_Text_to_Code_in_Very_Low_Resource_Programming_Languages.html#appendix",
    "title": "Synthetic Programming Elicitation and Repair for Text-to-Code in Very Low-Resource Programming Languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03636v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03636v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9438"
  },
  {
    "objectID": "posts/Whats_Wrong_with_Your_Code_Generated_by_Large_Language_Models_An_Extensive_Study/2024-07-08-Whats_Wrong_with_Your_Code_Generated_by_Large_Language_Models_An_Extensive_Study.html#appendix",
    "href": "posts/Whats_Wrong_with_Your_Code_Generated_by_Large_Language_Models_An_Extensive_Study/2024-07-08-Whats_Wrong_with_Your_Code_Generated_by_Large_Language_Models_An_Extensive_Study.html#appendix",
    "title": "What’s Wrong with Your Code Generated by Large Language Models? An Extensive Study",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06153v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06153v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14163"
  },
  {
    "objectID": "posts/The_Good_The_Bad_and_The_Greedy_Evaluation_of_LLMs_Should_Not_Ignore_Non_Determinism/2024-07-15-The_Good_The_Bad_and_The_Greedy_Evaluation_of_LLMs_Should_Not_Ignore_Non_Determinism.html#appendix",
    "href": "posts/The_Good_The_Bad_and_The_Greedy_Evaluation_of_LLMs_Should_Not_Ignore_Non_Determinism/2024-07-15-The_Good_The_Bad_and_The_Greedy_Evaluation_of_LLMs_Should_Not_Ignore_Non_Determinism.html#appendix",
    "title": "The Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore Non-Determinism",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10457v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10457v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5472"
  },
  {
    "objectID": "posts/Turn_Level_Empathy_Prediction_Using_Psychological_Indicators/2024-07-11-Turn_Level_Empathy_Prediction_Using_Psychological_Indicators.html#appendix",
    "href": "posts/Turn_Level_Empathy_Prediction_Using_Psychological_Indicators/2024-07-11-Turn_Level_Empathy_Prediction_Using_Psychological_Indicators.html#appendix",
    "title": "Turn-Level Empathy Prediction Using Psychological Indicators",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08607v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08607v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3044"
  },
  {
    "objectID": "posts/Efficient_course_recommendations_with_T5_based_ranking_and_summarization/2024-06-27-Efficient_course_recommendations_with_T5_based_ranking_and_summarization.html#appendix",
    "href": "posts/Efficient_course_recommendations_with_T5_based_ranking_and_summarization/2024-06-27-Efficient_course_recommendations_with_T5_based_ranking_and_summarization.html#appendix",
    "title": "Efficient course recommendations with T5-based ranking and summarization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19018v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19018v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9587"
  },
  {
    "objectID": "posts/TwIPS_A_Large_Language_Model_Powered_Texting_Application_to_Simplify_Conversational_Nuances_for_Autistic_Users/2024-07-25-TwIPS_A_Large_Language_Model_Powered_Texting_Application_to_Simplify_Conversational_Nuances_for_Autistic_Users.html",
    "href": "posts/TwIPS_A_Large_Language_Model_Powered_Texting_Application_to_Simplify_Conversational_Nuances_for_Autistic_Users/2024-07-25-TwIPS_A_Large_Language_Model_Powered_Texting_Application_to_Simplify_Conversational_Nuances_for_Autistic_Users.html",
    "title": "TwIPS: A Large Language Model Powered Texting Application to Simplify Conversational Nuances for Autistic Users",
    "section": "",
    "text": "Summary:\nTwIPS is a prototype texting application powered by a large language model (LLM) designed to assist autistic users in deciphering tone and meaning, ensuring emotional tone alignment, and providing alternative phrasing for messages that could be misconstrued. The application includes three features: Interpret, Preview, and Suggest. Interpret describes the overall tone and meaning of incoming messages and identifies ambiguous language elements. Preview allows users to preview the recipient’s likely emotional reaction to their message, and Suggest complements Preview by offering a differently phrased alternative message.\nAn in-lab user study with 8 autistic participants revealed that TwIPS enabled a convenient way for participants to seek clarifications, provided a better alternative to tone indicators, and facilitated constructive reflection on writing technique and style. Participants’ feedback for improving the prototype centered around enhancing personalization and implementing measures to prevent over-relying on the application.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/TwIPS_A_Large_Language_Model_Powered_Texting_Application_to_Simplify_Conversational_Nuances_for_Autistic_Users/2024-07-25-TwIPS_A_Large_Language_Model_Powered_Texting_Application_to_Simplify_Conversational_Nuances_for_Autistic_Users.html#appendix",
    "href": "posts/TwIPS_A_Large_Language_Model_Powered_Texting_Application_to_Simplify_Conversational_Nuances_for_Autistic_Users/2024-07-25-TwIPS_A_Large_Language_Model_Powered_Texting_Application_to_Simplify_Conversational_Nuances_for_Autistic_Users.html#appendix",
    "title": "TwIPS: A Large Language Model Powered Texting Application to Simplify Conversational Nuances for Autistic Users",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17760v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17760v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17125"
  },
  {
    "objectID": "posts/Safe_Unlearning_A_Surprisingly_Effective_and_Generalizable_Solution_to_Defend_Against_Jailbreak_Attacks/2024-07-03-Safe_Unlearning_A_Surprisingly_Effective_and_Generalizable_Solution_to_Defend_Against_Jailbreak_Attacks.html",
    "href": "posts/Safe_Unlearning_A_Surprisingly_Effective_and_Generalizable_Solution_to_Defend_Against_Jailbreak_Attacks/2024-07-03-Safe_Unlearning_A_Surprisingly_Effective_and_Generalizable_Solution_to_Defend_Against_Jailbreak_Attacks.html",
    "title": "Safe Unlearning: A Surprisingly Effective and Generalizable Solution to Defend Against Jailbreak Attacks",
    "section": "",
    "text": "Summary:\nThe paper “Safe Unlearning: A Surprisingly Effective and Generalizable Solution to Defend Against Jailbreak Attacks” presents a novel approach to address the vulnerability of large language models (LLMs) to jailbreak attacks. The authors propose unlearning harmful knowledge in the LLM as a more effective way to defend against such attacks than mainstream supervised fine-tuning (SFT) approaches. The proposed method, called Safe Unlearning, involves training the LLM with a small set of raw harmful questions without incorporating any jailbreak prompts. The results show that Safe Unlearning significantly outperforms Llama2-7B-Chat, which is fine-tuned on a large number of safety alignment samples, in terms of Attack Success Rate (ASR) on out-of-distribution (OOD) harmful questions wrapped with various complex jailbreak prompts. The authors attribute the strong generalization ability of Safe Unlearning to the intrinsic relatedness among harmful responses across harmful questions.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an interesting and novel approach to addressing the vulnerability of LLMs to jailbreak attacks. The proposed method, Safe Unlearning, shows promising results in terms of reducing the ASR on OOD harmful questions wrapped with various complex jailbreak prompts. However, the paper does not provide a detailed comparison of Safe Unlearning with other unlearning-based approaches, which could have strengthened the argument for the proposed method. Additionally, the paper does not discuss the potential limitations or shortcomings of Safe Unlearning, such as the impact of unlearning on the overall performance of the LLM or the potential for overfitting to the small set of raw harmful questions used in training. Overall, the paper provides a valuable"
  },
  {
    "objectID": "posts/Safe_Unlearning_A_Surprisingly_Effective_and_Generalizable_Solution_to_Defend_Against_Jailbreak_Attacks/2024-07-03-Safe_Unlearning_A_Surprisingly_Effective_and_Generalizable_Solution_to_Defend_Against_Jailbreak_Attacks.html#appendix",
    "href": "posts/Safe_Unlearning_A_Surprisingly_Effective_and_Generalizable_Solution_to_Defend_Against_Jailbreak_Attacks/2024-07-03-Safe_Unlearning_A_Surprisingly_Effective_and_Generalizable_Solution_to_Defend_Against_Jailbreak_Attacks.html#appendix",
    "title": "Safe Unlearning: A Surprisingly Effective and Generalizable Solution to Defend Against Jailbreak Attacks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02855v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02855v1\n\n\nTruncated\nFalse\n\n\nWord Count\n16311"
  },
  {
    "objectID": "posts/OPTune_Efficient_Online_Preference_Tuning/2024-06-11-OPTune_Efficient_Online_Preference_Tuning.html#appendix",
    "href": "posts/OPTune_Efficient_Online_Preference_Tuning/2024-06-11-OPTune_Efficient_Online_Preference_Tuning.html#appendix",
    "title": "OPTune: Efficient Online Preference Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07657v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07657v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7692"
  },
  {
    "objectID": "posts/Investigating_the_Influence_of_Prompt_Specific_Shortcuts_in_AI_Generated_Text_Detection/2024-06-24-Investigating_the_Influence_of_Prompt_Specific_Shortcuts_in_AI_Generated_Text_Detection.html#appendix",
    "href": "posts/Investigating_the_Influence_of_Prompt_Specific_Shortcuts_in_AI_Generated_Text_Detection/2024-06-24-Investigating_the_Influence_of_Prompt_Specific_Shortcuts_in_AI_Generated_Text_Detection.html#appendix",
    "title": "Investigating the Influence of Prompt-Specific Shortcuts in AI Generated Text Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16275v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16275v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8427"
  },
  {
    "objectID": "posts/RoboMorph_Evolving_Robot_Morphology_using_Large_Language_Models/2024-07-11-RoboMorph_Evolving_Robot_Morphology_using_Large_Language_Models.html#appendix",
    "href": "posts/RoboMorph_Evolving_Robot_Morphology_using_Large_Language_Models/2024-07-11-RoboMorph_Evolving_Robot_Morphology_using_Large_Language_Models.html#appendix",
    "title": "RoboMorph: Evolving Robot Morphology using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08626v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08626v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6644"
  },
  {
    "objectID": "posts/APEER_Automatic_Prompt_Engineering_Enhances_Large_Language_Model_Reranking/2024-06-20-APEER_Automatic_Prompt_Engineering_Enhances_Large_Language_Model_Reranking.html#appendix",
    "href": "posts/APEER_Automatic_Prompt_Engineering_Enhances_Large_Language_Model_Reranking/2024-06-20-APEER_Automatic_Prompt_Engineering_Enhances_Large_Language_Model_Reranking.html#appendix",
    "title": "APEER: Automatic Prompt Engineering Enhances Large Language Model Reranking",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14449v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14449v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7262"
  },
  {
    "objectID": "posts/Can_Language_Models_Serve_as_Text_Based_World_Simulators/2024-06-10-Can_Language_Models_Serve_as_Text_Based_World_Simulators.html#appendix",
    "href": "posts/Can_Language_Models_Serve_as_Text_Based_World_Simulators/2024-06-10-Can_Language_Models_Serve_as_Text_Based_World_Simulators.html#appendix",
    "title": "Can Language Models Serve as Text-Based World Simulators?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06485v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06485v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6025"
  },
  {
    "objectID": "posts/CoSQA+_Enhancing_Code_Search_Dataset_with_Matching_Code/2024-06-17-CoSQA+_Enhancing_Code_Search_Dataset_with_Matching_Code.html#appendix",
    "href": "posts/CoSQA+_Enhancing_Code_Search_Dataset_with_Matching_Code/2024-06-17-CoSQA+_Enhancing_Code_Search_Dataset_with_Matching_Code.html#appendix",
    "title": "CoSQA+: Enhancing Code Search Dataset with Matching Code",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11589v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11589v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6587"
  },
  {
    "objectID": "posts/Jogging_the_Memory_of_Unlearned_Model_Through_Targeted_Relearning_Attack/2024-06-19-Jogging_the_Memory_of_Unlearned_Model_Through_Targeted_Relearning_Attack.html#appendix",
    "href": "posts/Jogging_the_Memory_of_Unlearned_Model_Through_Targeted_Relearning_Attack/2024-06-19-Jogging_the_Memory_of_Unlearned_Model_Through_Targeted_Relearning_Attack.html#appendix",
    "title": "Jogging the Memory of Unlearned Model Through Targeted Relearning Attack",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13356v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13356v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5602"
  },
  {
    "objectID": "posts/Towards_Fast_Multilingual_LLM_Inference_Speculative_Decoding_and_Specialized_Drafters/2024-06-24-Towards_Fast_Multilingual_LLM_Inference_Speculative_Decoding_and_Specialized_Drafters.html#appendix",
    "href": "posts/Towards_Fast_Multilingual_LLM_Inference_Speculative_Decoding_and_Specialized_Drafters/2024-06-24-Towards_Fast_Multilingual_LLM_Inference_Speculative_Decoding_and_Specialized_Drafters.html#appendix",
    "title": "Towards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16758v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16758v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6782"
  },
  {
    "objectID": "posts/Catching_Chameleons_Detecting_Evolving_Disinformation_Generated_using_Large_Language_Models/2024-06-26-Catching_Chameleons_Detecting_Evolving_Disinformation_Generated_using_Large_Language_Models.html#appendix",
    "href": "posts/Catching_Chameleons_Detecting_Evolving_Disinformation_Generated_using_Large_Language_Models/2024-06-26-Catching_Chameleons_Detecting_Evolving_Disinformation_Generated_using_Large_Language_Models.html#appendix",
    "title": "Catching Chameleons: Detecting Evolving Disinformation Generated using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17992v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17992v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7315"
  },
  {
    "objectID": "posts/PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models/2024-06-27-PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models.html#major-findings",
    "href": "posts/PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models/2024-06-27-PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models.html#major-findings",
    "title": "PhysioLLM: Supporting Personalized Health Insights with Wearables and Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nImproved Understanding of Health Data: PhysioLLM outperforms both the Fitbit App alone and a generic LLM chatbot in facilitating a deeper, personalized understanding of health data.\nPersonalized Insights: The system provides effective personalized insights using an LLM architecture, which improves one’s understanding of their own health.\nActionable Steps Toward Personal Health Goals: The interface is perceived as more personalized than chatting with a generic LLM-based chatbot, and it results in users having more motivation to change and their goals being found to be more actionable."
  },
  {
    "objectID": "posts/PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models/2024-06-27-PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models/2024-06-27-PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models.html#analysis-and-critique",
    "title": "PhysioLLM: Supporting Personalized Health Insights with Wearables and Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nLimited Expert Health Knowledge: The system uses an off-the-shelf, general-purpose LLM, which has limited expert health knowledge. Integrations of fine-tuned specialized LLMs with the system will further improve the quality of the insights.\nHandling Randomness and Unknowns: The system has limitations in handling the randomness and unknowns in the data and contexts. However, its adaptability ensures beneficial and personalized suggestions.\nPotential for Positive Behavior Change: Anecdotal evidence suggests that the system has the potential to nudge people towards positive behavior change, which merits further study.\nPrivacy and Ethical Considerations: The system has embedded counter-action prompts to prevent abusive uses, but further tests on the robustness of the safety prompt are needed. The system should acknowledge its limitations and ensure that no raw data is sent to the LLM, and all data and survey results are de-identified.\n**Broader User"
  },
  {
    "objectID": "posts/PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models/2024-06-27-PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models.html#appendix",
    "href": "posts/PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models/2024-06-27-PhysioLLM_Supporting_Personalized_Health_Insights_with_Wearables_and_Large_Language_Models.html#appendix",
    "title": "PhysioLLM: Supporting Personalized Health Insights with Wearables and Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19283v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19283v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7356"
  },
  {
    "objectID": "posts/COMCAT_Leveraging_Human_Judgment_to_Improve_Automatic_Documentation_and_Summarization/2024-07-18-COMCAT_Leveraging_Human_Judgment_to_Improve_Automatic_Documentation_and_Summarization.html#appendix",
    "href": "posts/COMCAT_Leveraging_Human_Judgment_to_Improve_Automatic_Documentation_and_Summarization/2024-07-18-COMCAT_Leveraging_Human_Judgment_to_Improve_Automatic_Documentation_and_Summarization.html#appendix",
    "title": "COMCAT: Leveraging Human Judgment to Improve Automatic Documentation and Summarization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.13648v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.13648v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11075"
  },
  {
    "objectID": "posts/LGR2_Language_Guided_Reward_Relabeling_for_Accelerating_Hierarchical_Reinforcement_Learning/2024-06-09-LGR2_Language_Guided_Reward_Relabeling_for_Accelerating_Hierarchical_Reinforcement_Learning.html#appendix",
    "href": "posts/LGR2_Language_Guided_Reward_Relabeling_for_Accelerating_Hierarchical_Reinforcement_Learning/2024-06-09-LGR2_Language_Guided_Reward_Relabeling_for_Accelerating_Hierarchical_Reinforcement_Learning.html#appendix",
    "title": "LGR2: Language Guided Reward Relabeling for Accelerating Hierarchical Reinforcement Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05881v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05881v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10516"
  },
  {
    "objectID": "posts/Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs/2024-06-20-Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs.html#major-findings",
    "href": "posts/Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs/2024-06-20-Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs.html#major-findings",
    "title": "Taxonomy-Guided Zero-Shot Recommendations with LLMs",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe use of a taxonomy dictionary provides a systematic framework for categorizing and organizing items, enhancing the structure and clarity of item information.\nThe TaxRec approach, which uses taxonomy to retrieve knowledge and enhance LLMs’ ability as personal recommenders, significantly improves recommendation quality compared to current zero-shot recommenders.\nThe two-step process of TaxRec, which includes one-time taxonomy categorization and LLM-based recommendation, effectively handles large item pools and makes the recommendation process more efficient, accurate, and scalable."
  },
  {
    "objectID": "posts/Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs/2024-06-20-Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs.html#analysis-and-critique",
    "href": "posts/Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs/2024-06-20-Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs.html#analysis-and-critique",
    "title": "Taxonomy-Guided Zero-Shot Recommendations with LLMs",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper does not discuss the potential limitations of the proposed method, such as the quality and completeness of the taxonomy generated by LLMs and the sufficiency of LLMs’ domain knowledge in certain areas.\nThe paper does not provide a comparison of the proposed method with other taxonomy-based recommendation approaches, which could have helped to better understand the advantages and disadvantages of the proposed method.\nThe paper does not discuss the potential impact of the proposed method on the computational resources required for generating recommendations, which is an important consideration in practical applications.\nThe paper does not provide a detailed analysis of the experimental results, such as the impact of different taxonomy categories on the recommendation quality and the performance of the method in different application domains.\nThe paper does not discuss the potential ethical implications of using LLMs for recommendation,"
  },
  {
    "objectID": "posts/Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs/2024-06-20-Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs.html#appendix",
    "href": "posts/Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs/2024-06-20-Taxonomy_Guided_Zero_Shot_Recommendations_with_LLMs.html#appendix",
    "title": "Taxonomy-Guided Zero-Shot Recommendations with LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14043v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14043v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5941"
  },
  {
    "objectID": "posts/M2CVD_Multi_Model_Collaboration_for_Code_Vulnerability_Detection/2024-06-10-M2CVD_Multi_Model_Collaboration_for_Code_Vulnerability_Detection.html#appendix",
    "href": "posts/M2CVD_Multi_Model_Collaboration_for_Code_Vulnerability_Detection/2024-06-10-M2CVD_Multi_Model_Collaboration_for_Code_Vulnerability_Detection.html#appendix",
    "title": "M2CVD: Multi-Model Collaboration for Code Vulnerability Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05940v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05940v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9185"
  },
  {
    "objectID": "posts/DOCBENCH_A_Benchmark_for_Evaluating_LLM_based_Document_Reading_Systems/2024-07-15-DOCBENCH_A_Benchmark_for_Evaluating_LLM_based_Document_Reading_Systems.html#appendix",
    "href": "posts/DOCBENCH_A_Benchmark_for_Evaluating_LLM_based_Document_Reading_Systems/2024-07-15-DOCBENCH_A_Benchmark_for_Evaluating_LLM_based_Document_Reading_Systems.html#appendix",
    "title": "DOCBENCH: A Benchmark for Evaluating LLM-based Document Reading Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10701v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10701v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5979"
  },
  {
    "objectID": "posts/SDoH_GPT_Using_Large_Language_Models_to_Extract_Social_Determinants_of_Health_(SDoH)/2024-07-24-SDoH_GPT_Using_Large_Language_Models_to_Extract_Social_Determinants_of_Health_(SDoH).html#appendix",
    "href": "posts/SDoH_GPT_Using_Large_Language_Models_to_Extract_Social_Determinants_of_Health_(SDoH)/2024-07-24-SDoH_GPT_Using_Large_Language_Models_to_Extract_Social_Determinants_of_Health_(SDoH).html#appendix",
    "title": "SDoH-GPT: Using Large Language Models to Extract Social Determinants of Health (SDoH)",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17126v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17126v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9716"
  },
  {
    "objectID": "posts/What_Did_I_Do_Wrong_Quantifying_LLMs_Sensitivity_and_Consistency_to_Prompt_Engineering/2024-06-18-What_Did_I_Do_Wrong_Quantifying_LLMs_Sensitivity_and_Consistency_to_Prompt_Engineering.html#appendix",
    "href": "posts/What_Did_I_Do_Wrong_Quantifying_LLMs_Sensitivity_and_Consistency_to_Prompt_Engineering/2024-06-18-What_Did_I_Do_Wrong_Quantifying_LLMs_Sensitivity_and_Consistency_to_Prompt_Engineering.html#appendix",
    "title": "What Did I Do Wrong? Quantifying LLMs’ Sensitivity and Consistency to Prompt Engineering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12334v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12334v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6408"
  },
  {
    "objectID": "posts/Generative_Monoculture_in_Large_Language_Models/2024-07-02-Generative_Monoculture_in_Large_Language_Models.html#appendix",
    "href": "posts/Generative_Monoculture_in_Large_Language_Models/2024-07-02-Generative_Monoculture_in_Large_Language_Models.html#appendix",
    "title": "Generative Monoculture in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02209v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02209v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13500"
  },
  {
    "objectID": "posts/CodeUpdateArena_Benchmarking_Knowledge_Editing_on_API_Updates/2024-07-08-CodeUpdateArena_Benchmarking_Knowledge_Editing_on_API_Updates.html",
    "href": "posts/CodeUpdateArena_Benchmarking_Knowledge_Editing_on_API_Updates/2024-07-08-CodeUpdateArena_Benchmarking_Knowledge_Editing_on_API_Updates.html",
    "title": "CodeUpdateArena: Benchmarking Knowledge Editing on API Updates",
    "section": "",
    "text": "Summary:\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/CodeUpdateArena_Benchmarking_Knowledge_Editing_on_API_Updates/2024-07-08-CodeUpdateArena_Benchmarking_Knowledge_Editing_on_API_Updates.html#appendix",
    "href": "posts/CodeUpdateArena_Benchmarking_Knowledge_Editing_on_API_Updates/2024-07-08-CodeUpdateArena_Benchmarking_Knowledge_Editing_on_API_Updates.html#appendix",
    "title": "CodeUpdateArena: Benchmarking Knowledge Editing on API Updates",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06249v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06249v1\n\n\nTruncated\nFalse\n\n\nWord Count\n24551"
  },
  {
    "objectID": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#summary-1",
    "href": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#summary-1",
    "title": "LangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling",
    "section": "Summary:",
    "text": "Summary:\nThe paper introduces a novel framework, LangTopo, which aligns graph structure modeling with natural language understanding at the token level. LangTopo quantifies the graph structure modeling capabilities of GNNs and LLMs by constructing a codebook for the graph modality and performs consistency maximization. This process aligns the text description of LLM with the topological modeling of GNN, allowing LLM to learn the ability of GNN to capture graph structures, enabling LLM to handle graph-structured data independently. The effectiveness of the proposed method is demonstrated on multiple datasets."
  },
  {
    "objectID": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#major-findings",
    "href": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#major-findings",
    "title": "LangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe paper proposes LangTopo, a new framework for learning graph structures using LLMs, which enables LLMs to learn GNNs’ ability to model graph structures through supervised learning.\nLangTopo achieves alignment between the natural language descriptive text in LLMs and the processing and operation of GNN models by constructing a codebook for the graph data modality.\nUnlike existing paradigms that usually introduce external modules to recognize graph structures, LangTopo endows the LLM itself with the ability to model graph structures, obviating the need for external data or model integration during inference."
  },
  {
    "objectID": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#analysis-and-critique",
    "href": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#analysis-and-critique",
    "title": "LangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper presents a promising approach to addressing the challenges of combining the structural modeling capacity of GNNs with the text processing capability of LLMs.\nThe use of an external GNN to extract spatial structure embeddings and training a projection layer or adapter to inject these embeddings into the LLM has been a common approach, but LLMs still lack the ability to handle graph data independently and continue to rely on external models during inference.\nThe paper’s focus on modeling, rather than embedding, is a significant contribution to the field, as it addresses the fundamental issue of LLMs lacking the capability to model graph structures.\nThe paper’s evaluation on multiple datasets demonstrates the effectiveness of the proposed method, but further research is needed to explore the generalizability and scalability of LangTopo.\nThe paper’s limitation is the unexplored scenario of jointly training with multiple datasets for graph modality"
  },
  {
    "objectID": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#appendix",
    "href": "posts/LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling/2024-06-19-LangTopo_Aligning_Language_Descriptions_of_Graphs_with_Tokenized_Topological_Modeling.html#appendix",
    "title": "LangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13250v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13250v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10341"
  },
  {
    "objectID": "posts/Agent_Driven_Automatic_Software_Improvement/2024-06-24-Agent_Driven_Automatic_Software_Improvement.html#appendix",
    "href": "posts/Agent_Driven_Automatic_Software_Improvement/2024-06-24-Agent_Driven_Automatic_Software_Improvement.html#appendix",
    "title": "Agent-Driven Automatic Software Improvement",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16739v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16739v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5961"
  },
  {
    "objectID": "posts/iMotion_LLM_Motion_Prediction_Instruction_Tuning/2024-06-10-iMotion_LLM_Motion_Prediction_Instruction_Tuning.html#appendix",
    "href": "posts/iMotion_LLM_Motion_Prediction_Instruction_Tuning/2024-06-10-iMotion_LLM_Motion_Prediction_Instruction_Tuning.html#appendix",
    "title": "iMotion-LLM: Motion Prediction Instruction Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06211v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06211v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5777"
  },
  {
    "objectID": "posts/CoEvol_Constructing_Better_Responses_for_Instruction_Finetuning_through_Multi_Agent_Cooperation/2024-06-11-CoEvol_Constructing_Better_Responses_for_Instruction_Finetuning_through_Multi_Agent_Cooperation.html#appendix",
    "href": "posts/CoEvol_Constructing_Better_Responses_for_Instruction_Finetuning_through_Multi_Agent_Cooperation/2024-06-11-CoEvol_Constructing_Better_Responses_for_Instruction_Finetuning_through_Multi_Agent_Cooperation.html#appendix",
    "title": "CoEvol: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07054v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07054v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6780"
  },
  {
    "objectID": "posts/Audio_Entailment_Assessing_Deductive_Reasoning_for_Audio_Understanding/2024-07-25-Audio_Entailment_Assessing_Deductive_Reasoning_for_Audio_Understanding.html#appendix",
    "href": "posts/Audio_Entailment_Assessing_Deductive_Reasoning_for_Audio_Understanding/2024-07-25-Audio_Entailment_Assessing_Deductive_Reasoning_for_Audio_Understanding.html#appendix",
    "title": "Audio Entailment: Assessing Deductive Reasoning for Audio Understanding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.18062v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.18062v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9853"
  },
  {
    "objectID": "posts/PostMark_A_Robust_Blackbox_Watermark_for_Large_Language_Models/2024-06-20-PostMark_A_Robust_Blackbox_Watermark_for_Large_Language_Models.html#appendix",
    "href": "posts/PostMark_A_Robust_Blackbox_Watermark_for_Large_Language_Models/2024-06-20-PostMark_A_Robust_Blackbox_Watermark_for_Large_Language_Models.html#appendix",
    "title": "PostMark: A Robust Blackbox Watermark for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14517v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14517v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10409"
  },
  {
    "objectID": "posts/Breaking_Bias_Building_Bridges_Evaluation_and_Mitigation_of_Social_Biases_in_LLMs_via_Contact_Hypothesis/2024-07-02-Breaking_Bias_Building_Bridges_Evaluation_and_Mitigation_of_Social_Biases_in_LLMs_via_Contact_Hypothesis.html#appendix",
    "href": "posts/Breaking_Bias_Building_Bridges_Evaluation_and_Mitigation_of_Social_Biases_in_LLMs_via_Contact_Hypothesis/2024-07-02-Breaking_Bias_Building_Bridges_Evaluation_and_Mitigation_of_Social_Biases_in_LLMs_via_Contact_Hypothesis.html#appendix",
    "title": "Breaking Bias, Building Bridges: Evaluation and Mitigation of Social Biases in LLMs via Contact Hypothesis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02030v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02030v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7434"
  },
  {
    "objectID": "posts/Knowledge_Tagging_System_on_Math_Questions_via_LLMs_with_Flexible_Demonstration_Retriever/2024-06-19-Knowledge_Tagging_System_on_Math_Questions_via_LLMs_with_Flexible_Demonstration_Retriever.html#appendix",
    "href": "posts/Knowledge_Tagging_System_on_Math_Questions_via_LLMs_with_Flexible_Demonstration_Retriever/2024-06-19-Knowledge_Tagging_System_on_Math_Questions_via_LLMs_with_Flexible_Demonstration_Retriever.html#appendix",
    "title": "Knowledge Tagging System on Math Questions via LLMs with Flexible Demonstration Retriever",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13885v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13885v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6455"
  },
  {
    "objectID": "posts/Retrieval_Augmented_Code_Generation_for_Situated_Action_Generation_A_Case_Study_on_Minecraft/2024-06-25-Retrieval_Augmented_Code_Generation_for_Situated_Action_Generation_A_Case_Study_on_Minecraft.html#appendix",
    "href": "posts/Retrieval_Augmented_Code_Generation_for_Situated_Action_Generation_A_Case_Study_on_Minecraft/2024-06-25-Retrieval_Augmented_Code_Generation_for_Situated_Action_Generation_A_Case_Study_on_Minecraft.html#appendix",
    "title": "Retrieval-Augmented Code Generation for Situated Action Generation: A Case Study on Minecraft",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17553v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17553v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4809"
  },
  {
    "objectID": "posts/PEFT_U_Parameter_Efficient_Fine_Tuning_for_User_Personalization/2024-07-25-PEFT_U_Parameter_Efficient_Fine_Tuning_for_User_Personalization.html#major-findings",
    "href": "posts/PEFT_U_Parameter_Efficient_Fine_Tuning_for_User_Personalization/2024-07-25-PEFT_U_Parameter_Efficient_Fine_Tuning_for_User_Personalization.html#major-findings",
    "title": "PEFT-U: Parameter-Efficient Fine-Tuning for User Personalization",
    "section": "Major Findings",
    "text": "Major Findings\n\nThe PEFT-U Benchmark is the first of its kind to focus on modeling user preferences in NLP with an emphasis on identical inputs that require different model outputs depending upon the user.\nThe benchmark consists of over 13+ personalized tasks and 15k+ users across domains such as Hate Speech, Sentiment/Emotion, and Humor.\nThe authors implement and empirically analyze a series of personalized prompting approaches (non-parametric) vs tuning and compartmentalizing user-level knowledge (parametric) for personalized tasks."
  },
  {
    "objectID": "posts/PEFT_U_Parameter_Efficient_Fine_Tuning_for_User_Personalization/2024-07-25-PEFT_U_Parameter_Efficient_Fine_Tuning_for_User_Personalization.html#analysis-and-critique",
    "href": "posts/PEFT_U_Parameter_Efficient_Fine_Tuning_for_User_Personalization/2024-07-25-PEFT_U_Parameter_Efficient_Fine_Tuning_for_User_Personalization.html#analysis-and-critique",
    "title": "PEFT-U: Parameter-Efficient Fine-Tuning for User Personalization",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\n\nThe paper does not provide a detailed comparison of the proposed approach with existing personalization methods in NLP.\nThe authors do not discuss the limitations of their approach, such as the potential for overfitting to specific users or the scalability of the proposed methods.\nThe paper does not provide a clear definition of what constitutes a “personalized” task, which may limit the generalizability of the proposed benchmark.\nThe authors do not discuss the potential ethical implications of personalizing LLMs, such as the risk of reinforcing existing biases or stereotypes.\nThe paper does not provide a detailed analysis of the performance of the proposed methods on each of the 13+ personalized tasks, which may limit the usefulness of the benchmark for evaluating the effectiveness of personalization methods."
  },
  {
    "objectID": "posts/PEFT_U_Parameter_Efficient_Fine_Tuning_for_User_Personalization/2024-07-25-PEFT_U_Parameter_Efficient_Fine_Tuning_for_User_Personalization.html#appendix",
    "href": "posts/PEFT_U_Parameter_Efficient_Fine_Tuning_for_User_Personalization/2024-07-25-PEFT_U_Parameter_Efficient_Fine_Tuning_for_User_Personalization.html#appendix",
    "title": "PEFT-U: Parameter-Efficient Fine-Tuning for User Personalization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.18078v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.18078v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7032"
  },
  {
    "objectID": "posts/AutoCAP_Towards_Automatic_Cross_lingual_Alignment_Planning_for_Zero_shot_Chain_of_Thought/2024-06-20-AutoCAP_Towards_Automatic_Cross_lingual_Alignment_Planning_for_Zero_shot_Chain_of_Thought.html#appendix",
    "href": "posts/AutoCAP_Towards_Automatic_Cross_lingual_Alignment_Planning_for_Zero_shot_Chain_of_Thought/2024-06-20-AutoCAP_Towards_Automatic_Cross_lingual_Alignment_Planning_for_Zero_shot_Chain_of_Thought.html#appendix",
    "title": "AutoCAP: Towards Automatic Cross-lingual Alignment Planning for Zero-shot Chain-of-Thought",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13940v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13940v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4960"
  },
  {
    "objectID": "posts/Knowledge_Graph_Tuning_Real_time_Large_Language_Model_Personalization_based_on_Human_Feedback/2024-05-30-Knowledge_Graph_Tuning_Real_time_Large_Language_Model_Personalization_based_on_Human_Feedback.html#appendix",
    "href": "posts/Knowledge_Graph_Tuning_Real_time_Large_Language_Model_Personalization_based_on_Human_Feedback/2024-05-30-Knowledge_Graph_Tuning_Real_time_Large_Language_Model_Personalization_based_on_Human_Feedback.html#appendix",
    "title": "Knowledge Graph Tuning: Real-time Large Language Model Personalization based on Human Feedback",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.19686v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.19686v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6292"
  },
  {
    "objectID": "posts/Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model/2024-07-03-Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model.html#major-findings",
    "href": "posts/Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model/2024-07-03-Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model.html#major-findings",
    "title": "Raw Text is All you Need: Knowledge-intensive Multi-turn Instruction Tuning for Large Language Model",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe proposed R2S framework allows LLMs to generate dialogues that are coherent, contextually relevant, and embed rich, domain-specific knowledge into conversations.\nThe creation of a comprehensive knowledge-intensive benchmark, k-Bench, facilitates the training and evaluation of the proposed methods, covering a diverse range of topics and serving as a vital resource for assessing the effectiveness of CoD and the overall framework.\nThe synthetic instruction dataset gInstruct retains an extensive amount of knowledge from the raw documents in a dialogue format, which is used to fine-tune an open-source LLM, referred to as gLLM. The experimental results demonstrate that this synthetic instruction approach is highly effective in enhancing the SFT model, enabling it to excel across various performance metrics."
  },
  {
    "objectID": "posts/Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model/2024-07-03-Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model.html#analysis-and-critique",
    "href": "posts/Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model/2024-07-03-Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model.html#analysis-and-critique",
    "title": "Raw Text is All you Need: Knowledge-intensive Multi-turn Instruction Tuning for Large Language Model",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper does not discuss the potential limitations of the proposed framework, such as the computational resources required for generating and fine-tuning the gLLM model.\nThe paper does not address the potential biases that may be introduced during the data collection and processing stages, which could impact the performance of the gLLM model.\nThe paper does not provide a comprehensive comparison with other existing methods for generating multi-turn dialogues for instruction tuning, which could help to better understand the advantages and disadvantages of the proposed approach.\nThe paper does not discuss the potential applications and use cases of"
  },
  {
    "objectID": "posts/Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model/2024-07-03-Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model.html#appendix",
    "href": "posts/Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model/2024-07-03-Raw_Text_is_All_you_Need_Knowledge_intensive_Multi_turn_Instruction_Tuning_for_Large_Language_Model.html#appendix",
    "title": "Raw Text is All you Need: Knowledge-intensive Multi-turn Instruction Tuning for Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03040v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03040v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5924"
  },
  {
    "objectID": "posts/AutoPureData_Automated_Filtering_of_Web_Data_for_LLM_Fine_tuning/2024-06-27-AutoPureData_Automated_Filtering_of_Web_Data_for_LLM_Fine_tuning.html#appendix",
    "href": "posts/AutoPureData_Automated_Filtering_of_Web_Data_for_LLM_Fine_tuning/2024-06-27-AutoPureData_Automated_Filtering_of_Web_Data_for_LLM_Fine_tuning.html#appendix",
    "title": "AutoPureData: Automated Filtering of Web Data for LLM Fine-tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19271v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19271v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2024"
  },
  {
    "objectID": "posts/Beyond_Demographics_Aligning_Role_playing_LLM_based_Agents_Using_Human_Belief_Networks/2024-06-25-Beyond_Demographics_Aligning_Role_playing_LLM_based_Agents_Using_Human_Belief_Networks.html#appendix",
    "href": "posts/Beyond_Demographics_Aligning_Role_playing_LLM_based_Agents_Using_Human_Belief_Networks/2024-06-25-Beyond_Demographics_Aligning_Role_playing_LLM_based_Agents_Using_Human_Belief_Networks.html#appendix",
    "title": "Beyond Demographics: Aligning Role-playing LLM-based Agents Using Human Belief Networks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17232v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17232v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7041"
  },
  {
    "objectID": "posts/Simulating_Classroom_Education_with_LLM_Empowered_Agents/2024-06-27-Simulating_Classroom_Education_with_LLM_Empowered_Agents.html#appendix",
    "href": "posts/Simulating_Classroom_Education_with_LLM_Empowered_Agents/2024-06-27-Simulating_Classroom_Education_with_LLM_Empowered_Agents.html#appendix",
    "title": "Simulating Classroom Education with LLM-Empowered Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19226v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19226v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6252"
  },
  {
    "objectID": "posts/GenderAlign_An_Alignment_Dataset_for_Mitigating_Gender_Bias_in_Large_Language_Models/2024-06-20-GenderAlign_An_Alignment_Dataset_for_Mitigating_Gender_Bias_in_Large_Language_Models.html#appendix",
    "href": "posts/GenderAlign_An_Alignment_Dataset_for_Mitigating_Gender_Bias_in_Large_Language_Models/2024-06-20-GenderAlign_An_Alignment_Dataset_for_Mitigating_Gender_Bias_in_Large_Language_Models.html#appendix",
    "title": "GenderAlign: An Alignment Dataset for Mitigating Gender Bias in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13925v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13925v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6741"
  },
  {
    "objectID": "posts/Fast_Matrix_Multiplications_for_Lookup_Table_Quantized_LLMs/2024-07-15-Fast_Matrix_Multiplications_for_Lookup_Table_Quantized_LLMs.html#appendix",
    "href": "posts/Fast_Matrix_Multiplications_for_Lookup_Table_Quantized_LLMs/2024-07-15-Fast_Matrix_Multiplications_for_Lookup_Table_Quantized_LLMs.html#appendix",
    "title": "Fast Matrix Multiplications for Lookup Table-Quantized LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10960v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10960v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7852"
  },
  {
    "objectID": "posts/Evaluating_Large_Language_Models_with_Grid_Based_Game_Competitions_An_Extensible_LLM_Benchmark_and_Leaderboard/2024-07-11-Evaluating_Large_Language_Models_with_Grid_Based_Game_Competitions_An_Extensible_LLM_Benchmark_and_Leaderboard.html#major-findings",
    "href": "posts/Evaluating_Large_Language_Models_with_Grid_Based_Game_Competitions_An_Extensible_LLM_Benchmark_and_Leaderboard/2024-07-11-Evaluating_Large_Language_Models_with_Grid_Based_Game_Competitions_An_Extensible_LLM_Benchmark_and_Leaderboard.html#major-findings",
    "title": "Evaluating Large Language Models with Grid-Based Game Competitions: An Extensible LLM Benchmark and Leaderboard",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nLLMs perform relatively well in simpler formats, such as list prompts for Tic-Tac-Toe and Connect Four, but their performance declines with more complex prompts, especially those involving illustrations and images.\nLLMs show a tendency to make invalid moves when faced with more complex prompts, underscoring the need for improved strategic decision-making processes.\nThe study reveals both the strengths and limitations of LLMs, pointing to the need for ongoing research to enhance their ability to process complex and visual data, improve decision-making processes, and develop more sophisticated benchmarking tools."
  },
  {
    "objectID": "posts/Evaluating_Large_Language_Models_with_Grid_Based_Game_Competitions_An_Extensible_LLM_Benchmark_and_Leaderboard/2024-07-11-Evaluating_Large_Language_Models_with_Grid_Based_Game_Competitions_An_Extensible_LLM_Benchmark_and_Leaderboard.html#analysis-and-critique",
    "href": "posts/Evaluating_Large_Language_Models_with_Grid_Based_Game_Competitions_An_Extensible_LLM_Benchmark_and_Leaderboard/2024-07-11-Evaluating_Large_Language_Models_with_Grid_Based_Game_Competitions_An_Extensible_LLM_Benchmark_and_Leaderboard.html#analysis-and-critique",
    "title": "Evaluating Large Language Models with Grid-Based Game Competitions: An Extensible LLM Benchmark and Leaderboard",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThis study provides a valuable contribution to the field by introducing a novel and extensible benchmark for LLMs using grid-based games. The use of open-source game simulation code and the generation of detailed data files in various formats facilitate further analysis and comparison of LLM performance. However, the study has some limitations. The focus on a select group of LLMs might not capture the full diversity of strategic approaches across available models. Additionally, the simplicity of the games used in this benchmark may not challenge LLMs’ strategic capabilities as much as more complex games like chess or Go might.\nFuture work could explore several promising directions to extend research and deepen our understanding"
  },
  {
    "objectID": "posts/Evaluating_Large_Language_Models_with_Grid_Based_Game_Competitions_An_Extensible_LLM_Benchmark_and_Leaderboard/2024-07-11-Evaluating_Large_Language_Models_with_Grid_Based_Game_Competitions_An_Extensible_LLM_Benchmark_and_Leaderboard.html#appendix",
    "href": "posts/Evaluating_Large_Language_Models_with_Grid_Based_Game_Competitions_An_Extensible_LLM_Benchmark_and_Leaderboard/2024-07-11-Evaluating_Large_Language_Models_with_Grid_Based_Game_Competitions_An_Extensible_LLM_Benchmark_and_Leaderboard.html#appendix",
    "title": "Evaluating Large Language Models with Grid-Based Game Competitions: An Extensible LLM Benchmark and Leaderboard",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07796v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07796v2\n\n\nTruncated\nFalse\n\n\nWord Count\n13403"
  },
  {
    "objectID": "posts/Machine_Translation_Hallucination_Detection_for_Low_and_High_Resource_Languages_using_Large_Language_Models/2024-07-23-Machine_Translation_Hallucination_Detection_for_Low_and_High_Resource_Languages_using_Large_Language_Models.html#appendix",
    "href": "posts/Machine_Translation_Hallucination_Detection_for_Low_and_High_Resource_Languages_using_Large_Language_Models/2024-07-23-Machine_Translation_Hallucination_Detection_for_Low_and_High_Resource_Languages_using_Large_Language_Models.html#appendix",
    "title": "Machine Translation Hallucination Detection for Low and High Resource Languages using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16470v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16470v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6122"
  },
  {
    "objectID": "posts/SLIP_Securing_LLMs_IP_Using_Weights_Decomposition/2024-07-15-SLIP_Securing_LLMs_IP_Using_Weights_Decomposition.html#appendix",
    "href": "posts/SLIP_Securing_LLMs_IP_Using_Weights_Decomposition/2024-07-15-SLIP_Securing_LLMs_IP_Using_Weights_Decomposition.html#appendix",
    "title": "SLIP: Securing LLMs IP Using Weights Decomposition",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10886v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10886v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8145"
  },
  {
    "objectID": "posts/FaceGPT_Self_supervised_Learning_to_Chat_about_3D_Human_Faces/2024-06-11-FaceGPT_Self_supervised_Learning_to_Chat_about_3D_Human_Faces.html#appendix",
    "href": "posts/FaceGPT_Self_supervised_Learning_to_Chat_about_3D_Human_Faces/2024-06-11-FaceGPT_Self_supervised_Learning_to_Chat_about_3D_Human_Faces.html#appendix",
    "title": "FaceGPT: Self-supervised Learning to Chat about 3D Human Faces",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07163v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07163v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6381"
  },
  {
    "objectID": "posts/Causal_Inference_with_Latent_Variables_Recent_Advances_and_Future_Prospectives/2024-06-20-Causal_Inference_with_Latent_Variables_Recent_Advances_and_Future_Prospectives.html#appendix",
    "href": "posts/Causal_Inference_with_Latent_Variables_Recent_Advances_and_Future_Prospectives/2024-06-20-Causal_Inference_with_Latent_Variables_Recent_Advances_and_Future_Prospectives.html#appendix",
    "title": "Causal Inference with Latent Variables: Recent Advances and Future Prospectives",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13966v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13966v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11886"
  },
  {
    "objectID": "posts/ConvoCache_Smart_Re_Use_of_Chatbot_Responses/2024-06-26-ConvoCache_Smart_Re_Use_of_Chatbot_Responses.html#appendix",
    "href": "posts/ConvoCache_Smart_Re_Use_of_Chatbot_Responses/2024-06-26-ConvoCache_Smart_Re_Use_of_Chatbot_Responses.html#appendix",
    "title": "ConvoCache: Smart Re-Use of Chatbot Responses",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18133v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18133v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4233"
  },
  {
    "objectID": "posts/Enhancing_Agent_Learning_through_World_Dynamics_Modeling/2024-07-25-Enhancing_Agent_Learning_through_World_Dynamics_Modeling.html#appendix",
    "href": "posts/Enhancing_Agent_Learning_through_World_Dynamics_Modeling/2024-07-25-Enhancing_Agent_Learning_through_World_Dynamics_Modeling.html#appendix",
    "title": "Enhancing Agent Learning through World Dynamics Modeling",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17695v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17695v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6832"
  },
  {
    "objectID": "posts/How_Good_(Or_Bad)_Are_LLMs_at_Detecting_Misleading_Visualizations/2024-07-24-How_Good_(Or_Bad)_Are_LLMs_at_Detecting_Misleading_Visualizations.html#appendix",
    "href": "posts/How_Good_(Or_Bad)_Are_LLMs_at_Detecting_Misleading_Visualizations/2024-07-24-How_Good_(Or_Bad)_Are_LLMs_at_Detecting_Misleading_Visualizations.html#appendix",
    "title": "How Good (Or Bad) Are LLMs at Detecting Misleading Visualizations?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17291v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17291v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10270"
  },
  {
    "objectID": "posts/Model_Merging_and_Safety_Alignment_One_Bad_Model_Spoils_the_Bunch/2024-06-20-Model_Merging_and_Safety_Alignment_One_Bad_Model_Spoils_the_Bunch.html#appendix",
    "href": "posts/Model_Merging_and_Safety_Alignment_One_Bad_Model_Spoils_the_Bunch/2024-06-20-Model_Merging_and_Safety_Alignment_One_Bad_Model_Spoils_the_Bunch.html#appendix",
    "title": "Model Merging and Safety Alignment: One Bad Model Spoils the Bunch",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14563v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14563v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8326"
  },
  {
    "objectID": "posts/61A_Bot_AI_homework_assistance_in_CS1_is_fast_and_cheap____but_is_it_helpful/2024-06-09-61A_Bot_AI_homework_assistance_in_CS1_is_fast_and_cheap____but_is_it_helpful.html#appendix",
    "href": "posts/61A_Bot_AI_homework_assistance_in_CS1_is_fast_and_cheap____but_is_it_helpful/2024-06-09-61A_Bot_AI_homework_assistance_in_CS1_is_fast_and_cheap____but_is_it_helpful.html#appendix",
    "title": "61A-Bot: AI homework assistance in CS1 is fast and cheap – but is it helpful?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05600v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05600v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7095"
  },
  {
    "objectID": "posts/Tactics_Techniques_and_Procedures_(TTPs)_in_Interpreted_Malware_A_Zero_Shot_Generation_with_Large_Language_Models/2024-07-11-Tactics_Techniques_and_Procedures_(TTPs)_in_Interpreted_Malware_A_Zero_Shot_Generation_with_Large_Language_Models.html#appendix",
    "href": "posts/Tactics_Techniques_and_Procedures_(TTPs)_in_Interpreted_Malware_A_Zero_Shot_Generation_with_Large_Language_Models/2024-07-11-Tactics_Techniques_and_Procedures_(TTPs)_in_Interpreted_Malware_A_Zero_Shot_Generation_with_Large_Language_Models.html#appendix",
    "title": "Tactics, Techniques, and Procedures (TTPs) in Interpreted Malware: A Zero-Shot Generation with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08532v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08532v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14754"
  },
  {
    "objectID": "posts/Decision_Making_Behavior_Evaluation_Framework_for_LLMs_under_Uncertain_Context/2024-06-10-Decision_Making_Behavior_Evaluation_Framework_for_LLMs_under_Uncertain_Context.html#appendix",
    "href": "posts/Decision_Making_Behavior_Evaluation_Framework_for_LLMs_under_Uncertain_Context/2024-06-10-Decision_Making_Behavior_Evaluation_Framework_for_LLMs_under_Uncertain_Context.html#appendix",
    "title": "Decision-Making Behavior Evaluation Framework for LLMs under Uncertain Context",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05972v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05972v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6256"
  },
  {
    "objectID": "posts/Detecting_and_Understanding_Vulnerabilities_in_Language_Models_via_Mechanistic_Interpretability/2024-07-29-Detecting_and_Understanding_Vulnerabilities_in_Language_Models_via_Mechanistic_Interpretability.html#appendix",
    "href": "posts/Detecting_and_Understanding_Vulnerabilities_in_Language_Models_via_Mechanistic_Interpretability/2024-07-29-Detecting_and_Understanding_Vulnerabilities_in_Language_Models_via_Mechanistic_Interpretability.html#appendix",
    "title": "Detecting and Understanding Vulnerabilities in Language Models via Mechanistic Interpretability",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19842v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19842v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6824"
  },
  {
    "objectID": "posts/Large_Language_Models_as_Recommender_Systems_A_Study_of_Popularity_Bias/2024-06-03-Large_Language_Models_as_Recommender_Systems_A_Study_of_Popularity_Bias.html#appendix",
    "href": "posts/Large_Language_Models_as_Recommender_Systems_A_Study_of_Popularity_Bias/2024-06-03-Large_Language_Models_as_Recommender_Systems_A_Study_of_Popularity_Bias.html#appendix",
    "title": "Large Language Models as Recommender Systems: A Study of Popularity Bias",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01285v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01285v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9391"
  },
  {
    "objectID": "posts/IDEAL_Leveraging_Infinite_and_Dynamic_Characterizations_of_Large_Language_Models_for_Query_focused_Summarization/2024-07-15-IDEAL_Leveraging_Infinite_and_Dynamic_Characterizations_of_Large_Language_Models_for_Query_focused_Summarization.html#appendix",
    "href": "posts/IDEAL_Leveraging_Infinite_and_Dynamic_Characterizations_of_Large_Language_Models_for_Query_focused_Summarization/2024-07-15-IDEAL_Leveraging_Infinite_and_Dynamic_Characterizations_of_Large_Language_Models_for_Query_focused_Summarization.html#appendix",
    "title": "IDEAL: Leveraging Infinite and Dynamic Characterizations of Large Language Models for Query-focused Summarization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10486v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10486v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6156"
  },
  {
    "objectID": "posts/Stronger_Faster_and_Cheaper_Log_Parsing_with_LLMs/2024-06-10-Stronger_Faster_and_Cheaper_Log_Parsing_with_LLMs.html#appendix",
    "href": "posts/Stronger_Faster_and_Cheaper_Log_Parsing_with_LLMs/2024-06-10-Stronger_Faster_and_Cheaper_Log_Parsing_with_LLMs.html#appendix",
    "title": "Stronger, Faster, and Cheaper Log Parsing with LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06156v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06156v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11355"
  },
  {
    "objectID": "posts/PORT_Preference_Optimization_on_Reasoning_Traces/2024-06-23-PORT_Preference_Optimization_on_Reasoning_Traces.html#appendix",
    "href": "posts/PORT_Preference_Optimization_on_Reasoning_Traces/2024-06-23-PORT_Preference_Optimization_on_Reasoning_Traces.html#appendix",
    "title": "PORT: Preference Optimization on Reasoning Traces",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16061v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16061v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8636"
  },
  {
    "objectID": "posts/Large_Language_Models_for_Automatic_Milestone_Detection_in_Group_Discussions/2024-06-16-Large_Language_Models_for_Automatic_Milestone_Detection_in_Group_Discussions.html#appendix",
    "href": "posts/Large_Language_Models_for_Automatic_Milestone_Detection_in_Group_Discussions/2024-06-16-Large_Language_Models_for_Automatic_Milestone_Detection_in_Group_Discussions.html#appendix",
    "title": "Large Language Models for Automatic Milestone Detection in Group Discussions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.10842v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.10842v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4838"
  },
  {
    "objectID": "posts/The_Power_of_Combining_Data_and_Knowledge_GPT_4o_is_an_Effective_Interpreter_of_Machine_Learning_Models_in_Predicting_Lymph_Node_Metastasis_of_Lung_Cancer/2024-07-25-The_Power_of_Combining_Data_and_Knowledge_GPT_4o_is_an_Effective_Interpreter_of_Machine_Learning_Models_in_Predicting_Lymph_Node_Metastasis_of_Lung_Cancer.html#appendix",
    "href": "posts/The_Power_of_Combining_Data_and_Knowledge_GPT_4o_is_an_Effective_Interpreter_of_Machine_Learning_Models_in_Predicting_Lymph_Node_Metastasis_of_Lung_Cancer/2024-07-25-The_Power_of_Combining_Data_and_Knowledge_GPT_4o_is_an_Effective_Interpreter_of_Machine_Learning_Models_in_Predicting_Lymph_Node_Metastasis_of_Lung_Cancer.html#appendix",
    "title": "The Power of Combining Data and Knowledge: GPT-4o is an Effective Interpreter of Machine Learning Models in Predicting Lymph Node Metastasis of Lung Cancer",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17900v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17900v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4823"
  },
  {
    "objectID": "posts/Raccoon_Prompt_Extraction_Benchmark_of_LLM_Integrated_Applications/2024-06-10-Raccoon_Prompt_Extraction_Benchmark_of_LLM_Integrated_Applications.html#appendix",
    "href": "posts/Raccoon_Prompt_Extraction_Benchmark_of_LLM_Integrated_Applications/2024-06-10-Raccoon_Prompt_Extraction_Benchmark_of_LLM_Integrated_Applications.html#appendix",
    "title": "Raccoon: Prompt Extraction Benchmark of LLM-Integrated Applications",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06737v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06737v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6069"
  },
  {
    "objectID": "posts/CovScore_Evaluation_of_Multi_Document_Abstractive_Title_Set_Generation/2024-07-24-CovScore_Evaluation_of_Multi_Document_Abstractive_Title_Set_Generation.html#major-findings",
    "href": "posts/CovScore_Evaluation_of_Multi_Document_Abstractive_Title_Set_Generation/2024-07-24-CovScore_Evaluation_of_Multi_Document_Abstractive_Title_Set_Generation.html#major-findings",
    "title": "CovScore: Evaluation of Multi-Document Abstractive Title Set Generation",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nCovScore Methodology: The authors present a novel methodology for reference-less evaluation of title sets, which can be deployed manually or automatically. The methodology reports separate scores for each aspect, alongside an aggregate score, addressing the drawbacks of using aggregate metrics.\nCase Study on Holocaust Survivor Testimonies: The authors conduct a case study on a dataset of Holocaust survivor testimonies, demonstrating the importance of studying these testimonies for Holocaust research and the unique test case they provide due to the recounted common yet unique experiences.\nEffectiveness of the Methodology: The authors demonstrate the effectiveness of their methodology by experimenting with both naturalistic and synthetic title set generation systems and comparing their performance by studying the intricate trade-offs existing between the different sets."
  },
  {
    "objectID": "posts/CovScore_Evaluation_of_Multi_Document_Abstractive_Title_Set_Generation/2024-07-24-CovScore_Evaluation_of_Multi_Document_Abstractive_Title_Set_Generation.html#analysis-and-critique",
    "href": "posts/CovScore_Evaluation_of_Multi_Document_Abstractive_Title_Set_Generation/2024-07-24-CovScore_Evaluation_of_Multi_Document_Abstractive_Title_Set_Generation.html#analysis-and-critique",
    "title": "CovScore: Evaluation of Multi-Document Abstractive Title Set Generation",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nLimited Dataset: The methodology is tested on a single type of dataset (Holocaust survivor testimonies), which may limit its generalizability to other types of datasets.\nSample Size: The annotation process is based on a small sample (10 documents) from each domain, which may not sufficiently cover the entirety of the domain and could bias the annotation process.\nSegmentation of Testimonies: The prior ontology labeling of the segments was done on segments of constant 1-minute length, which could cause unrelated information to be included in the segment and misplace small but crucial segments.\nUse of LLMs: The use of LLMs as judge models for measurement annotation may be limited by their black-box nature, high cost, and lack of replicability.\nEthical Considerations: The use of Holocaust testimonies"
  },
  {
    "objectID": "posts/CovScore_Evaluation_of_Multi_Document_Abstractive_Title_Set_Generation/2024-07-24-CovScore_Evaluation_of_Multi_Document_Abstractive_Title_Set_Generation.html#appendix",
    "href": "posts/CovScore_Evaluation_of_Multi_Document_Abstractive_Title_Set_Generation/2024-07-24-CovScore_Evaluation_of_Multi_Document_Abstractive_Title_Set_Generation.html#appendix",
    "title": "CovScore: Evaluation of Multi-Document Abstractive Title Set Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17390v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17390v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9655"
  },
  {
    "objectID": "posts/LLMs_assist_NLP_Researchers_Critique_Paper_(Meta_)Reviewing/2024-06-24-LLMs_assist_NLP_Researchers_Critique_Paper_(Meta_)Reviewing.html#appendix",
    "href": "posts/LLMs_assist_NLP_Researchers_Critique_Paper_(Meta_)Reviewing/2024-06-24-LLMs_assist_NLP_Researchers_Critique_Paper_(Meta_)Reviewing.html#appendix",
    "title": "LLMs assist NLP Researchers: Critique Paper (Meta-)Reviewing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16253v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16253v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7952"
  },
  {
    "objectID": "posts/ChatGPT_Doesnt_Trust_Chargers_Fans_Guardrail_Sensitivity_in_Context/2024-07-09-ChatGPT_Doesnt_Trust_Chargers_Fans_Guardrail_Sensitivity_in_Context.html#appendix",
    "href": "posts/ChatGPT_Doesnt_Trust_Chargers_Fans_Guardrail_Sensitivity_in_Context/2024-07-09-ChatGPT_Doesnt_Trust_Chargers_Fans_Guardrail_Sensitivity_in_Context.html#appendix",
    "title": "ChatGPT Doesn’t Trust Chargers Fans: Guardrail Sensitivity in Context",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06866v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06866v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9182"
  },
  {
    "objectID": "posts/EERPD_Leveraging_Emotion_and_Emotion_Regulation_for_Improving_Personality_Detection/2024-06-23-EERPD_Leveraging_Emotion_and_Emotion_Regulation_for_Improving_Personality_Detection.html#appendix",
    "href": "posts/EERPD_Leveraging_Emotion_and_Emotion_Regulation_for_Improving_Personality_Detection/2024-06-23-EERPD_Leveraging_Emotion_and_Emotion_Regulation_for_Improving_Personality_Detection.html#appendix",
    "title": "EERPD: Leveraging Emotion and Emotion Regulation for Improving Personality Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16079v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16079v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5645"
  },
  {
    "objectID": "posts/Instruct_Not_Assist_LLM_based_Multi_Turn_Planning_and_Hierarchical_Questioning_for_Socratic_Code_Debugging/2024-06-17-Instruct_Not_Assist_LLM_based_Multi_Turn_Planning_and_Hierarchical_Questioning_for_Socratic_Code_Debugging.html#appendix",
    "href": "posts/Instruct_Not_Assist_LLM_based_Multi_Turn_Planning_and_Hierarchical_Questioning_for_Socratic_Code_Debugging/2024-06-17-Instruct_Not_Assist_LLM_based_Multi_Turn_Planning_and_Hierarchical_Questioning_for_Socratic_Code_Debugging.html#appendix",
    "title": "Instruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11709v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11709v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9274"
  },
  {
    "objectID": "posts/LLaSA_Large_Multimodal_Agent_for_Human_Activity_Analysis_Through_Wearable_Sensors/2024-06-20-LLaSA_Large_Multimodal_Agent_for_Human_Activity_Analysis_Through_Wearable_Sensors.html#appendix",
    "href": "posts/LLaSA_Large_Multimodal_Agent_for_Human_Activity_Analysis_Through_Wearable_Sensors/2024-06-20-LLaSA_Large_Multimodal_Agent_for_Human_Activity_Analysis_Through_Wearable_Sensors.html#appendix",
    "title": "LLaSA: Large Multimodal Agent for Human Activity Analysis Through Wearable Sensors",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14498v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14498v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3974"
  },
  {
    "objectID": "posts/NeBuLa_A_discourse_aware_Minecraft_Builder/2024-06-26-NeBuLa_A_discourse_aware_Minecraft_Builder.html#appendix",
    "href": "posts/NeBuLa_A_discourse_aware_Minecraft_Builder/2024-06-26-NeBuLa_A_discourse_aware_Minecraft_Builder.html#appendix",
    "title": "NeBuLa: A discourse aware Minecraft Builder",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18164v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18164v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6185"
  },
  {
    "objectID": "posts/Exploring_Large_Language_Models_for_Relevance_Judgments_in_Tetun/2024-06-11-Exploring_Large_Language_Models_for_Relevance_Judgments_in_Tetun.html#appendix",
    "href": "posts/Exploring_Large_Language_Models_for_Relevance_Judgments_in_Tetun/2024-06-11-Exploring_Large_Language_Models_for_Relevance_Judgments_in_Tetun.html#appendix",
    "title": "Exploring Large Language Models for Relevance Judgments in Tetun",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07299v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07299v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3697"
  },
  {
    "objectID": "posts/GraphEval_A_Knowledge_Graph_Based_LLM_Hallucination_Evaluation_Framework/2024-07-15-GraphEval_A_Knowledge_Graph_Based_LLM_Hallucination_Evaluation_Framework.html#appendix",
    "href": "posts/GraphEval_A_Knowledge_Graph_Based_LLM_Hallucination_Evaluation_Framework/2024-07-15-GraphEval_A_Knowledge_Graph_Based_LLM_Hallucination_Evaluation_Framework.html#appendix",
    "title": "GraphEval: A Knowledge-Graph Based LLM Hallucination Evaluation Framework",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10793v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10793v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5868"
  },
  {
    "objectID": "posts/Prism_A_Framework_for_Decoupling_and_Assessing_the_Capabilities_of_VLMs/2024-06-20-Prism_A_Framework_for_Decoupling_and_Assessing_the_Capabilities_of_VLMs.html#appendix",
    "href": "posts/Prism_A_Framework_for_Decoupling_and_Assessing_the_Capabilities_of_VLMs/2024-06-20-Prism_A_Framework_for_Decoupling_and_Assessing_the_Capabilities_of_VLMs.html#appendix",
    "title": "Prism: A Framework for Decoupling and Assessing the Capabilities of VLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14544v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14544v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8916"
  },
  {
    "objectID": "posts/Hypothetical_Minds_Scaffolding_Theory_of_Mind_for_Multi_Agent_Tasks_with_Large_Language_Models/2024-07-09-Hypothetical_Minds_Scaffolding_Theory_of_Mind_for_Multi_Agent_Tasks_with_Large_Language_Models.html",
    "href": "posts/Hypothetical_Minds_Scaffolding_Theory_of_Mind_for_Multi_Agent_Tasks_with_Large_Language_Models/2024-07-09-Hypothetical_Minds_Scaffolding_Theory_of_Mind_for_Multi_Agent_Tasks_with_Large_Language_Models.html",
    "title": "Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models",
    "section": "",
    "text": "Summary:\nThe paper introduces Hypothetical Minds, an autonomous agent that leverages large language models (LLMs) to handle the challenges of multi-agent reinforcement learning (MARL). The agent features a cognitively-inspired architecture with modular components for perception, memory, and hierarchical planning over two levels of abstraction. The Theory of Mind module is a key component that scaffolds the high-level planning process by generating hypotheses about other agents’ strategies in natural language, evaluating, and iteratively refining these hypotheses based on their predictive accuracy. The paper demonstrates that Hypothetical Minds significantly improves performance over previous LLM-agent and RL baselines on a range of competitive, mixed motive, and collaborative domains in the Melting Pot benchmark.\nMajor Findings:"
  },
  {
    "objectID": "posts/Hypothetical_Minds_Scaffolding_Theory_of_Mind_for_Multi_Agent_Tasks_with_Large_Language_Models/2024-07-09-Hypothetical_Minds_Scaffolding_Theory_of_Mind_for_Multi_Agent_Tasks_with_Large_Language_Models.html#appendix",
    "href": "posts/Hypothetical_Minds_Scaffolding_Theory_of_Mind_for_Multi_Agent_Tasks_with_Large_Language_Models/2024-07-09-Hypothetical_Minds_Scaffolding_Theory_of_Mind_for_Multi_Agent_Tasks_with_Large_Language_Models.html#appendix",
    "title": "Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07086v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07086v1\n\n\nTruncated\nTrue\n\n\nWord Count\n27806"
  },
  {
    "objectID": "posts/Improving_Expert_Radiology_Report_Summarization_by_Prompting_Large_Language_Models_with_a_Layperson_Summary/2024-06-20-Improving_Expert_Radiology_Report_Summarization_by_Prompting_Large_Language_Models_with_a_Layperson_Summary.html#appendix",
    "href": "posts/Improving_Expert_Radiology_Report_Summarization_by_Prompting_Large_Language_Models_with_a_Layperson_Summary/2024-06-20-Improving_Expert_Radiology_Report_Summarization_by_Prompting_Large_Language_Models_with_a_Layperson_Summary.html#appendix",
    "title": "Improving Expert Radiology Report Summarization by Prompting Large Language Models with a Layperson Summary",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14500v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14500v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8909"
  },
  {
    "objectID": "posts/Artificial_Intuition_Efficient_Classification_of_Scientific_Abstracts/2024-07-08-Artificial_Intuition_Efficient_Classification_of_Scientific_Abstracts.html#appendix",
    "href": "posts/Artificial_Intuition_Efficient_Classification_of_Scientific_Abstracts/2024-07-08-Artificial_Intuition_Efficient_Classification_of_Scientific_Abstracts.html#appendix",
    "title": "Artificial Intuition: Efficient Classification of Scientific Abstracts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06093v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06093v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5527"
  },
  {
    "objectID": "posts/VidyaRANG_Conversational_Learning_Based_Platform_powered_by_Large_Language_Model/2024-07-23-VidyaRANG_Conversational_Learning_Based_Platform_powered_by_Large_Language_Model.html#appendix",
    "href": "posts/VidyaRANG_Conversational_Learning_Based_Platform_powered_by_Large_Language_Model/2024-07-23-VidyaRANG_Conversational_Learning_Based_Platform_powered_by_Large_Language_Model.html#appendix",
    "title": "VidyaRANG: Conversational Learning Based Platform powered by Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16209v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16209v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3698"
  },
  {
    "objectID": "posts/GraCoRe_Benchmarking_Graph_Comprehension_and_Complex_Reasoning_in_Large_Language_Models/2024-07-03-GraCoRe_Benchmarking_Graph_Comprehension_and_Complex_Reasoning_in_Large_Language_Models.html#appendix",
    "href": "posts/GraCoRe_Benchmarking_Graph_Comprehension_and_Complex_Reasoning_in_Large_Language_Models/2024-07-03-GraCoRe_Benchmarking_Graph_Comprehension_and_Complex_Reasoning_in_Large_Language_Models.html#appendix",
    "title": "GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02936v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02936v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5687"
  },
  {
    "objectID": "posts/An_Investigation_of_Prompt_Variations_for_Zero_shot_LLM_based_Rankers/2024-06-20-An_Investigation_of_Prompt_Variations_for_Zero_shot_LLM_based_Rankers.html#appendix",
    "href": "posts/An_Investigation_of_Prompt_Variations_for_Zero_shot_LLM_based_Rankers/2024-06-20-An_Investigation_of_Prompt_Variations_for_Zero_shot_LLM_based_Rankers.html#appendix",
    "title": "An Investigation of Prompt Variations for Zero-shot LLM-based Rankers",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14117v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14117v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7110"
  },
  {
    "objectID": "posts/NormTab_Improving_Symbolic_Reasoning_in_LLMs_Through_Tabular_Data_Normalization/2024-06-25-NormTab_Improving_Symbolic_Reasoning_in_LLMs_Through_Tabular_Data_Normalization.html#appendix",
    "href": "posts/NormTab_Improving_Symbolic_Reasoning_in_LLMs_Through_Tabular_Data_Normalization/2024-06-25-NormTab_Improving_Symbolic_Reasoning_in_LLMs_Through_Tabular_Data_Normalization.html#appendix",
    "title": "NormTab: Improving Symbolic Reasoning in LLMs Through Tabular Data Normalization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17961v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17961v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6898"
  },
  {
    "objectID": "posts/LLMEmbed_Rethinking_Lightweight_LLMs_Genuine_Function_in_Text_Classification/2024-06-06-LLMEmbed_Rethinking_Lightweight_LLMs_Genuine_Function_in_Text_Classification.html#appendix",
    "href": "posts/LLMEmbed_Rethinking_Lightweight_LLMs_Genuine_Function_in_Text_Classification/2024-06-06-LLMEmbed_Rethinking_Lightweight_LLMs_Genuine_Function_in_Text_Classification.html#appendix",
    "title": "LLMEmbed: Rethinking Lightweight LLM’s Genuine Function in Text Classification",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03725v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03725v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5774"
  },
  {
    "objectID": "posts/Teaching_LLMs_at_Charles_University_Assignments_and_Activities/2024-07-29-Teaching_LLMs_at_Charles_University_Assignments_and_Activities.html#appendix",
    "href": "posts/Teaching_LLMs_at_Charles_University_Assignments_and_Activities/2024-07-29-Teaching_LLMs_at_Charles_University_Assignments_and_Activities.html#appendix",
    "title": "Teaching LLMs at Charles University: Assignments and Activities",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19798v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19798v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2201"
  },
  {
    "objectID": "posts/LANE_Logic_Alignment_of_Non_tuning_Large_Language_Models_and_Online_Recommendation_Systems_for_Explainable_Reason_Generation/2024-07-03-LANE_Logic_Alignment_of_Non_tuning_Large_Language_Models_and_Online_Recommendation_Systems_for_Explainable_Reason_Generation.html#appendix",
    "href": "posts/LANE_Logic_Alignment_of_Non_tuning_Large_Language_Models_and_Online_Recommendation_Systems_for_Explainable_Reason_Generation/2024-07-03-LANE_Logic_Alignment_of_Non_tuning_Large_Language_Models_and_Online_Recommendation_Systems_for_Explainable_Reason_Generation.html#appendix",
    "title": "LANE: Logic Alignment of Non-tuning Large Language Models and Online Recommendation Systems for Explainable Reason Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02833v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02833v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9264"
  },
  {
    "objectID": "posts/Does_Object_Grounding_Really_Reduce_Hallucination_of_Large_Vision_Language_Models/2024-06-20-Does_Object_Grounding_Really_Reduce_Hallucination_of_Large_Vision_Language_Models.html#appendix",
    "href": "posts/Does_Object_Grounding_Really_Reduce_Hallucination_of_Large_Vision_Language_Models/2024-06-20-Does_Object_Grounding_Really_Reduce_Hallucination_of_Large_Vision_Language_Models.html#appendix",
    "title": "Does Object Grounding Really Reduce Hallucination of Large Vision-Language Models?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14492v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14492v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7908"
  },
  {
    "objectID": "posts/M2Lingual_Enhancing_Multilingual_Multi_Turn_Instruction_Alignment_in_Large_Language_Models/2024-06-24-M2Lingual_Enhancing_Multilingual_Multi_Turn_Instruction_Alignment_in_Large_Language_Models.html#appendix",
    "href": "posts/M2Lingual_Enhancing_Multilingual_Multi_Turn_Instruction_Alignment_in_Large_Language_Models/2024-06-24-M2Lingual_Enhancing_Multilingual_Multi_Turn_Instruction_Alignment_in_Large_Language_Models.html#appendix",
    "title": "M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16783v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16783v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8562"
  },
  {
    "objectID": "posts/A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions/2024-06-06-A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions.html",
    "href": "posts/A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions/2024-06-06-A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions.html",
    "title": "A Survey on Medical Large Language Models: Technology, Application, Trustworthiness, and Future Directions",
    "section": "",
    "text": "Summary:\nThis survey provides a comprehensive overview of Medical Large Language Models (Med-LLMs), outlining their evolution from general to medical-specific domains and their transformative impact on healthcare. The study explores the fundamental history and technology of LLMs, delving into the progressive adaptation and refinements of general LLM models in the medical domain. It emphasizes advanced algorithms that boost the LLMs’ performance in handling complicated medical environments, including clinical reasoning, knowledge graph, retrieval-augmented generation, human alignment, and multi-modal learning.\nThe survey also explores the extensive applications of Med-LLMs across domains such as clinical decision support, report generation, and medical education, illustrating their potential to streamline healthcare services and augment patient outcomes. Recognizing the imperative for responsible innovation, the study discusses the challenges of ensuring fairness, accountability, privacy, and robustness in Med-LLMs applications, where ethical considerations, rigorous evaluation methodologies, and the formulation of regulatory frameworks are pivotal to fostering trustworthiness in these systems.\nMajor Findings:\nAnalysis and Critique:\nThis survey provides a comprehensive investigation of the potential strengths and limitations of Med-LLMs for professionals and researchers, ensuring a responsible landscape in the healthcare setting. However, it is important to note that the study primarily focuses on"
  },
  {
    "objectID": "posts/A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions/2024-06-06-A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions.html#appendix",
    "href": "posts/A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions/2024-06-06-A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions.html#appendix",
    "title": "A Survey on Medical Large Language Models: Technology, Application, Trustworthiness, and Future Directions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03712v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03712v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18909"
  },
  {
    "objectID": "posts/Coherent_Zero_Shot_Visual_Instruction_Generation/2024-06-06-Coherent_Zero_Shot_Visual_Instruction_Generation.html#appendix",
    "href": "posts/Coherent_Zero_Shot_Visual_Instruction_Generation/2024-06-06-Coherent_Zero_Shot_Visual_Instruction_Generation.html#appendix",
    "title": "Coherent Zero-Shot Visual Instruction Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04337v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04337v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5054"
  },
  {
    "objectID": "posts/Educating_LLMs_like_Human_Students_Structure_aware_Injection_of_Domain_Knowledge/2024-07-23-Educating_LLMs_like_Human_Students_Structure_aware_Injection_of_Domain_Knowledge.html#appendix",
    "href": "posts/Educating_LLMs_like_Human_Students_Structure_aware_Injection_of_Domain_Knowledge/2024-07-23-Educating_LLMs_like_Human_Students_Structure_aware_Injection_of_Domain_Knowledge.html#appendix",
    "title": "Educating LLMs like Human Students: Structure-aware Injection of Domain Knowledge",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16724v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16724v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7569"
  },
  {
    "objectID": "posts/Finding_Safety_Neurons_in_Large_Language_Models/2024-06-20-Finding_Safety_Neurons_in_Large_Language_Models.html#appendix",
    "href": "posts/Finding_Safety_Neurons_in_Large_Language_Models/2024-06-20-Finding_Safety_Neurons_in_Large_Language_Models.html#appendix",
    "title": "Finding Safety Neurons in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14144v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14144v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10356"
  },
  {
    "objectID": "posts/Preference_Learning_Algorithms_Do_Not_Learn_Preference_Rankings/2024-05-29-Preference_Learning_Algorithms_Do_Not_Learn_Preference_Rankings.html#appendix",
    "href": "posts/Preference_Learning_Algorithms_Do_Not_Learn_Preference_Rankings/2024-05-29-Preference_Learning_Algorithms_Do_Not_Learn_Preference_Rankings.html#appendix",
    "title": "Preference Learning Algorithms Do Not Learn Preference Rankings",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.19534v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.19534v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10665"
  },
  {
    "objectID": "posts/Improving_LLMs_for_Recommendation_with_Out_Of_Vocabulary_Tokens/2024-06-12-Improving_LLMs_for_Recommendation_with_Out_Of_Vocabulary_Tokens.html#appendix",
    "href": "posts/Improving_LLMs_for_Recommendation_with_Out_Of_Vocabulary_Tokens/2024-06-12-Improving_LLMs_for_Recommendation_with_Out_Of_Vocabulary_Tokens.html#appendix",
    "title": "Improving LLMs for Recommendation with Out-Of-Vocabulary Tokens",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.08477v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.08477v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9535"
  },
  {
    "objectID": "posts/ScholarChemQA_Unveiling_the_Power_of_Language_Models_in_Chemical_Research_Question_Answering/2024-07-24-ScholarChemQA_Unveiling_the_Power_of_Language_Models_in_Chemical_Research_Question_Answering.html#appendix",
    "href": "posts/ScholarChemQA_Unveiling_the_Power_of_Language_Models_in_Chemical_Research_Question_Answering/2024-07-24-ScholarChemQA_Unveiling_the_Power_of_Language_Models_in_Chemical_Research_Question_Answering.html#appendix",
    "title": "ScholarChemQA: Unveiling the Power of Language Models in Chemical Research Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16931v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16931v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10882"
  },
  {
    "objectID": "posts/UniGen_A_Unified_Framework_for_Textual_Dataset_Generation_Using_Large_Language_Models/2024-06-27-UniGen_A_Unified_Framework_for_Textual_Dataset_Generation_Using_Large_Language_Models.html#appendix",
    "href": "posts/UniGen_A_Unified_Framework_for_Textual_Dataset_Generation_Using_Large_Language_Models/2024-06-27-UniGen_A_Unified_Framework_for_Textual_Dataset_Generation_Using_Large_Language_Models.html#appendix",
    "title": "UniGen: A Unified Framework for Textual Dataset Generation Using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18966v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18966v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5825"
  },
  {
    "objectID": "posts/Privacy_in_LLM_based_Recommendation_Recent_Advances_and_Future_Directions/2024-06-03-Privacy_in_LLM_based_Recommendation_Recent_Advances_and_Future_Directions.html#appendix",
    "href": "posts/Privacy_in_LLM_based_Recommendation_Recent_Advances_and_Future_Directions/2024-06-03-Privacy_in_LLM_based_Recommendation_Recent_Advances_and_Future_Directions.html#appendix",
    "title": "Privacy in LLM-based Recommendation: Recent Advances and Future Directions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01363v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01363v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3447"
  },
  {
    "objectID": "posts/OptiMUS_0.3_Using_Large_Language_Models_to_Model_and_Solve_Optimization_Problems_at_Scale/2024-07-29-OptiMUS_0.3_Using_Large_Language_Models_to_Model_and_Solve_Optimization_Problems_at_Scale.html#appendix",
    "href": "posts/OptiMUS_0.3_Using_Large_Language_Models_to_Model_and_Solve_Optimization_Problems_at_Scale/2024-07-29-OptiMUS_0.3_Using_Large_Language_Models_to_Model_and_Solve_Optimization_Problems_at_Scale.html#appendix",
    "title": "OptiMUS-0.3: Using Large Language Models to Model and Solve Optimization Problems at Scale",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19633v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19633v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9822"
  },
  {
    "objectID": "posts/Crosslingual_Capabilities_and_Knowledge_Barriers_in_Multilingual_Large_Language_Models/2024-06-23-Crosslingual_Capabilities_and_Knowledge_Barriers_in_Multilingual_Large_Language_Models.html#appendix",
    "href": "posts/Crosslingual_Capabilities_and_Knowledge_Barriers_in_Multilingual_Large_Language_Models/2024-06-23-Crosslingual_Capabilities_and_Knowledge_Barriers_in_Multilingual_Large_Language_Models.html#appendix",
    "title": "Crosslingual Capabilities and Knowledge Barriers in Multilingual Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16135v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16135v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11266"
  },
  {
    "objectID": "posts/Ragnarök_A_Reusable_RAG_Framework_and_Baselines_for_TREC_2024_Retrieval_Augmented_Generation_Track/2024-06-24-Ragnarök_A_Reusable_RAG_Framework_and_Baselines_for_TREC_2024_Retrieval_Augmented_Generation_Track.html#appendix",
    "href": "posts/Ragnarök_A_Reusable_RAG_Framework_and_Baselines_for_TREC_2024_Retrieval_Augmented_Generation_Track/2024-06-24-Ragnarök_A_Reusable_RAG_Framework_and_Baselines_for_TREC_2024_Retrieval_Augmented_Generation_Track.html#appendix",
    "title": "Ragnarök: A Reusable RAG Framework and Baselines for TREC 2024 Retrieval-Augmented Generation Track",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16828v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16828v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6500"
  },
  {
    "objectID": "posts/Prose_to_P4_Leveraging_High_Level_Languages/2024-06-19-Prose_to_P4_Leveraging_High_Level_Languages.html#appendix",
    "href": "posts/Prose_to_P4_Leveraging_High_Level_Languages/2024-06-19-Prose_to_P4_Leveraging_High_Level_Languages.html#appendix",
    "title": "Prose-to-P4: Leveraging High Level Languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13679v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13679v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4347"
  },
  {
    "objectID": "posts/BIPED_Pedagogically_Informed_Tutoring_System_for_ESL_Education/2024-06-05-BIPED_Pedagogically_Informed_Tutoring_System_for_ESL_Education.html#appendix",
    "href": "posts/BIPED_Pedagogically_Informed_Tutoring_System_for_ESL_Education/2024-06-05-BIPED_Pedagogically_Informed_Tutoring_System_for_ESL_Education.html#appendix",
    "title": "BIPED: Pedagogically Informed Tutoring System for ESL Education",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03486v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03486v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7759"
  },
  {
    "objectID": "posts/The_current_status_of_large_language_models_in_summarizing_radiology_report_impressions/2024-06-04-The_current_status_of_large_language_models_in_summarizing_radiology_report_impressions.html#appendix",
    "href": "posts/The_current_status_of_large_language_models_in_summarizing_radiology_report_impressions/2024-06-04-The_current_status_of_large_language_models_in_summarizing_radiology_report_impressions.html#appendix",
    "title": "The current status of large language models in summarizing radiology report impressions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02134v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02134v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7591"
  },
  {
    "objectID": "posts/Categorical_Syllogisms_Revisited_A_Review_of_the_Logical_Reasoning_Abilities_of_LLMs_for_Analyzing_Categorical_Syllogism/2024-06-26-Categorical_Syllogisms_Revisited_A_Review_of_the_Logical_Reasoning_Abilities_of_LLMs_for_Analyzing_Categorical_Syllogism.html",
    "href": "posts/Categorical_Syllogisms_Revisited_A_Review_of_the_Logical_Reasoning_Abilities_of_LLMs_for_Analyzing_Categorical_Syllogism/2024-06-26-Categorical_Syllogisms_Revisited_A_Review_of_the_Logical_Reasoning_Abilities_of_LLMs_for_Analyzing_Categorical_Syllogism.html",
    "title": "Categorical Syllogisms Revisited: A Review of the Logical Reasoning Abilities of LLMs for Analyzing Categorical Syllogism",
    "section": "",
    "text": "Summary:\nThis paper provides a systematic overview of prior works on the logical reasoning ability of large language models (LLMs) for analyzing categorical syllogisms. The authors investigate all possible variations of categorical syllogisms from a purely logical perspective and examine the underlying configurations tested by existing datasets. The results indicate that compared to template-based synthetic datasets, crowdsourcing approaches sacrifice the coverage of configurations for more language variations, thus bringing challenges to fully testing LLMs under different situations. The paper also summarizes the findings and observations for the performances of LLMs in inferring the validity of syllogisms from the current literature. The error rate breakdown analyses suggest that the interpretation of quantifiers is the current bottleneck that limits the performances of LLMs. Finally, the paper discusses several points that might be worth considering when researchers plan on the future release of categorical syllogism datasets.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive review of the current literature regarding categorical syllogisms and the logical reasoning abilities of LLMs. The authors’ analysis of the limitations of existing datasets and the bottlenecks in LLMs’ performance is insightful and valuable for future research. However, the paper does not provide a clear solution to the identified problems or propose new models to improve LLMs’ performance. Additionally, the paper does not discuss the potential biases or methodological issues in the existing literature, which could be a limitation of the review. Overall, the paper is well-structured, coherent, and effectively communicates the essential information from the academic article."
  },
  {
    "objectID": "posts/Categorical_Syllogisms_Revisited_A_Review_of_the_Logical_Reasoning_Abilities_of_LLMs_for_Analyzing_Categorical_Syllogism/2024-06-26-Categorical_Syllogisms_Revisited_A_Review_of_the_Logical_Reasoning_Abilities_of_LLMs_for_Analyzing_Categorical_Syllogism.html#appendix",
    "href": "posts/Categorical_Syllogisms_Revisited_A_Review_of_the_Logical_Reasoning_Abilities_of_LLMs_for_Analyzing_Categorical_Syllogism/2024-06-26-Categorical_Syllogisms_Revisited_A_Review_of_the_Logical_Reasoning_Abilities_of_LLMs_for_Analyzing_Categorical_Syllogism.html#appendix",
    "title": "Categorical Syllogisms Revisited: A Review of the Logical Reasoning Abilities of LLMs for Analyzing Categorical Syllogism",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18762v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18762v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7262"
  },
  {
    "objectID": "posts/Arena_Learning_Build_Data_Flywheel_for_LLMs_Post_training_via_Simulated_Chatbot_Arena/2024-07-15-Arena_Learning_Build_Data_Flywheel_for_LLMs_Post_training_via_Simulated_Chatbot_Arena.html#appendix",
    "href": "posts/Arena_Learning_Build_Data_Flywheel_for_LLMs_Post_training_via_Simulated_Chatbot_Arena/2024-07-15-Arena_Learning_Build_Data_Flywheel_for_LLMs_Post_training_via_Simulated_Chatbot_Arena.html#appendix",
    "title": "Arena Learning: Build Data Flywheel for LLMs Post-training via Simulated Chatbot Arena",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10627v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10627v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10689"
  },
  {
    "objectID": "posts/Understanding_Different_Design_Choices_in_Training_Large_Time_Series_Models/2024-06-20-Understanding_Different_Design_Choices_in_Training_Large_Time_Series_Models.html#appendix",
    "href": "posts/Understanding_Different_Design_Choices_in_Training_Large_Time_Series_Models/2024-06-20-Understanding_Different_Design_Choices_in_Training_Large_Time_Series_Models.html#appendix",
    "title": "Understanding Different Design Choices in Training Large Time Series Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14045v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14045v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7858"
  },
  {
    "objectID": "posts/Machine_Unlearning_Fails_to_Remove_Data_Poisoning_Attacks/2024-06-25-Machine_Unlearning_Fails_to_Remove_Data_Poisoning_Attacks.html#appendix",
    "href": "posts/Machine_Unlearning_Fails_to_Remove_Data_Poisoning_Attacks/2024-06-25-Machine_Unlearning_Fails_to_Remove_Data_Poisoning_Attacks.html#appendix",
    "title": "Machine Unlearning Fails to Remove Data Poisoning Attacks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17216v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17216v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15361"
  },
  {
    "objectID": "posts/Fairness_and_Bias_in_Multimodal_AI_A_Survey/2024-06-27-Fairness_and_Bias_in_Multimodal_AI_A_Survey.html#appendix",
    "href": "posts/Fairness_and_Bias_in_Multimodal_AI_A_Survey/2024-06-27-Fairness_and_Bias_in_Multimodal_AI_A_Survey.html#appendix",
    "title": "Fairness and Bias in Multimodal AI: A Survey",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19097v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19097v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5909"
  },
  {
    "objectID": "posts/CLIMB_A_Benchmark_of_Clinical_Bias_in_Large_Language_Models/2024-07-07-CLIMB_A_Benchmark_of_Clinical_Bias_in_Large_Language_Models.html#appendix",
    "href": "posts/CLIMB_A_Benchmark_of_Clinical_Bias_in_Large_Language_Models/2024-07-07-CLIMB_A_Benchmark_of_Clinical_Bias_in_Large_Language_Models.html#appendix",
    "title": "CLIMB: A Benchmark of Clinical Bias in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05250v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05250v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6808"
  },
  {
    "objectID": "posts/RePrompt_Planning_by_Automatic_Prompt_Engineering_for_Large_Language_Models_Agents/2024-06-17-RePrompt_Planning_by_Automatic_Prompt_Engineering_for_Large_Language_Models_Agents.html#appendix",
    "href": "posts/RePrompt_Planning_by_Automatic_Prompt_Engineering_for_Large_Language_Models_Agents/2024-06-17-RePrompt_Planning_by_Automatic_Prompt_Engineering_for_Large_Language_Models_Agents.html#appendix",
    "title": "RePrompt: Planning by Automatic Prompt Engineering for Large Language Models Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11132v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11132v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9868"
  },
  {
    "objectID": "posts/Multilingual_Blending_LLM_Safety_Alignment_Evaluation_with_Language_Mixture/2024-07-10-Multilingual_Blending_LLM_Safety_Alignment_Evaluation_with_Language_Mixture.html#appendix",
    "href": "posts/Multilingual_Blending_LLM_Safety_Alignment_Evaluation_with_Language_Mixture/2024-07-10-Multilingual_Blending_LLM_Safety_Alignment_Evaluation_with_Language_Mixture.html#appendix",
    "title": "Multilingual Blending: LLM Safety Alignment Evaluation with Language Mixture",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07342v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07342v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10780"
  },
  {
    "objectID": "posts/Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models/2024-06-17-Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models.html",
    "href": "posts/Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models/2024-06-17-Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models.html",
    "title": "Long Code Arena: a Set of Benchmarks for Long-Context Code Models",
    "section": "",
    "text": "Summary:\nThe paper introduces Long Code Arena, a suite of six benchmarks for code processing tasks that require project-wide context. These tasks include library-based code generation, CI builds repair, project-level code completion, commit message generation, bug localization, and module summarization. The paper highlights the limitations of existing ML4SE benchmarks, such as short context length and limited resemblance to practical use cases. Long Code Arena aims to address these issues by providing manually verified datasets, evaluation suites, and open-source baseline solutions based on popular LLMs. The benchmark page, leaderboard, and links to datasets are available on HuggingFace Spaces.\nMajor Findings:"
  },
  {
    "objectID": "posts/Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models/2024-06-17-Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models.html#appendix",
    "href": "posts/Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models/2024-06-17-Long_Code_Arena_a_Set_of_Benchmarks_for_Long_Context_Code_Models.html#appendix",
    "title": "Long Code Arena: a Set of Benchmarks for Long-Context Code Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.11612v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.11612v1\n\n\nTruncated\nTrue\n\n\nWord Count\n31007"
  },
  {
    "objectID": "posts/VAIYAKARANA__A_Benchmark_for_Automatic_Grammar_Correction_in_Bangla/2024-06-20-VAIYAKARANA__A_Benchmark_for_Automatic_Grammar_Correction_in_Bangla.html",
    "href": "posts/VAIYAKARANA__A_Benchmark_for_Automatic_Grammar_Correction_in_Bangla/2024-06-20-VAIYAKARANA__A_Benchmark_for_Automatic_Grammar_Correction_in_Bangla.html",
    "title": "VAIYAKARANA : A Benchmark for Automatic Grammar Correction in Bangla",
    "section": "",
    "text": "Summary:\nThe paper titled “VAIYAKARANA: A Benchmark for Automatic Grammar Correction in Bangla” by Pramit Bhattacharyya and Arnab Bhattacharya proposes a pragmatic approach to generate grammatically incorrect sentences in Bangla. The authors categorize the different kinds of errors in Bangla into 5 broad classes and 12 finer classes. They then use these categories to generate erroneous sentences systematically from a correct sentence. This approach can generate a large number of wrong sentences, which can be used to train neural networks. The authors also provide a dataset, Vaiyākaraṇa, consisting of 92,830 grammatically incorrect sentences and 18,426 correct sentences. They also collected 619 human-generated sentences from essays written by Bangla native speakers. The authors evaluate their corpus against neural models and LLMs and benchmark it against human evaluators, who are native speakers of Bangla. The analysis shows that native speakers are far more accurate than state-of-the-art models to detect whether a sentence is grammatically correct. However, even native speakers find it difficult to categorize the type of error. This shows the efficacy of the Vaiyākaraṇa corpus. The methodology of generating erroneous sentences can be applied for most other Indian languages as well.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel approach to generate grammatically incorrect sentences in"
  },
  {
    "objectID": "posts/VAIYAKARANA__A_Benchmark_for_Automatic_Grammar_Correction_in_Bangla/2024-06-20-VAIYAKARANA__A_Benchmark_for_Automatic_Grammar_Correction_in_Bangla.html#appendix",
    "href": "posts/VAIYAKARANA__A_Benchmark_for_Automatic_Grammar_Correction_in_Bangla/2024-06-20-VAIYAKARANA__A_Benchmark_for_Automatic_Grammar_Correction_in_Bangla.html#appendix",
    "title": "VAIYAKARANA : A Benchmark for Automatic Grammar Correction in Bangla",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14284v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14284v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20042"
  },
  {
    "objectID": "posts/BADGE_BADminton_report_Generation_and_Evaluation_with_LLM/2024-06-26-BADGE_BADminton_report_Generation_and_Evaluation_with_LLM.html#appendix",
    "href": "posts/BADGE_BADminton_report_Generation_and_Evaluation_with_LLM/2024-06-26-BADGE_BADminton_report_Generation_and_Evaluation_with_LLM.html#appendix",
    "title": "BADGE: BADminton report Generation and Evaluation with LLM",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18116v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18116v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6049"
  },
  {
    "objectID": "posts/A_Survey_of_Attacks_on_Large_Vision_Language_Models_Resources_Advances_and_Future_Trends/2024-07-10-A_Survey_of_Attacks_on_Large_Vision_Language_Models_Resources_Advances_and_Future_Trends.html#major-findings",
    "href": "posts/A_Survey_of_Attacks_on_Large_Vision_Language_Models_Resources_Advances_and_Future_Trends/2024-07-10-A_Survey_of_Attacks_on_Large_Vision_Language_Models_Resources_Advances_and_Future_Trends.html#major-findings",
    "title": "A Survey of Attacks on Large Vision-Language Models: Resources, Advances, and Future Trends",
    "section": "Major Findings",
    "text": "Major Findings\n\nAdversarial Attacks: These attacks manipulate model outputs by introducing subtle perturbations to the input data, causing the model to produce incorrect or undesirable outputs. These perturbations are meticulously designed to exploit the model’s vulnerabilities.\nJailbreak Attacks: These attacks exploit weaknesses in the model to bypass its intended restrictions and controls, leading to the model executing unauthorized commands, accessing restricted data, or performing actions beyond its designed capabilities.\nPrompt Injection Attacks: These attacks involve manipulating the model’s input prompts to alter its behavior or outputs in unintended ways. By injecting malicious or misleading prompts, attackers can steer the model to generate incorrect, biased, or harmful responses.\nData Poisoning/Backdoor Attacks: These attacks tamper with the training data to undermine the model’s performance and reliability. In these attacks, malicious data is inserted into the training dataset, causing the model to learn and propagate incorrect patterns."
  },
  {
    "objectID": "posts/A_Survey_of_Attacks_on_Large_Vision_Language_Models_Resources_Advances_and_Future_Trends/2024-07-10-A_Survey_of_Attacks_on_Large_Vision_Language_Models_Resources_Advances_and_Future_Trends.html#analysis-and-critique",
    "href": "posts/A_Survey_of_Attacks_on_Large_Vision_Language_Models_Resources_Advances_and_Future_Trends/2024-07-10-A_Survey_of_Attacks_on_Large_Vision_Language_Models_Resources_Advances_and_Future_Trends.html#analysis-and-critique",
    "title": "A Survey of Attacks on Large Vision-Language Models: Resources, Advances, and Future Trends",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\nThe paper provides a comprehensive overview of the current landscape of attacks on LVLMs. However, it does not delve into the specific methodologies used in each type of attack, which could be beneficial for understanding the nuances of each attack. Additionally, the paper does not discuss potential defense strategies against these attacks, which is a crucial aspect of ensuring the security and robustness of LVLMs.\nMoreover, the paper could benefit from a more in-depth discussion on the ethical implications of these attacks, as they can have significant real-world consequences. For instance, adversarial attacks on autonomous driving systems could lead"
  },
  {
    "objectID": "posts/A_Survey_of_Attacks_on_Large_Vision_Language_Models_Resources_Advances_and_Future_Trends/2024-07-10-A_Survey_of_Attacks_on_Large_Vision_Language_Models_Resources_Advances_and_Future_Trends.html#appendix",
    "href": "posts/A_Survey_of_Attacks_on_Large_Vision_Language_Models_Resources_Advances_and_Future_Trends/2024-07-10-A_Survey_of_Attacks_on_Large_Vision_Language_Models_Resources_Advances_and_Future_Trends.html#appendix",
    "title": "A Survey of Attacks on Large Vision-Language Models: Resources, Advances, and Future Trends",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07403v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07403v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11932"
  },
  {
    "objectID": "posts/Exploring_the_Capabilities_of_LLMs_for_Code_Change_Related_Tasks/2024-07-03-Exploring_the_Capabilities_of_LLMs_for_Code_Change_Related_Tasks.html#appendix",
    "href": "posts/Exploring_the_Capabilities_of_LLMs_for_Code_Change_Related_Tasks/2024-07-03-Exploring_the_Capabilities_of_LLMs_for_Code_Change_Related_Tasks.html#appendix",
    "title": "Exploring the Capabilities of LLMs for Code Change Related Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02824v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02824v1\n\n\nTruncated\nFalse\n\n\nWord Count\n16271"
  },
  {
    "objectID": "posts/The_Synergy_between_Data_and_Multi_Modal_Large_Language_Models_A_Survey_from_Co_Development_Perspective/2024-07-11-The_Synergy_between_Data_and_Multi_Modal_Large_Language_Models_A_Survey_from_Co_Development_Perspective.html",
    "href": "posts/The_Synergy_between_Data_and_Multi_Modal_Large_Language_Models_A_Survey_from_Co_Development_Perspective/2024-07-11-The_Synergy_between_Data_and_Multi_Modal_Large_Language_Models_A_Survey_from_Co_Development_Perspective.html",
    "title": "The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective",
    "section": "",
    "text": "Summary:\nThe paper discusses the development of multi-modal large language models (MLLMs) and the importance of data in their performance. The authors propose a new taxonomy that emphasizes the synergy between multi-modal data and MLLMs, aiming to understand and mine the mutual benefits for both data and model development. The taxonomy is organized based on the hierarchy of data-related technologies essential for developing MLLMs. The paper also provides a comprehensive review of existing works related to MLLMs from the data-model co-development perspective and a regularly maintained project associated with this survey.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive review of the development of MLLMs and the importance of data in their performance. The proposed taxonomy and the review of existing works offer a new perspective for MLLM development and a roadmap for future research. However, the paper does not discuss the limitations or potential biases in the reviewed works, which could be a topic for future research. Additionally, the paper does not discuss the potential ethical implications of MLLMs, which is an important consideration in the development and deployment of these models."
  },
  {
    "objectID": "posts/The_Synergy_between_Data_and_Multi_Modal_Large_Language_Models_A_Survey_from_Co_Development_Perspective/2024-07-11-The_Synergy_between_Data_and_Multi_Modal_Large_Language_Models_A_Survey_from_Co_Development_Perspective.html#appendix",
    "href": "posts/The_Synergy_between_Data_and_Multi_Modal_Large_Language_Models_A_Survey_from_Co_Development_Perspective/2024-07-11-The_Synergy_between_Data_and_Multi_Modal_Large_Language_Models_A_Survey_from_Co_Development_Perspective.html#appendix",
    "title": "The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08583v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08583v1\n\n\nTruncated\nFalse\n\n\nWord Count\n26789"
  },
  {
    "objectID": "posts/Let_the_Code_LLM_Edit_Itself_When_You_Edit_the_Code/2024-07-03-Let_the_Code_LLM_Edit_Itself_When_You_Edit_the_Code.html#appendix",
    "href": "posts/Let_the_Code_LLM_Edit_Itself_When_You_Edit_the_Code/2024-07-03-Let_the_Code_LLM_Edit_Itself_When_You_Edit_the_Code.html#appendix",
    "title": "Let the Code LLM Edit Itself When You Edit the Code",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03157v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03157v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6193"
  },
  {
    "objectID": "posts/Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data/2024-06-20-Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data.html",
    "href": "posts/Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data/2024-06-20-Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data.html",
    "title": "Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data",
    "section": "",
    "text": "Summary:\nThe paper explores the ability of large language models (LLMs) to infer and verbalize latent structure from disparate training data, a phenomenon known as inductive out-of-context reasoning (OOCR). The authors demonstrate that frontier LLMs can perform inductive OOCR, as evidenced by a suite of five tasks. In one experiment, an LLM was finetuned on a corpus consisting only of distances between an unknown city and other known cities. Remarkably, the LLM could verbalize that the unknown city is Paris and use this fact to answer downstream questions without in-context learning or Chain of Thought. Further experiments showed that LLMs trained only on individual coin flip outcomes could verbalize whether the coin is biased, and those trained only on pairs could articulate a definition of a function and compute inverses. However, OOCR was found to be unreliable, particularly for smaller LLMs learning complex structures. The ability of LLMs to “connect the dots” without explicit in-context learning poses a potential obstacle to monitoring and controlling the knowledge acquired by LLMs.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an interesting exploration of the ability of LLMs to infer and verbalize latent structure from disparate training data. The authors’ findings suggest that LLMs can perform inductive OOCR, a type of generalization that allows them to infer latent information from evidence distributed across training documents and apply it to downstream tasks without in-context learning. However, the authors note that OOCR is unreliable, particularly for smaller LLMs learning complex structures. This raises questions about the robustness and"
  },
  {
    "objectID": "posts/Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data/2024-06-20-Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data.html#appendix",
    "href": "posts/Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data/2024-06-20-Connecting_the_Dots_LLMs_can_Infer_and_Verbalize_Latent_Structure_from_Disparate_Training_Data.html#appendix",
    "title": "Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14546v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14546v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20777"
  },
  {
    "objectID": "posts/Aligning_Large_Language_Models_with_Diverse_Political_Viewpoints/2024-06-20-Aligning_Large_Language_Models_with_Diverse_Political_Viewpoints.html#appendix",
    "href": "posts/Aligning_Large_Language_Models_with_Diverse_Political_Viewpoints/2024-06-20-Aligning_Large_Language_Models_with_Diverse_Political_Viewpoints.html#appendix",
    "title": "Aligning Large Language Models with Diverse Political Viewpoints",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14155v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14155v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5339"
  },
  {
    "objectID": "posts/PenHeal_A_Two_Stage_LLM_Framework_for_Automated_Pentesting_and_Optimal_Remediation/2024-07-25-PenHeal_A_Two_Stage_LLM_Framework_for_Automated_Pentesting_and_Optimal_Remediation.html#appendix",
    "href": "posts/PenHeal_A_Two_Stage_LLM_Framework_for_Automated_Pentesting_and_Optimal_Remediation/2024-07-25-PenHeal_A_Two_Stage_LLM_Framework_for_Automated_Pentesting_and_Optimal_Remediation.html#appendix",
    "title": "PenHeal: A Two-Stage LLM Framework for Automated Pentesting and Optimal Remediation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17788v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17788v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9946"
  },
  {
    "objectID": "posts/SimsChat_A_Customisable_Persona_Driven_Role_Playing_Agent/2024-06-25-SimsChat_A_Customisable_Persona_Driven_Role_Playing_Agent.html#appendix",
    "href": "posts/SimsChat_A_Customisable_Persona_Driven_Role_Playing_Agent/2024-06-25-SimsChat_A_Customisable_Persona_Driven_Role_Playing_Agent.html#appendix",
    "title": "SimsChat: A Customisable Persona-Driven Role-Playing Agent",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17962v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17962v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6407"
  },
  {
    "objectID": "posts/From_Text_to_Test_AI_Generated_Control_Software_for_Materials_Science_Instruments/2024-06-23-From_Text_to_Test_AI_Generated_Control_Software_for_Materials_Science_Instruments.html#appendix",
    "href": "posts/From_Text_to_Test_AI_Generated_Control_Software_for_Materials_Science_Instruments/2024-06-23-From_Text_to_Test_AI_Generated_Control_Software_for_Materials_Science_Instruments.html#appendix",
    "title": "From Text to Test: AI-Generated Control Software for Materials Science Instruments",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16224v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16224v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8908"
  },
  {
    "objectID": "posts/THaLLE_Text_Hyperlocally_Augmented_Large_Language_Extension____Technical_Report/2024-06-11-THaLLE_Text_Hyperlocally_Augmented_Large_Language_Extension____Technical_Report.html#appendix",
    "href": "posts/THaLLE_Text_Hyperlocally_Augmented_Large_Language_Extension____Technical_Report/2024-06-11-THaLLE_Text_Hyperlocally_Augmented_Large_Language_Extension____Technical_Report.html#appendix",
    "title": "THaLLE: Text Hyperlocally Augmented Large Language Extension – Technical Report",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07505v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07505v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5344"
  },
  {
    "objectID": "posts/LLMs_instead_of_Human_Judges_A_Large_Scale_Empirical_Study_across_20_NLP_Evaluation_Tasks/2024-06-26-LLMs_instead_of_Human_Judges_A_Large_Scale_Empirical_Study_across_20_NLP_Evaluation_Tasks.html#appendix",
    "href": "posts/LLMs_instead_of_Human_Judges_A_Large_Scale_Empirical_Study_across_20_NLP_Evaluation_Tasks/2024-06-26-LLMs_instead_of_Human_Judges_A_Large_Scale_Empirical_Study_across_20_NLP_Evaluation_Tasks.html#appendix",
    "title": "LLMs instead of Human Judges? A Large Scale Empirical Study across 20 NLP Evaluation Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18403v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18403v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5321"
  },
  {
    "objectID": "posts/Global_is_Good_Local_is_Bad_Understanding_Brand_Bias_in_LLMs/2024-06-20-Global_is_Good_Local_is_Bad_Understanding_Brand_Bias_in_LLMs.html#appendix",
    "href": "posts/Global_is_Good_Local_is_Bad_Understanding_Brand_Bias_in_LLMs/2024-06-20-Global_is_Good_Local_is_Bad_Understanding_Brand_Bias_in_LLMs.html#appendix",
    "title": "Global is Good, Local is Bad?: Understanding Brand Bias in LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13997v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13997v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4379"
  },
  {
    "objectID": "posts/Explicit_and_Implicit_Large_Language_Model_Personas_Generate_Opinions_but_Fail_to_Replicate_Deeper_Perceptions_and_Biases/2024-06-20-Explicit_and_Implicit_Large_Language_Model_Personas_Generate_Opinions_but_Fail_to_Replicate_Deeper_Perceptions_and_Biases.html#appendix",
    "href": "posts/Explicit_and_Implicit_Large_Language_Model_Personas_Generate_Opinions_but_Fail_to_Replicate_Deeper_Perceptions_and_Biases/2024-06-20-Explicit_and_Implicit_Large_Language_Model_Personas_Generate_Opinions_but_Fail_to_Replicate_Deeper_Perceptions_and_Biases.html#appendix",
    "title": "Explicit and Implicit Large Language Model Personas Generate Opinions but Fail to Replicate Deeper Perceptions and Biases",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14462v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14462v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6689"
  },
  {
    "objectID": "posts/Beyond_Correctness_Benchmarking_Multi_dimensional_Code_Generation_for_Large_Language_Models/2024-07-16-Beyond_Correctness_Benchmarking_Multi_dimensional_Code_Generation_for_Large_Language_Models.html#major-findings",
    "href": "posts/Beyond_Correctness_Benchmarking_Multi_dimensional_Code_Generation_for_Large_Language_Models/2024-07-16-Beyond_Correctness_Benchmarking_Multi_dimensional_Code_Generation_for_Large_Language_Models.html#major-findings",
    "title": "Beyond Correctness: Benchmarking Multi-dimensional Code Generation for Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nCurrent LLMs’ ability to generate high-quality code on demand does not yet meet the requirements of software development.\nReadability serves as a critical indicator of the overall quality of generated code.\nMost LLMs exhibit an inherent preference for specific coding styles, making it difficult for them to follow user instructions that are inconsistent with their preference."
  },
  {
    "objectID": "posts/Beyond_Correctness_Benchmarking_Multi_dimensional_Code_Generation_for_Large_Language_Models/2024-07-16-Beyond_Correctness_Benchmarking_Multi_dimensional_Code_Generation_for_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/Beyond_Correctness_Benchmarking_Multi_dimensional_Code_Generation_for_Large_Language_Models/2024-07-16-Beyond_Correctness_Benchmarking_Multi_dimensional_Code_Generation_for_Large_Language_Models.html#analysis-and-critique",
    "title": "Beyond Correctness: Benchmarking Multi-dimensional Code Generation for Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe RACE benchmark provides a valuable contribution to the evaluation of code generated by LLMs, addressing the limitations of existing benchmarks that primarily focus on code correctness. However, the benchmark could be expanded to include additional dimensions, such as security, testability, and dynamic behavior. Additionally, the experiments have only been conducted on Python code data, and future work should consider expanding to multilingual code to explore differences in model preferences across languages.\nThe findings highlight the need for further improvement in the ability of LLMs to generate high-quality code across multiple dimensions based on user demands. The inherent preference bias of LLMs for specific coding styles can lead to the ossification of code style and hinder their ability to meet specific real-world project requirements. Future efforts should focus on improving the ability of LLMs to meet real-world requirements and explore deeper factors influencing generated code quality.\nIn conclusion, the RACE benchmark provides a valuable tool for evaluating the quality of code generated by LLMs and highlights the need for further improvement in this area. The findings of this study can help researchers gain a deeper understanding of the coding capabilities of current LLMs and guide future directions for model improvement."
  },
  {
    "objectID": "posts/Beyond_Correctness_Benchmarking_Multi_dimensional_Code_Generation_for_Large_Language_Models/2024-07-16-Beyond_Correctness_Benchmarking_Multi_dimensional_Code_Generation_for_Large_Language_Models.html#appendix",
    "href": "posts/Beyond_Correctness_Benchmarking_Multi_dimensional_Code_Generation_for_Large_Language_Models/2024-07-16-Beyond_Correctness_Benchmarking_Multi_dimensional_Code_Generation_for_Large_Language_Models.html#appendix",
    "title": "Beyond Correctness: Benchmarking Multi-dimensional Code Generation for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.11470v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.11470v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6582"
  },
  {
    "objectID": "posts/Do_they_mean_us_Interpreting_Referring_Expressions_in_Intergroup_Bias/2024-06-25-Do_they_mean_us_Interpreting_Referring_Expressions_in_Intergroup_Bias.html",
    "href": "posts/Do_they_mean_us_Interpreting_Referring_Expressions_in_Intergroup_Bias/2024-06-25-Do_they_mean_us_Interpreting_Referring_Expressions_in_Intergroup_Bias.html",
    "title": "Do they mean ‘us’? Interpreting Referring Expressions in Intergroup Bias",
    "section": "",
    "text": "Summary:\nThis paper presents a study on intergroup bias in language, focusing on the variations in language used by in-group and out-group members in online sports forums. The authors curate a unique dataset of over 6 million game-time comments from opposing perspectives in NFL team subreddits, each comment grounded in non-linguistic descriptions of the events that precipitated these comments. The study reveals that modeling the bias through tagging of implicit and explicit referring expressions requires a rich, contextual understanding of language and the world. The authors use LLMs for automated tagging and discover that some LLMs perform best when prompted with linguistic descriptions of the win probability at the time of the comment. Large-scale tagging of comments using LLMs uncovers linear variations in the form of referent across win probabilities that distinguish in-group and out-group utterances.\nMajor Findings:"
  },
  {
    "objectID": "posts/Do_they_mean_us_Interpreting_Referring_Expressions_in_Intergroup_Bias/2024-06-25-Do_they_mean_us_Interpreting_Referring_Expressions_in_Intergroup_Bias.html#appendix",
    "href": "posts/Do_they_mean_us_Interpreting_Referring_Expressions_in_Intergroup_Bias/2024-06-25-Do_they_mean_us_Interpreting_Referring_Expressions_in_Intergroup_Bias.html#appendix",
    "title": "Do they mean ‘us’? Interpreting Referring Expressions in Intergroup Bias",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17947v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17947v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14790"
  },
  {
    "objectID": "posts/AgentDojo_A_Dynamic_Environment_to_Evaluate_Attacks_and_Defenses_for_LLM_Agents/2024-06-19-AgentDojo_A_Dynamic_Environment_to_Evaluate_Attacks_and_Defenses_for_LLM_Agents.html#appendix",
    "href": "posts/AgentDojo_A_Dynamic_Environment_to_Evaluate_Attacks_and_Defenses_for_LLM_Agents/2024-06-19-AgentDojo_A_Dynamic_Environment_to_Evaluate_Attacks_and_Defenses_for_LLM_Agents.html#appendix",
    "title": "AgentDojo: A Dynamic Environment to Evaluate Attacks and Defenses for LLM Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13352v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13352v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7934"
  },
  {
    "objectID": "posts/Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients/2024-06-23-Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients.html#major-findings",
    "href": "posts/Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients/2024-06-23-Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients.html#major-findings",
    "title": "Effectiveness of ChatGPT in explaining complex medical reports to patients",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nInaccurate Information: ChatGPT’s explanations contained errors, including incorrect interpretation of abbreviations, URLs, and test results.\nInappropriate Language: The language used by ChatGPT was sometimes too complex, grammatically incorrect, or used American English, which is inappropriate in the UK.\nLimited Personalization: The responses were not always tailored to the patient, and the content was often too vague or technical.\nAI Distrust: Patients and doctors expressed reluctance to trust ChatGPT responses unless they were checked, preferably by clinicians. Some patients did not want to use them at all.\nIntegration Challenges: Integrating ChatGPT into existing clinical workflows, including getting approval from the NHS, poses significant challenges."
  },
  {
    "objectID": "posts/Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients/2024-06-23-Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients.html#analysis-and-critique",
    "href": "posts/Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients/2024-06-23-Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients.html#analysis-and-critique",
    "title": "Effectiveness of ChatGPT in explaining complex medical reports to patients",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe study highlights the potential of ChatGPT in assisting with complex medical reports but also underscores the need for improvements. The issues identified, such as inaccurate information, inappropriate language, limited personalization, and AI distrust, need to be addressed before LLMs can be effectively used to explain complex personal medical information to patients. The study also points out the challenges of integrating LLMs into clinical workflow and the need for more research on what patients and doctors need from such tools.\nThe study’s limitations include the small sample size for annotations and the lack of comprehensive data on focus group participants, which may have introduced bias. The use of only the webpage version of ChatGPT4 also limits the applicability of the findings to other LLMs.\nEthical considerations were addressed, with two ethical approvals obtained and all experiments conducted with the informed consent of the participants."
  },
  {
    "objectID": "posts/Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients/2024-06-23-Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients.html#appendix",
    "href": "posts/Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients/2024-06-23-Effectiveness_of_ChatGPT_in_explaining_complex_medical_reports_to_patients.html#appendix",
    "title": "Effectiveness of ChatGPT in explaining complex medical reports to patients",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.15963v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.15963v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7576"
  },
  {
    "objectID": "posts/Hierarchical_Context_Pruning_Optimizing_Real_World_Code_Completion_with_Repository_Level_Pretrained_Code_LLMs/2024-06-26-Hierarchical_Context_Pruning_Optimizing_Real_World_Code_Completion_with_Repository_Level_Pretrained_Code_LLMs.html#appendix",
    "href": "posts/Hierarchical_Context_Pruning_Optimizing_Real_World_Code_Completion_with_Repository_Level_Pretrained_Code_LLMs/2024-06-26-Hierarchical_Context_Pruning_Optimizing_Real_World_Code_Completion_with_Repository_Level_Pretrained_Code_LLMs.html#appendix",
    "title": "Hierarchical Context Pruning: Optimizing Real-World Code Completion with Repository-Level Pretrained Code LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18294v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18294v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6374"
  },
  {
    "objectID": "posts/Graph_Augmented_LLMs_for_Personalized_Health_Insights_A_Case_Study_in_Sleep_Analysis/2024-06-24-Graph_Augmented_LLMs_for_Personalized_Health_Insights_A_Case_Study_in_Sleep_Analysis.html#appendix",
    "href": "posts/Graph_Augmented_LLMs_for_Personalized_Health_Insights_A_Case_Study_in_Sleep_Analysis/2024-06-24-Graph_Augmented_LLMs_for_Personalized_Health_Insights_A_Case_Study_in_Sleep_Analysis.html#appendix",
    "title": "Graph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16252v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16252v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3224"
  },
  {
    "objectID": "posts/M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering/2024-06-06-M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering.html",
    "href": "posts/M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering/2024-06-06-M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering.html",
    "title": "M-QALM: A Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall in Large Language Models via Question Answering",
    "section": "",
    "text": "Summary:\nThe paper introduces M-QALM, a benchmark for evaluating clinical reading comprehension and knowledge recall in large language models (LLMs) through question answering. The authors conduct a large-scale empirical study using 22 datasets in three generalist and three specialist biomedical sub-domains. They analyze the performance of 15 LLMs, focusing on factors such as instruction tuning, domain-adapted models, and fine-tuning on medical knowledge datasets. The results show that while recent domain-adapted models may lack adequate knowledge, fine-tuning on medical knowledge datasets shows encouraging results, even generalizing to unseen specialist sub-domains. The paper also includes a skill-oriented manual error analysis, revealing a significant gap between the models’ capabilities to recall necessary knowledge and integrate it with the presented context.\nMajor Findings:"
  },
  {
    "objectID": "posts/M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering/2024-06-06-M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering.html#appendix",
    "href": "posts/M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering/2024-06-06-M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering.html#appendix",
    "title": "M-QALM: A Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall in Large Language Models via Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03699v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03699v1\n\n\nTruncated\nTrue\n\n\nWord Count\n32275"
  },
  {
    "objectID": "posts/GUI_Action_Narrator_Where_and_When_Did_That_Action_Take_Place/2024-06-19-GUI_Action_Narrator_Where_and_When_Did_That_Action_Take_Place.html#appendix",
    "href": "posts/GUI_Action_Narrator_Where_and_When_Did_That_Action_Take_Place/2024-06-19-GUI_Action_Narrator_Where_and_When_Did_That_Action_Take_Place.html#appendix",
    "title": "GUI Action Narrator: Where and When Did That Action Take Place?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13719v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13719v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6190"
  },
  {
    "objectID": "posts/BeHonest_Benchmarking_Honesty_of_Large_Language_Models/2024-06-19-BeHonest_Benchmarking_Honesty_of_Large_Language_Models.html#appendix",
    "href": "posts/BeHonest_Benchmarking_Honesty_of_Large_Language_Models/2024-06-19-BeHonest_Benchmarking_Honesty_of_Large_Language_Models.html#appendix",
    "title": "BeHonest: Benchmarking Honesty of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13261v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13261v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9544"
  },
  {
    "objectID": "posts/All_Roads_Lead_to_Rome_Unveiling_the_Trajectory_of_Recommender_Systems_Across_the_LLM_Era/2024-07-14-All_Roads_Lead_to_Rome_Unveiling_the_Trajectory_of_Recommender_Systems_Across_the_LLM_Era.html#appendix",
    "href": "posts/All_Roads_Lead_to_Rome_Unveiling_the_Trajectory_of_Recommender_Systems_Across_the_LLM_Era/2024-07-14-All_Roads_Lead_to_Rome_Unveiling_the_Trajectory_of_Recommender_Systems_Across_the_LLM_Era.html#appendix",
    "title": "All Roads Lead to Rome: Unveiling the Trajectory of Recommender Systems Across the LLM Era",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10081v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10081v1\n\n\nTruncated\nFalse\n\n\nWord Count\n19034"
  },
  {
    "objectID": "posts/LLaMAX_Scaling_Linguistic_Horizons_of_LLM_by_Enhancing_Translation_Capabilities_Beyond_100_Languages/2024-07-08-LLaMAX_Scaling_Linguistic_Horizons_of_LLM_by_Enhancing_Translation_Capabilities_Beyond_100_Languages.html#appendix",
    "href": "posts/LLaMAX_Scaling_Linguistic_Horizons_of_LLM_by_Enhancing_Translation_Capabilities_Beyond_100_Languages/2024-07-08-LLaMAX_Scaling_Linguistic_Horizons_of_LLM_by_Enhancing_Translation_Capabilities_Beyond_100_Languages.html#appendix",
    "title": "LLaMAX: Scaling Linguistic Horizons of LLM by Enhancing Translation Capabilities Beyond 100 Languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05975v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05975v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10244"
  },
  {
    "objectID": "posts/Through_the_Theory_of_Minds_Eye_Reading_Minds_with_Multimodal_Video_Large_Language_Models/2024-06-19-Through_the_Theory_of_Minds_Eye_Reading_Minds_with_Multimodal_Video_Large_Language_Models.html#appendix",
    "href": "posts/Through_the_Theory_of_Minds_Eye_Reading_Minds_with_Multimodal_Video_Large_Language_Models/2024-06-19-Through_the_Theory_of_Minds_Eye_Reading_Minds_with_Multimodal_Video_Large_Language_Models.html#appendix",
    "title": "Through the Theory of Mind’s Eye: Reading Minds with Multimodal Video Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13763v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13763v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4909"
  },
  {
    "objectID": "posts/On_the_Universal_Truthfulness_Hyperplane_Inside_LLMs/2024-07-11-On_the_Universal_Truthfulness_Hyperplane_Inside_LLMs.html#appendix",
    "href": "posts/On_the_Universal_Truthfulness_Hyperplane_Inside_LLMs/2024-07-11-On_the_Universal_Truthfulness_Hyperplane_Inside_LLMs.html#appendix",
    "title": "On the Universal Truthfulness Hyperplane Inside LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08582v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08582v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14310"
  },
  {
    "objectID": "posts/OMG_LLaVA_Bridging_Image_level_Object_level_Pixel_level_Reasoning_and_Understanding/2024-06-27-OMG_LLaVA_Bridging_Image_level_Object_level_Pixel_level_Reasoning_and_Understanding.html#appendix",
    "href": "posts/OMG_LLaVA_Bridging_Image_level_Object_level_Pixel_level_Reasoning_and_Understanding/2024-06-27-OMG_LLaVA_Bridging_Image_level_Object_level_Pixel_level_Reasoning_and_Understanding.html#appendix",
    "title": "OMG-LLaVA: Bridging Image-level, Object-level, Pixel-level Reasoning and Understanding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19389v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19389v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9015"
  },
  {
    "objectID": "posts/Real_Time_Anomaly_Detection_and_Reactive_Planning_with_Large_Language_Models/2024-07-11-Real_Time_Anomaly_Detection_and_Reactive_Planning_with_Large_Language_Models.html",
    "href": "posts/Real_Time_Anomaly_Detection_and_Reactive_Planning_with_Large_Language_Models/2024-07-11-Real_Time_Anomaly_Detection_and_Reactive_Planning_with_Large_Language_Models.html",
    "title": "Real-Time Anomaly Detection and Reactive Planning with Large Language Models",
    "section": "",
    "text": "Summary:\nThis paper presents a two-stage reasoning framework for detecting and mitigating out-of-distribution failure modes in robotic systems using large language models (LLMs). The first stage is a fast binary anomaly classifier that analyzes observations in the LLM embedding space, which may trigger a slower fallback selection stage that utilizes the reasoning capabilities of generative LLMs. These stages correspond to branch points in a model predictive control strategy that maintains the joint feasibility of continuing along various fallback plans to account for the slow reasoner’s latency as soon as an anomaly is detected, ensuring safety. The fast anomaly classifier outperforms autoregressive reasoning with state-of-the-art GPT models, even when instantiated with relatively small language models. This enables the runtime monitor to improve the trustworthiness of dynamic robotic systems, such as quadrotors or autonomous vehicles, under resource and time constraints.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an innovative approach to detecting and mitigating out-of-distribution failure modes in robotic systems using large language models. The two-stage reasoning framework and the model predictive control strategy provide a promising solution to ensure safety in dynamic robotic systems. However, the paper does not provide a detailed analysis of the limitations and potential biases of the proposed approach. Additionally, the paper does not discuss the methodological issues, conflicting evidence, or areas that require further research or clarification. Further research is needed to evaluate the proposed approach in real-world scenarios and to address the potential limitations and biases of the approach."
  },
  {
    "objectID": "posts/Real_Time_Anomaly_Detection_and_Reactive_Planning_with_Large_Language_Models/2024-07-11-Real_Time_Anomaly_Detection_and_Reactive_Planning_with_Large_Language_Models.html#appendix",
    "href": "posts/Real_Time_Anomaly_Detection_and_Reactive_Planning_with_Large_Language_Models/2024-07-11-Real_Time_Anomaly_Detection_and_Reactive_Planning_with_Large_Language_Models.html#appendix",
    "title": "Real-Time Anomaly Detection and Reactive Planning with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08735v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08735v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18740"
  },
  {
    "objectID": "posts/Mental_Modeling_of_Reinforcement_Learning_Agents_by_Language_Models/2024-06-26-Mental_Modeling_of_Reinforcement_Learning_Agents_by_Language_Models.html#appendix",
    "href": "posts/Mental_Modeling_of_Reinforcement_Learning_Agents_by_Language_Models/2024-06-26-Mental_Modeling_of_Reinforcement_Learning_Agents_by_Language_Models.html#appendix",
    "title": "Mental Modeling of Reinforcement Learning Agents by Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18505v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18505v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9604"
  },
  {
    "objectID": "posts/Spider2_V_How_Far_Are_Multimodal_Agents_From_Automating_Data_Science_and_Engineering_Workflows/2024-07-15-Spider2_V_How_Far_Are_Multimodal_Agents_From_Automating_Data_Science_and_Engineering_Workflows.html",
    "href": "posts/Spider2_V_How_Far_Are_Multimodal_Agents_From_Automating_Data_Science_and_Engineering_Workflows/2024-07-15-Spider2_V_How_Far_Are_Multimodal_Agents_From_Automating_Data_Science_and_Engineering_Workflows.html",
    "title": "Spider2-V: How Far Are Multimodal Agents From Automating Data Science and Engineering Workflows?",
    "section": "",
    "text": "Summary:\nThe paper introduces Spider2-V, a multimodal agent benchmark that covers the entire data science and engineering workflow. It includes 494 real-world tasks in a real-time executable computer environment and 20 professional enterprise data software. The benchmark aims to evaluate a multimodal agent’s ability to perform professional data-related tasks by writing code and managing the GUI in enterprise data software systems. The tasks are derived from real-world practices and are supplemented with retrieval-augmented agents with official documentation and tutorials of these software systems. The benchmark is designed to balance realistic simulation with evaluation simplicity and features automatic configurations for task setup and customized evaluation metrics for each task.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a comprehensive and well-structured summary of the Spider2-V benchmark. The benchmark is a significant contribution to the field of data science and engineering, as it covers the entire data workflow and integrates visual interfaces. However, the paper does not provide a detailed analysis of the limitations or potential biases of the benchmark. It would be beneficial to include a more in-depth discussion of these aspects to provide a more balanced perspective on the benchmark’s strengths and weaknesses. Additionally, the paper could benefit from a more detailed comparison with other existing benchmarks in the field, highlighting the unique features and advantages of Spider2-V."
  },
  {
    "objectID": "posts/Spider2_V_How_Far_Are_Multimodal_Agents_From_Automating_Data_Science_and_Engineering_Workflows/2024-07-15-Spider2_V_How_Far_Are_Multimodal_Agents_From_Automating_Data_Science_and_Engineering_Workflows.html#appendix",
    "href": "posts/Spider2_V_How_Far_Are_Multimodal_Agents_From_Automating_Data_Science_and_Engineering_Workflows/2024-07-15-Spider2_V_How_Far_Are_Multimodal_Agents_From_Automating_Data_Science_and_Engineering_Workflows.html#appendix",
    "title": "Spider2-V: How Far Are Multimodal Agents From Automating Data Science and Engineering Workflows?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10956v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10956v1\n\n\nTruncated\nFalse\n\n\nWord Count\n25225"
  },
  {
    "objectID": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#major-findings",
    "href": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#major-findings",
    "title": "MolX: Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nMolX significantly improves the performance of LLMs on various molecule-related tasks, outperforming baselines on tasks such as molecule-to-text translation, retrosynthesis, and property prediction.\nMolX can act as a plug-in module to the LLM, enhancing its performance on molecule-related tasks while fully preserving its general-purpose usage on other domains.\nThe proposed method only introduces a small number of trainable parameters, making it an efficient solution for enhancing LLMs."
  },
  {
    "objectID": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#analysis-and-critique",
    "href": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#analysis-and-critique",
    "title": "MolX: Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper does not discuss the potential limitations of the MolX framework, such as its performance on more complex molecular structures or its ability to handle large-scale molecular datasets.\nThe paper does not provide a comparison with other multi-modal approaches for molecular learning, which could provide a more comprehensive evaluation of the proposed method.\nThe paper does not discuss the potential applications of MolX in other domains, such as drug discovery or materials science, which could provide additional insights into its potential impact.\nThe paper does not discuss the potential ethical implications of using LLMs for molecular learning, such as the potential for bias in the generated molecular structures or the potential for misuse in the development of harmful substances.\n\nOverall, the paper presents a promising approach for enhancing the ability of LLMs to comprehend molecules. However, further research is needed to fully evaluate its limitations, compare it with other approaches, and explore its potential applications and ethical implications."
  },
  {
    "objectID": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#appendix",
    "href": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#appendix",
    "title": "MolX: Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06777v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06777v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8694"
  },
  {
    "objectID": "posts/Probability_of_Differentiation_Reveals_Brittleness_of_Homogeneity_Bias_in_Large_Language_Models/2024-07-10-Probability_of_Differentiation_Reveals_Brittleness_of_Homogeneity_Bias_in_Large_Language_Models.html#appendix",
    "href": "posts/Probability_of_Differentiation_Reveals_Brittleness_of_Homogeneity_Bias_in_Large_Language_Models/2024-07-10-Probability_of_Differentiation_Reveals_Brittleness_of_Homogeneity_Bias_in_Large_Language_Models.html#appendix",
    "title": "Probability of Differentiation Reveals Brittleness of Homogeneity Bias in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07329v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07329v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6590"
  },
  {
    "objectID": "posts/Sub_SA_Strengthen_In_context_Learning_via_Submodular_Selective_Annotation/2024-07-08-Sub_SA_Strengthen_In_context_Learning_via_Submodular_Selective_Annotation.html#appendix",
    "href": "posts/Sub_SA_Strengthen_In_context_Learning_via_Submodular_Selective_Annotation/2024-07-08-Sub_SA_Strengthen_In_context_Learning_via_Submodular_Selective_Annotation.html#appendix",
    "title": "Sub-SA: Strengthen In-context Learning via Submodular Selective Annotation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05693v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05693v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6160"
  },
  {
    "objectID": "posts/Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue/2024-06-04-Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue.html",
    "href": "posts/Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue/2024-06-04-Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue.html",
    "title": "Position Debiasing Fine-Tuning for Causal Perception in Long-Term Dialogue",
    "section": "",
    "text": "Summary:\nThe paper proposes a novel method, Causal Perception long-term Dialogue framework (CPD), to alleviate the position bias in large language models (LLMs) for long-term dialogue tasks. The CPD framework employs perturbation-based causal variable discovery to extract causally relevant utterances from dialogue history and enhances the model’s causal perception during fine-tuning. The framework includes a local-position awareness method for inter-sentence position correlation elimination and a causal-perception fine-tuning strategy to improve the model’s ability to discover causal invariant factors. Experimental results on two datasets demonstrate that the proposed method effectively alleviates position bias and achieves significant progress compared to existing baselines.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a well-structured and coherent summary of the proposed CPD framework for addressing position bias in LLMs for long-term dialogue tasks. The use of perturbation-based causal variable discovery and the local-position awareness method are innovative approaches to extract causally relevant utterances from dialogue history. The causal-perception fine-tuning strategy also provides a promising direction for improving the model’s ability to discover causal invariant factors.\nHowever, the paper could benefit from a more detailed analysis of the limitations and potential biases of the proposed method. For instance, the paper does not discuss the potential impact of the perturbation-based approach on the model’s performance or the generalizability of the method to other types of dialogue tasks. Additionally, the paper could provide more insights into the potential challenges and trade-offs in implementing the proposed method in real-world applications.\nOverall, the paper presents a promising approach to addressing position bias in LLMs for long-term dialogue tasks. The proposed CPD framework and the experimental results provide valuable insights into the potential of perturbation-based causal variable discovery and causal-perception fine-t"
  },
  {
    "objectID": "posts/Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue/2024-06-04-Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue.html#appendix",
    "href": "posts/Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue/2024-06-04-Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue.html#appendix",
    "title": "Position Debiasing Fine-Tuning for Causal Perception in Long-Term Dialogue",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02002v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02002v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7030"
  },
  {
    "objectID": "posts/Towards_Large_Language_Model_Aided_Program_Refinement/2024-06-26-Towards_Large_Language_Model_Aided_Program_Refinement.html#appendix",
    "href": "posts/Towards_Large_Language_Model_Aided_Program_Refinement/2024-06-26-Towards_Large_Language_Model_Aided_Program_Refinement.html#appendix",
    "title": "Towards Large Language Model Aided Program Refinement",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18616v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18616v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5456"
  },
  {
    "objectID": "posts/Predicting_the_Big_Five_Personality_Traits_in_Chinese_Counselling_Dialogues_Using_Large_Language_Models/2024-06-25-Predicting_the_Big_Five_Personality_Traits_in_Chinese_Counselling_Dialogues_Using_Large_Language_Models.html#appendix",
    "href": "posts/Predicting_the_Big_Five_Personality_Traits_in_Chinese_Counselling_Dialogues_Using_Large_Language_Models/2024-06-25-Predicting_the_Big_Five_Personality_Traits_in_Chinese_Counselling_Dialogues_Using_Large_Language_Models.html#appendix",
    "title": "Predicting the Big Five Personality Traits in Chinese Counselling Dialogues Using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17287v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17287v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10813"
  },
  {
    "objectID": "posts/Is_ChatGPT_a_Better_Explainer_than_My_Professor_Evaluating_the_Explanation_Capabilities_of_LLMs_in_Conversation_Compared_to_a_Human_Baseline/2024-06-26-Is_ChatGPT_a_Better_Explainer_than_My_Professor_Evaluating_the_Explanation_Capabilities_of_LLMs_in_Conversation_Compared_to_a_Human_Baseline.html#appendix",
    "href": "posts/Is_ChatGPT_a_Better_Explainer_than_My_Professor_Evaluating_the_Explanation_Capabilities_of_LLMs_in_Conversation_Compared_to_a_Human_Baseline/2024-06-26-Is_ChatGPT_a_Better_Explainer_than_My_Professor_Evaluating_the_Explanation_Capabilities_of_LLMs_in_Conversation_Compared_to_a_Human_Baseline.html#appendix",
    "title": "Is ChatGPT a Better Explainer than My Professor?: Evaluating the Explanation Capabilities of LLMs in Conversation Compared to a Human Baseline",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18512v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18512v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4167"
  },
  {
    "objectID": "posts/Adversarial_Attacks_on_Large_Language_Models_in_Medicine/2024-06-18-Adversarial_Attacks_on_Large_Language_Models_in_Medicine.html#appendix",
    "href": "posts/Adversarial_Attacks_on_Large_Language_Models_in_Medicine/2024-06-18-Adversarial_Attacks_on_Large_Language_Models_in_Medicine.html#appendix",
    "title": "Adversarial Attacks on Large Language Models in Medicine",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12259v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12259v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9477"
  },
  {
    "objectID": "posts/Efficient_Training_of_Large_Language_Models_on_Distributed_Infrastructures_A_Survey/2024-07-29-Efficient_Training_of_Large_Language_Models_on_Distributed_Infrastructures_A_Survey.html",
    "href": "posts/Efficient_Training_of_Large_Language_Models_on_Distributed_Infrastructures_A_Survey/2024-07-29-Efficient_Training_of_Large_Language_Models_on_Distributed_Infrastructures_A_Survey.html",
    "title": "Efficient Training of Large Language Models on Distributed Infrastructures: A Survey",
    "section": "",
    "text": "Summary:\nThe paper provides a comprehensive overview of the challenges and advancements in training large language models (LLMs) on distributed infrastructures. It discusses various AI accelerators, network infrastructure, resource scheduling, and parallelism schemes for LLM training. The paper also covers heterogeneity in LLM training, low-bit fixed point training, memory optimization techniques, in-network aggregation, and checkpoint-free recovery methods. The survey aims to provide insights into improving LLM training systems and tackling ongoing challenges, such as scalability, efficiency, and reliability.\nKey Terms:\n**Major"
  },
  {
    "objectID": "posts/Efficient_Training_of_Large_Language_Models_on_Distributed_Infrastructures_A_Survey/2024-07-29-Efficient_Training_of_Large_Language_Models_on_Distributed_Infrastructures_A_Survey.html#appendix",
    "href": "posts/Efficient_Training_of_Large_Language_Models_on_Distributed_Infrastructures_A_Survey/2024-07-29-Efficient_Training_of_Large_Language_Models_on_Distributed_Infrastructures_A_Survey.html#appendix",
    "title": "Efficient Training of Large Language Models on Distributed Infrastructures: A Survey",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20018v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20018v1\n\n\nTruncated\nTrue\n\n\nWord Count\n37218"
  },
  {
    "objectID": "posts/Security_Vulnerability_Detection_with_Multitask_Self_Instructed_Fine_Tuning_of_Large_Language_Models/2024-06-09-Security_Vulnerability_Detection_with_Multitask_Self_Instructed_Fine_Tuning_of_Large_Language_Models.html#appendix",
    "href": "posts/Security_Vulnerability_Detection_with_Multitask_Self_Instructed_Fine_Tuning_of_Large_Language_Models/2024-06-09-Security_Vulnerability_Detection_with_Multitask_Self_Instructed_Fine_Tuning_of_Large_Language_Models.html#appendix",
    "title": "Security Vulnerability Detection with Multitask Self-Instructed Fine-Tuning of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05892v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05892v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10513"
  },
  {
    "objectID": "posts/Buffer_of_Thoughts_Thought_Augmented_Reasoning_with_Large_Language_Models/2024-06-06-Buffer_of_Thoughts_Thought_Augmented_Reasoning_with_Large_Language_Models.html#appendix",
    "href": "posts/Buffer_of_Thoughts_Thought_Augmented_Reasoning_with_Large_Language_Models/2024-06-06-Buffer_of_Thoughts_Thought_Augmented_Reasoning_with_Large_Language_Models.html#appendix",
    "title": "Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04271v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04271v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6204"
  },
  {
    "objectID": "posts/Verbalized_Machine_Learning_Revisiting_Machine_Learning_with_Language_Models/2024-06-06-Verbalized_Machine_Learning_Revisiting_Machine_Learning_with_Language_Models.html#appendix",
    "href": "posts/Verbalized_Machine_Learning_Revisiting_Machine_Learning_with_Language_Models/2024-06-06-Verbalized_Machine_Learning_Revisiting_Machine_Learning_with_Language_Models.html#appendix",
    "title": "Verbalized Machine Learning: Revisiting Machine Learning with Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04344v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04344v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10781"
  },
  {
    "objectID": "posts/Behavioral_Testing_Can_Large_Language_Models_Implicitly_Resolve_Ambiguous_Entities/2024-07-25-Behavioral_Testing_Can_Large_Language_Models_Implicitly_Resolve_Ambiguous_Entities.html#appendix",
    "href": "posts/Behavioral_Testing_Can_Large_Language_Models_Implicitly_Resolve_Ambiguous_Entities/2024-07-25-Behavioral_Testing_Can_Large_Language_Models_Implicitly_Resolve_Ambiguous_Entities.html#appendix",
    "title": "Behavioral Testing: Can Large Language Models Implicitly Resolve Ambiguous Entities?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17125v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17125v2\n\n\nTruncated\nFalse\n\n\nWord Count\n7094"
  },
  {
    "objectID": "posts/A_Comprehensive_Evaluation_of_Parameter_Efficient_Fine_Tuning_on_Automated_Program_Repair/2024-06-09-A_Comprehensive_Evaluation_of_Parameter_Efficient_Fine_Tuning_on_Automated_Program_Repair.html#appendix",
    "href": "posts/A_Comprehensive_Evaluation_of_Parameter_Efficient_Fine_Tuning_on_Automated_Program_Repair/2024-06-09-A_Comprehensive_Evaluation_of_Parameter_Efficient_Fine_Tuning_on_Automated_Program_Repair.html#appendix",
    "title": "A Comprehensive Evaluation of Parameter-Efficient Fine-Tuning on Automated Program Repair",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05639v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05639v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12423"
  },
  {
    "objectID": "posts/ReCaLL_Membership_Inference_via_Relative_Conditional_Log_Likelihoods/2024-06-23-ReCaLL_Membership_Inference_via_Relative_Conditional_Log_Likelihoods.html#appendix",
    "href": "posts/ReCaLL_Membership_Inference_via_Relative_Conditional_Log_Likelihoods/2024-06-23-ReCaLL_Membership_Inference_via_Relative_Conditional_Log_Likelihoods.html#appendix",
    "title": "ReCaLL: Membership Inference via Relative Conditional Log-Likelihoods",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.15968v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.15968v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8640"
  },
  {
    "objectID": "posts/JailbreakHunter_A_Visual_Analytics_Approach_for_Jailbreak_Prompts_Discovery_from_Large_Scale_Human_LLM_Conversational_Datasets/2024-07-03-JailbreakHunter_A_Visual_Analytics_Approach_for_Jailbreak_Prompts_Discovery_from_Large_Scale_Human_LLM_Conversational_Datasets.html#appendix",
    "href": "posts/JailbreakHunter_A_Visual_Analytics_Approach_for_Jailbreak_Prompts_Discovery_from_Large_Scale_Human_LLM_Conversational_Datasets/2024-07-03-JailbreakHunter_A_Visual_Analytics_Approach_for_Jailbreak_Prompts_Discovery_from_Large_Scale_Human_LLM_Conversational_Datasets.html#appendix",
    "title": "JailbreakHunter: A Visual Analytics Approach for Jailbreak Prompts Discovery from Large-Scale Human-LLM Conversational Datasets",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03045v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03045v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13931"
  },
  {
    "objectID": "posts/MindSearch_Mimicking_Human_Minds_Elicits_Deep_AI_Searcher/2024-07-29-MindSearch_Mimicking_Human_Minds_Elicits_Deep_AI_Searcher.html#appendix",
    "href": "posts/MindSearch_Mimicking_Human_Minds_Elicits_Deep_AI_Searcher/2024-07-29-MindSearch_Mimicking_Human_Minds_Elicits_Deep_AI_Searcher.html#appendix",
    "title": "MindSearch: Mimicking Human Minds Elicits Deep AI Searcher",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20183v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20183v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5127"
  },
  {
    "objectID": "posts/Jailbreaking_as_a_Reward_Misspecification_Problem/2024-06-20-Jailbreaking_as_a_Reward_Misspecification_Problem.html#appendix",
    "href": "posts/Jailbreaking_as_a_Reward_Misspecification_Problem/2024-06-20-Jailbreaking_as_a_Reward_Misspecification_Problem.html#appendix",
    "title": "Jailbreaking as a Reward Misspecification Problem",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14393v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14393v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7548"
  },
  {
    "objectID": "posts/Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models/2024-07-08-Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models.html#major-findings",
    "href": "posts/Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models/2024-07-08-Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models.html#major-findings",
    "title": "Merge, Ensemble, and Cooperate! A Survey on Collaborative Strategies in the Era of Large Language Models",
    "section": "Major Findings",
    "text": "Major Findings\n\nMerging: This approach integrates the parameters of multiple LLMs into a single, unified model, requiring that the parameters are compatible within a linear space. Merging methods are tailored to be more suitable for LLMs, effectively leveraging the collaborative advantages of diverse LLMs.\nEnsemble: Ensemble methods focus on combining the outputs generated by various LLMs to produce coherent results, with less emphasis on the parameters of the individual models. These methods are derived from traditional fusion techniques commonly explored in machine learning.\nCooperation: Cooperation extends beyond merging and ensemble, focusing on cooperative methods that harness the diverse strengths of LLMs to achieve specific objectives. These techniques expand the methodologies for model collaboration, holding significant research importance for LLMs."
  },
  {
    "objectID": "posts/Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models/2024-07-08-Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models/2024-07-08-Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models.html#analysis-and-critique",
    "title": "Merge, Ensemble, and Cooperate! A Survey on Collaborative Strategies in the Era of Large Language Models",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\nThe paper provides a well-structured and coherent summary of the emerging research area of collaboration strategies for LLMs. The authors’ categorization of these strategies into Merging, Ensemble, and Cooperation offers a clear understanding of their respective frameworks and applications.\nHowever, the paper does not discuss the potential limitations, unanswered questions, or biases that may be apparent while reviewing the text. Additionally, the paper does not address any methodological issues, conflicting evidence, or areas that require further research or clarification.\nIn conclusion, the paper serves as a valuable resource for understanding the strategies and methodologies for collaborative efforts among LLMs. However, it would benefit from a more critical analysis of the discussed topics, addressing potential limitations and areas for further research."
  },
  {
    "objectID": "posts/Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models/2024-07-08-Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models.html#appendix",
    "href": "posts/Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models/2024-07-08-Merge_Ensemble_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models.html#appendix",
    "title": "Merge, Ensemble, and Cooperate! A Survey on Collaborative Strategies in the Era of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06089v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06089v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14228"
  },
  {
    "objectID": "posts/Language_models_are_robotic_planners_reframing_plans_as_goal_refinement_graphs/2024-07-22-Language_models_are_robotic_planners_reframing_plans_as_goal_refinement_graphs.html#appendix",
    "href": "posts/Language_models_are_robotic_planners_reframing_plans_as_goal_refinement_graphs/2024-07-22-Language_models_are_robotic_planners_reframing_plans_as_goal_refinement_graphs.html#appendix",
    "title": "Language models are robotic planners: reframing plans as goal refinement graphs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.15677v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.15677v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5999"
  },
  {
    "objectID": "posts/FreeTraj_Tuning_Free_Trajectory_Control_in_Video_Diffusion_Models/2024-06-24-FreeTraj_Tuning_Free_Trajectory_Control_in_Video_Diffusion_Models.html#appendix",
    "href": "posts/FreeTraj_Tuning_Free_Trajectory_Control_in_Video_Diffusion_Models/2024-06-24-FreeTraj_Tuning_Free_Trajectory_Control_in_Video_Diffusion_Models.html#appendix",
    "title": "FreeTraj: Tuning-Free Trajectory Control in Video Diffusion Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16863v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16863v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8202"
  },
  {
    "objectID": "posts/The_Dark_Side_of_Function_Calling_Pathways_to_Jailbreaking_Large_Language_Models/2024-07-25-The_Dark_Side_of_Function_Calling_Pathways_to_Jailbreaking_Large_Language_Models.html#appendix",
    "href": "posts/The_Dark_Side_of_Function_Calling_Pathways_to_Jailbreaking_Large_Language_Models/2024-07-25-The_Dark_Side_of_Function_Calling_Pathways_to_Jailbreaking_Large_Language_Models.html#appendix",
    "title": "The Dark Side of Function Calling: Pathways to Jailbreaking Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17915v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17915v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5067"
  },
  {
    "objectID": "posts/Semantically_Diverse_Language_Generation_for_Uncertainty_Estimation_in_Language_Models/2024-06-06-Semantically_Diverse_Language_Generation_for_Uncertainty_Estimation_in_Language_Models.html#appendix",
    "href": "posts/Semantically_Diverse_Language_Generation_for_Uncertainty_Estimation_in_Language_Models/2024-06-06-Semantically_Diverse_Language_Generation_for_Uncertainty_Estimation_in_Language_Models.html#appendix",
    "title": "Semantically Diverse Language Generation for Uncertainty Estimation in Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04306v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04306v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10058"
  },
  {
    "objectID": "posts/Advancing_Tool_Augmented_Large_Language_Models_Integrating_Insights_from_Errors_in_Inference_Trees/2024-06-11-Advancing_Tool_Augmented_Large_Language_Models_Integrating_Insights_from_Errors_in_Inference_Trees.html#appendix",
    "href": "posts/Advancing_Tool_Augmented_Large_Language_Models_Integrating_Insights_from_Errors_in_Inference_Trees/2024-06-11-Advancing_Tool_Augmented_Large_Language_Models_Integrating_Insights_from_Errors_in_Inference_Trees.html#appendix",
    "title": "Advancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07115v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07115v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6467"
  },
  {
    "objectID": "posts/Self_assessment_Exhibition_and_Recognition_a_Review_of_Personality_in_Large_Language_Models/2024-06-25-Self_assessment_Exhibition_and_Recognition_a_Review_of_Personality_in_Large_Language_Models.html#appendix",
    "href": "posts/Self_assessment_Exhibition_and_Recognition_a_Review_of_Personality_in_Large_Language_Models/2024-06-25-Self_assessment_Exhibition_and_Recognition_a_Review_of_Personality_in_Large_Language_Models.html#appendix",
    "title": "Self-assessment, Exhibition, and Recognition: a Review of Personality in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17624v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17624v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9841"
  },
  {
    "objectID": "posts/Rectifier_Code_Translation_with_Corrector_via_LLMs/2024-07-10-Rectifier_Code_Translation_with_Corrector_via_LLMs.html#appendix",
    "href": "posts/Rectifier_Code_Translation_with_Corrector_via_LLMs/2024-07-10-Rectifier_Code_Translation_with_Corrector_via_LLMs.html#appendix",
    "title": "Rectifier: Code Translation with Corrector via LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07472v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07472v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11178"
  },
  {
    "objectID": "posts/An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics/2024-06-10-An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics.html",
    "href": "posts/An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics/2024-06-10-An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics.html",
    "title": "An Empirical Design Justice Approach to Identifying Ethical Considerations in the Intersection of Large Language Models and Social Robotics",
    "section": "",
    "text": "Summary:\nThe integration of Large Language Models (LLMs) in social robotics presents a unique set of ethical challenges and social impacts. This research aims to identify ethical considerations that arise in the design and development of these two technologies in combination. Using LLMs for social robotics may provide benefits, such as enabling natural language open-domain dialogues. However, the intersection of these two technologies also gives rise to ethical concerns related to misinformation, non-verbal cues, emotional disruption, and biases. The robot’s physical social embodiment adds complexity, as ethical hazards associated with LLM-based Social AI, such as hallucinations and misinformation, can be exacerbated due to the effects of physical embodiment on social perception and communication. To address these challenges, this study employs an empirical design justice-based methodology, focusing on identifying socio-technical ethical considerations through a qualitative co-design and interaction study. The purpose of the study is to identify ethical considerations relevant to the process of co-design of, and interaction with a humanoid social robot as the interface of a LLM, and to evaluate how a design justice methodology can be used in the context of designing LLMs-based social robotics.\nMajor Findings:\nAnalysis and Critique:\nThe study presents a novel methodological approach based on previous work on design justice in AI and HRI. The approach enables the identification and validation of ethical concerns through empirical design justice-based data from diverse participants. However, the study also highlights limitations, such as the inability to confidently determine ethical considerations in"
  },
  {
    "objectID": "posts/An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics/2024-06-10-An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics.html#appendix",
    "href": "posts/An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics/2024-06-10-An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics.html#appendix",
    "title": "An Empirical Design Justice Approach to Identifying Ethical Considerations in the Intersection of Large Language Models and Social Robotics",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06400v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06400v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14471"
  },
  {
    "objectID": "posts/HyCIR_Boosting_Zero_Shot_Composed_Image_Retrieval_with_Synthetic_Labels/2024-07-08-HyCIR_Boosting_Zero_Shot_Composed_Image_Retrieval_with_Synthetic_Labels.html#appendix",
    "href": "posts/HyCIR_Boosting_Zero_Shot_Composed_Image_Retrieval_with_Synthetic_Labels/2024-07-08-HyCIR_Boosting_Zero_Shot_Composed_Image_Retrieval_with_Synthetic_Labels.html#appendix",
    "title": "HyCIR: Boosting Zero-Shot Composed Image Retrieval with Synthetic Labels",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05795v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05795v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10950"
  },
  {
    "objectID": "posts/DiVERT_Distractor_Generation_with_Variational_Errors_Represented_as_Text_for_Math_Multiple_choice_Questions/2024-06-27-DiVERT_Distractor_Generation_with_Variational_Errors_Represented_as_Text_for_Math_Multiple_choice_Questions.html#appendix",
    "href": "posts/DiVERT_Distractor_Generation_with_Variational_Errors_Represented_as_Text_for_Math_Multiple_choice_Questions/2024-06-27-DiVERT_Distractor_Generation_with_Variational_Errors_Represented_as_Text_for_Math_Multiple_choice_Questions.html#appendix",
    "title": "DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.19356v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.19356v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9499"
  },
  {
    "objectID": "posts/Is_the_Digital_Forensics_and_Incident_Response_Pipeline_Ready_for_Text_Based_Threats_in_LLM_Era/2024-07-25-Is_the_Digital_Forensics_and_Incident_Response_Pipeline_Ready_for_Text_Based_Threats_in_LLM_Era.html#appendix",
    "href": "posts/Is_the_Digital_Forensics_and_Incident_Response_Pipeline_Ready_for_Text_Based_Threats_in_LLM_Era/2024-07-25-Is_the_Digital_Forensics_and_Incident_Response_Pipeline_Ready_for_Text_Based_Threats_in_LLM_Era.html#appendix",
    "title": "Is the Digital Forensics and Incident Response Pipeline Ready for Text-Based Threats in LLM Era?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17870v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17870v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4669"
  },
  {
    "objectID": "posts/Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias/2024-07-08-Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias.html",
    "href": "posts/Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias/2024-07-08-Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias.html",
    "title": "Do Multilingual Large Language Models Mitigate Stereotype Bias?",
    "section": "",
    "text": "Summary: This paper investigates the impact of multilingual training on bias mitigation in large language models (LLMs). The authors train six LLMs of identical size (2.6B parameters) and architecture, including five monolingual models (English, German, French, Italian, and Spanish) and one multilingual model. The models are evaluated on standard bias benchmarks, which are automatically translated and verified for both translation quality and bias preservation. The results show that multilingual training effectively mitigates bias, and multilingual models achieve not only lower bias but also superior prediction accuracy compared to monolingual models with the same amount of training data, model architecture, and size.\nMajor Findings: 1. Multilingual training effectively mitigates bias in LLMs. 2. Multilingual models achieve lower bias than monolingual models with the same amount of training data, model architecture, and size. 3. Multilingual models outperform monolingual models in prediction accuracy.\nAnalysis and Critique: The paper presents a well-structured and coherent summary of the research, providing a clear overview of the methodology and findings. The use of a controlled setting and the evaluation of both bias and prediction accuracy are strengths of the study. However, the paper does not discuss potential limitations or shortcomings of the research, such as the generalizability of the findings to other languages or the impact of different translation methods on the results. Additionally, the paper does not address the potential for biases to be introduced during the translation process, which could affect the validity of the results. Further research is needed to explore these issues and to validate the findings in other contexts."
  },
  {
    "objectID": "posts/Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias/2024-07-08-Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias.html#appendix",
    "href": "posts/Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias/2024-07-08-Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias.html#appendix",
    "title": "Do Multilingual Large Language Models Mitigate Stereotype Bias?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05740v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05740v1\n\n\nTruncated\nFalse\n\n\nWord Count\n21234"
  },
  {
    "objectID": "posts/The_Career_Interests_of_Large_Language_Models/2024-07-11-The_Career_Interests_of_Large_Language_Models.html#appendix",
    "href": "posts/The_Career_Interests_of_Large_Language_Models/2024-07-11-The_Career_Interests_of_Large_Language_Models.html#appendix",
    "title": "The Career Interests of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08564v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08564v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8543"
  },
  {
    "objectID": "posts/Jailbreaking_LLMs_with_Arabic_Transliteration_and_Arabizi/2024-06-26-Jailbreaking_LLMs_with_Arabic_Transliteration_and_Arabizi.html#appendix",
    "href": "posts/Jailbreaking_LLMs_with_Arabic_Transliteration_and_Arabizi/2024-06-26-Jailbreaking_LLMs_with_Arabic_Transliteration_and_Arabizi.html#appendix",
    "title": "Jailbreaking LLMs with Arabic Transliteration and Arabizi",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18725v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18725v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8377"
  },
  {
    "objectID": "posts/RES_Q_Evaluating_Code_Editing_Large_Language_Model_Systems_at_the_Repository_Scale/2024-06-24-RES_Q_Evaluating_Code_Editing_Large_Language_Model_Systems_at_the_Repository_Scale.html#appendix",
    "href": "posts/RES_Q_Evaluating_Code_Editing_Large_Language_Model_Systems_at_the_Repository_Scale/2024-06-24-RES_Q_Evaluating_Code_Editing_Large_Language_Model_Systems_at_the_Repository_Scale.html#appendix",
    "title": "RES-Q: Evaluating Code-Editing Large Language Model Systems at the Repository Scale",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16801v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16801v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3509"
  },
  {
    "objectID": "posts/Beyond_Generative_Artificial_Intelligence_Roadmap_for_Natural_Language_Generation/2024-07-15-Beyond_Generative_Artificial_Intelligence_Roadmap_for_Natural_Language_Generation.html",
    "href": "posts/Beyond_Generative_Artificial_Intelligence_Roadmap_for_Natural_Language_Generation/2024-07-15-Beyond_Generative_Artificial_Intelligence_Roadmap_for_Natural_Language_Generation.html",
    "title": "Beyond Generative Artificial Intelligence: Roadmap for Natural Language Generation",
    "section": "",
    "text": "Summary:\nThis paper conducts a review of a representative sample of surveys recently published in Natural Language Generation (NLG) to provide a research roadmap for the scientific community. The goal is to identify which NLG aspects are not suitably addressed by Large Language Models (LLMs) and suggest future lines of research. The paper discusses the evolution of NLG, from modular architectures to global approaches, and the current focus on developing larger LLMs. However, these models still lack precision and have problems generating texts faithfully like humans. The paper also highlights the need for further contextual knowledge and information modalities to improve LLM performance in more demanding tasks.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive review of recent surveys in NLG and identifies key research gaps that need to be addressed. However, the paper does not discuss the methodology used to select the surveys or the criteria for inclusion. Additionally, the paper does not provide a detailed analysis of the limitations of the reviewed surveys or the potential biases in their findings. The paper also does not discuss the potential impact of the identified research gaps on the development of NLG systems or the implications for the broader field of AI. Overall, the paper provides a valuable contribution to the field of NLG by highlight"
  },
  {
    "objectID": "posts/Beyond_Generative_Artificial_Intelligence_Roadmap_for_Natural_Language_Generation/2024-07-15-Beyond_Generative_Artificial_Intelligence_Roadmap_for_Natural_Language_Generation.html#appendix",
    "href": "posts/Beyond_Generative_Artificial_Intelligence_Roadmap_for_Natural_Language_Generation/2024-07-15-Beyond_Generative_Artificial_Intelligence_Roadmap_for_Natural_Language_Generation.html#appendix",
    "title": "Beyond Generative Artificial Intelligence: Roadmap for Natural Language Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10554v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10554v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8979"
  },
  {
    "objectID": "posts/A_Comparative_Study_of_DSL_Code_Generation_Fine_Tuning_vs._Optimized_Retrieval_Augmentation/2024-07-03-A_Comparative_Study_of_DSL_Code_Generation_Fine_Tuning_vs._Optimized_Retrieval_Augmentation.html#appendix",
    "href": "posts/A_Comparative_Study_of_DSL_Code_Generation_Fine_Tuning_vs._Optimized_Retrieval_Augmentation/2024-07-03-A_Comparative_Study_of_DSL_Code_Generation_Fine_Tuning_vs._Optimized_Retrieval_Augmentation.html#appendix",
    "title": "A Comparative Study of DSL Code Generation: Fine-Tuning vs. Optimized Retrieval Augmentation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.02742v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.02742v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6386"
  },
  {
    "objectID": "posts/Virtual_Agents_for_Alcohol_Use_Counseling_Exploring_LLM_Powered_Motivational_Interviewing/2024-07-10-Virtual_Agents_for_Alcohol_Use_Counseling_Exploring_LLM_Powered_Motivational_Interviewing.html#major-findings",
    "href": "posts/Virtual_Agents_for_Alcohol_Use_Counseling_Exploring_LLM_Powered_Motivational_Interviewing/2024-07-10-Virtual_Agents_for_Alcohol_Use_Counseling_Exploring_LLM_Powered_Motivational_Interviewing.html#major-findings",
    "title": "Virtual Agents for Alcohol Use Counseling: Exploring LLM-Powered Motivational Interviewing",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nLLM-powered virtual agents match human counselors’ empathetic and adaptive conversational skills, presenting a significant step forward in virtual health counseling.\nThe LLM-powered virtual agent demonstrates the ability to effectively use elements of MI to facilitate behavior change.\nFrom a clinical perspective, LLM-powered virtual agents provide conversational quality that surpasses therapeutic thresholds for MI competence."
  },
  {
    "objectID": "posts/Virtual_Agents_for_Alcohol_Use_Counseling_Exploring_LLM_Powered_Motivational_Interviewing/2024-07-10-Virtual_Agents_for_Alcohol_Use_Counseling_Exploring_LLM_Powered_Motivational_Interviewing.html#analysis-and-critique",
    "href": "posts/Virtual_Agents_for_Alcohol_Use_Counseling_Exploring_LLM_Powered_Motivational_Interviewing/2024-07-10-Virtual_Agents_for_Alcohol_Use_Counseling_Exploring_LLM_Powered_Motivational_Interviewing.html#analysis-and-critique",
    "title": "Virtual Agents for Alcohol Use Counseling: Exploring LLM-Powered Motivational Interviewing",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe study’s findings suggest that LLMs have the potential to support complex counseling tasks across various health contexts.\nHowever, the study’s limitations include the small convenience samples used and the potential for LLMs to have seen and memorized data from the Anno-MI dataset.\nFuture research should focus on refining LLMs’ capabilities, such as developing prompting strategies for greater personalization and knowledge integration, enhancing the interface with multi-modal communication features, and addressing safety concerns before LLMs can be used to provide health advice directly to patients without oversight.\n\nOverall, the article presents a promising approach to addressing the global burden of health problems, including mental health disorders and substance abuse, by leveraging the capabilities of LLMs in virtual counseling. However, further research is needed to address the limitations and concerns raised in the study."
  },
  {
    "objectID": "posts/Virtual_Agents_for_Alcohol_Use_Counseling_Exploring_LLM_Powered_Motivational_Interviewing/2024-07-10-Virtual_Agents_for_Alcohol_Use_Counseling_Exploring_LLM_Powered_Motivational_Interviewing.html#appendix",
    "href": "posts/Virtual_Agents_for_Alcohol_Use_Counseling_Exploring_LLM_Powered_Motivational_Interviewing/2024-07-10-Virtual_Agents_for_Alcohol_Use_Counseling_Exploring_LLM_Powered_Motivational_Interviewing.html#appendix",
    "title": "Virtual Agents for Alcohol Use Counseling: Exploring LLM-Powered Motivational Interviewing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08095v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08095v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10434"
  },
  {
    "objectID": "posts/AMONGAGENTS_Evaluating_Large_Language_Models_in_the_Interactive_Text_Based_Social_Deduction_Game/2024-07-24-AMONGAGENTS_Evaluating_Large_Language_Models_in_the_Interactive_Text_Based_Social_Deduction_Game.html#appendix",
    "href": "posts/AMONGAGENTS_Evaluating_Large_Language_Models_in_the_Interactive_Text_Based_Social_Deduction_Game/2024-07-24-AMONGAGENTS_Evaluating_Large_Language_Models_in_the_Interactive_Text_Based_Social_Deduction_Game.html#appendix",
    "title": "AMONGAGENTS: Evaluating Large Language Models in the Interactive Text-Based Social Deduction Game",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16521v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16521v2\n\n\nTruncated\nFalse\n\n\nWord Count\n8569"
  },
  {
    "objectID": "posts/MMM_Multilingual_Mutual_Reinforcement_Effect_Mix_Datasets__Test_with_Open_domain_Information_Extraction_Large_Language_Models/2024-07-15-MMM_Multilingual_Mutual_Reinforcement_Effect_Mix_Datasets__Test_with_Open_domain_Information_Extraction_Large_Language_Models.html#appendix",
    "href": "posts/MMM_Multilingual_Mutual_Reinforcement_Effect_Mix_Datasets__Test_with_Open_domain_Information_Extraction_Large_Language_Models/2024-07-15-MMM_Multilingual_Mutual_Reinforcement_Effect_Mix_Datasets__Test_with_Open_domain_Information_Extraction_Large_Language_Models.html#appendix",
    "title": "MMM: Multilingual Mutual Reinforcement Effect Mix Datasets & Test with Open-domain Information Extraction Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10953v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10953v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5622"
  },
  {
    "objectID": "posts/Fine_tuned_network_relies_on_generic_representation_to_solve_unseen_cognitive_task/2024-06-27-Fine_tuned_network_relies_on_generic_representation_to_solve_unseen_cognitive_task.html#appendix",
    "href": "posts/Fine_tuned_network_relies_on_generic_representation_to_solve_unseen_cognitive_task/2024-06-27-Fine_tuned_network_relies_on_generic_representation_to_solve_unseen_cognitive_task.html#appendix",
    "title": "Fine-tuned network relies on generic representation to solve unseen cognitive task",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18926v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18926v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4648"
  },
  {
    "objectID": "posts/Exploring_Changes_in_Nation_Perception_with_Nationality_Assigned_Personas_in_LLMs/2024-06-20-Exploring_Changes_in_Nation_Perception_with_Nationality_Assigned_Personas_in_LLMs.html#appendix",
    "href": "posts/Exploring_Changes_in_Nation_Perception_with_Nationality_Assigned_Personas_in_LLMs/2024-06-20-Exploring_Changes_in_Nation_Perception_with_Nationality_Assigned_Personas_in_LLMs.html#appendix",
    "title": "Exploring Changes in Nation Perception with Nationality-Assigned Personas in LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13993v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13993v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4062"
  },
  {
    "objectID": "posts/POEM_Interactive_Prompt_Optimization_for_Enhancing_Multimodal_Reasoning_of_Large_Language_Models/2024-06-06-POEM_Interactive_Prompt_Optimization_for_Enhancing_Multimodal_Reasoning_of_Large_Language_Models.html#appendix",
    "href": "posts/POEM_Interactive_Prompt_Optimization_for_Enhancing_Multimodal_Reasoning_of_Large_Language_Models/2024-06-06-POEM_Interactive_Prompt_Optimization_for_Enhancing_Multimodal_Reasoning_of_Large_Language_Models.html#appendix",
    "title": "POEM: Interactive Prompt Optimization for Enhancing Multimodal Reasoning of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03843v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03843v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12924"
  },
  {
    "objectID": "posts/A_Three_Pronged_Approach_to_Cross_Lingual_Adaptation_with_Multilingual_LLMs/2024-06-25-A_Three_Pronged_Approach_to_Cross_Lingual_Adaptation_with_Multilingual_LLMs.html#appendix",
    "href": "posts/A_Three_Pronged_Approach_to_Cross_Lingual_Adaptation_with_Multilingual_LLMs/2024-06-25-A_Three_Pronged_Approach_to_Cross_Lingual_Adaptation_with_Multilingual_LLMs.html#appendix",
    "title": "A Three-Pronged Approach to Cross-Lingual Adaptation with Multilingual LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17377v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17377v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6250"
  },
  {
    "objectID": "posts/Disce_aut_Deficere_Evaluating_LLMs_Proficiency_on_the_INVALSI_Italian_Benchmark/2024-06-25-Disce_aut_Deficere_Evaluating_LLMs_Proficiency_on_the_INVALSI_Italian_Benchmark.html#appendix",
    "href": "posts/Disce_aut_Deficere_Evaluating_LLMs_Proficiency_on_the_INVALSI_Italian_Benchmark/2024-06-25-Disce_aut_Deficere_Evaluating_LLMs_Proficiency_on_the_INVALSI_Italian_Benchmark.html#appendix",
    "title": "Disce aut Deficere: Evaluating LLMs Proficiency on the INVALSI Italian Benchmark",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17535v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17535v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8268"
  },
  {
    "objectID": "posts/RB_SQL_A_Retrieval_based_LLM_Framework_for_Text_to_SQL/2024-07-11-RB_SQL_A_Retrieval_based_LLM_Framework_for_Text_to_SQL.html#appendix",
    "href": "posts/RB_SQL_A_Retrieval_based_LLM_Framework_for_Text_to_SQL/2024-07-11-RB_SQL_A_Retrieval_based_LLM_Framework_for_Text_to_SQL.html#appendix",
    "title": "RB-SQL: A Retrieval-based LLM Framework for Text-to-SQL",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08273v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08273v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7686"
  },
  {
    "objectID": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#major-findings",
    "href": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#major-findings",
    "title": "McEval: Massively Multilingual Code Evaluation",
    "section": "Major Findings",
    "text": "Major Findings\n\nMcEval is the first massively multilingual code evaluation benchmark, covering 40 programming languages with 16K test samples.\nThe benchmark includes challenging code completion, understanding, and generation evaluation tasks with finely curated multilingual instruction corpora McEval-Instruct.\nThe authors introduce an effective multilingual coder mCoder trained on McEval-Instruct to support multilingual programming language generation."
  },
  {
    "objectID": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#analysis-and-critique",
    "href": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#analysis-and-critique",
    "title": "McEval: Massively Multilingual Code Evaluation",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\n\nThe paper does not provide a detailed comparison of McEval with existing benchmarks, making it difficult to assess its advantages and limitations.\nThe paper does not discuss the potential biases in the data used for training mCoder, which could impact its performance on certain tasks or languages.\nThe paper does not provide a detailed analysis of the performance of mCoder on different tasks and languages, making it difficult to assess its strengths and weaknesses.\nThe paper does not discuss the potential applications of McEval and mCoder in real-world software development scenarios.\nThe paper does not discuss the potential ethical implications of using mCoder for code generation, such as the risk of generating code that violates software licenses or copyright laws."
  },
  {
    "objectID": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#appendix",
    "href": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#appendix",
    "title": "McEval: Massively Multilingual Code Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07436v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07436v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7788"
  },
  {
    "objectID": "posts/Reinforced_Prompt_Personalization_for_Recommendation_with_Large_Language_Models/2024-07-24-Reinforced_Prompt_Personalization_for_Recommendation_with_Large_Language_Models.html#appendix",
    "href": "posts/Reinforced_Prompt_Personalization_for_Recommendation_with_Large_Language_Models/2024-07-24-Reinforced_Prompt_Personalization_for_Recommendation_with_Large_Language_Models.html#appendix",
    "title": "Reinforced Prompt Personalization for Recommendation with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17115v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17115v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11227"
  },
  {
    "objectID": "posts/LLMCloudHunter_Harnessing_LLMs_for_Automated_Extraction_of_Detection_Rules_from_Cloud_Based_CTI/2024-07-06-LLMCloudHunter_Harnessing_LLMs_for_Automated_Extraction_of_Detection_Rules_from_Cloud_Based_CTI.html#appendix",
    "href": "posts/LLMCloudHunter_Harnessing_LLMs_for_Automated_Extraction_of_Detection_Rules_from_Cloud_Based_CTI/2024-07-06-LLMCloudHunter_Harnessing_LLMs_for_Automated_Extraction_of_Detection_Rules_from_Cloud_Based_CTI.html#appendix",
    "title": "LLMCloudHunter: Harnessing LLMs for Automated Extraction of Detection Rules from Cloud-Based CTI",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05194v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05194v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11552"
  },
  {
    "objectID": "posts/Confabulation_The_Surprising_Value_of_Large_Language_Model_Hallucinations/2024-06-06-Confabulation_The_Surprising_Value_of_Large_Language_Model_Hallucinations.html#appendix",
    "href": "posts/Confabulation_The_Surprising_Value_of_Large_Language_Model_Hallucinations/2024-06-06-Confabulation_The_Surprising_Value_of_Large_Language_Model_Hallucinations.html#appendix",
    "title": "Confabulation: The Surprising Value of Large Language Model Hallucinations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04175v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04175v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5509"
  },
  {
    "objectID": "posts/$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning/2024-07-08-$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning.html#summary-1",
    "href": "posts/$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning/2024-07-08-$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning.html#summary-1",
    "title": "\\(R^2\\)-Guard: Robust Reasoning Enabled LLM Guardrail via Knowledge-Enhanced Logical Reasoning",
    "section": "Summary:",
    "text": "Summary:\n\nThe paper introduces -Guard, a robust reasoning enabled LLM guardrail that addresses the limitations of existing guardrail models.\n-Guard consists of two main components: a data-driven category-specific learning component and a knowledge-enhanced reasoning component.\nThe category-specific learning component computes the probability that the prompt falls into different unsafe categories, while the reasoning component makes the final prediction of the overall probability that the prompt is unsafe based on logical inference.\n-Guard employs probabilistic graphical models (PGMs) to implement the reasoning component, which allows for explicit logical inference based on given safety knowledge."
  },
  {
    "objectID": "posts/$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning/2024-07-08-$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning.html#major-findings",
    "href": "posts/$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning/2024-07-08-$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning.html#major-findings",
    "title": "\\(R^2\\)-Guard: Robust Reasoning Enabled LLM Guardrail via Knowledge-Enhanced Logical Reasoning",
    "section": "Major Findings:",
    "text": "Major Findings:\n\n-Guard addresses the limitations of existing guardrail models, such as ineffectiveness due to inadequate training on long-tail data from correlated safety categories, susceptibility to jailbreaks, and inflexibility regarding new safety categories.\n-Guard consists of two main components: a data-driven category-specific learning component and a knowledge-enhanced reasoning component.\n-Guard employs probabilistic graphical models (PGMs) to implement the reasoning component, which allows for explicit logical inference based on given safety knowledge."
  },
  {
    "objectID": "posts/$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning/2024-07-08-$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning.html#analysis-and-critique",
    "href": "posts/$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning/2024-07-08-$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning.html#analysis-and-critique",
    "title": "\\(R^2\\)-Guard: Robust Reasoning Enabled LLM Guardrail via Knowledge-Enhanced Logical Reasoning",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nOne limitation of -Guard is its requirement for explicit specification of safety knowledge rules in PGMs, which necessitates human effort to annotate detailed safety categories and their interconnections.\nHowever, this explicit knowledge also enhances -Guard’s effectiveness and robustness compared to purely data-driven guardrail models.\n-Guard has a broader impact in three key areas: motivating the guardrail community to transition from purely data-driven approaches to those enabled by logical reasoning, providing the symbolic reasoning community with a robust framework for encoding knowledge, performing logical inference, and knowledge weight learning with weak supervision, and safeguarding widespread LLM deployments in various systems.\nThe paper does not see any negative impact of their guardrail model."
  },
  {
    "objectID": "posts/$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning/2024-07-08-$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning.html#appendix",
    "href": "posts/$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning/2024-07-08-$R^2$_Guard_Robust_Reasoning_Enabled_LLM_Guardrail_via_Knowledge_Enhanced_Logical_Reasoning.html#appendix",
    "title": "\\(R^2\\)-Guard: Robust Reasoning Enabled LLM Guardrail via Knowledge-Enhanced Logical Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05557v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05557v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7884"
  },
  {
    "objectID": "posts/Enhancing_Hallucination_Detection_through_Perturbation_Based_Synthetic_Data_Generation_in_System_Responses/2024-07-07-Enhancing_Hallucination_Detection_through_Perturbation_Based_Synthetic_Data_Generation_in_System_Responses.html#appendix",
    "href": "posts/Enhancing_Hallucination_Detection_through_Perturbation_Based_Synthetic_Data_Generation_in_System_Responses/2024-07-07-Enhancing_Hallucination_Detection_through_Perturbation_Based_Synthetic_Data_Generation_in_System_Responses.html#appendix",
    "title": "Enhancing Hallucination Detection through Perturbation-Based Synthetic Data Generation in System Responses",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05474v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05474v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5380"
  },
  {
    "objectID": "posts/Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory/2024-06-20-Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory.html",
    "href": "posts/Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory/2024-06-20-Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory.html",
    "title": "Artificial Leviathan: Exploring Social Evolution of LLM Agents Through the Lens of Hobbesian Social Contract Theory",
    "section": "",
    "text": "Summary:\nThe paper presents a novel multi-agent simulation framework that generates believable artificial societies capable of replicating complex human group behaviors and social interactions. The agents’ behaviors are conditioned by their innate psychological drives, intrinsic motivations, and the constraints of their simulated environment. Empirical evidence from systematic experiments establishes correlations between agent attributes and available resources, and the evolutionary trajectories of simulated societies. The analysis discusses the collective behaviors of the generative agents, highlighting the opportunities and potential risks associated with leveraging LLMs for societal simulations.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an innovative approach to simulating complex human group behaviors and social interactions using LLMs. The empirical evidence from systematic experiments supports the correlations between agent attributes and available resources, and the evolutionary trajectories of simulated societies. However, the paper does not address the limitations of LLMs in accurately modeling human behavior, such as the inability to capture the nuances of human emotions and decision-making processes. Additionally, the paper does not discuss the potential biases introduced by the LLMs used in the simulation, which could impact the accuracy of the results. Overall, the paper provides a valuable contribution to the field of computational social science, but further research is needed to address the limitations and biases of LLMs in simulating human behavior."
  },
  {
    "objectID": "posts/Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory/2024-06-20-Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory.html#appendix",
    "href": "posts/Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory/2024-06-20-Artificial_Leviathan_Exploring_Social_Evolution_of_LLM_Agents_Through_the_Lens_of_Hobbesian_Social_Contract_Theory.html#appendix",
    "title": "Artificial Leviathan: Exploring Social Evolution of LLM Agents Through the Lens of Hobbesian Social Contract Theory",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14373v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14373v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12979"
  },
  {
    "objectID": "posts/Are_LLMs_Naturally_Good_at_Synthetic_Tabular_Data_Generation/2024-06-20-Are_LLMs_Naturally_Good_at_Synthetic_Tabular_Data_Generation.html#appendix",
    "href": "posts/Are_LLMs_Naturally_Good_at_Synthetic_Tabular_Data_Generation/2024-06-20-Are_LLMs_Naturally_Good_at_Synthetic_Tabular_Data_Generation.html#appendix",
    "title": "Are LLMs Naturally Good at Synthetic Tabular Data Generation?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14541v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14541v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10309"
  },
  {
    "objectID": "posts/Look_Within_Why_LLMs_Hallucinate_A_Causal_Perspective/2024-07-14-Look_Within_Why_LLMs_Hallucinate_A_Causal_Perspective.html#appendix",
    "href": "posts/Look_Within_Why_LLMs_Hallucinate_A_Causal_Perspective/2024-07-14-Look_Within_Why_LLMs_Hallucinate_A_Causal_Perspective.html#appendix",
    "title": "Look Within, Why LLMs Hallucinate: A Causal Perspective",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10153v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10153v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5521"
  },
  {
    "objectID": "posts/LLM_Internal_States_Reveal_Hallucination_Risk_Faced_With_a_Query/2024-07-03-LLM_Internal_States_Reveal_Hallucination_Risk_Faced_With_a_Query.html#appendix",
    "href": "posts/LLM_Internal_States_Reveal_Hallucination_Risk_Faced_With_a_Query/2024-07-03-LLM_Internal_States_Reveal_Hallucination_Risk_Faced_With_a_Query.html#appendix",
    "title": "LLM Internal States Reveal Hallucination Risk Faced With a Query",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03282v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03282v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11970"
  },
  {
    "objectID": "posts/Multi_Agent_Software_Development_through_Cross_Team_Collaboration/2024-06-13-Multi_Agent_Software_Development_through_Cross_Team_Collaboration.html#appendix",
    "href": "posts/Multi_Agent_Software_Development_through_Cross_Team_Collaboration/2024-06-13-Multi_Agent_Software_Development_through_Cross_Team_Collaboration.html#appendix",
    "title": "Multi-Agent Software Development through Cross-Team Collaboration",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.08979v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.08979v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8963"
  },
  {
    "objectID": "posts/DARA_Decomposition_Alignment_Reasoning_Autonomous_Language_Agent_for_Question_Answering_over_Knowledge_Graphs/2024-06-11-DARA_Decomposition_Alignment_Reasoning_Autonomous_Language_Agent_for_Question_Answering_over_Knowledge_Graphs.html#appendix",
    "href": "posts/DARA_Decomposition_Alignment_Reasoning_Autonomous_Language_Agent_for_Question_Answering_over_Knowledge_Graphs/2024-06-11-DARA_Decomposition_Alignment_Reasoning_Autonomous_Language_Agent_for_Question_Answering_over_Knowledge_Graphs.html#appendix",
    "title": "DARA: Decomposition-Alignment-Reasoning Autonomous Language Agent for Question Answering over Knowledge Graphs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07080v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07080v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8918"
  },
  {
    "objectID": "posts/$β$_DPO_Direct_Preference_Optimization_with_Dynamic_$β$/2024-07-11-$β$_DPO_Direct_Preference_Optimization_with_Dynamic_$β$.html",
    "href": "posts/$β$_DPO_Direct_Preference_Optimization_with_Dynamic_$β$/2024-07-11-$β$_DPO_Direct_Preference_Optimization_with_Dynamic_$β$.html",
    "title": "\\(β\\)-DPO: Direct Preference Optimization with Dynamic \\(β\\)",
    "section": "",
    "text": "Summary:\nThe paper introduces a novel framework called β-DPO, which aims to optimize DPO by dynamically adjusting the β parameter in response to the variability in the informativeness of pairwise data. The proposed method incorporates β-guided data filtering and batch-level dynamic β calibration, demonstrating significant improvements in DPO’s performance across a range of models and datasets. The empirical evaluations indicate that β-DPO offers an adaptable training paradigm for LLMs with human feedback.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a promising framework for LLM optimization, albeit with room for advancement. Future endeavors should explore:"
  },
  {
    "objectID": "posts/$β$_DPO_Direct_Preference_Optimization_with_Dynamic_$β$/2024-07-11-$β$_DPO_Direct_Preference_Optimization_with_Dynamic_$β$.html#appendix",
    "href": "posts/$β$_DPO_Direct_Preference_Optimization_with_Dynamic_$β$/2024-07-11-$β$_DPO_Direct_Preference_Optimization_with_Dynamic_$β$.html#appendix",
    "title": "\\(β\\)-DPO: Direct Preference Optimization with Dynamic \\(β\\)",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08639v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08639v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13055"
  },
  {
    "objectID": "posts/Data_Centric_AI_in_the_Age_of_Large_Language_Models/2024-06-20-Data_Centric_AI_in_the_Age_of_Large_Language_Models.html#major-findings",
    "href": "posts/Data_Centric_AI_in_the_Age_of_Large_Language_Models/2024-06-20-Data_Centric_AI_in_the_Age_of_Large_Language_Models.html#major-findings",
    "title": "Data-Centric AI in the Age of Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nData-Centric Benchmarks and Data Curation: The authors advocate for a suite of data-centric benchmarks tailored to the scale and complexity of data for LLMs. These benchmarks can be used to develop new data curation methods and document research efforts and results, which can help promote openness and transparency in AI and LLM research.\nData Attribution: The authors emphasize the importance of data attribution for legal and safety purposes, such as respecting copyright/intellectual property rights and mitigating problematic outputs of LLMs. They describe promising directions for data attribution and removal.\nKnowledge Transfer: The authors discuss the potential of transferring the knowledge of trained LLMs to compact and specialized models. They highlight existing efforts and new opportunities where the outputs of a trained LLM are treated as (synthesized) data.\nInference Contextualization with Data: The authors describe how LLMs can flexibly use data at inference to augment the outputs’ factuality or quality. They elaborate on this paradigm with respect to two prevalent technical frameworks and highlight how it can improve the personalization of LLMs."
  },
  {
    "objectID": "posts/Data_Centric_AI_in_the_Age_of_Large_Language_Models/2024-06-20-Data_Centric_AI_in_the_Age_of_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/Data_Centric_AI_in_the_Age_of_Large_Language_Models/2024-06-20-Data_Centric_AI_in_the_Age_of_Large_Language_Models.html#analysis-and-critique",
    "title": "Data-Centric AI in the Age of Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nLimited Research on Data-Centric Approaches: While the paper provides a comprehensive overview of the role of data in LLMs, it also highlights the lack of research in this area. The authors argue that the bulk of research to date has focused on modeling improvements, with little attention paid to how to best use data for the developmental and inferential stages of LLMs.\nChallenges in Data Attribution and Unlearning:"
  },
  {
    "objectID": "posts/Data_Centric_AI_in_the_Age_of_Large_Language_Models/2024-06-20-Data_Centric_AI_in_the_Age_of_Large_Language_Models.html#appendix",
    "href": "posts/Data_Centric_AI_in_the_Age_of_Large_Language_Models/2024-06-20-Data_Centric_AI_in_the_Age_of_Large_Language_Models.html#appendix",
    "title": "Data-Centric AI in the Age of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14473v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14473v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10052"
  },
  {
    "objectID": "posts/Blending_LLMs_into_Cascaded_Speech_Translation_KITs_Offline_Speech_Translation_System_for_IWSLT_2024/2024-06-24-Blending_LLMs_into_Cascaded_Speech_Translation_KITs_Offline_Speech_Translation_System_for_IWSLT_2024.html#appendix",
    "href": "posts/Blending_LLMs_into_Cascaded_Speech_Translation_KITs_Offline_Speech_Translation_System_for_IWSLT_2024/2024-06-24-Blending_LLMs_into_Cascaded_Speech_Translation_KITs_Offline_Speech_Translation_System_for_IWSLT_2024.html#appendix",
    "title": "Blending LLMs into Cascaded Speech Translation: KIT’s Offline Speech Translation System for IWSLT 2024",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16777v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16777v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4916"
  },
  {
    "objectID": "posts/FACTS_About_Building_Retrieval_Augmented_Generation_based_Chatbots/2024-07-10-FACTS_About_Building_Retrieval_Augmented_Generation_based_Chatbots.html#appendix",
    "href": "posts/FACTS_About_Building_Retrieval_Augmented_Generation_based_Chatbots/2024-07-10-FACTS_About_Building_Retrieval_Augmented_Generation_based_Chatbots.html#appendix",
    "title": "FACTS About Building Retrieval Augmented Generation-based Chatbots",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07858v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07858v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5997"
  },
  {
    "objectID": "posts/Can_Large_Language_Models_Understand_DL_Lite_Ontologies_An_Empirical_Study/2024-06-25-Can_Large_Language_Models_Understand_DL_Lite_Ontologies_An_Empirical_Study.html#appendix",
    "href": "posts/Can_Large_Language_Models_Understand_DL_Lite_Ontologies_An_Empirical_Study/2024-06-25-Can_Large_Language_Models_Understand_DL_Lite_Ontologies_An_Empirical_Study.html#appendix",
    "title": "Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17532v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17532v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10388"
  },
  {
    "objectID": "posts/On_LLM_Wizards_Identifying_Large_Language_Models_Behaviors_for_Wizard_of_Oz_Experiments/2024-07-10-On_LLM_Wizards_Identifying_Large_Language_Models_Behaviors_for_Wizard_of_Oz_Experiments.html#appendix",
    "href": "posts/On_LLM_Wizards_Identifying_Large_Language_Models_Behaviors_for_Wizard_of_Oz_Experiments/2024-07-10-On_LLM_Wizards_Identifying_Large_Language_Models_Behaviors_for_Wizard_of_Oz_Experiments.html#appendix",
    "title": "On LLM Wizards: Identifying Large Language Models’ Behaviors for Wizard of Oz Experiments",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08067v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08067v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13493"
  },
  {
    "objectID": "posts/Distributional_reasoning_in_LLMs_Parallel_reasoning_processes_in_multi_hop_reasoning/2024-06-19-Distributional_reasoning_in_LLMs_Parallel_reasoning_processes_in_multi_hop_reasoning.html#appendix",
    "href": "posts/Distributional_reasoning_in_LLMs_Parallel_reasoning_processes_in_multi_hop_reasoning/2024-06-19-Distributional_reasoning_in_LLMs_Parallel_reasoning_processes_in_multi_hop_reasoning.html#appendix",
    "title": "Distributional reasoning in LLMs: Parallel reasoning processes in multi-hop reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13858v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13858v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7199"
  },
  {
    "objectID": "posts/Large_Language_Models_Memorize_Sensor_Datasets!_Implications_on_Human_Activity_Recognition_Research/2024-06-09-Large_Language_Models_Memorize_Sensor_Datasets!_Implications_on_Human_Activity_Recognition_Research.html#appendix",
    "href": "posts/Large_Language_Models_Memorize_Sensor_Datasets!_Implications_on_Human_Activity_Recognition_Research/2024-06-09-Large_Language_Models_Memorize_Sensor_Datasets!_Implications_on_Human_Activity_Recognition_Research.html#appendix",
    "title": "Large Language Models Memorize Sensor Datasets! Implications on Human Activity Recognition Research",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05900v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05900v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6787"
  },
  {
    "objectID": "posts/Chain_of_Probe_Examing_the_Necessity_and_Accuracy_of_CoT_Step_by_Step/2024-06-23-Chain_of_Probe_Examing_the_Necessity_and_Accuracy_of_CoT_Step_by_Step.html",
    "href": "posts/Chain_of_Probe_Examing_the_Necessity_and_Accuracy_of_CoT_Step_by_Step/2024-06-23-Chain_of_Probe_Examing_the_Necessity_and_Accuracy_of_CoT_Step_by_Step.html",
    "title": "Chain-of-Probe: Examing the Necessity and Accuracy of CoT Step-by-Step",
    "section": "",
    "text": "Summary:\nThe paper proposes a method called Chain-of-Probe (CoP) to examine the necessity and accuracy of Chain-of-Thought (CoT) in large language models (LLMs). The authors address the issue of early answering, where LLMs already have an answer before generating the CoT, and investigate the underlying causes of this phenomenon. The study reveals that early answering is linked to question difficulty, with models tending to predict answers in advance for simpler questions, making CoT unnecessary for simple tasks. The authors propose the CoP Score to evaluate and select CoTs, aiming for more positive improvements.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a novel method, CoP, to detect changes in model thoughts and addresses the issue of early answering in LLMs. However, the study has some limitations. First, CoP currently only applies to multiple-choice questions or questions where the answer is a single token, making it challenging to define the model’s confidence in the final prediction when the target word exceeds one token. Second, regarding the necessity of CoT, it is difficult to determine in advance whether a task is simple, making it impossible to pre-judge whether CoT is needed for a particular question. Lastly, concerning the accuracy of CoT, the CoP Tree has high precision but relatively low recall, leading to an increase in the number of samples needed.\nThe paper also raises ethical concerns regarding the use of GPT-4 as an evaluator. While the authors prioritize transparency, accountability, and mitigation of potential biases, the limitations of AI should be acknowledged, and it should supplement rather than replace human judgment.\nOverall, the paper provides valuable insights into the necessity and accuracy of CoT in LLMs and proposes a novel method to address the issue of early answering. However, further research is needed to overcome the limitations and ethical concerns raised in the study."
  },
  {
    "objectID": "posts/Chain_of_Probe_Examing_the_Necessity_and_Accuracy_of_CoT_Step_by_Step/2024-06-23-Chain_of_Probe_Examing_the_Necessity_and_Accuracy_of_CoT_Step_by_Step.html#appendix",
    "href": "posts/Chain_of_Probe_Examing_the_Necessity_and_Accuracy_of_CoT_Step_by_Step/2024-06-23-Chain_of_Probe_Examing_the_Necessity_and_Accuracy_of_CoT_Step_by_Step.html#appendix",
    "title": "Chain-of-Probe: Examing the Necessity and Accuracy of CoT Step-by-Step",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16144v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16144v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6521"
  },
  {
    "objectID": "posts/Annotation_alignment_Comparing_LLM_and_human_annotations_of_conversational_safety/2024-06-10-Annotation_alignment_Comparing_LLM_and_human_annotations_of_conversational_safety.html#appendix",
    "href": "posts/Annotation_alignment_Comparing_LLM_and_human_annotations_of_conversational_safety/2024-06-10-Annotation_alignment_Comparing_LLM_and_human_annotations_of_conversational_safety.html#appendix",
    "title": "Annotation alignment: Comparing LLM and human annotations of conversational safety",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06369v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06369v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7965"
  },
  {
    "objectID": "posts/Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs/2024-06-18-Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs.html",
    "href": "posts/Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs/2024-06-18-Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs.html",
    "title": "Can We Trust Large Language Models Generated Code? A Framework for In-Context Learning, Security Patterns, and Code Evaluations Across Diverse LLMs",
    "section": "",
    "text": "Summary:\nThis research aims to tackle the security and quality concerns of code generated by Large Language Models (LLMs) like ChatGPT and GitHub Copilot. These models are increasingly utilized for software development but are primarily trained on publicly available code repositories and internet-based textual data, which may contain insecure code. This presents a significant risk of perpetuating vulnerabilities in the generated code. The research introduces a framework for secure behavioral learning of LLMs through In-Context Learning (ICL) patterns during the code generation process, followed by rigorous security evaluations. Four diverse LLMs are selected for experimentation, and their coding capabilities are evaluated across three programming languages. The research indicates that ICL-driven one-shot and few-shot learning patterns can enhance code security, reducing vulnerabilities in various programming scenarios. However, developers and researchers should be aware that LLMs have a limited understanding of security principles, which may lead to security breaches when the generated code is deployed in production systems. The research highlights that LLMs are a potential source of new vulnerabilities to the software supply chain and emphasizes the importance of considering this when using LLMs for code generation.\nMajor Findings:\nAnalysis and Critique:\nThe research provides"
  },
  {
    "objectID": "posts/Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs/2024-06-18-Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs.html#appendix",
    "href": "posts/Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs/2024-06-18-Can_We_Trust_Large_Language_Models_Generated_Code_A_Framework_for_In_Context_Learning_Security_Patterns_and_Code_Evaluations_Across_Diverse_LLMs.html#appendix",
    "title": "Can We Trust Large Language Models Generated Code? A Framework for In-Context Learning, Security Patterns, and Code Evaluations Across Diverse LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12513v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12513v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18028"
  },
  {
    "objectID": "posts/Banishing_LLM_Hallucinations_Requires_Rethinking_Generalization/2024-06-25-Banishing_LLM_Hallucinations_Requires_Rethinking_Generalization.html#appendix",
    "href": "posts/Banishing_LLM_Hallucinations_Requires_Rethinking_Generalization/2024-06-25-Banishing_LLM_Hallucinations_Requires_Rethinking_Generalization.html#appendix",
    "title": "Banishing LLM Hallucinations Requires Rethinking Generalization",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17642v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17642v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5811"
  },
  {
    "objectID": "posts/SLMRec_Empowering_Small_Language_Models_for_Sequential_Recommendation/2024-05-28-SLMRec_Empowering_Small_Language_Models_for_Sequential_Recommendation.html#appendix",
    "href": "posts/SLMRec_Empowering_Small_Language_Models_for_Sequential_Recommendation/2024-05-28-SLMRec_Empowering_Small_Language_Models_for_Sequential_Recommendation.html#appendix",
    "title": "SLMRec: Empowering Small Language Models for Sequential Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.17890v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.17890v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6690"
  },
  {
    "objectID": "posts/CaLMQA_Exploring_culturally_specific_long_form_question_answering_across_23_languages/2024-06-25-CaLMQA_Exploring_culturally_specific_long_form_question_answering_across_23_languages.html#appendix",
    "href": "posts/CaLMQA_Exploring_culturally_specific_long_form_question_answering_across_23_languages/2024-06-25-CaLMQA_Exploring_culturally_specific_long_form_question_answering_across_23_languages.html#appendix",
    "title": "CaLMQA: Exploring culturally specific long-form question answering across 23 languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17761v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17761v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11413"
  },
  {
    "objectID": "posts/Prompting_Techniques_for_Secure_Code_Generation_A_Systematic_Investigation/2024-07-09-Prompting_Techniques_for_Secure_Code_Generation_A_Systematic_Investigation.html#appendix",
    "href": "posts/Prompting_Techniques_for_Secure_Code_Generation_A_Systematic_Investigation/2024-07-09-Prompting_Techniques_for_Secure_Code_Generation_A_Systematic_Investigation.html#appendix",
    "title": "Prompting Techniques for Secure Code Generation: A Systematic Investigation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07064v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07064v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20445"
  },
  {
    "objectID": "posts/SAFETY_J_Evaluating_Safety_with_Critique/2024-07-25-SAFETY_J_Evaluating_Safety_with_Critique.html#appendix",
    "href": "posts/SAFETY_J_Evaluating_Safety_with_Critique/2024-07-25-SAFETY_J_Evaluating_Safety_with_Critique.html#appendix",
    "title": "SAFETY-J: Evaluating Safety with Critique",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17075v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17075v2\n\n\nTruncated\nFalse\n\n\nWord Count\n8777"
  },
  {
    "objectID": "posts/Preliminary_WMT24_Ranking_of_General_MT_Systems_and_LLMs/2024-07-29-Preliminary_WMT24_Ranking_of_General_MT_Systems_and_LLMs.html#appendix",
    "href": "posts/Preliminary_WMT24_Ranking_of_General_MT_Systems_and_LLMs/2024-07-29-Preliminary_WMT24_Ranking_of_General_MT_Systems_and_LLMs.html#appendix",
    "title": "Preliminary WMT24 Ranking of General MT Systems and LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19884v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19884v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1564"
  },
  {
    "objectID": "posts/WildGuard_Open_One_Stop_Moderation_Tools_for_Safety_Risks_Jailbreaks_and_Refusals_of_LLMs/2024-06-26-WildGuard_Open_One_Stop_Moderation_Tools_for_Safety_Risks_Jailbreaks_and_Refusals_of_LLMs.html#appendix",
    "href": "posts/WildGuard_Open_One_Stop_Moderation_Tools_for_Safety_Risks_Jailbreaks_and_Refusals_of_LLMs/2024-06-26-WildGuard_Open_One_Stop_Moderation_Tools_for_Safety_Risks_Jailbreaks_and_Refusals_of_LLMs.html#appendix",
    "title": "WildGuard: Open One-Stop Moderation Tools for Safety Risks, Jailbreaks, and Refusals of LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18495v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18495v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13217"
  },
  {
    "objectID": "posts/ANOLE_An_Open_Autoregressive_Native_Large_Multimodal_Models_for_Interleaved_Image_Text_Generation/2024-07-08-ANOLE_An_Open_Autoregressive_Native_Large_Multimodal_Models_for_Interleaved_Image_Text_Generation.html#appendix",
    "href": "posts/ANOLE_An_Open_Autoregressive_Native_Large_Multimodal_Models_for_Interleaved_Image_Text_Generation/2024-07-08-ANOLE_An_Open_Autoregressive_Native_Large_Multimodal_Models_for_Interleaved_Image_Text_Generation.html#appendix",
    "title": "ANOLE: An Open, Autoregressive, Native Large Multimodal Models for Interleaved Image-Text Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06135v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06135v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3311"
  },
  {
    "objectID": "posts/Flooding_Spread_of_Manipulated_Knowledge_in_LLM_Based_Multi_Agent_Communities/2024-07-10-Flooding_Spread_of_Manipulated_Knowledge_in_LLM_Based_Multi_Agent_Communities.html#appendix",
    "href": "posts/Flooding_Spread_of_Manipulated_Knowledge_in_LLM_Based_Multi_Agent_Communities/2024-07-10-Flooding_Spread_of_Manipulated_Knowledge_in_LLM_Based_Multi_Agent_Communities.html#appendix",
    "title": "Flooding Spread of Manipulated Knowledge in LLM-Based Multi-Agent Communities",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07791v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07791v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11413"
  },
  {
    "objectID": "posts/Self_Evaluation_as_a_Defense_Against_Adversarial_Attacks_on_LLMs/2024-07-03-Self_Evaluation_as_a_Defense_Against_Adversarial_Attacks_on_LLMs.html#appendix",
    "href": "posts/Self_Evaluation_as_a_Defense_Against_Adversarial_Attacks_on_LLMs/2024-07-03-Self_Evaluation_as_a_Defense_Against_Adversarial_Attacks_on_LLMs.html#appendix",
    "title": "Self-Evaluation as a Defense Against Adversarial Attacks on LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03234v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03234v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18444"
  },
  {
    "objectID": "posts/Empowering_1000_tokenssecond_on_device_LLM_prefilling_with_mllm_NPU/2024-07-08-Empowering_1000_tokenssecond_on_device_LLM_prefilling_with_mllm_NPU.html#appendix",
    "href": "posts/Empowering_1000_tokenssecond_on_device_LLM_prefilling_with_mllm_NPU/2024-07-08-Empowering_1000_tokenssecond_on_device_LLM_prefilling_with_mllm_NPU.html#appendix",
    "title": "Empowering 1000 tokens/second on-device LLM prefilling with mllm-NPU",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05858v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05858v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11855"
  },
  {
    "objectID": "posts/Enhancing_Tool_Retrieval_with_Iterative_Feedback_from_Large_Language_Models/2024-06-25-Enhancing_Tool_Retrieval_with_Iterative_Feedback_from_Large_Language_Models.html#appendix",
    "href": "posts/Enhancing_Tool_Retrieval_with_Iterative_Feedback_from_Large_Language_Models/2024-06-25-Enhancing_Tool_Retrieval_with_Iterative_Feedback_from_Large_Language_Models.html#appendix",
    "title": "Enhancing Tool Retrieval with Iterative Feedback from Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.17465v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.17465v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5575"
  },
  {
    "objectID": "posts/Evaluating_LLMs_for_Text_to_SQL_Generation_With_Complex_SQL_Workload/2024-07-28-Evaluating_LLMs_for_Text_to_SQL_Generation_With_Complex_SQL_Workload.html#appendix",
    "href": "posts/Evaluating_LLMs_for_Text_to_SQL_Generation_With_Complex_SQL_Workload/2024-07-28-Evaluating_LLMs_for_Text_to_SQL_Generation_With_Complex_SQL_Workload.html#appendix",
    "title": "Evaluating LLMs for Text-to-SQL Generation With Complex SQL Workload",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.19517v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.19517v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4422"
  },
  {
    "objectID": "posts/Harnessing_the_Power_of_LLMs_Automating_Unit_Test_Generation_for_High_Performance_Computing/2024-07-06-Harnessing_the_Power_of_LLMs_Automating_Unit_Test_Generation_for_High_Performance_Computing.html#appendix",
    "href": "posts/Harnessing_the_Power_of_LLMs_Automating_Unit_Test_Generation_for_High_Performance_Computing/2024-07-06-Harnessing_the_Power_of_LLMs_Automating_Unit_Test_Generation_for_High_Performance_Computing.html#appendix",
    "title": "Harnessing the Power of LLMs: Automating Unit Test Generation for High-Performance Computing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05202v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05202v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10114"
  },
  {
    "objectID": "posts/Key_Point_Driven_Mathematical_Reasoning_Distillation_of_Large_Language_Model/2024-07-14-Key_Point_Driven_Mathematical_Reasoning_Distillation_of_Large_Language_Model.html#appendix",
    "href": "posts/Key_Point_Driven_Mathematical_Reasoning_Distillation_of_Large_Language_Model/2024-07-14-Key_Point_Driven_Mathematical_Reasoning_Distillation_of_Large_Language_Model.html#appendix",
    "title": "Key-Point-Driven Mathematical Reasoning Distillation of Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10167v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10167v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8199"
  },
  {
    "objectID": "posts/Themis_Towards_Flexible_and_Interpretable_NLG_Evaluation/2024-06-26-Themis_Towards_Flexible_and_Interpretable_NLG_Evaluation.html#appendix",
    "href": "posts/Themis_Towards_Flexible_and_Interpretable_NLG_Evaluation/2024-06-26-Themis_Towards_Flexible_and_Interpretable_NLG_Evaluation.html#appendix",
    "title": "Themis: Towards Flexible and Interpretable NLG Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.18365v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.18365v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6245"
  },
  {
    "objectID": "posts/HalluDial_A_Large_Scale_Benchmark_for_Automatic_Dialogue_Level_Hallucination_Evaluation/2024-06-11-HalluDial_A_Large_Scale_Benchmark_for_Automatic_Dialogue_Level_Hallucination_Evaluation.html#appendix",
    "href": "posts/HalluDial_A_Large_Scale_Benchmark_for_Automatic_Dialogue_Level_Hallucination_Evaluation/2024-06-11-HalluDial_A_Large_Scale_Benchmark_for_Automatic_Dialogue_Level_Hallucination_Evaluation.html#appendix",
    "title": "HalluDial: A Large-Scale Benchmark for Automatic Dialogue-Level Hallucination Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07070v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07070v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10462"
  },
  {
    "objectID": "posts/Divine_LLaMAs_Bias_Stereotypes_Stigmatization_and_Emotion_Representation_of_Religion_in_Large_Language_Models/2024-07-09-Divine_LLaMAs_Bias_Stereotypes_Stigmatization_and_Emotion_Representation_of_Religion_in_Large_Language_Models.html#appendix",
    "href": "posts/Divine_LLaMAs_Bias_Stereotypes_Stigmatization_and_Emotion_Representation_of_Religion_in_Large_Language_Models/2024-07-09-Divine_LLaMAs_Bias_Stereotypes_Stigmatization_and_Emotion_Representation_of_Religion_in_Large_Language_Models.html#appendix",
    "title": "Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.06908v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.06908v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6978"
  },
  {
    "objectID": "posts/T2VSafetyBench_Evaluating_the_Safety_of_Text_to_Video_Generative_Models/2024-07-08-T2VSafetyBench_Evaluating_the_Safety_of_Text_to_Video_Generative_Models.html#appendix",
    "href": "posts/T2VSafetyBench_Evaluating_the_Safety_of_Text_to_Video_Generative_Models/2024-07-08-T2VSafetyBench_Evaluating_the_Safety_of_Text_to_Video_Generative_Models.html#appendix",
    "title": "T2VSafetyBench: Evaluating the Safety of Text-to-Video Generative Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05965v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05965v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8108"
  },
  {
    "objectID": "posts/RedAgent_Red_Teaming_Large_Language_Models_with_Context_aware_Autonomous_Language_Agent/2024-07-23-RedAgent_Red_Teaming_Large_Language_Models_with_Context_aware_Autonomous_Language_Agent.html",
    "href": "posts/RedAgent_Red_Teaming_Large_Language_Models_with_Context_aware_Autonomous_Language_Agent/2024-07-23-RedAgent_Red_Teaming_Large_Language_Models_with_Context_aware_Autonomous_Language_Agent.html",
    "title": "RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent",
    "section": "",
    "text": "Summary:\nThe paper introduces RedAgent, a multi-agent language model system designed to generate context-aware jailbreak prompts for testing the security of large language models (LLMs). The system leverages a concept called “jailbreak strategy” to model existing attacks and improve the efficiency of red teaming methods. RedAgent can jailbreak most black-box LLMs within five queries, improving the efficiency of existing red teaming methods by two times. The system can also jailbreak customized LLM applications more efficiently, discovering 60 severe vulnerabilities in real-world applications with only two queries per vulnerability.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an innovative approach to testing the security of LLMs by generating context-aware jailbreak prompts. The use of a multi-agent language model system and the concept of “jailbreak strategy” are promising developments in the field of LLM security. However, the paper does not discuss the potential risks associated with using such a system, such as the possibility of malicious actors using it to exploit vulnerabilities in LLMs. Additionally, the paper does not provide a detailed analysis of the limitations of the system or the potential biases that may be introduced during the red teaming process. Further research is needed to address these concerns and ensure the responsible use of such systems."
  },
  {
    "objectID": "posts/RedAgent_Red_Teaming_Large_Language_Models_with_Context_aware_Autonomous_Language_Agent/2024-07-23-RedAgent_Red_Teaming_Large_Language_Models_with_Context_aware_Autonomous_Language_Agent.html#appendix",
    "href": "posts/RedAgent_Red_Teaming_Large_Language_Models_with_Context_aware_Autonomous_Language_Agent/2024-07-23-RedAgent_Red_Teaming_Large_Language_Models_with_Context_aware_Autonomous_Language_Agent.html#appendix",
    "title": "RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16667v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16667v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12111"
  },
  {
    "objectID": "posts/Text_to_Drive_Diverse_Driving_Behavior_Synthesis_via_Large_Language_Models/2024-06-06-Text_to_Drive_Diverse_Driving_Behavior_Synthesis_via_Large_Language_Models.html#appendix",
    "href": "posts/Text_to_Drive_Diverse_Driving_Behavior_Synthesis_via_Large_Language_Models/2024-06-06-Text_to_Drive_Diverse_Driving_Behavior_Synthesis_via_Large_Language_Models.html#appendix",
    "title": "Text-to-Drive: Diverse Driving Behavior Synthesis via Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04300v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04300v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10490"
  },
  {
    "objectID": "posts/PDSS_A_Privacy_Preserving_Framework_for_Step_by_Step_Distillation_of_Large_Language_Models/2024-06-18-PDSS_A_Privacy_Preserving_Framework_for_Step_by_Step_Distillation_of_Large_Language_Models.html#appendix",
    "href": "posts/PDSS_A_Privacy_Preserving_Framework_for_Step_by_Step_Distillation_of_Large_Language_Models/2024-06-18-PDSS_A_Privacy_Preserving_Framework_for_Step_by_Step_Distillation_of_Large_Language_Models.html#appendix",
    "title": "PDSS: A Privacy-Preserving Framework for Step-by-Step Distillation of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12403v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12403v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6497"
  },
  {
    "objectID": "posts/Demystifying_Verbatim_Memorization_in_Large_Language_Models/2024-07-25-Demystifying_Verbatim_Memorization_in_Large_Language_Models.html#appendix",
    "href": "posts/Demystifying_Verbatim_Memorization_in_Large_Language_Models/2024-07-25-Demystifying_Verbatim_Memorization_in_Large_Language_Models.html#appendix",
    "title": "Demystifying Verbatim Memorization in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17817v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17817v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14802"
  },
  {
    "objectID": "posts/SD_Eval_A_Benchmark_Dataset_for_Spoken_Dialogue_Understanding_Beyond_Words/2024-06-19-SD_Eval_A_Benchmark_Dataset_for_Spoken_Dialogue_Understanding_Beyond_Words.html#appendix",
    "href": "posts/SD_Eval_A_Benchmark_Dataset_for_Spoken_Dialogue_Understanding_Beyond_Words/2024-06-19-SD_Eval_A_Benchmark_Dataset_for_Spoken_Dialogue_Understanding_Beyond_Words.html#appendix",
    "title": "SD-Eval: A Benchmark Dataset for Spoken Dialogue Understanding Beyond Words",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13340v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13340v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5962"
  },
  {
    "objectID": "posts/Towards_Detecting_LLMs_Hallucination_via_Markov_Chain_based_Multi_agent_Debate_Framework/2024-06-05-Towards_Detecting_LLMs_Hallucination_via_Markov_Chain_based_Multi_agent_Debate_Framework.html#appendix",
    "href": "posts/Towards_Detecting_LLMs_Hallucination_via_Markov_Chain_based_Multi_agent_Debate_Framework/2024-06-05-Towards_Detecting_LLMs_Hallucination_via_Markov_Chain_based_Multi_agent_Debate_Framework.html#appendix",
    "title": "Towards Detecting LLMs Hallucination via Markov Chain-based Multi-agent Debate Framework",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03075v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03075v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5918"
  },
  {
    "objectID": "posts/LLM_enhanced_Reranking_in_Recommender_Systems/2024-06-18-LLM_enhanced_Reranking_in_Recommender_Systems.html#appendix",
    "href": "posts/LLM_enhanced_Reranking_in_Recommender_Systems/2024-06-18-LLM_enhanced_Reranking_in_Recommender_Systems.html#appendix",
    "title": "LLM-enhanced Reranking in Recommender Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12433v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12433v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8439"
  },
  {
    "objectID": "posts/LLM_Circuit_Analyses_Are_Consistent_Across_Training_and_Scale/2024-07-15-LLM_Circuit_Analyses_Are_Consistent_Across_Training_and_Scale.html#appendix",
    "href": "posts/LLM_Circuit_Analyses_Are_Consistent_Across_Training_and_Scale/2024-07-15-LLM_Circuit_Analyses_Are_Consistent_Across_Training_and_Scale.html#appendix",
    "title": "LLM Circuit Analyses Are Consistent Across Training and Scale",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10827v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10827v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11482"
  },
  {
    "objectID": "posts/OriGenEnhancing_RTL_Code_Generation_with_Code_to_Code_Augmentation_and_Self_Reflection/2024-07-23-OriGenEnhancing_RTL_Code_Generation_with_Code_to_Code_Augmentation_and_Self_Reflection.html#appendix",
    "href": "posts/OriGenEnhancing_RTL_Code_Generation_with_Code_to_Code_Augmentation_and_Self_Reflection/2024-07-23-OriGenEnhancing_RTL_Code_Generation_with_Code_to_Code_Augmentation_and_Self_Reflection.html#appendix",
    "title": "OriGen:Enhancing RTL Code Generation with Code-to-Code Augmentation and Self-Reflection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16237v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16237v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6014"
  },
  {
    "objectID": "posts/LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction/2024-06-20-LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction.html",
    "href": "posts/LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction/2024-06-20-LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction.html",
    "title": "LLM4CP: Adapting Large Language Models for Channel Prediction",
    "section": "",
    "text": "Summary:\nThe paper proposes a novel channel prediction method called LLM4CP, which is based on fine-tuning pre-trained GPT-2 for MISO-OFDM channel prediction tasks. The method predicts future downlink CSI sequences based on historical uplink CSI sequences and can be applied to both TDD and FDD systems. To account for channel characteristics, the authors have tailored preprocessor, embedding, and output modules to bridge the gap between CSI data and LLM. Preliminary simulations validate the superiority of LLM4CP over existing model-based and deep learning-based channel prediction methods in full-sample, few-shot, and generalization tests with acceptable training and inference costs.\nMajor Findings:\nAnalysis and Critique:\nOverall, the paper presents an interesting and promising approach to channel prediction based on fine-tuning pre-trained GPT-2. However, more detailed analysis and comparison with other state-of-the-art methods are needed to better understand its advantages and"
  },
  {
    "objectID": "posts/LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction/2024-06-20-LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction.html#appendix",
    "href": "posts/LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction/2024-06-20-LLM4CP_Adapting_Large_Language_Models_for_Channel_Prediction.html#appendix",
    "title": "LLM4CP: Adapting Large Language Models for Channel Prediction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14440v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14440v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8453"
  },
  {
    "objectID": "posts/Large_Language_Models_for_Anomaly_Detection_in_Computational_Workflows_from_Supervised_Fine_Tuning_to_In_Context_Learning/2024-07-24-Large_Language_Models_for_Anomaly_Detection_in_Computational_Workflows_from_Supervised_Fine_Tuning_to_In_Context_Learning.html#appendix",
    "href": "posts/Large_Language_Models_for_Anomaly_Detection_in_Computational_Workflows_from_Supervised_Fine_Tuning_to_In_Context_Learning/2024-07-24-Large_Language_Models_for_Anomaly_Detection_in_Computational_Workflows_from_Supervised_Fine_Tuning_to_In_Context_Learning.html#appendix",
    "title": "Large Language Models for Anomaly Detection in Computational Workflows: from Supervised Fine-Tuning to In-Context Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.17545v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.17545v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8769"
  },
  {
    "objectID": "posts/Ollabench_Evaluating_LLMs_Reasoning_for_Human_centric_Interdependent_Cybersecurity/2024-06-11-Ollabench_Evaluating_LLMs_Reasoning_for_Human_centric_Interdependent_Cybersecurity.html#appendix",
    "href": "posts/Ollabench_Evaluating_LLMs_Reasoning_for_Human_centric_Interdependent_Cybersecurity/2024-06-11-Ollabench_Evaluating_LLMs_Reasoning_for_Human_centric_Interdependent_Cybersecurity.html#appendix",
    "title": "Ollabench: Evaluating LLMs’ Reasoning for Human-centric Interdependent Cybersecurity",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06863v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06863v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7305"
  },
  {
    "objectID": "posts/Language_Models_Resist_Alignment/2024-06-10-Language_Models_Resist_Alignment.html#appendix",
    "href": "posts/Language_Models_Resist_Alignment/2024-06-10-Language_Models_Resist_Alignment.html#appendix",
    "title": "Language Models Resist Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06144v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06144v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5000"
  },
  {
    "objectID": "posts/Where_Do_Large_Language_Models_Fail_When_Generating_Code/2024-06-13-Where_Do_Large_Language_Models_Fail_When_Generating_Code.html#appendix",
    "href": "posts/Where_Do_Large_Language_Models_Fail_When_Generating_Code/2024-06-13-Where_Do_Large_Language_Models_Fail_When_Generating_Code.html#appendix",
    "title": "Where Do Large Language Models Fail When Generating Code?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.08731v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.08731v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9595"
  },
  {
    "objectID": "posts/LIT_Large_Language_Model_Driven_Intention_Tracking_for_Proactive_Human_Robot_Collaboration____A_Robot_Sous_Chef_Application/2024-06-19-LIT_Large_Language_Model_Driven_Intention_Tracking_for_Proactive_Human_Robot_Collaboration____A_Robot_Sous_Chef_Application.html#appendix",
    "href": "posts/LIT_Large_Language_Model_Driven_Intention_Tracking_for_Proactive_Human_Robot_Collaboration____A_Robot_Sous_Chef_Application/2024-06-19-LIT_Large_Language_Model_Driven_Intention_Tracking_for_Proactive_Human_Robot_Collaboration____A_Robot_Sous_Chef_Application.html#appendix",
    "title": "LIT: Large Language Model Driven Intention Tracking for Proactive Human-Robot Collaboration – A Robot Sous-Chef Application",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13787v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13787v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3696"
  },
  {
    "objectID": "posts/Open_LLM_Leaderboard_From_Multi_choice_to_Open_style_Questions_for_LLMs_Evaluation_Benchmark_and_Arena/2024-06-11-Open_LLM_Leaderboard_From_Multi_choice_to_Open_style_Questions_for_LLMs_Evaluation_Benchmark_and_Arena.html#appendix",
    "href": "posts/Open_LLM_Leaderboard_From_Multi_choice_to_Open_style_Questions_for_LLMs_Evaluation_Benchmark_and_Arena/2024-06-11-Open_LLM_Leaderboard_From_Multi_choice_to_Open_style_Questions_for_LLMs_Evaluation_Benchmark_and_Arena.html#appendix",
    "title": "Open-LLM-Leaderboard: From Multi-choice to Open-style Questions for LLMs Evaluation, Benchmark, and Arena",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07545v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07545v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5687"
  },
  {
    "objectID": "posts/Efficiently_Exploring_Large_Language_Models_for_Document_Level_Machine_Translation_with_In_context_Learning/2024-06-11-Efficiently_Exploring_Large_Language_Models_for_Document_Level_Machine_Translation_with_In_context_Learning.html#appendix",
    "href": "posts/Efficiently_Exploring_Large_Language_Models_for_Document_Level_Machine_Translation_with_In_context_Learning/2024-06-11-Efficiently_Exploring_Large_Language_Models_for_Document_Level_Machine_Translation_with_In_context_Learning.html#appendix",
    "title": "Efficiently Exploring Large Language Models for Document-Level Machine Translation with In-context Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07081v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07081v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6243"
  },
  {
    "objectID": "posts/Instruct_Large_Language_Models_to_Drive_like_Humans/2024-06-11-Instruct_Large_Language_Models_to_Drive_like_Humans.html#appendix",
    "href": "posts/Instruct_Large_Language_Models_to_Drive_like_Humans/2024-06-11-Instruct_Large_Language_Models_to_Drive_like_Humans.html#appendix",
    "title": "Instruct Large Language Models to Drive like Humans",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07296v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07296v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5303"
  },
  {
    "objectID": "posts/Can_Large_Language_Models_Automatically_Jailbreak_GPT_4V/2024-07-23-Can_Large_Language_Models_Automatically_Jailbreak_GPT_4V.html#appendix",
    "href": "posts/Can_Large_Language_Models_Automatically_Jailbreak_GPT_4V/2024-07-23-Can_Large_Language_Models_Automatically_Jailbreak_GPT_4V.html#appendix",
    "title": "Can Large Language Models Automatically Jailbreak GPT-4V?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.16686v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.16686v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6844"
  },
  {
    "objectID": "posts/MAVIS_Mathematical_Visual_Instruction_Tuning/2024-07-11-MAVIS_Mathematical_Visual_Instruction_Tuning.html#appendix",
    "href": "posts/MAVIS_Mathematical_Visual_Instruction_Tuning/2024-07-11-MAVIS_Mathematical_Visual_Instruction_Tuning.html#appendix",
    "title": "MAVIS: Mathematical Visual Instruction Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.08739v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.08739v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8660"
  },
  {
    "objectID": "posts/Enhancing_Computer_Programming_Education_with_LLMs_A_Study_on_Effective_Prompt_Engineering_for_Python_Code_Generation/2024-07-07-Enhancing_Computer_Programming_Education_with_LLMs_A_Study_on_Effective_Prompt_Engineering_for_Python_Code_Generation.html#appendix",
    "href": "posts/Enhancing_Computer_Programming_Education_with_LLMs_A_Study_on_Effective_Prompt_Engineering_for_Python_Code_Generation/2024-07-07-Enhancing_Computer_Programming_Education_with_LLMs_A_Study_on_Effective_Prompt_Engineering_for_Python_Code_Generation.html#appendix",
    "title": "Enhancing Computer Programming Education with LLMs: A Study on Effective Prompt Engineering for Python Code Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.05437v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.05437v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9547"
  },
  {
    "objectID": "posts/CREF_An_LLM_based_Conversational_Software_Repair_Framework_for_Programming_Tutors/2024-06-20-CREF_An_LLM_based_Conversational_Software_Repair_Framework_for_Programming_Tutors.html#appendix",
    "href": "posts/CREF_An_LLM_based_Conversational_Software_Repair_Framework_for_Programming_Tutors/2024-06-20-CREF_An_LLM_based_Conversational_Software_Repair_Framework_for_Programming_Tutors.html#appendix",
    "title": "CREF: An LLM-based Conversational Software Repair Framework for Programming Tutors",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13972v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13972v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12780"
  },
  {
    "objectID": "posts/GLBench_A_Comprehensive_Benchmark_for_Graph_with_Large_Language_Models/2024-07-11-GLBench_A_Comprehensive_Benchmark_for_Graph_with_Large_Language_Models.html#appendix",
    "href": "posts/GLBench_A_Comprehensive_Benchmark_for_Graph_with_Large_Language_Models/2024-07-11-GLBench_A_Comprehensive_Benchmark_for_Graph_with_Large_Language_Models.html#appendix",
    "title": "GLBench: A Comprehensive Benchmark for Graph with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.07457v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.07457v2\n\n\nTruncated\nFalse\n\n\nWord Count\n9223"
  },
  {
    "objectID": "posts/Sibyl_Simple_yet_Effective_Agent_Framework_for_Complex_Real_world_Reasoning/2024-07-15-Sibyl_Simple_yet_Effective_Agent_Framework_for_Complex_Real_world_Reasoning.html#appendix",
    "href": "posts/Sibyl_Simple_yet_Effective_Agent_Framework_for_Complex_Real_world_Reasoning/2024-07-15-Sibyl_Simple_yet_Effective_Agent_Framework_for_Complex_Real_world_Reasoning.html#appendix",
    "title": "Sibyl: Simple yet Effective Agent Framework for Complex Real-world Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-16\n\n\nAbstract\nhttps://arxiv.org/abs/2407.10718v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.10718v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6597"
  },
  {
    "objectID": "posts/Specify_and_Edit_Overcoming_Ambiguity_in_Text_Based_Image_Editing/2024-07-29-Specify_and_Edit_Overcoming_Ambiguity_in_Text_Based_Image_Editing.html",
    "href": "posts/Specify_and_Edit_Overcoming_Ambiguity_in_Text_Based_Image_Editing/2024-07-29-Specify_and_Edit_Overcoming_Ambiguity_in_Text_Based_Image_Editing.html",
    "title": "Specify and Edit: Overcoming Ambiguity in Text-Based Image Editing",
    "section": "",
    "text": "Summary:\nThe paper “Specify and Edit: Overcoming Ambiguity in Text-Based Image Editing” proposes a novel zero-shot inference pipeline called SANE (Specify ANd Edit) to improve the performance of diffusion-based text-to-image editing methods with ambiguous instructions. SANE leverages a large language model (LLM) to decompose ambiguous instructions into specific interventions, enhancing both interpretability and editing quality. The experiments conducted on two datasets demonstrate consistent performance improvements and increased output diversity. SANE is also versatile and can benefit both ambiguous and clear editing tasks.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a promising approach to addressing the limitations of diffusion-based text-to-image editing methods with ambiguous instructions. The use of a large language model to decompose ambiguous instructions into specific interventions is a novel and effective approach. The experiments conducted on two datasets demonstrate the effectiveness of SANE in improving editing quality and output diversity. However, the paper does not discuss the limitations of SANE, such as the difficulty in handling a high number of specific instructions and the lack of guarantee that each specific instruction is actually applied. Additionally, the paper does not provide a comparison with other methods that address ambiguity in text-based image editing. Overall, the paper presents a promising approach to addressing the limitations of diffusion-based text-to-image editing methods with ambiguous instructions."
  },
  {
    "objectID": "posts/Specify_and_Edit_Overcoming_Ambiguity_in_Text_Based_Image_Editing/2024-07-29-Specify_and_Edit_Overcoming_Ambiguity_in_Text_Based_Image_Editing.html#appendix",
    "href": "posts/Specify_and_Edit_Overcoming_Ambiguity_in_Text_Based_Image_Editing/2024-07-29-Specify_and_Edit_Overcoming_Ambiguity_in_Text_Based_Image_Editing.html#appendix",
    "title": "Specify and Edit: Overcoming Ambiguity in Text-Based Image Editing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.20232v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.20232v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17437"
  },
  {
    "objectID": "posts/Generating_Query_Recommendations_via_LLMs/2024-05-30-Generating_Query_Recommendations_via_LLMs.html#appendix",
    "href": "posts/Generating_Query_Recommendations_via_LLMs/2024-05-30-Generating_Query_Recommendations_via_LLMs.html#appendix",
    "title": "Generating Query Recommendations via LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2405.19749v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.19749v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1852"
  },
  {
    "objectID": "posts/LEXI_Large_Language_Models_Experimentation_Interface/2024-07-02-LEXI_Large_Language_Models_Experimentation_Interface.html#appendix",
    "href": "posts/LEXI_Large_Language_Models_Experimentation_Interface/2024-07-02-LEXI_Large_Language_Models_Experimentation_Interface.html#appendix",
    "title": "LEXI: Large Language Models Experimentation Interface",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01488v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01488v2\n\n\nTruncated\nFalse\n\n\nWord Count\n8957"
  },
  {
    "objectID": "posts/Interpretable_Catastrophic_Forgetting_of_Large_Language_Model_Fine_tuning_via_Instruction_Vector/2024-06-18-Interpretable_Catastrophic_Forgetting_of_Large_Language_Model_Fine_tuning_via_Instruction_Vector.html#appendix",
    "href": "posts/Interpretable_Catastrophic_Forgetting_of_Large_Language_Model_Fine_tuning_via_Instruction_Vector/2024-06-18-Interpretable_Catastrophic_Forgetting_of_Large_Language_Model_Fine_tuning_via_Instruction_Vector.html#appendix",
    "title": "Interpretable Catastrophic Forgetting of Large Language Model Fine-tuning via Instruction Vector",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.12227v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.12227v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8412"
  },
  {
    "objectID": "posts/Towards_Next_Era_of_Multi_objective_Optimization_Large_Language_Models_as_Architects_of_Evolutionary_Operators/2024-06-13-Towards_Next_Era_of_Multi_objective_Optimization_Large_Language_Models_as_Architects_of_Evolutionary_Operators.html#appendix",
    "href": "posts/Towards_Next_Era_of_Multi_objective_Optimization_Large_Language_Models_as_Architects_of_Evolutionary_Operators/2024-06-13-Towards_Next_Era_of_Multi_objective_Optimization_Large_Language_Models_as_Architects_of_Evolutionary_Operators.html#appendix",
    "title": "Towards Next Era of Multi-objective Optimization: Large Language Models as Architects of Evolutionary Operators",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.08987v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.08987v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8531"
  },
  {
    "objectID": "posts/What_Affects_the_Stability_of_Tool_Learning_An_Empirical_Study_on_the_Robustness_of_Tool_Learning_Frameworks/2024-07-03-What_Affects_the_Stability_of_Tool_Learning_An_Empirical_Study_on_the_Robustness_of_Tool_Learning_Frameworks.html#appendix",
    "href": "posts/What_Affects_the_Stability_of_Tool_Learning_An_Empirical_Study_on_the_Robustness_of_Tool_Learning_Frameworks/2024-07-03-What_Affects_the_Stability_of_Tool_Learning_An_Empirical_Study_on_the_Robustness_of_Tool_Learning_Frameworks.html#appendix",
    "title": "What Affects the Stability of Tool Learning? An Empirical Study on the Robustness of Tool Learning Frameworks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03007v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03007v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2525"
  },
  {
    "objectID": "posts/Improving_Conversational_Abilities_of_Quantized_Large_Language_Models_via_Direct_Preference_Alignment/2024-07-03-Improving_Conversational_Abilities_of_Quantized_Large_Language_Models_via_Direct_Preference_Alignment.html#appendix",
    "href": "posts/Improving_Conversational_Abilities_of_Quantized_Large_Language_Models_via_Direct_Preference_Alignment/2024-07-03-Improving_Conversational_Abilities_of_Quantized_Large_Language_Models_via_Direct_Preference_Alignment.html#appendix",
    "title": "Improving Conversational Abilities of Quantized Large Language Models via Direct Preference Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.03051v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.03051v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9273"
  },
  {
    "objectID": "posts/GraphReader_Building_Graph_based_Agent_to_Enhance_Long_Context_Abilities_of_Large_Language_Models/2024-06-20-GraphReader_Building_Graph_based_Agent_to_Enhance_Long_Context_Abilities_of_Large_Language_Models.html#appendix",
    "href": "posts/GraphReader_Building_Graph_based_Agent_to_Enhance_Long_Context_Abilities_of_Large_Language_Models/2024-06-20-GraphReader_Building_Graph_based_Agent_to_Enhance_Long_Context_Abilities_of_Large_Language_Models.html#appendix",
    "title": "GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.14550v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.14550v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7927"
  },
  {
    "objectID": "posts/IDA_Breaking_Barriers_in_No_code_UI_Automation_Through_Large_Language_Models_and_Human_Centric_Design/2024-07-23-IDA_Breaking_Barriers_in_No_code_UI_Automation_Through_Large_Language_Models_and_Human_Centric_Design.html#appendix",
    "href": "posts/IDA_Breaking_Barriers_in_No_code_UI_Automation_Through_Large_Language_Models_and_Human_Centric_Design/2024-07-23-IDA_Breaking_Barriers_in_No_code_UI_Automation_Through_Large_Language_Models_and_Human_Centric_Design.html#appendix",
    "title": "IDA: Breaking Barriers in No-code UI Automation Through Large Language Models and Human-Centric Design",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.15673v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.15673v2\n\n\nTruncated\nFalse\n\n\nWord Count\n8577"
  },
  {
    "objectID": "posts/Beyond_Numeric_Awards_In_Context_Dueling_Bandits_with_LLM_Agents/2024-07-02-Beyond_Numeric_Awards_In_Context_Dueling_Bandits_with_LLM_Agents.html",
    "href": "posts/Beyond_Numeric_Awards_In_Context_Dueling_Bandits_with_LLM_Agents/2024-07-02-Beyond_Numeric_Awards_In_Context_Dueling_Bandits_with_LLM_Agents.html",
    "title": "Beyond Numeric Awards: In-Context Dueling Bandits with LLM Agents",
    "section": "",
    "text": "Summary:\nThis paper investigates the performance of Large Language Models (LLMs) as decision-makers in the context of Dueling Bandits (DB). The study compares GPT-3.5 Turbo, GPT-4, and GPT-4 Turbo against established DB algorithms. The results reveal that LLMs, particularly GPT-4 Turbo, quickly identify the Condorcet winner, outperforming existing state-of-the-art algorithms in terms of weak regret. However, LLMs struggle to converge even when explicitly prompted to do so and are sensitive to prompt variations. To overcome these issues, the paper introduces an LLM-augmented algorithm, IF-Enhanced LLM, which combines the in-context decision-making capabilities of LLMs and theoretical guarantees inherited from classic DB algorithms. The proposed algorithm has theoretical guarantees on both weak and strong regret and is robust even with noisy and adversarial prompts.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an interesting approach to using LLMs in the context of DB. The findings that LLMs can quickly identify the Condorcet winner are promising, but the lack of convergence and sensitivity to prompt variations are limitations that need to be addressed. The proposed LLM-augmented algorithm, IF-Enhanced LLM, is a step in the right direction, as it combines the strengths of LLMs and classic DB algorithms. However, the robustness of this algorithm to noisy and adversarial prompts needs to be further validated in different scenarios and with different types of LLMs. Additionally,"
  },
  {
    "objectID": "posts/Beyond_Numeric_Awards_In_Context_Dueling_Bandits_with_LLM_Agents/2024-07-02-Beyond_Numeric_Awards_In_Context_Dueling_Bandits_with_LLM_Agents.html#appendix",
    "href": "posts/Beyond_Numeric_Awards_In_Context_Dueling_Bandits_with_LLM_Agents/2024-07-02-Beyond_Numeric_Awards_In_Context_Dueling_Bandits_with_LLM_Agents.html#appendix",
    "title": "Beyond Numeric Awards: In-Context Dueling Bandits with LLM Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-09\n\n\nAbstract\nhttps://arxiv.org/abs/2407.01887v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.01887v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11940"
  },
  {
    "objectID": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#major-findings",
    "href": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#major-findings",
    "title": "World Models with Hints of Large Language Models for Goal Achieving",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nDLLM integrates hinting subgoals from LLMs into the model rollouts to encourage goal discovery and reaching in challenging tasks.\nDLLM assigns higher intrinsic rewards to samples that align with the hints outlined by the language model during model rollouts.\nDLLM outperforms recent methods in various challenging, sparse-reward environments such as HomeGrid, Crafter, and Minecraft."
  },
  {
    "objectID": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#analysis-and-critique",
    "href": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#analysis-and-critique",
    "title": "World Models with Hints of Large Language Models for Goal Achieving",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents an innovative approach to addressing the challenges of long-horizon tasks and sparse rewards in RL. The use of LLMs to provide hinting subgoals is a promising direction for improving exploration and goal-reaching in complex environments. However, the paper does not discuss potential limitations or biases in the LLMs used, which could impact the performance of DLLM. Additionally, the paper does not provide a detailed comparison with other methods that use intrinsic rewards or LLMs for goal-setting. Further research is needed to evaluate the robustness and generalizability of DLLM in different environments and tasks."
  },
  {
    "objectID": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#appendix",
    "href": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#appendix",
    "title": "World Models with Hints of Large Language Models for Goal Achieving",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07381v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07381v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10623"
  },
  {
    "objectID": "posts/Every_Language_Counts_Learn_and_Unlearn_in_Multilingual_LLMs/2024-06-19-Every_Language_Counts_Learn_and_Unlearn_in_Multilingual_LLMs.html#appendix",
    "href": "posts/Every_Language_Counts_Learn_and_Unlearn_in_Multilingual_LLMs/2024-06-19-Every_Language_Counts_Learn_and_Unlearn_in_Multilingual_LLMs.html#appendix",
    "title": "Every Language Counts: Learn and Unlearn in Multilingual LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13748v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13748v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5047"
  },
  {
    "objectID": "posts/DR_RAG_Applying_Dynamic_Document_Relevance_to_Retrieval_Augmented_Generation_for_Question_Answering/2024-06-11-DR_RAG_Applying_Dynamic_Document_Relevance_to_Retrieval_Augmented_Generation_for_Question_Answering.html#appendix",
    "href": "posts/DR_RAG_Applying_Dynamic_Document_Relevance_to_Retrieval_Augmented_Generation_for_Question_Answering/2024-06-11-DR_RAG_Applying_Dynamic_Document_Relevance_to_Retrieval_Augmented_Generation_for_Question_Answering.html#appendix",
    "title": "DR-RAG: Applying Dynamic Document Relevance to Retrieval-Augmented Generation for Question-Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07348v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07348v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6121"
  },
  {
    "objectID": "posts/Hierarchical_Micro_Segmentations_for_Zero_Trust_Services_via_Large_Language_Model_(LLM)_enhanced_Graph_Diffusion/2024-06-20-Hierarchical_Micro_Segmentations_for_Zero_Trust_Services_via_Large_Language_Model_(LLM)_enhanced_Graph_Diffusion.html#appendix",
    "href": "posts/Hierarchical_Micro_Segmentations_for_Zero_Trust_Services_via_Large_Language_Model_(LLM)_enhanced_Graph_Diffusion/2024-06-20-Hierarchical_Micro_Segmentations_for_Zero_Trust_Services_via_Large_Language_Model_(LLM)_enhanced_Graph_Diffusion.html#appendix",
    "title": "Hierarchical Micro-Segmentations for Zero-Trust Services via Large Language Model (LLM)-enhanced Graph Diffusion",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.13964v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.13964v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11153"
  },
  {
    "objectID": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#major-findings",
    "href": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#major-findings",
    "title": "SemCoder: Training Code Language Models with Comprehensive Semantics",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe paper introduces a novel strategy to train Code LLMs with comprehensive semantics, including high-level functional descriptions, local execution effects of individual statements, and overall input/output behavior.\nThe authors propose training Code LLMs to write code and represent and reason about execution behaviors using natural language, mimicking human verbal debugging.\nThe paper presents SEMCODER, a Code LLM with only 6.7B parameters, which shows competitive performance with GPT-3.5-turbo on code generation and execution reasoning tasks.\nSEMCODER achieves 81.1% on HumanEval (GPT-3.5-turbo: 76.8%) and 54.5% on CRUXEval-I (GPT-3.5-turbo: 50.3%).\nThe paper also studies the effectiveness of SEMCODER’s monologue-style execution reasoning compared to concrete scratchpad reasoning, showing that their approach integrates semantics from multiple dimensions more smoothly."
  },
  {
    "objectID": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#analysis-and-critique",
    "href": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#analysis-and-critique",
    "title": "SemCoder: Training Code Language Models with Comprehensive Semantics",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a novel approach to training Code LLMs with comprehensive semantics, which has the potential to improve the performance of Code LLMs on code generation and execution reasoning tasks. The authors’ proposal to train Code LLMs to write code and represent and reason about execution behaviors using natural language is an interesting and promising direction.\nHowever, the paper does not provide a detailed comparison of SEMCODER with other state-of-the-art Code LLMs, which makes it difficult to evaluate the effectiveness of their approach. Additionally, the"
  },
  {
    "objectID": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#appendix",
    "href": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#appendix",
    "title": "SemCoder: Training Code Language Models with Comprehensive Semantics",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-23\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01006v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01006v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18724"
  },
  {
    "objectID": "posts/Large_Language_Models_in_Student_Assessment_Comparing_ChatGPT_and_Human_Graders/2024-06-24-Large_Language_Models_in_Student_Assessment_Comparing_ChatGPT_and_Human_Graders.html#appendix",
    "href": "posts/Large_Language_Models_in_Student_Assessment_Comparing_ChatGPT_and_Human_Graders/2024-06-24-Large_Language_Models_in_Student_Assessment_Comparing_ChatGPT_and_Human_Graders.html#appendix",
    "title": "Large Language Models in Student Assessment: Comparing ChatGPT and Human Graders",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16510v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16510v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9017"
  },
  {
    "objectID": "posts/Knowledge_Mechanisms_in_Large_Language_Models_A_Survey_and_Perspective/2024-07-22-Knowledge_Mechanisms_in_Large_Language_Models_A_Survey_and_Perspective.html",
    "href": "posts/Knowledge_Mechanisms_in_Large_Language_Models_A_Survey_and_Perspective/2024-07-22-Knowledge_Mechanisms_in_Large_Language_Models_A_Survey_and_Perspective.html",
    "title": "Knowledge Mechanisms in Large Language Models: A Survey and Perspective",
    "section": "",
    "text": "Summary:\nThis paper reviews the knowledge mechanisms in Large Language Models (LLMs) and proposes a novel taxonomy across the entire life cycle of LLMs. The taxonomy encompasses knowledge utilization at a specific time and knowledge evolution across all periods of LLMs. The paper introduces preliminaries of this field and reviews knowledge utilization mechanisms from a new perspective. It also delves into the fundamental principles for knowledge evolution and discusses challenges of knowledge utilization, and posits some promising hypotheses to explore potential avenues for developing powerful and trustworthy models. The paper also provides some future directions and tools for knowledge mechanism analysis.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive review of the knowledge mechanisms in LLMs and proposes a novel taxonomy for knowledge mechanisms in LLMs. The paper introduces a new perspective to analyze knowledge utilization mechanisms from three levels: memorization, comprehension and application, and creation. The paper also discusses knowledge evolution in individual and group LLMs, and analyzes the inherent conflicts and integration in this process. However, the paper does not provide empirical evidence to support its hypotheses and does not discuss the limitations of its proposed taxonomy. The paper also does not discuss the ethical implications of its proposed taxonomy."
  },
  {
    "objectID": "posts/Knowledge_Mechanisms_in_Large_Language_Models_A_Survey_and_Perspective/2024-07-22-Knowledge_Mechanisms_in_Large_Language_Models_A_Survey_and_Perspective.html#appendix",
    "href": "posts/Knowledge_Mechanisms_in_Large_Language_Models_A_Survey_and_Perspective/2024-07-22-Knowledge_Mechanisms_in_Large_Language_Models_A_Survey_and_Perspective.html#appendix",
    "title": "Knowledge Mechanisms in Large Language Models: A Survey and Perspective",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-30\n\n\nAbstract\nhttps://arxiv.org/abs/2407.15017v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2407.15017v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18185"
  },
  {
    "objectID": "posts/ShadowLLM_Predictor_based_Contextual_Sparsity_for_Large_Language_Models/2024-06-24-ShadowLLM_Predictor_based_Contextual_Sparsity_for_Large_Language_Models.html#appendix",
    "href": "posts/ShadowLLM_Predictor_based_Contextual_Sparsity_for_Large_Language_Models/2024-06-24-ShadowLLM_Predictor_based_Contextual_Sparsity_for_Large_Language_Models.html#appendix",
    "title": "ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-07-07\n\n\nAbstract\nhttps://arxiv.org/abs/2406.16635v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.16635v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6242"
  }
]