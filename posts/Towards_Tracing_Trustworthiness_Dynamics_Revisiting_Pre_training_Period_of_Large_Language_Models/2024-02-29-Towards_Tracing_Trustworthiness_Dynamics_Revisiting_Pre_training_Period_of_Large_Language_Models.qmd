
---
title: "Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models"
id: "2402.19465v1"
description: "Exploring Large Language Models' Trustworthiness during Pre-training: A First Step."
author: Chen Qian, Jie Zhang, Wei Yao, Dongrui Liu, Zhenfei Yin, Yu Qiao, Yong Liu, Jing Shao
date: "2024-02-29"
image: "https://browse.arxiv.org/html/2402.19465v1/x1.png"
categories: ['production', 'architectures']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.19465v1/x1.png)

### Tracing Trustworthiness Dynamics in Large Language Models Pre-training

**Summary:**

- This study explores the trustworthiness of large language models (LLMs) during the pre-training phase, focusing on five dimensions: reliability, privacy, toxicity, fairness, and robustness.
- Linear probing is applied to LLMs, revealing that they can distinguish concepts in each trustworthiness dimension early in pre-training.
- Steering vectors are extracted from LLMs' pre-training checkpoints to enhance their trustworthiness.
- Mutual information probing during pre-training uncovers a two-phase phenomenon: fitting and compression.

**Major Findings:**

1. LLMs in early pre-training can already distinguish concepts in trustworthiness dimensions through linear probing.
2. Steering vectors extracted from pre-training checkpoints can enhance the LLM's trustworthiness

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x7b-instruct       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.19465v1](https://arxiv.org/abs/2402.19465v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.19465v1](https://browse.arxiv.org/html/2402.19465v1)       |
| Truncated       | False       |
| Word Count       | 10553       |