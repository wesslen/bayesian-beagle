
---
title: "Vision-LLMs Can Fool Themselves with Self-Generated Typographic Attacks"
id: "2402.00626v1"
description: "LVLMs vulnerable to typographic attacks; new benchmark and self-generated attacks more effective."
author: Maan Qraitem, Nazia Tasnim, Kate Saenko, Bryan A. Plummer
date: "2024-02-01"
image: "../../img/2402.00626v1/image_1.png"
categories: ['architectures', 'robustness', 'security', 'production']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.00626v1/image_1.png)

### **Summary:**
- Large Vision-Language Models (LVLMs) are vulnerable to typographic attacks, which involve superimposing misleading text onto an image.
- The vulnerability of LVLMs to typographic attacks remains unstudied, and prior work attacks may not be the most effective.
- The authors introduce a novel benchmark to test LVLMs' vulnerability to typographic attacks and a new and more effective typographic attack: Self-Generated typographic attacks.

### **Major Findings:**
1. Typographic attacks represent a significant threat against LVLM(s).
2. Typographic attacks recommended by GPT-4V using the new method are more effective against GPT-4V itself compared to prior work attacks and against other open-source models like LLaVA, InstructBLIP, and MiniGPT4.
3. Self-Generated typographic attacks are more effective at reducing LVLM(s) performance compared to prior work attacks.

### **Analysis and Critique:**
- The study introduces a novel benchmark to test LVLMs' vulnerability to typographic attacks, addressing an important gap in the literature.
- The introduction of Self-Generated typographic attacks provides a more effective method for misleading LVLMs, highlighting the need for improved security measures.
- The study demonstrates the susceptibility of LVLMs to typographic attacks, raising concerns about the robustness of these models in real-world applications.
- The findings suggest that further research is needed to develop defense mechanisms against typographic attacks for LVLMs, as these attacks pose a significant threat to their performance and reliability.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-26       |
| Abstract | [https://arxiv.org/abs/2402.00626v1](https://arxiv.org/abs/2402.00626v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.00626v1](https://browse.arxiv.org/html/2402.00626v1)       |
| Truncated       | False       |
| Word Count       | 5468       |