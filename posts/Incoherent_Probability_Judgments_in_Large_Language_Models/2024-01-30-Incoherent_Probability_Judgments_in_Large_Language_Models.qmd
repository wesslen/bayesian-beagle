
---
title: "Incoherent Probability Judgments in Large Language Models"
id: "2401.16646v1"
description: "LLMs excel at text generation but struggle with coherent probability judgments, showing human-like biases."
author: Jian-Qiao Zhu, Thomas L. Griffiths
date: "2024-01-30"
image: "https://browse.arxiv.org/html/2401.16646v1/x1.png"
categories: ['social-sciences', 'hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.16646v1/x1.png)

### **Summary:**
The article evaluates the coherence of probability judgments made by Large Language Models (LLMs) and compares them to human probability judgments. The study finds that LLMs often produce incoherent probability judgments, displaying systematic deviations from the rules of probability theory. The mean-variance relationship of probability judgments produced by LLMs shows an inverted-U-shaped pattern, similar to that seen in humans. The article proposes that these deviations from rationality can be explained by linking autoregressive LLMs to implicit Bayesian inference and drawing parallels with the Bayesian Sampler model of human probability judgments.

### Major Findings:
1. Large Language Models (LLMs) exhibit incoherent probability judgments, displaying human-like systematic deviations from the rules of probability theory.
2. The mean-variance relationship of probability judgments produced by LLMs shows an inverted-U-shaped pattern, similar to that seen in humans.
3. The study found that LLMs exhibit shared patterns of incoherence with humans, suggesting underlying mechanisms employed by LLMs in the formation of probability judgments.

### Analysis and Critique:
The article provides valuable insights into the coherence of probability judgments in Large Language Models (LLMs) and their comparison to human judgments. However, the study does not address potential biases or limitations in the evaluation of LLMs' probability judgments. Additionally, the proposed explanation for the observed patterns in LLMs' probability judgments, linking autoregressive processes to implicit Bayesian inference, requires further empirical validation. The article suggests a novel approach for enhancing the accuracy of probability outputs generated by AI systems, but the practical implications and feasibility of recalibrating incoherent judgments need to be explored in future research. Overall, the study contributes to understanding the interplay between computational-level objectives and algorithmic-level execution in artificial and natural cognitive processes, highlighting the complementary nature of Bayesian and neural network models in understanding machine and human intelligence.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2401.16646v1](https://arxiv.org/abs/2401.16646v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.16646v1](https://browse.arxiv.org/html/2401.16646v1)       |
| Truncated       | False       |
| Word Count       | 4802       |