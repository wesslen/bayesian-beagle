[
  {
    "objectID": "posts/MBBQ_A_Dataset_for_Cross_Lingual_Comparison_of_Stereotypes_in_Generative_LLMs/2024-06-11-MBBQ_A_Dataset_for_Cross_Lingual_Comparison_of_Stereotypes_in_Generative_LLMs.html#appendix",
    "href": "posts/MBBQ_A_Dataset_for_Cross_Lingual_Comparison_of_Stereotypes_in_Generative_LLMs/2024-06-11-MBBQ_A_Dataset_for_Cross_Lingual_Comparison_of_Stereotypes_in_Generative_LLMs.html#appendix",
    "title": "MBBQ: A Dataset for Cross-Lingual Comparison of Stereotypes in Generative LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07243v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07243v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10630"
  },
  {
    "objectID": "posts/How_Efficient_is_LLM_Generated_Code_A_Rigorous__High_Standard_Benchmark/2024-06-10-How_Efficient_is_LLM_Generated_Code_A_Rigorous__High_Standard_Benchmark.html#appendix",
    "href": "posts/How_Efficient_is_LLM_Generated_Code_A_Rigorous__High_Standard_Benchmark/2024-06-10-How_Efficient_is_LLM_Generated_Code_A_Rigorous__High_Standard_Benchmark.html#appendix",
    "title": "How Efficient is LLM-Generated Code? A Rigorous & High-Standard Benchmark",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06647v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06647v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8226"
  },
  {
    "objectID": "posts/Exploring_Large_Language_Models_for_Relevance_Judgments_in_Tetun/2024-06-11-Exploring_Large_Language_Models_for_Relevance_Judgments_in_Tetun.html#appendix",
    "href": "posts/Exploring_Large_Language_Models_for_Relevance_Judgments_in_Tetun/2024-06-11-Exploring_Large_Language_Models_for_Relevance_Judgments_in_Tetun.html#appendix",
    "title": "Exploring Large Language Models for Relevance Judgments in Tetun",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07299v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07299v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3697"
  },
  {
    "objectID": "posts/A_Survey_of_Backdoor_Attacks_and_Defenses_on_Large_Language_Models_Implications_for_Security_Measures/2024-06-10-A_Survey_of_Backdoor_Attacks_and_Defenses_on_Large_Language_Models_Implications_for_Security_Measures.html#appendix",
    "href": "posts/A_Survey_of_Backdoor_Attacks_and_Defenses_on_Large_Language_Models_Implications_for_Security_Measures/2024-06-10-A_Survey_of_Backdoor_Attacks_and_Defenses_on_Large_Language_Models_Implications_for_Security_Measures.html#appendix",
    "title": "A Survey of Backdoor Attacks and Defenses on Large Language Models: Implications for Security Measures",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06852v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06852v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9560"
  },
  {
    "objectID": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#major-findings",
    "href": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#major-findings",
    "title": "Teaching Language Models to Self-Improve by Learning from Language Feedback",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nSRT significantly outperforms strong baselines across diverse tasks and model sizes, with an average performance enhancement of 3.7 to 4.0 points.\nWhen applied to a 70B parameter model, SRT increases the win rate from 9.6% to 25.8% on the AlpacaEval 2.0 benchmark, surpassing well-established systems such as GPT-4-0314, Claude 2, and Gemini.\nThe success of SRT primarily stems from its language feedback feature, which identifies weak areas and offers valuable suggestions for improvement."
  },
  {
    "objectID": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#analysis-and-critique",
    "href": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#analysis-and-critique",
    "title": "Teaching Language Models to Self-Improve by Learning from Language Feedback",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper presents a novel and promising approach to aligning language models using self-refinement and language feedback.\nThe empirical evaluations demonstrate the effectiveness of SRT in improving model performance across various tasks and model sizes.\nThe paper highlights the crucial role of language feedback in the success of SRT, suggesting potential for further exploration in this direction.\nHowever, the paper does not discuss potential limitations or challenges associated with the SRT method, such as the computational cost of generating feedback and refinements or the potential for overfitting to the feedback.\nAdditionally, the paper does not address the potential for biases in the feedback and refinements generated by the more advanced model, which could impact the alignment of the base model.\nFuture work could explore these limitations and potential solutions to improve the SRT method."
  },
  {
    "objectID": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#appendix",
    "href": "posts/Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback/2024-06-11-Teaching_Language_Models_to_Self_Improve_by_Learning_from_Language_Feedback.html#appendix",
    "title": "Teaching Language Models to Self-Improve by Learning from Language Feedback",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07168v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07168v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6361"
  },
  {
    "objectID": "posts/Chain_of_Agents_Large_Language_Models_Collaborating_on_Long_Context_Tasks/2024-06-04-Chain_of_Agents_Large_Language_Models_Collaborating_on_Long_Context_Tasks.html#appendix",
    "href": "posts/Chain_of_Agents_Large_Language_Models_Collaborating_on_Long_Context_Tasks/2024-06-04-Chain_of_Agents_Large_Language_Models_Collaborating_on_Long_Context_Tasks.html#appendix",
    "title": "Chain of Agents: Large Language Models Collaborating on Long-Context Tasks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02818v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02818v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6877"
  },
  {
    "objectID": "posts/iMotion_LLM_Motion_Prediction_Instruction_Tuning/2024-06-10-iMotion_LLM_Motion_Prediction_Instruction_Tuning.html#appendix",
    "href": "posts/iMotion_LLM_Motion_Prediction_Instruction_Tuning/2024-06-10-iMotion_LLM_Motion_Prediction_Instruction_Tuning.html#appendix",
    "title": "iMotion-LLM: Motion Prediction Instruction Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06211v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06211v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5777"
  },
  {
    "objectID": "posts/Advancing_Tool_Augmented_Large_Language_Models_Integrating_Insights_from_Errors_in_Inference_Trees/2024-06-11-Advancing_Tool_Augmented_Large_Language_Models_Integrating_Insights_from_Errors_in_Inference_Trees.html#appendix",
    "href": "posts/Advancing_Tool_Augmented_Large_Language_Models_Integrating_Insights_from_Errors_in_Inference_Trees/2024-06-11-Advancing_Tool_Augmented_Large_Language_Models_Integrating_Insights_from_Errors_in_Inference_Trees.html#appendix",
    "title": "Advancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07115v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07115v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6467"
  },
  {
    "objectID": "posts/How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States/2024-06-09-How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States.html",
    "href": "posts/How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States/2024-06-09-How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States.html",
    "title": "How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States",
    "section": "",
    "text": "Summary:\nThis paper explores how alignment and jailbreak work in large language models (LLMs) by using weak classifiers to explain LLM safety through intermediate hidden states. The authors confirm that LLMs learn ethical concepts during pre-training rather than alignment and can identify malicious and normal inputs in the early layers. Alignment associates the early concepts with emotion guesses in the middle layers and then refines them to specific reject tokens for safe generations. Jailbreak disturbs the transformation of early unethical classification into negative emotions. The paper conducts experiments on models from 7B to 70B across various model families to prove their conclusion.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a novel perspective on LLM safety by explaining how alignment and jailbreak work through intermediate hidden states. The use of weak classifiers to explain LLM safety is an innovative approach that could be applied to other aspects of LLM behavior. However, the paper does not discuss the limitations of using weak classifiers or the potential biases that may be introduced. Additionally, the paper does not address the potential risks of jailbreak, such as the generation of harmful content, and how these risks can be mitigated. Overall, the paper provides valuable insights into LLM safety and offers a new perspective on how alignment and jailbreak work."
  },
  {
    "objectID": "posts/How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States/2024-06-09-How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States.html#appendix",
    "href": "posts/How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States/2024-06-09-How_Alignment_and_Jailbreak_Work_Explain_LLM_Safety_through_Intermediate_Hidden_States.html#appendix",
    "title": "How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05644v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05644v1\n\n\nTruncated\nFalse\n\n\nWord Count\n19114"
  },
  {
    "objectID": "posts/Enhancing_Repository_Level_Code_Generation_with_Integrated_Contextual_Information/2024-06-05-Enhancing_Repository_Level_Code_Generation_with_Integrated_Contextual_Information.html#appendix",
    "href": "posts/Enhancing_Repository_Level_Code_Generation_with_Integrated_Contextual_Information/2024-06-05-Enhancing_Repository_Level_Code_Generation_with_Integrated_Contextual_Information.html#appendix",
    "title": "Enhancing Repository-Level Code Generation with Integrated Contextual Information",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03283v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03283v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9447"
  },
  {
    "objectID": "posts/M2CVD_Multi_Model_Collaboration_for_Code_Vulnerability_Detection/2024-06-10-M2CVD_Multi_Model_Collaboration_for_Code_Vulnerability_Detection.html#appendix",
    "href": "posts/M2CVD_Multi_Model_Collaboration_for_Code_Vulnerability_Detection/2024-06-10-M2CVD_Multi_Model_Collaboration_for_Code_Vulnerability_Detection.html#appendix",
    "title": "M2CVD: Multi-Model Collaboration for Code Vulnerability Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05940v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05940v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9185"
  },
  {
    "objectID": "posts/Accessing_GPT_4_level_Mathematical_Olympiad_Solutions_via_Monte_Carlo_Tree_Self_refine_with_LLaMa_3_8B/2024-06-11-Accessing_GPT_4_level_Mathematical_Olympiad_Solutions_via_Monte_Carlo_Tree_Self_refine_with_LLaMa_3_8B.html#appendix",
    "href": "posts/Accessing_GPT_4_level_Mathematical_Olympiad_Solutions_via_Monte_Carlo_Tree_Self_refine_with_LLaMa_3_8B/2024-06-11-Accessing_GPT_4_level_Mathematical_Olympiad_Solutions_via_Monte_Carlo_Tree_Self_refine_with_LLaMa_3_8B.html#appendix",
    "title": "Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07394v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07394v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5818"
  },
  {
    "objectID": "posts/VersiCode_Towards_Version_controllable_Code_Generation/2024-06-11-VersiCode_Towards_Version_controllable_Code_Generation.html#appendix",
    "href": "posts/VersiCode_Towards_Version_controllable_Code_Generation/2024-06-11-VersiCode_Towards_Version_controllable_Code_Generation.html#appendix",
    "title": "VersiCode: Towards Version-controllable Code Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07411v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07411v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6957"
  },
  {
    "objectID": "posts/Efficiently_Exploring_Large_Language_Models_for_Document_Level_Machine_Translation_with_In_context_Learning/2024-06-11-Efficiently_Exploring_Large_Language_Models_for_Document_Level_Machine_Translation_with_In_context_Learning.html#appendix",
    "href": "posts/Efficiently_Exploring_Large_Language_Models_for_Document_Level_Machine_Translation_with_In_context_Learning/2024-06-11-Efficiently_Exploring_Large_Language_Models_for_Document_Level_Machine_Translation_with_In_context_Learning.html#appendix",
    "title": "Efficiently Exploring Large Language Models for Document-Level Machine Translation with In-context Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07081v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07081v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6243"
  },
  {
    "objectID": "posts/Towards_more_realistic_evaluation_of_LLM_based_code_generation_an_experimental_study_and_beyond/2024-06-11-Towards_more_realistic_evaluation_of_LLM_based_code_generation_an_experimental_study_and_beyond.html#appendix",
    "href": "posts/Towards_more_realistic_evaluation_of_LLM_based_code_generation_an_experimental_study_and_beyond/2024-06-11-Towards_more_realistic_evaluation_of_LLM_based_code_generation_an_experimental_study_and_beyond.html#appendix",
    "title": "Towards more realistic evaluation of LLM-based code generation: an experimental study and beyond",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06918v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06918v1\n\n\nTruncated\nFalse\n\n\nWord Count\n0"
  },
  {
    "objectID": "posts/QuickLLaMA_Query_aware_Inference_Acceleration_for_Large_Language_Models/2024-06-11-QuickLLaMA_Query_aware_Inference_Acceleration_for_Large_Language_Models.html#appendix",
    "href": "posts/QuickLLaMA_Query_aware_Inference_Acceleration_for_Large_Language_Models/2024-06-11-QuickLLaMA_Query_aware_Inference_Acceleration_for_Large_Language_Models.html#appendix",
    "title": "QuickLLaMA: Query-aware Inference Acceleration for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07528v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07528v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7459"
  },
  {
    "objectID": "posts/Benchmark_Data_Contamination_of_Large_Language_Models_A_Survey/2024-06-06-Benchmark_Data_Contamination_of_Large_Language_Models_A_Survey.html#appendix",
    "href": "posts/Benchmark_Data_Contamination_of_Large_Language_Models_A_Survey/2024-06-06-Benchmark_Data_Contamination_of_Large_Language_Models_A_Survey.html#appendix",
    "title": "Benchmark Data Contamination of Large Language Models: A Survey",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04244v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04244v1\n\n\nTruncated\nFalse\n\n\nWord Count\n13688"
  },
  {
    "objectID": "posts/Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities/2024-06-11-Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities.html",
    "href": "posts/Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities/2024-06-11-Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities.html",
    "title": "Toxic Memes: A Survey of Computational Perspectives on the Detection and Explanation of Meme Toxicities",
    "section": "",
    "text": "Summary:\nThis paper provides a comprehensive survey of 158 papers on computational perspectives on toxic memes, covering key developments up to early 2024. The study identifies a wide variety of terminology used to refer to toxic memes, highlighting the need for a clearer taxonomy and harmonized definitions. The authors introduce a novel taxonomy and offer insights into various dimensions of meme toxicity, including intent, target, and conveyance tactics. The paper also catalogs datasets containing toxic memes, analyzes prevalent challenges, and identifies emerging trends in computational approaches to toxic meme detection and interpretation. The survey aims to promote interdisciplinary collaboration and innovation to foster media literacy and a safer online ecosystem.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides a comprehensive survey of the literature on computational perspectives on toxic memes, offering valuable insights into the current state of the field. The introduction of a novel taxonomy and harmonized definitions is a significant contribution, as it addresses the need for a clearer taxonomy and harmonized definitions. The paper also identifies emerging trends in computational approaches to toxic meme detection and interpretation, which can guide future research in the field.\nHowever, the paper does not provide a critical analysis of the limitations and biases of the existing literature. Additionally, the paper does not discuss the potential ethical implications of using computational approaches to detect and interpret toxic memes. Future research should address these limitations and consider the ethical implications of using computational approaches to detect and interpret toxic"
  },
  {
    "objectID": "posts/Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities/2024-06-11-Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities.html#appendix",
    "href": "posts/Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities/2024-06-11-Toxic_Memes_A_Survey_of_Computational_Perspectives_on_the_Detection_and_Explanation_of_Meme_Toxicities.html#appendix",
    "title": "Toxic Memes: A Survey of Computational Perspectives on the Detection and Explanation of Meme Toxicities",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07353v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07353v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20322"
  },
  {
    "objectID": "posts/Instruct_Large_Language_Models_to_Drive_like_Humans/2024-06-11-Instruct_Large_Language_Models_to_Drive_like_Humans.html#appendix",
    "href": "posts/Instruct_Large_Language_Models_to_Drive_like_Humans/2024-06-11-Instruct_Large_Language_Models_to_Drive_like_Humans.html#appendix",
    "title": "Instruct Large Language Models to Drive like Humans",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07296v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07296v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5303"
  },
  {
    "objectID": "posts/A_Tool_for_Test_Case_Scenarios_Generation_Using_Large_Language_Models/2024-06-11-A_Tool_for_Test_Case_Scenarios_Generation_Using_Large_Language_Models.html#appendix",
    "href": "posts/A_Tool_for_Test_Case_Scenarios_Generation_Using_Large_Language_Models/2024-06-11-A_Tool_for_Test_Case_Scenarios_Generation_Using_Large_Language_Models.html#appendix",
    "title": "A Tool for Test Case Scenarios Generation Using Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07021v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07021v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3062"
  },
  {
    "objectID": "posts/Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents/2024-06-10-Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents.html",
    "href": "posts/Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents/2024-06-10-Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents.html",
    "title": "Transforming Wearable Data into Health Insights using Large Language Model Agents",
    "section": "",
    "text": "Summary: The paper presents a study on the Personal Health Insights Agent (PHIA), an AI model designed to answer personal health queries using wearable data. PHIA outperforms the Code Generation baseline by 14% (84% vs. 74%) in exact matching accuracy for objective personal health queries. In open-ended reasoning quality, PHIA demonstrates a significant advantage over the Code Generation baseline in all ratings except for personalization. Expert evaluation shows that PHIA has a significant advantage over the Code Generation baseline in overall code quality, avoiding hallucinations, and personalization. PHIA is also quantitatively less likely to generate code that raises an error.\nMajor Findings: 1. PHIA outperforms the Code Generation baseline by 14% in exact matching accuracy for objective personal health queries. 2. PHIA demonstrates a significant advantage over the Code Generation baseline in open-ended reasoning quality."
  },
  {
    "objectID": "posts/Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents/2024-06-10-Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents.html#appendix",
    "href": "posts/Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents/2024-06-10-Transforming_Wearable_Data_into_Health_Insights_using_Large_Language_Model_Agents.html#appendix",
    "title": "Transforming Wearable Data into Health Insights using Large Language Model Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06464v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06464v1\n\n\nTruncated\nTrue\n\n\nWord Count\n28809"
  },
  {
    "objectID": "posts/Do_LLMs_Recognize_me_When_I_is_not_me_Assessment_of_LLMs_Understanding_of_Turkish_Indexical_Pronouns_in_Indexical_Shift_Contexts/2024-06-08-Do_LLMs_Recognize_me_When_I_is_not_me_Assessment_of_LLMs_Understanding_of_Turkish_Indexical_Pronouns_in_Indexical_Shift_Contexts.html#appendix",
    "href": "posts/Do_LLMs_Recognize_me_When_I_is_not_me_Assessment_of_LLMs_Understanding_of_Turkish_Indexical_Pronouns_in_Indexical_Shift_Contexts/2024-06-08-Do_LLMs_Recognize_me_When_I_is_not_me_Assessment_of_LLMs_Understanding_of_Turkish_Indexical_Pronouns_in_Indexical_Shift_Contexts.html#appendix",
    "title": "Do LLMs Recognize me, When I is not me: Assessment of LLMs Understanding of Turkish Indexical Pronouns in Indexical Shift Contexts",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05569v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05569v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5917"
  },
  {
    "objectID": "posts/Progressive_Query_Expansion_for_Retrieval_Over_Cost_constrained_Data_Sources/2024-06-11-Progressive_Query_Expansion_for_Retrieval_Over_Cost_constrained_Data_Sources.html#appendix",
    "href": "posts/Progressive_Query_Expansion_for_Retrieval_Over_Cost_constrained_Data_Sources/2024-06-11-Progressive_Query_Expansion_for_Retrieval_Over_Cost_constrained_Data_Sources.html#appendix",
    "title": "Progressive Query Expansion for Retrieval Over Cost-constrained Data Sources",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07136v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07136v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4716"
  },
  {
    "objectID": "posts/Language_Models_are_Alignable_Decision_Makers_Dataset_and_Application_to_the_Medical_Triage_Domain/2024-06-10-Language_Models_are_Alignable_Decision_Makers_Dataset_and_Application_to_the_Medical_Triage_Domain.html#appendix",
    "href": "posts/Language_Models_are_Alignable_Decision_Makers_Dataset_and_Application_to_the_Medical_Triage_Domain/2024-06-10-Language_Models_are_Alignable_Decision_Makers_Dataset_and_Application_to_the_Medical_Triage_Domain.html#appendix",
    "title": "Language Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06435v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06435v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9086"
  },
  {
    "objectID": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#summary-1",
    "href": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#summary-1",
    "title": "Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining",
    "section": "Summary:",
    "text": "Summary:\n\nThe paper introduces a novel framework that combines context-aware retrieval-augmented generation with a prompt-based TTS system.\nThe proposed framework incorporates an innovative Context-Aware Contrastive Language-Audio Pre-training (CA-CLAP) model to extract context-aware, style-related textual features (STFs) under audio supervision.\nThe CA-CLAP model employs an audio encoder for extracting style embeddings from speech and a text encoder for deriving STFs from both the text and its context.\nThe framework also implements cross-attention mechanisms between textual and contextual features to enhance context integration.\nThe paper makes the following contributions: 1) proposing a RAG-enhanced prompt-based TTS framework to enhance audio prompt specialized selection, 2) designing a CA-CLAP model to extract textual and acoustic representations for retrieval, and 3) conducting extensive subjective and objective experiments to demonstrate the proposed methods’ superiority over baselines and the introduced CA-CLAP’s better results than text-only embedding methods."
  },
  {
    "objectID": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#major-findings",
    "href": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#major-findings",
    "title": "Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe proposed RAG-enhanced prompt-based TTS framework improves audio prompt specialized selection.\nThe CA-CLAP model effectively extracts context-aware, style-related textual features (STFs) under audio supervision.\nThe proposed methods outperform baselines, and the introduced CA-CLAP achieves better results than text-only embedding methods."
  },
  {
    "objectID": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#analysis-and-critique",
    "href": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#analysis-and-critique",
    "title": "Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper effectively addresses the challenge of selecting appropriate speech prompts by adapting the RAG concept to the speech domain.\nThe proposed framework incorporates an innovative CA-CLAP model to extract context-aware, style-related textual features (STFs) under audio supervision, which enhances the overall quality and relevance of the retrieved content.\nThe paper provides extensive subjective and objective experiments to demonstrate the proposed methods’ superiority over baselines and the introduced CA-CLAP’s better results than"
  },
  {
    "objectID": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#appendix",
    "href": "posts/Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining/2024-06-06-Retrieval_Augmented_Generation_in_Prompt_based_Text_to_Speech_Synthesis_with_Context_Aware_Contrastive_Language_Audio_Pretraining.html#appendix",
    "title": "Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03714v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03714v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3915"
  },
  {
    "objectID": "posts/Whats_in_an_embedding_Would_a_rose_by_any_embedding_smell_as_sweet/2024-06-11-Whats_in_an_embedding_Would_a_rose_by_any_embedding_smell_as_sweet.html#appendix",
    "href": "posts/Whats_in_an_embedding_Would_a_rose_by_any_embedding_smell_as_sweet/2024-06-11-Whats_in_an_embedding_Would_a_rose_by_any_embedding_smell_as_sweet.html#appendix",
    "title": "What’s in an embedding? Would a rose by any embedding smell as sweet?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06870v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06870v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5609"
  },
  {
    "objectID": "posts/Large_language_models_for_generating_rules_yay_or_nay/2024-06-10-Large_language_models_for_generating_rules_yay_or_nay.html#appendix",
    "href": "posts/Large_language_models_for_generating_rules_yay_or_nay/2024-06-10-Large_language_models_for_generating_rules_yay_or_nay.html#appendix",
    "title": "Large language models for generating rules, yay or nay?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06835v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06835v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4575"
  },
  {
    "objectID": "posts/An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection/2024-06-10-An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection.html",
    "href": "posts/An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection/2024-06-10-An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection.html",
    "title": "An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection",
    "section": "",
    "text": "Summary:\nThe paper introduces CodeBreaker, a pioneering LLM-assisted backdoor attack framework on code completion models. Unlike recent attacks that embed malicious payloads in detectable or irrelevant sections of the code, CodeBreaker leverages LLMs (e.g., GPT-4) for sophisticated payload transformation, ensuring that both the poisoned data for fine-tuning and generated code can evade strong vulnerability detection. CodeBreaker stands out with its comprehensive coverage of vulnerabilities, making it the first to provide such an extensive set for evaluation.\nMajor Findings:\nAnalysis and Critique:\nWhile CodeBreaker presents a significant advancement in backdoor attacks on code completion models, there are potential limitations and areas for improvement. The reliance on LLMs for payload transformation and obfuscation may introduce new vulnerabilities in the LLMs themselves, as they are used to facilitate adversarial attacks. Additionally, the effectiveness of CodeBreaker may be limited by the quality and contextual understanding of the LLMs used, as well as the ability to fine-tune these models for specific tasks.\nFurther research is needed to explore the potential for more robust defenses"
  },
  {
    "objectID": "posts/An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection/2024-06-10-An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection.html#appendix",
    "href": "posts/An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection/2024-06-10-An_LLM_Assisted_Easy_to_Trigger_Backdoor_Attack_on_Code_Completion_Models_Injecting_Disguised_Vulnerabilities_against_Strong_Detection.html#appendix",
    "title": "An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06822v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06822v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11894"
  },
  {
    "objectID": "posts/PITCH_Productivity_and_Mental_Well_being_Coaching_through_Daily_Conversational_Interaction/2024-06-11-PITCH_Productivity_and_Mental_Well_being_Coaching_through_Daily_Conversational_Interaction.html#appendix",
    "href": "posts/PITCH_Productivity_and_Mental_Well_being_Coaching_through_Daily_Conversational_Interaction/2024-06-11-PITCH_Productivity_and_Mental_Well_being_Coaching_through_Daily_Conversational_Interaction.html#appendix",
    "title": "PITCH: Productivity and Mental Well-being Coaching through Daily Conversational Interaction",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07485v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07485v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3364"
  },
  {
    "objectID": "posts/LLMs_for_User_Interest_Exploration_A_Hybrid_Approach/2024-05-25-LLMs_for_User_Interest_Exploration_A_Hybrid_Approach.html#appendix",
    "href": "posts/LLMs_for_User_Interest_Exploration_A_Hybrid_Approach/2024-05-25-LLMs_for_User_Interest_Exploration_A_Hybrid_Approach.html#appendix",
    "title": "LLMs for User Interest Exploration: A Hybrid Approach",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-14\n\n\nAbstract\nhttps://arxiv.org/abs/2405.16363v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.16363v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5005"
  },
  {
    "objectID": "posts/POEM_Interactive_Prompt_Optimization_for_Enhancing_Multimodal_Reasoning_of_Large_Language_Models/2024-06-06-POEM_Interactive_Prompt_Optimization_for_Enhancing_Multimodal_Reasoning_of_Large_Language_Models.html#appendix",
    "href": "posts/POEM_Interactive_Prompt_Optimization_for_Enhancing_Multimodal_Reasoning_of_Large_Language_Models/2024-06-06-POEM_Interactive_Prompt_Optimization_for_Enhancing_Multimodal_Reasoning_of_Large_Language_Models.html#appendix",
    "title": "POEM: Interactive Prompt Optimization for Enhancing Multimodal Reasoning of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03843v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03843v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12924"
  },
  {
    "objectID": "posts/Open_LLM_Leaderboard_From_Multi_choice_to_Open_style_Questions_for_LLMs_Evaluation_Benchmark_and_Arena/2024-06-11-Open_LLM_Leaderboard_From_Multi_choice_to_Open_style_Questions_for_LLMs_Evaluation_Benchmark_and_Arena.html#appendix",
    "href": "posts/Open_LLM_Leaderboard_From_Multi_choice_to_Open_style_Questions_for_LLMs_Evaluation_Benchmark_and_Arena/2024-06-11-Open_LLM_Leaderboard_From_Multi_choice_to_Open_style_Questions_for_LLMs_Evaluation_Benchmark_and_Arena.html#appendix",
    "title": "Open-LLM-Leaderboard: From Multi-choice to Open-style Questions for LLMs Evaluation, Benchmark, and Arena",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07545v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07545v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5687"
  },
  {
    "objectID": "posts/MrRank_Improving_Question_Answering_Retrieval_System_through_Multi_Result_Ranking_Model/2024-06-09-MrRank_Improving_Question_Answering_Retrieval_System_through_Multi_Result_Ranking_Model.html#appendix",
    "href": "posts/MrRank_Improving_Question_Answering_Retrieval_System_through_Multi_Result_Ranking_Model/2024-06-09-MrRank_Improving_Question_Answering_Retrieval_System_through_Multi_Result_Ranking_Model.html#appendix",
    "title": "MrRank: Improving Question Answering Retrieval System through Multi-Result Ranking Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05733v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05733v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5268"
  },
  {
    "objectID": "posts/FaceGPT_Self_supervised_Learning_to_Chat_about_3D_Human_Faces/2024-06-11-FaceGPT_Self_supervised_Learning_to_Chat_about_3D_Human_Faces.html#appendix",
    "href": "posts/FaceGPT_Self_supervised_Learning_to_Chat_about_3D_Human_Faces/2024-06-11-FaceGPT_Self_supervised_Learning_to_Chat_about_3D_Human_Faces.html#appendix",
    "title": "FaceGPT: Self-supervised Learning to Chat about 3D Human Faces",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07163v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07163v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6381"
  },
  {
    "objectID": "posts/TextGrad_Automatic_Differentiation_via_Text/2024-06-11-TextGrad_Automatic_Differentiation_via_Text.html#appendix",
    "href": "posts/TextGrad_Automatic_Differentiation_via_Text/2024-06-11-TextGrad_Automatic_Differentiation_via_Text.html#appendix",
    "title": "TextGrad: Automatic Differentiation via Text",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07496v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07496v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14644"
  },
  {
    "objectID": "posts/61A_Bot_AI_homework_assistance_in_CS1_is_fast_and_cheap____but_is_it_helpful/2024-06-09-61A_Bot_AI_homework_assistance_in_CS1_is_fast_and_cheap____but_is_it_helpful.html#appendix",
    "href": "posts/61A_Bot_AI_homework_assistance_in_CS1_is_fast_and_cheap____but_is_it_helpful/2024-06-09-61A_Bot_AI_homework_assistance_in_CS1_is_fast_and_cheap____but_is_it_helpful.html#appendix",
    "title": "61A-Bot: AI homework assistance in CS1 is fast and cheap – but is it helpful?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05600v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05600v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7095"
  },
  {
    "objectID": "posts/Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text/2024-06-10-Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text.html",
    "href": "posts/Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text/2024-06-10-Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text.html",
    "title": "Synth-SBDH: A Synthetic Dataset of Social and Behavioral Determinants of Health for Clinical Text",
    "section": "",
    "text": "Summary:\nThe study introduces Synth-SBDH, a novel synthetic dataset with detailed SBDH annotations, encompassing status, temporal information, and rationale across 15 SBDH categories. The dataset is the largest publicly available SBDH dataset and is generated and annotated by an LLM (GPT-4). The utility of Synth-SBDH is showcased on three tasks using real-world clinical datasets from two distinct hospital settings, highlighting its versatility, generalizability, and distillation capabilities. Models trained on Synth-SBDH consistently outperform counterparts with no Synth-SBDH training, achieving up to 62.5% macro-F improvements. Synth-SBDH proves effective for rare SBDH categories and under-resource constraints. Human evaluation demonstrates a Human-LLM alignment of 71.06% and uncovers areas for future refinements.\nMajor Findings:\nAnalysis and Critique:\nThe study presents a novel synthetic dataset, Synth-SBDH, which addresses the limitations of existing SBDH datasets and leverages the potential of LLMs in healthcare. The dataset is comprehensive, covering a wide range of SBDH categories and providing detailed"
  },
  {
    "objectID": "posts/Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text/2024-06-10-Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text.html#appendix",
    "href": "posts/Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text/2024-06-10-Synth_SBDH_A_Synthetic_Dataset_of_Social_and_Behavioral_Determinants_of_Health_for_Clinical_Text.html#appendix",
    "title": "Synth-SBDH: A Synthetic Dataset of Social and Behavioral Determinants of Health for Clinical Text",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06056v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06056v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20269"
  },
  {
    "objectID": "posts/Buffer_of_Thoughts_Thought_Augmented_Reasoning_with_Large_Language_Models/2024-06-06-Buffer_of_Thoughts_Thought_Augmented_Reasoning_with_Large_Language_Models.html#appendix",
    "href": "posts/Buffer_of_Thoughts_Thought_Augmented_Reasoning_with_Large_Language_Models/2024-06-06-Buffer_of_Thoughts_Thought_Augmented_Reasoning_with_Large_Language_Models.html#appendix",
    "title": "Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04271v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04271v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6204"
  },
  {
    "objectID": "posts/Advancing_Annotation_of_Stance_in_Social_Media_Posts_A_Comparative_Analysis_of_Large_Language_Models_and_Crowd_Sourcing/2024-06-11-Advancing_Annotation_of_Stance_in_Social_Media_Posts_A_Comparative_Analysis_of_Large_Language_Models_and_Crowd_Sourcing.html#appendix",
    "href": "posts/Advancing_Annotation_of_Stance_in_Social_Media_Posts_A_Comparative_Analysis_of_Large_Language_Models_and_Crowd_Sourcing/2024-06-11-Advancing_Annotation_of_Stance_in_Social_Media_Posts_A_Comparative_Analysis_of_Large_Language_Models_and_Crowd_Sourcing.html#appendix",
    "title": "Advancing Annotation of Stance in Social Media Posts: A Comparative Analysis of Large Language Models and Crowd Sourcing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07483v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07483v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7463"
  },
  {
    "objectID": "posts/A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions/2024-06-06-A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions.html",
    "href": "posts/A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions/2024-06-06-A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions.html",
    "title": "A Survey on Medical Large Language Models: Technology, Application, Trustworthiness, and Future Directions",
    "section": "",
    "text": "Summary:\nThis survey provides a comprehensive overview of Medical Large Language Models (Med-LLMs), outlining their evolution from general to medical-specific domains and their transformative impact on healthcare. The study explores the fundamental history and technology of LLMs, delving into the progressive adaptation and refinements of general LLM models in the medical domain. It emphasizes advanced algorithms that boost the LLMs’ performance in handling complicated medical environments, including clinical reasoning, knowledge graph, retrieval-augmented generation, human alignment, and multi-modal learning.\nThe survey also explores the extensive applications of Med-LLMs across domains such as clinical decision support, report generation, and medical education, illustrating their potential to streamline healthcare services and augment patient outcomes. Recognizing the imperative for responsible innovation, the study discusses the challenges of ensuring fairness, accountability, privacy, and robustness in Med-LLMs applications, where ethical considerations, rigorous evaluation methodologies, and the formulation of regulatory frameworks are pivotal to fostering trustworthiness in these systems.\nMajor Findings:\nAnalysis and Critique:\nThis survey provides a comprehensive investigation of the potential strengths and limitations of Med-LLMs for professionals and researchers, ensuring a responsible landscape in the healthcare setting. However, it is important to note that the study primarily focuses on"
  },
  {
    "objectID": "posts/A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions/2024-06-06-A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions.html#appendix",
    "href": "posts/A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions/2024-06-06-A_Survey_on_Medical_Large_Language_Models_Technology_Application_Trustworthiness_and_Future_Directions.html#appendix",
    "title": "A Survey on Medical Large Language Models: Technology, Application, Trustworthiness, and Future Directions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03712v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03712v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18909"
  },
  {
    "objectID": "posts/The_current_status_of_large_language_models_in_summarizing_radiology_report_impressions/2024-06-04-The_current_status_of_large_language_models_in_summarizing_radiology_report_impressions.html#appendix",
    "href": "posts/The_current_status_of_large_language_models_in_summarizing_radiology_report_impressions/2024-06-04-The_current_status_of_large_language_models_in_summarizing_radiology_report_impressions.html#appendix",
    "title": "The current status of large language models in summarizing radiology report impressions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-14\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02134v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02134v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7591"
  },
  {
    "objectID": "posts/DR_RAG_Applying_Dynamic_Document_Relevance_to_Retrieval_Augmented_Generation_for_Question_Answering/2024-06-11-DR_RAG_Applying_Dynamic_Document_Relevance_to_Retrieval_Augmented_Generation_for_Question_Answering.html#appendix",
    "href": "posts/DR_RAG_Applying_Dynamic_Document_Relevance_to_Retrieval_Augmented_Generation_for_Question_Answering/2024-06-11-DR_RAG_Applying_Dynamic_Document_Relevance_to_Retrieval_Augmented_Generation_for_Question_Answering.html#appendix",
    "title": "DR-RAG: Applying Dynamic Document Relevance to Retrieval-Augmented Generation for Question-Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07348v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07348v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6121"
  },
  {
    "objectID": "posts/Annotation_alignment_Comparing_LLM_and_human_annotations_of_conversational_safety/2024-06-10-Annotation_alignment_Comparing_LLM_and_human_annotations_of_conversational_safety.html#appendix",
    "href": "posts/Annotation_alignment_Comparing_LLM_and_human_annotations_of_conversational_safety/2024-06-10-Annotation_alignment_Comparing_LLM_and_human_annotations_of_conversational_safety.html#appendix",
    "title": "Annotation alignment: Comparing LLM and human annotations of conversational safety",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06369v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06369v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7965"
  },
  {
    "objectID": "posts/RepoQA_Evaluating_Long_Context_Code_Understanding/2024-06-10-RepoQA_Evaluating_Long_Context_Code_Understanding.html#appendix",
    "href": "posts/RepoQA_Evaluating_Long_Context_Code_Understanding/2024-06-10-RepoQA_Evaluating_Long_Context_Code_Understanding.html#appendix",
    "title": "RepoQA: Evaluating Long Context Code Understanding",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06025v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06025v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2740"
  },
  {
    "objectID": "posts/Preference_Learning_Algorithms_Do_Not_Learn_Preference_Rankings/2024-05-29-Preference_Learning_Algorithms_Do_Not_Learn_Preference_Rankings.html#appendix",
    "href": "posts/Preference_Learning_Algorithms_Do_Not_Learn_Preference_Rankings/2024-05-29-Preference_Learning_Algorithms_Do_Not_Learn_Preference_Rankings.html#appendix",
    "title": "Preference Learning Algorithms Do Not Learn Preference Rankings",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-14\n\n\nAbstract\nhttps://arxiv.org/abs/2405.19534v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.19534v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10665"
  },
  {
    "objectID": "posts/DICE_Detecting_In_distribution_Contamination_in_LLMs_Fine_tuning_Phase_for_Math_Reasoning/2024-06-06-DICE_Detecting_In_distribution_Contamination_in_LLMs_Fine_tuning_Phase_for_Math_Reasoning.html#appendix",
    "href": "posts/DICE_Detecting_In_distribution_Contamination_in_LLMs_Fine_tuning_Phase_for_Math_Reasoning/2024-06-06-DICE_Detecting_In_distribution_Contamination_in_LLMs_Fine_tuning_Phase_for_Math_Reasoning.html#appendix",
    "title": "DICE: Detecting In-distribution Contamination in LLM’s Fine-tuning Phase for Math Reasoning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04197v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04197v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6104"
  },
  {
    "objectID": "posts/VideoLLaMA_2_Advancing_Spatial_Temporal_Modeling_and_Audio_Understanding_in_Video_LLMs/2024-06-11-VideoLLaMA_2_Advancing_Spatial_Temporal_Modeling_and_Audio_Understanding_in_Video_LLMs.html#appendix",
    "href": "posts/VideoLLaMA_2_Advancing_Spatial_Temporal_Modeling_and_Audio_Understanding_in_Video_LLMs/2024-06-11-VideoLLaMA_2_Advancing_Spatial_Temporal_Modeling_and_Audio_Understanding_in_Video_LLMs.html#appendix",
    "title": "VideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understanding in Video-LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07476v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07476v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5170"
  },
  {
    "objectID": "posts/HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs/2024-06-10-HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs.html",
    "href": "posts/HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs/2024-06-10-HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs.html",
    "title": "HOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs",
    "section": "",
    "text": "Summary:\nThe paper introduces a new method called HOLMES for multi-hop question answering (MHQA) using large language models (LLMs). The method involves transforming unstructured text into a hyper-relational knowledge graph (KG) using a query-derived schema, which is then used as input to the LLM. The proposed method significantly improves upon the state-of-the-art (SoTA) multi-hop QA method, achieving 18.7% and 20% improvements in exact match (EM) scores on the Hotpot dataset and 26% and 14.3% on the MuSiQue dataset for GPT-3.5 and GPT-4, respectively. Additionally, the method uses up to 67% fewer tokens to represent query-relevant information than the current SoTA method and up to 60% fewer tokens compared to the original supporting documents.\nMajor Findings:\nAnalysis and Critique:\nThe proposed method, HOLMES, presents a significant improvement over the SoTA multi-hop QA method. The use of a hyper-relational KG as input to the LLM allows for a more efficient and effective representation of query-relevant information. The method’s ability to use fewer tokens to represent this information is particularly noteworthy, as it can lead to reduced computational costs and improved performance.\nHowever, there are some potential limitations and areas for further research. For example, the method’s reliance on a query-"
  },
  {
    "objectID": "posts/HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs/2024-06-10-HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs.html#appendix",
    "href": "posts/HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs/2024-06-10-HOLMES_Hyper_Relational_Knowledge_Graphs_for_Multi_hop_Question_Answering_using_LLMs.html#appendix",
    "title": "HOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06027v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06027v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20470"
  },
  {
    "objectID": "posts/Security_Vulnerability_Detection_with_Multitask_Self_Instructed_Fine_Tuning_of_Large_Language_Models/2024-06-09-Security_Vulnerability_Detection_with_Multitask_Self_Instructed_Fine_Tuning_of_Large_Language_Models.html#appendix",
    "href": "posts/Security_Vulnerability_Detection_with_Multitask_Self_Instructed_Fine_Tuning_of_Large_Language_Models/2024-06-09-Security_Vulnerability_Detection_with_Multitask_Self_Instructed_Fine_Tuning_of_Large_Language_Models.html#appendix",
    "title": "Security Vulnerability Detection with Multitask Self-Instructed Fine-Tuning of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05892v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05892v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10513"
  },
  {
    "objectID": "posts/An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics/2024-06-10-An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics.html",
    "href": "posts/An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics/2024-06-10-An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics.html",
    "title": "An Empirical Design Justice Approach to Identifying Ethical Considerations in the Intersection of Large Language Models and Social Robotics",
    "section": "",
    "text": "Summary:\nThe integration of Large Language Models (LLMs) in social robotics presents a unique set of ethical challenges and social impacts. This research aims to identify ethical considerations that arise in the design and development of these two technologies in combination. Using LLMs for social robotics may provide benefits, such as enabling natural language open-domain dialogues. However, the intersection of these two technologies also gives rise to ethical concerns related to misinformation, non-verbal cues, emotional disruption, and biases. The robot’s physical social embodiment adds complexity, as ethical hazards associated with LLM-based Social AI, such as hallucinations and misinformation, can be exacerbated due to the effects of physical embodiment on social perception and communication. To address these challenges, this study employs an empirical design justice-based methodology, focusing on identifying socio-technical ethical considerations through a qualitative co-design and interaction study. The purpose of the study is to identify ethical considerations relevant to the process of co-design of, and interaction with a humanoid social robot as the interface of a LLM, and to evaluate how a design justice methodology can be used in the context of designing LLMs-based social robotics.\nMajor Findings:\nAnalysis and Critique:\nThe study presents a novel methodological approach based on previous work on design justice in AI and HRI. The approach enables the identification and validation of ethical concerns through empirical design justice-based data from diverse participants. However, the study also highlights limitations, such as the inability to confidently determine ethical considerations in"
  },
  {
    "objectID": "posts/An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics/2024-06-10-An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics.html#appendix",
    "href": "posts/An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics/2024-06-10-An_Empirical_Design_Justice_Approach_to_Identifying_Ethical_Considerations_in_the_Intersection_of_Large_Language_Models_and_Social_Robotics.html#appendix",
    "title": "An Empirical Design Justice Approach to Identifying Ethical Considerations in the Intersection of Large Language Models and Social Robotics",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06400v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06400v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14471"
  },
  {
    "objectID": "posts/Safety_Alignment_Should_Be_Made_More_Than_Just_a_Few_Tokens_Deep/2024-06-10-Safety_Alignment_Should_Be_Made_More_Than_Just_a_Few_Tokens_Deep.html#appendix",
    "href": "posts/Safety_Alignment_Should_Be_Made_More_Than_Just_a_Few_Tokens_Deep/2024-06-10-Safety_Alignment_Should_Be_Made_More_Than_Just_a_Few_Tokens_Deep.html#appendix",
    "title": "Safety Alignment Should Be Made More Than Just a Few Tokens Deep",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05946v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05946v1\n\n\nTruncated\nFalse\n\n\nWord Count\n16740"
  },
  {
    "objectID": "posts/MedExQA_Medical_Question_Answering_Benchmark_with_Multiple_Explanations/2024-06-10-MedExQA_Medical_Question_Answering_Benchmark_with_Multiple_Explanations.html#appendix",
    "href": "posts/MedExQA_Medical_Question_Answering_Benchmark_with_Multiple_Explanations/2024-06-10-MedExQA_Medical_Question_Answering_Benchmark_with_Multiple_Explanations.html#appendix",
    "title": "MedExQA: Medical Question Answering Benchmark with Multiple Explanations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06331v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06331v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7134"
  },
  {
    "objectID": "posts/Sunnie_An_Anthropomorphic_LLM_Based_Conversational_Agent_for_Mental_Well_Being_Activity_Recommendation/2024-05-22-Sunnie_An_Anthropomorphic_LLM_Based_Conversational_Agent_for_Mental_Well_Being_Activity_Recommendation.html#appendix",
    "href": "posts/Sunnie_An_Anthropomorphic_LLM_Based_Conversational_Agent_for_Mental_Well_Being_Activity_Recommendation/2024-05-22-Sunnie_An_Anthropomorphic_LLM_Based_Conversational_Agent_for_Mental_Well_Being_Activity_Recommendation.html#appendix",
    "title": "Sunnie: An Anthropomorphic LLM-Based Conversational Agent for Mental Well-Being Activity Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-14\n\n\nAbstract\nhttps://arxiv.org/abs/2405.13803v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.13803v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1391"
  },
  {
    "objectID": "posts/Can_I_understand_what_I_create_Self_Knowledge_Evaluation_of_Large_Language_Models/2024-06-10-Can_I_understand_what_I_create_Self_Knowledge_Evaluation_of_Large_Language_Models.html#appendix",
    "href": "posts/Can_I_understand_what_I_create_Self_Knowledge_Evaluation_of_Large_Language_Models/2024-06-10-Can_I_understand_what_I_create_Self_Knowledge_Evaluation_of_Large_Language_Models.html#appendix",
    "title": "Can I understand what I create? Self-Knowledge Evaluation of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06140v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06140v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7449"
  },
  {
    "objectID": "posts/Navigating_User_Experience_of_ChatGPT_based_Conversational_Recommender_Systems_The_Effects_of_Prompt_Guidance_and_Recommendation_Domain/2024-05-22-Navigating_User_Experience_of_ChatGPT_based_Conversational_Recommender_Systems_The_Effects_of_Prompt_Guidance_and_Recommendation_Domain.html#appendix",
    "href": "posts/Navigating_User_Experience_of_ChatGPT_based_Conversational_Recommender_Systems_The_Effects_of_Prompt_Guidance_and_Recommendation_Domain/2024-05-22-Navigating_User_Experience_of_ChatGPT_based_Conversational_Recommender_Systems_The_Effects_of_Prompt_Guidance_and_Recommendation_Domain.html#appendix",
    "title": "Navigating User Experience of ChatGPT-based Conversational Recommender Systems: The Effects of Prompt Guidance and Recommendation Domain",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-14\n\n\nAbstract\nhttps://arxiv.org/abs/2405.13560v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.13560v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8278"
  },
  {
    "objectID": "posts/Privacy_in_LLM_based_Recommendation_Recent_Advances_and_Future_Directions/2024-06-03-Privacy_in_LLM_based_Recommendation_Recent_Advances_and_Future_Directions.html#appendix",
    "href": "posts/Privacy_in_LLM_based_Recommendation_Recent_Advances_and_Future_Directions/2024-06-03-Privacy_in_LLM_based_Recommendation_Recent_Advances_and_Future_Directions.html#appendix",
    "title": "Privacy in LLM-based Recommendation: Recent Advances and Future Directions",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-14\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01363v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01363v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3447"
  },
  {
    "objectID": "posts/Large_Language_Models_as_Evaluators_for_Recommendation_Explanations/2024-06-06-Large_Language_Models_as_Evaluators_for_Recommendation_Explanations.html#appendix",
    "href": "posts/Large_Language_Models_as_Evaluators_for_Recommendation_Explanations/2024-06-06-Large_Language_Models_as_Evaluators_for_Recommendation_Explanations.html#appendix",
    "title": "Large Language Models as Evaluators for Recommendation Explanations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03248v2\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03248v2\n\n\nTruncated\nFalse\n\n\nWord Count\n7752"
  },
  {
    "objectID": "posts/Large_Language_Models_Memorize_Sensor_Datasets!_Implications_on_Human_Activity_Recognition_Research/2024-06-09-Large_Language_Models_Memorize_Sensor_Datasets!_Implications_on_Human_Activity_Recognition_Research.html#appendix",
    "href": "posts/Large_Language_Models_Memorize_Sensor_Datasets!_Implications_on_Human_Activity_Recognition_Research/2024-06-09-Large_Language_Models_Memorize_Sensor_Datasets!_Implications_on_Human_Activity_Recognition_Research.html#appendix",
    "title": "Large Language Models Memorize Sensor Datasets! Implications on Human Activity Recognition Research",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05900v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05900v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6787"
  },
  {
    "objectID": "posts/Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model/2024-06-11-Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model.html",
    "href": "posts/Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model/2024-06-11-Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model.html",
    "title": "Paying More Attention to Source Context: Mitigating Unfaithful Translations from Large Language Model",
    "section": "",
    "text": "Summary:\nThe paper focuses on the issue of unfaithful translations in large language models (LLMs) due to insufficient focus on the source context. The authors propose three methods to address this issue: reweight attention, contrastive decoding, and target-constrained tuning. The reweight attention method adjusts the attention weight of the source context to help models focus on the source context during generation. Contrastive decoding reduces the influence of target prefixes, and target-constrained tuning encourages LLMs to avoid excessive dependence on specific target prefixes. The experimental results show that the proposed methods improve translation performance across several language pairs in the proposed unfaithful translation test sets, outperforming baseline methods and effectively reducing the phenomenon of hallucinatory and unfaithful translations.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model/2024-06-11-Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model.html#appendix",
    "href": "posts/Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model/2024-06-11-Paying_More_Attention_to_Source_Context_Mitigating_Unfaithful_Translations_from_Large_Language_Model.html#appendix",
    "title": "Paying More Attention to Source Context: Mitigating Unfaithful Translations from Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07036v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07036v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10716"
  },
  {
    "objectID": "posts/M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering/2024-06-06-M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering.html",
    "href": "posts/M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering/2024-06-06-M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering.html",
    "title": "M-QALM: A Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall in Large Language Models via Question Answering",
    "section": "",
    "text": "Summary:\nThe paper introduces M-QALM, a benchmark for evaluating clinical reading comprehension and knowledge recall in large language models (LLMs) through question answering. The authors conduct a large-scale empirical study using 22 datasets in three generalist and three specialist biomedical sub-domains. They analyze the performance of 15 LLMs, focusing on factors such as instruction tuning, domain-adapted models, and fine-tuning on medical knowledge datasets. The results show that while recent domain-adapted models may lack adequate knowledge, fine-tuning on medical knowledge datasets shows encouraging results, even generalizing to unseen specialist sub-domains. The paper also includes a skill-oriented manual error analysis, revealing a significant gap between the models’ capabilities to recall necessary knowledge and integrate it with the presented context.\nMajor Findings:"
  },
  {
    "objectID": "posts/M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering/2024-06-06-M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering.html#appendix",
    "href": "posts/M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering/2024-06-06-M_QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering.html#appendix",
    "title": "M-QALM: A Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall in Large Language Models via Question Answering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03699v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03699v1\n\n\nTruncated\nTrue\n\n\nWord Count\n32275"
  },
  {
    "objectID": "posts/SecureNet_A_Comparative_Study_of_DeBERTa_and_Large_Language_Models_for_Phishing_Detection/2024-06-10-SecureNet_A_Comparative_Study_of_DeBERTa_and_Large_Language_Models_for_Phishing_Detection.html#appendix",
    "href": "posts/SecureNet_A_Comparative_Study_of_DeBERTa_and_Large_Language_Models_for_Phishing_Detection/2024-06-10-SecureNet_A_Comparative_Study_of_DeBERTa_and_Large_Language_Models_for_Phishing_Detection.html#appendix",
    "title": "SecureNet: A Comparative Study of DeBERTa and Large Language Models for Phishing Detection",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06663v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06663v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8220"
  },
  {
    "objectID": "posts/Generalization_Enhanced_Code_Vulnerability_Detection_via_Multi_Task_Instruction_Fine_Tuning/2024-06-06-Generalization_Enhanced_Code_Vulnerability_Detection_via_Multi_Task_Instruction_Fine_Tuning.html#appendix",
    "href": "posts/Generalization_Enhanced_Code_Vulnerability_Detection_via_Multi_Task_Instruction_Fine_Tuning/2024-06-06-Generalization_Enhanced_Code_Vulnerability_Detection_via_Multi_Task_Instruction_Fine_Tuning.html#appendix",
    "title": "Generalization-Enhanced Code Vulnerability Detection via Multi-Task Instruction Fine-Tuning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03718v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03718v1\n\n\nTruncated\nFalse\n\n\nWord Count\n22567"
  },
  {
    "objectID": "posts/Aligning_Agents_like_Large_Language_Models/2024-06-06-Aligning_Agents_like_Large_Language_Models.html",
    "href": "posts/Aligning_Agents_like_Large_Language_Models/2024-06-06-Aligning_Agents_like_Large_Language_Models.html",
    "title": "Aligning Agents like Large Language Models",
    "section": "",
    "text": "Summary:\nThe paper explores the challenge of training agents to behave as desired in complex 3D environments using high-dimensional sensory information. The authors draw an analogy between the undesirable behaviors of imitation learning agents and the unhelpful responses of unaligned large language models (LLMs). They investigate the procedure for aligning LLMs and apply it to aligning agents in a 3D environment from pixels. The authors focus on an academically illustrative part of a modern console game where players must navigate from a randomly selected spawn point to one of three jumppads. They demonstrate that they can align their agent to consistently perform the desired mode while providing insights and advice for successfully applying this approach to training agents.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an innovative approach to aligning agents in complex 3D environments by drawing an analogy between the undesirable behaviors of imitation learning agents and the unhelpful responses of unaligned LLMs. The authors’ investigation of the procedure for aligning LLMs and its application to aligning agents is a significant contribution to the field. However, the paper’s focus on an academically illustrative part of a modern console game may limit the generalizability of the findings to other complex 3D environments. Additionally, the use of synthetic preference labelling may not fully capture the complexity of human preferences in real-world scenarios. Further research is needed to evaluate the effectiveness of this approach in more diverse and complex environments and to explore the use of human preference labelling."
  },
  {
    "objectID": "posts/Aligning_Agents_like_Large_Language_Models/2024-06-06-Aligning_Agents_like_Large_Language_Models.html#appendix",
    "href": "posts/Aligning_Agents_like_Large_Language_Models/2024-06-06-Aligning_Agents_like_Large_Language_Models.html#appendix",
    "title": "Aligning Agents like Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04208v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04208v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12915"
  },
  {
    "objectID": "posts/Semantically_Diverse_Language_Generation_for_Uncertainty_Estimation_in_Language_Models/2024-06-06-Semantically_Diverse_Language_Generation_for_Uncertainty_Estimation_in_Language_Models.html#appendix",
    "href": "posts/Semantically_Diverse_Language_Generation_for_Uncertainty_Estimation_in_Language_Models/2024-06-06-Semantically_Diverse_Language_Generation_for_Uncertainty_Estimation_in_Language_Models.html#appendix",
    "title": "Semantically Diverse Language Generation for Uncertainty Estimation in Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04306v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04306v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10058"
  },
  {
    "objectID": "posts/Ask_LLMs_Directly_What_shapes_your_bias_Measuring_Social_Bias_in_Large_Language_Models/2024-06-06-Ask_LLMs_Directly_What_shapes_your_bias_Measuring_Social_Bias_in_Large_Language_Models.html#appendix",
    "href": "posts/Ask_LLMs_Directly_What_shapes_your_bias_Measuring_Social_Bias_in_Large_Language_Models/2024-06-06-Ask_LLMs_Directly_What_shapes_your_bias_Measuring_Social_Bias_in_Large_Language_Models.html#appendix",
    "title": "Ask LLMs Directly, What shapes your bias?: Measuring Social Bias in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04064v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04064v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5188"
  },
  {
    "objectID": "posts/A_Superalignment_Framework_in_Autonomous_Driving_with_Large_Language_Models/2024-06-09-A_Superalignment_Framework_in_Autonomous_Driving_with_Large_Language_Models.html#appendix",
    "href": "posts/A_Superalignment_Framework_in_Autonomous_Driving_with_Large_Language_Models/2024-06-09-A_Superalignment_Framework_in_Autonomous_Driving_with_Large_Language_Models.html#appendix",
    "title": "A Superalignment Framework in Autonomous Driving with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05651v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05651v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3979"
  },
  {
    "objectID": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#major-findings",
    "href": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#major-findings",
    "title": "Solution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe team proposes a new instruction-tuned vision-language model with two novel ideas: grounding visual cues in the text modality and utilizing an object detection algorithm to capture complex diagrammatic visual patterns.\nThe team achieves a 27.11 WOSA score on the challenge split and qualitatively validates the effectiveness of their proposed approach.\nThe team utilizes the Segmentation Anything Model (SAM) algorithm to capture the complex visual features and uses this information as input for the LLM."
  },
  {
    "objectID": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#analysis-and-critique",
    "href": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#analysis-and-critique",
    "title": "Solution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper does not provide a detailed analysis of the performance of the proposed method compared to other state-of-the-art methods.\nThe paper does not discuss the limitations of the proposed method or any potential biases that were apparent while reviewing the text.\nThe paper does not discuss any methodological issues, conflicting evidence, or areas that require further research or clarification.\nThe paper does not provide a detailed analysis of the performance of the proposed method on different types of puzzles.\nThe paper does not discuss the generalizability of the proposed method to other types of multimodal reasoning tasks."
  },
  {
    "objectID": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#appendix",
    "href": "posts/Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024/2024-06-10-Solution_for_SMART_101_Challenge_of_CVPR_Multi_modal_Algorithmic_Reasoning_Task_2024.html#appendix",
    "title": "Solution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05963v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05963v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3407"
  },
  {
    "objectID": "posts/Session_Context_Embedding_for_Intent_Understanding_in_Product_Search/2024-06-03-Session_Context_Embedding_for_Intent_Understanding_in_Product_Search.html#appendix",
    "href": "posts/Session_Context_Embedding_for_Intent_Understanding_in_Product_Search/2024-06-03-Session_Context_Embedding_for_Intent_Understanding_in_Product_Search.html#appendix",
    "title": "Session Context Embedding for Intent Understanding in Product Search",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-14\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01702v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01702v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3385"
  },
  {
    "objectID": "posts/3D_Properties_Identifying_Challenges_in_DPO_and_Charting_a_Path_Forward/2024-06-11-3D_Properties_Identifying_Challenges_in_DPO_and_Charting_a_Path_Forward.html#appendix",
    "href": "posts/3D_Properties_Identifying_Challenges_in_DPO_and_Charting_a_Path_Forward/2024-06-11-3D_Properties_Identifying_Challenges_in_DPO_and_Charting_a_Path_Forward.html#appendix",
    "title": "3D-Properties: Identifying Challenges in DPO and Charting a Path Forward",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07327v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07327v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8028"
  },
  {
    "objectID": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#major-findings",
    "href": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#major-findings",
    "title": "DomainRAG: A Chinese Benchmark for Evaluating Domain-specific Retrieval-Augmented Generation",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nExisting closed-book LLMs struggle with domain-specific questions, emphasizing the importance of RAG models for solving expert problems.\nThere is room for RAG models to improve their abilities in comprehending conversational history, analyzing structural information, denoising, processing multi-document interactions, and faithfulness in expert knowledge.\nThe use of domain-specific corpora and questions is essential to assess the ability of LLMs to effectively use external knowledge from specific fields to solve expert problems."
  },
  {
    "objectID": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#analysis-and-critique",
    "href": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#analysis-and-critique",
    "title": "DomainRAG: A Chinese Benchmark for Evaluating Domain-specific Retrieval-Augmented Generation",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper provides a comprehensive evaluation of RAG models in a domain-specific context, which is crucial for addressing the limitations of LLMs in expert and domain-specific applications.\nThe study identifies six essential abilities for RAG models, which can serve as a foundation for future research and development in this area.\nThe experimental results highlight the need for RAG models to improve their performance in complex scenarios involving various kinds of information sources.\nThe paper could benefit from a more detailed analysis of the limitations and potential biases of the evaluated LLMs and RAG models.\nFuture studies should explore more sophisticated frameworks for enhancing the performance of RAG systems and evaluate their performance in various application scenarios."
  },
  {
    "objectID": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#appendix",
    "href": "posts/DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation/2024-06-09-DomainRAG_A_Chinese_Benchmark_for_Evaluating_Domain_specific_Retrieval_Augmented_Generation.html#appendix",
    "title": "DomainRAG: A Chinese Benchmark for Evaluating Domain-specific Retrieval-Augmented Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05654v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05654v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6448"
  },
  {
    "objectID": "posts/Validating_LLM_Generated_Programs_with_Metamorphic_Prompt_Testing/2024-06-11-Validating_LLM_Generated_Programs_with_Metamorphic_Prompt_Testing.html#appendix",
    "href": "posts/Validating_LLM_Generated_Programs_with_Metamorphic_Prompt_Testing/2024-06-11-Validating_LLM_Generated_Programs_with_Metamorphic_Prompt_Testing.html#appendix",
    "title": "Validating LLM-Generated Programs with Metamorphic Prompt Testing",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06864v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06864v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6738"
  },
  {
    "objectID": "posts/A_Probabilistic_Framework_for_LLM_Hallucination_Detection_via_Belief_Tree_Propagation/2024-06-11-A_Probabilistic_Framework_for_LLM_Hallucination_Detection_via_Belief_Tree_Propagation.html#appendix",
    "href": "posts/A_Probabilistic_Framework_for_LLM_Hallucination_Detection_via_Belief_Tree_Propagation/2024-06-11-A_Probabilistic_Framework_for_LLM_Hallucination_Detection_via_Belief_Tree_Propagation.html#appendix",
    "title": "A Probabilistic Framework for LLM Hallucination Detection via Belief Tree Propagation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06950v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06950v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10310"
  },
  {
    "objectID": "posts/How_to_Understand_Whole_Software_Repository/2024-06-03-How_to_Understand_Whole_Software_Repository.html#appendix",
    "href": "posts/How_to_Understand_Whole_Software_Repository/2024-06-03-How_to_Understand_Whole_Software_Repository.html#appendix",
    "title": "How to Understand Whole Software Repository?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-14\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01422v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01422v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10556"
  },
  {
    "objectID": "posts/DCA_Bench_A_Benchmark_for_Dataset_Curation_Agents/2024-06-11-DCA_Bench_A_Benchmark_for_Dataset_Curation_Agents.html#appendix",
    "href": "posts/DCA_Bench_A_Benchmark_for_Dataset_Curation_Agents/2024-06-11-DCA_Bench_A_Benchmark_for_Dataset_Curation_Agents.html#appendix",
    "title": "DCA-Bench: A Benchmark for Dataset Curation Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07275v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07275v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8553"
  },
  {
    "objectID": "posts/Can_Language_Models_Serve_as_Text_Based_World_Simulators/2024-06-10-Can_Language_Models_Serve_as_Text_Based_World_Simulators.html#appendix",
    "href": "posts/Can_Language_Models_Serve_as_Text_Based_World_Simulators/2024-06-10-Can_Language_Models_Serve_as_Text_Based_World_Simulators.html#appendix",
    "title": "Can Language Models Serve as Text-Based World Simulators?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06485v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06485v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6025"
  },
  {
    "objectID": "posts/Item_Language_Model_for_Conversational_Recommendation/2024-06-05-Item_Language_Model_for_Conversational_Recommendation.html#appendix",
    "href": "posts/Item_Language_Model_for_Conversational_Recommendation/2024-06-05-Item_Language_Model_for_Conversational_Recommendation.html#appendix",
    "title": "Item-Language Model for Conversational Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02844v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02844v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6105"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Bayesian beagle",
    "section": "",
    "text": "Welcome to the Bayesian beagle blog! This project is a unique intersection of machine learning and scientific communication, providing a platform where readers can quickly get insights from the latest research papers hosted on ArXiv. Utilizing state-of-the-art Large Language Models (LLMs), our system generates concise, comprehensible summaries of complex research articles, covering a wide array of disciplines.\nAll content is LLM generated. Assume skepticism and verify in the original paper as LLM models are imperfect and can struggle under certain circumstances.\nOur blog is built using Quarto and then published with Netlify.\n\n\n\n\ngraph LR\n    A[\"Download daily Arxiv articles\"] --&gt; B[\"Predict and Filter LLM topic\"]\n    B --&gt; C[\"Summarize short docs\"]\n    B --&gt; D[\"Summarize by Map-Reduce long docs\"]\n    C --&gt; E[\"Update website with summaries daily\"]\n    D --&gt; E"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian beagle",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nDCA-Bench: A Benchmark for Dataset Curation Agents\n\n\n\narchitectures\n\n\n\nLLMs can help curate datasets, but real-world issues are complex. DCA-Bench measures LLM agents’ ability to detect dataset quality issues.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOllabench: Evaluating LLMs’ Reasoning for Human-centric Interdependent Cybersecurity\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nOllaBench evaluates LLMs for cybersecurity, revealing commercial models lead in accuracy but have room for improvement, while smaller open-weight models show promise.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Probabilistic Framework for LLM Hallucination Detection via Belief Tree Propagation\n\n\n\nrobustness\n\n\n\nBTProp: New method improves hallucination detection in LLMs by 3%-9% via a belief tree and hidden Markov tree model.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nValidating LLM-Generated Programs with Metamorphic Prompt Testing\n\n\n\nrobustness\n\n\nsecurity\n\n\nprompt-engineering\n\n\nprogramming\n\n\n\nTL;DR: Metamorphic prompt testing detects 75% of GPT-4’s erroneous code, with 8.6% false positives.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnomaly Detection on Unstable Logs with GPT Models\n\n\n\narchitectures\n\n\nproduction\n\n\nprogramming\n\n\nprompt-engineering\n\n\n\nLLM (GPT-3) outperforms supervised baselines for anomaly detection on unstable logs, with fine-tuning superior to prompt engineering.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3D-Properties: Identifying Challenges in DPO and Charting a Path Forward\n\n\n\narchitectures\n\n\nsocial-sciences\n\n\neducation\n\n\n\nDPO in LLMs: Examining 3D-properties, issues, and solutions for better alignment with human preference.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSingle-Codec: Single-Codebook Speech Codec towards High-Performance Speech Generation\n\n\n\nproduction\n\n\n\nSingle-Codec, a single-sequence codec, improves TTS efficiency and robustness, outperforming multi-codebook codecs in quality, bandwidth, and LLM-TTS performance.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaying More Attention to Source Context: Mitigating Unfaithful Translations from Large Language Model\n\n\n\nrobustness\n\n\n\nLLMs can generate unfaithful translations due to bias towards target tokens. Our methods encourage LLMs to focus more on source context, reducing hallucinatory translations.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLimited Out-of-Context Knowledge Reasoning in Large Language Models\n\n\n\narchitectures\n\n\nproduction\n\n\neducation\n\n\n\nLLMs struggle with out-of-context reasoning and cross-lingual knowledge transfer, despite training adjustments.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReinforcement Learning from Human Feedback without Reward Inference: Model-Free Algorithm and Instance-Dependent Analysis\n\n\n\narchitectures\n\n\nproduction\n\n\n\nRLHF not harder than classic RL; end-to-end RLHF can improve performance by avoiding pitfalls in reward inference.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRS-Agent: Automating Remote Sensing Tasks through Intelligent Agents\n\n\n\nprompt-engineering\n\n\n\nTL;DR: RS-Agent: A LLM-driven remote sensing agent excelling in complex tasks, outperforming in scene classification, visual question answering, and object counting.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCAAP: Context-Aware Action Planning Prompting to Solve Computer Tasks with Front-End UI Only\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nLLM-based agent uses screenshots for context, achieving 94.4% success on MiniWoB++ problems with 1.48 demos per type, enabling broader automation applications.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMcEval: Massively Multilingual Code Evaluation\n\n\n\narchitectures\n\n\nprogramming\n\n\neducation\n\n\nproduction\n\n\nprompt-engineering\n\n\n\nTL;DR: Introducing McEval, a multilingual code benchmark for 40 languages, challenging LLMs in code tasks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Human-AI Collaboration in Healthcare: Guided Deferral Systems with Large Language Models\n\n\n\nsocial-sciences\n\n\n\nTL;DR: Human-AI collaboration improves LLMs’ reliability in healthcare, reducing uncertainty via a guided deferral system.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understanding in Video-LLMs\n\n\n\nproduction\n\n\neducation\n\n\n\nVideoLLaMA 2 improves video and audio understanding with competitive results in multimodal tasks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDR-RAG: Applying Dynamic Document Relevance to Retrieval-Augmented Generation for Question-Answering\n\n\n\narchitectures\n\n\n\nDR-RAG improves QA accuracy by enhancing document retrieval, using a two-stage framework and a small classifier, while maintaining efficiency.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoEvol: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation\n\n\n\nhci\n\n\neducation\n\n\n\nCoEvol: LLM-based framework improves instruction responses, outperforming baselines in MT-Bench and AlpacaEval.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJoint Demonstration and Preference Learning Improves Policy Alignment with Human Feedback\n\n\n\nsocial-sciences\n\n\n\nTL;DR: AIHF outperforms RLHF and DPO in aligning human preference and value in AI, especially with limited data.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvancing Annotation of Stance in Social Media Posts: A Comparative Analysis of Large Language Models and Crowd Sourcing\n\n\n\nproduction\n\n\nsocial-sciences\n\n\n\nLLMs’ stance annotation accuracy depends on text’s explicitness, often mirroring human performance.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGraphCoder: Enhancing Repository-Level Code Completion via Code Context Graph-based Retrieval and Language Model\n\n\n\nprogramming\n\n\n\nGraphCoder improves code completion with a graph-based retrieval-generation process, outperforming baseline methods in accuracy and efficiency.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTextGrad: Automatic Differentiation via Text\n\n\n\narchitectures\n\n\nproduction\n\n\n\nTextGrad optimizes compound AI systems by backpropagating textual feedback, improving performance across various tasks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models for Constrained-Based Causal Discovery\n\n\n\nhci\n\n\n\nLLMs can assist in causal graph generation, but performance varies. A statistical-inspired voting schema improves results, suggesting potential for knowledge-based CIT in…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFaceGPT: Self-supervised Learning to Chat about 3D Human Faces\n\n\n\neducation\n\n\n\nFaceGPT: Self-supervised 3D face reconstruction from images and text, without 3D annotations.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpen-LLM-Leaderboard: From Multi-choice to Open-style Questions for LLMs Evaluation, Benchmark, and Arena\n\n\n\narchitectures\n\n\nproduction\n\n\nprompt-engineering\n\n\nhci\n\n\n\nLLMs may favor certain answer IDs due to biases. Open-style questions can eliminate this, but pose new challenges. We introduce the Open-LLM-Leaderboard to track LLM…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBertaQA: How Much Do Language Models Know About Local Culture?\n\n\n\nsocial-sciences\n\n\n\nLLMs struggle with local cultural knowledge but improve with continued pre-training in that language.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPITCH: Productivity and Mental Well-being Coaching through Daily Conversational Interaction\n\n\n\nproduction\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\nhci\n\n\n\nPITCH: A conversational AI for productivity, using rotating prompts to boost engagement and mental well-being.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeveraging Large Language Models for Efficient Failure Analysis in Game Development\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nThis paper presents a method using Large Language Models to automatically identify code changes causing test failures, achieving 71% accuracy and reducing debugging time by…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat’s in an embedding? Would a rose by any embedding smell as sweet?\n\n\n\neducation\n\n\n\n[TEXT] This study examines the relationship between social media use and mental health in young adults. Results suggest a negative correlation between excessive social media…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProgressive Query Expansion for Retrieval Over Cost-constrained Data Sources\n\n\n\nrobustness\n\n\n\nProQE combines PRF and LLMs for progressive query expansion, improving accuracy and cost-effectiveness in retrieval systems.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Tool for Test Case Scenarios Generation Using Large Language Models\n\n\n\nhci\n\n\nprompt-engineering\n\n\neducation\n\n\nprogramming\n\n\n\nTL;DR: Tool generates test case scenarios from user requirements using an LLM-based agent.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstruct Large Language Models to Drive like Humans\n\n\n\narchitectures\n\n\n\nInstructDriver: Transforming LLM into a motion planner with human-aligned behavior for autonomous driving.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nToxic Memes: A Survey of Computational Perspectives on the Detection and Explanation of Meme Toxicities\n\n\n\narchitectures\n\n\nhci\n\n\nsocial-sciences\n\n\n\nSurvey on toxic memes: new taxonomy, trends, and challenges in computational analysis.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuickLLaMA: Query-aware Inference Acceleration for Large Language Models\n\n\n\narchitectures\n\n\nproduction\n\n\n\nQ-LLM enhances LLMs’ context understanding, improving accuracy on benchmarks without extra training.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards more realistic evaluation of LLM-based code generation: an experimental study and beyond\n\n\n\nrobustness\n\n\nprogramming\n\n\n\n[TEXT] This study examines the impact of social media on the mental health of adolescents. Results indicate a significant correlation between excessive social media use and…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEfficiently Exploring Large Language Models for Document-Level Machine Translation with In-context Learning\n\n\n\nprompt-engineering\n\n\n\nLLMs struggle with document-level translation. Our Context-Aware Prompting method (CAP) improves LLM translation accuracy, cohesion, and coherence.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVersiCode: Towards Version-controllable Code Generation\n\n\n\narchitectures\n\n\nproduction\n\n\nprogramming\n\n\n\nTL;DR: VersiCode dataset tests LLMs’ ability to generate version-correct code, revealing challenges and limitations.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHalluDial: A Large-Scale Benchmark for Automatic Dialogue-Level Hallucination Evaluation\n\n\n\nrobustness\n\n\n\nHalluDial: A Comprehensive Benchmark for Automatic Dialogue-Level Hallucination Evaluation in LLMs.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAccessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B\n\n\n\narchitectures\n\n\neducation\n\n\n\nMCTSr algorithm improves LLMs’ mathematical reasoning by integrating Monte Carlo Tree Search, enhancing accuracy in complex tasks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDARA: Decomposition-Alignment-Reasoning Autonomous Language Agent for Question Answering over Knowledge Graphs\n\n\n\nhci\n\n\nprompt-engineering\n\n\n\nDARA framework improves LLM-powered agents’ KGQA performance, outperforming in-context learning-based agents and alternative fine-tuned agents.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMerging Improves Self-Critique Against Jailbreak Attacks\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nMerging and self-critique improve LLM robustness against jailbreak attacks.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees\n\n\n\nprogramming\n\n\n\nTP-LLaMA model outperforms baselines in tool-augmented LLMs by optimizing inference trajectories using preference data from decision trees, enhancing utilization of expert…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGuiding LLM Temporal Logic Generation with Explicit Separation of Data and Control\n\n\n\narchitectures\n\n\n\nLLMs can improve reactive program synthesis by separating control and data in temporal logic specifications, enhancing specification generation.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeaching Language Models to Self-Improve by Learning from Language Feedback\n\n\n\nsocial-sciences\n\n\n\nSRT uses model feedback for alignment, reducing reliance on human annotations, and significantly improves model performance across tasks and sizes.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Large Language Models for Relevance Judgments in Tetun\n\n\n\narchitectures\n\n\n\nLLMs can automate relevance assessments in low-resource languages, with results similar to high-resource languages.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTHaLLE: Text Hyperlocally Augmented Large Language Extension – Technical Report\n\n\n\narchitectures\n\n\nproduction\n\n\nprompt-engineering\n\n\neducation\n\n\n\nLLMs show promise in financial analysis, with our 8B THaLLE models outperforming others on mock CFA exams.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWorld Models with Hints of Large Language Models for Goal Achieving\n\n\n\nproduction\n\n\nhci\n\n\n\nDLLM, a multi-modal RL approach, improves exploration in long-horizon tasks by integrating hinting subgoals from LLMs, outperforming recent methods in sparse-reward…\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMBBQ: A Dataset for Cross-Lingual Comparison of Stereotypes in Generative LLMs\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLLMs exhibit language-dependent biases, with non-English languages suffering more. MBBQ dataset reveals cross-lingual differences in bias behavior.\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan Language Models Serve as Text-Based World Simulators?\n\n\n\nsocial-sciences\n\n\n\nLLMs, like GPT-4, are not yet reliable text-based world simulators, despite their capabilities, as per the ByteSized32-State-Prediction benchmark.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMolX: Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension\n\n\n\neducation\n\n\n\nLLMs struggle with molecule-related tasks; this study introduces MolX, a multi-modal external module, to enhance LLMs’ molecule comprehension, outperforming baselines in…\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024\n\n\n\nhci\n\n\neducation\n\n\nsocial-sciences\n\n\n\nTeam HYU_MLLAB_KT solves SMART-101 CVPR 2024 challenge with LLM and object detection, achieving 29.5 accuracy on test set and 27.1 WOSA on challenge set.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStronger, Faster, and Cheaper Log Parsing with LLMs\n\n\n\neducation\n\n\n\nLogBatcher: Cost-effective LLM-based log parser with no training or labeled data, using clustering and cache matching for efficient parsing.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards a Personal Health Large Language Model\n\n\n\neducation\n\n\n\nPH-LLM, a fine-tuned Gemini model, excels in personal health insights, outperforming experts in fitness and nearing their level in sleep, while accurately predicting sleep…\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecureNet: A Comparative Study of DeBERTa and Large Language Models for Phishing Detection\n\n\n\nrobustness\n\n\nsecurity\n\n\neducation\n\n\n\nTL;DR: DeBERTa V3 outperforms LLMs like GPT-4 in detecting phishing content, achieving 95.17% recall, while GPT-4 scores 91.04%.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Context Learning and Fine-Tuning GPT for Argument Mining\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nGPT-4 and GPT-3.5 excel in Argument Type Classification using In-Context Learning and fine-tuning, respectively.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCan I understand what I create? Self-Knowledge Evaluation of Large Language Models\n\n\n\nsocial-sciences\n\n\n\nLLMs struggle with self-generated questions due to human-alignment issues, but fine-tuning improves math performance.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedExQA: Medical Question Answering Benchmark with Multiple Explanations\n\n\n\neducation\n\n\n\nMedExQA benchmark evaluates medical knowledge in LLMs via explanations, highlighting the need for explainability. New medical model, MedPhi-2, outperforms Llama2-based…\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSafety Alignment Should Be Made More Than Just a Few Tokens Deep\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nShallow safety alignment in LLMs can lead to vulnerabilities; deepening alignment beyond initial tokens can improve robustness.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn Empirical Design Justice Approach to Identifying Ethical Considerations in the Intersection of Large Language Models and Social Robotics\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLLMs in social robotics offer benefits but raise ethical concerns like misinformation, biased responses, and emotional disruption, exacerbated by physical embodiment.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSilent Signals, Loud Impact: LLMs for Word-Sense Disambiguation of Coded Dog Whistles\n\n\n\nsocial-sciences\n\n\n\nLLMs used to create dataset of 16,550 disambiguated dog whistle examples for hate speech detection and political science.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShould We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue\n\n\n\nhci\n\n\neducation\n\n\n\nLLM adaptation techniques vary in effectiveness based on base LLM and dialogue type; human evaluation is crucial.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs\n\n\n\nhci\n\n\n\nTL;DR: Our method uses context-aware, query-relevant knowledge graphs to improve LLM performance on complex questions, reducing token usage by up to 67%.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRepoQA: Evaluating Long Context Code Understanding\n\n\n\neducation\n\n\n\nRepoQA benchmark evaluates LLMs on long-context code understanding, showing gaps in open vs. proprietary models and language-specific strengths.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnnotation alignment: Comparing LLM and human annotations of conversational safety\n\n\n\nsecurity\n\n\nsocial-sciences\n\n\n\nGPT-4 aligns with human safety perceptions, but more data is needed to assess demographic disparities and idiosyncratic variation.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHarnessing AI for efficient analysis of complex policy documents: a case study of Executive Order 14110\n\n\n\nsecurity\n\n\n\nAI systems Gemini 1.5 Pro and Claude 3 Opus excel in policy document analysis, rivaling human experts in accuracy but with greater efficiency.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models\n\n\n\nrobustness\n\n\nsecurity\n\n\nprompt-engineering\n\n\n\nTL;DR: Chain-of-Scrutiny (CoS) is a user-friendly, black-box defense against backdoor attacks in LLMs, ensuring reasoning consistency to detect attacks.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSynth-SBDH: A Synthetic Dataset of Social and Behavioral Determinants of Health for Clinical Text\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nSynth-SBDH dataset improves SBDH extraction from clinical text, outperforming counterparts and proving effective for rare categories and resource constraints.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRaccoon: Prompt Extraction Benchmark of LLM-Integrated Applications\n\n\n\nrobustness\n\n\nsecurity\n\n\nprompt-engineering\n\n\neducation\n\n\n\nRaccoon benchmark evaluates LLM susceptibility to prompt extraction attacks, offering insights and defenses.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDecision-Making Behavior Evaluation Framework for LLMs under Uncertain Context\n\n\n\nrobustness\n\n\nhci\n\n\nsocial-sciences\n\n\n\nLLMs, like ChatGPT-4.0-Turbo, Claude-3-Opus, and Gemini-1.0-pro, exhibit human-like decision-making patterns but vary in risk, probability, and loss aversion. Ethical…\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection\n\n\n\nrobustness\n\n\nsecurity\n\n\nprogramming\n\n\n\nCodeBreaker: LLM-assisted backdoor attack framework for code completion models, evading vulnerability detection.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating the Retrieval Component in LLM-Based Question Answering Systems\n\n\n\nhci\n\n\n\nBaseline for evaluating retrievers in RAG-based chatbots shows better performance assessment, considering LLMs’ strengths and weaknesses.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge language models for generating rules, yay or nay?\n\n\n\nprogramming\n\n\n\nLLMs can aid engineering safety-critical systems by generating logic rules, but lack threshold generation ability.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLanguage Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain\n\n\n\nsecurity\n\n\n\nNew dataset for medical triage decision-making; LLMs used as ethical decision-makers, alignable to different attributes.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course\n\n\n\nsocial-sciences\n\n\nprogramming\n\n\neducation\n\n\nhci\n\n\nprompt-engineering\n\n\n\nStudents’ LLM usage in programming education influenced by career expectations, peer usage, and affects self-efficacy and midterm performance.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTransforming Wearable Data into Health Insights using Large Language Model Agents\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nPHIA, a new AI system, accurately interprets wearable health data, potentially enabling personalized wellness insights.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Food Safety in Supply Chains: The Potential Role of Large Language Models in Preventing Campylobacter Contamination\n\n\n\nrobustness\n\n\n\nTL;DR: GPTs can aid HACCP implementation to reduce Campylobacter contamination in the food supply chain, but barriers exist.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM2CVD: Multi-Model Collaboration for Code Vulnerability Detection\n\n\n\nrobustness\n\n\nsecurity\n\n\nprogramming\n\n\n\nM2CVD combines LLMs and code models for improved vulnerability detection, outperforming baselines on real-world datasets.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLanguage Models Resist Alignment\n\n\n\nrobustness\n\n\n\nAlignment fine-tuning in LLMs is elastic and can revert to pre-training behavior, especially with larger models and more pre-training data.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niMotion-LLM: Motion Prediction Instruction Tuning\n\n\n\nrobustness\n\n\nhci\n\n\n\niMotion-LLM: A multimodal model for trajectory prediction in multi-agent scenarios, guided by textual instructions, enhancing safety and contextual relevance.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey of Backdoor Attacks and Defenses on Large Language Models: Implications for Security Measures\n\n\n\nrobustness\n\n\nsecurity\n\n\n\nTL;DR: This paper explores backdoor attacks on large language models, categorizing them by fine-tuning methods and discussing future research directions.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow Efficient is LLM-Generated Code? A Rigorous & High-Standard Benchmark\n\n\n\nprogramming\n\n\n\nLLMs struggle to generate expert-level efficient code, per new benchmark ENAMEL, which evaluates efficiency and correctness of LLM-generated code.\n\n\n\nJun 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDomainRAG: A Chinese Benchmark for Evaluating Domain-specific Retrieval-Augmented Generation\n\n\n\neducation\n\n\n\nRAG models outperform LLMs in domain-specific tasks like college enrollment, but improvements are needed in areas like conversation, structure analysis, and denoising.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Superalignment Framework in Autonomous Driving with Large Language Models\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\n\nTL;DR: Novel security framework for autonomous vehicles using multi-agent LLM approach, ensuring data protection and adherence to regulations.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHello Again! LLM-powered Personalized Agent for Long-term Dialogue\n\n\n\nhci\n\n\n\nLD-Agent: A framework for long-term dialogue systems with event memory, persona modeling, and response generation.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models Memorize Sensor Datasets! Implications on Human Activity Recognition Research\n\n\n\nrobustness\n\n\n\nLLMs may have seen HAR benchmark data during training, potentially skewing evaluation results.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Comprehensive Evaluation of Parameter-Efficient Fine-Tuning on Automated Program Repair\n\n\n\nprompt-engineering\n\n\n\nPEFT methods improve LLMs’ bug-fixing capabilities in APR, outperforming existing techniques. Larger parameters/datasets don’t guarantee better performance.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey on LLM-Based Agentic Workflows and LLM-Profiled Components\n\n\n\nprompt-engineering\n\n\n\nLLMs enable advanced workflows, focusing on reusable components for clearer role understanding.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecurity Vulnerability Detection with Multitask Self-Instructed Fine-Tuning of Large Language Models\n\n\n\nrobustness\n\n\nprompt-engineering\n\n\nsecurity\n\n\neducation\n\n\n\nMSIVD: Multitask LLM & GNN technique improves vulnerability detection, outperforming existing methods with F1 scores of 0.92 (BigVul) and 0.48 (PreciseBugs).\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n61A-Bot: AI homework assistance in CS1 is fast and cheap – but is it helpful?\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\n61A-Bot reduces homework completion time, but effects may not transfer to assignments without bot access.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMrRank: Improving Question Answering Retrieval System through Multi-Result Ranking Model\n\n\n\nrobustness\n\n\n\nNew method combines IR systems for LLMs, improving performance and reducing hallucinations.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLGR2: Language Guided Reward Relabeling for Accelerating Hierarchical Reinforcement Learning\n\n\n\nhci\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\nprogramming\n\n\n\nLGR2: A language-guided HRL framework for robotic control, mitigating non-stationarity and achieving high success rates in complex tasks.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo LLMs Exhibit Human-Like Reasoning? Evaluating Theory of Mind in LLMs for Open-Ended Responses\n\n\n\nhci\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLLMs struggle with Theory of Mind reasoning in open-ended questions, but incorporating human intentions and emotions can improve their performance, though not fully…\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMoPS: Modular Story Premise Synthesis for Open-Ended Automatic Story Generation\n\n\n\nsocial-sciences\n\n\neducation\n\n\n\nMoPS generates diverse, fascinating, and original story premises for automatic story generation, outperforming existing methods.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Against the RAG: Jamming Retrieval-Augmented Generation with Blocker Documents\n\n\n\nrobustness\n\n\n\nTL;DR: RAG systems are vulnerable to jamming attacks using blocker documents, which can prevent them from answering queries. New methods for generating blocker documents are…\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nZero-Shot End-To-End Spoken Question Answering In Medical Domain\n\n\n\nhci\n\n\n\nE2E methodologies for SQA in the medical domain require fewer resources and improve accuracy compared to traditional cascade systems.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States\n\n\n\nrobustness\n\n\n\nLLMs learn ethics in pre-training, align concepts with emotions, and refine for safe output. Jailbreaks disrupt this process, causing harm.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre Large Language Models Actually Good at Text Style Transfer?\n\n\n\nprompt-engineering\n\n\nsocial-sciences\n\n\n\nLLMs struggle with TST in non-English languages, but finetuning improves results, highlighting the need for dedicated datasets.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDigital Business Model Analysis Using a Large Language Model\n\n\n\nhci\n\n\nprogramming\n\n\n\nThis study proposes an LLM-based method for comparing and analyzing similar companies across different business domains to support digital business model design.\n\n\n\nJun 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreativity Has Left the Chat: The Price of Debiasing Language Models\n\n\n\nhci\n\n\nprompt-engineering\n\n\n\nRLHF alignment in LLMs reduces toxicity but limits creativity, impacting marketing tasks. Balance between consistency and creativity is crucial.\n\n\n\nJun 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo LLMs Recognize me, When I is not me: Assessment of LLMs Understanding of Turkish Indexical Pronouns in Indexical Shift Contexts\n\n\n\nsocial-sciences\n\n\n\nTL;DR: Advanced LLMs struggle with Turkish’s unique grammatical challenge, the Indexical Shift, highlighting the need for low-resource language research.\n\n\n\nJun 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Do Language Models Learn in Context? The Structured Task Hypothesis\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\n[TEXT] This study examines the relationship between social media use and mental health in young adults. Results indicate a significant correlation between excessive social…\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVerbalized Machine Learning: Revisiting Machine Learning with Language Models\n\n\n\nprompt-engineering\n\n\n\nVML uses LLMs to solve ML problems, offering easy encoding of inductive bias, automatic model class selection, and interpretable learner updates.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAsk LLMs Directly, What shapes your bias?: Measuring Social Bias in Large Language Models\n\n\n\nhci\n\n\n\nThis paper proposes a method to quantify social biases in LLMs by considering diverse social perceptions, offering a more nuanced understanding of bias.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemantically Diverse Language Generation for Uncertainty Estimation in Language Models\n\n\n\nrobustness\n\n\n\nLLMs can hallucinate due to predictive uncertainty. SDLG quantifies this, improving trustworthiness and efficiency in LLMs.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAligning Agents like Large Language Models\n\n\n\nhci\n\n\n\nWe align 3D agents with desired behaviors using LLM alignment techniques, improving imitation learning.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeneralization-Enhanced Code Vulnerability Detection via Multi-Task Instruction Fine-Tuning\n\n\n\nprogramming\n\n\n\nVulLLM, a multi-task framework with LLMs, outperforms SOTA models in vulnerability detection by capturing root causes, not just superficial features.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM-QALM: A Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall in Large Language Models via Question Answering\n\n\n\neducation\n\n\n\nLLMs’ success in healthcare tasks depends on recall, comprehension, and integration of knowledge, with instruction tuning and fine-tuning on medical datasets showing promise.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models as Evaluators for Recommendation Explanations\n\n\n\nrecommender\n\n\n\nLLMs, like GPT4, can accurately evaluate recommendation explanations with proper prompts and settings, offering a cost-effective solution.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDICE: Detecting In-distribution Contamination in LLM’s Fine-tuning Phase for Math Reasoning\n\n\n\neducation\n\n\n\nDICE detects in-distribution contamination in LLMs, potentially overestimating model capabilities.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMEmbed: Rethinking Lightweight LLM’s Genuine Function in Text Classification\n\n\n\nprompt-engineering\n\n\n\nLLMEmbed: Efficient LLM-based text classification with low overhead.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Survey on Medical Large Language Models: Technology, Application, Trustworthiness, and Future Directions\n\n\n\nprogramming\n\n\n\nMed-LLMs revolutionize healthcare, offering clinical decision support, report generation, and medical education. Ethical considerations and robust evaluation are crucial for…\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuffer of Thoughts: Thought-Augmented Reasoning with Large Language Models\n\n\n\nprompt-engineering\n\n\n\nBoT improves LLMs’ reasoning, outperforming SOTA methods on 10 tasks with 12% cost, potentially surpassing Llama3-70B with Llama3-8B.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People\n\n\n\nhci\n\n\n\nThis study proposes a method to compare human and GPT-4 conversational tones, creating an interpretable representation of their relations.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRefactoring to Pythonic Idioms: A Hybrid Knowledge-Driven Approach Leveraging Large Language Models\n\n\n\nprompt-engineering\n\n\n\nHybrid approach combines LLMs and rule-based methods for Python code idiomatization, outperforming LLM-only and rule-based approaches.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPOEM: Interactive Prompt Optimization for Enhancing Multimodal Reasoning of Large Language Models\n\n\n\nprompt-engineering\n\n\neducation\n\n\n\nIntroducing ame: A Visual Analytics System for Prompt Engineering in Multimodal LLMs.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRetrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining\n\n\n\nprompt-engineering\n\n\n\nContext-Aware RAG improves prompt-based TTS, outperforming text-only retrieval methods.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaCE: Parsimonious Concept Engineering for Large Language Models\n\n\n\nrobustness\n\n\n\nTL;DR: PaCE is a novel framework for aligning LLMs, improving output quality while preserving linguistic capabilities.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoherent Zero-Shot Visual Instruction Generation\n\n\n\neducation\n\n\n\nNew framework generates consistent, visually appealing multi-step instructions using diffusion models and LLMs.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfabulation: The Surprising Value of Large Language Model Hallucinations\n\n\n\nhci\n\n\n\nLLM confabulations mirror human narrativity, offering potential value in AI communication.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBenchmark Data Contamination of Large Language Models: A Survey\n\n\n\nprogramming\n\n\n\nTL;DR: Large Language Models face Benchmark Data Contamination, requiring new evaluation methods for reliable performance.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nText-to-Drive: Diverse Driving Behavior Synthesis via Large Language Models\n\n\n\nhci\n\n\nsocial-sciences\n\n\n\nTL;DR: Text-to-Drive (T2D) uses LLMs to generate diverse driving behaviors for autonomous vehicle simulation, offering a scalable and intuitive method for human operators.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTool-Planner: Dynamic Solution Tree Planning for Large Language Model with Tool Clustering\n\n\n\neducation\n\n\n\nTL;DR: Tool-Planner improves tool learning in LLMs like GPT-4 and Claude 3, optimizing planning and handling errors.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFastGAS: Fast Graph-based Annotation Selection for In-Context Learning\n\n\n\nprompt-engineering\n\n\n\nFastGAS: A graph-based method for efficient instance selection in in-context learning, improving performance and reducing selection time.\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nItem-Language Model for Conversational Recommendation\n\n\n\nrecommender\n\n\nprogramming\n\n\n\nTL;DR: Proposed Item-Language Model (ILM) addresses LLM limitations in recommender systems, aligning item representations with user interaction signals.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSynthetic Programming Elicitation and Repair for Text-to-Code in Very Low-Resource Programming Languages\n\n\n\nprogramming\n\n\n\nLLMs struggle with unseen programming languages. SPEAC, a new approach, enables LLMs to generate valid code for these languages.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nText-like Encoding of Collaborative Information in Large Language Models for Recommendation\n\n\n\nrecommender\n\n\n\nBinLLM: A novel method integrating collaborative info into LLMs via text-like binary encoding, improving recommendation performance.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Detecting LLMs Hallucination via Markov Chain-based Multi-agent Debate Framework\n\n\n\nprogramming\n\n\n\nMarkov Chain-based multi-agent debate improves hallucination detection in LLMs, outperforming baselines.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBIPED: Pedagogically Informed Tutoring System for ESL Education\n\n\n\neducation\n\n\n\nLLMs can serve as effective tutors for English learners. We developed a dataset and models that replicate human teachers’ diverse teaching strategies.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models\n\n\n\nprogramming\n\n\n\nThis work enhances LLMs for long texts by considering fragment-level relations, improving story understanding, code generation, and chatting.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnhancing Repository-Level Code Generation with Integrated Contextual Information\n\n\n\nprogramming\n\n\n\nCatCoder improves LLM code generation for repositories, outperforming RepoCoder by up to 17.35% in pass@k score, and shows consistent improvements across various LLMs.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring User Retrieval Integration towards Large Language Models for Cross-Domain Sequential Recommendation\n\n\n\nrecommender\n\n\n\nURLLM improves CDSR by integrating user retrieval and domain grounding on LLM, addressing cold-start issues and semantic reasoning.\n\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPosition Debiasing Fine-Tuning for Causal Perception in Long-Term Dialogue\n\n\n\nprogramming\n\n\n\nCPD method alleviates position bias in LLMs, improving long-term dialogue relevance.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nXRec: Large Language Models for Explainable Recommendation\n\n\n\nrecommender\n\n\n\nXRec framework uses LLMs for explainable recommendations, outperforming baselines in understanding user preferences.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe current status of large language models in summarizing radiology report impressions\n\n\n\nprogramming\n\n\n\nLLMs struggle to replace radiologists in summarizing radiology reports, despite few-shot prompt improvements.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models Make Sample-Efficient Recommender Systems\n\n\n\nrecommender\n\n\n\nLLMs improve recommender systems’ efficiency, needing less training data for superior performance.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Mathematical Extrapolation of Large Language Models with Synthetic Data\n\n\n\nprogramming\n\n\n\nLLMs excel in various tasks but struggle with multi-step reasoning. Fine-tuning on synthetic data improves performance in complex arithmetic puzzles.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChain of Agents: Large Language Models Collaborating on Long-Context Tasks\n\n\n\nprogramming\n\n\n\nChain-of-Agents (CoA) improves long-context tasks by dividing text among agents, showing up to 10% improvement over baselines.\n\n\n\nJun 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Understand Whole Software Repository?\n\n\n\nprogramming\n\n\n\nTL;DR: RepoUnderstander improves ASE by understanding whole repositories, outperforming SWE-agent by 18.5%.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemCoder: Training Code Language Models with Comprehensive Semantics\n\n\n\nprogramming\n\n\n\nSemCoder: A 6.7B Code LLM excels in code generation and execution reasoning, outperforming GPT-3.5-turbo, by integrating semantics from multiple dimensions.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession Context Embedding for Intent Understanding in Product Search\n\n\n\nrecommender\n\n\n\nSession embedding improves search by capturing user intent from multiple engagements, outperforming single query-item pair relevance training.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrivacy in LLM-based Recommendation: Recent Advances and Future Directions\n\n\n\nrecommender\n\n\n\nPrivacy in LLM-based recommendations: attacks, protection, challenges, and future directions.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLarge Language Models as Recommender Systems: A Study of Popularity Bias\n\n\n\nrecommender\n\n\n\nLLMs in recommenders can reduce popularity bias, showing less bias than traditional systems without explicit mitigation.\n\n\n\nJun 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerating Query Recommendations via LLMs\n\n\n\nrecommender\n\n\n\n[TEXT] This study examines the impact of climate change on the global wine industry. Results indicate significant shifts in wine production regions and grape varieties due…\n\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKnowledge Graph Tuning: Real-time Large Language Model Personalization based on Human Feedback\n\n\n\nrecommender\n\n\n\nKGT: A novel, efficient, and interpretable method for real-time personalization of LLMs using knowledge graphs, improving user experience and performance.\n\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKeyword-driven Retrieval-Augmented Large Language Models for Cold-start User Recommendations\n\n\n\nrecommender\n\n\n\nTL;DR: KALM4Rec improves cold-start recommendations using keywords and LLMs for candidate retrieval and re-ranking.\n\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPreference Learning Algorithms Do Not Learn Preference Rankings\n\n\n\nrecommender\n\n\n\nDespite high performance, preference-tuned LLMs often have low ranking accuracy, due to limitations in the DPO objective and a gap between observed and idealized ranking…\n\n\n\nMay 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSLMRec: Empowering Small Language Models for Sequential Recommendation\n\n\n\nrecommender\n\n\n\nSLMRec: Small Language Model for Sequential Recommendation achieves 6.6x training, 8.0x inference speedups with 13% of LLM-based model parameters.\n\n\n\nMay 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteLLM-2: Multimodal Large Representation Models for Recommendation\n\n\n\nrecommender\n\n\n\nTL;DR: NoteLLM-2 enhances multimodal representation in I2I recommendations by focusing on visual content and fusing it with textual information.\n\n\n\nMay 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRAGSys: Item-Cold-Start Recommender as RAG System\n\n\n\nrecommender\n\n\n\nICL for LLMs resembles item-cold-start recommenders, prioritizing discovery and maximizing information gain. Diversity and quality bias in demonstrations are crucial for…\n\n\n\nMay 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLMs for User Interest Exploration: A Hybrid Approach\n\n\n\nrecommender\n\n\n\nHybrid framework with LLMs and classic models improves novel interest discovery, boosting user enjoyment.\n\n\n\nMay 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNavigating User Experience of ChatGPT-based Conversational Recommender Systems: The Effects of Prompt Guidance and Recommendation Domain\n\n\n\nrecommender\n\n\n\nPrompt guidance in ChatGPT-based CRS enhances user experience, with book recommendations showing more engagement than job recommendations.\n\n\n\nMay 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSunnie: An Anthropomorphic LLM-Based Conversational Agent for Mental Well-Being Activity Recommendation\n\n\n\nrecommender\n\n\n\nThis LaTeX document guides authors on formatting ACM articles.\n\n\n\nMay 22, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/What_Do_Language_Models_Learn_in_Context_The_Structured_Task_Hypothesis/2024-06-06-What_Do_Language_Models_Learn_in_Context_The_Structured_Task_Hypothesis.html#appendix",
    "href": "posts/What_Do_Language_Models_Learn_in_Context_The_Structured_Task_Hypothesis/2024-06-06-What_Do_Language_Models_Learn_in_Context_The_Structured_Task_Hypothesis.html#appendix",
    "title": "What Do Language Models Learn in Context? The Structured Task Hypothesis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04216v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04216v1\n\n\nTruncated\nFalse\n\n\nWord Count\n15"
  },
  {
    "objectID": "posts/Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue/2024-06-04-Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue.html",
    "href": "posts/Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue/2024-06-04-Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue.html",
    "title": "Position Debiasing Fine-Tuning for Causal Perception in Long-Term Dialogue",
    "section": "",
    "text": "Summary:\nThe paper proposes a novel method, Causal Perception long-term Dialogue framework (CPD), to alleviate the position bias in large language models (LLMs) for long-term dialogue tasks. The CPD framework employs perturbation-based causal variable discovery to extract causally relevant utterances from dialogue history and enhances the model’s causal perception during fine-tuning. The framework includes a local-position awareness method for inter-sentence position correlation elimination and a causal-perception fine-tuning strategy to improve the model’s ability to discover causal invariant factors. Experimental results on two datasets demonstrate that the proposed method effectively alleviates position bias and achieves significant progress compared to existing baselines.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a well-structured and coherent summary of the proposed CPD framework for addressing position bias in LLMs for long-term dialogue tasks. The use of perturbation-based causal variable discovery and the local-position awareness method are innovative approaches to extract causally relevant utterances from dialogue history. The causal-perception fine-tuning strategy also provides a promising direction for improving the model’s ability to discover causal invariant factors.\nHowever, the paper could benefit from a more detailed analysis of the limitations and potential biases of the proposed method. For instance, the paper does not discuss the potential impact of the perturbation-based approach on the model’s performance or the generalizability of the method to other types of dialogue tasks. Additionally, the paper could provide more insights into the potential challenges and trade-offs in implementing the proposed method in real-world applications.\nOverall, the paper presents a promising approach to addressing position bias in LLMs for long-term dialogue tasks. The proposed CPD framework and the experimental results provide valuable insights into the potential of perturbation-based causal variable discovery and causal-perception fine-t"
  },
  {
    "objectID": "posts/Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue/2024-06-04-Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue.html#appendix",
    "href": "posts/Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue/2024-06-04-Position_Debiasing_Fine_Tuning_for_Causal_Perception_in_Long_Term_Dialogue.html#appendix",
    "title": "Position Debiasing Fine-Tuning for Causal Perception in Long-Term Dialogue",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-14\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02002v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02002v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7030"
  },
  {
    "objectID": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#major-findings",
    "href": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#major-findings",
    "title": "MolX: Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nMolX significantly improves the performance of LLMs on various molecule-related tasks, outperforming baselines on tasks such as molecule-to-text translation, retrosynthesis, and property prediction.\nMolX can act as a plug-in module to the LLM, enhancing its performance on molecule-related tasks while fully preserving its general-purpose usage on other domains.\nThe proposed method only introduces a small number of trainable parameters, making it an efficient solution for enhancing LLMs."
  },
  {
    "objectID": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#analysis-and-critique",
    "href": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#analysis-and-critique",
    "title": "MolX: Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe paper does not discuss the potential limitations of the MolX framework, such as its performance on more complex molecular structures or its ability to handle large-scale molecular datasets.\nThe paper does not provide a comparison with other multi-modal approaches for molecular learning, which could provide a more comprehensive evaluation of the proposed method.\nThe paper does not discuss the potential applications of MolX in other domains, such as drug discovery or materials science, which could provide additional insights into its potential impact.\nThe paper does not discuss the potential ethical implications of using LLMs for molecular learning, such as the potential for bias in the generated molecular structures or the potential for misuse in the development of harmful substances.\n\nOverall, the paper presents a promising approach for enhancing the ability of LLMs to comprehend molecules. However, further research is needed to fully evaluate its limitations, compare it with other approaches, and explore its potential applications and ethical implications."
  },
  {
    "objectID": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#appendix",
    "href": "posts/MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension/2024-06-10-MolX_Enhancing_Large_Language_Models_for_Molecular_Learning_with_A_Multi_Modal_Extension.html#appendix",
    "title": "MolX: Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06777v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06777v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8694"
  },
  {
    "objectID": "posts/Ollabench_Evaluating_LLMs_Reasoning_for_Human_centric_Interdependent_Cybersecurity/2024-06-11-Ollabench_Evaluating_LLMs_Reasoning_for_Human_centric_Interdependent_Cybersecurity.html#appendix",
    "href": "posts/Ollabench_Evaluating_LLMs_Reasoning_for_Human_centric_Interdependent_Cybersecurity/2024-06-11-Ollabench_Evaluating_LLMs_Reasoning_for_Human_centric_Interdependent_Cybersecurity.html#appendix",
    "title": "Ollabench: Evaluating LLMs’ Reasoning for Human-centric Interdependent Cybersecurity",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06863v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06863v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7305"
  },
  {
    "objectID": "posts/XRec_Large_Language_Models_for_Explainable_Recommendation/2024-06-04-XRec_Large_Language_Models_for_Explainable_Recommendation.html#appendix",
    "href": "posts/XRec_Large_Language_Models_for_Explainable_Recommendation/2024-06-04-XRec_Large_Language_Models_for_Explainable_Recommendation.html#appendix",
    "title": "XRec: Large Language Models for Explainable Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-14\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02377v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02377v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6297"
  },
  {
    "objectID": "posts/Anomaly_Detection_on_Unstable_Logs_with_GPT_Models/2024-06-11-Anomaly_Detection_on_Unstable_Logs_with_GPT_Models.html#appendix",
    "href": "posts/Anomaly_Detection_on_Unstable_Logs_with_GPT_Models/2024-06-11-Anomaly_Detection_on_Unstable_Logs_with_GPT_Models.html#appendix",
    "title": "Anomaly Detection on Unstable Logs with GPT Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07467v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07467v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11408"
  },
  {
    "objectID": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#major-findings",
    "href": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#major-findings",
    "title": "SemCoder: Training Code Language Models with Comprehensive Semantics",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe paper introduces a novel strategy to train Code LLMs with comprehensive semantics, including high-level functional descriptions, local execution effects of individual statements, and overall input/output behavior.\nThe authors propose training Code LLMs to write code and represent and reason about execution behaviors using natural language, mimicking human verbal debugging.\nThe paper presents SEMCODER, a Code LLM with only 6.7B parameters, which shows competitive performance with GPT-3.5-turbo on code generation and execution reasoning tasks.\nSEMCODER achieves 81.1% on HumanEval (GPT-3.5-turbo: 76.8%) and 54.5% on CRUXEval-I (GPT-3.5-turbo: 50.3%).\nThe paper also studies the effectiveness of SEMCODER’s monologue-style execution reasoning compared to concrete scratchpad reasoning, showing that their approach integrates semantics from multiple dimensions more smoothly."
  },
  {
    "objectID": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#analysis-and-critique",
    "href": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#analysis-and-critique",
    "title": "SemCoder: Training Code Language Models with Comprehensive Semantics",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents a novel approach to training Code LLMs with comprehensive semantics, which has the potential to improve the performance of Code LLMs on code generation and execution reasoning tasks. The authors’ proposal to train Code LLMs to write code and represent and reason about execution behaviors using natural language is an interesting and promising direction.\nHowever, the paper does not provide a detailed comparison of SEMCODER with other state-of-the-art Code LLMs, which makes it difficult to evaluate the effectiveness of their approach. Additionally, the"
  },
  {
    "objectID": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#appendix",
    "href": "posts/SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics/2024-06-03-SemCoder_Training_Code_Language_Models_with_Comprehensive_Semantics.html#appendix",
    "title": "SemCoder: Training Code Language Models with Comprehensive Semantics",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-14\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01006v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01006v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18724"
  },
  {
    "objectID": "posts/Synthetic_Programming_Elicitation_and_Repair_for_Text_to_Code_in_Very_Low_Resource_Programming_Languages/2024-06-05-Synthetic_Programming_Elicitation_and_Repair_for_Text_to_Code_in_Very_Low_Resource_Programming_Languages.html#appendix",
    "href": "posts/Synthetic_Programming_Elicitation_and_Repair_for_Text_to_Code_in_Very_Low_Resource_Programming_Languages/2024-06-05-Synthetic_Programming_Elicitation_and_Repair_for_Text_to_Code_in_Very_Low_Resource_Programming_Languages.html#appendix",
    "title": "Synthetic Programming Elicitation and Repair for Text-to-Code in Very Low-Resource Programming Languages",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03636v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03636v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9438"
  },
  {
    "objectID": "posts/Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models/2024-06-08-Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models.html",
    "href": "posts/Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models/2024-06-08-Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models.html",
    "title": "Creativity Has Left the Chat: The Price of Debiasing Language Models",
    "section": "",
    "text": "Summary:\nThe paper “Creativity Has Left the Chat: The Price of Debiasing Language Models” explores the impact of the Reinforcement Learning from Human Feedback (RLHF) process on the creativity and output diversity of Large Language Models (LLMs). The authors use the Llama-2 series of models to conduct three experiments, focusing on the Llama-2-7B-text (base model) and Llama-2-7B-chat (aligned model). The experiments reveal that while RLHF effectively reduces biases and toxicity in LLMs, it may inadvertently lead to a reduction in the models’ creative potential. The aligned models exhibit lower entropy in token predictions, form distinct clusters in the embedding space, and gravitate towards “attractor states,” indicating limited output diversity. These findings have significant implications for marketers who rely on LLMs for creative tasks, as the trade-off between consistency and creativity in aligned models should be carefully considered.\nMajor Findings:\nAnalysis and Critique:\nThe paper provides valuable insights into the unintended consequences of the RLHF process on the creativity and output diversity of LLMs. However, the study is limited by the computational costs and resource demands, which prevented the authors from delving into various parameters or configurations of the RLHF process. Future research should explore different parameters and configurations to understand their impact on the creativity and output diversity of aligned LLMs. Additionally, further investigation is needed to analyze other unintended consequences of model alignment and RLHF to enhance our understanding of the trade-offs involved in practical applications of these models."
  },
  {
    "objectID": "posts/Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models/2024-06-08-Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models.html#appendix",
    "href": "posts/Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models/2024-06-08-Creativity_Has_Left_the_Chat_The_Price_of_Debiasing_Language_Models.html#appendix",
    "title": "Creativity Has Left the Chat: The Price of Debiasing Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05587v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05587v1\n\n\nTruncated\nFalse\n\n\nWord Count\n20391"
  },
  {
    "objectID": "posts/Verbalized_Machine_Learning_Revisiting_Machine_Learning_with_Language_Models/2024-06-06-Verbalized_Machine_Learning_Revisiting_Machine_Learning_with_Language_Models.html#appendix",
    "href": "posts/Verbalized_Machine_Learning_Revisiting_Machine_Learning_with_Language_Models/2024-06-06-Verbalized_Machine_Learning_Revisiting_Machine_Learning_with_Language_Models.html#appendix",
    "title": "Verbalized Machine Learning: Revisiting Machine Learning with Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04344v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04344v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10781"
  },
  {
    "objectID": "posts/Text_like_Encoding_of_Collaborative_Information_in_Large_Language_Models_for_Recommendation/2024-06-05-Text_like_Encoding_of_Collaborative_Information_in_Large_Language_Models_for_Recommendation.html#appendix",
    "href": "posts/Text_like_Encoding_of_Collaborative_Information_in_Large_Language_Models_for_Recommendation/2024-06-05-Text_like_Encoding_of_Collaborative_Information_in_Large_Language_Models_for_Recommendation.html#appendix",
    "title": "Text-like Encoding of Collaborative Information in Large Language Models for Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03210v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03210v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6859"
  },
  {
    "objectID": "posts/Stronger_Faster_and_Cheaper_Log_Parsing_with_LLMs/2024-06-10-Stronger_Faster_and_Cheaper_Log_Parsing_with_LLMs.html#appendix",
    "href": "posts/Stronger_Faster_and_Cheaper_Log_Parsing_with_LLMs/2024-06-10-Stronger_Faster_and_Cheaper_Log_Parsing_with_LLMs.html#appendix",
    "title": "Stronger, Faster, and Cheaper Log Parsing with LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06156v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06156v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11355"
  },
  {
    "objectID": "posts/Towards_a_Personal_Health_Large_Language_Model/2024-06-10-Towards_a_Personal_Health_Large_Language_Model.html",
    "href": "posts/Towards_a_Personal_Health_Large_Language_Model/2024-06-10-Towards_a_Personal_Health_Large_Language_Model.html",
    "title": "Towards a Personal Health Large Language Model",
    "section": "",
    "text": "Summary:\nThe paper introduces Personal Health Large Language Model (PH-LLM), a version of Gemini fine-tuned for personal health and wellness. PH-LLM is evaluated on three aspects of personal health: generating personalized insights and recommendations for user goals in the domains of sleep and fitness, assessing levels of expert domain knowledge, and predicting patient-reported outcomes in sleep quality from detailed sensor information. The model is benchmarked against expert human responses and evaluated through comprehensive human and automatic evaluation of domain-specific rubrics. The results show that both Gemini Ultra 1.0 and PH-LLM are not statistically different from expert performance in fitness, while experts remain superior for sleep. However, fine-tuning PH-LLM provided significant improvements in using relevant domain knowledge and personalizing information for sleep insights. PH-LLM achieved 79% on sleep (N=629 questions) and 88% on fitness (N=99 questions) in multiple choice question examinations, both of which exceed average scores from a sample of human experts. The model also demonstrated the ability to predict self-reported assessments of sleep quality by training it to predict self-reported sleep disruption and sleep impairment outcomes from textual and multimodal encoding representations of wearable sensor data.\nMajor Findings:"
  },
  {
    "objectID": "posts/Towards_a_Personal_Health_Large_Language_Model/2024-06-10-Towards_a_Personal_Health_Large_Language_Model.html#appendix",
    "href": "posts/Towards_a_Personal_Health_Large_Language_Model/2024-06-10-Towards_a_Personal_Health_Large_Language_Model.html#appendix",
    "title": "Towards a Personal Health Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06474v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06474v1\n\n\nTruncated\nFalse\n\n\nWord Count\n17580"
  },
  {
    "objectID": "posts/Generating_Query_Recommendations_via_LLMs/2024-05-30-Generating_Query_Recommendations_via_LLMs.html#appendix",
    "href": "posts/Generating_Query_Recommendations_via_LLMs/2024-05-30-Generating_Query_Recommendations_via_LLMs.html#appendix",
    "title": "Generating Query Recommendations via LLMs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-14\n\n\nAbstract\nhttps://arxiv.org/abs/2405.19749v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.19749v1\n\n\nTruncated\nFalse\n\n\nWord Count\n1852"
  },
  {
    "objectID": "posts/Single_Codec_Single_Codebook_Speech_Codec_towards_High_Performance_Speech_Generation/2024-06-11-Single_Codec_Single_Codebook_Speech_Codec_towards_High_Performance_Speech_Generation.html#appendix",
    "href": "posts/Single_Codec_Single_Codebook_Speech_Codec_towards_High_Performance_Speech_Generation/2024-06-11-Single_Codec_Single_Codebook_Speech_Codec_towards_High_Performance_Speech_Generation.html#appendix",
    "title": "Single-Codec: Single-Codebook Speech Codec towards High-Performance Speech Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07422v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07422v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4062"
  },
  {
    "objectID": "posts/Knowledge_Graph_Tuning_Real_time_Large_Language_Model_Personalization_based_on_Human_Feedback/2024-05-30-Knowledge_Graph_Tuning_Real_time_Large_Language_Model_Personalization_based_on_Human_Feedback.html#appendix",
    "href": "posts/Knowledge_Graph_Tuning_Real_time_Large_Language_Model_Personalization_based_on_Human_Feedback/2024-05-30-Knowledge_Graph_Tuning_Real_time_Large_Language_Model_Personalization_based_on_Human_Feedback.html#appendix",
    "title": "Knowledge Graph Tuning: Real-time Large Language Model Personalization based on Human Feedback",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-14\n\n\nAbstract\nhttps://arxiv.org/abs/2405.19686v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.19686v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6292"
  },
  {
    "objectID": "posts/Hello_Again!_LLM_powered_Personalized_Agent_for_Long_term_Dialogue/2024-06-09-Hello_Again!_LLM_powered_Personalized_Agent_for_Long_term_Dialogue.html#appendix",
    "href": "posts/Hello_Again!_LLM_powered_Personalized_Agent_for_Long_term_Dialogue/2024-06-09-Hello_Again!_LLM_powered_Personalized_Agent_for_Long_term_Dialogue.html#appendix",
    "title": "Hello Again! LLM-powered Personalized Agent for Long-term Dialogue",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05925v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05925v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6818"
  },
  {
    "objectID": "posts/In_Context_Learning_and_Fine_Tuning_GPT_for_Argument_Mining/2024-06-10-In_Context_Learning_and_Fine_Tuning_GPT_for_Argument_Mining.html#appendix",
    "href": "posts/In_Context_Learning_and_Fine_Tuning_GPT_for_Argument_Mining/2024-06-10-In_Context_Learning_and_Fine_Tuning_GPT_for_Argument_Mining.html#appendix",
    "title": "In-Context Learning and Fine-Tuning GPT for Argument Mining",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06699v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06699v1\n\n\nTruncated\nFalse\n\n\nWord Count\n2590"
  },
  {
    "objectID": "posts/Limited_Out_of_Context_Knowledge_Reasoning_in_Large_Language_Models/2024-06-11-Limited_Out_of_Context_Knowledge_Reasoning_in_Large_Language_Models.html#appendix",
    "href": "posts/Limited_Out_of_Context_Knowledge_Reasoning_in_Large_Language_Models/2024-06-11-Limited_Out_of_Context_Knowledge_Reasoning_in_Large_Language_Models.html#appendix",
    "title": "Limited Out-of-Context Knowledge Reasoning in Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07393v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07393v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5931"
  },
  {
    "objectID": "posts/Reinforcement_Learning_from_Human_Feedback_without_Reward_Inference_Model_Free_Algorithm_and_Instance_Dependent_Analysis/2024-06-11-Reinforcement_Learning_from_Human_Feedback_without_Reward_Inference_Model_Free_Algorithm_and_Instance_Dependent_Analysis.html#appendix",
    "href": "posts/Reinforcement_Learning_from_Human_Feedback_without_Reward_Inference_Model_Free_Algorithm_and_Instance_Dependent_Analysis/2024-06-11-Reinforcement_Learning_from_Human_Feedback_without_Reward_Inference_Model_Free_Algorithm_and_Instance_Dependent_Analysis.html#appendix",
    "title": "Reinforcement Learning from Human Feedback without Reward Inference: Model-Free Algorithm and Instance-Dependent Analysis",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07455v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07455v1\n\n\nTruncated\nFalse\n\n\nWord Count\n11143"
  },
  {
    "objectID": "posts/RS_Agent_Automating_Remote_Sensing_Tasks_through_Intelligent_Agents/2024-06-11-RS_Agent_Automating_Remote_Sensing_Tasks_through_Intelligent_Agents.html#appendix",
    "href": "posts/RS_Agent_Automating_Remote_Sensing_Tasks_through_Intelligent_Agents/2024-06-11-RS_Agent_Automating_Remote_Sensing_Tasks_through_Intelligent_Agents.html#appendix",
    "title": "RS-Agent: Automating Remote Sensing Tasks through Intelligent Agents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07089v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07089v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5913"
  },
  {
    "objectID": "posts/A_Comprehensive_Evaluation_of_Parameter_Efficient_Fine_Tuning_on_Automated_Program_Repair/2024-06-09-A_Comprehensive_Evaluation_of_Parameter_Efficient_Fine_Tuning_on_Automated_Program_Repair.html#appendix",
    "href": "posts/A_Comprehensive_Evaluation_of_Parameter_Efficient_Fine_Tuning_on_Automated_Program_Repair/2024-06-09-A_Comprehensive_Evaluation_of_Parameter_Efficient_Fine_Tuning_on_Automated_Program_Repair.html#appendix",
    "title": "A Comprehensive Evaluation of Parameter-Efficient Fine-Tuning on Automated Program Repair",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05639v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05639v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12423"
  },
  {
    "objectID": "posts/CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only/2024-06-11-CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only.html",
    "href": "posts/CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only/2024-06-11-CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only.html",
    "title": "CAAP: Context-Aware Action Planning Prompting to Solve Computer Tasks with Front-End UI Only",
    "section": "",
    "text": "Summary:\nThe paper introduces an LLM-based agent that operates solely on the basis of screenshots for recognizing environments, while leveraging in-context learning to eliminate the need for collecting large datasets of human demonstration. The proposed method, named Context-Aware Action Planning (CAAP) prompting, encourages the agent to meticulously review the context in various angles. The agent achieves a success rate of 94.4% on 67 types of MiniWoB++ problems, utilizing only 1.48 demonstrations per problem type. The method offers the potential for broader applications, especially for tasks that require inter-application coordination on computers or smartphones.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents a novel approach to LLM-based agents that addresses the limitations of existing methods reliant on HTML or DOM inputs and those that combine supervised learning (SL) and reinforcement learning (RL). The proposed agent operates solely on visual inputs and utilizes a large language model (LLM). The CAAP prompting approach is introduced to enhance the decision-making capabilities of ICL-based agents. The evaluations using the MiniWoB++ benchmark demonstrate the superiority of the proposed method. However, the scope of validation remains limited, and further research is needed to evaluate the agent across a broader array of benchmarks. Additionally, the agent’s reliance on visual observation data may lead to observation failures, as demonstrated in the case study. The paper also acknowledges the limitations of the benchmark directives and the need for more comprehensive assessment from a research perspective."
  },
  {
    "objectID": "posts/CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only/2024-06-11-CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only.html#appendix",
    "href": "posts/CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only/2024-06-11-CAAP_Context_Aware_Action_Planning_Prompting_to_Solve_Computer_Tasks_with_Front_End_UI_Only.html#appendix",
    "title": "CAAP: Context-Aware Action Planning Prompting to Solve Computer Tasks with Front-End UI Only",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06947v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06947v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10877"
  },
  {
    "objectID": "posts/A_Survey_on_LLM_Based_Agentic_Workflows_and_LLM_Profiled_Components/2024-06-09-A_Survey_on_LLM_Based_Agentic_Workflows_and_LLM_Profiled_Components.html#appendix",
    "href": "posts/A_Survey_on_LLM_Based_Agentic_Workflows_and_LLM_Profiled_Components/2024-06-09-A_Survey_on_LLM_Based_Agentic_Workflows_and_LLM_Profiled_Components.html#appendix",
    "title": "A Survey on LLM-Based Agentic Workflows and LLM-Profiled Components",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05804v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05804v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5941"
  },
  {
    "objectID": "posts/Keyword_driven_Retrieval_Augmented_Large_Language_Models_for_Cold_start_User_Recommendations/2024-05-30-Keyword_driven_Retrieval_Augmented_Large_Language_Models_for_Cold_start_User_Recommendations.html#appendix",
    "href": "posts/Keyword_driven_Retrieval_Augmented_Large_Language_Models_for_Cold_start_User_Recommendations/2024-05-30-Keyword_driven_Retrieval_Augmented_Large_Language_Models_for_Cold_start_User_Recommendations.html#appendix",
    "title": "Keyword-driven Retrieval-Augmented Large Language Models for Cold-start User Recommendations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-14\n\n\nAbstract\nhttps://arxiv.org/abs/2405.19612v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.19612v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8262"
  },
  {
    "objectID": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#major-findings",
    "href": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#major-findings",
    "title": "McEval: Massively Multilingual Code Evaluation",
    "section": "Major Findings",
    "text": "Major Findings\n\nMcEval is the first massively multilingual code evaluation benchmark, covering 40 programming languages with 16K test samples.\nThe benchmark includes challenging code completion, understanding, and generation evaluation tasks with finely curated multilingual instruction corpora McEval-Instruct.\nThe authors introduce an effective multilingual coder mCoder trained on McEval-Instruct to support multilingual programming language generation."
  },
  {
    "objectID": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#analysis-and-critique",
    "href": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#analysis-and-critique",
    "title": "McEval: Massively Multilingual Code Evaluation",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\n\nThe paper does not provide a detailed comparison of McEval with existing benchmarks, making it difficult to assess its advantages and limitations.\nThe paper does not discuss the potential biases in the data used for training mCoder, which could impact its performance on certain tasks or languages.\nThe paper does not provide a detailed analysis of the performance of mCoder on different tasks and languages, making it difficult to assess its strengths and weaknesses.\nThe paper does not discuss the potential applications of McEval and mCoder in real-world software development scenarios.\nThe paper does not discuss the potential ethical implications of using mCoder for code generation, such as the risk of generating code that violates software licenses or copyright laws."
  },
  {
    "objectID": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#appendix",
    "href": "posts/McEval_Massively_Multilingual_Code_Evaluation/2024-06-11-McEval_Massively_Multilingual_Code_Evaluation.html#appendix",
    "title": "McEval: Massively Multilingual Code Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07436v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07436v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7788"
  },
  {
    "objectID": "posts/Silent_Signals_Loud_Impact_LLMs_for_Word_Sense_Disambiguation_of_Coded_Dog_Whistles/2024-06-10-Silent_Signals_Loud_Impact_LLMs_for_Word_Sense_Disambiguation_of_Coded_Dog_Whistles.html#appendix",
    "href": "posts/Silent_Signals_Loud_Impact_LLMs_for_Word_Sense_Disambiguation_of_Coded_Dog_Whistles/2024-06-10-Silent_Signals_Loud_Impact_LLMs_for_Word_Sense_Disambiguation_of_Coded_Dog_Whistles.html#appendix",
    "title": "Silent Signals, Loud Impact: LLMs for Word-Sense Disambiguation of Coded Dog Whistles",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06840v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06840v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8725"
  },
  {
    "objectID": "posts/Should_We_Fine_Tune_or_RAG_Evaluating_Different_Techniques_to_Adapt_LLMs_for_Dialogue/2024-06-10-Should_We_Fine_Tune_or_RAG_Evaluating_Different_Techniques_to_Adapt_LLMs_for_Dialogue.html#appendix",
    "href": "posts/Should_We_Fine_Tune_or_RAG_Evaluating_Different_Techniques_to_Adapt_LLMs_for_Dialogue/2024-06-10-Should_We_Fine_Tune_or_RAG_Evaluating_Different_Techniques_to_Adapt_LLMs_for_Dialogue.html#appendix",
    "title": "Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06399v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06399v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3367"
  },
  {
    "objectID": "posts/Towards_Human_AI_Collaboration_in_Healthcare_Guided_Deferral_Systems_with_Large_Language_Models/2024-06-11-Towards_Human_AI_Collaboration_in_Healthcare_Guided_Deferral_Systems_with_Large_Language_Models.html#appendix",
    "href": "posts/Towards_Human_AI_Collaboration_in_Healthcare_Guided_Deferral_Systems_with_Large_Language_Models/2024-06-11-Towards_Human_AI_Collaboration_in_Healthcare_Guided_Deferral_Systems_with_Large_Language_Models.html#appendix",
    "title": "Towards Human-AI Collaboration in Healthcare: Guided Deferral Systems with Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07212v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07212v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4804"
  },
  {
    "objectID": "posts/NoteLLM_2_Multimodal_Large_Representation_Models_for_Recommendation/2024-05-27-NoteLLM_2_Multimodal_Large_Representation_Models_for_Recommendation.html#appendix",
    "href": "posts/NoteLLM_2_Multimodal_Large_Representation_Models_for_Recommendation/2024-05-27-NoteLLM_2_Multimodal_Large_Representation_Models_for_Recommendation.html#appendix",
    "title": "NoteLLM-2: Multimodal Large Representation Models for Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-14\n\n\nAbstract\nhttps://arxiv.org/abs/2405.16789v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.16789v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7838"
  },
  {
    "objectID": "posts/RAGSys_Item_Cold_Start_Recommender_as_RAG_System/2024-05-27-RAGSys_Item_Cold_Start_Recommender_as_RAG_System.html#appendix",
    "href": "posts/RAGSys_Item_Cold_Start_Recommender_as_RAG_System/2024-05-27-RAGSys_Item_Cold_Start_Recommender_as_RAG_System.html#appendix",
    "title": "RAGSys: Item-Cold-Start Recommender as RAG System",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-14\n\n\nAbstract\nhttps://arxiv.org/abs/2405.17587v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.17587v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9098"
  },
  {
    "objectID": "posts/Large_Language_Models_as_Recommender_Systems_A_Study_of_Popularity_Bias/2024-06-03-Large_Language_Models_as_Recommender_Systems_A_Study_of_Popularity_Bias.html#appendix",
    "href": "posts/Large_Language_Models_as_Recommender_Systems_A_Study_of_Popularity_Bias/2024-06-03-Large_Language_Models_as_Recommender_Systems_A_Study_of_Popularity_Bias.html#appendix",
    "title": "Large Language Models as Recommender Systems: A Study of Popularity Bias",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-14\n\n\nAbstract\nhttps://arxiv.org/abs/2406.01285v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.01285v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9391"
  },
  {
    "objectID": "posts/Towards_Detecting_LLMs_Hallucination_via_Markov_Chain_based_Multi_agent_Debate_Framework/2024-06-05-Towards_Detecting_LLMs_Hallucination_via_Markov_Chain_based_Multi_agent_Debate_Framework.html#appendix",
    "href": "posts/Towards_Detecting_LLMs_Hallucination_via_Markov_Chain_based_Multi_agent_Debate_Framework/2024-06-05-Towards_Detecting_LLMs_Hallucination_via_Markov_Chain_based_Multi_agent_Debate_Framework.html#appendix",
    "title": "Towards Detecting LLMs Hallucination via Markov Chain-based Multi-agent Debate Framework",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03075v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03075v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5918"
  },
  {
    "objectID": "posts/Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110/2024-06-10-Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110.html",
    "href": "posts/Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110/2024-06-10-Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110.html",
    "title": "Harnessing AI for efficient analysis of complex policy documents: a case study of Executive Order 14110",
    "section": "",
    "text": "Summary:\nThis study investigates the accuracy and reliability of large language model (LLM)-based AI systems in extracting information from complex policy documents, such as Executive Order 14110. The research focuses on question answering and tasks involving content extraction, comparing the performance of four commercial AI systems (Claude 3 Opus, ChatGPT-4, Gemini Pro 1.5, and Command R+) to manual analysis conducted by human experts. The results show that Gemini and Claude demonstrated the most comprehensive understanding of the EO, consistently providing concise, accurate, and detailed responses. However, achieving acceptable levels of reproducibility and trustworthiness remains a critical challenge that necessitates further research and development.\nMajor Findings:\nAnalysis and Critique:\nThe study provides valuable insights into the potential of AI in policy analysis, but there are several limitations to consider:\nFurther research could involve testing other AI models, including open-source alternatives, mixture-of-"
  },
  {
    "objectID": "posts/Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110/2024-06-10-Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110.html#appendix",
    "href": "posts/Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110/2024-06-10-Harnessing_AI_for_efficient_analysis_of_complex_policy_documents_a_case_study_of_Executive_Order_14110.html#appendix",
    "title": "Harnessing AI for efficient analysis of complex policy documents: a case study of Executive Order 14110",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06657v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06657v1\n\n\nTruncated\nFalse\n\n\nWord Count\n25409"
  },
  {
    "objectID": "posts/LLMEmbed_Rethinking_Lightweight_LLMs_Genuine_Function_in_Text_Classification/2024-06-06-LLMEmbed_Rethinking_Lightweight_LLMs_Genuine_Function_in_Text_Classification.html#appendix",
    "href": "posts/LLMEmbed_Rethinking_Lightweight_LLMs_Genuine_Function_in_Text_Classification/2024-06-06-LLMEmbed_Rethinking_Lightweight_LLMs_Genuine_Function_in_Text_Classification.html#appendix",
    "title": "LLMEmbed: Rethinking Lightweight LLM’s Genuine Function in Text Classification",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03725v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03725v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5774"
  },
  {
    "objectID": "posts/CoEvol_Constructing_Better_Responses_for_Instruction_Finetuning_through_Multi_Agent_Cooperation/2024-06-11-CoEvol_Constructing_Better_Responses_for_Instruction_Finetuning_through_Multi_Agent_Cooperation.html#appendix",
    "href": "posts/CoEvol_Constructing_Better_Responses_for_Instruction_Finetuning_through_Multi_Agent_Cooperation/2024-06-11-CoEvol_Constructing_Better_Responses_for_Instruction_Finetuning_through_Multi_Agent_Cooperation.html#appendix",
    "title": "CoEvol: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07054v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07054v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6780"
  },
  {
    "objectID": "posts/Joint_Demonstration_and_Preference_Learning_Improves_Policy_Alignment_with_Human_Feedback/2024-06-11-Joint_Demonstration_and_Preference_Learning_Improves_Policy_Alignment_with_Human_Feedback.html#appendix",
    "href": "posts/Joint_Demonstration_and_Preference_Learning_Improves_Policy_Alignment_with_Human_Feedback/2024-06-11-Joint_Demonstration_and_Preference_Learning_Improves_Policy_Alignment_with_Human_Feedback.html#appendix",
    "title": "Joint Demonstration and Preference Learning Improves Policy Alignment with Human Feedback",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06874v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06874v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10718"
  },
  {
    "objectID": "posts/Chain_of_Scrutiny_Detecting_Backdoor_Attacks_for_Large_Language_Models/2024-06-10-Chain_of_Scrutiny_Detecting_Backdoor_Attacks_for_Large_Language_Models.html#appendix",
    "href": "posts/Chain_of_Scrutiny_Detecting_Backdoor_Attacks_for_Large_Language_Models/2024-06-10-Chain_of_Scrutiny_Detecting_Backdoor_Attacks_for_Large_Language_Models.html#appendix",
    "title": "Chain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05948v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05948v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6961"
  },
  {
    "objectID": "posts/GraphCoder_Enhancing_Repository_Level_Code_Completion_via_Code_Context_Graph_based_Retrieval_and_Language_Model/2024-06-11-GraphCoder_Enhancing_Repository_Level_Code_Completion_via_Code_Context_Graph_based_Retrieval_and_Language_Model.html#appendix",
    "href": "posts/GraphCoder_Enhancing_Repository_Level_Code_Completion_via_Code_Context_Graph_based_Retrieval_and_Language_Model/2024-06-11-GraphCoder_Enhancing_Repository_Level_Code_Completion_via_Code_Context_Graph_based_Retrieval_and_Language_Model.html#appendix",
    "title": "GraphCoder: Enhancing Repository-Level Code Completion via Code Context Graph-based Retrieval and Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07003v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07003v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9656"
  },
  {
    "objectID": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#major-findings",
    "href": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#major-findings",
    "title": "Characterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People",
    "section": "Major Findings",
    "text": "Major Findings\n\nThe proposed method enables the characterization of conversational tones and their taxonomies in any target human population as well as LLMs, without relying on predefined taxonomies or constrained sets of stimuli.\nThe study addresses the challenges of biased apriori taxonomy and biased stimulus set in existing research on conversational tones.\nThe paper presents an additional experiment where humans and GPT-4 annotated all sentences with all tones, resulting in an interpretable geometric representation of relations between conversational tones in humans and GPT-4."
  },
  {
    "objectID": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#analysis-and-critique",
    "href": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#analysis-and-critique",
    "title": "Characterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People",
    "section": "Analysis and Critique",
    "text": "Analysis and Critique\nThe paper presents a novel and promising approach to characterize conversational tones and their taxonomies in humans and LLMs. The proposed method addresses the limitations"
  },
  {
    "objectID": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#appendix",
    "href": "posts/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People/2024-06-06-Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.html#appendix",
    "title": "Characterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04278v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04278v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14313"
  },
  {
    "objectID": "posts/Raccoon_Prompt_Extraction_Benchmark_of_LLM_Integrated_Applications/2024-06-10-Raccoon_Prompt_Extraction_Benchmark_of_LLM_Integrated_Applications.html#appendix",
    "href": "posts/Raccoon_Prompt_Extraction_Benchmark_of_LLM_Integrated_Applications/2024-06-10-Raccoon_Prompt_Extraction_Benchmark_of_LLM_Integrated_Applications.html#appendix",
    "title": "Raccoon: Prompt Extraction Benchmark of LLM-Integrated Applications",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06737v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06737v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6069"
  },
  {
    "objectID": "posts/Large_Language_Models_for_Constrained_Based_Causal_Discovery/2024-06-11-Large_Language_Models_for_Constrained_Based_Causal_Discovery.html#appendix",
    "href": "posts/Large_Language_Models_for_Constrained_Based_Causal_Discovery/2024-06-11-Large_Language_Models_for_Constrained_Based_Causal_Discovery.html#appendix",
    "title": "Large Language Models for Constrained-Based Causal Discovery",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07378v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07378v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7632"
  },
  {
    "objectID": "posts/Refactoring_to_Pythonic_Idioms_A_Hybrid_Knowledge_Driven_Approach_Leveraging_Large_Language_Models/2024-06-06-Refactoring_to_Pythonic_Idioms_A_Hybrid_Knowledge_Driven_Approach_Leveraging_Large_Language_Models.html#appendix",
    "href": "posts/Refactoring_to_Pythonic_Idioms_A_Hybrid_Knowledge_Driven_Approach_Leveraging_Large_Language_Models/2024-06-06-Refactoring_to_Pythonic_Idioms_A_Hybrid_Knowledge_Driven_Approach_Leveraging_Large_Language_Models.html#appendix",
    "title": "Refactoring to Pythonic Idioms: A Hybrid Knowledge-Driven Approach Leveraging Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03660v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03660v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14284"
  },
  {
    "objectID": "posts/SLMRec_Empowering_Small_Language_Models_for_Sequential_Recommendation/2024-05-28-SLMRec_Empowering_Small_Language_Models_for_Sequential_Recommendation.html#appendix",
    "href": "posts/SLMRec_Empowering_Small_Language_Models_for_Sequential_Recommendation/2024-05-28-SLMRec_Empowering_Small_Language_Models_for_Sequential_Recommendation.html#appendix",
    "title": "SLMRec: Empowering Small Language Models for Sequential Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-14\n\n\nAbstract\nhttps://arxiv.org/abs/2405.17890v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2405.17890v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6690"
  },
  {
    "objectID": "posts/LGR2_Language_Guided_Reward_Relabeling_for_Accelerating_Hierarchical_Reinforcement_Learning/2024-06-09-LGR2_Language_Guided_Reward_Relabeling_for_Accelerating_Hierarchical_Reinforcement_Learning.html#appendix",
    "href": "posts/LGR2_Language_Guided_Reward_Relabeling_for_Accelerating_Hierarchical_Reinforcement_Learning/2024-06-09-LGR2_Language_Guided_Reward_Relabeling_for_Accelerating_Hierarchical_Reinforcement_Learning.html#appendix",
    "title": "LGR2: Language Guided Reward Relabeling for Accelerating Hierarchical Reinforcement Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05881v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05881v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10516"
  },
  {
    "objectID": "posts/BertaQA_How_Much_Do_Language_Models_Know_About_Local_Culture/2024-06-11-BertaQA_How_Much_Do_Language_Models_Know_About_Local_Culture.html#appendix",
    "href": "posts/BertaQA_How_Much_Do_Language_Models_Know_About_Local_Culture/2024-06-11-BertaQA_How_Much_Do_Language_Models_Know_About_Local_Culture.html#appendix",
    "title": "BertaQA: How Much Do Language Models Know About Local Culture?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07302v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07302v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5979"
  },
  {
    "objectID": "posts/BIPED_Pedagogically_Informed_Tutoring_System_for_ESL_Education/2024-06-05-BIPED_Pedagogically_Informed_Tutoring_System_for_ESL_Education.html#appendix",
    "href": "posts/BIPED_Pedagogically_Informed_Tutoring_System_for_ESL_Education/2024-06-05-BIPED_Pedagogically_Informed_Tutoring_System_for_ESL_Education.html#appendix",
    "title": "BIPED: Pedagogically Informed Tutoring System for ESL Education",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03486v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03486v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7759"
  },
  {
    "objectID": "posts/Decision_Making_Behavior_Evaluation_Framework_for_LLMs_under_Uncertain_Context/2024-06-10-Decision_Making_Behavior_Evaluation_Framework_for_LLMs_under_Uncertain_Context.html#appendix",
    "href": "posts/Decision_Making_Behavior_Evaluation_Framework_for_LLMs_under_Uncertain_Context/2024-06-10-Decision_Making_Behavior_Evaluation_Framework_for_LLMs_under_Uncertain_Context.html#appendix",
    "title": "Decision-Making Behavior Evaluation Framework for LLMs under Uncertain Context",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05972v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05972v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6256"
  },
  {
    "objectID": "posts/Evaluating_the_Retrieval_Component_in_LLM_Based_Question_Answering_Systems/2024-06-10-Evaluating_the_Retrieval_Component_in_LLM_Based_Question_Answering_Systems.html#appendix",
    "href": "posts/Evaluating_the_Retrieval_Component_in_LLM_Based_Question_Answering_Systems/2024-06-10-Evaluating_the_Retrieval_Component_in_LLM_Based_Question_Answering_Systems.html#appendix",
    "title": "Evaluating the Retrieval Component in LLM-Based Question Answering Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06458v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06458v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4825"
  },
  {
    "objectID": "posts/Leveraging_Large_Language_Models_for_Efficient_Failure_Analysis_in_Game_Development/2024-06-11-Leveraging_Large_Language_Models_for_Efficient_Failure_Analysis_in_Game_Development.html#appendix",
    "href": "posts/Leveraging_Large_Language_Models_for_Efficient_Failure_Analysis_in_Game_Development/2024-06-11-Leveraging_Large_Language_Models_for_Efficient_Failure_Analysis_in_Game_Development.html#appendix",
    "title": "Leveraging Large Language Models for Efficient Failure Analysis in Game Development",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07084v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07084v1\n\n\nTruncated\nFalse\n\n\nWord Count\n6064"
  },
  {
    "objectID": "posts/Large_Language_Models_Make_Sample_Efficient_Recommender_Systems/2024-06-04-Large_Language_Models_Make_Sample_Efficient_Recommender_Systems.html#appendix",
    "href": "posts/Large_Language_Models_Make_Sample_Efficient_Recommender_Systems/2024-06-04-Large_Language_Models_Make_Sample_Efficient_Recommender_Systems.html#appendix",
    "title": "Large Language Models Make Sample-Efficient Recommender Systems",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-14\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02368v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02368v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3649"
  },
  {
    "objectID": "posts/Do_LLMs_Exhibit_Human_Like_Reasoning_Evaluating_Theory_of_Mind_in_LLMs_for_Open_Ended_Responses/2024-06-09-Do_LLMs_Exhibit_Human_Like_Reasoning_Evaluating_Theory_of_Mind_in_LLMs_for_Open_Ended_Responses.html#appendix",
    "href": "posts/Do_LLMs_Exhibit_Human_Like_Reasoning_Evaluating_Theory_of_Mind_in_LLMs_for_Open_Ended_Responses/2024-06-09-Do_LLMs_Exhibit_Human_Like_Reasoning_Evaluating_Theory_of_Mind_in_LLMs_for_Open_Ended_Responses.html#appendix",
    "title": "Do LLMs Exhibit Human-Like Reasoning? Evaluating Theory of Mind in LLMs for Open-Ended Responses",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05659v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05659v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10269"
  },
  {
    "objectID": "posts/PaCE_Parsimonious_Concept_Engineering_for_Large_Language_Models/2024-06-06-PaCE_Parsimonious_Concept_Engineering_for_Large_Language_Models.html#appendix",
    "href": "posts/PaCE_Parsimonious_Concept_Engineering_for_Large_Language_Models/2024-06-06-PaCE_Parsimonious_Concept_Engineering_for_Large_Language_Models.html#appendix",
    "title": "PaCE: Parsimonious Concept Engineering for Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04331v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04331v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9538"
  },
  {
    "objectID": "posts/Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course/2024-06-10-Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course.html",
    "href": "posts/Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course/2024-06-10-Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course.html",
    "title": "Insights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course",
    "section": "",
    "text": "Summary:\nThis study explores the social dynamics surrounding the use of large language models (LLMs) in an undergraduate programming course. The research is guided by the social shaping of technology theory and focuses on two research questions: (1) How do social perceptions influence the usage of LLMs in an undergraduate intermediate-level programming course? (2) How does LLM usage relate to programming self-efficacy and midterm scores among undergraduate students in an intermediate-level programming course?\nThe study employs a mixed-methods approach, including an anonymous student survey, student interviews, and a regression analysis of midterm performance data with students’ self-reported use of LLMs on homework. The findings suggest that students’ engagement with LLMs is significantly associated with their perceptions of their future careers and their peers’ usage. Additionally, the use of LLMs has mixed impacts on students’ self-efficacy and perceived learning outcomes, with a notable negative correlation between LLM usage and self-efficacy regardless of major and a negative correlation between LLM usage and performance on the first midterm.\nMajor Findings:\nAnalysis and Critique:\nThe study provides valuable insights into the social dynamics surrounding the use of LLMs in undergraduate programming education. However, the research has some limitations, including the context of the study, potential selection bias, reliance on self-reported data, and the correlational nature of the regression analyses. Additionally, the study’s focus on peer-reviewed literature may have led to the omission of relevant contributions from non-peer-reviewed sources. Despite these limitations, the research offers a nuanced understanding of the complex dynamic between technology and social factors, challenging the notion of technological determinism. As LLMs and other AI technologies continue to evolve, it is crucial to consider the social dynamics that shape their appropriation."
  },
  {
    "objectID": "posts/Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course/2024-06-10-Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course.html#appendix",
    "href": "posts/Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course/2024-06-10-Insights_from_Social_Shaping_Theory_The_Appropriation_of_Large_Language_Models_in_an_Undergraduate_Programming_Course.html#appendix",
    "title": "Insights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06451v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06451v1\n\n\nTruncated\nFalse\n\n\nWord Count\n14658"
  },
  {
    "objectID": "posts/MoPS_Modular_Story_Premise_Synthesis_for_Open_Ended_Automatic_Story_Generation/2024-06-09-MoPS_Modular_Story_Premise_Synthesis_for_Open_Ended_Automatic_Story_Generation.html#appendix",
    "href": "posts/MoPS_Modular_Story_Premise_Synthesis_for_Open_Ended_Automatic_Story_Generation/2024-06-09-MoPS_Modular_Story_Premise_Synthesis_for_Open_Ended_Automatic_Story_Generation.html#appendix",
    "title": "MoPS: Modular Story Premise Synthesis for Open-Ended Automatic Story Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05690v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05690v1\n\n\nTruncated\nFalse\n\n\nWord Count\n9468"
  },
  {
    "objectID": "posts/Exploring_Mathematical_Extrapolation_of_Large_Language_Models_with_Synthetic_Data/2024-06-04-Exploring_Mathematical_Extrapolation_of_Large_Language_Models_with_Synthetic_Data.html#appendix",
    "href": "posts/Exploring_Mathematical_Extrapolation_of_Large_Language_Models_with_Synthetic_Data/2024-06-04-Exploring_Mathematical_Extrapolation_of_Large_Language_Models_with_Synthetic_Data.html#appendix",
    "title": "Exploring Mathematical Extrapolation of Large Language Models with Synthetic Data",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-14\n\n\nAbstract\nhttps://arxiv.org/abs/2406.02100v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.02100v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3993"
  },
  {
    "objectID": "posts/Coherent_Zero_Shot_Visual_Instruction_Generation/2024-06-06-Coherent_Zero_Shot_Visual_Instruction_Generation.html#appendix",
    "href": "posts/Coherent_Zero_Shot_Visual_Instruction_Generation/2024-06-06-Coherent_Zero_Shot_Visual_Instruction_Generation.html#appendix",
    "title": "Coherent Zero-Shot Visual Instruction Generation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04337v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04337v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5054"
  },
  {
    "objectID": "posts/Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination/2024-06-10-Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination.html",
    "href": "posts/Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination/2024-06-10-Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination.html",
    "title": "Enhancing Food Safety in Supply Chains: The Potential Role of Large Language Models in Preventing Campylobacter Contamination",
    "section": "",
    "text": "Summary:\nThis study explores the potential of large language models (LLMs), specifically generative pre-trained transformers (GPTs), to mitigate Campylobacter contamination across four typical stages of the food supply chain: primary production, food processing, distribution and retail, and preparation and consumption. The study also considers critical barriers to implementing GPTs at each step of the supply chain and proposes initial measures to overcome these obstacles.\nMajor Findings:\nAnalysis and Critique:\nThe study presents an intriguing potential for LLMs to enhance food safety, but the ‘LLM – food safety’ interface remains largely underexplored. The proposed applications of LLMs in this domain are promising, but they require further investigation and practical applications. The study also acknowledges that the adoption of LLMs in the food industry and agri-food supply chains may face several inhibiting factors, such as technological adoption, cultural barriers, data quality and availability, and technical challenges in integrating LLMs with existing food processing and slaughterhouse systems.\nTo alleviate these barriers and enable the deployment of LLMs for bacterial contamination reduction across food supply chains, a"
  },
  {
    "objectID": "posts/Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination/2024-06-10-Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination.html#appendix",
    "href": "posts/Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination/2024-06-10-Enhancing_Food_Safety_in_Supply_Chains_The_Potential_Role_of_Large_Language_Models_in_Preventing_Campylobacter_Contamination.html#appendix",
    "title": "Enhancing Food Safety in Supply Chains: The Potential Role of Large Language Models in Preventing Campylobacter Contamination",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06049v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06049v1\n\n\nTruncated\nFalse\n\n\nWord Count\n18111"
  },
  {
    "objectID": "posts/Confabulation_The_Surprising_Value_of_Large_Language_Model_Hallucinations/2024-06-06-Confabulation_The_Surprising_Value_of_Large_Language_Model_Hallucinations.html#appendix",
    "href": "posts/Confabulation_The_Surprising_Value_of_Large_Language_Model_Hallucinations/2024-06-06-Confabulation_The_Surprising_Value_of_Large_Language_Model_Hallucinations.html#appendix",
    "title": "Confabulation: The Surprising Value of Large Language Model Hallucinations",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04175v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04175v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5509"
  },
  {
    "objectID": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#summary-1",
    "href": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#summary-1",
    "title": "FragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models",
    "section": "Summary:",
    "text": "Summary:\n\nThe paper proposes a method to improve the processing of long contexts in Large Language Models (LLMs) by exploiting fragment-level relations in external memory.\nThe authors formulate fragment-level relations and present several instantiations for different text types.\nThey introduce a relation-aware fragment assessment criteria and present the fragment-connected Hierarchical Memory based LLM.\nThe proposed method is validated on long story understanding, repository-level code generation, and long-term chatting tasks."
  },
  {
    "objectID": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#major-findings",
    "href": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#major-findings",
    "title": "FragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nFragment-level Relations: The authors propose a method to exploit fragment-level relations in external memory to improve the processing of long contexts in LLMs.\nRelation-aware Fragment Assessment: The authors introduce a relation-aware fragment assessment criteria to better assess the importance of each fragment in the context.\nFragment-connected Hierarchical Memory based LLM: The authors present a new LLM architecture that incorporates fragment-level relations in external memory to improve the processing of long contexts."
  },
  {
    "objectID": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#analysis-and-critique",
    "href": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#analysis-and-critique",
    "title": "FragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe proposed method effectively addresses the issue of isolated fragment processing in existing External Memory augmented LLMs.\nThe paper provides a comprehensive evaluation of the proposed method on various long text processing tasks, demonstrating its effectiveness.\nHowever, the paper does not discuss the potential limitations or challenges of the proposed method, such as the computational overhead or the impact on the model’s performance.\nAdditionally, the paper does not provide a comparison with other existing methods for processing long contexts in LLMs.\nThe paper could benefit from a more detailed discussion of the potential applications and implications of the proposed method in real-world scenarios.\nOverall, the paper presents a promising approach to improve the processing of long contexts in LLMs, but further research is needed to fully evaluate its potential and limitations."
  },
  {
    "objectID": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#appendix",
    "href": "posts/FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models/2024-06-05-FragRel_Exploiting_Fragment_level_Relations_in_the_External_Memory_of_Large_Language_Models.html#appendix",
    "title": "FragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03092v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03092v1\n\n\nTruncated\nFalse\n\n\nWord Count\n7567"
  },
  {
    "objectID": "posts/Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents/2024-06-09-Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents.html",
    "href": "posts/Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents/2024-06-09-Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents.html",
    "title": "Machine Against the RAG: Jamming Retrieval-Augmented Generation with Blocker Documents",
    "section": "",
    "text": "Summary:\nThe paper introduces a new class of denial-of-service vulnerabilities in retrieval-augmented generation (RAG) systems, where a single “blocker” document in the RAG database can cause the system to refuse to answer certain queries. The authors demonstrate this attack against several popular large language models (LLMs) and show that resistance to jamming is a novel LLM-safety property not captured by existing safety and trustworthiness metrics.\nThe authors investigate several methods for generating blocker documents, including a new method based on black-box optimization that does not require knowledge of the embedding or LLM used by the target RAG system. They also discuss the limitations of this method, such as producing blocker documents that have no semantics and can be easily filtered out from RAG databases.\nThe paper concludes with a discussion of future research directions, such as minimizing the number of queries to the target RAG system, generating blocker documents with access to a RAG system whose database is not exactly the same as the target system, and generating passive blocker documents that are difficult to detect or even semantically plausible.\nMajor Findings:\nAnalysis and Critique:\nThe paper presents an interesting and novel attack on RAG systems, highlighting a previously unrecognized vulnerability. The authors’ investigation of different methods for generating blocker documents is thorough and well-presented. However, the paper could benefit from a more in-depth discussion of the potential real-world implications of this attack and possible countermeasures. Additionally, the limitations of the black-box optimization method for generating blocker documents should be further explored and addressed."
  },
  {
    "objectID": "posts/Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents/2024-06-09-Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents.html#appendix",
    "href": "posts/Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents/2024-06-09-Machine_Against_the_RAG_Jamming_Retrieval_Augmented_Generation_with_Blocker_Documents.html#appendix",
    "title": "Machine Against the RAG: Jamming Retrieval-Augmented Generation with Blocker Documents",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05870v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05870v1\n\n\nTruncated\nFalse\n\n\nWord Count\n12156"
  },
  {
    "objectID": "posts/Text_to_Drive_Diverse_Driving_Behavior_Synthesis_via_Large_Language_Models/2024-06-06-Text_to_Drive_Diverse_Driving_Behavior_Synthesis_via_Large_Language_Models.html#appendix",
    "href": "posts/Text_to_Drive_Diverse_Driving_Behavior_Synthesis_via_Large_Language_Models/2024-06-06-Text_to_Drive_Diverse_Driving_Behavior_Synthesis_via_Large_Language_Models.html#appendix",
    "title": "Text-to-Drive: Diverse Driving Behavior Synthesis via Large Language Models",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.04300v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.04300v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10490"
  },
  {
    "objectID": "posts/Zero_Shot_End_To_End_Spoken_Question_Answering_In_Medical_Domain/2024-06-09-Zero_Shot_End_To_End_Spoken_Question_Answering_In_Medical_Domain.html#appendix",
    "href": "posts/Zero_Shot_End_To_End_Spoken_Question_Answering_In_Medical_Domain/2024-06-09-Zero_Shot_End_To_End_Spoken_Question_Answering_In_Medical_Domain.html#appendix",
    "title": "Zero-Shot End-To-End Spoken Question Answering In Medical Domain",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05876v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05876v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4005"
  },
  {
    "objectID": "posts/HalluDial_A_Large_Scale_Benchmark_for_Automatic_Dialogue_Level_Hallucination_Evaluation/2024-06-11-HalluDial_A_Large_Scale_Benchmark_for_Automatic_Dialogue_Level_Hallucination_Evaluation.html#appendix",
    "href": "posts/HalluDial_A_Large_Scale_Benchmark_for_Automatic_Dialogue_Level_Hallucination_Evaluation/2024-06-11-HalluDial_A_Large_Scale_Benchmark_for_Automatic_Dialogue_Level_Hallucination_Evaluation.html#appendix",
    "title": "HalluDial: A Large-Scale Benchmark for Automatic Dialogue-Level Hallucination Evaluation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07070v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07070v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10462"
  },
  {
    "objectID": "posts/DARA_Decomposition_Alignment_Reasoning_Autonomous_Language_Agent_for_Question_Answering_over_Knowledge_Graphs/2024-06-11-DARA_Decomposition_Alignment_Reasoning_Autonomous_Language_Agent_for_Question_Answering_over_Knowledge_Graphs.html#appendix",
    "href": "posts/DARA_Decomposition_Alignment_Reasoning_Autonomous_Language_Agent_for_Question_Answering_over_Knowledge_Graphs/2024-06-11-DARA_Decomposition_Alignment_Reasoning_Autonomous_Language_Agent_for_Question_Answering_over_Knowledge_Graphs.html#appendix",
    "title": "DARA: Decomposition-Alignment-Reasoning Autonomous Language Agent for Question Answering over Knowledge Graphs",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07080v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07080v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8918"
  },
  {
    "objectID": "posts/Language_Models_Resist_Alignment/2024-06-10-Language_Models_Resist_Alignment.html#appendix",
    "href": "posts/Language_Models_Resist_Alignment/2024-06-10-Language_Models_Resist_Alignment.html#appendix",
    "title": "Language Models Resist Alignment",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.06144v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.06144v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5000"
  },
  {
    "objectID": "posts/Merging_Improves_Self_Critique_Against_Jailbreak_Attacks/2024-06-11-Merging_Improves_Self_Critique_Against_Jailbreak_Attacks.html#appendix",
    "href": "posts/Merging_Improves_Self_Critique_Against_Jailbreak_Attacks/2024-06-11-Merging_Improves_Self_Critique_Against_Jailbreak_Attacks.html#appendix",
    "title": "Merging Improves Self-Critique Against Jailbreak Attacks",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07188v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07188v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3164"
  },
  {
    "objectID": "posts/Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering/2024-06-06-Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering.html",
    "href": "posts/Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering/2024-06-06-Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering.html",
    "title": "Tool-Planner: Dynamic Solution Tree Planning for Large Language Model with Tool Clustering",
    "section": "",
    "text": "Summary: The paper introduces Tool-Planner, a task-processing framework that groups tools based on their API functions into toolkits. This approach allows large language models (LLMs) to implement planning across various toolkits and reselect or adjust tools when a tool error occurs. The authors propose Tool-Planner to address the challenges of redundant error correction and designing a correct plan among multiple tools in tool learning. The experiments conducted demonstrate that Tool-Planner has a high pass and win rate across different datasets and optimizes the planning scheme for tool learning in models such as GPT-4 and Claude 3.\nMajor Findings: 1. Tool-Planner achieves state-of-the-art performance on five out of six datasets and shows competitive performance on the remaining dataset. 2. The method improves the pass rate by +8.8% and the win rate by +9.1% compared to the"
  },
  {
    "objectID": "posts/Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering/2024-06-06-Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering.html#appendix",
    "href": "posts/Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering/2024-06-06-Tool_Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering.html#appendix",
    "title": "Tool-Planner: Dynamic Solution Tree Planning for Large Language Model with Tool Clustering",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03807v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03807v1\n\n\nTruncated\nTrue\n\n\nWord Count\n29774"
  },
  {
    "objectID": "posts/Exploring_User_Retrieval_Integration_towards_Large_Language_Models_for_Cross_Domain_Sequential_Recommendation/2024-06-05-Exploring_User_Retrieval_Integration_towards_Large_Language_Models_for_Cross_Domain_Sequential_Recommendation.html#appendix",
    "href": "posts/Exploring_User_Retrieval_Integration_towards_Large_Language_Models_for_Cross_Domain_Sequential_Recommendation/2024-06-05-Exploring_User_Retrieval_Integration_towards_Large_Language_Models_for_Cross_Domain_Sequential_Recommendation.html#appendix",
    "title": "Exploring User Retrieval Integration towards Large Language Models for Cross-Domain Sequential Recommendation",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03085v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03085v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8121"
  },
  {
    "objectID": "posts/Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer/2024-06-09-Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer.html",
    "href": "posts/Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer/2024-06-09-Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer.html",
    "title": "Are Large Language Models Actually Good at Text Style Transfer?",
    "section": "",
    "text": "Summary:\nThis paper evaluates the performance of large language models (LLMs) on Text Style Transfer (TST), specifically focusing on sentiment transfer and text detoxification across three languages: English, Hindi, and Bengali. The study analyzes the capabilities of pre-trained LLMs using zero-shot and few-shot prompting as well as parameter-efficient finetuning on publicly available datasets. The evaluation is conducted using automatic metrics, GPT-4, and human evaluations, revealing that while some prompted LLMs perform well in English, their performance in other languages remains average. However, finetuning significantly improves results compared to zero-shot and few-shot prompting, making them comparable to previous state-of-the-art.\nMajor Findings:\nAnalysis and Critique:"
  },
  {
    "objectID": "posts/Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer/2024-06-09-Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer.html#appendix",
    "href": "posts/Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer/2024-06-09-Are_Large_Language_Models_Actually_Good_at_Text_Style_Transfer.html#appendix",
    "title": "Are Large Language Models Actually Good at Text Style Transfer?",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05885v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05885v1\n\n\nTruncated\nFalse\n\n\nWord Count\n27021"
  },
  {
    "objectID": "posts/Guiding_LLM_Temporal_Logic_Generation_with_Explicit_Separation_of_Data_and_Control/2024-06-11-Guiding_LLM_Temporal_Logic_Generation_with_Explicit_Separation_of_Data_and_Control.html#appendix",
    "href": "posts/Guiding_LLM_Temporal_Logic_Generation_with_Explicit_Separation_of_Data_and_Control/2024-06-11-Guiding_LLM_Temporal_Logic_Generation_with_Explicit_Separation_of_Data_and_Control.html#appendix",
    "title": "Guiding LLM Temporal Logic Generation with Explicit Separation of Data and Control",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07400v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07400v1\n\n\nTruncated\nFalse\n\n\nWord Count\n4241"
  },
  {
    "objectID": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#major-findings",
    "href": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#major-findings",
    "title": "Digital Business Model Analysis Using a Large Language Model",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nThe study demonstrates the potential of using LLMs for analyzing and designing new business models, which is still an evolving field with scarce research.\nThe proposed method can support idea generation in digital business model design by learning patterns from the commonalities of DX cases and using this knowledge as a reference when considering DX initiatives.\nThe analysis examples show that LLM can effectively extract similar DX cases, not only within the same industry but also from different industries, and consider their commonalities to support the ideation of digital business models."
  },
  {
    "objectID": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#analysis-and-critique",
    "href": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#analysis-and-critique",
    "title": "Digital Business Model Analysis Using a Large Language Model",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\n\nThe study’s findings are preliminary, and further research is needed to refine the analytical methods using advanced NLP technologies and broaden the examination of digital business models across a wider spectrum of industries.\nThe proposed method potentially offers companies easy access to insights into the use of digital technologies and business model innovations that have previously been less accessible.\nThe authors plan to develop a recommendation system, possibly implemented via chatbots, that could suggest similar cases to act as a catalyst for companies aiming to accelerate their DX efforts.\nThe study makes certain academic contributions by demonstrating the potential of this approach, but more research is needed to fully understand its implications and limitations."
  },
  {
    "objectID": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#appendix",
    "href": "posts/Digital_Business_Model_Analysis_Using_a_Large_Language_Model/2024-06-09-Digital_Business_Model_Analysis_Using_a_Large_Language_Model.html#appendix",
    "title": "Digital Business Model Analysis Using a Large Language Model",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.05741v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.05741v1\n\n\nTruncated\nFalse\n\n\nWord Count\n3431"
  },
  {
    "objectID": "posts/FastGAS_Fast_Graph_based_Annotation_Selection_for_In_Context_Learning/2024-06-06-FastGAS_Fast_Graph_based_Annotation_Selection_for_In_Context_Learning.html#appendix",
    "href": "posts/FastGAS_Fast_Graph_based_Annotation_Selection_for_In_Context_Learning/2024-06-06-FastGAS_Fast_Graph_based_Annotation_Selection_for_In_Context_Learning.html#appendix",
    "title": "FastGAS: Fast Graph-based Annotation Selection for In-Context Learning",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.03730v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.03730v1\n\n\nTruncated\nFalse\n\n\nWord Count\n8522"
  },
  {
    "objectID": "posts/THaLLE_Text_Hyperlocally_Augmented_Large_Language_Extension____Technical_Report/2024-06-11-THaLLE_Text_Hyperlocally_Augmented_Large_Language_Extension____Technical_Report.html#appendix",
    "href": "posts/THaLLE_Text_Hyperlocally_Augmented_Large_Language_Extension____Technical_Report/2024-06-11-THaLLE_Text_Hyperlocally_Augmented_Large_Language_Extension____Technical_Report.html#appendix",
    "title": "THaLLE: Text Hyperlocally Augmented Large Language Extension – Technical Report",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07505v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07505v1\n\n\nTruncated\nFalse\n\n\nWord Count\n5344"
  },
  {
    "objectID": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#major-findings",
    "href": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#major-findings",
    "title": "World Models with Hints of Large Language Models for Goal Achieving",
    "section": "Major Findings:",
    "text": "Major Findings:\n\nDLLM integrates hinting subgoals from LLMs into the model rollouts to encourage goal discovery and reaching in challenging tasks.\nDLLM assigns higher intrinsic rewards to samples that align with the hints outlined by the language model during model rollouts.\nDLLM outperforms recent methods in various challenging, sparse-reward environments such as HomeGrid, Crafter, and Minecraft."
  },
  {
    "objectID": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#analysis-and-critique",
    "href": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#analysis-and-critique",
    "title": "World Models with Hints of Large Language Models for Goal Achieving",
    "section": "Analysis and Critique:",
    "text": "Analysis and Critique:\nThe paper presents an innovative approach to addressing the challenges of long-horizon tasks and sparse rewards in RL. The use of LLMs to provide hinting subgoals is a promising direction for improving exploration and goal-reaching in complex environments. However, the paper does not discuss potential limitations or biases in the LLMs used, which could impact the performance of DLLM. Additionally, the paper does not provide a detailed comparison with other methods that use intrinsic rewards or LLMs for goal-setting. Further research is needed to evaluate the robustness and generalizability of DLLM in different environments and tasks."
  },
  {
    "objectID": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#appendix",
    "href": "posts/World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving/2024-06-11-World_Models_with_Hints_of_Large_Language_Models_for_Goal_Achieving.html#appendix",
    "title": "World Models with Hints of Large Language Models for Goal Achieving",
    "section": "Appendix",
    "text": "Appendix\n\n\n\nModel\naccounts/fireworks/models/mixtral-8x22b-instruct\n\n\nDate Generated\n2024-06-12\n\n\nAbstract\nhttps://arxiv.org/abs/2406.07381v1\n\n\nHTML\nhttps://browse.arxiv.org/html/2406.07381v1\n\n\nTruncated\nFalse\n\n\nWord Count\n10623"
  }
]