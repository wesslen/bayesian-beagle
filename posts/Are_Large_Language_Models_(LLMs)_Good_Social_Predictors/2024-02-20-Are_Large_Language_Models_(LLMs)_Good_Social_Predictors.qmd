
---
title: "Are Large Language Models (LLMs) Good Social Predictors?"
id: "2402.12620v1"
description: "LLMs struggle with social prediction without input shortcuts, requiring further enhancement."
author: Kaiqi Yang, Hang Li, Hongzhi Wen, Tai-Quan Peng, Jiliang Tang, Hui Liu
date: "2024-02-20"
image: "../../https://browse.arxiv.org/html/2402.12620v1/extracted/5418884/img/votingresult1.png"
categories: ['social-sciences', 'hci']
format:
  html:
    code-overflow: wrap
---

![](../../https://browse.arxiv.org/html/2402.12620v1/extracted/5418884/img/votingresult1.png)

### Summary:
- The article examines the predictive power of Large Language Models (LLMs) in social studies, particularly in predicting human features such as presidential voting.
- Previous studies have reported promising performance of LLMs in predicting human responses, but the article finds that this performance is due to the existence of input shortcut features to the response.
- The article introduces a novel social prediction task, Soc-PRF Prediction, which utilizes general features as input and simulates real-world social study settings.
- Through comprehensive investigations on various LLMs, the article reveals that LLMs cannot work as expected on social prediction when given general input features without shortcuts.

### Major Findings:
1. The promising performance of LLMs in social prediction is due to the existence of input shortcut features to the response.
2. LLMs cannot work on social prediction with general input features without shortcuts.
3. The article introduces a novel social prediction task, Soc-PRF Prediction, to evaluate the predictive power of LLMs.

### Analysis and Critique:
- The article raises questions about the true capability of LLMs in social predictions, challenging the prevailing perception of their prowess.
- The study suggests that incorporating labeled data and enriching input features could benefit social prediction, but further experiments are needed to validate these suggestions.
- The article does not investigate how to select informative features that enhance prediction and what is the upper bound of this task, which could be a potential direction for future research.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.12620v1](https://arxiv.org/abs/2402.12620v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.12620v1](https://browse.arxiv.org/html/2402.12620v1)       |
| Truncated       | False       |
| Word Count       | 6491       |