
---
title: "The Persuasive Power of Large Language Models"
description: "Large Language Models can generate effective arguments and interact with each other in opinion dynamics, suggesting potential impact on online discourse."
author: "gpt-3.5-turbo-1106"
date: "2023-12-24"
link: "https://browse.arxiv.org/html/2312.15523v1"
image: "https://browse.arxiv.org/html/2312.15523v1/extracted/5315218/img/chat-example.png"
categories: ['hci']
file-modified: 2024-01-02
format:
  html:
    code-overflow: wrap
---

**Takeaways**
- Large Language Models (LLMs) are increasingly capable of emulating social agents and engaging in complex interactions, raising concerns about potential implications for online discourse.
- In a study on climate change persuasion, LLMs demonstrated the ability to generate effective arguments, incorporating dimensions of social pragmatics that influence opinion change.
- While arguments that conveyed knowledge, trust, status, and support were perceived as most effective by both LLM agents and human judges, humans showed a disproportionate preference for knowledge-based arguments.

# Introduction
Large Language Models (LLMs) have the capacity to function as social agents and interact with both humans and other artificial agents. This development has raised concerns about the potential impact of LLMs on online discourse and the spread of misinformation.

# Methods
- The study used a synthetic persuasion dialogue scenario on climate change, where a 'convincer' LLM agent generated arguments for a 'skeptic' LLM agent.
- The persuasiveness of machine-generated arguments was evaluated by human judges.

# Results
- LLMs were found to mimic human-like dynamics of persuasion and opinion change, and arguments containing knowledge, trust, status, and support were rated most effective by both LLM agents and human judges.
- However, humans showed a stronger preference for knowledge-based arguments compared to LLM agents.

# Discussion
The study presents limitations due to the simplified experimental design and the need for future research to explore multi-turn conversations, diverse agent profiles, and the impact of argument length on persuasiveness.

# Critique
The study's comparison of LLM convincing probabilities with human rankings of social dimensions faces challenges in recreating identical conditions for humans and LLMs, and future research is urged to elucidate the opinion-change process within LLM agents. Additionally, concerns are raised about the ethical implications and potential risks associated with the use of LLMs in influencing online discourse.

## Appendix

|          |          |
|----------|----------|
| Link     | [https://browse.arxiv.org/html/2312.15523v1](https://browse.arxiv.org/html/2312.15523v1)       |
| Truncated       | False       |
| Word Count       | 5448       |