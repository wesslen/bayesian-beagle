
---
title: "Model-Enhanced LLM-Driven VUI Testing of VPA Apps"
id: "2407.02791v1"
description: "Elevate, a VUI testing framework, uses LLMs for better natural language processing, improving state space coverage and efficiency compared to Vitas."
author: Suwan Li, Lei Bu, Guangdong Bai, Fuman Xie, Kai Chen, Chang Yue
date: "2024-07-03"
image: "https://browse.arxiv.org/html/2407.02791v1/extracted/5706958/figure/choose_input_example.png"
categories: ['prompt-engineering', 'security']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2407.02791v1/extracted/5706958/figure/choose_input_example.png)

### Summary:

The paper introduces Elevate, a model-enhanced large language model (LLM)-driven VUI testing framework for VPA apps. Elevate leverages LLMs' strong natural language processing capabilities to compensate for semantic information loss during model-based VUI testing. It operates by prompting LLMs to extract states from VPA apps' outputs and generate context-related inputs. During the automatic interactions with the app, it incrementally constructs the behavior model, which facilitates the LLM in generating inputs that are highly likely to discover new states. Elevate bridges the LLM and the behavior model with innovative techniques such as encoding behavior model into prompts and selecting LLM-generated inputs based on the context relevance. Elevate is benchmarked on 4,000 real-world Alexa skills, against the state-of-the-art tester Vitas, and achieves 15% higher state space coverage compared to Vitas on all types of apps, and exhibits significant advancement in efficiency.

### Major Findings:

1. Elevate, a model-enhanced LLM-driven VUI testing framework, is introduced to tackle the inherent lack of a visible user interface in VPA apps.
2. Elevate leverages LLMs' strong natural language processing capabilities to compensate for semantic information loss during model-based VUI testing.
3. Elevate operates by prompting LLMs to extract states from VPA apps' outputs and generate context-related inputs, incrementally constructing the behavior model.
4. Elevate is benchmarked on 4,000 real-world Alexa skills, achieving 15% higher state space coverage compared to Vitas on all types of apps, and exhibiting significant advancement in efficiency.

### Analysis and Critique:

The paper presents a novel approach to VUI testing for VPA apps, leveraging the power of LLMs to compensate for semantic information loss during model-based testing. The proposed framework, Elevate, demonstrates promising results in terms of state space coverage and efficiency when compared to the state-of-the-art tester, Vitas. However, the paper does not discuss the potential limitations or challenges of using LLMs for VUI testing, such as the risk

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-09       |
| Abstract | [https://arxiv.org/abs/2407.02791v1](https://arxiv.org/abs/2407.02791v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.02791v1](https://browse.arxiv.org/html/2407.02791v1)       |
| Truncated       | False       |
| Word Count       | 9664       |