
---
title: "Jatmo: Prompt Injection Defense by Task-Specific Finetuning"
id: "2312.17673v1"
description: "Jatmo creates task-specific models resilient to prompt-injection attacks for LLMs."
author: Julien Piet, Maha Alrashed, Chawin Sitawarin, Sizhe Chen, Zeming Wei, Elizabeth Sun, Basel Alomair, David Wagner
date: "2023-12-29"
image: "../../../bayesian-beagle.png"
categories: ['hci', 'programming', 'security']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### Summary:
The article introduces Jatmo, a method for generating task-specific models that are resilient to prompt-injection attacks. It leverages task-specific fine-tuning and a teacher instruction-tuned model to create robust defenses against prompt injections while maintaining the quality of outputs. The experiments demonstrate the effectiveness of Jatmo in mitigating prompt-injection attacks, making it a valuable contribution to the field of Large Language Models (LLMs) security. The article also discusses the different types of prompt injection attacks, the process of building task-specific models, and the generation of synthetic datasets for various tasks.

### Major Findings:
1. Jatmo provides a robust defense against prompt-injection attacks while maintaining the quality of outputs.
2. Task-specific models perform as well as GPT-3.5-Turbo and are immune to prompt-injection attacks, using 400 or fewer examples per task for fine-tuning.
3. The prompts used in the synthetic dataset generation process are crucial for ensuring the quality and diversity of the dataset, contributing to the effectiveness and accuracy of the fine-tuned language model.

### Analysis and Critique:
The article's major findings demonstrate the effectiveness of Jatmo in defending against prompt-injection attacks and the significance of task-specific models and synthetic dataset generation. However, potential limitations or areas for further research could include the scalability of Jatmo to larger and more complex tasks, as well as the generalizability of the findings to different types of prompt-injection attacks. Additionally, the article could benefit from discussing potential ethical considerations or unintended consequences of using Jatmo in real-world applications. Further research could explore these aspects to provide a more comprehensive understanding of the implications of Jatmo in the context of LLM security.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2312.17673v1](https://arxiv.org/abs/2312.17673v1)        |
| HTML     | [https://browse.arxiv.org/html/2312.17673v1](https://browse.arxiv.org/html/2312.17673v1)       |
| Truncated       | True       |
| Word Count       | 15999       |