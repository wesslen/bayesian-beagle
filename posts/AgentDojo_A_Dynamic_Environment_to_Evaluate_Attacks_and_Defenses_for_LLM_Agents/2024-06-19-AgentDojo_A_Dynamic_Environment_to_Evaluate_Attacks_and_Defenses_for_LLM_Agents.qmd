
---
title: "AgentDojo: A Dynamic Environment to Evaluate Attacks and Defenses for LLM Agents"
id: "2406.13352v1"
description: "AI agents are vulnerable to prompt injection attacks; AgentDojo is a framework to evaluate and improve their adversarial robustness."
author: Edoardo Debenedetti, Jie Zhang, Mislav Balunović, Luca Beurer-Kellner, Marc Fischer, Florian Tramèr
date: "2024-06-19"
image: "https://browse.arxiv.org/html/2406.13352v1/x1.png"
categories: ['security']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.13352v1/x1.png)

### Summary:

AgentDojo is a dynamic benchmarking framework designed to measure the ability of AI agents to safely solve tasks in adversarial settings. It is populated with 97 realistic tasks and 629 security test cases, and is not a static test suite but rather an extensible environment for designing and evaluating new agent tasks, defenses, and adaptive attacks. The framework is challenging for both attacks and defenses, as current LLMs fail at many tasks even in the absence of attacks, and existing prompt injection attacks break some security properties but not all. AgentDojo is expected to foster research on new design principles for AI agents that solve common tasks in a reliable and robust manner.

### Major Findings:

1. AgentDojo is a dynamic benchmarking framework that evaluates the ability of AI agents to safely solve tasks in adversarial settings.
2. The framework is populated with 97 realistic tasks and 629 security test cases, and is not a static test suite but rather an extensible environment for designing and evaluating new agent tasks, defenses, and adaptive attacks.
3. Current LLMs fail at many tasks even in the absence of attacks, and existing prompt injection attacks break some security properties but not all.

### Analysis and Critique:

AgentDojo is a promising framework for evaluating the ability of AI agents to safely solve tasks in adversarial settings. However, it is important to note that the current version of the framework is populated with general-purpose agents, defenses, and attacks that are not designed specifically for any given tasks or security scenarios. Future research is needed to develop new agent and defense designs that can improve the utility and robustness of agents in AgentDojo. Additionally, significant breakthroughs in the ability of LLMs to distinguish instructions from data will likely be necessary to thwart stronger, adaptive attacks proposed by the community. Overall, AgentDojo has the potential to serve as a live benchmark environment for measuring the progress of AI agents on increasingly challenging tasks, but also as a quantitative way of showcasing the inherent security limitations of current AI agents in adversarial settings.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-23       |
| Abstract | [https://arxiv.org/abs/2406.13352v1](https://arxiv.org/abs/2406.13352v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.13352v1](https://browse.arxiv.org/html/2406.13352v1)       |
| Truncated       | False       |
| Word Count       | 7934       |