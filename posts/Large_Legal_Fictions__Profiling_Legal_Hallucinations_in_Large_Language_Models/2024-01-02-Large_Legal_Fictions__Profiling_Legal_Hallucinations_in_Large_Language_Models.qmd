
---
title: "Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models"
description: "LLMs in law risk legal hallucinations 69-88% of interviews; caution against unsupervised use; risky for pro se litigants."
author: Matthew Dahl, Varun Magesh, Mirac Suzgun, Daniel E. Ho
date: "2024-01-02"
image: "https://browse.arxiv.org/html/2401.01301v1/x1.png"
categories: ['hci', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.01301v1/x1.png)

### Key Findings:

1. **Prevalence of Legal Hallucinations:** The study found that legal hallucinations occur at high rates between 69% and 88% of the time across the tested large language models (LLMs). These hallucinations occur when the models are asked specific, verifiable questions about random federal court cases.

2. **Failures in Correcting Incorrect Legal Assumptions:** The study also revealed that the LLMs often fail to correct a user's incorrect legal assumptions when presented with contra-factual questions.

3. **Inability to Predict or Acknowledge Hallucinations:** The evidence provided by the study suggests that LLMs cannot always predict when they are producing legal hallucinations and do not have the self-awareness to recognize these hallucinations.


### Sections:

#### 1. Introduction
   - Discusses the transformative potential of large language models in the legal industry.
   - Highlights the critical challenge to the widespread adoption of LLMs - the issue of legal hallucinations.

#### 2. Preliminaries and Background
  - Provides an overview and definition of large language models (LLMs).
  - Explores the concept of hallucination in LLMs and how it has been studied in different contexts.
  
#### 3. Profiling Hallucinations Using Legal Research Tasks
  - Outlines the different tasks used to assess legal hallucinations in LLMs, categorized by complexity.
  - Discusses the findings of the study, noting variations in hallucination rates across different types of legal queries.

#### 4. Experimental Design
  - Describes the data construction and the process of reference-based and reference-free querying to assess hallucinations in LLMs.
  
#### 5. Results
  - Provides insights into how hallucinations vary by task complexity, court hierarchy, jurisdiction, case prominence, year, and across different LLMs.
  - Discusses contra-factual bias and model calibration, highlighting challenges in LLMs' responses to legal queries.

#### 6. Discussion
  - Summarizes the implications of the findings, emphasizing the obstacles in the integration of LLMs into legal tasks.

### Critique:

The study offers a comprehensive analysis of legal hallucinations in LLMs, shedding light on the prevalence and potential challenges associated with the integration of LLMs into legal tasks. However, the study's findings are limited to the tested LLMs and may not be generalizable to all LLMs. Additionally, the study relies on hypothetical examples of legal hallucinations, and there may be limitations in real-world applications of LLMs in legal settings.

The study could benefit from a deeper exploration of the potential implications of legal hallucinations and the development of strategies to mitigate these issues in the use of LLMs for legal research and analysis. Furthermore, there might be scope to investigate the ethical and legal implications of relying on AI systems for legal tasks, especially in critical decision-making scenarios.

Overall, while the study offers valuable insights into the challenges posed by legal hallucinations in LLMs, further research and practical applications are needed to address these challenges and enhance the reliability and accuracy of LLMs in legal contexts.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-03       |
| Abstract | [http://arxiv.org/abs/2401.01301v1](http://arxiv.org/abs/2401.01301v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.01301v1](https://browse.arxiv.org/html/2401.01301v1)       |
| Truncated       | True       |
| Word Count       | 21736       |