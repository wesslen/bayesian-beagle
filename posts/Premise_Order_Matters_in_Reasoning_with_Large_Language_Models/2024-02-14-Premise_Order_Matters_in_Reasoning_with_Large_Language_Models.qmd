
---
title: "Premise Order Matters in Reasoning with Large Language Models"
id: "2402.08939v1"
description: "LLMs struggle with premise ordering in reasoning tasks, leading to significant performance drops. New benchmark released."
author: Xinyun Chen, Ryan A. Chi, Xuezhi Wang, Denny Zhou
date: "2024-02-14"
image: "../../https://browse.arxiv.org/html/2402.08939v1/extracted/5407747/img/figure2.png"
categories: ['prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](../../https://browse.arxiv.org/html/2402.08939v1/extracted/5407747/img/figure2.png)

### **Summary:**
- Large language models (LLMs) have shown impressive reasoning performance in various domains, but they are surprisingly sensitive to the ordering of premises in reasoning tasks.
- LLMs achieve the best performance when the premise order aligns with the context required in intermediate reasoning steps.
- Permuting the premise order can cause a performance drop of over 30% in deductive reasoning tasks and mathematical problem-solving.

### **Major Findings:**
1. LLMs are surprisingly brittle to the ordering of the premises, with a performance drop of over 30% when the premise order does not align with the context required in intermediate reasoning steps.
2. LLMs achieve the best performance when the premises are arranged in the same order as they appear in the ground-truth proof, especially in deductive reasoning tasks.
3. The performance gap is more significant when the number of premises increases, and the accuracy decrease caused by different ordering can be more than 30%.

### **Analysis and Critique:**
- LLMs exhibit failure modes that align with human-like cognitive bias, such as the Reversal Curse and distractibility.
- The premise order effect in LLM reasoning indicates that LLMs are more comfortable reasoning via reading left-to-right instead of back-and-forth, which can be attributed to the auto-regressive model design or the reasoning bias learned from the training corpus.
- The study leaves proposing new training and modeling techniques to mitigate the premise order effect as future work.

The article provides valuable insights into the limitations of LLMs in reasoning tasks and highlights the need for further research to address the premise order effect. However, the study could benefit from a more in-depth exploration of the underlying factors contributing to the observed sensitivity to premise ordering. Additionally, further investigation into the potential biases learned from the training corpus and their impact on LLM reasoning performance would enhance the comprehensiveness of the analysis.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.08939v1](https://arxiv.org/abs/2402.08939v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.08939v1](https://browse.arxiv.org/html/2402.08939v1)       |
| Truncated       | False       |
| Word Count       | 6131       |