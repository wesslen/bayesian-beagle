
---
title: "What's in an embedding? Would a rose by any embedding smell as sweet?"
id: "2406.06870v1"
description: "[TEXT] This study examines the relationship between social media use and mental health in young adults. Results suggest a negative correlation between excessive social media use and mental well-being.

[TL;DR] Excessive social media use linked to poor mental health in young adults."
author: Venkat Venkatasubramanian
date: "2024-06-11"
image: "../../../bayesian-beagle.png"
categories: ['education']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### Summary:

The article discusses the limitations of Large Language Models (LLMs) and suggests integrating them with an "algebraic" representation of knowledge, including symbolic AI elements used in expert systems, to create Large Knowledge Models (LKMs). This integration aims to create models that not only possess "deep" knowledge grounded in first principles but also have the ability to reason and explain, mimicking human expert capabilities.

### Major Findings:

1. LLMs, such as GPT-3.5, use high-dimensional vectors for embedding tokens, which raises the question of whether they use a "geometric" representation rather than an "algebraic" one for their knowledge internally.
2. The performance of LLMs critically depends on the quantity and quality of data used in their training. As the LLM has more parameters and is trained on more data, its problem-solving capability grows enormously.
3. Recent research from Anthropic AI and Open AI reveals that LLMs, such as Claude 3 Sonnet, use a "geometry"-like internal representation in a high-dimensional embedding space rather than an "algebraic" one. This representation captures the meanings of words and phrases and their relative distances, making it easier to do sophisticated "reasoning," such as analogies and metaphors.

### Analysis and Critique:

1. The article suggests that relying only on a "geometric" understanding of the world limits the potential of LLMs, particularly for science and engineering applications.
2. The authors argue that current LLMs have achieved animal-like mastery of their tasks but not a "deeper" mechanistic understanding of the world, as humans do.
3. The article highlights the need for LLMs to evolve beyond their current capabilities and incorporate both "algebraic" (i.e., symbolic) and "geometric" representations of the world, particularly for science and engineering.
4. The authors propose the development of hybrid AI systems, called Large Knowledge Models (LKMs), which would not be limited to NLP-based techniques or NLP-like applications only.
5. The article concludes that to harness the potential of generative AI safely and effectively, a paradigm shift from LLMs to LKMs is needed.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-23       |
| Abstract | [https://arxiv.org/abs/2406.06870v1](https://arxiv.org/abs/2406.06870v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.06870v1](https://browse.arxiv.org/html/2406.06870v1)       |
| Truncated       | False       |
| Word Count       | 5609       |