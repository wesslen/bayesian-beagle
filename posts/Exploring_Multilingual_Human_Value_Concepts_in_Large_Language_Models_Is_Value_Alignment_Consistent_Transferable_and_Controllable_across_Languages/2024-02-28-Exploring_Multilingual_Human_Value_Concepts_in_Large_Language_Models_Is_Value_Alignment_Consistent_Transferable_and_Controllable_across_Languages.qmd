
---
title: "Exploring Multilingual Human Value Concepts in Large Language Models: Is Value Alignment Consistent, Transferable and Controllable across Languages?"
id: "2402.18120v1"
description: "LLMs encode multilingual human values, with cross-lingual inconsistencies and transfer traits. Suggestions for LLM pre-training."
author: Shaoyang Xu, Weilong Dong, Zishan Guo, Xinwei Wu, Deyi Xiong
date: "2024-02-28"
image: "https://browse.arxiv.org/html/2402.18120v1/x1.png"
categories: ['social-sciences', 'hci', 'architectures']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.18120v1/x1.png)

### Summary:
This article explores multilingual human value concepts in Large Language Models (LLMs) and investigates the consistency, transferability, and controllability of value alignment across languages. The authors empirically substantiate the existence of multilingual human values in LLMs and disclose three traits arising from language resource disparities: cross-lingual inconsistency, distorted linguistic relationships, and unidirectional cross-lingual transfer between high- and low-resource languages. They also validate the feasibility of cross-lingual control over value alignment capabilities of LLMs, leveraging the dominant language as a source language. The findings suggest that the composition of multilingual data for LLMs pre-training should include a limited number of dominant languages for cross-lingual alignment transfer while avoiding their excessive prevalence and maintaining a balanced distribution of non-dominant languages.

### Major Findings:
1. LLMs encode concepts that represent human values in multiple languages, and the larger the models, the more precisely these concepts are captured.
2. The cross-lingual concept consistency and transferability are intricately tied to the multilinguality pattern of the models to be extracted. The presence of dominant languages tends to bring about a monotonic cross-lingual transfer pattern, whereas a balanced multilinguality facilitates mutual cross-lingual transfer.
3. The value alignment of LLMs can be effectively transferred across languages, with the dominant language as a source language.

### Analysis and Critique:
- The study provides valuable insights into the multilingual human value concepts in LLMs and the potential for cross-lingual control over value alignment. However, the findings are based on specific datasets and models, and the generalizability of the results to other contexts is not fully addressed.
- The article acknowledges the limitations of relying on translations from translation engines and the semi-automated evaluation of model control. However, it would be beneficial to discuss potential biases introduced by these limitations and their impact on the validity of the findings.
- The suggestions for enhancing multilingual AI safety and utility are based on the authors' findings and may require further validation and refinement through additional research and experimentation. The potential implications of implementing these suggestions should be thoroughly considered.

Overall, the article provides valuable insights into the multilingual human value concepts in LLMs and the potential for cross-lingual control over value alignment, but further research is needed to address the limitations and validate the practical implications of the findings.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.18120v1](https://arxiv.org/abs/2402.18120v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.18120v1](https://browse.arxiv.org/html/2402.18120v1)       |
| Truncated       | False       |
| Word Count       | 9194       |