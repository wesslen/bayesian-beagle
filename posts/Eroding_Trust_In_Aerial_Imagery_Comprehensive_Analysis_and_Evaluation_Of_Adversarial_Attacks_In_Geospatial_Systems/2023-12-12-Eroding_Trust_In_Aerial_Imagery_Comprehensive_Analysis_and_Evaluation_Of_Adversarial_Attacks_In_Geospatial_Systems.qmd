
---
title: "Eroding Trust In Aerial Imagery: Comprehensive Analysis and Evaluation Of Adversarial Attacks In Geospatial Systems"
id: "2312.07389v1"
description: "Adversarial attacks threaten aerial imagery integrity, requiring urgent analysis and mitigation."
author: Michael Lanier, Aayush Dhakal, Zhexiao Xiong, Arthur Li, Nathan Jacobs, Yevgeniy Vorobeychik
date: "2023-12-12"
image: "../../../bayesian-beagle.png"
categories: ['security']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### **Summary:**
The article discusses the erosion of trust in aerial imagery due to adversarial attacks, particularly those exploiting control over labels or employing physically feasible trojans. The study focuses on the degradation of confidence in geospatial systems and proposes and evaluates innovative attack methodologies, including those tailored to overhead images. The authors demonstrate the potential risks and highlight the non-trivial nature of the problem compared to recent works.

### **Major Findings:**
1. The study demonstrates the success of white box evasion attacks against classifiers trained on electro-optical remote sensing imagery.
2. Categorical inference attacks are effective at recovering training data's geolocation, given white box access to a model trained on such data.
3. The authors present a novel physically realizable Trojan attack against a classifier trained on electro-optical remote sensing imagery, providing evidence that this type of attack is weak.

### **Analysis and Critique:**
The article provides a comprehensive analysis of adversarial attacks in geospatial systems, highlighting the potential risks and challenges associated with defending against such attacks. The study's findings shed light on the vulnerability of classifiers trained on remote sensing imagery and emphasize the need for robust defenses against adversarial attacks. However, the article lacks a detailed discussion of potential countermeasures and mitigation strategies to address the identified vulnerabilities. Additionally, the study's focus on specific datasets and attack methodologies may limit the generalizability of the findings to broader contexts. Further research is needed to explore the applicability of the proposed defense mechanisms and to address the limitations of the study.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2312.07389v1](https://arxiv.org/abs/2312.07389v1)        |
| HTML     | [https://browse.arxiv.org/html/2312.07389v1](https://browse.arxiv.org/html/2312.07389v1)       |
| Truncated       | False       |
| Word Count       | 13324       |