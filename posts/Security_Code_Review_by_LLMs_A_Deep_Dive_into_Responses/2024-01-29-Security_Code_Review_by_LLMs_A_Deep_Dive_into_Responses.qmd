
---
title: "Security Code Review by LLMs: A Deep Dive into Responses"
id: "2401.16310v1"
description: "LLMs struggle with verbosity, vagueness, and incompleteness in security code review."
author: Jiaxin Yu, Peng Liang, Yujia Fu, Amjed Tahir, Mojtaba Shahin, Chong Wang, Yangxiao Cai
date: "2024-01-29"
image: "../../../bayesian-beagle.png"
categories: ['robustness', 'security', 'prompt-engineering', 'architectures', 'programming']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### Summary:
Security code review aims to combine automated tools and manual efforts to detect security defects during development. This study compared the detection performance of three state-of-the-art Large Language Models (LLMs) under five prompts on 549 code files that contain security defects from real-world code reviews. The results indicate that the responses produced by LLMs often suffer from verbosity, vagueness, and incompleteness, highlighting the necessity to enhance their conciseness, understandability, and compliance to security defect detection.

### Major Findings:
1. The study compared the detection performance of three state-of-the-art LLMs (Gemini Pro, GPT-4, and GPT-3.5) under five prompts on 549 code files that contain security defects from real-world code reviews.
2. The responses produced by LLMs often suffer from verbosity, vagueness, and incompleteness, highlighting the necessity to enhance their conciseness, understandability, and compliance to security defect detection.
3. The study revealed the deficiencies of LLM-generated responses in security code review and paves the way for future optimization of LLMs towards this task.

### Analysis and Critique:
The study provides valuable insights into the challenges of utilizing LLMs for automated security code review. However, it is important to note that the LLMs performed poorly in detecting security defects, indicating the need for further improvement in their capabilities. Additionally, the study focused on the deficiencies of LLM-generated responses, but further research is needed to address the underlying problems and optimize LLMs for security code review. The findings of this study have implications for the development and application of LLMs in software development tasks, highlighting the need for domain-specific LLMs and prompt optimization.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-26       |
| Abstract | [https://arxiv.org/abs/2401.16310v1](https://arxiv.org/abs/2401.16310v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.16310v1](https://browse.arxiv.org/html/2401.16310v1)       |
| Truncated       | False       |
| Word Count       | 9038       |