
---
title: "Probing Language Models' Gesture Understanding for Enhanced Human-AI Interaction"
id: "2401.17858v1"
description: "Proposal to study Large Language Models' ability to interpret non-verbal cues in text."
author: Philipp Wicke
date: "2024-01-31"
image: "https://browse.arxiv.org/html/2401.17858v1/extracted/5380014/images/page01.png"
categories: ['programming', 'prompt-engineering', 'social-sciences', 'hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.17858v1/extracted/5380014/images/page01.png)

### **Summary:**
The proposal aims to investigate the interaction between Large Language Models (LLMs) and non-verbal communication, specifically focusing on gestures. It sets out a plan to examine the proficiency of LLMs in deciphering both explicit and implicit non-verbal cues within textual prompts and their ability to associate these gestures with various contextual factors. The research proposes to test established psycholinguistic study designs to construct a comprehensive dataset that pairs textual prompts with detailed gesture descriptions, encompassing diverse regional variations, and semantic labels. To assess LLMs’ comprehension of gestures, experiments are planned, evaluating their ability to simulate human behavior in order to replicate psycholinguistic experiments. These experiments consider cultural dimensions and measure the agreement between LLM-identified gestures and the dataset, shedding light on the models’ contextual interpretation of non-verbal cues (e.g. gestures).

### Major Findings:
1. The proposal aims to investigate the proficiency of LLMs in deciphering both explicit and implicit non-verbal cues within textual prompts and their ability to associate these gestures with various contextual factors.
2. The research proposes to test established psycholinguistic study designs to construct a comprehensive dataset that pairs textual prompts with detailed gesture descriptions, encompassing diverse regional variations, and semantic labels.
3. Experiments are planned to evaluate LLMs' ability to simulate human behavior and replicate psycholinguistic experiments, considering cultural dimensions and measuring the agreement between LLM-identified gestures and the dataset.

### Analysis and Critique:
The proposal presents a comprehensive plan to investigate the interaction between LLMs and non-verbal communication, particularly focusing on gestures. However, it is important to note that the research has not been conducted, and the strengths and weaknesses outlined are based on anticipated outcomes. The reliance on open-source models may introduce limitations in terms of model complexity compared to proprietary counterparts like GPT-3, raising questions about the generalizability of the findings to models with different architectures and scales. Future research directions could include extending the study to multimodal models and exploring the impact of gesture-based communication on user experience and engagement with conversational AI systems.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-26       |
| Abstract | [https://arxiv.org/abs/2401.17858v1](https://arxiv.org/abs/2401.17858v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.17858v1](https://browse.arxiv.org/html/2401.17858v1)       |
| Truncated       | False       |
| Word Count       | 3310       |