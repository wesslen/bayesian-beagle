
---
title: "Active Use of Latent Constituency Representation in both Humans and Large Language Models"
id: "2405.18241v1"
description: "Humans and LLMs like ChatGPT construct similar latent representations of hierarchical linguistic constituents."
author: Wei Liu, Ming Xiang, Nai Ding
date: "2024-05-28"
image: "../../img/2405.18241v1/image_1.png"
categories: ['hci', 'social-sciences']
format:
  html:
    code-overflow: wrap
---

![](../../img/2405.18241v1/image_1.png)

**Summary:**

The study titled "Active Use of Latent Constituency Representation in both Humans and Large Language Models" explores the understanding of sentence representation in the human brain and large language models (LLMs) like ChatGPT. The research aims to demonstrate that humans and LLMs construct similar latent representations of hierarchical linguistic constituents by analyzing their behaviors during a novel one-shot learning task. In this task, participants infer which words should be deleted from a sentence. Both humans and LLMs tend to delete a constituent, instead of a nonconstituent word string, while a naive sequence processing model that has access to word properties and ordinal positions does not show this property. The study concludes that a latent tree-structured constituency representation can emerge in both the human brain and LLMs.

**Major Findings:**

1. Humans and LLMs, such as ChatGPT, construct similar latent representations of hierarchical linguistic constituents during a novel one-shot learning task.
2. Both humans and LLMs tend to delete a constituent, instead of a nonconstituent word string, in the task, while a naive sequence processing model does not show this property.
3. A latent tree-structured constituency representation can emerge in both the human brain and LLMs.

**Analysis and Critique:**

The study provides an interesting perspective on the understanding of sentence representation in the human brain and LLMs. The use of a novel one-shot learning task to analyze the behaviors of humans and LLMs is a unique approach to explore the latent representations of hierarchical linguistic constituents. However, the study does not discuss the potential limitations or shortcomings of the task or the results. Additionally, the study does not provide a comparison of the performance of humans and LLMs in the task, which could have been useful to understand the differences and similarities between the two. Furthermore, the study does not discuss the implications of the findings for the development of more advanced LLMs or the understanding of human language processing. Overall, the study provides valuable insights into the latent representations of hierarchical linguistic constituents in humans and LLMs, but further research is needed to fully understand the implications of the findings.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2405.18241v1](https://arxiv.org/abs/2405.18241v1)        |
| HTML     | [https://browse.arxiv.org/html/2405.18241v1](https://browse.arxiv.org/html/2405.18241v1)       |
| Truncated       | False       |
| Word Count       | 24170       |