
---
title: "SYNFAC-EDIT: Synthetic Imitation Edit Feedback for Factual Alignment in Clinical Summarization"
id: "2402.13919v1"
description: "GPT used to improve factual accuracy in clinical NLP."
author: Prakamya Mishra, Zonghai Yao, Parth Vashisht, Feiyun Ouyang, Beining Wang, Vidhi Dhaval Mody, Hong Yu
date: "2024-02-21"
image: "https://browse.arxiv.org/html/2402.13919v1/extracted/5416467/Images/acl_main.png"
categories: ['robustness', 'production']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.13919v1/extracted/5416467/Images/acl_main.png)

### Summary:
The article introduces a novel pipeline, SYNFAC-EDIT, which utilizes large language models (LLMs) to generate high-quality feedback for enhancing factual consistency in clinical note summarization. The research focuses on edit feedback, aiming to reduce hallucinations and align closely with medical facts. The study leverages GPT's advanced capabilities in clinical NLP to offer expert-level edit feedback. The pipeline generates synthetic preference-based data in two directions for alignment training, HighLow and LowHigh, using GPT-3.5 and GPT-4. The experiments demonstrate the efficacy of utilizing synthetic edit feedback to enhance the factual accuracy of model-generated summaries.

### Major Findings:
1. Large language models (LLMs) struggle with factual inaccuracies, which is a critical issue in clinical NLP applications.
2. The SYNFAC-EDIT pipeline utilizes GPT's advanced capabilities to generate high-quality feedback for enhancing factual consistency in clinical note summarization.
3. The experiments demonstrate the efficacy of utilizing synthetic edit feedback to enhance the factual accuracy of model-generated summaries.

### Analysis and Critique:
- The study is limited to the task of factuality alignment in clinical summarization, and the adaptation of the proposed method to other domains remains unexplored.
- The research relies on domain expert annotators for human evaluation, and employing more qualified domain experts as annotators would enhance the statistical significance of the results.
- Privacy protection and ethical considerations are crucial when dealing with clinical text and patient data, and the study acknowledges the need for strict adherence to data protection laws and ethical standards.
- The potential biases present in large language models (LLMs) and the broader ethical societal implications of technology usage are highlighted as important considerations for future work.

Overall, the study demonstrates the potential of using large language models to improve the factual accuracy of clinical summaries, but it also raises important limitations and ethical considerations that need to be addressed for the safe, fair, and effective use of technology in healthcare.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.13919v1](https://arxiv.org/abs/2402.13919v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.13919v1](https://browse.arxiv.org/html/2402.13919v1)       |
| Truncated       | False       |
| Word Count       | 8150       |