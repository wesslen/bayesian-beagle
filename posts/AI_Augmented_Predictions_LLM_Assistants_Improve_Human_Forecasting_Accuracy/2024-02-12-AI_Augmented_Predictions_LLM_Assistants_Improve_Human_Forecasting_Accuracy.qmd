
---
title: "AI-Augmented Predictions: LLM Assistants Improve Human Forecasting Accuracy"
id: "2402.07862v1"
description: "LLMs improve forecasting accuracy by 23%, even with biased assistants, in cognitively demanding tasks."
author: Philipp Schoenegger, Peter S. Park, Ezra Karger, Philip E. Tetlock
date: "2024-02-12"
image: "../../img/2402.07862v1/image_1.png"
categories: ['architectures', 'production']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.07862v1/image_1.png)

### Summary:
- The study explores the potential of large language models (LLMs) to augment judgment in forecasting tasks, finding that LLM augmentation significantly enhances forecasting accuracy by 23% across both types of assistants, compared to the control group.
- Participants were randomly assigned to three conditions: Treatment (superforecasting prompt), Treatment (Bias) (biased prompt), and Control, with results showing that both LLM treatments outperformed the control group in forecasting accuracy.
- The mixed effects model analysis showed that both the superforecasting and biased LLM augmentation conditions had significant effects on increasing accuracy in forecasting.

### Major Findings:
1. LLM augmentation significantly enhances forecasting accuracy by 23% across both types of assistants, compared to the control group.
2. Both LLM treatments outperformed the control group in forecasting accuracy, with no significant difference between the superforecasting and biased LLM treatments.
3. Both the superforecasting and biased LLM augmentation conditions had significant effects on increasing accuracy in forecasting.

### Analysis and Critique:
- The study's findings suggest that LLM augmentation can significantly enhance forecasting accuracy, even when the assistant is biased.
- The results raise questions about the overall impact of LLM augmentation on aggregate accuracy and the potential variation in effectiveness based on question difficulty.
- The biased LLM augmentation treatment prompt has a significant impact on forecasting accuracy, particularly in Question 3, highlighting the potential for biased language models to influence predictions.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-13       |
| Abstract | [https://arxiv.org/abs/2402.07862v1](https://arxiv.org/abs/2402.07862v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.07862v1](https://browse.arxiv.org/html/2402.07862v1)       |
| Truncated       | True       |
| Word Count       | 16365       |