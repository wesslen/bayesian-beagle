
---
title: "Understanding Fine-grained Distortions in Reports of Scientific Findings"
id: "2402.12431v1"
description: "Distorted science communication harms trust and behavior. Detecting distortions in findings is challenging."
author: Amelie WÃ¼hrl, Dustin Wright, Roman Klinger, Isabelle Augenstein
date: "2024-02-19"
image: "https://browse.arxiv.org/html/2402.12431v1/x1.png"
categories: ['robustness', 'social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.12431v1/x1.png)

The article "Understanding Fine-grained Distortions in Reports of Scientific Findings" investigates the impact of distorted science communication on individuals and society. The authors emphasize the importance of understanding how scientific findings are reported to the general public and the need for methods to detect distortions from the original work automatically. The article makes three foundational contributions: annotating 1,600 instances of scientific findings from academic papers paired with corresponding findings as reported in news articles and tweets, establishing baselines for automatically detecting distortions, and analyzing the prevalence of changes in these characteristics in both human-annotated and large-scale unlabeled data. The results show that scientific findings frequently undergo subtle distortions when reported, with tweets distorting findings more often than science news reports. Detecting fine-grained distortions automatically poses a challenging task, with task-specific models consistently outperforming few-shot LLM prompting.

### Major Findings:
1. Scientific findings frequently undergo subtle distortions when reported, with tweets distorting findings more often than science news reports.
2. Detecting fine-grained distortions automatically poses a challenging task, with task-specific models consistently outperforming few-shot LLM prompting.
3. The prevalence of changes in causality, certainty, generality, and sensationalism in both human-annotated and large-scale unlabeled data highlights the need for further research in this area.

### Analysis and Critique:
- The article provides valuable insights into the prevalence of distortions in science communication, but the limitations of the study should be acknowledged.
- The agreement scores for the annotation tasks are relatively low, indicating the complexity and subjectivity of the concepts being studied.
- The few-shot prompting experiments show that LLMs do not effectively leverage the annotation instructions and examples provided as prompts, suggesting the need for further prompt engineering or fine-tuning.
- The large-scale analysis validates the robustness of the results, but future work is needed to determine the full extent of distortions with further developed models.
- The article raises important ethical considerations regarding the exposure of annotators to false information and the potential impact of the study on detecting and counteracting false information online.

Overall, the article provides a comprehensive analysis of fine-grained distortions in science communication and highlights the need for further research in this area. The findings have implications for improving the accuracy and reliability of scientific information reported to the general public.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.12431v1](https://arxiv.org/abs/2402.12431v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.12431v1](https://browse.arxiv.org/html/2402.12431v1)       |
| Truncated       | False       |
| Word Count       | 10400       |