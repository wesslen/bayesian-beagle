<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Shulin Zeng">
<meta name="author" content="Jun Liu">
<meta name="author" content="Guohao Dai">
<meta name="author" content="Xinhao Yang">
<meta name="author" content="Tianyu Fu">
<meta name="author" content="Hongyi Wang">
<meta name="author" content="Wenheng Ma">
<meta name="author" content="Hanbo Sun">
<meta name="author" content="Shiyao Li">
<meta name="author" content="Zixiao Huang">
<meta name="author" content="Yadong Dai">
<meta name="author" content="Jintao Li">
<meta name="author" content="Zehao Wang">
<meta name="author" content="Ruoyu Zhang">
<meta name="author" content="Kairui Wen">
<meta name="author" content="Xuefei Ning">
<meta name="author" content="Yu Wang">
<meta name="dcterms.date" content="2024-01-08">
<meta name="description" content="FlightLLM enables efficient LLM inference on FPGAs, overcoming challenges with sparse DSP chain, memory bandwidth, and compilation overhead.">

<title>Bayesian beagle - FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Bayesian beagle - FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs">
<meta property="og:description" content="FlightLLM enables efficient LLM inference on FPGAs, overcoming challenges with sparse DSP chain, memory bandwidth, and compilation overhead.">
<meta property="og:image" content="https://browse.arxiv.org/html/2401.03868v2/x1.png">
<meta property="og:site-name" content="Bayesian beagle">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../icon.jpg" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Bayesian beagle</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">Bayesian beagle</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/wesslen/bayesian-beagle" rel="" target=""><i class="bi bi-github" role="img" aria-label="github">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs</h1>
  <div class="quarto-categories">
    <div class="quarto-category">architectures</div>
  </div>
  </div>

<div>
  <div class="description">
    FlightLLM enables efficient LLM inference on FPGAs, overcoming challenges with sparse DSP chain, memory bandwidth, and compilation overhead.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Authors</div>
    <div class="quarto-title-meta-contents">
             <p>Shulin Zeng </p>
             <p>Jun Liu </p>
             <p>Guohao Dai </p>
             <p>Xinhao Yang </p>
             <p>Tianyu Fu </p>
             <p>Hongyi Wang </p>
             <p>Wenheng Ma </p>
             <p>Hanbo Sun </p>
             <p>Shiyao Li </p>
             <p>Zixiao Huang </p>
             <p>Yadong Dai </p>
             <p>Jintao Li </p>
             <p>Zehao Wang </p>
             <p>Ruoyu Zhang </p>
             <p>Kairui Wen </p>
             <p>Xuefei Ning </p>
             <p>Yu Wang </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 8, 2024</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p><img src="https://browse.arxiv.org/html/2401.03868v2/x1.png" class="img-fluid"></p>
<section id="flightllm-efficient-large-language-model-inference-with-a-complete-mapping-flow-on-fpgas" class="level1">
<h1>FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs</h1>
<section id="major-takeaways" class="level2">
<h2 class="anchored" data-anchor-id="major-takeaways">Major Takeaways</h2>
<ol type="1">
<li><strong>Efficiency Enhancement</strong>: FlightLLM addresses the efficiency limitations of Large Language Models (LLMs) by leveraging FPGA-specific resources to achieve higher energy and cost efficiency compared to commercial GPUs.</li>
<li><strong>Complete Mapping Flow</strong>: The paper proposes a complete mapping flow for LLM inference on FPGAs, highlighting innovations in computation and memory overhead solutions.</li>
<li><strong>Performance Comparison</strong>: FlightLLM outperforms SOTA accelerators, achieving better latency and throughput compared to GPUs and other FPGA-based accelerators.</li>
</ol>
</section>
<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<p>The paper introduces FlightLLM, a solution for efficient Large Language Model (LLM) inference on FPGAs. It addresses the challenges of heavy computation and memory overheads by leveraging FPGA-specific resources. FlightLLM achieves higher energy and cost efficiency compared to commercial GPUs and outperforms SOTA accelerators.</p>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<ul>
<li>Recent developments in Large Language Models (LLMs) have highlighted their significant impact across various domains.</li>
<li>LLMs are widely used in latency-sensitive scenarios, necessitating efficient computation and memory management.</li>
<li>Compression techniques such as sparsification and quantization are employed to mitigate computation and memory overheads, but current hardware platforms struggle to efficiently support these methods.</li>
</ul>
</section>
<section id="background-and-related-work" class="level2">
<h2 class="anchored" data-anchor-id="background-and-related-work">Background and Related Work</h2>
<ul>
<li>Transformer-based LLMs achieve state-of-the-art performance across Natural Language Processing (NLP) tasks. The transformer model architecture consists of cascaded transformer blocks with Multi-Head Attention (MHA) and Feed Forward Network (FFN) networks.</li>
<li>Efficient transformer models leverage compression techniques such as sparsification and quantization to reduce computation and memory overheads. Previous works have focused on specialized architectures to accelerate sparse attention and optimize linear layers with mixed-precision quantization.</li>
</ul>
</section>
<section id="computing-architecture" class="level2">
<h2 class="anchored" data-anchor-id="computing-architecture">Computing Architecture</h2>
<ul>
<li>FlightLLM’s overall architecture includes a task scheduler, memory controller, and multiple computing cores equipped with a unified Matrix Processing Engine (MPE), Memory Management Unit (MMU), Special Function Unit (SFU), and Instruction Scheduler.</li>
<li>The configurable sparse DSP chain and always-on-chip decode scheme enhance computation efficiency and memory bandwidth, while supporting different sparsity patterns. FlightLLM also supports mixed-precision quantization and length adaptive compilation to reduce instruction storage overhead.</li>
</ul>
</section>
<section id="always-on-chip-decode" class="level2">
<h2 class="anchored" data-anchor-id="always-on-chip-decode">Always-on-chip Decode</h2>
<ul>
<li>The on-chip decode scheme in FlightLLM enables efficient memory bandwidth utilization by keeping activations in on-chip memory during the decode stage, reducing frequent access to off-chip memory.</li>
<li>Mixed-precision support using a dedicated dequantization unit helps optimize compactly stored mixed-precision data and reduce memory access overhead.</li>
</ul>
</section>
<section id="length-adaptive-compilation" class="level2">
<h2 class="anchored" data-anchor-id="length-adaptive-compilation">Length Adaptive Compilation</h2>
<ul>
<li>FlightLLM proposes a length adaptive compilation approach to reduce the instruction storage overhead by allowing different lengths of prefill or decode to share the same instructions within threshold ranges, optimizing memory utilization.</li>
</ul>
</section>
<section id="analytical-model-for-rtl-generation" class="level2">
<h2 class="anchored" data-anchor-id="analytical-model-for-rtl-generation">Analytical Model for RTL Generation</h2>
<ul>
<li>FlightLLM uses an analytical model to optimize hardware resource utilization and dynamically adjust the computing parallelism and buffer size to generate corresponding RTL code for implementation on different FPGA platforms.</li>
</ul>
</section>
<section id="evaluation" class="level2">
<h2 class="anchored" data-anchor-id="evaluation">Evaluation</h2>
<ul>
<li>FlightLLM is evaluated on state-of-the-art LLMs such as OPT-6.7B and LLaMA2-7B, achieving better latency, throughput, energy efficiency, and cost efficiency compared to both commercial GPUs and SOTA accelerators.</li>
<li>The latency breakdown analysis and multi-batch performance comparisons highlight FlightLLM’s efficient hardware performance.</li>
</ul>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>The paper introduces FlightLLM as a promising approach for efficient LLM inference on FPGAs, enabling higher energy and cost efficiency compared to commercial GPUs and SOTA accelerators. FlightLLM demonstrates optimizations in computation efficiency, memory bandwidth utilization, and latency reductions, making it a competitive solution for LLM inference.</p>
</section>
<section id="critique" class="level2">
<h2 class="anchored" data-anchor-id="critique">Critique</h2>
<ul>
<li>The paper does not provide a detailed discussion of potential limitations or trade-offs with FlightLLM’s approach, which could help provide a more comprehensive understanding of its applicability and potential constraints.</li>
<li>While the evaluation results are promising, it would be useful to compare FlightLLM’s performance against a wider range of FPGA-based LLM accelerators to provide a more comprehensive picture of its comparative advantages.</li>
</ul>
<p>Overall, the paper effectively presents FlightLLM as a compelling solution for efficient LLM inference, highlighting innovations in FPGA-based acceleration and performance optimizations.</p>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>gpt-3.5-turbo-1106</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-02-26</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="http://arxiv.org/abs/2401.03868v2">http://arxiv.org/abs/2401.03868v2</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2401.03868v2">https://browse.arxiv.org/html/2401.03868v2</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>False</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>12121</td>
</tr>
</tbody>
</table>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="wesslen/bayesian-beagle" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/wesslen/bayesian-beagle/edit/main/posts/FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs/2024-01-08-FlightLLM_Efficient_Large_Language_Model_Inference_with_a_Complete_Mapping_Flow_on_FPGAs.qmd" class="toc-action">Edit this page</a></p></div></div></div></div></footer></body></html>