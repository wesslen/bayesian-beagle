
---
title: "Evidence of a log scaling law for political persuasion with large language models"
id: "2406.14508v1"
description: "Larger language models only slightly more persuasive than smaller ones, with task completion being key."
author: Kobi Hackenburg, Ben M. Tappin, Paul RÃ¶ttger, Scott Hale, Jonathan Bright, Helen Margetts
date: "2024-06-20"
image: "https://browse.arxiv.org/html/2406.14508v1/x1.png"
categories: ['production', 'social-sciences', 'hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.14508v1/x1.png)

### Summary:

This study investigates the persuasive capabilities of large language models (LLMs) on political issues. The authors generated 720 persuasive messages on 10 U.S. political issues using 24 language models of varying sizes. They then deployed these messages in a large-scale randomized survey experiment to estimate the persuasive capability of each model. The findings reveal a log scaling law, where model persuasiveness is characterized by sharply diminishing returns. This means that current frontier models are barely more persuasive than models smaller in size by an order of magnitude or more. Additionally, the study finds that mere task completion (coherence, staying on topic) appears to account for larger models' persuasive advantage. These findings suggest that further scaling model size will not significantly increase the persuasiveness of static LLM-generated messages.

### Major Findings:

1. The persuasiveness of language models follows a log scaling law, with sharply diminishing returns as model size increases.
2. Current frontier models, such as Claude-3-Opus and GPT-4-Turbo, are not significantly more persuasive than models with as few as 7-13 billion parameters (e.g., Qwen1.5-7B and Llama-2-13B).
3. Mere task completion (coherence, staying on topic) appears to account for larger models' persuasive advantage.

### Analysis and Critique:

The study provides valuable insights into the persuasive capabilities of LLMs on political issues. However, there are some limitations and potential areas for further research:

1. The study does not explicitly train or optimize models for persuasiveness, which could potentially lead to an underestimation of the persuasive ceiling.
2. The sample of participants in the survey experiment skewed liberal, Democratic, and female, which may limit the generalizability of the findings.
3. The study focuses on static, single-turn messages, and does not explore the potential impact of prolonged multi-turn dialogue or personalization on model persuasiveness.
4. The study does not investigate the potential impact of in-domain fine-tuning or more advanced prompting strategies on model persuasiveness.

Overall, the study offers a comprehensive analysis

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-23       |
| Abstract | [https://arxiv.org/abs/2406.14508v1](https://arxiv.org/abs/2406.14508v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.14508v1](https://browse.arxiv.org/html/2406.14508v1)       |
| Truncated       | False       |
| Word Count       | 9012       |