<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Shujie Li">
<meta name="author" content="Liang Li">
<meta name="author" content="Ruiying Geng">
<meta name="author" content="Min Yang">
<meta name="author" content="Binhua Li">
<meta name="author" content="Guanghu Yuan">
<meta name="author" content="Wanwei He">
<meta name="author" content="Shao Yuan">
<meta name="author" content="Can Ma">
<meta name="author" content="Fei Huang">
<meta name="author" content="Yongbin Li">
<meta name="dcterms.date" content="2024-01-02">
<meta name="description" content="Data-to-text (D2T) generation enhanced by graph-based pre-training shows effective performance on various structured data.">

<title>Bayesian beagle - Unifying Structured Data as Graph for Data-to-Text Pre-Training</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Bayesian beagle - Unifying Structured Data as Graph for Data-to-Text Pre-Training">
<meta property="og:description" content="Data-to-text (D2T) generation enhanced by graph-based pre-training shows effective performance on various structured data.">
<meta property="og:image" content="https://browse.arxiv.org/html/2401.01183v1/x1.png">
<meta property="og:site-name" content="Bayesian beagle">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../icon.jpg" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Bayesian beagle</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">Bayesian beagle</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/wesslen/bayesian-beagle" rel="" target=""><i class="bi bi-github" role="img" aria-label="github">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Unifying Structured Data as Graph for Data-to-Text Pre-Training</h1>
  <div class="quarto-categories">
    <div class="quarto-category">production</div>
  </div>
  </div>

<div>
  <div class="description">
    Data-to-text (D2T) generation enhanced by graph-based pre-training shows effective performance on various structured data.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Authors</div>
    <div class="quarto-title-meta-contents">
             <p>Shujie Li </p>
             <p>Liang Li </p>
             <p>Ruiying Geng </p>
             <p>Min Yang </p>
             <p>Binhua Li </p>
             <p>Guanghu Yuan </p>
             <p>Wanwei He </p>
             <p>Shao Yuan </p>
             <p>Can Ma </p>
             <p>Fei Huang </p>
             <p>Yongbin Li </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 2, 2024</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p><img src="https://browse.arxiv.org/html/2401.01183v1/x1.png" class="img-fluid"></p>
<section id="takeaways-from-the-paper" class="level3">
<h3 class="anchored" data-anchor-id="takeaways-from-the-paper">Takeaways from the Paper</h3>
<ol type="1">
<li><p><strong>Structured Data-to-Text Generation Enhancement:</strong> The paper proposes a unified data-to-text pre-training method that unifies different types of structured data (tables, key-value data, knowledge graphs) into a graph format to enhance data-to-text generation tasks.</p></li>
<li><p><strong>Structure-Enhanced Transformer:</strong> The paper introduces a structure-enhanced pre-training method for data-to-text generation by designing a structure-enhanced Transformer with position and attention matrices to effectively capture the structural information of the input graph.</p></li>
<li><p><strong>Extensive Experimental Validation:</strong> The proposed model, UniD2T, has been extensively validated through experiments on six benchmark datasets, showcasing substantial improvements over strong baselines in various data-to-text generation tasks.</p></li>
</ol>
<hr>
</section>
<section id="abstract" class="level3">
<h3 class="anchored" data-anchor-id="abstract">Abstract</h3>
<p>The paper introduces a unified data-to-text pre-training method that converts diverse structured data into a graph format, enabling a structure-enhanced Transformer to capture the structural information in the input graph. Extensive experiments on six benchmark datasets demonstrate the effectiveness of the proposed model in enhancing data-to-text generation tasks.</p>
<hr>
</section>
<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<ul>
<li><p><strong>Significance of Data-to-Text Generation:</strong> Data-to-text (D2T) generation is crucial for multiple applications such as journalism, medical diagnosis, financial and weather reports, and sports broadcasting.</p></li>
<li><p><strong>Challenges in Previous Pre-Training Methods:</strong> Previous pre-training methods oversimplified structured data into a sequence without capturing its input structures, and designed training objectives tailored for specific data structures, leading to inefficiency in dealing with diverse structured data.</p></li>
<li><p><strong>Objective of the Paper:</strong> The paper proposes a unified data-to-text pre-training method (UniD2T) by unifying different types of structured data into a graph format and introducing a structure-enhanced pre-training method for D2T generation.</p></li>
</ul>
</section>
<section id="methodology" class="level3">
<h3 class="anchored" data-anchor-id="methodology">Methodology</h3>
<ul>
<li><p><strong>Problem Definition:</strong> The Graph-to-Text (G2T) model takes a graph as input and produces text as output, with each input graph converted into an input sequence for the model.</p></li>
<li><p><strong>Model Architecture:</strong> The proposed model is built upon the pre-trained T5 model. The structure-enhanced Transformer introduces position and attention matrices to replace the original position embedding and attention mask, effectively capturing the graph structures.</p></li>
<li><p><strong>Pre-training Objectives:</strong> The pre-training objectives include struct denoising and graph-to-text generation, facilitating the model to capture relationships between neighboring nodes in the input graph.</p></li>
</ul>
</section>
<section id="experimental-results" class="level3">
<h3 class="anchored" data-anchor-id="experimental-results">Experimental Results</h3>
<ul>
<li><p><strong>Task and Datasets:</strong> Experiments are conducted on table-to-text, graph-to-text, and key-value-to-text generation tasks using benchmark datasets such as WebNLG, DART, ToTTo, WikiBio, WikiTableT, and CoSQL.</p></li>
<li><p><strong>Implementation Details:</strong> The UniD2T model is pre-trained on NVIDIA A100 GPUs with specific batch size, gradient clipping, and learning rate details provided.</p></li>
<li><p><strong>Performance Comparison:</strong> Extensive comparisons with strong baselines such as BERT2BERT, LATTICE, CoNT, GraphWriter, and others across various datasets demonstrate the superior performance of UniD2T in terms of evaluation metrics such as BLEU, ROUGE, METEOR, and PARENT.</p></li>
</ul>
</section>
<section id="further-analysis-and-case-studies" class="level3">
<h3 class="anchored" data-anchor-id="further-analysis-and-case-studies">Further Analysis and Case Studies</h3>
<ul>
<li><p><strong>Ablation Study:</strong> Investigating the impact of pre-training with graph structure and linear structure demonstrates the significantly improved performance of UniD2T over T5-Large in various data-to-text tasks.</p></li>
<li><p><strong>Human Evaluation:</strong> Human evaluation shows that UniD2T generates more accurate and contextually appropriate sentences, demonstrating the model’s proficiency in capturing specific facts and logical reasoning.</p></li>
</ul>
</section>
<section id="conclusion-and-limitations" class="level3">
<h3 class="anchored" data-anchor-id="conclusion-and-limitations">Conclusion and Limitations</h3>
<ul>
<li><p><strong>Conclusion:</strong> The paper presents a unified data-to-text pre-training method, UniD2T, which significantly improves performance across various downstream data-to-text generation tasks on benchmark datasets.</p></li>
<li><p><strong>Limitations:</strong> The paper acknowledges limitations such as limited pre-training datasets and a focus on graph structures without further improvement of pre-training objectives.</p></li>
</ul>
<hr>
</section>
<section id="critique-of-the-paper" class="level3">
<h3 class="anchored" data-anchor-id="critique-of-the-paper">Critique of the Paper</h3>
<p>The paper presents a comprehensive and innovative approach to address the challenges of structured data-to-text generation through a unified pre-training method. However, it would benefit from addressing potential limitations in the generalizability of the model to diverse language patterns and domains, as well as scalability to larger datasets.</p>
<p>Furthermore, the paper could benefit from a more in-depth discussion of the limitations experienced when incorporating edge direction in the graph structure, as well as proposing potential solutions or directions for future research.</p>
<p>Overall, the paper provides valuable insights into the enhancement of data-to-text generation tasks through structured data unification and the adoption of a structure-enhanced Transformer model. However, it could benefit from addressing the identified limitations and providing more detailed insights into the practical implications and future directions of the research.</p>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>gpt-3.5-turbo-1106</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-02-02</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="http://arxiv.org/abs/2401.01183v1">http://arxiv.org/abs/2401.01183v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2401.01183v1">https://browse.arxiv.org/html/2401.01183v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>False</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>11140</td>
</tr>
</tbody>
</table>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="wesslen/bayesian-beagle" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/wesslen/bayesian-beagle/edit/main/posts/Unifying_Structured_Data_as_Graph_for_Data_to_Text_Pre_Training/2024-01-02-Unifying_Structured_Data_as_Graph_for_Data_to_Text_Pre_Training.qmd" class="toc-action">Edit this page</a></p></div></div></div></div></footer></body></html>