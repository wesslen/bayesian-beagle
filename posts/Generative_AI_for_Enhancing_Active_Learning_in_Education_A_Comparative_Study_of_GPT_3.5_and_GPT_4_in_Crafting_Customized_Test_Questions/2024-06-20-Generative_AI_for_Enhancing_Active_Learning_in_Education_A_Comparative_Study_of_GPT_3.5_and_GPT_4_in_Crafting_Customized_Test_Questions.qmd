
---
title: "Generative AI for Enhancing Active Learning in Education: A Comparative Study of GPT-3.5 and GPT-4 in Crafting Customized Test Questions"
id: "2406.13903v1"
description: "GPT-4 excels at creating complex math questions, improving GPT-3.5's problem-solving skills, showcasing AI's potential in personalized education."
author: Hamdireza Rouzegar, Masoud Makrehchi
date: "2024-06-20"
image: "../../../bayesian-beagle.png"
categories: ['prompt-engineering', 'education', 'hci']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### Summary:

This study investigates the potential of Large Language Models (LLMs), specifically GPT-3.5 and GPT-4, in generating customized test questions for Grade 9 math, aligning with active learning principles. The research employs an iterative method where these models adjust questions based on difficulty and content, responding to feedback from a simulated 'student' model. A novel aspect of the research involves using GPT-4 as a 'teacher' to create complex questions, with GPT-3.5 as the 'student' responding to these challenges. The findings demonstrate GPT-4's superior ability to generate precise, challenging questions and improvements in GPT-3.5's ability to handle more complex problems after receiving instruction from GPT-4. These results highlight the potential of LLMs to mimic and enhance active learning scenarios, offering a promising path for AI in customized education.

### Major Findings:

1. GPT-4 demonstrates a superior ability to generate precise, challenging questions compared to GPT-3.5.
2. GPT-3.5 shows notable improvements in handling more complex problems after receiving instruction from GPT-4.
3. The use of LLMs in education, particularly in question design, aligns with the principles of active learning by providing tailored content that challenges students at their level of understanding.

### Analysis and Critique:

While the study provides valuable insights into the potential of LLMs in education, there are some limitations and areas for further research. The study focuses on Grade 9 mathematics, and while the use of GPT-4 as a 'teacher' and GPT-3.5 as a 'student' extends the understanding of LLMs' potential in education, the scope of subjects should be broadened to include a diverse array of subjects and academic levels. The evaluation criteria primarily assess the immediate response of LLMs to varying difficulty levels of questions, and future studies should incorporate evaluations on student growth, teacher feedback, and the ability of LLMs to engage with active learning principles more deeply. The study also highlights the need for testing across broader demographics and LLM configurations to enhance the generalizability of findings. Lastly, the long-term retention and application of learned concepts in LLMs remain unexplored and should be investigated in future work.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-23       |
| Abstract | [https://arxiv.org/abs/2406.13903v1](https://arxiv.org/abs/2406.13903v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.13903v1](https://browse.arxiv.org/html/2406.13903v1)       |
| Truncated       | False       |
| Word Count       | 6168       |