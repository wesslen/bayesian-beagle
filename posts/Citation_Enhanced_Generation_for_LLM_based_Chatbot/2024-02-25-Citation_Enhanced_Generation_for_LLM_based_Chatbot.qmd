
---
title: "Citation-Enhanced Generation for LLM-based Chatbot"
id: "2402.16063v1"
description: "LLMs in chatbots may produce hallucinated content; CEG approach with retrieval argumentation addresses this issue."
author: Weitao Li, Junkai Li, Weizhi Ma, Yang Liu
date: "2024-02-25"
image: "https://browse.arxiv.org/html/2402.16063v1/extracted/5429917/figure1.png"
categories: ['robustness', 'hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.16063v1/extracted/5429917/figure1.png)

### **Summary:**
- Large language models (LLMs) integrated into chatbots may produce hallucinated content in responses, limiting their applicability.
- The proposed Citation-Enhanced Generation (CEG) approach addresses this issue in a post-hoc way by incorporating a retrieval module to search for supporting documents relevant to the generated content and employing a natural language inference-based citation generation module.
- Experiments on various hallucination-related datasets show that the CEG framework outperforms state-of-the-art methods in both hallucination detection and response regeneration on three benchmarks.

### **Major Findings:**
1. CEG framework outperforms state-of-the-art methods in hallucination detection and response regeneration on three benchmarks.
2. The retrieval augmentation and citation generation modules play a crucial role in providing better results in the CEG framework.
3. The choice of retrieval model significantly impacts the performance of the retrieval augmentation module.

### **Analysis and Critique:**
- The study is limited by the use of a specific corpus and retriever, limiting the applicability of the framework to general knowledge-based question-answering scenarios.
- The experiments are conducted on existing benchmarks and manual annotations, which may not fully represent real-world scenarios.
- The adopted NLI method in the citation generation module inherently relies on the LLMâ€™s world knowledge, which may limit its effectiveness in certain scenarios.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.16063v1](https://arxiv.org/abs/2402.16063v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.16063v1](https://browse.arxiv.org/html/2402.16063v1)       |
| Truncated       | False       |
| Word Count       | 6648       |