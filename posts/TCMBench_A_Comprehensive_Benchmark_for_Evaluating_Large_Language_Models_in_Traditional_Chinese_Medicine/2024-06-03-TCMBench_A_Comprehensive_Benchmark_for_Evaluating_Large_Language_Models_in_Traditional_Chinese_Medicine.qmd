
---
title: "TCMBench: A Comprehensive Benchmark for Evaluating Large Language Models in Traditional Chinese Medicine"
id: "2406.01126v1"
description: "LLMs struggle in TCM domain, but domain knowledge can improve performance. Traditional metrics for text generation quality may be flawed, suggesting the need for domain-specific metrics like TCMScore."
author: Wenjing Yue, Xiaoling Wang, Wei Zhu, Ming Guan, Huanran Zheng, Pengfei Wang, Changzhi Sun, Xin Ma
date: "2024-06-03"
image: "https://browse.arxiv.org/html/2406.01126v1/x1.png"
categories: ['education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.01126v1/x1.png)

### Summary:

The paper introduces TCM-Bench, a comprehensive benchmark for evaluating the performance of large language models (LLMs) in Traditional Chinese Medicine (TCM). The benchmark consists of the TCM-ED dataset, which includes 5,473 questions sourced from the TCM Licensing Exam (TCMLE), and a metric called TCMScore for evaluating the quality of answers generated by LLMs for TCM-related questions. The main findings from the benchmark are: (1) LLMs have significant room for improvement in TCM, (2) Introducing domain knowledge can enhance LLMs’ performance, but it may affect their basic capabilities, (3) Traditional metrics for text generation quality are susceptible to text length and surface semantic ambiguity, while domain-specific metrics like TCMScore can further supplement and explain their evaluation results.

### Major Findings:

1. LLMs have significant room for improvement in TCM: The unsatisfactory performance of LLMs on this benchmark underscores their significant room for improvement in TCM.
2. Introducing domain knowledge can enhance LLMs’ performance: Introducing domain knowledge can enhance LLMs’ performance in TCM. However, for in-domain models like ZhongJing-TCM, the quality of generated analysis text has decreased, and it is hypothesized that their fine-tuning process affects the basic LLM capabilities.
3. Traditional metrics for text generation quality are susceptible to text length and surface semantic ambiguity: Traditional metrics for text generation quality like Rouge and BertScore are susceptible to text length and surface semantic ambiguity. Domain-specific metrics such as TCMScore can further supplement and explain their evaluation results.

### Analysis and Critique:

* The paper provides a comprehensive benchmark for evaluating LLMs in TCM, which is a significant contribution to the field.
* The TCMScore metric is a valuable addition to the evaluation of LLMs in TCM, as it considers the consistency of TCM semantics and knowledge.
* The paper highlights the limitations of LLMs in TCM and the need for further research in this area.
* The paper does not provide a detailed analysis of the performance of different LLMs on the benchmark, which would

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2406.01126v1](https://arxiv.org/abs/2406.01126v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.01126v1](https://browse.arxiv.org/html/2406.01126v1)       |
| Truncated       | False       |
| Word Count       | 7454       |