
---
title: "Logic-Scaffolding: Personalized Aspect-Instructed Recommendation Explanation Generation using LLMs"
id: "2312.14345v1"
description: "Large Language Models have potential for recommendation explanations, but existing models struggle. Logic-Scaffolding offers a solution."
author: Behnam Rahdari, Hao Ding, Ziwei Fan, Yifei Ma, Zhuotong Chen, Anoop Deoras, Branislav Kveton
date: "2023-12-22"
image: "https://browse.arxiv.org/html/2312.14345v1/x1.png"
categories: ['hci', 'prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2312.14345v1/x1.png)

### Major Takeaways

1. **Large Language Models (LLMs)** possess reasoning ability and natural language text generation, making them suitable for providing explanations in recommender systems, but existing models struggle to produce reliable zero-shot explanations.

2. The limitations of generic LLMs include a lack of true personalization, transparency, and potential for producing inappropriate explanations, emphasizing the need to address these limitations for reliable, personalized, and responsible explainable recommender systems.

3. The proposed **Logic-Scaffolding** framework combines **aspect-based explanation** and **chain-of-thought prompting** to generate explanations through intermediate reasoning steps, aiming to address the limitations of generic LLMs.

### Characteristics of a Good Explanation

- **Personalization**: Enhancing user understanding and satisfaction by tailoring explanations to individual preferences and needs.
- **Factuality**: Emphasizing the need for accurate and reliable information to establish credibility and minimize the risk of misinformation.
- **Robustness**: Ensuring consistent and relevant explanations at the prompt level and across diverse domains.
- **Human Readability**: Requiring explanations to be easily understandable, transparent, and aligned with human cognition.
- **Proper Utterance**: Focusing on delivering clear, concise, and unbiased explanations to effectively communicate reasoning behind recommendations.

### Aspect-Instructed Recommendation Evidence Generation

- **Relevant Item Selection**: Involves selecting influential items related to the recommended item from the user’s history based on a given recommended item.
- **Aspect Extraction**: Leveraging few-shot learning technique to extract essential aspects of items within the catalog, defining an aspect as the fine-grained feature of an item.
- **Chain-of-Thought Reasoning**: Adopting the chain-of-thought prompting technique to guide the generation of explanations, leveraging information from the plot and extracted aspects of the recommended movie, as well as from relevant items in the user’s watching history.

### Demonstration of Results

- **Generating the Explanation**: Using movie data to ensure recognition among individuals, the demonstration showcases an interactive user interface and a comparison between zero-shot explanations and those generated by the Logic-Scaffolding model.
- **Human Evaluation**: A between-subjects study involving participant ratings on criteria such as relevance, human-readability, factuality, and proper utterance shows the Logic-Scaffolding model consistently receiving higher ratings than the zero-shot approach across all criteria. An effect size test further highlights the significant improvements in factuality offered by the Logic-Scaffolding framework.

### Critique

The paper effectively introduces the Logic-Scaffolding framework to address the limitations of generic LLMs in generating explanations for recommender systems. However, it would benefit from a more detailed comparison with existing explanation generation approaches, as well as a discussion on potential challenges or limitations of the proposed framework in real-world applications. Additionally, the study's reliance on a specific dataset and model may limit the generalizability of the findings.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-12       |
| Abstract | [http://arxiv.org/abs/2312.14345v1](http://arxiv.org/abs/2312.14345v1)        |
| HTML     | [https://browse.arxiv.org/html/2312.14345v1](https://browse.arxiv.org/html/2312.14345v1)       |
| Truncated       | False       |
| Word Count       | 3123       |