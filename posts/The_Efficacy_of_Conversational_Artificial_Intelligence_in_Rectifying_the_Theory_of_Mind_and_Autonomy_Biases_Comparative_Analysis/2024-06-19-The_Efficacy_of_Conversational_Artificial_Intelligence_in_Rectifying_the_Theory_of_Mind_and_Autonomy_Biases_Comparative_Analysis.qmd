
---
title: "The Efficacy of Conversational Artificial Intelligence in Rectifying the Theory of Mind and Autonomy Biases: Comparative Analysis"
id: "2406.13813v1"
description: "Non-therapeutic chatbots outperform therapeutic ones in rectifying cognitive biases and recognizing affect."
author: Marcin Rządeczka, Anna Sterna, Julia Stolińska, Paulina Kaczyńska, Marcin Moskalewicz
date: "2024-06-19"
image: "../../img/2406.13813v1/image_1.png"
categories: ['social-sciences', 'hci']
format:
  html:
    code-overflow: wrap
---

![](../../img/2406.13813v1/image_1.png)

**Summary:**

This study evaluates the efficacy of Conversational Artificial Intelligence (CAI) in rectifying cognitive biases and recognizing affect in human-AI interactions, which is crucial for digital mental health interventions. The research employs a structured methodology with clinical-based virtual case scenarios simulating typical user-bot interactions. Performance and affect recognition were assessed across two categories of cognitive biases: theory of mind biases (anthropomorphization of AI, overtrust in AI, attribution to AI) and autonomy biases (illusion of control, fundamental attribution error, just-world hypothesis). A qualitative feedback mechanism was used with an ordinal scale to quantify responses based on accuracy, therapeutic quality, and adherence to CBT principles. Therapeutic bots (Wysa, Youper) and general-use LLMs (GTP 3.5, GTP 4, Gemini Pro) were evaluated through scripted interactions, double-reviewed by cognitive scientists and a clinical psychologist. Statistical analysis showed therapeutic bots were consistently outperformed by non-therapeutic bots in bias rectification and in 4 out of 6 biases in affect recognition. The data suggests that non-therapeutic chatbots are more effective in addressing some cognitive biases.

**Major Findings:**

1. Non-therapeutic chatbots, such as GTP 3.5, GTP 4, and Gemini Pro, demonstrated superior capabilities in cognitive reframing, a crucial technique in CBT, compared to a control group of specialized therapeutic chatbots such as Wysa and Youper.
2. The therapeutic group demonstrated lower average scores compared to the non-therapeutic group, with the differences being particularly notable in Overtrust Bias, Fundamental Attribution Error, and Just-World Hypothesis.
3. GPT-4 achieved consistently high scores, with an average ranging from 4.43 to 4.78 across all biases in bias identification/rectification. In contrast, the general-purpose Gemini Pro showed varied performance, with a highly variable average from 2.33 to 4.03, displaying stronger accuracy with some biases, such as the

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-23       |
| Abstract | [https://arxiv.org/abs/2406.13813v1](https://arxiv.org/abs/2406.13813v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.13813v1](https://browse.arxiv.org/html/2406.13813v1)       |
| Truncated       | False       |
| Word Count       | 17145       |