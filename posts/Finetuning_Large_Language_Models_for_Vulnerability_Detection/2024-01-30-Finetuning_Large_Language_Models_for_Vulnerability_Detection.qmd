
---
title: "Finetuning Large Language Models for Vulnerability Detection"
id: "2401.17010v1"
description: "TL;DR: Finetuned WizardCoder LLM improves vulnerability detection in source code."
author: Alexey Shestov, Anton Cheshkov, Rodion Levichev, Ravil Mussabayev, Pavel Zadorozhny, Evgeny Maslov, Chibirev Vadim, Egor Bulychev
date: "2024-01-30"
image: "../../../bayesian-beagle.png"
categories: ['security', 'architectures', 'robustness', 'programming', 'production']
format:
  html:
    code-overflow: wrap
---

![](None)

### Summary:
This academic article presents the results of finetuning large language models (LLMs) for the task of detecting vulnerabilities in source code. The authors leverage the WizardCoder, a state-of-the-art LLM, and adapt it for vulnerability detection through further finetuning. They also explore optimal training regimes and techniques to improve classification performance on imbalanced vulnerability datasets. The results demonstrate the effectiveness of adapting pretrained LLMs for specialized source code analysis tasks.

### Major Findings:
1. The finetuned WizardCoder model achieves improvement in ROC AUC and F1 measures on balanced and imbalanced vulnerability datasets over CodeBERT-like models.
2. The standard LLM training approach for vulnerability detection, formulating the task as a question answering problem, achieved inferior results compared to the binary classification approach.
3. Batch packing, a strategy to mitigate small sequence lengths, provided over 13x speedup in training time and enabled faster iteration and tuning.

### Analysis and Critique:
The article provides valuable insights into the effectiveness of finetuning large language models for vulnerability detection. However, the study has limitations, such as the small dataset size and the lack of project-level context information. The focal loss with sample weighting showed minor improvements, indicating the need for more advanced methods to address class imbalance. Additionally, the study highlights the importance of context size and loss reduction methods in training large language models for vulnerability detection. Further research is needed to explore advanced techniques for leveraging hard examples without detriment to learning on easier cases, while taking label quality into account.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-02       |
| Abstract | [https://arxiv.org/abs/2401.17010v1](https://arxiv.org/abs/2401.17010v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.17010v1](https://browse.arxiv.org/html/2401.17010v1)       |
| Truncated       | False       |
| Word Count       | 12914       |