
---
title: "Large Language Models are Not Stable Recommender Systems"
description: "LLMs struggle as recommender systems due to position bias. STELLA framework mitigates bias, improving recommendation performance."
author: "['Tianhui Ma', 'Yuan Cheng', 'Hengshu Zhu', 'Hui Xiong']"
date: "2023-12-25"
image: "https://browse.arxiv.org/html/2312.15746v1/x1.png"
categories: ['recommender']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2312.15746v1/x1.png)

### Major Takeaways

- **Large language models (LLMs)** are observed to exhibit **position bias**, affecting the stability and accuracy of their recommendations across various scenarios.
- The proposed **STELLA framework** employs a two-stage pipeline to address position bias in LLMs, using a Bayesian probabilistic framework to adjust biased output and enhance recommendation performance.
- Extensive experiments validate the effectiveness of the STELLA framework in **reducing variance** and **enhancing recommendation performance** of LLMs.

### Introduction
- Recommender systems play a crucial role in various online services, and while traditional models have limitations in capturing user preferences in complex contexts, there is growing interest in exploring the use of LLMs for novel recommender systems.

### Position Bias in Large Language Model
- Using LLMs as recommender systems introduces **position bias**, making recommendation results sensitive to the order of input candidate items.
- The position bias problem in using LLMs for recommendation systems is still in its early stages and requires systematic exploration.

### Calibrating the Position Bias
- The proposed STELLA framework involves a **probing stage** to detect position biases and a **recommendation stage** that employs a Bayesian strategy to adjust biased output of LLMs with an entropy indicator.

### Experiments
- Extensive experiments on various datasets demonstrate that the raw output of LLMs is highly unstable, but STELLA provides stable and consistent performance, significantly outperforming baseline approaches.

### Critique
- The paper focuses on the effectiveness of the proposed framework but lacks a detailed analysis of potential limitations or trade-offs associated with implementing the STELLA framework.
- The language and technical complexity of the paper may pose challenges for readers with limited expertise in natural language processing and Bayesian frameworks.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-02       |
| HTML     |        |
| Truncated       | False       |
| Word Count       | 8647       |