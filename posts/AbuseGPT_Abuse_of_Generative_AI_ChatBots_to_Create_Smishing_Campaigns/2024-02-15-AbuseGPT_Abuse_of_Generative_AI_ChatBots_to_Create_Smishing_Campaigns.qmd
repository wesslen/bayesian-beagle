
---
title: "AbuseGPT: Abuse of Generative AI ChatBots to Create Smishing Campaigns"
id: "2402.09728v1"
description: "AI chatbots can be exploited to create smishing texts, posing a cybersecurity threat."
author: Ashfak Md Shibli, Mir Mehedi A. Pritom, Maanak Gupta
date: "2024-02-15"
image: "../../img/2402.09728v1/image_1.png"
categories: ['security', 'hci', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.09728v1/image_1.png)

### **Summary:**
- The article discusses the growing threat of SMS phishing, also known as "smishing," and the potential exploitation of generative AI chatbot services to create smishing texts and campaigns.
- The authors propose the AbuseGPT method to demonstrate how attackers can exploit existing generative AI-based chatbot services to create smishing texts and campaigns.
- The study highlights the lack of pre-existing work that shows the impacts of generative text-based models on creating SMS phishing, making it the first of its kind to shed light on this emerging cybersecurity threat.

### Major Findings:
1. The authors successfully demonstrated the AbuseGPT method to show how generative AI-based chatbot services can be exploited by attackers to create smishing texts and campaigns.
2. The study revealed strong empirical evidence to show that attackers can exploit ethical standards in existing generative AI-based chatbot services to create newer and craftier smishing campaigns.
3. The authors discussed future research directions and guidelines to protect the abuse of generative AI-based services and safeguard users from smishing attacks.

### Analysis and Critique:
- The study successfully demonstrates the potential exploitation of generative AI chatbot services to create smishing texts and campaigns, highlighting the urgent need to strengthen generative AI's security to prevent these abuse use cases.
- The authors recommend preventive and proactive actions from both AI chatbot owners and mobile operators to safeguard users from smishing attacks.
- The study has limitations, including the time-sensitive nature of prompt injection success and the lack of evaluation of the attack success rate of AI-crafted smishing messages against real humans. These limitations should be addressed in future research.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.09728v1](https://arxiv.org/abs/2402.09728v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.09728v1](https://browse.arxiv.org/html/2402.09728v1)       |
| Truncated       | False       |
| Word Count       | 5873       |