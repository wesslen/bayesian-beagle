
---
title: "Assessing LLMs Suitability for Knowledge Graph Completion"
id: "2405.17249v1"
description: "LLMs can handle Knowledge Graph tasks but may hallucinate answers. Proper prompts improve performance."
author: Vasile Ionut Remus Iga, Gheorghe Cosmin Silaghi
date: "2024-05-27"
image: "https://browse.arxiv.org/html/2405.17249v1/extracted/5621435/ontology.png"
categories: ['robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2405.17249v1/extracted/5621435/ontology.png)

### Summary:

- The paper explores the use of Large Language Models (LLMs) for Knowledge Graph Completion (KGC) tasks in the context of a Task-Oriented Dialogue (TOD) system.
- Two prominent LLMs, Mixtral-8x7B-Instruct-v0.1 and gpt-3.5-turbo-0125, are evaluated using various prompts and techniques, including Direct Prompting (DP), In-Context Learning (ICL), and Chain of Thought (COT), in Zero- and One-Shot contexts.
- The experiments are conducted on a TOD system use case, and the results are evaluated using both strict and flexible metrics measurement manners.
- The paper contributes to the assessment of LLMs for KGC tasks, the introduction of two personalized datasets, and the investigation of the feasibility of integrating LLMs into a domain-specific ontology-enhanced TOD system.

### Major Findings:

1. LLMs can be suitable for KGC tasks if prompts encapsulate sufficient information and relevant examples.
2. The performance of LLMs for KGC tasks can be evaluated using various prompting techniques and levels of complexity.
3. The evaluation of LLMs for KGC tasks can be conducted using both strict and flexible metrics measurement manners.

### Analysis and Critique:

- The paper provides a comprehensive evaluation of LLMs for KGC tasks in the context of a TOD system. However, the evaluation is limited to two LLMs and a specific use case.
- The paper introduces two personalized datasets for evaluating LLMs for KGC tasks, but the generalizability of these datasets to other domains and tasks is not discussed.
- The paper does not discuss the potential limitations and biases of LLMs for KGC tasks, such as the risk of hallucination and the need for large amounts of training data.
- The paper does not provide a comparison of the performance of LLMs for KGC tasks with other approaches, such as rule-based or embedding-based methods.
- The paper does not discuss the potential ethical implications of using LLMs for KGC tasks, such as the risk of perpetuating biases in the training data.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2405.17249v1](https://arxiv.org/abs/2405.17249v1)        |
| HTML     | [https://browse.arxiv.org/html/2405.17249v1](https://browse.arxiv.org/html/2405.17249v1)       |
| Truncated       | False       |
| Word Count       | 5347       |