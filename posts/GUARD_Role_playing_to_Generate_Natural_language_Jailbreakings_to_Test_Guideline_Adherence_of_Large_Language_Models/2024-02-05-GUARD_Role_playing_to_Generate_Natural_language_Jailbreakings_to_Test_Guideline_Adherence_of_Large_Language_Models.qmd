
---
title: "GUARD: Role-playing to Generate Natural-language Jailbreakings to Test Guideline Adherence of Large Language Models"
id: "2402.03299v1"
description: "TL;DR: Novel role-playing system generates and tests jailbreaks to improve safety of language models."
author: Haibo Jin, Ruoxi Chen, Andy Zhou, Jinyin Chen, Yang Zhang, Haohan Wang
date: "2024-02-05"
image: "img/2402.03299v1/image_1.png"
categories: ['robustness', 'production', 'architectures', 'security']
format:
  html:
    code-overflow: wrap
---

![](img/2402.03299v1/image_1.png)

### Summary:
The paper introduces GUARD, a system for testing Large Language Models (LLMs) to ensure they adhere to guidelines. GUARD uses a role-playing approach to generate jailbreak prompts, which are used to test the LLMs' responses to potentially harmful or unethical queries. The system consists of four roles: Translator, Generator, Evaluator, and Optimizer, each responsible for different aspects of generating and evaluating jailbreak prompts. GUARD leverages existing jailbreak prompts and organizes them into a knowledge graph to make them more accessible and easier to retrieve. The system also automatically follows government-issued guidelines to generate jailbreaks and has been empirically validated on various LLMs, demonstrating its effectiveness in inducing unethical or guideline-violating responses.

**Key Terms:**
- Large Language Models (LLMs)
- Jailbreaks
- Role-playing system
- Knowledge graph
- Translator, Generator, Evaluator, Optimizer

### Major Findings:
1. GUARD system effectively generates jailbreak prompts to test LLMs' adherence to guidelines.
2. Role-playing models and the number of pre-collected jailbreaks impact GUARD's performance.
3. Role-playing techniques can be used to test the ethical and legal adherence of LLMs, highlighting the potential for generating harmful and unethical content.

### Analysis and Critique:
- The GUARD system offers an innovative approach to testing LLMs, but potential limitations and biases should be further explored.
- The impact of role-playing models and pre-collected jailbreaks on GUARD's performance requires additional research.
- Ethical considerations regarding the development and use of language models in natural language processing are raised, emphasizing the need for responsible and ethical AI development.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-06       |
| Abstract | [https://arxiv.org/abs/2402.03299v1](https://arxiv.org/abs/2402.03299v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.03299v1](https://browse.arxiv.org/html/2402.03299v1)       |
| Truncated       | True       |
| Word Count       | 20870       |