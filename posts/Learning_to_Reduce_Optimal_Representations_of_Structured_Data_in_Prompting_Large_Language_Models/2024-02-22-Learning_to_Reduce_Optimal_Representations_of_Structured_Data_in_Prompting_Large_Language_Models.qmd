
---
title: "Learning to Reduce: Optimal Representations of Structured Data in Prompting Large Language Models"
id: "2402.14195v1"
description: "TL;DR: Proposed framework uses reinforcement learning to improve large language model's reasoning with structured data."
author: Younghun Lee, Sungchul Kim, Tong Yu, Ryan A. Rossi, Xiang Chen
date: "2024-02-22"
image: "https://browse.arxiv.org/html/2402.14195v1/extracted/5423917/figs/model.png"
categories: ['prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.14195v1/extracted/5423917/figs/model.png)

### **Summary:**
- Large Language Models (LLMs) struggle to integrate structured data into their prompts, as they need to understand long text data or select the most relevant evidence prior to inference.
- The paper proposes a framework, Learning to Reduce, which fine-tunes a language model to generate a reduced version of an input context using On-Policy Reinforcement Learning.
- Experimental results show that the model achieves comparable accuracies in selecting relevant evidence and improves the LLM’s performance on downstream tasks, especially with lengthy contexts.

### **Major Findings:**
1. LLMs struggle to integrate structured data into their prompts due to the need to understand long text data or select the most relevant evidence prior to inference.
2. The Learning to Reduce framework achieves comparable accuracies in selecting relevant evidence and improves the LLM’s performance on downstream tasks, especially with lengthy contexts.
3. The model shows generalizability on different datasets and helps improve the LLM’s performance on structured data QA tasks.

### **Analysis and Critique:**
- LLMs struggle with lengthy context and structured data, leading to performance drops in QA tasks.
- The proposed Learning to Reduce framework shows promise in addressing these challenges, but further experiments on different datasets are needed to fully assess its effectiveness.
- The generalizability of the model is a significant strength, but potential biases in the manual annotation process for the generalizability test should be considered.
- The paper provides a comprehensive approach to addressing the limitations of LLMs in handling structured data, but further research is needed to fully validate the proposed framework.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-26       |
| Abstract | [https://arxiv.org/abs/2402.14195v1](https://arxiv.org/abs/2402.14195v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.14195v1](https://browse.arxiv.org/html/2402.14195v1)       |
| Truncated       | False       |
| Word Count       | 4279       |