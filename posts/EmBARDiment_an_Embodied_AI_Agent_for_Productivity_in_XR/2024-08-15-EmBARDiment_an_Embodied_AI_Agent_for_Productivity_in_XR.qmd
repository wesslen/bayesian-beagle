
---
title: "EmBARDiment: an Embodied AI Agent for Productivity in XR"
id: "2408.08158v1"
description: "New XR chat-bot uses attention framework for intuitive, context-aware interactions, reducing explicit prompts."
author: Riccardo Bovo, Steven Abreu, Karan Ahuja, Eric J Gonzalez, Li-Te Cheng, Mar Gonzalez-Franco
date: "2024-08-15"
image: "https://browse.arxiv.org/html/2408.08158v1/extracted/5793662/pictures/conditions.png"
categories: ['prompt-engineering', 'hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.08158v1/extracted/5793662/pictures/conditions.png)

### Summary:

EmBARDiment is a novel approach that leverages an implicit attention framework to enable embodied LLM agents in XR environments. This approach aims to derive context from the user's actions, eye-gaze, and visual saliency within the XR environment, minimizing the reliance on engineered explicit prompts. The primary contributions of this work include the proposal of a novel attention framework and the conduction of user studies to evaluate its effectiveness in enhancing user interactions and experience.

### Major Findings:

1. EmBARDiment proposes a novel attention framework that leverages gaze-based saliency driven contextual memory for embodied LLM agents in XR, enabling implicit user cues for context-aware assistance.
2. User studies demonstrate the effectiveness of the proposed contextual framework in enhancing user interactions and experience, showcasing its efficacy over baseline explicit text-based input conditions.
3. The use of visual attention to guide contextual memory selection results in fewer question reformulations and enhanced user satisfaction and perceived helpfulness of the system.

### Analysis and Critique:

1. The study focuses on a scenario where the AI agent's attention is aligned with the user's attention, which may not always be the case in real-world applications. Future work should explore scenarios where the AI agent's focus needs to diverge from the user's focus.
2. The contextual memory in the system has a maximum capacity of 250 words, which may not be sufficient for all use cases. The impact of changing the capacity on the LLM's performance and responsiveness needs to be further investigated.
3. The study does not discuss the potential privacy implications of using eye-gaze data for contextual memory selection. Future work should address these concerns and explore ways to ensure user privacy.
4. The study does not provide a detailed comparison of the proposed approach with other existing methods for context-aware assistance in XR environments. A more comprehensive comparison would provide a better understanding of the strengths and limitations of the proposed approach.
5. The study does not discuss the potential scalability and generalizability of the proposed approach. Future work should explore the applicability of the proposed approach to different XR applications and environments.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-20       |
| Abstract | [https://arxiv.org/abs/2408.08158v1](https://arxiv.org/abs/2408.08158v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.08158v1](https://browse.arxiv.org/html/2408.08158v1)       |
| Truncated       | False       |
| Word Count       | 8561       |