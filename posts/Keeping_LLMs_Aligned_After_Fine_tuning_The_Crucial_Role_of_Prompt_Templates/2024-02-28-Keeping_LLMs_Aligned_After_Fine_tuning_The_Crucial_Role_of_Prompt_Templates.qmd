
---
title: "Keeping LLMs Aligned After Fine-tuning: The Crucial Role of Prompt Templates"
id: "2402.18540v1"
description: "Fine-tuning chat models without safety prompts can lead to unsafe behaviors. PTST principle mitigates this."
author: Kaifeng Lyu, Haoyu Zhao, Xinran Gu, Dingli Yu, Anirudh Goyal, Sanjeev Arora
date: "2024-02-28"
image: "../../img/2402.18540v1/image_1.png"
categories: ['hci', 'architectures', 'robustness', 'production', 'security']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.18540v1/image_1.png)

### Summary:
- The article emphasizes the critical role of prompt templates in maintaining safety alignment in Large Language Models (LLMs) after fine-tuning. It introduces the "Pure Tuning, Safe Testing" (PTST) principle and demonstrates its effectiveness through extensive experiments on various chat models and datasets. The section also discusses the importance of using system prompts at test time to ensure safety and helpfulness.

### Major Findings:
1. The "Pure Tuning, Safe Testing" (PTST) principle significantly reduces unsafe behaviors in fine-tuned models.
2. Prompt template switching and testing (PTST) is effective in mitigating safety degradation and reducing the attack success rate on harmful queries.
3. The methodology used to evaluate the helpfulness of models in generating responses provides valuable insights into their reliability and effectiveness.

### Analysis and Critique:
- The article provides valuable insights into the trade-off between model helpfulness and safety, contributing to the broader understanding of LLM fine-tuning practices.
- The experiments on different models and datasets offer significant implications for the deployment of fine-tuned LLMs in public settings, emphasizing the importance of considering prompt templates in preserving safety.
- The discussion on prompt templates for fine-tuning highlights the potential safety degradation when using the same training and test prompt templates, pointing to the significance of this aspect in LLM development and deployment.
- The evaluation methodology used for assessing the helpfulness of models in generating responses provides essential insight into their reliability and effectiveness.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.18540v1](https://arxiv.org/abs/2402.18540v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.18540v1](https://browse.arxiv.org/html/2402.18540v1)       |
| Truncated       | True       |
| Word Count       | 19722       |