
---
title: "Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education"
id: "2401.03676v1"
description: "Usage of Large Language Models for education raises concerns about potential bypassing of AI-generated content detectors. Study shows poor detector performance."
author: ['Wei Hung Pan', 'Ming Jie Chok', 'Jonathan Leong Shan Wong', 'Yung Xin Shin', 'Yeong Shian Poon', 'Zhou Yang', 'Chun Yong Chong', 'David Lo', 'Mei Kuan Lim']
date: "2024-01-08"
image: "https://browse.arxiv.org/html/2401.03676v1/x1.png"
categories: ['programming', 'education', 'prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.03676v1/x1.png)

# Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education

## Key Findings
1. **Existing AIGC Detectors perform poorly** in distinguishing between human-written code and AI-generated code, indicating the inherent weaknesses of current detectors. This underscores the need for further research and development in this domain to enhance their efficacy.
2. Variations in the prompts used to generate AI-generated content significantly impact the **sensitivity and accuracy** of AIGC Detectors, particularly the GLTR model.
3. A need for **comprehensive guidelines and policies** to safeguard the responsible and ethical usage of AI in the educational context is emphasized. Educators are encouraged to consider the **integration of generative AI** into education processes, the automation level, and its ethical focus.

## Abstract
The paper presents an empirical study evaluating the performance of AI-generated content (AIGC) detectors in distinguish AI-generated code from human-written code. A dataset comprising programming problems and corresponding human-written and AI-generated Python solutions was collected from various online sources. 13 variations of prompts were used to instruct an AI model to generate outputs, and the performance of five AIGC detectors was evaluated. Results indicate that existing detectors perform poorly in distinguishing AI-generated from human-written code.

## Introduction
- Large Language Models (LLMs) have advanced to the point of generating human-like code, raising concerns in programming education about potential academic misconduct.
- Accessibility of LLMs has implications for educational assessment and academic dishonesty, thereby compelling educators to utilize AIGC Detectors to ascertain student integrity.

## Background and Motivations
- Software Engineering (SE) and Computer Science (CS) education are significantly impacted by the emergence of generative AI, introducing complexities and challenges in educational assessment and evaluation.
- There is a noticeable impact on academic dishonesty due to growing student reliance on AI-driven solutions.
- Educators find themselves compelled to utilize AIGC Detectors, while the limitations of these detectors in recognizing AI-generated code remain uncertain.

## Empirical Study Design and Methodology
- The study includes the research questions, methodology, process overview, and data collection details.
- Research questions revolve around the accuracy and limitations of existing AIGC Detectors in detecting AI-generated code, evaluating their effectiveness and potential vulnerabilities with different code variants.

## Results
- Existing AIGC Detectors perform poorly in distinguishing between human-written and AI-generated code, indicating the inherent weaknesses of current detectors. GLTR demonstrates the highest sensitivity and significant variability across different code variants.
- Limitations of AIGC Detectors include their struggle in detecting AI-generated code accurately, highlighting the need for ongoing research and development to enhance their reliability.

## Discussion
- Suggestions are provided for SE and CS educators to address the challenges and opportunities presented by the integration of AI into education.
- Key areas for improvement include defining objectives, considering automation levels, focusing on ethical considerations, continuous evaluation, and comprehensive policies.

## Threats to Validity
- The study acknowledges challenges related to prompts used for AIGC generation, verification of human-written code, and the impact of vague queries on AIGC Detector performance.

## Conclusion and Future Work
- Promising opportunities exist for AIGC Detector tools to positively impact education, but challenges need to be addressed. Ethical guidelines and ongoing tool refinement are vital for responsible AI usage in education.

## Data Availability
The replication package, including associated data, has been made publicly available for transparency and reproducibility.

## Critique and Potential Problems
- The study's reliance on one specific type of AI model, ChatGPT, might limit the generalizability of the findings to other AI models.
- The study could benefit from a more diverse range of programming languages and problem types to better assess the performance of AIGC Detectors in a broader context.
- The implications of the findings on educational practice and student learning outcomes could be further elucidated for a more comprehensive understanding of the study's practical significance.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [http://arxiv.org/abs/2401.03676v1](http://arxiv.org/abs/2401.03676v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.03676v1](https://browse.arxiv.org/html/2401.03676v1)       |
| Truncated       | False       |
| Word Count       | 12715       |