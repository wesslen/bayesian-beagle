
---
title: "Opening A Pandora's Box: Things You Should Know in the Era of Custom GPTs"
id: "2401.00905v1"
description: "Custom GPTs pose security threats, with 26 potential attack vectors identified. Urgent need for robust security measures."
author: Guanhong Tao, Siyuan Cheng, Zhuo Zhang, Junmin Zhu, Guangyu Shen, Xiangyu Zhang
date: "2023-12-31"
image: "../../../bayesian-beagle.png"
categories: ['security']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### Summary:

The article delves into the potential security and privacy threats posed by custom Generative Pre-trained Transformers (GPTs). It categorizes attack scenarios into three threat models and utilizes the STRIDE threat modeling framework to identify potential security threats. The authors emphasize the urgent need for robust security and privacy measures in the custom GPT ecosystem, especially with the forthcoming launch of the official GPT store by OpenAI. The article also discusses various security threats to custom GPTs, potential attack vectors, and channels leveraged by malicious GPTs to compromise system integrity and user data.

### Major Findings:
1. The urgent need for robust security and privacy measures in the custom GPT ecosystem, especially with the forthcoming launch of the official GPT store by OpenAI.
2. The identification of potential security threats and attack vectors underscores the severity of these problems and the importance of building practical countermeasures against security threats.
3. The trade-off between user privacy and platform security highlights the need for developing generalizable defense techniques and implementing passive defensive measures to enhance platform security.

### Analysis and Critique:
The article provides valuable insights into the potential security threats associated with custom GPTs and the implications of malicious GPTs and users on benign users. It underscores the importance of understanding and addressing these security threats to ensure the safety and integrity of custom GPT systems. The detailed examples provided offer valuable insights into how these attacks can be executed and their potential impact on users. Additionally, the trade-off between user privacy and platform security emphasizes the need for developing generalizable defense techniques and implementing passive defensive measures to enhance platform security. However, the article could benefit from further exploration of potential biases and limitations in the research, as well as areas that require further investigation.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-26       |
| Abstract | [https://arxiv.org/abs/2401.00905v1](https://arxiv.org/abs/2401.00905v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.00905v1](https://browse.arxiv.org/html/2401.00905v1)       |
| Truncated       | True       |
| Word Count       | 14316       |