
---
title: "Language Models Trained to do Arithmetic Predict Human Risky and Intertemporal Choice"
id: "2405.19313v1"
description: "LLMs, like Arithmetic-GPT, can model human decision-making when pretrained on ecologically valid arithmetic datasets."
author: Jian-Qiao Zhu, Haijiang Yan, Thomas L. Griffiths
date: "2024-05-29"
image: "https://browse.arxiv.org/html/2405.19313v1/x1.png"
categories: ['hci', 'social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2405.19313v1/x1.png)

### Summary:

The paper explores the potential of using Large Language Models (LLMs) as models of human cognition, focusing on decision-making in risky and intertemporal choice scenarios. The authors propose a novel approach to enhance the utility of LLMs as cognitive models by leveraging computationally equivalent tasks and examining the specific task distributions required for LLMs to exhibit human-like behaviors. They apply this approach to decision-making, where the key computationally equivalent task is the arithmetic of expected value calculations. The authors show that an LLM pretrained on an ecologically valid arithmetic dataset, called Arithmetic-GPT, predicts human behavior better than many traditional cognitive models. The results suggest that pretraining LLMs on ecologically valid arithmetic datasets is sufficient to produce a strong correspondence between these models and human decision-making. The paper also emphasizes the importance of carefully investigating LLMs used as cognitive models via ablation studies of the pretraining data.

### Major Findings:

1. LLMs, such as Arithmetic-GPT, can be pretrained on ecologically valid arithmetic datasets to exhibit human-like decision-making behaviors in risky and intertemporal choice scenarios.
2. Pretraining LLMs on ecologically valid arithmetic datasets is sufficient to produce a strong correspondence between these models and human decision-making.
3. The embeddings generated by LLMs, when not finetuned on human risky choices, poorly predict those choices, highlighting the importance of understanding what enables LLMs to exhibit human-like decision-making behavior.

### Analysis and Critique:

The paper presents an innovative approach to using LLMs as cognitive models by focusing on computationally equivalent tasks and ecologically valid arithmetic datasets. The results demonstrate the potential of this approach in predicting human decision-making behaviors. However, several limitations and unanswered questions remain:

1. The paper does not address the issue of LLMs being trained on vastly larger datasets than those available to human learners, which may limit their suitability as cognitive models.
2. The inclusion of value alignment steps, such as Reinforcement Learning from Human Feedback and Direct Preference Optimization, may artificially enhance human-like behaviors in leading LLMs, which is not discussed in the paper.


## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2405.19313v1](https://arxiv.org/abs/2405.19313v1)        |
| HTML     | [https://browse.arxiv.org/html/2405.19313v1](https://browse.arxiv.org/html/2405.19313v1)       |
| Truncated       | False       |
| Word Count       | 6858       |