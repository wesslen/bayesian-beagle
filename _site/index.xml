<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Bayesian beagle</title>
<link>https://bayesian-beagle.netlify.app/index.html</link>
<atom:link href="https://bayesian-beagle.netlify.app/index.xml" rel="self" type="application/rss+xml"/>
<description>Quarto blog of LLM-generated summaries of Arxiv preprints</description>
<generator>quarto-1.3.450</generator>
<lastBuildDate>Thu, 29 Feb 2024 00:00:00 GMT</lastBuildDate>
<item>
  <title>Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match Human Crowd Accuracy</title>
  <dc:creator>Philipp Schoenegger, Indre Tuminauskaite, Peter S. Park, Philip E. Tetlock</dc:creator>
  <link>https://bayesian-beagle.netlify.app/posts/Wisdom_of_the_Silicon_Crowd_LLM_Ensemble_Prediction_Capabilities_Match_Human_Crowd_Accuracy/2024-02-29-Wisdom_of_the_Silicon_Crowd_LLM_Ensemble_Prediction_Capabilities_Match_Human_Crowd_Accuracy.html</link>
  <description><![CDATA[ 



<p><img src="https://bayesian-beagle.netlify.app/posts/Wisdom_of_the_Silicon_Crowd_LLM_Ensemble_Prediction_Capabilities_Match_Human_Crowd_Accuracy/https:/browse.arxiv.org/html/2402.19379v1/x1.png" class="img-fluid"></p>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<ul>
<li>Human forecasting accuracy relies on the ‘wisdom of the crowd’ effect, where predictions are improved by aggregating across a crowd of individual forecasters.</li>
<li>Frontier LLMs underperform compared to a human crowd in a probabilistic forecasting context and fail to clear simple benchmarks.</li>
<li>An LLM ensemble approach, consisting of a crowd of twelve LLMs, has been shown to outperform a simple no-information benchmark and is statistically equivalent to the human crowd in forecasting accuracy.</li>
<li>LLM predictions benefit from exposure to the median human prediction as information, improving accuracy by up to 28%.</li>
<li>The ‘wisdom of the crowd’ effect for LLMs, or the ‘wisdom of the silicon crowd,’ has been replicated, opening up potential applications throughout society.</li>
</ul>
</section>
<section id="major-findings" class="level3">
<h3 class="anchored" data-anchor-id="major-findings">Major Findings</h3>
<ol type="1">
<li>An LLM ensemble approach outperforms a simple no-information</li>
</ol>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>accounts/fireworks/models/mixtral-8x7b-instruct</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-03-13</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="https://arxiv.org/abs/2402.19379v1">https://arxiv.org/abs/2402.19379v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2402.19379v1">https://browse.arxiv.org/html/2402.19379v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>False</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>9200</td>
</tr>
</tbody>
</table>


</section>

 ]]></description>
  <category>hci</category>
  <category>production</category>
  <category>social-sciences</category>
  <guid>https://bayesian-beagle.netlify.app/posts/Wisdom_of_the_Silicon_Crowd_LLM_Ensemble_Prediction_Capabilities_Match_Human_Crowd_Accuracy/2024-02-29-Wisdom_of_the_Silicon_Crowd_LLM_Ensemble_Prediction_Capabilities_Match_Human_Crowd_Accuracy.html</guid>
  <pubDate>Thu, 29 Feb 2024 00:00:00 GMT</pubDate>
  <media:content url="https://browse.arxiv.org/html/2402.19379v1/x1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment</title>
  <dc:creator>Yiju Guo, Ganqu Cui, Lifan Yuan, Ning Ding, Jiexin Wang, Huimin Chen, Bowen Sun, Ruobing Xie, Jie Zhou, Yankai Lin, Zhiyuan Liu, Maosong Sun</dc:creator>
  <link>https://bayesian-beagle.netlify.app/posts/Controllable_Preference_Optimization_Toward_Controllable_Multi_Objective_Alignment/2024-02-29-Controllable_Preference_Optimization_Toward_Controllable_Multi_Objective_Alignment.html</link>
  <description><![CDATA[ 



<p><img src="https://bayesian-beagle.netlify.app/posts/Controllable_Preference_Optimization_Toward_Controllable_Multi_Objective_Alignment/https:/browse.arxiv.org/html/2402.19085v1/x1.png" class="img-fluid"></p>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary:</h3>
<ul>
<li>Controllable Preference Optimization (CPO) is a method for aligning large language models (LLMs) with human preferences and values, specifically targeting helpful, honest, and harmless LLMs.</li>
<li>The “3H” principle can lead to trade-offs between objectives, known as the “alignment tax,” where improving one alignment objective might negatively impact others.</li>
<li>CPO introduces controllable preference supervised fine-tuning (CPSFT) and controllable direct preference optimization (CDPO) to optimize LLMs based on explicit preference conditions, mitigating the alignment tax and achieving Pareto improvements in multi-objective alignment.</li>
</ul>
</section>
<section id="major-findings" class="level3">
<h3 class="anchored" data-anchor-id="major-findings">Major Findings:</h3>
<ol type="1">
<li><strong>Controllable Preference Optimization</strong>: CPO, consisting of CPSFT and CDPO, explicitly specifies preference scores for different objectives, guiding the model to generate responses that meet the requirements, sur</li>
</ol>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>accounts/fireworks/models/mixtral-8x7b-instruct</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-03-13</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="https://arxiv.org/abs/2402.19085v1">https://arxiv.org/abs/2402.19085v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2402.19085v1">https://browse.arxiv.org/html/2402.19085v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>False</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>6069</td>
</tr>
</tbody>
</table>


</section>

 ]]></description>
  <category>social-sciences</category>
  <category>architectures</category>
  <guid>https://bayesian-beagle.netlify.app/posts/Controllable_Preference_Optimization_Toward_Controllable_Multi_Objective_Alignment/2024-02-29-Controllable_Preference_Optimization_Toward_Controllable_Multi_Objective_Alignment.html</guid>
  <pubDate>Thu, 29 Feb 2024 00:00:00 GMT</pubDate>
  <media:content url="https://browse.arxiv.org/html/2402.19085v1/x1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models</title>
  <dc:creator>Hongbang Yuan, Pengfei Cao, Zhuoran Jin, Yubo Chen, Daojian Zeng, Kang Liu, Jun Zhao</dc:creator>
  <link>https://bayesian-beagle.netlify.app/posts/Whispers_that_Shake_Foundations_Analyzing_and_Mitigating_False_Premise_Hallucinations_in_Large_Language_Models/2024-02-29-Whispers_that_Shake_Foundations_Analyzing_and_Mitigating_False_Premise_Hallucinations_in_Large_Language_Models.html</link>
  <description><![CDATA[ 



<p><img src="https://bayesian-beagle.netlify.app/posts/Whispers_that_Shake_Foundations_Analyzing_and_Mitigating_False_Premise_Hallucinations_in_Large_Language_Models/https:/browse.arxiv.org/html/2402.19103v1/x1.png" class="img-fluid"></p>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary"><strong>Summary:</strong></h3>
<ul>
<li>False premise hallucination is a significant issue in Large Language Models (LLMs) where models generate false text based on false premise questions.</li>
<li>A study analyzes this issue and proposes a method called FAITH (False premise Attention head constraIning for miTigating Hallucinations) to mitigate it.</li>
<li>FAITH constrains a small subset of attention heads, called false premise heads, that disturb the knowledge extraction process, leading to false premise hallucinations.</li>
<li>Experiments show that constraining only a few attention heads in the model yields a significant increase in model performance.</li>
</ul>
</section>
<section id="major-findings" class="level3">
<h3 class="anchored" data-anchor-id="major-findings">Major Findings:</h3>
<ol type="1">
<li><strong>False Premise Hallucination:</strong> A specific type of hallucination in LLMs where models generate false text based on false premise questions.</li>
<li><strong>False Premise Heads:</strong> A small subset of attention heads in LLMs that</li>
</ol>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>accounts/fireworks/models/mixtral-8x7b-instruct</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-03-13</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="https://arxiv.org/abs/2402.19103v1">https://arxiv.org/abs/2402.19103v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2402.19103v1">https://browse.arxiv.org/html/2402.19103v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>False</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>5838</td>
</tr>
</tbody>
</table>


</section>

 ]]></description>
  <category>robustness</category>
  <category>prompt-engineering</category>
  <guid>https://bayesian-beagle.netlify.app/posts/Whispers_that_Shake_Foundations_Analyzing_and_Mitigating_False_Premise_Hallucinations_in_Large_Language_Models/2024-02-29-Whispers_that_Shake_Foundations_Analyzing_and_Mitigating_False_Premise_Hallucinations_in_Large_Language_Models.html</guid>
  <pubDate>Thu, 29 Feb 2024 00:00:00 GMT</pubDate>
  <media:content url="https://browse.arxiv.org/html/2402.19103v1/x1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL</title>
  <dc:creator>Yifei Zhou, Andrea Zanette, Jiayi Pan, Sergey Levine, Aviral Kumar</dc:creator>
  <link>https://bayesian-beagle.netlify.app/posts/ArCHer_Training_Language_Model_Agents_via_Hierarchical_Multi_Turn_RL/2024-02-29-ArCHer_Training_Language_Model_Agents_via_Hierarchical_Multi_Turn_RL.html</link>
  <description><![CDATA[ 



<p><img src="https://bayesian-beagle.netlify.app/posts/ArCHer_Training_Language_Model_Agents_via_Hierarchical_Multi_Turn_RL/https:/browse.arxiv.org/html/2402.19446v1/x1.png" class="img-fluid"></p>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary:</h3>
<ul>
<li>Large language models (LLMs) have the potential to address decision-making or “agent” problems that can be expressed in text or natural language.</li>
<li>Current RL methods for LLMs largely focus on single-turn reward maximization, which cannot effectively train LLMs to seek and incorporate information over multiple turns, perform credit assignment, or reason about their past actions.</li>
<li>The paper proposes an algorithmic framework, ArCHer, for developing multi-turn RL algorithms for fine-tuning LLMs, preserving the flexibility of existing single-turn RL methods while accommodating multiple turns, long horizons, and delayed rewards effectively.</li>
<li>ArCHer adopts a hierarchical RL approach, running two RL algorithms in parallel: a high-level off-policy RL algorithm that trains a value function to aggregate reward over utterances, and a low-level RL algorithm that utilizes this high-level</li>
</ul>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>accounts/fireworks/models/mixtral-8x7b-instruct</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-03-13</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="https://arxiv.org/abs/2402.19446v1">https://arxiv.org/abs/2402.19446v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2402.19446v1">https://browse.arxiv.org/html/2402.19446v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>False</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>16897</td>
</tr>
</tbody>
</table>


</section>

 ]]></description>
  <category>hci</category>
  <category>production</category>
  <category>architectures</category>
  <guid>https://bayesian-beagle.netlify.app/posts/ArCHer_Training_Language_Model_Agents_via_Hierarchical_Multi_Turn_RL/2024-02-29-ArCHer_Training_Language_Model_Agents_via_Hierarchical_Multi_Turn_RL.html</guid>
  <pubDate>Thu, 29 Feb 2024 00:00:00 GMT</pubDate>
  <media:content url="https://browse.arxiv.org/html/2402.19446v1/x1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>PRSA: Prompt Reverse Stealing Attacks against Large Language Models</title>
  <dc:creator>Yong Yang, Xuhong Zhang, Yi Jiang, Xi Chen, Haoyu Wang, Shouling Ji, Zonghui Wang</dc:creator>
  <link>https://bayesian-beagle.netlify.app/posts/PRSA_Prompt_Reverse_Stealing_Attacks_against_Large_Language_Models/2024-02-29-PRSA_Prompt_Reverse_Stealing_Attacks_against_Large_Language_Models.html</link>
  <description><![CDATA[ 



<p><img src="https://bayesian-beagle.netlify.app/posts/PRSA_Prompt_Reverse_Stealing_Attacks_against_Large_Language_Models/https:/browse.arxiv.org/html/2402.19200v1/extracted/5440247/figures/prompt_jailbreaking.png" class="img-fluid"></p>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary"><strong>Summary:</strong></h3>
<ul>
<li>Prompt Stealing Attacks against Large Language Models (LLMs) pose a risk to intellectual property rights due to the exposure of input-output pairs.</li>
<li>PRSA, a novel attack framework, is proposed to infer target prompts by analyzing critical features of input-output pairs using a generative model.</li>
<li>PRSA consists of two main phases: prompt mutation and prompt pruning.</li>
<li>Prompt mutation uses a prompt attention algorithm based on differential feedback to optimize the generative model.</li>
<li>Prompt pruning identifies and masks input-dependent words to enhance the surrogate prompt’s generality.</li>
<li>PRSA is effective in stealing prompts across various categories in the marketplace and LLM application platforms.</li>
</ul>
</section>
<section id="major-findings" class="level3">
<h3 class="anchored" data-anchor-id="major-findings">Major Findings:</h3>
<ol type="1">
<li>PRSA poses a severe threat in real-world scenarios, stealing prompts effectively across various categories in the marketplace and</li>
</ol>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>accounts/fireworks/models/mixtral-8x7b-instruct</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-03-13</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="https://arxiv.org/abs/2402.19200v1">https://arxiv.org/abs/2402.19200v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2402.19200v1">https://browse.arxiv.org/html/2402.19200v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>False</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>12660</td>
</tr>
</tbody>
</table>


</section>

 ]]></description>
  <category>production</category>
  <category>robustness</category>
  <category>security</category>
  <category>prompt-engineering</category>
  <category>architectures</category>
  <guid>https://bayesian-beagle.netlify.app/posts/PRSA_Prompt_Reverse_Stealing_Attacks_against_Large_Language_Models/2024-02-29-PRSA_Prompt_Reverse_Stealing_Attacks_against_Large_Language_Models.html</guid>
  <pubDate>Thu, 29 Feb 2024 00:00:00 GMT</pubDate>
  <media:content url="https://browse.arxiv.org/html/2402.19200v1/extracted/5440247/figures/prompt_jailbreaking.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Aligning Language Models for Versatile Text-based Item Retrieval</title>
  <dc:creator>Yuxuan Lei, Jianxun Lian, Jing Yao, Mingqi Wu, Defu Lian, Xing Xie</dc:creator>
  <link>https://bayesian-beagle.netlify.app/posts/Aligning_Language_Models_for_Versatile_Text_based_Item_Retrieval/2024-02-29-Aligning_Language_Models_for_Versatile_Text_based_Item_Retrieval.html</link>
  <description><![CDATA[ 



<p><img src="https://bayesian-beagle.netlify.app/posts/Aligning_Language_Models_for_Versatile_Text_based_Item_Retrieval/https:/browse.arxiv.org/html/2402.18899v1/x1.png" class="img-fluid"></p>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary:</h3>
<ul>
<li>The paper “Aligning Language Models for Versatile Text-based Item Retrieval” discusses the limitations of general-purpose text embeddings for item retrieval tasks and proposes a specialized fine-tuning dataset for improving language models’ performance in this area.</li>
<li>The authors create a dataset with 10 tasks tailored to unlocking models’ representation ability for item retrieval, demonstrating significant improvements in various retrieval tasks after fine-tuning embedding models on the dataset.</li>
<li>The refined model is applied in a conversational setting, enhancing the capabilities of LLM-based Recommender Agents like Chat-Rec.</li>
</ul>
</section>
<section id="major-findings" class="level3">
<h3 class="anchored" data-anchor-id="major-findings">Major Findings:</h3>
<ol type="1">
<li><strong>General-purpose text embedding models fall short in achieving satisfactory zero-shot performance for specific tasks like item retrieval.</strong></li>
<li>**A specialized fine-tuning dataset, encompassing 10 distinct types of tasks,</li>
</ol>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>accounts/fireworks/models/mixtral-8x7b-instruct</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-03-13</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="https://arxiv.org/abs/2402.18899v1">https://arxiv.org/abs/2402.18899v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2402.18899v1">https://browse.arxiv.org/html/2402.18899v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>False</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>3406</td>
</tr>
</tbody>
</table>


</section>

 ]]></description>
  <category>architectures</category>
  <category>recommender</category>
  <guid>https://bayesian-beagle.netlify.app/posts/Aligning_Language_Models_for_Versatile_Text_based_Item_Retrieval/2024-02-29-Aligning_Language_Models_for_Versatile_Text_based_Item_Retrieval.html</guid>
  <pubDate>Thu, 29 Feb 2024 00:00:00 GMT</pubDate>
  <media:content url="https://browse.arxiv.org/html/2402.18899v1/x1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>PeLLE: Encoder-based language models for Brazilian Portuguese based on open data</title>
  <dc:creator>Guilherme Lamartine de Mello, Marcelo Finger, and Felipe Serras, Miguel de Mello Carpi, Marcos Menon Jose, Pedro Henrique Domingues, Paulo Cavalim</dc:creator>
  <link>https://bayesian-beagle.netlify.app/posts/PeLLE_Encoder_based_language_models_for_Brazilian_Portuguese_based_on_open_data/2024-02-29-PeLLE_Encoder_based_language_models_for_Brazilian_Portuguese_based_on_open_data.html</link>
  <description><![CDATA[ 



<p><img src="https://bayesian-beagle.netlify.app/../bayesian-beagle.png" class="img-fluid"></p>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary:</h3>
<ul>
<li>The paper introduces PeLLE, a family of Large Language Models (LLMs) for Brazilian Portuguese based on the RoBERTa architecture and trained on the curated, open Carolina corpus.</li>
<li>PeLLE models are compared to existing multilingual and Portuguese-specific refined pretrained Transformer-based LLM encoders in various downstream tasks.</li>
<li>The results suggest that larger models perform better in some tasks, while smaller-but-curated data in pretraining benefits others.</li>
</ul>
</section>
<section id="major-findings" class="level3">
<h3 class="anchored" data-anchor-id="major-findings">Major Findings:</h3>
<ol type="1">
<li>PeLLE models, when compared to existing multilingual and Portuguese-specific refined pretrained Transformer-based LLM encoders, show competitive performance in various downstream tasks.</li>
<li>Larger models generally perform better in regression tasks when all other factors are equalized.</li>
<li>The pure Portuguese-only pretrained model, pPeLLE</li>
</ol>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>accounts/fireworks/models/mixtral-8x7b-instruct</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-03-13</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="https://arxiv.org/abs/2402.19204v1">https://arxiv.org/abs/2402.19204v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2402.19204v1">https://browse.arxiv.org/html/2402.19204v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>False</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>5656</td>
</tr>
</tbody>
</table>


</section>

 ]]></description>
  <category>production</category>
  <category>architectures</category>
  <guid>https://bayesian-beagle.netlify.app/posts/PeLLE_Encoder_based_language_models_for_Brazilian_Portuguese_based_on_open_data/2024-02-29-PeLLE_Encoder_based_language_models_for_Brazilian_Portuguese_based_on_open_data.html</guid>
  <pubDate>Thu, 29 Feb 2024 00:00:00 GMT</pubDate>
  <media:content url="https://bayesian-beagle.netlify.app/bayesian-beagle.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Analyzing and Reducing Catastrophic Forgetting in Parameter Efficient Tuning</title>
  <dc:creator>Weijieying Ren, Xinlong Li, Lei Wang, Tianxiang Zhao, Wei Qin</dc:creator>
  <link>https://bayesian-beagle.netlify.app/posts/Analyzing_and_Reducing_Catastrophic_Forgetting_in_Parameter_Efficient_Tuning/2024-02-29-Analyzing_and_Reducing_Catastrophic_Forgetting_in_Parameter_Efficient_Tuning.html</link>
  <description><![CDATA[ 



<p><img src="https://bayesian-beagle.netlify.app/posts/Analyzing_and_Reducing_Catastrophic_Forgetting_in_Parameter_Efficient_Tuning/https:/browse.arxiv.org/html/2402.18865v1/x1.png" class="img-fluid"></p>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<ul>
<li>Large Language Models (LLMs) suffer from catastrophic forgetting when continuously fine-tuned on complex domain-specific tasks.</li>
<li>The study explores the geometric connections of different minima in the continual learning scenario of LLMs through the lens of mode connectivity.</li>
<li>The authors propose Interpolation-based LoRA (I-LoRA), a simple yet effective method that strikes a balance between plasticity and stability in LLMs’ continual learning.</li>
<li>I-LoRA consistently outperforms previous state-of-the-art approaches in eight domain-specific CL benchmarks with up to 10% performance gains.</li>
</ul>
</section>
<section id="major-findings" class="level3">
<h3 class="anchored" data-anchor-id="major-findings">Major Findings</h3>
<ol type="1">
<li><strong>Mode Connectivity in LLMs:</strong> The study uncovers the mode connectivity phenomenon in the LLMs continual learning scenario, where different minima can be connected by a low-loss valley.</li>
<li>**I-LoRA</li>
</ol>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>accounts/fireworks/models/mixtral-8x7b-instruct</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-03-13</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="https://arxiv.org/abs/2402.18865v1">https://arxiv.org/abs/2402.18865v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2402.18865v1">https://browse.arxiv.org/html/2402.18865v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>False</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>6698</td>
</tr>
</tbody>
</table>


</section>

 ]]></description>
  <category>programming</category>
  <category>architectures</category>
  <guid>https://bayesian-beagle.netlify.app/posts/Analyzing_and_Reducing_Catastrophic_Forgetting_in_Parameter_Efficient_Tuning/2024-02-29-Analyzing_and_Reducing_Catastrophic_Forgetting_in_Parameter_Efficient_Tuning.html</guid>
  <pubDate>Thu, 29 Feb 2024 00:00:00 GMT</pubDate>
  <media:content url="https://browse.arxiv.org/html/2402.18865v1/x1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of LLMs as Mathematical Problem Solvers</title>
  <dc:creator>Qintong Li, Leyang Cui, Xueliang Zhao, Lingpeng Kong, Wei Bi</dc:creator>
  <link>https://bayesian-beagle.netlify.app/posts/GSM_Plus_A_Comprehensive_Benchmark_for_Evaluating_the_Robustness_of_LLMs_as_Mathematical_Problem_Solvers/2024-02-29-GSM_Plus_A_Comprehensive_Benchmark_for_Evaluating_the_Robustness_of_LLMs_as_Mathematical_Problem_Solvers.html</link>
  <description><![CDATA[ 



<p><img src="https://bayesian-beagle.netlify.app/posts/GSM_Plus_A_Comprehensive_Benchmark_for_Evaluating_the_Robustness_of_LLMs_as_Mathematical_Problem_Solvers/https:/browse.arxiv.org/html/2402.19255v1/x1.png" class="img-fluid"></p>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary:</h3>
<ul>
<li>Large language models (LLMs) have shown impressive performance in mathematical reasoning benchmarks, but there are debates about their understanding and application of mathematical knowledge.</li>
<li>A new benchmark, GSM-Plus, is introduced to evaluate the robustness of LLMs’ math reasoning capability by testing various question variations.</li>
<li>The experiments on 25 LLMs and 4 prompting techniques show that LLMs’ performances are not robust, with mistakes made even on previously solved problems with new statements or altered targets.</li>
<li>An iterative method generating and verifying intermediate thoughts based on reasoning goals and calculation results is explored to achieve more robust performance.</li>
</ul>
</section>
<section id="major-findings" class="level3">
<h3 class="anchored" data-anchor-id="major-findings">Major Findings:</h3>
<ol type="1">
<li><strong>Performance varies among LLMs:</strong> Different LLMs exhibit varying levels of math reasoning abilities, with even top-performing models making mistakes on altered problems.</li>
<li><strong>Non-robust performance:</strong> LLMs struggle with new statements or altered targets, even</li>
</ol>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>accounts/fireworks/models/mixtral-8x7b-instruct</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-03-13</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="https://arxiv.org/abs/2402.19255v1">https://arxiv.org/abs/2402.19255v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2402.19255v1">https://browse.arxiv.org/html/2402.19255v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>False</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>2949</td>
</tr>
</tbody>
</table>


</section>

 ]]></description>
  <category>production</category>
  <category>education</category>
  <category>robustness</category>
  <category>security</category>
  <category>prompt-engineering</category>
  <category>architectures</category>
  <guid>https://bayesian-beagle.netlify.app/posts/GSM_Plus_A_Comprehensive_Benchmark_for_Evaluating_the_Robustness_of_LLMs_as_Mathematical_Problem_Solvers/2024-02-29-GSM_Plus_A_Comprehensive_Benchmark_for_Evaluating_the_Robustness_of_LLMs_as_Mathematical_Problem_Solvers.html</guid>
  <pubDate>Thu, 29 Feb 2024 00:00:00 GMT</pubDate>
  <media:content url="https://browse.arxiv.org/html/2402.19255v1/x1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Crafting Knowledge: Exploring the Creative Mechanisms of Chat-Based Search Engines</title>
  <dc:creator>Lijia Ma, Xingchen Xu, Yong Tan</dc:creator>
  <link>https://bayesian-beagle.netlify.app/posts/Crafting_Knowledge_Exploring_the_Creative_Mechanisms_of_Chat_Based_Search_Engines/2024-02-29-Crafting_Knowledge_Exploring_the_Creative_Mechanisms_of_Chat_Based_Search_Engines.html</link>
  <description><![CDATA[ 



<p><img src="https:/browse.arxiv.org/html/2402.19421v1/extracted/5413983/img/new_bing_example.png" class="img-fluid"></p>
<section id="research-summary" class="level3">
<h3 class="anchored" data-anchor-id="research-summary">Research Summary</h3>
<p><strong>Summary:</strong></p>
<ul>
<li>Chat-based search engines, like Bing Chat and Bard, are a new category of chatbots that combine search engine capabilities with large language models (LLMs) to deliver responses in natural language.</li>
<li>These chat-based search engines demonstrate human-like metacognitive skills, including the acquisition of new knowledge and the demonstration of creativity.</li>
<li>The “cognitive” process through which chatbots discern pertinent information and formulate final responses remains largely inscrutable due to the complexity of the underlying LLMs.</li>
<li>The visibility of a website in chat-based search engines is crucial, as it influences decision-making processes and the distribution of welfare among stakeholders.</li>
<li>The study aims to investigate the criteria for citation in chat-based search engines and compare them with the ranking criteria of conventional search engines.</li>
</ul>
</section>
<section id="major-findings" class="level3">
<h3 class="anchored" data-anchor-id="major-findings">Major Findings</h3>
<ol type="1">
<li>**Chat-based</li>
</ol>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>accounts/fireworks/models/mixtral-8x7b-instruct</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-03-13</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="https://arxiv.org/abs/2402.19421v1">https://arxiv.org/abs/2402.19421v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2402.19421v1">https://browse.arxiv.org/html/2402.19421v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>False</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>11501</td>
</tr>
</tbody>
</table>


</section>

 ]]></description>
  <category>hci</category>
  <category>production</category>
  <category>social-sciences</category>
  <category>prompt-engineering</category>
  <guid>https://bayesian-beagle.netlify.app/posts/Crafting_Knowledge_Exploring_the_Creative_Mechanisms_of_Chat_Based_Search_Engines/2024-02-29-Crafting_Knowledge_Exploring_the_Creative_Mechanisms_of_Chat_Based_Search_Engines.html</guid>
  <pubDate>Thu, 29 Feb 2024 00:00:00 GMT</pubDate>
  <media:content url="https://bayesian-beagle.netlify.app/https:/browse.arxiv.org/html/2402.19421v1/extracted/5413983/img/new_bing_example.png" medium="image" type="image/png"/>
</item>
<item>
  <title>How to Understand Support? An Implicit-enhanced Causal Inference Approach for Weakly-supervised Phrase Grounding</title>
  <dc:creator>Jiamin Luo, Jianing Zhao, Jingjing Wang, Guodong Zhou</dc:creator>
  <link>https://bayesian-beagle.netlify.app/posts/How_to_Understand_Support_An_Implicit_enhanced_Causal_Inference_Approach_for_Weakly_supervised_Phrase_Grounding/2024-02-29-How_to_Understand_Support_An_Implicit_enhanced_Causal_Inference_Approach_for_Weakly_supervised_Phrase_Grounding.html</link>
  <description><![CDATA[ 



<p><img src="https://bayesian-beagle.netlify.app/posts/How_to_Understand_Support_An_Implicit_enhanced_Causal_Inference_Approach_for_Weakly_supervised_Phrase_Grounding/https:/browse.arxiv.org/html/2402.19116v1/x1.png" class="img-fluid"></p>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<ul>
<li>Weakly-supervised Phrase Grounding (WPG) is an emerging task in multimodal learning that involves inferring fine-grained phrase-region matching using coarse-grained sentence-image pairs for training.</li>
<li>Existing studies on WPG often overlook implicit phrase-region matching relations, which are crucial for evaluating a model’s ability to understand deep multimodal semantics.</li>
<li>This paper proposes an Implicit-Enhanced Causal Inference (IECI) approach that uses intervention and counterfactual techniques to address the challenges of modeling implicit relations and highlighting them beyond the explicit.</li>
<li>A high-quality implicit-enhanced dataset is annotated to evaluate IECI, and results show its advantages over state-of-the-art baselines.</li>
</ul>
</section>
<section id="major-findings" class="level3">
<h3 class="anchored" data-anchor-id="major-findings">Major Findings</h3>
<ol type="1">
<li><strong>Implicit Relations in WPG:</strong> The paper highlights the importance</li>
</ol>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>accounts/fireworks/models/mixtral-8x7b-instruct</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-03-13</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="https://arxiv.org/abs/2402.19116v1">https://arxiv.org/abs/2402.19116v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2402.19116v1">https://browse.arxiv.org/html/2402.19116v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>False</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>7721</td>
</tr>
</tbody>
</table>


</section>

 ]]></description>
  <category>architectures</category>
  <guid>https://bayesian-beagle.netlify.app/posts/How_to_Understand_Support_An_Implicit_enhanced_Causal_Inference_Approach_for_Weakly_supervised_Phrase_Grounding/2024-02-29-How_to_Understand_Support_An_Implicit_enhanced_Causal_Inference_Approach_for_Weakly_supervised_Phrase_Grounding.html</guid>
  <pubDate>Thu, 29 Feb 2024 00:00:00 GMT</pubDate>
  <media:content url="https://browse.arxiv.org/html/2402.19116v1/x1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Compositional API Recommendation for Library-Oriented Code Generation</title>
  <dc:creator>Zexiong Ma, Shengnan An, Bing Xie, Zeqi Lin</dc:creator>
  <link>https://bayesian-beagle.netlify.app/posts/Compositional_API_Recommendation_for_Library_Oriented_Code_Generation/2024-02-29-Compositional_API_Recommendation_for_Library_Oriented_Code_Generation.html</link>
  <description><![CDATA[ 



<p><img src="https://bayesian-beagle.netlify.app/posts/Compositional_API_Recommendation_for_Library_Oriented_Code_Generation/https:/browse.arxiv.org/html/2402.19431v1/x1.png" class="img-fluid"></p>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary:</h3>
<ul>
<li>Large language models (LLMs) have achieved exceptional performance in code generation, but the performance remains unsatisfactory in generating library-oriented code, especially for libraries not present in the training data of LLMs.</li>
<li>A new approach, CAPIR (Compositional API Recommendation), is proposed to address the challenge of granularity inconsistency between developmental requirements and API recommendation.</li>
<li>CAPIR employs an LLM-based Decomposer, an embedding-based Retriever, and an LLM-based Reranker to break down coarse-grained tasks, identify relevant APIs, and filter out redundant APIs.</li>
<li>Two new benchmarks, RAPID and LOCG, are presented to facilitate the evaluation of API recommendation methods on coarse-grained requirements.</li>
<li>Experimental results show that CAPIR outperforms existing baselines in API recommendation and library</li>
</ul>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>accounts/fireworks/models/mixtral-8x7b-instruct</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-03-13</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="https://arxiv.org/abs/2402.19431v1">https://arxiv.org/abs/2402.19431v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2402.19431v1">https://browse.arxiv.org/html/2402.19431v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>False</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>11838</td>
</tr>
</tbody>
</table>


</section>

 ]]></description>
  <category>production</category>
  <category>architectures</category>
  <category>programming</category>
  <category>recommender</category>
  <guid>https://bayesian-beagle.netlify.app/posts/Compositional_API_Recommendation_for_Library_Oriented_Code_Generation/2024-02-29-Compositional_API_Recommendation_for_Library_Oriented_Code_Generation.html</guid>
  <pubDate>Thu, 29 Feb 2024 00:00:00 GMT</pubDate>
  <media:content url="https://browse.arxiv.org/html/2402.19431v1/x1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Let LLMs Take on the Latest Challenges! A Chinese Dynamic Question Answering Benchmark</title>
  <dc:creator>Zhikun Xu, Yinghui Li, Ruixue Ding, Xinyu Wang, Boli Chen, Yong Jiang, Xiaodong Deng, Jianxin Ma, Hai-Tao Zheng, Wenlian Lu, Pengjun Xie, Chang Zhou, Fei Huang</dc:creator>
  <link>https://bayesian-beagle.netlify.app/posts/Let_LLMs_Take_on_the_Latest_Challenges!_A_Chinese_Dynamic_Question_Answering_Benchmark/2024-02-29-Let_LLMs_Take_on_the_Latest_Challenges!_A_Chinese_Dynamic_Question_Answering_Benchmark.html</link>
  <description><![CDATA[ 



<p><img src="https://bayesian-beagle.netlify.app/posts/Let_LLMs_Take_on_the_Latest_Challenges!_A_Chinese_Dynamic_Question_Answering_Benchmark/https:/browse.arxiv.org/html/2402.19248v1/x1.png" class="img-fluid"></p>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary:</h3>
<ul>
<li>The paper introduces CDQA, a Chinese Dynamic QA benchmark, to evaluate the ability of Large Language Models (LLMs) in answering questions related to the latest news on the Chinese Internet.</li>
<li>The dataset is collected through a pipeline that combines humans and models, and is classified according to the frequency of answer changes.</li>
<li>Mainstream and advanced Chinese LLMs have been evaluated on CDQA, revealing that the benchmark is challenging and worthy of further study.</li>
</ul>
</section>
<section id="major-findings" class="level3">
<h3 class="anchored" data-anchor-id="major-findings">Major Findings:</h3>
<ol type="1">
<li><strong>CDQA</strong>: The paper presents CDQA, a Chinese Dynamic QA benchmark designed to evaluate the capability of LLMs in answering questions related to the latest news on the Chinese Internet. The dataset is collected through a pipeline that combines humans and models and is classified according to the frequency of answer changes.</li>
<li><strong>Evaluation of LLMs</strong>: Several mainstream and advanced Chinese LLMs have been</li>
</ol>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>accounts/fireworks/models/mixtral-8x7b-instruct</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-03-13</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="https://arxiv.org/abs/2402.19248v1">https://arxiv.org/abs/2402.19248v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2402.19248v1">https://browse.arxiv.org/html/2402.19248v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>False</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>6054</td>
</tr>
</tbody>
</table>


</section>

 ]]></description>
  <category>production</category>
  <category>architectures</category>
  <guid>https://bayesian-beagle.netlify.app/posts/Let_LLMs_Take_on_the_Latest_Challenges!_A_Chinese_Dynamic_Question_Answering_Benchmark/2024-02-29-Let_LLMs_Take_on_the_Latest_Challenges!_A_Chinese_Dynamic_Question_Answering_Benchmark.html</guid>
  <pubDate>Thu, 29 Feb 2024 00:00:00 GMT</pubDate>
  <media:content url="https://browse.arxiv.org/html/2402.19248v1/x1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Teaching Large Language Models an Unseen Language on the Fly</title>
  <dc:creator>Chen Zhang, Xiao Liu, Jiuheng Lin, Yansong Feng</dc:creator>
  <link>https://bayesian-beagle.netlify.app/posts/Teaching_Large_Language_Models_an_Unseen_Language_on_the_Fly/2024-02-29-Teaching_Large_Language_Models_an_Unseen_Language_on_the_Fly.html</link>
  <description><![CDATA[ 



<p><img src="https://bayesian-beagle.netlify.app/posts/Teaching_Large_Language_Models_an_Unseen_Language_on_the_Fly/https:/browse.arxiv.org/html/2402.19167v1/x1.png" class="img-fluid"></p>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary:</h3>
<ul>
<li>Existing large language models (LLMs) struggle to support numerous low-resource languages, particularly the extremely low-resource ones.</li>
<li>A new framework, DiPMT++, is introduced for adapting LLMs to unseen languages by in-context learning.</li>
<li>Using a dictionary and only 5K parallel sentences, DiPMT++ significantly enhances the performance of GPT-4 from 0 to 16 BLEU for Chinese-to-Zhuang translation and achieves 32 BLEU for Zhuang-to-Chinese translation.</li>
<li>The framework has practical utility in aiding humans to translate completely unseen languages, contributing to the preservation of linguistic diversity.</li>
</ul>
</section>
<section id="major-findings" class="level3">
<h3 class="anchored" data-anchor-id="major-findings">Major Findings:</h3>
<ol type="1">
<li>DiPMT++ is a framework that adapts LLMs to unseen languages through in-context learning.</li>
<li>Using a dictionary and 5K parallel sentences</li>
</ol>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>accounts/fireworks/models/mixtral-8x7b-instruct</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-03-13</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="https://arxiv.org/abs/2402.19167v1">https://arxiv.org/abs/2402.19167v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2402.19167v1">https://browse.arxiv.org/html/2402.19167v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>False</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>8344</td>
</tr>
</tbody>
</table>


</section>

 ]]></description>
  <category>architectures</category>
  <category>prompt-engineering</category>
  <guid>https://bayesian-beagle.netlify.app/posts/Teaching_Large_Language_Models_an_Unseen_Language_on_the_Fly/2024-02-29-Teaching_Large_Language_Models_an_Unseen_Language_on_the_Fly.html</guid>
  <pubDate>Thu, 29 Feb 2024 00:00:00 GMT</pubDate>
  <media:content url="https://browse.arxiv.org/html/2402.19167v1/x1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>StarCoder 2 and The Stack v2: The Next Generation</title>
  <dc:creator>Anton Lozhkov, Raymond Li, Loubna Ben Allal, Federico Cassano, Joel Lamy-Poirier, Nouamane Tazi, Ao Tang, Dmytro Pykhtar, Jiawei Liu, Yuxiang Wei, Tianyang Liu, Max Tian, Denis Kocetkov, Arthur Zucker, Younes Belkada, Zijian Wang, Qian Liu, Dmitry Abulkhanov, Indraneil Paul, Zhuang Li, Wen-Ding Li, Megan Risdal, Jia Li, Jian Zhu, Terry Yue Zhuo, Evgenii Zheltonozhskii, Nii Osae Osae Dade, Wenhao Yu, Lucas Krauß, Naman Jain, Yixuan Su, Xuanli He, Manan Dey, Edoardo Abati, Yekun Chai, Niklas Muennighoff, Xiangru Tang, Muhtasham Oblokulov, Christopher Akiki, Marc Marone, Chenghao Mou, Mayank Mishra, Alex Gu, Binyuan Hui, Tri Dao, Armel Zebaze, Olivier Dehaene, Nicolas Patry, Canwen Xu, Julian McAuley, Han Hu, Torsten Scholak, Sebastien Paquet, Jennifer Robinson, Carolyn Jane Anderson, Nicolas Chapados, Mostofa Patwary, Nima Tajbakhsh, Yacine Jernite, Carlos Muñoz Ferrandis, Lingming Zhang, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, Harm de Vries</dc:creator>
  <link>https://bayesian-beagle.netlify.app/posts/StarCoder_2_and_The_Stack_v2_The_Next_Generation/2024-02-29-StarCoder_2_and_The_Stack_v2_The_Next_Generation.html</link>
  <description><![CDATA[ 



<p><img src="https://bayesian-beagle.netlify.app/posts/StarCoder_2_and_The_Stack_v2_The_Next_Generation/https:/browse.arxiv.org/html/2402.19173v1/x1.png" class="img-fluid"></p>
<p><strong>Summary:</strong></p>
<ul>
<li>The BigCode project introduces StarCoder2, a Large Language Model for Code (Code LLM), trained on a dataset 4× larger than its predecessor.</li>
<li>The Stack v2 dataset, built on Software Heritage’s source code archive, includes 619 programming languages and high-quality data sources like GitHub pull requests and Kaggle notebooks.</li>
<li>StarCoder2 models with 3B, 7B, and 15B parameters are trained, with the small model outperforming similar-sized Code LLMs and the large model surpassing competitors of comparable size.</li>
</ul>
<p><strong>Major Findings:</strong></p>
<ol type="1">
<li><strong>Larger, more diverse training dataset</strong>: The use of a larger and more diverse training dataset led to improved performance in StarCoder2 models compared to their predecessors.</li>
<li><strong>StarCoder2-15B performance</strong>: The StarCoder</li>
</ol>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>accounts/fireworks/models/mixtral-8x7b-instruct</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-03-13</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="https://arxiv.org/abs/2402.19173v1">https://arxiv.org/abs/2402.19173v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2402.19173v1">https://browse.arxiv.org/html/2402.19173v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>True</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>31564</td>
</tr>
</tbody>
</table>


</section>

 ]]></description>
  <category>production</category>
  <category>programming</category>
  <category>architectures</category>
  <guid>https://bayesian-beagle.netlify.app/posts/StarCoder_2_and_The_Stack_v2_The_Next_Generation/2024-02-29-StarCoder_2_and_The_Stack_v2_The_Next_Generation.html</guid>
  <pubDate>Thu, 29 Feb 2024 00:00:00 GMT</pubDate>
  <media:content url="https://browse.arxiv.org/html/2402.19173v1/x1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>On the Scaling Laws of Geographical Representation in Language Models</title>
  <dc:creator>Nathan Godey, Éric de la Clergerie, Benoît Sagot</dc:creator>
  <link>https://bayesian-beagle.netlify.app/posts/On_the_Scaling_Laws_of_Geographical_Representation_in_Language_Models/2024-02-29-On_the_Scaling_Laws_of_Geographical_Representation_in_Language_Models.html</link>
  <description><![CDATA[ 



<p><img src="https://bayesian-beagle.netlify.app/posts/On_the_Scaling_Laws_of_Geographical_Representation_in_Language_Models/https:/browse.arxiv.org/html/2402.19406v1/x1.png" class="img-fluid"></p>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary:</h3>
<ul>
<li>Recent studies have shown that language models implicitly embed geographical information in their hidden representations.</li>
<li>This geographical knowledge can be observed even in tiny models and scales consistently as the model size increases.</li>
<li>Larger language models cannot mitigate the geographical bias inherited from the training data.</li>
</ul>
</section>
<section id="major-findings" class="level3">
<h3 class="anchored" data-anchor-id="major-findings">Major Findings:</h3>
<ol type="1">
<li><strong>Geographical knowledge in language models:</strong> Geographical knowledge is observable even in tiny models and scales consistently as the model size increases.</li>
<li><strong>Geographical bias in language models:</strong> Larger language models cannot mitigate the geographical bias inherited from the training data.</li>
<li><strong>Correlation between model performance and training data frequency:</strong> The performance of models in terms of geographical probing is correlated with the frequency of corresponding country names in the training data.</li>
</ol>
</section>
<section id="analysis-and-critique" class="level3">
<h3 class="anchored" data-anchor-id="analysis-and-critique">Analysis and Critique:</h3>
<ul>
<li>The study does not provide a clear definition of what constitutes a “tiny”</li>
</ul>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>accounts/fireworks/models/mixtral-8x7b-instruct</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-03-13</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="https://arxiv.org/abs/2402.19406v1">https://arxiv.org/abs/2402.19406v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2402.19406v1">https://browse.arxiv.org/html/2402.19406v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>False</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>3038</td>
</tr>
</tbody>
</table>


</section>

 ]]></description>
  <category>social-sciences</category>
  <guid>https://bayesian-beagle.netlify.app/posts/On_the_Scaling_Laws_of_Geographical_Representation_in_Language_Models/2024-02-29-On_the_Scaling_Laws_of_Geographical_Representation_in_Language_Models.html</guid>
  <pubDate>Thu, 29 Feb 2024 00:00:00 GMT</pubDate>
  <media:content url="https://browse.arxiv.org/html/2402.19406v1/x1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>RL-GPT: Integrating Reinforcement Learning and Code-as-policy</title>
  <dc:creator>Shaoteng Liu, Haoqi Yuan, Minda Hu, Yanwei Li, Yukang Chen, Shu Liu, Zongqing Lu, Jiaya Jia</dc:creator>
  <link>https://bayesian-beagle.netlify.app/posts/RL_GPT_Integrating_Reinforcement_Learning_and_Code_as_policy/2024-02-29-RL_GPT_Integrating_Reinforcement_Learning_and_Code_as_policy.html</link>
  <description><![CDATA[ 



<p><img src="https://bayesian-beagle.netlify.app/posts/RL_GPT_Integrating_Reinforcement_Learning_and_Code_as_policy/https:/browse.arxiv.org/html/2402.19299v1/x1.png" class="img-fluid"></p>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary"><strong>Summary:</strong></h3>
<ul>
<li>RL-GPT is a hierarchical framework that combines Large Language Models (LLMs) and Reinforcement Learning (RL) to improve the efficiency of LLMs in handling complex, embodied tasks.</li>
<li>The framework consists of a slow agent and a fast agent. The slow agent decomposes tasks into sub-actions and determines which actions can be directly coded, while the fast agent writes code and instantiates RL configurations for low-level execution.</li>
<li>RL-GPT outperforms traditional RL methods and existing GPT agents in Minecraft tasks, such as rapidly obtaining diamonds within a single day using an RTX3090 and achieving state-of-the-art performance across all designated MineDojo tasks.</li>
</ul>
</section>
<section id="major-findings" class="level3">
<h3 class="anchored" data-anchor-id="major-findings">Major Findings:</h3>
<ol type="1">
<li><strong>Hierarchical Framework:</strong> RL-GPT introduces a two-level hierarchical framework that</li>
</ol>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>accounts/fireworks/models/mixtral-8x7b-instruct</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-03-13</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="https://arxiv.org/abs/2402.19299v1">https://arxiv.org/abs/2402.19299v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2402.19299v1">https://browse.arxiv.org/html/2402.19299v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>False</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>6483</td>
</tr>
</tbody>
</table>


</section>

 ]]></description>
  <category>production</category>
  <category>programming</category>
  <category>architectures</category>
  <guid>https://bayesian-beagle.netlify.app/posts/RL_GPT_Integrating_Reinforcement_Learning_and_Code_as_policy/2024-02-29-RL_GPT_Integrating_Reinforcement_Learning_and_Code_as_policy.html</guid>
  <pubDate>Thu, 29 Feb 2024 00:00:00 GMT</pubDate>
  <media:content url="https://browse.arxiv.org/html/2402.19299v1/x1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>On the Decision-Making Abilities in Role-Playing using Large Language Models</title>
  <dc:creator>Chenglei Shen, Guofu Xie, Xiao Zhang, Jun Xu</dc:creator>
  <link>https://bayesian-beagle.netlify.app/posts/On_the_Decision_Making_Abilities_in_Role_Playing_using_Large_Language_Models/2024-02-29-On_the_Decision_Making_Abilities_in_Role_Playing_using_Large_Language_Models.html</link>
  <description><![CDATA[ 



<p><img src="https://bayesian-beagle.netlify.app/posts/On_the_Decision_Making_Abilities_in_Role_Playing_using_Large_Language_Models/https:/browse.arxiv.org/html/2402.18807v1/x1.png" class="img-fluid"></p>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<ul>
<li>Large Language Models (LLMs) are increasingly used for role-playing tasks, with decision-making abilities shaping behavioral patterns.</li>
<li>This paper evaluates the decision-making abilities of LLMs post role-playing, providing metrics and guidance for enhancing their performance.</li>
<li>Four aspects of decision-making abilities are analyzed: adaptability, exploration-exploitation trade-off ability, reasoning ability, and safety.</li>
<li>Results show stable differences in decision-making abilities across distinct roles, indicating that LLMs can effectively impersonate varied roles with genuine sociological characteristics.</li>
</ul>
</section>
<section id="major-findings" class="level3">
<h3 class="anchored" data-anchor-id="major-findings">Major Findings</h3>
<ol type="1">
<li><strong>Adaptability</strong>: LLMs can simulate diverse user groups with varying interests over time, reflecting adaptability in user preferences.</li>
<li><strong>Exploration-Exploitation Trade-off Ability</strong>: LLMs show varying exploration and exploitation tendencies depending on the role, with type E,</li>
</ol>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>accounts/fireworks/models/mixtral-8x7b-instruct</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-03-13</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="https://arxiv.org/abs/2402.18807v1">https://arxiv.org/abs/2402.18807v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2402.18807v1">https://browse.arxiv.org/html/2402.18807v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>False</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>6273</td>
</tr>
</tbody>
</table>


</section>

 ]]></description>
  <category>hci</category>
  <category>prompt-engineering</category>
  <guid>https://bayesian-beagle.netlify.app/posts/On_the_Decision_Making_Abilities_in_Role_Playing_using_Large_Language_Models/2024-02-29-On_the_Decision_Making_Abilities_in_Role_Playing_using_Large_Language_Models.html</guid>
  <pubDate>Thu, 29 Feb 2024 00:00:00 GMT</pubDate>
  <media:content url="https://browse.arxiv.org/html/2402.18807v1/x1.png" medium="image" type="image/png"/>
</item>
<item>
  <title>Exploring the Efficacy of Large Language Models in Summarizing Mental Health Counseling Sessions: A Benchmark Study</title>
  <dc:creator>Prottay Kumar Adhikary, Aseem Srivastava, Shivani Kumar, Salam Michael Singh, Puneet Manuja, Jini K Gopinath, Vijay Krishnan, Swati Kedia, Koushik Sinha Deb, Tanmoy Chakraborty</dc:creator>
  <link>https://bayesian-beagle.netlify.app/posts/Exploring_the_Efficacy_of_Large_Language_Models_in_Summarizing_Mental_Health_Counseling_Sessions_A_Benchmark_Study/2024-02-29-Exploring_the_Efficacy_of_Large_Language_Models_in_Summarizing_Mental_Health_Counseling_Sessions_A_Benchmark_Study.html</link>
  <description><![CDATA[ 



<p><img src="https://bayesian-beagle.netlify.app/img/2402.19052v1/image_1.png" class="img-fluid"></p>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary"><strong>Summary:</strong></h3>
<ul>
<li>The article explores the effectiveness of Large Language Models (LLMs) in summarizing mental health counseling sessions through aspect-based summarization.</li>
<li>A new dataset, MentalCLOUDS, is introduced, which consists of 191 counseling sessions with summaries focused on three distinct counseling components.</li>
<li>Eleven state-of-the-art LLMs are assessed for their ability to address the task of component-guided summarization in counseling.</li>
<li>Findings suggest that task-specific LLMs, such as MentalLlama, Mistral, and MentalBART, perform better in terms of standard quantitative metrics and expert evaluation.</li>
</ul>
</section>
<section id="major-findings" class="level3">
<h3 class="anchored" data-anchor-id="major-findings"><strong>Major Findings:</strong></h3>
<ol type="1">
<li>Task-specific LLMs, MentalLlama, Mistral, and MentalBART, outperform other models in summarizing mental health counseling sessions based on standard quantitative</li>
</ol>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>accounts/fireworks/models/mixtral-8x7b-instruct</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-03-13</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="https://arxiv.org/abs/2402.19052v1">https://arxiv.org/abs/2402.19052v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2402.19052v1">https://browse.arxiv.org/html/2402.19052v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>False</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>16555</td>
</tr>
</tbody>
</table>


</section>

 ]]></description>
  <category>social-sciences</category>
  <category>architectures</category>
  <guid>https://bayesian-beagle.netlify.app/posts/Exploring_the_Efficacy_of_Large_Language_Models_in_Summarizing_Mental_Health_Counseling_Sessions_A_Benchmark_Study/2024-02-29-Exploring_the_Efficacy_of_Large_Language_Models_in_Summarizing_Mental_Health_Counseling_Sessions_A_Benchmark_Study.html</guid>
  <pubDate>Thu, 29 Feb 2024 00:00:00 GMT</pubDate>
  <media:content url="https://bayesian-beagle.netlify.app/img/2402.19052v1/image_1.png" medium="image" type="image/png" height="115" width="144"/>
</item>
<item>
  <title>Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models</title>
  <dc:creator>Chen Qian, Jie Zhang, Wei Yao, Dongrui Liu, Zhenfei Yin, Yu Qiao, Yong Liu, Jing Shao</dc:creator>
  <link>https://bayesian-beagle.netlify.app/posts/Towards_Tracing_Trustworthiness_Dynamics_Revisiting_Pre_training_Period_of_Large_Language_Models/2024-02-29-Towards_Tracing_Trustworthiness_Dynamics_Revisiting_Pre_training_Period_of_Large_Language_Models.html</link>
  <description><![CDATA[ 



<p><img src="https://bayesian-beagle.netlify.app/posts/Towards_Tracing_Trustworthiness_Dynamics_Revisiting_Pre_training_Period_of_Large_Language_Models/https:/browse.arxiv.org/html/2402.19465v1/x1.png" class="img-fluid"></p>
<section id="tracing-trustworthiness-dynamics-in-large-language-models-pre-training" class="level3">
<h3 class="anchored" data-anchor-id="tracing-trustworthiness-dynamics-in-large-language-models-pre-training">Tracing Trustworthiness Dynamics in Large Language Models Pre-training</h3>
<p><strong>Summary:</strong></p>
<ul>
<li>This study explores the trustworthiness of large language models (LLMs) during the pre-training phase, focusing on five dimensions: reliability, privacy, toxicity, fairness, and robustness.</li>
<li>Linear probing is applied to LLMs, revealing that they can distinguish concepts in each trustworthiness dimension early in pre-training.</li>
<li>Steering vectors are extracted from LLMs’ pre-training checkpoints to enhance their trustworthiness.</li>
<li>Mutual information probing during pre-training uncovers a two-phase phenomenon: fitting and compression.</li>
</ul>
<p><strong>Major Findings:</strong></p>
<ol type="1">
<li>LLMs in early pre-training can already distinguish concepts in trustworthiness dimensions through linear probing.</li>
<li>Steering vectors extracted from pre-training checkpoints can enhance the LLM’s trustworthiness</li>
</ol>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<table class="table">
<tbody>
<tr class="odd">
<td>Model</td>
<td>accounts/fireworks/models/mixtral-8x7b-instruct</td>
</tr>
<tr class="even">
<td>Date Generated</td>
<td>2024-03-13</td>
</tr>
<tr class="odd">
<td>Abstract</td>
<td><a href="https://arxiv.org/abs/2402.19465v1">https://arxiv.org/abs/2402.19465v1</a></td>
</tr>
<tr class="even">
<td>HTML</td>
<td><a href="https://browse.arxiv.org/html/2402.19465v1">https://browse.arxiv.org/html/2402.19465v1</a></td>
</tr>
<tr class="odd">
<td>Truncated</td>
<td>False</td>
</tr>
<tr class="even">
<td>Word Count</td>
<td>10553</td>
</tr>
</tbody>
</table>


</section>

 ]]></description>
  <category>production</category>
  <category>architectures</category>
  <guid>https://bayesian-beagle.netlify.app/posts/Towards_Tracing_Trustworthiness_Dynamics_Revisiting_Pre_training_Period_of_Large_Language_Models/2024-02-29-Towards_Tracing_Trustworthiness_Dynamics_Revisiting_Pre_training_Period_of_Large_Language_Models.html</guid>
  <pubDate>Thu, 29 Feb 2024 00:00:00 GMT</pubDate>
  <media:content url="https://browse.arxiv.org/html/2402.19465v1/x1.png" medium="image" type="image/png"/>
</item>
</channel>
</rss>
