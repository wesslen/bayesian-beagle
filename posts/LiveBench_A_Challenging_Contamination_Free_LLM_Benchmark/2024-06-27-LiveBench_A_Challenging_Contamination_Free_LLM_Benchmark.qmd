
---
title: "LiveBench: A Challenging, Contamination-Free LLM Benchmark"
id: "2406.19314v1"
description: "LiveBench: A dynamic, contamination-free LLM benchmark with diverse tasks and automatic scoring."
author: Colin White, Samuel Dooley, Manley Roberts, Arka Pal, Ben Feuer, Siddhartha Jain, Ravid Shwartz-Ziv, Neel Jain, Khalid Saifullah, Siddartha Naidu, Chinmay Hegde, Yann LeCun, Tom Goldstein, Willie Neiswanger, Micah Goldblum
date: "2024-06-27"
image: "../../../bayesian-beagle.png"
categories: ['architectures', 'production', 'social-sciences', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

**Summary:**
The paper introduces LiveBench, a new benchmark for large language models (LLMs) that aims to address the issues of test set contamination and the limitations of LLM judging and human crowdsourcing. LiveBench features frequently-updated questions from recent information sources, automatic scoring based on objective ground-truth values, and a wide variety of challenging tasks across six categories: coding, data, instruction, language, math, and reasoning. The benchmark includes questions based on recent math competitions, arXiv papers, news articles, and datasets, as well as harder, contamination-free versions of tasks from previous benchmarks. The study compares 49 LLMs on LiveBench, with claude-3-5-sonnet-20240620 performing the best across all categories and overall.

**Major Findings:**
1. LiveBench is a new benchmark for LL

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-07       |
| Abstract | [https://arxiv.org/abs/2406.19314v1](https://arxiv.org/abs/2406.19314v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.19314v1](https://browse.arxiv.org/html/2406.19314v1)       |
| Truncated       | True       |
| Word Count       | 27632       |