
---
title: "Round Trip Translation Defence against Large Language Model Jailbreaking Attacks"
id: "2402.13517v1"
description: "New method defends against social-engineered attacks on large language models, mitigating over 70% of attacks."
author: Canaan Yung, Hadi Mohaghegh Dolatabadi, Sarah Erfani, Christopher Leckie
date: "2024-02-21"
image: "https://browse.arxiv.org/html/2402.13517v1/extracted/5421742/Figures/Figure1.png"
categories: ['security', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.13517v1/extracted/5421742/Figures/Figure1.png)

### **Summary:**
- Large language models (LLMs) are vulnerable to social-engineered attacks that are human-interpretable but require a high level of comprehension for LLMs to counteract.
- The Round Trip Translation (RTT) method is proposed as the first algorithm specifically designed to defend against social-engineered attacks on LLMs.
- RTT paraphrases the adversarial prompt and generalizes the idea conveyed, making it easier for LLMs to detect induced harmful behavior. This method is versatile, lightweight, and transferrable to different LLMs.

### **Major Findings:**
1. RTT successfully mitigated over 70% of Prompt Automatic Iterative Refinement (PAIR) attacks, which is currently the most effective defense to the best of our knowledge.
2. The defense reduced the attack success rate of the MathsAttack by almost 40%.
3. RTT outperformed other paraphrasing techniques and the strongest existing defense, SmoothLLM, by a significant margin.

### **Analysis and Critique:**
- The study only tested and verified the effectiveness of one translation algorithm (Google translate) in terms of its defensive performance against adversarial attacks and impact on benign input. Results may vary with different translation algorithms.
- The impact of RTT on benign input was examined using math word problems at the grade school level, and the impact may vary with other types of queries and higher levels of problem inputs on LLMs. Testing RTT with a more diverse range of datasets is necessary to increase its reliability as a pre-processing technique for LLMs.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-26       |
| Abstract | [https://arxiv.org/abs/2402.13517v1](https://arxiv.org/abs/2402.13517v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.13517v1](https://browse.arxiv.org/html/2402.13517v1)       |
| Truncated       | False       |
| Word Count       | 3439       |