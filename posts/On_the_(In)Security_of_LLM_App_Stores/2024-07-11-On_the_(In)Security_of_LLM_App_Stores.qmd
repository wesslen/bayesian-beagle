
---
title: "On the (In)Security of LLM App Stores"
id: "2407.08422v1"
description: "Study reveals security risks in LLM apps, including misleading descriptions, privacy violations, harmful content, and malware potential."
author: Xinyi Hou, Yanjie Zhao, Haoyu Wang
date: "2024-07-11"
image: "https://browse.arxiv.org/html/2407.08422v1/x1.png"
categories: ['security', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2407.08422v1/x1.png)

# Summary

The study examines the security concerns in LLM app stores, focusing on the rapid growth of custom LLM apps and the potential for misuse. The researchers propose a three-layer concern framework to identify security risks, including LLM apps with abusive potential, malicious intent, and exploitable vulnerabilities. Over five months, they collected 786,036 LLM apps from six major app stores: GPT Store, FlowGPT, Poe, Coze, Cici, and Character.AI. The study integrates static and dynamic analysis, the development of a large-scale toxic word dictionary (ToxicDict), and automated monitoring tools to identify and mitigate threats.

The findings reveal that 15,146 apps had misleading descriptions, 1,366 collected sensitive personal information against their privacy policies, and 15,996 generated harmful content such as hate speech, self-harm, extremism, etc. Additionally, 616 apps could be used for malicious activities, including malware generation and phishing. The study highlights the urgent need for robust regulatory frameworks and enhanced enforcement mechanisms.

## Major Findings

1. Misleading descriptions: 15,146 apps had misleading descriptions, potentially deceiving users and hiding malicious intent.
2. Privacy policy violations: 1,366 apps collected sensitive personal information against their privacy policies, posing a risk to user privacy.
3. Harmful content generation: 15,996 apps generated harmful content, including hate speech, self-harm, extremism, etc.
4. Malicious activities: 616 apps could be used for malicious activities, such as malware generation and phishing.

## Analysis and Critique

The study provides a comprehensive analysis of the security concerns in LLM app stores, highlighting the need for stronger regulatory measures and improved security practices. However, the research has some limitations. The dataset used may not be entirely representative of the broader LLM app ecosystem, as it only includes six app stores. Additionally, the accuracy of the findings is influenced by the quality and completeness of the data provided by the app stores. The methodology employed for detecting abusive potential, malicious intent, and exploitable vulnerabilities relies on predefined criteria and automated tools

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-16       |
| Abstract | [https://arxiv.org/abs/2407.08422v1](https://arxiv.org/abs/2407.08422v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.08422v1](https://browse.arxiv.org/html/2407.08422v1)       |
| Truncated       | False       |
| Word Count       | 12874       |