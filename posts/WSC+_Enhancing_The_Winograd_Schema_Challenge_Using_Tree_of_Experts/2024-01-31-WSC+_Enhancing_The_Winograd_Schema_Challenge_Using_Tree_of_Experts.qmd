
---
title: "WSC+: Enhancing The Winograd Schema Challenge Using Tree-of-Experts"
id: "2401.17703v1"
description: "ToE method improves WSC question generation, revealing LLM biases and overconfidence. GPT-4 accuracy 68.7%."
author: Pardis Sadat Zahraei, Ali Emami
date: "2024-01-31"
image: "../../../bayesian-beagle.png"
categories: ['production', 'prompt-engineering', 'architectures']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### Overall Summary:

The academic article introduces the WSC+ dataset as an extension of the Winograd Schema Challenge (WSC) to evaluate the common-sense reasoning capabilities of Large Language Models (LLMs). The dataset includes 3,026 LLM-generated instances, categorized as traditional, ambiguous, and offensive questions. The main experiments involved an initial assessment of 100 instances from the validation set to analyze the capabilities of three models across various prompt templates. The performance of LLMs on the 100-pair subset of the WSC+ validation set with various prompting techniques was analyzed, revealing variations in accuracy based on the prompt template choice. Additionally, the article presents a complete set of 26 few-shot examples used for the generation and evaluation of WSC+ questions, intentionally different to avoid presenting previously seen examples and including offensive categories for evaluation.

### Major Findings:
1. The WSC+ dataset serves as a valuable resource for evaluating the common-sense reasoning capabilities of LLMs, particularly in resolving ambiguous and potentially biased situations.
2. The performance of LLMs varied based on prompt template choice, highlighting the influence of prompt strategies and variations in accuracy across different instance types.
3. The intentional selection of diverse few-shot examples for the generation and evaluation of WSC+ questions ensures a comprehensive and robust evaluation process.

### Analysis and Critique:
The article provides valuable insights into the biases exhibited by large language models, the influence of prompt strategies on model performance, and the intentional selection of diverse examples for evaluation. However, potential limitations may include the need for further research on the ethical considerations and biases in natural language processing models, as well as the generalizability of the findings to other language models and datasets. Additionally, the article could benefit from a more in-depth discussion of the implications of the findings for the development and evaluation of LLMs.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2401.17703v1](https://arxiv.org/abs/2401.17703v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.17703v1](https://browse.arxiv.org/html/2401.17703v1)       |
| Truncated       | True       |
| Word Count       | 17528       |