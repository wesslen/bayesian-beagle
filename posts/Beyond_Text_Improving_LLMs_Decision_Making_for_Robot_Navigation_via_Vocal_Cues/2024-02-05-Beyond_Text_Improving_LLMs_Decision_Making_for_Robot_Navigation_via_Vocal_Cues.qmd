
---
title: "Beyond Text: Improving LLM's Decision Making for Robot Navigation via Vocal Cues"
id: "2402.03494v1"
description: "Text-based LLMs struggle in human-robot interaction, but integrating audio features improves performance by 70.26%."
author: Xingpeng Sun, Haoming Meng, Souradip Chakraborty, Amrit Singh Bedi, Aniket Bera
date: "2024-02-05"
image: "https://browse.arxiv.org/html/2402.03494v1/extracted/5391291/cover.png"
categories: ['hci', 'social-sciences', 'security']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.03494v1/extracted/5391291/cover.png)

### Summary:
- The article discusses the limitations of text-based Large Language Models (LLMs) in human-robot interactions, particularly in scenarios like social navigation where verbal instructions are crucial.
- The authors propose "Beyond Text," an approach that integrates audio transcription and affective vocal features to improve LLM decision-making for robot navigation.
- The article presents the Disfluent Navigational Instruction Audio Dataset (DNIA) and demonstrates the effectiveness of Beyond Text in improving LLM decision-making and robustness against adversarial attacks.

### Major Findings:
1. **Limitations of Text-based LLMs:**
   - LLMs struggle with interpreting audio information, particularly nuanced vocal features in speech tones, leading to challenges in human audio-guided social navigation.
   - Existing LLMs primarily focus on transcription rather than analyzing vocal features, which is crucial for assessing the trustworthiness of human guidance.

2. **Beyond Text Approach:**
   - Integrates audio transcription and affective vocal features to improve LLM decision-making for robot navigation.
   - Achieves a 70.26% winning rate, outperforming existing LLMs by 48.30%, and enhances robustness against token manipulation adversarial attacks.

3. **Disfluent Navigational Instruction Audio Dataset (DNIA):**
   - Contains audio clips capturing vocal and textual uncertainties, providing a foundation for studying human uncertainty in audio-guided navigation tasks.
   - Used for human evaluation to calculate the winning rate of analyzing human navigational guidance uncertainty.

### Analysis and Critique:
- The article effectively addresses the limitations of text-based LLMs in human-robot interactions and proposes a novel approach, "Beyond Text," to improve LLM decision-making.
- The authors provide empirical evidence of the effectiveness of Beyond Text in improving LLM decision-making and robustness against adversarial attacks.
- The article raises open questions and future research directions, emphasizing the need to improve audio augmentation, define uncertainty more granularly, advance LLMs to listen to audio without text, and integrate with real-world social robotics.
- The impact statements highlight the potential societal consequences of the research, emphasizing the development of reliable and robust language-based robotics systems.

Overall, the article effectively communicates the essential information from the academic article, providing a well-structured and coherent summary.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.03494v1](https://arxiv.org/abs/2402.03494v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.03494v1](https://browse.arxiv.org/html/2402.03494v1)       |
| Truncated       | False       |
| Word Count       | 7573       |