
---
title: "Scaling the Authoring of AutoTutors with Large Language Models"
id: "2402.09216v1"
description: "LLMs used in Intelligent Tutoring Systems with guardrails for better learning results."
author: Sankalan Pal Chowdhury, Vil√©m Zouhar, Mrinmaya Sachan
date: "2024-02-14"
image: "https://browse.arxiv.org/html/2402.09216v1/x24.png"
categories: ['social-sciences', 'prompt-engineering', 'education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.09216v1/x24.png)

### Summary:
- The article explores the potential of using Large Language Models (LLMs) to author Intelligent Tutoring Systems, specifically for math word problems.
- The authors propose a hybrid approach where LLMs author the entire script for the tutoring system, while the pedagogical design is still left to learning experts.
- They create a sample end-to-end tutoring system named MWPTutor, which uses LLMs to fill in the state space of a pre-defined finite state transducer.
- Through a human evaluation study on two datasets based on math word problems, they show that MWPTutor achieves a better overall tutoring score than an instructed, but otherwise free-form, GPT-4.

### Major Findings:
1. MWPTutor, using LLMs to author the state space, achieves a better overall tutoring score than GPT-4.
2. The proposed hybrid approach retains the structure and pedagogy of traditional tutoring systems while bringing in additional flexibility of LLM-based approaches.
3. The article highlights the potential of using LLMs to scale up the benefits of expert human tutoring to millions of students.

### Analysis and Critique:
- The article presents a promising approach to using LLMs for authoring Intelligent Tutoring Systems, but it also identifies several limitations and areas for improvement.
- MWPTutor tends to sound monotonous and dry, lacking finer feedback or affective statements, while GPT-4 sounds more natural and includes finer feedback and affective statements.
- Both MWPTutor and GPT-4 have shortcomings, such as overcomplicating questions, making redundant calculations, and leading the student to wrong answers.
- The article acknowledges the need for future work to improve the solution step space, strategy space, and matching requirements for solution alignment.
- The authors outline potential steps for future work, including using smaller specialized LLMs trained for this task and relaxing the format requirement of "one step per line" on the student solution.

Overall, the article presents a promising approach to using LLMs for authoring Intelligent Tutoring Systems, but it also highlights the need for further research and development to address the identified limitations and shortcomings.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-26       |
| Abstract | [https://arxiv.org/abs/2402.09216v1](https://arxiv.org/abs/2402.09216v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.09216v1](https://browse.arxiv.org/html/2402.09216v1)       |
| Truncated       | False       |
| Word Count       | 10536       |