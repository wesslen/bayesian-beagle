
---
title: "Adversarial Search Engine Optimization for Large Language Models"
id: "2406.18382v1"
description: "Attackers can manipulate LLMs to favor their content, degrading overall LLM performance."
author: Fredrik Nestaas, Edoardo Debenedetti, Florian Tram√®r
date: "2024-06-26"
image: "https://browse.arxiv.org/html/2406.18382v1/x1.png"
categories: ['security', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.18382v1/x1.png)

### Summary:

The paper introduces a new class of attacks called Preference Manipulation Attacks, which manipulate an LLM's selections to favor the attacker. These attacks can be used to promote the attacker's products and discredit competitors, thereby increasing user traffic and monetization. The authors demonstrate these attacks on production LLM search engines (Bing and Perplexity) and plugin APIs (for GPT-4 and Claude). As LLMs are increasingly used to rank third-party content, Preference Manipulation Attacks are expected to emerge as a significant threat.

### Major Findings:

1. Preference Manipulation Attacks can be used to manipulate an LLM system's responses, promoting the adversary's third-party products or discrediting others.
2. These attacks are effective on production LLM search engines (Bing and Perplexity) and plugin APIs (for GPT-4 and Claude).
3. Preference Manipulation Attacks can lead to a prisoner's dilemma, where all parties are incentivized to launch attacks, but this collectively degrades the LLM's outputs for everyone.

### Analysis and Critique:

The paper presents a novel and significant threat to LLMs, as Preference Manipulation Attacks can be used to manipulate an LLM's selections to favor the attacker. The authors demonstrate the effectiveness of these attacks on production LLM search engines and plugin APIs, which raises concerns about the security and reliability of LLMs in real-world applications.

However, the paper does not provide a detailed analysis of the potential countermeasures or defenses against Preference Manipulation Attacks. Additionally, the authors do not discuss the ethical implications of these attacks, such as the potential for misuse by malicious actors.

Further research is needed to develop effective countermeasures against Preference Manipulation Attacks and to explore the ethical implications of these attacks in more detail.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-07       |
| Abstract | [https://arxiv.org/abs/2406.18382v1](https://arxiv.org/abs/2406.18382v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.18382v1](https://browse.arxiv.org/html/2406.18382v1)       |
| Truncated       | False       |
| Word Count       | 13149       |