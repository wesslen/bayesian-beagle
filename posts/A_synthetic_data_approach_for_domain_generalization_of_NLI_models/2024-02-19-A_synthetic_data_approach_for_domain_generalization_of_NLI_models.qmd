
---
title: "A synthetic data approach for domain generalization of NLI models"
id: "2402.12368v1"
description: "NLI benchmark task for LLMs, domain generalization, synthetic data improves model generalization."
author: Mohammad Javad Hosseini, Andrey Petrov, Alex Fabrikant, Annie Louis
date: "2024-02-19"
image: "https://browse.arxiv.org/html/2402.12368v1/x1.png"
categories: ['production', 'architectures']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.12368v1/x1.png)

### **Summary:**
- Natural Language Inference (NLI) datasets are crucial for transfer learning and model evaluation.
- The performance of NLI models on out-of-distribution/domain data is not well-understood.
- The article presents a new approach for generating synthetic NLI data in diverse domains and lengths, leading to improved generalization to new downstream test settings.

### **Major Findings:**
1. The synthetic NLI data approach improves the generalization power of NLI models, especially for small models and fast inference.
2. Models trained on the synthetic data outperform those trained on existing datasets, showing significant improvements in performance.
3. The synthetic data also improves in-distribution performance when used to augment the training data for models with sufficient capacity.

### **Analysis and Critique:**
- The article provides valuable insights into the domain generalization of NLI models, but it does not address potential biases in the synthetic data generation process.
- The study focuses on English language datasets, and the generalization of the approach to other languages remains an open question.
- The article does not release the synthetic general NLI data, limiting the reproducibility of the results for other researchers.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.12368v1](https://arxiv.org/abs/2402.12368v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.12368v1](https://browse.arxiv.org/html/2402.12368v1)       |
| Truncated       | False       |
| Word Count       | 6067       |