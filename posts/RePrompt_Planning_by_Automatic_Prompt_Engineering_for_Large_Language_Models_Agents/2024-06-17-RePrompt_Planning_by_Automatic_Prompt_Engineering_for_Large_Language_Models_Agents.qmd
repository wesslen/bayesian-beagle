
---
title: "RePrompt: Planning by Automatic Prompt Engineering for Large Language Models Agents"
id: "2406.11132v1"
description: "RePrompt optimizes LLM prompts for better performance in tasks like code generation and travel planning."
author: Weizhe Chen, Sven Koenig, Bistra Dilkina
date: "2024-06-17"
image: "https://browse.arxiv.org/html/2406.11132v1/extracted/5671344/figures/reprompt_workflow.png"
categories: ['programming']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.11132v1/extracted/5671344/figures/reprompt_workflow.png)

### Summary:

The paper proposes a novel method called RePrompt, which optimizes the step-by-step instructions in the prompt of LLM agents based on chat history obtained from interactions with LLM agents. The method uses "gradient descent" to optimize the prompt, enabling LLMs to learn how to plan in specific domains. The authors demonstrate the effectiveness of their approach in PDDL generation and travel planning tasks, showing improved performance with updated prompts.

### Major Findings:

1. The RePrompt method improves the performance of LLM agents in various reasoning tasks by optimizing the prompt based on chat history.
2. The proposed method has been successfully applied to PDDL generation and travel planning tasks, demonstrating its versatility and effectiveness.
3. Using updated prompts as the initial prompt, RePrompt generally improves the performance for different reasoning tasks.

### Analysis and Critique:

1. The paper presents a promising approach to automatic prompt engineering, which could potentially save time and resources compared to manual prompt engineering.
2. The authors demonstrate the effectiveness of their method in two specific domains, but further research is needed to evaluate its performance in other domains and tasks.
3. The paper does not discuss potential limitations or biases in the proposed method, which could be an important consideration for future work.
4. The authors do not provide a detailed comparison with other automatic prompt engineering methods, making it difficult to assess the relative strengths and weaknesses of RePrompt.
5. The paper does not discuss the potential impact of the proposed method on the generalizability of LLMs, as the optimized prompts may be limited to the training data and harm the LLMs' ability to generalize to new tasks.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-23       |
| Abstract | [https://arxiv.org/abs/2406.11132v1](https://arxiv.org/abs/2406.11132v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.11132v1](https://browse.arxiv.org/html/2406.11132v1)       |
| Truncated       | False       |
| Word Count       | 9868       |