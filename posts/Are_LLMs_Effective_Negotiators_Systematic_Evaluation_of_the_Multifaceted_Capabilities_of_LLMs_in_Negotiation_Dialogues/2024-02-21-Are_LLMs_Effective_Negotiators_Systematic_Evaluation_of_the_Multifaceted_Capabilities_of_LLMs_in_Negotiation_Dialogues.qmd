
---
title: "Are LLMs Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of LLMs in Negotiation Dialogues"
id: "2402.13550v1"
description: "LLMs can enhance negotiation research but struggle with context and strategic responses."
author: Deuksin Kwon, Emily Weiss, Tara Kulshrestha, Kushal Chawla, Gale M. Lucas, Jonathan Gratch
date: "2024-02-21"
image: "https://browse.arxiv.org/html/2402.13550v1/x1.png"
categories: ['social-sciences', 'hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.13550v1/x1.png)

### Summary:
The article evaluates the capabilities of Large Language Models (LLMs) in negotiation dialogues. The study aims to understand how LLMs can advance different aspects of negotiation research, such as designing dialogue systems, providing pedagogical feedback, and scaling up data collection practices. The authors devise a methodology to systematically analyze the multifaceted capabilities of LLMs across diverse dialogue scenarios covering all the time stages of a typical negotiation interaction. The analysis reveals that LLMs, particularly GPT-4, demonstrate remarkable performance in comprehension and partner modeling tasks. However, they struggle with subjective assessments and response generation tasks. The study also explores the impact of popular prompting strategies, such as Chain-of-Thought (CoT) and few-shot prompting, on LLM performance.

### Major Findings:
1. GPT-4 outperforms other LLMs in comprehension tasks in the Start stage, but struggles in the End stage, particularly in subjective assessments.
2. LLMs perform well in annotation tasks, with GPT-3.5 and GPT-4 outperforming the fine-tuned Flan-T5 baseline.
3. LLMs, including GPT-4, demonstrate strong out-of-the-box Theory of Mind (ToM) abilities for partner modeling tasks, but struggle with response generation tasks.

### Analysis and Critique:
- The study provides valuable insights into the multifaceted capabilities of LLMs in negotiation dialogues, highlighting their potential applications in various use cases.
- The authors acknowledge the limitations of the study, such as the use of publicly available negotiation datasets in English, which may not fully represent negotiation scenarios in other languages or cultures.
- The evaluation of LLMs using zero-shot prompts may not fully capture their potential with more sophisticated prompt engineering methods.
- The study raises ethical considerations related to the use of LLMs for social influence interactions, emphasizing the need for transparency, consent procedures, continuous monitoring, and ethical discussions in this area.

Overall, the article provides a comprehensive analysis of LLMs in negotiation dialogues, offering valuable insights and recommendations for future research in this domain.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.13550v1](https://arxiv.org/abs/2402.13550v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.13550v1](https://browse.arxiv.org/html/2402.13550v1)       |
| Truncated       | False       |
| Word Count       | 8401       |