
---
title: "Can Large Language Model Agents Simulate Human Trust Behaviors?"
id: "2402.04559v1"
description: "LLM agents can simulate human trust behaviors with high alignment and implications for various scenarios."
author: Chengxing Xie, Canyu Chen, Feiran Jia, Ziyu Ye, Kai Shu, Adel Bibi, Ziniu Hu, Philip Torr, Bernard Ghanem, Guohao Li
date: "2024-02-07"
image: "../../img/2402.04559v1/image_1.png"
categories: ['social-sciences', 'hci']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.04559v1/image_1.png)

### Summary:
- The paper investigates whether Large Language Model (LLM) agents can simulate human trust behaviors, focusing on Trust Games and Belief-Desire-Intention (BDI) modeling.
- LLM agents generally exhibit trust behaviors and have high behavioral alignment with humans regarding trust behaviors.
- The study explores biases in agent trust and differences in trust towards agents and humans, with implications for human simulation, LLM agent cooperation, and human-agent collaboration.

### Major Findings:
1. LLM agents exhibit high behavioral alignment with humans in trust behaviors.
2. The study's implications extend to applications in human simulation, LLM agent cooperation, and human-agent collaboration.
3. Understanding the intrinsic properties of agent trust can have implications for human simulation, agent cooperation, and human-agent collaboration.

### Analysis and Critique:
- The findings suggest the potential for LLM agents to simulate complex human interactions and societal systems.
- The study's implications extend to applications in human simulation, LLM agent cooperation, and human-agent collaboration, highlighting the significance of the research in understanding and leveraging LLM agents in various scenarios.
- The challenges of manipulating agent trust and the potential impact of reasoning strategies on LLM agents' behaviors are significant, highlighting the need for further research in this area.
- The data on the impact of race on agent trust provides insights into trust dynamics, and the behavior of language model agents in trust games contributes to understanding the role of race in trust dynamics and the behavior of language model agents in trust games.
- The prompts for different trust game scenarios are essential for understanding how large language model agents simulate human trust behaviors in various settings, contributing to a deeper understanding of the dynamics of trust and cooperation in social interactions.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.04559v1](https://arxiv.org/abs/2402.04559v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.04559v1](https://browse.arxiv.org/html/2402.04559v1)       |
| Truncated       | True       |
| Word Count       | 31254       |