
---
title: "mCoT: Multilingual Instruction Tuning for Reasoning Consistency in Language Models"
id: "2406.02301v1"
description: "LLMs struggle with multilingual reasoning, but our 7B mCoT model achieves impressive consistency across languages."
author: Huiyuan Lai, Malvina Nissim
date: "2024-06-04"
image: "https://browse.arxiv.org/html/2406.02301v1/x1.png"
categories: ['architectures', 'prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.02301v1/x1.png)

### Summary:

This paper explores the multilingual reasoning consistency of large language models (LLMs) across multiple languages. The authors compile the first large-scale multilingual math reasoning dataset, mCoT-MATH, covering eleven diverse languages. They then introduce multilingual CoT instruction tuning to boost reasoning capability across languages, thereby improving model consistency. The 7B parameter model mCoT achieves impressive consistency across languages and superior or comparable performance to close- and open-source models even of much larger sizes.

### Major Findings:

1. The authors compile and distribute mCoT-MATH, the first large-scale multilingual math CoT reasoning dataset containing around 6.3 million samples for 11 diverse languages.
2. Based on mCoT-MATH, the authors train and make available a 7B parameter model mCoT for multilingual math reasoning, which achieves impressive consistency across languages, and superior or comparable performance to close- and open-source models.
3. The authors propose to study reasoning consistency of LLMs across different languages, providing insights into the evaluation of this ability of LLMs.

### Analysis and Critique:

1. The paper does not discuss the potential limitations of the proposed method, such as the generalizability of the results to other types of reasoning tasks or the impact of the quality of the machine-translated data on the model's performance.
2. The paper does not provide a detailed comparison of the proposed method with other existing methods for improving the reasoning consistency of LLMs.
3. The paper does not discuss the potential ethical implications of using machine-translated data for training LLMs, such as the risk of perpetuating biases present in the original data.
4. The paper does not provide a detailed analysis of the impact of the size of the LLMs on their reasoning consistency.
5. The paper does not discuss the potential impact of the proposed method on the development of LLMs for low-resource languages.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2406.02301v1](https://arxiv.org/abs/2406.02301v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.02301v1](https://browse.arxiv.org/html/2406.02301v1)       |
| Truncated       | False       |
| Word Count       | 5955       |