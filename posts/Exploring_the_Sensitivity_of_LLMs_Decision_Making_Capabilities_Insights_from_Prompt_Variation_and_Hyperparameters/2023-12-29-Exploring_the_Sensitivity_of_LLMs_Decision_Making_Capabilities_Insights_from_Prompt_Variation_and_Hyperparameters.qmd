
---
title: "Exploring the Sensitivity of LLMs' Decision-Making Capabilities: Insights from Prompt Variation and Hyperparameters"
id: "2312.17476v1"
description: "Study examines language models' decision making with varying prompts and hyperparameters showing human-like exploration-exploitation tradeoff."
author: Manikanta Loya, Divya Anand Sinha, Richard Futrell
date: "2023-12-29"
image: "https://browse.arxiv.org/html/2312.17476v1/x1.png"
categories: ['hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2312.17476v1/x1.png)

### Major Takeaways
1. **Large Language Models (LLMs)'** decision-making capabilities are sensitive to variations in input prompts and hyperparameters, with performance fluctuating based on these factors.
2. **Human-like exploration-exploitation tradeoff** in decision-making tasks can be observed in LLMs with basic adjustments to prompts, contrary to previous findings.
3. LLMs' decision-making abilities are more influenced by the choice of prompt rather than temperature settings, emphasizing the importance of varying prompts to elicit desired behavior.

### Introduction
The study explores the decision-making abilities of LLMs, highlighting the need to understand their cognitive abilities and characteristics, especially in economic decision-making contexts. The authors emphasize the importance of considering variability as a function of prompt and hyperparameters in psychological LLM research.

### Background and Related Work
- Researchers have adopted methods from cognitive psychology and behavioral economics to evaluate LLMs, aiming to characterize their behavior akin to human evaluations.
- Prior research has shown that subtle modifications in input prompts can lead to varied outcomes in reasoning tasks, indicating the sensitivity of LLMs to prompt variations.

### Horizon Task Experiments
- The Horizon Task involves a trade-off between exploration and exploitation, which is fundamental in decision-making.
- The authors follow the experimental design of Binz and Schulz (2023) and evaluate LLMs' performance using the Horizon task, observing the impact of prompt variations and hyperparameters on LLM behavior.

### Varying Temperature
- Different temperature settings (0.0, 0.5, 1.0) impact LLM behavior, with higher temperatures resulting in suboptimal decision-making but demonstrating a more pronounced learning effect.

### Varying Prompt
- Variations in input prompt, particularly the Chain of Thought (CoT) prompting technique, influence LLM behavior, with modified prompts yielding human-like negative slopes, indicating an exploration-exploitation trade-off.

### CoT Prompting with Hints
- Adding hints within the input prompt to guide decision-making has shown that superhuman performance can be achieved, emphasizing the potential controllability of language model behavior in decision-making tasks.

### Conclusion
The study reveals the sensitivity of LLM psychological behavior to prompt and hyperparameters, cautioning that model behavior can diverge under different settings.

### Limitations
The study is limited in scope, focusing on one task from a previous study and presenting only a few variations of temperature and prompt. It also acknowledges the limitation of experimenting with only some available models as of the time of the study.

### Critique
The study provides valuable insights into the sensitivity of LLMs' decision-making capabilities but has limitations in its scope and experimentation. Future research should aim to address these limitations and consider potential biases and limitations of LLMs if deployed as economic decision-makers.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-27       |
| Abstract | [http://arxiv.org/abs/2312.17476v1](http://arxiv.org/abs/2312.17476v1)        |
| HTML     | [https://browse.arxiv.org/html/2312.17476v1](https://browse.arxiv.org/html/2312.17476v1)       |
| Truncated       | False       |
| Word Count       | 4103       |