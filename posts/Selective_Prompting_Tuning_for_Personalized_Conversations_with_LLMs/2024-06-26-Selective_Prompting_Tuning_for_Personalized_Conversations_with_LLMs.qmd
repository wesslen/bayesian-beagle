
---
title: "Selective Prompting Tuning for Personalized Conversations with LLMs"
id: "2406.18187v1"
description: "Selective Prompt Tuning improves LLMs' personalized dialogue, enhancing response diversity by up to 90%."
author: Qiushi Huang, Xubo Liu, Tom Ko, Bo Wu, Wenwu Wang, Yu Zhang, Lilian Tang
date: "2024-06-26"
image: "https://browse.arxiv.org/html/2406.18187v1/x1.png"
categories: ['recommender', 'hci', 'prompt-engineering', 'social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2406.18187v1/x1.png)

### Summary:

The paper introduces Selective Prompt Tuning (SPT), a novel method for personalized dialogue generation using large language models (LLMs). SPT aims to address the challenges of diverse conversational settings and overfitting to small-scale datasets. The method utilizes a group of soft prompts and a trainable dense retriever to adaptively select suitable prompts based on input contexts. SPT also incorporates context-prompt contrastive learning and prompt fusion learning to enhance the diversity of personalized conversations. Experiments on the CONVAI2 dataset demonstrate that SPT significantly improves response diversity and other critical performance indicators.

### Major Findings:

1. SPT enhances response diversity by up to 90% compared to traditional methods, such as textual prompting and direct fine-tuning.
2. The context-prompt contrastive mechanism and prompt fusion learning within the SPT framework foster prompt diversity and adaptability.
3. SPT consistently outperforms baselines across models with various sizes, offering profound insights into different dialogue scenarios.

### Analysis and Critique:

The paper presents a promising approach to personalized dialogue generation using LLMs. The proposed SPT method effectively addresses the challenges of diverse conversational settings and overfitting to small-scale datasets. The use of a trainable dense retriever and the integration of context-prompt contrastive learning and prompt fusion learning contribute to the method's success.

However, the paper does not discuss potential limitations or shortcomings of the SPT method. For instance, the method's performance on larger datasets or in real-world applications is not evaluated. Additionally, the paper does not explore the potential impact of the method on the quality of generated responses, such as their coherence, relevance, or appropriateness.

Further research is needed to evaluate the SPT method's generalizability, robustness, and potential biases. It would also be beneficial to compare the SPT method with other state-of-the-art approaches to personalized dialogue generation, such as reinforcement learning or transfer learning methods.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-07       |
| Abstract | [https://arxiv.org/abs/2406.18187v1](https://arxiv.org/abs/2406.18187v1)        |
| HTML     | [https://browse.arxiv.org/html/2406.18187v1](https://browse.arxiv.org/html/2406.18187v1)       |
| Truncated       | False       |
| Word Count       | 8201       |