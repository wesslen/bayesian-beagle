
---
title: "Estimating Contribution Quality in Online Deliberations Using a Large Language Model"
id: "2408.11936v1"
description: "LLM outperforms individual human annotators in rating deliberation contributions; nudges after inactivity boost participation without compromising quality."
author: Lodewijk Gelauff, Mohak Goyal, Bhargav Dindukurthi, Ashish Goel, Alice Siu
date: "2024-08-21"
image: "https://browse.arxiv.org/html/2408.11936v1/x1.png"
categories: ['hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2408.11936v1/x1.png)

# Summary:

This paper explores the use of a large language model (LLM) to estimate the quality of contributions in online deliberations, a task traditionally performed by human annotators. The study uses data from various deliberation events, including one conducted in collaboration with Meta in 32 countries and another with 38 post-secondary institutions in the US. The LLM rates contributions based on justification, novelty, expansion of the conversation, and potential for further expansion, with scores ranging from 1 to 5. The model outperforms individual human annotators and is competitive with pairs and groups of three human annotators. The paper also demonstrates the usefulness of automated quality ratings by assessing the effect of nudges on the quality of deliberation, showing that nudging leads to more ideas being generated in the conversation without losing overall quality.

# Major Findings:

1. The LLM outperforms individual human annotators and is competitive with pairs and groups of three human annotators in rating the quality of contributions in online deliberations.
2. The use of automated quality ratings can help assess the impact of interventions, such as nudges, on the quality of deliberation.
3. Nudging after prolonged inactivity is highly effective, increasing the likelihood of the individual requesting to speak in the next 30 seconds by 65%.
4. The quality ratings for statements prompted by nudging are similar to those made without nudging, signifying that nudging leads to more ideas being generated in the conversation without losing overall quality.

# Analysis and Critique:

While the use of LLMs for estimating the quality of contributions in online deliberations shows promise, there are some potential limitations and areas for improvement. For instance, the model's performance could be further enhanced through fine-tuning and mean correction. Additionally, the relationship between discussion quality and opinion change, measured through pre- and post-event surveys, should be explored to understand how discourse quality influences participant perspectives. Furthermore, the unpredictability of LLMs and the potential for biases in their outputs necessitate ongoing human quality control. Lastly, integrating automated assessments with other evaluation metrics could provide a more comprehensive understanding of deliberative quality.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-27       |
| Abstract | [https://arxiv.org/abs/2408.11936v1](https://arxiv.org/abs/2408.11936v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.11936v1](https://browse.arxiv.org/html/2408.11936v1)       |
| Truncated       | False       |
| Word Count       | 8672       |