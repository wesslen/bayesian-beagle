
---
title: "SuperCLUE-Math6: Graded Multi-Step Math Reasoning Benchmark for LLMs in Chinese"
id: "2401.11819v1"
description: "SuperCLUE-Math6 is a new Chinese math dataset to evaluate reasoning abilities of language models."
author: Liang Xu, Hang Xue, Lei Zhu, Kangkang Zhao
date: "2024-01-22"
image: "../../../bayesian-beagle.png"
categories: ['production']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### **Summary:**
The article introduces SuperCLUE-Math6 (SC-Math6), a benchmark dataset designed to evaluate the mathematical reasoning abilities of Chinese language models. The dataset consists of over 2000 mathematical word problems requiring multi-step reasoning and providing natural language solutions. The authors propose an innovative scheme to quantify the reasoning capability of large models based on performance over problems with different reasoning steps. Experiments on 12 representative Chinese models demonstrate a clear stratification of reasoning levels, with top models showing superior performance. The article highlights the threefold contributions of SC-Math6: the construction of the benchmark dataset, the proposal of a novel scoring scheme, and comprehensive benchmarking and analysis of leading Chinese models.

### Major Findings:
1. SC-Math6 fills the gap in Chinese mathematical reasoning benchmarks and provides a comprehensive testbed to advance the intelligence of Chinese language models.
2. The diverse problems and reasoning patterns in SC-Math6 complement existing benchmarks and inspire new model designs and training strategies targeting enhanced mathematical intelligence.
3. Top models like GPT-4 exhibit remarkably high performance on multi-step problems, demonstrating advanced reasoning skills, while lower-level models show large performance gaps.

### Analysis and Critique:
The article provides valuable insights into the mathematical reasoning capabilities of Chinese language models and introduces a comprehensive benchmark dataset. However, the article lacks a detailed discussion of potential biases in the dataset construction and the limitations of the proposed scoring scheme. Additionally, the article could benefit from a more in-depth analysis of the implications of the findings for the development of Chinese language models. Further research is needed to address these limitations and to validate the effectiveness of SC-Math6 in improving the reasoning abilities of Chinese language models. 

Overall, the article makes a significant contribution to the evaluation and benchmarking of mathematical reasoning capabilities of major Chinese language models, but further research and validation are necessary to fully establish the effectiveness of SC-Math6.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2401.11819v1](https://arxiv.org/abs/2401.11819v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.11819v1](https://browse.arxiv.org/html/2401.11819v1)       |
| Truncated       | False       |
| Word Count       | 8356       |