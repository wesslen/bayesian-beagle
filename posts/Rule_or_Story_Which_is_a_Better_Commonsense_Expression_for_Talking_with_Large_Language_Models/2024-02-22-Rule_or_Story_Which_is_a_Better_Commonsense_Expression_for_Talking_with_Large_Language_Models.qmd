
---
title: "Rule or Story, Which is a Better Commonsense Expression for Talking with Large Language Models?"
id: "2402.14355v1"
description: "Stories are better than rules for retrieving commonsense from large language models."
author: Ning Bian, Xianpei Han, Hongyu Lin, Yaojie Lu, Ben He, Le Sun
date: "2024-02-22"
image: "https://browse.arxiv.org/html/2402.14355v1/x1.png"
categories: ['hci', 'social-sciences']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.14355v1/x1.png)

### **Summary:**
- This paper investigates the effectiveness of stories and rules as commonsense expressions for large language models (LLMs).
- Experimental results show that stories outperform rules in retrieving and leveraging commonsense from LLMs.
- Stories are more effective for answering questions regarding daily events, while rules are more effective for scientific questions.

### **Major Findings:**
1. Stories result in more confident commonsense generation than rules for LLMs.
2. LLMs generate more accurate stories than rules in terms of commonsense.
3. LLMs are more confident in commonsense reasoning based on stories than on rules.

### **Analysis and Critique:**
- The study provides valuable insights into the effectiveness of stories and rules as commonsense expressions for LLMs.
- The findings emphasize the importance of using appropriate language to express, retrieve, and leverage commonsense for LLMs.
- The study identifies challenges in generating stories, such as commonsense hallucination and semantic drifting, and proposes an iterative self-supervised fine-tuning method to address these issues.
- The limitations of the study include the focus on specific LLMs and the reliance on model-based scoring methods for evaluating stories.

Overall, the study contributes to the understanding of how LLMs retrieve and leverage commonsense, highlighting the potential for further research to refine and improve the commonsense abilities of LLMs.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-26       |
| Abstract | [https://arxiv.org/abs/2402.14355v1](https://arxiv.org/abs/2402.14355v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.14355v1](https://browse.arxiv.org/html/2402.14355v1)       |
| Truncated       | False       |
| Word Count       | 9075       |