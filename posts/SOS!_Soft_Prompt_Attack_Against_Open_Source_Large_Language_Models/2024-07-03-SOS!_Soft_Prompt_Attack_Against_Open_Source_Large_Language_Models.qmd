
---
title: "SOS! Soft Prompt Attack Against Open-Source Large Language Models"
id: "2407.03160v1"
description: "New attack, SOS, targets open-source LLMs, maintaining model utility. Also introduces copyright token for content protection."
author: Ziqing Yang, Michael Backes, Yang Zhang, Ahmed Salem
date: "2024-07-03"
image: "../../img/2407.03160v1/image_1.png"
categories: ['robustness', 'programming', 'security']
format:
  html:
    code-overflow: wrap
---

![](../../img/2407.03160v1/image_1.png)

**Summary:**
The paper presents a novel attack called SOS (Soft prompt attack against Open-Source LLMs) that targets open-source large language models (LLMs). SOS is designed to be computationally efficient and does not require clean data or modification of the model weights, ensuring the model's utility remains intact. The attack addresses security issues in various scenarios, including backdoor attacks, jailbreak attacks, and prompt stealing attacks. The authors demonstrate the effectiveness of SOS across all evaluated targets and present a novel technique called the copyright token, which enables users to mark their copyrighted content and prevent models from using it.

**Key Terms:**

* SOS: Soft prompt attack against Open-Source LLMs
* LLMs: Large language models
* Backdoor attack
* Jailbreak attack
* Prompt stealing attack
* Copyright token

**Major Findings:**

1. SOS is a computationally efficient attack

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-09       |
| Abstract | [https://arxiv.org/abs/2407.03160v1](https://arxiv.org/abs/2407.03160v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.03160v1](https://browse.arxiv.org/html/2407.03160v1)       |
| Truncated       | True       |
| Word Count       | 28326       |