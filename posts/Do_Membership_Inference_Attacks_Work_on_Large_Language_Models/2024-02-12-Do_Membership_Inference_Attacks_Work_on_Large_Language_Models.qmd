
---
title: "Do Membership Inference Attacks Work on Large Language Models?"
id: "2402.07841v1"
description: "Limited success of membership inference attacks on large language models' pre-training data."
author: Michael Duan, Anshuman Suri, Niloofar Mireshghallah, Sewon Min, Weijia Shi, Luke Zettlemoyer, Yulia Tsvetkov, Yejin Choi, David Evans, Hannaneh Hajishirzi
date: "2024-02-12"
image: "../../../bayesian-beagle.png"
categories: ['production']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

**Summary:**
This academic article investigates the effectiveness of Membership Inference Attacks (MIAs) on Large Language Models (LLMs) pre-trained on the Pile dataset. The authors find that existing MIAs barely outperform random guessing for most settings across varying LLM sizes and domains. The poor performance can be attributed to the combination of a large dataset and few training iterations, as well as an inherently fuzzy boundary between members and non-members. Specific settings where LLMs have been shown to be vulnerable to membership inference are also discussed, revealing that the apparent success in such settings can be attributed to a distribution shift.

**Major Findings:**
1. **Ineffectiveness of MIAs on LLMs:** Contrary to previous research, existing MIAs barely outperform random guessing for most settings across varying LLM sizes and domains.
2. **Impact of Large Datasets and Few Training Iter

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x7b-instruct       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.07841v1](https://arxiv.org/abs/2402.07841v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.07841v1](https://browse.arxiv.org/html/2402.07841v1)       |
| Truncated       | True       |
| Word Count       | 39418       |