
---
title: "Exploring the Efficacy of Large Language Models in Summarizing Mental Health Counseling Sessions: A Benchmark Study"
id: "2402.19052v1"
description: "MentalLlama, Mistral, and MentalBART excel in summarizing counseling sessions, but can improve in opportunity costs and perceived effectiveness."
author: Prottay Kumar Adhikary, Aseem Srivastava, Shivani Kumar, Salam Michael Singh, Puneet Manuja, Jini K Gopinath, Vijay Krishnan, Swati Kedia, Koushik Sinha Deb, Tanmoy Chakraborty
date: "2024-02-29"
image: "../../img/2402.19052v1/image_1.png"
categories: ['social-sciences', 'architectures']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.19052v1/image_1.png)

### **Summary:**

- The article explores the effectiveness of Large Language Models (LLMs) in summarizing mental health counseling sessions through aspect-based summarization.
- A new dataset, MentalCLOUDS, is introduced, which consists of 191 counseling sessions with summaries focused on three distinct counseling components.
- Eleven state-of-the-art LLMs are assessed for their ability to address the task of component-guided summarization in counseling.
- Findings suggest that task-specific LLMs, such as MentalLlama, Mistral, and MentalBART, perform better in terms of standard quantitative metrics and expert evaluation.

### **Major Findings:**

1. Task-specific LLMs, MentalLlama, Mistral, and MentalBART, outperform other models in summarizing mental health counseling sessions based on standard quantitative

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x7b-instruct       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.19052v1](https://arxiv.org/abs/2402.19052v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.19052v1](https://browse.arxiv.org/html/2402.19052v1)       |
| Truncated       | False       |
| Word Count       | 16555       |