
---
title: "What Does the Bot Say? Opportunities and Risks of Large Language Models in Social Media Bot Detection"
id: "2402.00371v1"
description: "LLMs improve bot detection but also pose risks, with potential to evade detection."
author: Shangbin Feng, Herun Wan, Ningnan Wang, Zhaoxuan Tan, Minnan Luo, Yulia Tsvetkov
date: "2024-02-01"
image: "../../img/2402.00371v1/image_1.png"
categories: ['architectures', 'robustness', 'security', 'social-sciences']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.00371v1/image_1.png)

### Summary:
- The article explores the opportunities and risks of using Large Language Models (LLMs) in social media bot detection, proposing a novel framework for LLM-based bot detectors. It discusses the performance of various bot detection models, including LLM-based detectors, on different datasets and manipulated versions of the datasets. The distributions of accounts' metadata selected by LLMs for bot detection are examined, and the impact of in-context examples in LLM-based bot detectors is explored. The experiment details, including the datasets used, LLMs employed, baseline methods, and implementation details, are also provided.

### Major Findings:
1. LLMs have the capability to significantly enhance bot detection, but also pose a threat to the reliability of existing bot detection systems.
2. LLM-based bot detectors demonstrate superior performance, especially with instruction tuning, and robustness to manipulation strategies.
3. LLMs do not simply follow established heuristics but rather examine in a case-by-case manner and suggest diverse edits of bot neighborhoods.

### Analysis and Critique:
- The findings suggest that LLMs are effective in preserving the content of bot posts and iteratively refining generations based on feedback from external classifiers. The statistics of added/removed neighbors by LLMs indicate their sophisticated decision-making process. However, the risks associated with LLM-guided manipulation strategies and the ethical considerations of using LLMs in social media bot detection require further research and exploration. The experiment details provide a comprehensive overview of the evaluation of various methods for social bot detection and manipulation strategies, emphasizing the significance of the study in the field.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.00371v1](https://arxiv.org/abs/2402.00371v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.00371v1](https://browse.arxiv.org/html/2402.00371v1)       |
| Truncated       | True       |
| Word Count       | 23494       |