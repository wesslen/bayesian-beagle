
---
title: "Both Matter: Enhancing the Emotional Intelligence of Large Language Models without Compromising the General Intelligence"
id: "2402.10073v1"
description: "Emotional Intelligence (EI) is crucial for AI assistants; MoEI enhances EI without compromising general intelligence."
author: Weixiang Zhao, Zhuojun Li, Shilong Wang, Yang Wang, Yulin Hu, Yanyan Zhao, Chen Wei, Bing Qin
date: "2024-02-15"
image: "../../img/2402.10073v1/image_1.png"
categories: ['hci', 'architectures', 'social-sciences', 'production']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.10073v1/image_1.png)

**Summary:**
The section provides a comprehensive overview of the evaluation of Emotional Intelligence (EI) and General Intelligence (GI) in large language models (LLMs) using the MoEI method. It includes a taxonomy of emotional intelligence, implementation details in EIBENCH, performance on larger LLM backbones, and comparisons with baselines across different tasks and datasets. The results demonstrate the effectiveness of MoEI in enhancing EI and maintaining GI across various LLM architectures and sizes.

**Major Findings:**
1. The MoEI method significantly enhances the EI of LLMs while maintaining their GI.
2. MoEI outperforms other methods in enhancing EI and safeguarding GI across different tasks and datasets.
3. The comparison with baselines and different volumes of replayed data highlights the effectiveness of MoEI in improving emotional and general intelligence capabilities.

**Analysis and Critique:**
- The section provides valuable insights into the effectiveness of the MoEI method in enhancing EI and maintaining GI in LLMs.
- It highlights the importance of balancing EI-enhancement and GI-maintenance, as well as the significance of modular parameter expansion and intra-inter modulation in achieving effective EI enhancement.
- The results and findings presented in this section have broader implications for the development and improvement of LLMs in the context of emotional and general intelligence.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-16       |
| Abstract | [https://arxiv.org/abs/2402.10073v1](https://arxiv.org/abs/2402.10073v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.10073v1](https://browse.arxiv.org/html/2402.10073v1)       |
| Truncated       | True       |
| Word Count       | 22380       |