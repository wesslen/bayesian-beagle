
---
title: "Prompting Encoder Models for Zero-Shot Classification: A Cross-Domain Study in Italian"
id: "2407.20654v1"
description: "Smaller, domain-specific Italian LMs improve performance in legal/bureaucratic tasks, even with limited resources, offering new insights for specialized contexts."
author: Serena Auriemma, Martina Miliani, Mauro Madeddu, Alessandro Bondielli, Lucia Passaro, Alessandro Lenci
date: "2024-07-30"
image: "../../../bayesian-beagle.png"
categories: ['prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

**Summary:**

This paper explores the feasibility of employing smaller, domain-specific encoder Language Models (LMs) alongside prompting techniques to enhance performance in specialized contexts, focusing on the Italian bureaucratic and legal language. The study evaluates two models, BureauBERTo and Ita-Legal-BERT, in zero-shot classification tasks using prompt-based techniques. The results indicate that further pre-trained models may show diminished robustness in general knowledge but exhibit superior adaptability for domain-specific tasks, even in a zero-shot setting. The application of calibration techniques and in-domain verbalizers significantly enhances the efficacy of encoder models.

**Major Findings:**

1. Further pre-trained models, such as BureauBERTo and Ita-Legal-BERT, exhibit superior adaptability for domain-specific tasks in a zero-shot setting.
2. The application of calibration techniques and in-domain verbalizers significantly enhances the efficacy of encoder models.
3. Domain-specialized models prove to be particularly advantageous in scenarios where in-domain resources or expertise are scarce.

**Analysis and Critique:**

While the study provides valuable insights into the use of Italian models in specialized contexts, there are some potential limitations and areas for further research. The study focuses on a specific language (Italian) and two domain-specific models, which may not generalize to other languages or models. Additionally, the evaluation of the models is limited to zero-shot classification tasks, and further research is needed to assess their performance in other NLP tasks. Lastly, the study does not address potential biases or ethical considerations in the use of these models.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-06       |
| Abstract | [https://arxiv.org/abs/2407.20654v1](https://arxiv.org/abs/2407.20654v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.20654v1](https://browse.arxiv.org/html/2407.20654v1)       |
| Truncated       | False       |
| Word Count       | 12221       |