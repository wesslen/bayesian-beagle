
---
title: "Trained Without My Consent: Detecting Code Inclusion In Language Models Trained on Code"
id: "2402.09299v1"
description: "Code auditing for Large Language Models (LLMs) is challenging due to potential copyright infringement. TraWiC offers a solution."
author: Vahid Majdinasab, Amin Nikanjam, Foutse Khomh
date: "2024-02-14"
image: "../../img/2402.09299v1/image_1.png"
categories: ['security', 'programming', 'production', 'robustness', 'architectures']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.09299v1/image_1.png)

### Summary:
- The article introduces TraWiC, a model-agnostic method for detecting code inclusion in Large Language Models (LLMs) trained on code. It outperforms traditional clone detection tools and addresses the challenge of auditing code developed using LLMs.
- The methodology for detecting dataset inclusion in language models trained on code is detailed, including the Fill-In-the-Middle (FIM) technique and an end-to-end data processing example using TraWiC.
- The section discusses the selection of the random forests classifier for dataset inclusion detection, the comparison with clone detection approaches, and the effect of different classification methods on TraWiC's performance.
- The sensitivity analysis of the approach for detecting dataset inclusion in language models trained on code is presented, along with the impact of noise ratio on precision, accuracy, F-score, sensitivity, and specificity.
- The conclusion section highlights the significance of TraWiC and outlines future plans for testing TraWiC on more capable LLMs and investigating other aspects of code for conducting model inclusion attacks.

### Major Findings:
1. TraWiC, a model-agnostic approach, can detect code inclusion in LLMs with a recall of up to 99.19%.
2. The random forests classifier is effective for dataset inclusion detection, outperforming traditional clone detection tools.
3. The approach is robust in detecting dataset inclusion despite deliberate obfuscations in the training dataset.

### Analysis and Critique:
- The article provides valuable insights into the challenges of auditing code developed using LLMs and proposes an effective solution in the form of TraWiC. However, further research is needed to test TraWiC on more capable LLMs and investigate other aspects of code for conducting model inclusion attacks.
- The methodology and findings of the article contribute to the field of software engineering and intellectual property protection. However, potential biases and limitations in the experimental design should be carefully considered.
- The sensitivity analysis and feature importance provide a comprehensive understanding of the approach's performance, but methodological issues related to the impact of noise on precision and accuracy should be further explored.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-15       |
| Abstract | [https://arxiv.org/abs/2402.09299v1](https://arxiv.org/abs/2402.09299v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.09299v1](https://browse.arxiv.org/html/2402.09299v1)       |
| Truncated       | True       |
| Word Count       | 28277       |