
---
title: "MultiPLY: A Multisensory Object-Centric Embodied Large Language Model in 3D World"
id: "2401.08577v1"
description: "MultiPLY is a large language model that incorporates multisensory interactive data for improved performance."
author: Yining Hong, Zishuo Zheng, Peihao Chen, Yian Wang, Junyan Li, Chuang Gan
date: "2024-01-16"
image: "../../../bayesian-beagle.png"
categories: ['hci', 'social-sciences']
format:
  html:
    code-overflow: wrap
---

![](None)

### Summary:

The article introduces MultiPLY, a multisensory embodied large language model that encodes object-centric multisensory representations, including visual, audio, tactile, and thermal information. The model is trained on a large-scale multisensory interaction dataset comprising 500k data collected by an agent actively engaging with 3D embodied environments. MultiPLY excels at multiple tasks, including multisensory captioning, question answering, dialogue, manipulation, navigation, tool use, task decomposition, and more. The model outperforms baselines by a large margin on object retrieval, tool use, multisensory captioning, and task decomposition. The section also discusses the construction of the Multisensory-Universe dataset, the process of generating tasks in a 3D scene, and the actions that can be used to interact with the environment.

### Major Findings:
1. MultiPLY excels at multiple tasks, including multisensory captioning, question answering, dialogue, manipulation, navigation, tool use, and task decomposition.
2. The model outperforms baselines by a large margin on object retrieval, tool use, multisensory captioning, and task decomposition.
3. The Multisensory-Universe dataset comprises 500k multisensory data collected by an agent actively engaging with 3D embodied environments.

### Analysis and Critique:
The article presents a novel approach to incorporating multisensory interactive data into large language models, which has significant implications for advancing the field of embodied language understanding and interaction with the 3D world. However, the lack of detailed navigation and control policy in the model is acknowledged as a limitation, indicating potential areas for future research and development. Additionally, the practical application of the model in real-world scenarios and its generalizability to diverse environments could be further explored.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-31       |
| Abstract | [https://arxiv.org/abs/2401.08577v1](https://arxiv.org/abs/2401.08577v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.08577v1](https://browse.arxiv.org/html/2401.08577v1)       |
| Truncated       | True       |
| Word Count       | 19775       |