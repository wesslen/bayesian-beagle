
---
title: "SPARQL Generation: an analysis on fine-tuning OpenLLaMA for Question Answering over a Life Science Knowledge Graph"
id: "2402.04627v1"
description: "LLMs improve question answering over knowledge graphs; semantic clues boost performance by 33%."
author: Julio C. Rangel, Tarcisio Mendes de Farias, Ana Claudia Sima, Norio Kobayashi
date: "2024-02-07"
image: "../../img/2402.04627v1/image_1.png"
categories: ['hci']
format:
  html:
    code-overflow: wrap
---

![](../../img/2402.04627v1/image_1.png)

### Summary:
- The article evaluates strategies for fine-tuning the OpenLlama Large Language Model (LLM) for question answering over life science knowledge graphs. It proposes an end-to-end data augmentation approach for extending a set of existing queries over a given knowledge graph towards a larger dataset of semantically enriched question-to-SPARQL query pairs. The study also investigates the role of semantic "clues" in the queries, such as meaningful variable names and inline comments. The approach is evaluated over the real-world Bgee gene expression knowledge graph, showing that semantic clues can improve model performance by up to 33% compared to a baseline with random variable names and no comments included.

### Major Findings:
1. The study evaluates strategies for fine-tuning the OpenLlama Large Language Model (LLM) for question answering over life science knowledge graphs.
2. An end-to-end data augmentation approach is proposed for extending a set of existing queries over a given knowledge graph towards a larger dataset of semantically enriched question-to-SPARQL query pairs.
3. The role of semantic "clues" in the queries, such as meaningful variable names and inline comments, is investigated, showing that semantic clues can improve model performance by up to 33% compared to a baseline with random variable names and no comments included.

### Analysis and Critique:
- The study provides valuable insights into the challenges and strategies for fine-tuning large language models for question answering over domain-specific knowledge graphs.
- The approach of augmenting the training set of question-to-SPARQL query pairs is effective in improving the performance of the OpenLlama model.
- However, the study also highlights the potential limitations of knowledge transfer in fine-tuning the model, as it may not always lead to significant improvements in performance.
- The findings suggest the need for further research and exploration of more advanced strategies for fine-tuning large language models for question answering over domain-specific knowledge graphs.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-08       |
| Abstract | [https://arxiv.org/abs/2402.04627v1](https://arxiv.org/abs/2402.04627v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.04627v1](https://browse.arxiv.org/html/2402.04627v1)       |
| Truncated       | False       |
| Word Count       | 7411       |