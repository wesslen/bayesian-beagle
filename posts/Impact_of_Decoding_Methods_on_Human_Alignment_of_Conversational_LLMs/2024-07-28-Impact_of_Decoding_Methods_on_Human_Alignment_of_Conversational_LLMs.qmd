
---
title: "Impact of Decoding Methods on Human Alignment of Conversational LLMs"
id: "2407.19526v1"
description: "TL;DR: Decoding methods impact LLM-human conversation alignment. Fewer beams, lower P-values improve alignment, but results vary by conversation type."
author: Shaz Furniturewala, Kokil Jaidka, Yashvardhan Sharma
date: "2024-07-28"
image: "https://browse.arxiv.org/html/2407.19526v1/extracted/5759861/complete_graph.png"
categories: ['social-sciences', 'hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2407.19526v1/extracted/5759861/complete_graph.png)

### Summary:

This paper examines the impact of decoding methods on the alignment between LLM-generated and human conversations. The authors introduce new measures of alignment in substance, style, and psychometric orientation and experiment with two conversation datasets. The results show that better alignment is attributed to fewer beams in Beam Search and lower values of P in Nucleus Sampling. The study also finds that task-oriented and open-ended datasets perform differently in terms of alignment, indicating the significance of taking into account the context of the interaction.

### Major Findings:

1. **Effect of Decoding Methods**: The study reveals that better alignment is achieved with fewer beams in Beam Search and lower values of P in Nucleus Sampling.
2. **Performance of Datasets**: The performance of task-oriented and open-ended datasets varies in terms of alignment, highlighting the importance of considering the context of the interaction.
3. **Alignment Metrics**: The authors introduce new metrics for measuring LLM alignment to human conversations in substance, style, and psychometric orientation.

### Analysis and Critique:

The paper provides valuable insights into the impact of decoding methods on the alignment between LLM-generated and human conversations. However, the study is limited to two specific aspects of style: politeness and negotiation. While these aspects are relevant to the task-specific dataset used, the results may not generalize to other facets of style on other datasets. The authors acknowledge this limitation and plan to expand on these experiments in future work.

Additionally, the study could benefit from a more comprehensive analysis of the impact of decoding methods on the alignment of LLM-generated conversations. For instance, the authors could explore the effect of decoding methods on other aspects of style, such as formality and sentiment, and on the semantic content of the conversations.

Furthermore, the study could be improved by comparing the performance of the proposed decoding methods with other decoding methods, such as Top-p Sampling and Temperature Scaling. This would provide a more comprehensive understanding of the strengths and weaknesses of different decoding methods in improving the alignment between LLM-generated and human conversations.

Finally, the authors could consider conducting a user study to evaluate the perceived quality of the LLM-generated conversations. This would provide a more

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-30       |
| Abstract | [https://arxiv.org/abs/2407.19526v1](https://arxiv.org/abs/2407.19526v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.19526v1](https://browse.arxiv.org/html/2407.19526v1)       |
| Truncated       | False       |
| Word Count       | 3736       |