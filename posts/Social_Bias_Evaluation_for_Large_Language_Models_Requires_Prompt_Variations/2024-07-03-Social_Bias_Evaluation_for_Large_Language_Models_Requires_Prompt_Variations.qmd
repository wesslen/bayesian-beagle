
---
title: "Social Bias Evaluation for Large Language Models Requires Prompt Variations"
id: "2407.03129v1"
description: "LLMs' performance and bias vary greatly with prompts; diverse prompts are recommended for accurate comparison."
author: Rem Hida, Masahiro Kaneko, Naoaki Okazaki
date: "2024-07-03"
image: "../../img/2407.03129v1/image_1.png"
categories: ['robustness', 'social-sciences', 'hci', 'prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](../../img/2407.03129v1/image_1.png)

**Summary:**

This paper investigates the sensitivity of 12 large language models (LLMs) to prompt variations in evaluating task performance and social bias, focusing on a question-answering dataset, BBQ. The study categorizes three prompt variation factors: 1) task instruction and prompt for task recognition, 2) few-shot examples for task performance improvement, and 3) debias-prompt for bias mitigation. The experimental results reveal that LLMs are highly sensitive to prompts in bias evaluation, with the ranking of LLMs and debiasing effectiveness fluctuating when comparing models for task performance and bias scores. The study also shows that LLMs have tradeoffs among task performance and social bias caused by the prompts, and the ambiguity of instances contributes to the sensitivity in advanced LLMs.

**Major Findings:**

1. LLMs are highly sensitive to prompts in bias evaluation, with the ranking of LLMs and debiasing effectiveness fluctuating when comparing models for task performance and bias scores.
2. LLMs have tradeoffs among task performance and social bias caused by the prompts, with less bias from prompt setting potentially resulting in reduced performance.
3. The ambiguity of instances contributes to the sensitivity in advanced LLMs, leading to various outputs.

**Analysis and Critique:**

The paper provides a comprehensive analysis of the sensitivity of LLMs to prompt variations in evaluating task performance and social bias. However, the study is limited to a single question-answering dataset, BBQ, and does not explore other types of datasets or tasks. Additionally, the paper does not discuss the potential impact of prompt variations on the fairness and ethical considerations of LLMs. Further research is needed to investigate the generalizability of the findings to other datasets and tasks and to explore the ethical implications of prompt variations in LLMs.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-09       |
| Abstract | [https://arxiv.org/abs/2407.03129v1](https://arxiv.org/abs/2407.03129v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.03129v1](https://browse.arxiv.org/html/2407.03129v1)       |
| Truncated       | False       |
| Word Count       | 17789       |