
---
title: "Beyond Probabilities: Unveiling the Misalignment in Evaluating Large Language Models"
id: "2402.13887v1"
description: "TL;DR: Probability-based evaluation of Large Language Models for MCQs has limitations, needs improvement."
author: Chenyang Lyu, Minghao Wu, Alham Fikri Aji
date: "2024-02-21"
image: "https://browse.arxiv.org/html/2402.13887v1/x1.png"
categories: ['production', 'social-sciences', 'architectures']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.13887v1/x1.png)

### **Summary:**
- Large Language Models (LLMs) have revolutionized natural language processing (NLP) research and applications.
- Current evaluation frameworks rely on output probabilities of LLMs for predictions, but this may not align with real-world LLM usage scenarios.
- Probability-based evaluation methods inadequately align with generation-based prediction, raising questions about their efficacy.

### **Major Findings:**
1. Probability-based evaluation methods do not effectively correspond with generative predictions.
2. Label-based predictions generally show stronger alignment with generation-based predictions compared to sequence-based predictions.
3. MCQ benchmarks may not be adequately correlated with human judgments, highlighting the need for more nuanced evaluation frameworks.

### **Analysis and Critique:**
- The study raises concerns about the reliability of probability-based evaluation outcomes derived from popular benchmarks.
- The misalignment between evaluation measures and real-world applicability underscores the necessity for a more holistic approach to LLM evaluation.
- The study emphasizes the urgent need for an evaluation approach that ensures accurate and reliable assessments of LLM capabilities, more closely aligned with real-world usage scenarios.

The study provides valuable insights into the limitations of current LLM evaluation methodologies and highlights the need for more comprehensive and nuanced evaluation frameworks to accurately assess the capabilities of LLMs. The findings underscore the importance of aligning evaluation criteria with real-world applications and emphasize the need for a more deliberate pace of research to ensure the reliability and effectiveness of LLM advancements.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-03-13       |
| Abstract | [https://arxiv.org/abs/2402.13887v1](https://arxiv.org/abs/2402.13887v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.13887v1](https://browse.arxiv.org/html/2402.13887v1)       |
| Truncated       | False       |
| Word Count       | 7539       |