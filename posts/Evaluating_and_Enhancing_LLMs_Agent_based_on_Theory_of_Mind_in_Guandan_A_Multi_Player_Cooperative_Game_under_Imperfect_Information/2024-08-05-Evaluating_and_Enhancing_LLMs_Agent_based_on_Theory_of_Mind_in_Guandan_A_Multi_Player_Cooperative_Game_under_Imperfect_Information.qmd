
---
title: "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information"
id: "2408.02559v1"
description: "LLMs can facilitate collaboration in complex games, but still lag behind RL models. They show Theory of Mind capabilities, improving performance against opposing agents."
author: Yauwai Yim, Chunkit Chan, Tianyu Shi, Zheye Deng, Wei Fan, Tianshi Zheng, Yangqiu Song
date: "2024-08-05"
image: "../../img/2408.02559v1/image_1.png"
categories: ['architectures']
format:
  html:
    code-overflow: wrap
---

![](../../img/2408.02559v1/image_1.png)

**Summary:**

This study evaluates the performance of open-source and closed-source Large Language Models (LLMs) in a complex card game, Guandan, which involves imperfect information and requires collaboration among agents. The research aims to explore the applicability of knowledge acquired by these models in sophisticated text-based games and compare their performance to established baselines using other types of agents. The study proposes a Theory of Mind (ToM) planning technique that allows LLM agents to adapt their strategy against various adversaries using only game rules, current state, and historical context as input. An external tool was incorporated to mitigate the challenge of dynamic and extensive action spaces in this card game. The results show that while a performance gap exists between current LLMs and state-of-the-art reinforcement learning (RL) models, LLMs demonstrate ToM capabilities in this game setting and consistently improve their performance against opposing agents.

**Major Findings:**

1. LLMs exhibit subpar performance compared to RL-based approaches in intricate and realistic scenarios, such as the Guandan card game.
2. The proposed ToM planning method optimizes LLM-agent's decision-making and collaboration in multi-agent gaming environments.
3. An RL-based model was developed to address LLMs' challenges in adapting to dynamic changes and extensive legal action lists.

**Analysis and Critique:**

The study provides valuable insights into the performance of LLMs in complex, multi-agent gaming environments. However, it is essential to acknowledge the limitations of LLMs without fine-tuning when faced with cooperative tasks involving imperfect information. The research highlights the significant limitations of most models in addressing such challenges effectively. Additionally, the study's focus on the Guandan card game may limit the generalizability of the findings to other complex social interactions and strategic thinking tasks. Future research should explore the potential of LLMs in a broader range of real-world tasks and address the identified limitations.

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-08-06       |
| Abstract | [https://arxiv.org/abs/2408.02559v1](https://arxiv.org/abs/2408.02559v1)        |
| HTML     | [https://browse.arxiv.org/html/2408.02559v1](https://browse.arxiv.org/html/2408.02559v1)       |
| Truncated       | False       |
| Word Count       | 23008       |