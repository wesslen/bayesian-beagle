
---
title: "Supervised Knowledge Makes Large Language Models Better In-context Learners"
id: "2312.15918v1"
description: "LLMs' in-context learning is enhanced through task-specific fine-tuned Language Models, improving generalizability and factuality."
author: ['Linyi Yang', 'Shuibai Zhang', 'Zhuohao Yu', 'Guangsheng Bao', 'Yidong Wang', 'Jindong Wang', 'Ruochen Xu', 'Wei Ye', 'Xing Xie', 'Weizhu Chen', 'Yue Zhang']
date: "2023-12-26"
image: "https://browse.arxiv.org/html/2312.15918v1/x1.png"
categories: ['prompt-engineering']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2312.15918v1/x1.png)

### Summary

This paper introduces SuperContext, a method to enhance the in-context learning abilities of Large Language Models (LLMs) using task-specific fine-tuned Language Models (SLMs). The research demonstrates that SuperContext significantly improves generalizability and factuality of LLMs in natural language understanding and question answering tasks. The findings of the paper suggest that integrating SLM outputs into LLM prompts can lead to better performance in OOD generalizability and factuality.

### Key Findings

1. **Enhanced Reliability**: SuperContext significantly improves the reliability of LLMs by generalizing out-of-distribution data, benefiting from discriminative models, and minimizing hallucinations in generative tasks.

2. **Improved Performance**: The method outperforms traditional in-context learning methods, surpassing both original LLMs and SLMs, showing substantial benefits compared to few-shot in-context learning.

3. **Use of Supervised Knowledge**: SuperContext leverages supervised knowledge from fine-tuned discriminative models to improve the in-context learning of LLMs, demonstrating superior performance in managing OOD data and mitigating hallucinations.

### Method

- **In-context Learning Baseline**: The paper discusses the traditional in-context learning baseline and contrasts it with the proposed SuperContext approach. 
- **SuperContext**: The paper details the SuperContext method, which involves integrating fine-tuned discriminative model outputs into LLM prompts to facilitate in-context learning.

### Experiments

- **Setup**: The paper outlines the experimental setup, including the source models, datasets, and baselines used for evaluating the performance of SuperContext.
- **NLU Results**: Results show that SuperContext significantly outperforms traditional in-context learning and performs well across various NLU tasks.
- **QA Results**: SuperContext demonstrates substantial improvements in mitigating hallucination in question answering tasks.

### Critique

While the paper provides comprehensive empirical evidence of the effectiveness of SuperContext in enhancing LLMs, there are some potential concerns and limitations that should be addressed:
- The paper could benefit from a more robust critique of the limitations and potential biases in the experimental setup.
- Ethical implications and potential societal impacts of deploying advanced language models should be further discussed.
- The paper may lack a detailed discussion of potential challenges or failure cases of the SuperContext method.

Overall, the paper provides valuable insights into improving the generalizability and factuality of LLMs through the use of supervised knowledge and discriminative models. However, further research and discussion are needed to address potential ethical, societal, and methodological considerations.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [http://arxiv.org/abs/2312.15918v1](http://arxiv.org/abs/2312.15918v1)        |
| HTML     | [https://browse.arxiv.org/html/2312.15918v1](https://browse.arxiv.org/html/2312.15918v1)       |
| Truncated       | False       |
| Word Count       | 12183       |