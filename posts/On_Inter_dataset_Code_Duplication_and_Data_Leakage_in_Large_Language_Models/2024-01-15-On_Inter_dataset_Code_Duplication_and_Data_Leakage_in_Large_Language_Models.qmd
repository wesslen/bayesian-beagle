
---
title: "On Inter-dataset Code Duplication and Data Leakage in Large Language Models"
id: "2401.07930v1"
description: "Large language models (LLMs) may have inflated performance metrics due to inter-dataset code duplication."
author: José Antonio Hernández López, Boqi Chen, Tushar Sharma, Dániel Varró
date: "2024-01-15"
image: "../../../bayesian-beagle.png"
categories: ['programming', 'education', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](../../../bayesian-beagle.png)

### Summary:
The article explores the phenomenon of inter-dataset code duplication in large language models (LLMs) and its impact on evaluating LLMs across diverse software engineering (SE) tasks. It discusses the presence of inter-dataset code duplication in datasets used for LLM-based solutions and its potential negative impact on the reliability of language model evaluations. The study also highlights the performance of different models for code translation, summarization, and search tasks, emphasizing the differences in performance between biased and unbiased groups.

### Major Findings:
1. The study reveals a potential threat to the evaluation of various LLMs across multiple SE tasks due to inter-dataset code duplication.
2. Larger language models are more susceptible to the impact of inter-dataset code duplication, and lightweight fine-tuning techniques are also more vulnerable to this threat.
3. The evaluation of different models for code translation, summarization, and search tasks shows differences in performance between biased and unbiased groups, indicating potential biases in model performance.

### Analysis and Critique:
The study's findings emphasize the importance of carefully considering dataset composition in pre-training and fine-tuning phases of LLM-based solutions. It also highlights the potential impact of inter-dataset code duplication on the validity of LLM evaluations in various software engineering tasks. The article provides valuable insights into the performance of different models for code-related tasks, shedding light on potential biases and limitations. However, the study's scope could be further expanded to include additional programming languages and software engineering tasks, as well as open source decoding-only language models, to provide a more comprehensive understanding of the impact of different language models in software development.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-26       |
| Abstract | [https://arxiv.org/abs/2401.07930v1](https://arxiv.org/abs/2401.07930v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.07930v1](https://browse.arxiv.org/html/2401.07930v1)       |
| Truncated       | True       |
| Word Count       | 19828       |