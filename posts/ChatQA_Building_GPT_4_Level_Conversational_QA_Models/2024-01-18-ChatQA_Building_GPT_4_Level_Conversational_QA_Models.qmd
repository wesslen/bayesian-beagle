
---
title: "ChatQA: Building GPT-4 Level Conversational QA Models"
id: "2401.10225v1"
description: "ChatQA family achieves GPT-4 level accuracies using two-stage tuning method and dense retriever for conversational QA."
author: ['Zihan Liu', 'Wei Ping', 'Rajarshi Roy', 'Peng Xu', 'Mohammad Shoeybi', 'Bryan Catanzaro']
date: "2024-01-18"
image: "https://browse.arxiv.org/html/2401.10225v1/x1.png"
categories: ['production', 'education', 'architectures']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.10225v1/x1.png)

**Summary:**

The article introduces ChatQA, a series of conversational question answering (QA) models designed to achieve GPT-4 level accuracies. The authors propose a two-stage instruction tuning method and a dense retriever for retrieval-augmented generation in conversational QA. They demonstrate superior performance of ChatQA-70B compared to GPT-4 on 10 conversational QA datasets. Additionally, the article discusses the importance of conversational QA in real-world applications and the challenges involved in building conversational QA models.

### Major Findings:
1. **ChatQA Models:** ChatQA-70B outperforms GPT-4 in terms of average score on 10 conversational QA datasets.
   
2. **Fine-Tuning and Retrieval:** The proposed two-stage instruction tuning method and dense retriever significantly enhance the models' capability for zero-shot conversational QA tasks, outperforming regular instruction tuning or RLHF-based recipes.

3. **Unanswerable Scenario:** Adding "unanswerable" samples in instruction tuning reduces model hallucination, improving the model's performance in handling scenarios where answers are unavailable.

### Analysis and Critique:
The article provided valuable insights into the development of ChatQA models. However, it lacked a detailed comparison with other existing conversational QA models, which could have further strengthened the findings. Additionally, the article focused on the model's technical aspects but did not extensively discuss potential ethical implications or biases that might arise from the deployment of ChatQA models. Moreover, while the results are promising, further external validation and testing are necessary to establish the generalizability of the ChatQA models across diverse conversational QA tasks and datasets.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-02-02       |
| Abstract | [http://arxiv.org/abs/2401.10225v1](http://arxiv.org/abs/2401.10225v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.10225v1](https://browse.arxiv.org/html/2401.10225v1)       |
| Truncated       | True       |
| Word Count       | 18597       |