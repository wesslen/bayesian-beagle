
---
title: "Fact-and-Reflection (FaR) Improves Confidence Calibration of Large Language Models"
id: "2402.17124v1"
description: "LLM confidence calibration improved by Fact-and-Reflection prompting method, reducing Expected Calibration Error by 23.5%."
author: Xinran Zhao, Hongming Zhang, Xiaoman Pan, Wenlin Yao, Dong Yu, Tongshuang Wu, Jianshu Chen
date: "2024-02-27"
image: "https://browse.arxiv.org/html/2402.17124v1/x1.png"
categories: ['prompt-engineering', 'robustness']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2402.17124v1/x1.png)

### **Summary:**
- The study explores how different prompting strategies influence Large Language Model (LLM) confidence calibration and proposes Fact-and-Reflection (FaR) prompting to improve LLM calibration.
- The FaR prompting method consists of two steps: fact elicitation and reflective reasoning, which significantly improves model confidence calibration.
- FaR prompting elicits the model to express concerns when answering questions they are uncertain of, which helps trigger retrieval augmentation for solving harder instances.

### **Major Findings:**
1. Different prompting methods generally suffer from over-confidence, and exhibit poor calibration at the instance level.
2. FaR prompting significantly reduces the confidence calibration error across various common metrics.
3. FaR prompting intrigues the model to generate cautious answers that express concerns, which helps detect hard instances that may benefit from retrieval augmented generation.

### **Analysis and Critique:**
- The study provides valuable insights into the influence of different prompting strategies on LLM confidence calibration and proposes an effective FaR prompting method to improve calibration.
- However, the study does not extensively explore the influence of FaR prompting on human instruction datasets, and the inner model dynamics are not closely examined.
- The study also highlights the limitations of using human-annotated external knowledge and the potential ethical considerations related to the datasets used in the research.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-06-05       |
| Abstract | [https://arxiv.org/abs/2402.17124v1](https://arxiv.org/abs/2402.17124v1)        |
| HTML     | [https://browse.arxiv.org/html/2402.17124v1](https://browse.arxiv.org/html/2402.17124v1)       |
| Truncated       | False       |
| Word Count       | 8439       |