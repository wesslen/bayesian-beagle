
---
title: "Collective Innovation in Groups of Large Language Models"
id: "2407.05377v1"
description: "LLMs playing a video game show collective innovation, with dynamic connectivity boosting performance."
author: Eleni Nisioti, Sebastian Risi, Ida Momennejad, Pierre-Yves Oudeyer, Cl√©ment Moulin-Frier
date: "2024-07-07"
image: "https://browse.arxiv.org/html/2407.05377v1/x1.png"
categories: ['social-sciences', 'education', 'hci']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2407.05377v1/x1.png)

### Summary:

This study explores the use of Large Language Models (LLMs) in collective innovation tasks, specifically in the context of playing Little Alchemy 2, a creative video game. The research aims to understand how LLMs perform in isolation and how their social connectivity affects their collective behavior. The authors argue that LLMs can be useful in computational studies of cultural evolution as generative models of individuals.

### Major Findings:

1. LLMs exhibit both useful skills and crucial limitations: When studying an LLM in isolation, the authors discovered that LLMs have the ability to leverage semantic knowledge about the task and exhibit multi-step reasoning. However, they also found that LLMs struggle with factual knowledge and exploration, which are essential for efficiently exploring the search space.

2. Groups with dynamic connectivity outperform fully-connected groups: The study found that groups of LLMs with dynamic connectivity, where agents are divided into sub-groups and visit other groups with a random probability, outperform fully-connected groups. This observation is in agreement with previous human and computational studies, which suggest that partially-connected groups are at an advantage due to the tree-like structure of innovation landscapes.

3. LLMs can benefit from social information but exhibit imperfect copying: The authors observed that LLMs can learn from the behavior of other agents and benefit from social information. However, they also found that LLMs exhibit imperfect copying, as there is some delay between the moment a neighbor of the LLM crafts an item and the LLM crafts it itself.

### Analysis and Critique:

* The study provides valuable insights into the use of LLMs in collective innovation tasks and highlights the importance of social connectivity in improving collective performance. However, the authors acknowledge that their work has limitations, such as the inability of smaller, open-source models to learn the task sufficiently well to lead to interesting emergent behaviors.
* The authors also note that their experiments did not examine whether pre-training equipped the LLMs with the ability to explore in-context, leverage common-sense knowledge, or memorize the solution of Little Alchemy 2. This leaves room for further research to explore these aspects and their impact on the performance of LLMs in collective innovation tasks.
* The study's findings have important implications for understanding how multi-

## Appendix

|          |          |
|----------|----------|
| Model     | accounts/fireworks/models/mixtral-8x22b-instruct       |
| Date Generated     | 2024-07-09       |
| Abstract | [https://arxiv.org/abs/2407.05377v1](https://arxiv.org/abs/2407.05377v1)        |
| HTML     | [https://browse.arxiv.org/html/2407.05377v1](https://browse.arxiv.org/html/2407.05377v1)       |
| Truncated       | False       |
| Word Count       | 8010       |