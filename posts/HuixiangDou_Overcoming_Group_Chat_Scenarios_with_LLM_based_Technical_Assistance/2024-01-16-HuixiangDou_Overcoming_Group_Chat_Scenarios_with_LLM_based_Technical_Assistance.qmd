
---
title: "HuixiangDou: Overcoming Group Chat Scenarios with LLM-based Technical Assistance"
id: "2401.08772v1"
description: "HuixiangDou is a technical assistant for algorithm developers, designed for group chat scenarios, with code available on GitHub."
author: ['Huanjun Kong', 'Songyang Zhang', 'Kai Chen']
date: "2024-01-16"
image: "https://browse.arxiv.org/html/2401.08772v1/extracted/5318483/baseline.png"
categories: ['education']
format:
  html:
    code-overflow: wrap
---

![](https://browse.arxiv.org/html/2401.08772v1/extracted/5318483/baseline.png)

### Summary of the Article:
This article presents HuixiangDou, a technical assistant powered by Large Language Models (LLM), designed to assist with open-source algorithm projects such as computer vision and deep learning projects from OpenMMLab. The article outlines the challenges of integrating such assistants into instant messaging group chats and discusses the evolution of the approach, from the baseline version to the improved and final versions. It also details the experiments conducted to fine-tune the models and evaluate their performance in group chat scenarios.

### Major Findings:
1. The Evolution of Approach
    - Baseline version suffered from hallucination issues, which led to the development of improved and final versions to address this challenge.
    - The improved version focused on refuse-to-answer scenarios, utilizing Reject and Response Pipelines to filter out non-technical content and improve precision in answering technical queries.
    - The final version enhanced the long context capability of the chat model, extended the Response Pipeline, and incorporated security measures to ensure safe and reliable interactions.

2. Experiments Conducted
    - Baseline fine-tuned models experienced issues with hallucinations, leading to insights on data quality issues and challenges in achieving accurate domain-specific responses.
    - RAG in Reject Pipeline and LLM Scoring were utilized to determine the likelihood of a query being a question, refine refusal response precision, and evaluate the relevance between questions and background.
    - Long Context and LLM Paging experiments focused on maximizing the capability of models to handle extensive and complex queries in group chat scenarios.

3. Limitations and Future Work
    - Identified limitations include difficulties in understanding professional user queries, the need for further pretraining, the loss of contextual information through message division, and the inability to support multimodal queries with images.

### Analysis and Critique:
The article provides a comprehensive overview of the challenges and iterative improvements in developing a technical assistant for group chat scenarios. However, it does not extensively discuss the ethical implications and user perspective of integrating such assistants into instant messaging platforms. Additionally, the experiments and solutions presented are primarily focused on technical aspects, with limited discussion on user experience and potential biases that could arise from the use of such assistants. The article also lacks a comparative analysis with existing solutions, which could provide a clearer understanding of the novel contributions of HuixiangDou. Further research is needed to address the identified limitations and improve the usability and reliability of the technical assistant in real-world group chat settings.

## Appendix

|          |          |
|----------|----------|
| Model     | gpt-3.5-turbo-1106       |
| Date Generated     | 2024-01-29       |
| Abstract | [http://arxiv.org/abs/2401.08772v1](http://arxiv.org/abs/2401.08772v1)        |
| HTML     | [https://browse.arxiv.org/html/2401.08772v1](https://browse.arxiv.org/html/2401.08772v1)       |
| Truncated       | False       |
| Word Count       | 5437       |